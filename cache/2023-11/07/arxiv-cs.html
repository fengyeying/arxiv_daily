<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Fri  3 Nov 23  to  Mon  6 Nov 23, announced Tue,  7 Nov 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item559">Cross-lists</a></li>
<li><a href="#item639">Replacements</a></li>
</ul>
<small>[ total of 1068 entries:  <b>1-1068</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Tue,  7 Nov 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02078" title="Abstract">arXiv:2311.02078</a> [<a href="/pdf/2311.02078" title="Download PDF">pdf</a>, <a href="/ps/2311.02078" title="Download PostScript">ps</a>, <a href="/format/2311.02078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretability is not Explainability: New Quantitative XAI Approach  with a focus on Recommender Systems in Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Porcedda%2C+R">Riccardo Porcedda</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> David C. Wyld et al. (Eds): MLNLP, NWCOM, DTMN, ASOFT, SIGPRO,
  AIFZ, CSITY, CLSB - 2023, pp. 171-188, 2023. CS &amp; IT - CSCP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The field of eXplainable Artificial Intelligence faces challenges due to the
absence of a widely accepted taxonomy that facilitates the quantitative
evaluation of explainability in Machine Learning algorithms. In this paper, we
propose a novel taxonomy that addresses the current gap in the literature by
providing a clear and unambiguous understanding of the key concepts and
relationships in XAI. Our approach is rooted in a systematic analysis of
existing definitions and frameworks, with a focus on transparency,
interpretability, completeness, complexity and understandability as essential
dimensions of explainability. This comprehensive taxonomy aims to establish a
shared vocabulary for future research. To demonstrate the utility of our
proposed taxonomy, we examine a case study of a Recommender System designed to
curate and recommend the most suitable online resources from MERLOT. By
employing the SHAP package, we quantify and enhance the explainability of the
RS within the context of our newly developed taxonomy.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02082" title="Abstract">arXiv:2311.02082</a> [<a href="/pdf/2311.02082" title="Download PDF">pdf</a>, <a href="/ps/2311.02082" title="Download PostScript">ps</a>, <a href="/format/2311.02082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Modelling of Organizational Knowledge as a Basis for Enterprise  Data Governance 4.0 -- Application to a Unified Clinical Data Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+M+A">Miguel AP Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Manara%2C+S">Stephane Manara</a>, 
<a href="/search/cs?searchtype=author&query=Mol%C3%A9%2C+B">Bruno Mol&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Muller%2C+T">Thomas Muller</a>, 
<a href="/search/cs?searchtype=author&query=Guillouche%2C+A">Aur&#xe9;lien Guillouche</a>, 
<a href="/search/cs?searchtype=author&query=Hesske%2C+L">Lysann Hesske</a>, 
<a href="/search/cs?searchtype=author&query=Jordan%2C+B">Bruce Jordan</a>, 
<a href="/search/cs?searchtype=author&query=Hubert%2C+G">Gilles Hubert</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+C">Chinmay Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Jagdev%2C+P">Pralipta Jagdev</a>, 
<a href="/search/cs?searchtype=author&query=Berger%2C+C+R">Cedric R. Berger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Individuals and organizations cope with an always-growing data amount,
heterogeneous in contents and formats. Prerequisites to get value out this data
and minimise inherent risks related to multiple usages are adequate data
management processes yielding data quality and control over its lifecycle.
Common data governance frameworks relying on people and policies falls short of
the overwhelming data complexity. Yet, harnessing this complexity is necessary
to achieve high quality standards. The later will condition the outcome of any
downstream data usage, including generative artificial intelligence trained on
this data. In this paper, we report our concrete experience establishing a
simple, cost-efficient framework, that enables metadata-driven, agile and
(semi-)automated data governance (i.e. Data Governance 4.0). We explain how we
implement and use this framework to integrate 25 years of clinical study data
at enterprise scale, in a fully productive environment. The framework
encompasses both methodologies and technologies leveraging semantic web
principles. We built an knowledge graph describing data assets avatars in their
business context including governance principles. Multiple ontologies
articulated by an enterprise upper ontology enable key governance actions such
as FAIRification, lifecycle management, definition of roles and
responsibilities, lineage across transformations and provenance from source
systems. This metadata model is a prerequisite to automatize data governance,
make it fit-for-purpose to each use case and dynamically adapting it to
business changes.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02083" title="Abstract">arXiv:2311.02083</a> [<a href="/pdf/2311.02083" title="Download PDF">pdf</a>, <a href="/format/2311.02083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MaRU: A Manga Retrieval and Understanding System Connecting Vision and  Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+C+T">Conghao Tom Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+V">Violet Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yixin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Manga, a widely celebrated Japanese comic art form, is renowned for its
diverse narratives and distinct artistic styles. However, the inherently visual
and intricate structure of Manga, which comprises images housing multiple
panels, poses significant challenges for content retrieval. To address this, we
present MaRU (Manga Retrieval and Understanding), a multi-staged system that
connects vision and language to facilitate efficient search of both dialogues
and scenes within Manga frames. The architecture of MaRU integrates an object
detection model for identifying text and frame bounding boxes, a Vision
Encoder-Decoder model for text recognition, a text encoder for embedding text,
and a vision-text encoder that merges textual and visual information into a
unified embedding space for scene retrieval. Rigorous evaluations reveal that
MaRU excels in end-to-end dialogue retrieval and exhibits promising results for
scene retrieval.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02084" title="Abstract">arXiv:2311.02084</a> [<a href="/pdf/2311.02084" title="Download PDF">pdf</a>, <a href="/format/2311.02084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ITEm: Unsupervised Image-Text Embedding Learning for eCommerce
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+B">Baohao Liao</a>, 
<a href="/search/cs?searchtype=author&query=Kozielski%2C+M">Michael Kozielski</a>, 
<a href="/search/cs?searchtype=author&query=Hewavitharana%2C+S">Sanjika Hewavitharana</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jiangbo Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Khadivi%2C+S">Shahram Khadivi</a>, 
<a href="/search/cs?searchtype=author&query=Lancewicki%2C+T">Tomer Lancewicki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Product embedding serves as a cornerstone for a wide range of applications in
eCommerce. The product embedding learned from multiple modalities shows
significant improvement over that from a single modality, since different
modalities provide complementary information. However, some modalities are more
informatively dominant than others. How to teach a model to learn embedding
from different modalities without neglecting information from the less dominant
modality is challenging. We present an image-text embedding model (ITEm), an
unsupervised learning method that is designed to better attend to image and
text modalities. We extend BERT by (1) learning an embedding from text and
image without knowing the regions of interest; (2) training a global
representation to predict masked words and to construct masked image patches
without their individual representations. We evaluate the pre-trained ITEm on
two tasks: the search for extremely similar products and the prediction of
product categories, showing substantial gains compared to strong baseline
models.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02085" title="Abstract">arXiv:2311.02085</a> [<a href="/pdf/2311.02085" title="Download PDF">pdf</a>, <a href="/format/2311.02085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preference Elicitation with Soft Attributes in Interactive  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biyik%2C+E">Erdem Biyik</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+F">Fan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Chow%2C+Y">Yinlam Chow</a>, 
<a href="/search/cs?searchtype=author&query=Haig%2C+A">Alex Haig</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+C">Chih-wei Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Ghavamzadeh%2C+M">Mohammad Ghavamzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Boutilier%2C+C">Craig Boutilier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Preference elicitation plays a central role in interactive recommender
systems. Most preference elicitation approaches use either item queries that
ask users to select preferred items from a slate, or attribute queries that ask
them to express their preferences for item characteristics. Unfortunately,
users often wish to describe their preferences using soft attributes for which
no ground-truth semantics is given. Leveraging concept activation vectors for
soft attribute semantics, we develop novel preference elicitation methods that
can accommodate soft attributes and bring together both item and
attribute-based preference elicitation. Our techniques query users using both
items and soft attributes to update the recommender system's belief about their
preferences to improve recommendation quality. We demonstrate the effectiveness
of our methods vis-a-vis competing approaches on both synthetic and real-world
datasets.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02086" title="Abstract">arXiv:2311.02086</a> [<a href="/pdf/2311.02086" title="Download PDF">pdf</a>, <a href="/format/2311.02086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synergizing Data Imputation and Electronic Health Records for Advancing  Prostate Cancer Research: Challenges, and Practical Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Batouche%2C+A+O">Abderrahim Oussama Batouche</a>, 
<a href="/search/cs?searchtype=author&query=Czeizler%2C+E">Eugen Czeizler</a>, 
<a href="/search/cs?searchtype=author&query=Koskinen%2C+M">Miika Koskinen</a>, 
<a href="/search/cs?searchtype=author&query=Mirtti%2C+T">Tuomas Mirtti</a>, 
<a href="/search/cs?searchtype=author&query=Rannikko%2C+A+S">Antti Sakari Rannikko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Databases (cs.DB)

</div>
<p class="mathjax">The presence of detailed clinical information in electronic health record
(EHR) systems presents promising prospects for enhancing patient care through
automated retrieval techniques. Nevertheless, it is widely acknowledged that
accessing data within EHRs is hindered by various methodological challenges.
Specifically, the clinical notes stored in EHRs are composed in a narrative
form, making them prone to ambiguous formulations and highly unstructured data
presentations, while structured reports commonly suffer from missing and/or
erroneous data entries. This inherent complexity poses significant challenges
when attempting automated large-scale medical knowledge extraction tasks,
necessitating the application of advanced tools, such as natural language
processing (NLP), as well as data audit techniques. This work aims to address
these obstacles by creating and validating a novel pipeline designed to extract
relevant data pertaining to prostate cancer patients. The objective is to
exploit the inherent redundancies available within the integrated structured
and unstructured data entries within EHRs in order to generate comprehensive
and reliable medical databases, ready to be used in advanced research studies.
Additionally, the study explores potential opportunities arising from these
data, offering valuable prospects for advancing research in prostate cancer.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02087" title="Abstract">arXiv:2311.02087</a> [<a href="/pdf/2311.02087" title="Download PDF">pdf</a>, <a href="/ps/2311.02087" title="Download PostScript">ps</a>, <a href="/format/2311.02087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design Of Rubble Analyzer Probe Using ML For Earthquake
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sebastian%2C+A">Abhishek Sebastian</a>, 
<a href="/search/cs?searchtype=author&query=Pragna%2C+R">R Pragna</a>, 
<a href="/search/cs?searchtype=author&query=Vythianathan%2C+K+V">K Vishal Vythianathan</a>, 
<a href="/search/cs?searchtype=author&query=Sai%2C+D+S">Dasaraju Sohan Sai</a>, 
<a href="/search/cs?searchtype=author&query=Al%2C+U+S+S+H">U Shiva Sri Hari Al</a>, 
<a href="/search/cs?searchtype=author&query=Anirudh%2C+R">R Anirudh</a>, 
<a href="/search/cs?searchtype=author&query=Choudhary%2C+A">Apurv Choudhary</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)

</div>
<p class="mathjax">The earthquake rubble analyzer uses machine learning to detect human presence
via ambient sounds, achieving 97.45% accuracy. It also provides real-time
environmental data, aiding in assessing survival prospects for trapped
individuals, crucial for post-earthquake rescue efforts
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02089" title="Abstract">arXiv:2311.02089</a> [<a href="/pdf/2311.02089" title="Download PDF">pdf</a>, <a href="/format/2311.02089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LlamaRec: Two-Stage Recommendation using Large Language Models for  Ranking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+Z">Zhenrui Yue</a>, 
<a href="/search/cs?searchtype=author&query=Rabhi%2C+S">Sara Rabhi</a>, 
<a href="/search/cs?searchtype=author&query=de+Souza+Pereira+Moreira%2C+G">Gabriel de Souza Pereira Moreira</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Oldridge%2C+E">Even Oldridge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to PGAI@CIKM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Recently, large language models (LLMs) have exhibited significant progress in
language understanding and generation. By leveraging textual features,
customized LLMs are also applied for recommendation and demonstrate
improvements across diverse recommendation scenarios. Yet the majority of
existing methods perform training-free recommendation that heavily relies on
pretrained knowledge (e.g., movie recommendation). In addition, inference on
LLMs is slow due to autoregressive generation, rendering existing methods less
effective for real-time recommendation. As such, we propose a two-stage
framework using large language models for ranking-based recommendation
(LlamaRec). In particular, we use small-scale sequential recommenders to
retrieve candidates based on the user interaction history. Then, both history
and retrieved items are fed to the LLM in text via a carefully designed prompt
template. Instead of generating next-item titles, we adopt a verbalizer-based
approach that transforms output logits into probability distributions over the
candidate items. Therefore, the proposed LlamaRec can efficiently rank items
without generating long text. To validate the effectiveness of the proposed
framework, we compare against state-of-the-art baseline methods on benchmark
datasets. Our experimental results demonstrate the performance of LlamaRec,
which consistently achieves superior performance in both recommendation
performance and efficiency.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02093" title="Abstract">arXiv:2311.02093</a> [<a href="/pdf/2311.02093" title="Download PDF">pdf</a>, <a href="/ps/2311.02093" title="Download PostScript">ps</a>, <a href="/format/2311.02093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Exploration on Integrated Sensing and Communication for the Future  Smart Internet of Things
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+Z">Zhaoxin Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fusang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Daqing Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Internet of Things (IoT) technologies are the foundation of a fully connected
world. Currently, IoT devices (or nodes) primarily use dedicated sensors to
sense and collect data at large scales, and then transmit the data to target
nodes or gateways through wireless communication for further processing and
analytics. In recent years, research efforts have been made to explore the
feasibility of using wireless communication for sensing (while assiduously
improving the transmission performance of wireless signals), in an attempt to
achieve integrated sensing and communication (ISAC) for smart IoT of the
future. In this paper, we leverage the capabilities of LoRa, a long-range IoT
communication technology, to explore the possibility of using LoRa signals for
both sensing and communication. Based on LoRa, we propose ISAC designs in two
typical scenarios of smart IoT, and verify the feasibility and effectiveness of
our designs in soil moisture monitoring and human presence detection.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02095" title="Abstract">arXiv:2311.02095</a> [<a href="/pdf/2311.02095" title="Download PDF">pdf</a>, <a href="/ps/2311.02095" title="Download PostScript">ps</a>, <a href="/format/2311.02095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transient Thermal and Electrical Characteristics of a Cylindrical LiFeS2  Cell with Equivalent Circuit Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Alsharif%2C+K+I">Khaled I Alsharif</a>, 
<a href="/search/eess?searchtype=author&query=Pesch%2C+A+H">Alexander H Pesch</a>, 
<a href="/search/eess?searchtype=author&query=Borra%2C+V">Vamsi Borra</a>, 
<a href="/search/eess?searchtype=author&query=Cortes%2C+P">Pedro Cortes</a>, 
<a href="/search/eess?searchtype=author&query=MacDonald%2C+E">Eric MacDonald</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+F+X">Frank X Li</a>, 
<a href="/search/eess?searchtype=author&query=Choo%2C+K">Kyosung Choo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> conference
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 9 th International Conference on Fluid Flow,
  Heat and Mass Transfer (FFHMT, 2022), 14, pp.50-5
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Materials Science (cond-mat.mtrl-sci)

</div>
<p class="mathjax">This study examines the discharge behaviour of a cylindrical LiFeS2 cell to
evaluate the parameters that can be used to predict and estimate the nonlinear
dynamic response of a battery. A linear model is developed to simulate the
discharge behaviour and examine the thermal behaviour. In particular, a
commercial-grade battery is discharged with the industry-standard hybrid power
pulsing characterization (HPPC) test and the current and voltage responses are
recorded. The dynamic system is modelled with the equivalent circuit model
(ECM) through MATLAB Simulink. A block diagram representation of the equivalent
circuit model governing equations was developed. The parameter estimation tool
was utilized to reduce the error and fit the simulation results to the
experimental voltage responses, in order to obtain state of charge dependent
dynamic parameters. Those parameters were then used in a Dual-Potential
Multi-Scale Multi-Domain (MSMD) Battery Model solved in ANSYS Fluent to analyze
the thermal behaviour by acquiring the temperature profiles and the temperature
distribution within the cell. The nonlinear behaviour of the battery was
characterized and the equivalent circuit model parameters were identified and
are shown to agree with the experimental voltage responses. Furthermore, it is
found that the battery temperature increased by 7.35 deg and was distributed
uniformly within the cell.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02099" title="Abstract">arXiv:2311.02099</a> [<a href="/pdf/2311.02099" title="Download PDF">pdf</a>, <a href="/format/2311.02099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Preference Learning Approach to Develop Safe and Personalizable  Autonomous Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karagulle%2C+R">Ruya Karagulle</a>, 
<a href="/search/cs?searchtype=author&query=Arechiga%2C+N">Nikos Arechiga</a>, 
<a href="/search/cs?searchtype=author&query=Best%2C+A">Andrew Best</a>, 
<a href="/search/cs?searchtype=author&query=DeCastro%2C+J">Jonathan DeCastro</a>, 
<a href="/search/cs?searchtype=author&query=Ozay%2C+N">Necmiye Ozay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures, 2 tables. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This work introduces a preference learning method that ensures adherence to
traffic rules for autonomous vehicles. Our approach incorporates priority
ordering of signal temporal logic (STL) formulas, describing traffic rules,
into a learning framework. By leveraging the parametric weighted signal
temporal logic (PWSTL), we formulate the problem of safety-guaranteed
preference learning based on pairwise comparisons, and propose an approach to
solve this learning problem. Our approach finds a feasible valuation for the
weights of the given PWSTL formula such that, with these weights, preferred
signals have weighted quantitative satisfaction measures greater than their
non-preferred counterparts. The feasible valuation of weights given by our
approach leads to a weighted STL formula which can be used in
correct-and-custom-by-construction controller synthesis. We demonstrate the
performance of our method with human subject studies in two different simulated
driving scenarios involving a stop sign and a pedestrian crossing. Our approach
yields competitive results compared to existing preference learning methods in
terms of capturing preferences, and notably outperforms them when safety is
considered.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02100" title="Abstract">arXiv:2311.02100</a> [<a href="/pdf/2311.02100" title="Download PDF">pdf</a>, <a href="/format/2311.02100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Study on Model Initialization Techniques Ensuring  Efficient Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaur%2C+I">Ishmeet Kaur</a>, 
<a href="/search/cs?searchtype=author&query=Jadhav%2C+A+J">Adwaita Janardhan Jadhav</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to be presented at IEEE 2nd International Conference on Intelligent Computing and Next Generation Networks (ICNGN2023) will be held November 17-18,2023 at Hangzhou, China
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Advancement in the field of machine learning is unavoidable, but something of
major concern is preserving the privacy of the users whose data is being used
for training these machine learning algorithms. Federated learning(FL) has
emerged as a promising paradigm for training machine learning models in a
distributed and privacy-preserving manner which enables one to collaborate and
train a global model without sharing local data. But starting this learning
process on each device in the right way, called ``model initialization" is
critical. The choice of initialization methods used for models plays a crucial
role in the performance, convergence speed, communication efficiency, privacy
guarantees of federated learning systems, etc. In this survey, we dive deeper
into a comprehensive study of various ways of model initialization techniques
in FL.Unlike other studies, our research meticulously compares, categorizes,
and delineates the merits and demerits of each technique, examining their
applicability across diverse FL scenarios. We highlight how factors like client
variability, data non-IIDness, model caliber, security considerations, and
network restrictions influence FL model outcomes and propose how strategic
initialization can address and potentially rectify many such challenges. The
motivation behind this survey is to highlight that the right start can help
overcome challenges like varying data quality, security issues, and network
problems. Our insights provide a foundational base for experts looking to fully
utilize FL, also while understanding the complexities of model initialization.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02101" title="Abstract">arXiv:2311.02101</a> [<a href="/pdf/2311.02101" title="Download PDF">pdf</a>, <a href="/format/2311.02101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving MaxSAT with Matrix Multiplication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Warde-Farley%2C+D">David Warde-Farley</a>, 
<a href="/search/cs?searchtype=author&query=Nair%2C+V">Vinod Nair</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yujia Li</a>, 
<a href="/search/cs?searchtype=author&query=Lobov%2C+I">Ivan Lobov</a>, 
<a href="/search/cs?searchtype=author&query=Gimeno%2C+F">Felix Gimeno</a>, 
<a href="/search/cs?searchtype=author&query=Osindero%2C+S">Simon Osindero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">We propose an incomplete algorithm for Maximum Satisfiability (MaxSAT)
specifically designed to run on neural network accelerators such as GPUs and
TPUs. Given a MaxSAT problem instance in conjunctive normal form, our procedure
constructs a Restricted Boltzmann Machine (RBM) with an equilibrium
distribution wherein the probability of a Boolean assignment is exponential in
the number of clauses it satisfies. Block Gibbs sampling is used to
stochastically search the space of assignments with parallel Markov chains.
Since matrix multiplication is the main computational primitive for block Gibbs
sampling in an RBM, our approach leads to an elegantly simple algorithm (40
lines of JAX) well-suited for neural network accelerators. Theoretical results
about RBMs guarantee that the required number of visible and hidden units of
the RBM scale only linearly with the number of variables and constant-sized
clauses in the MaxSAT instance, ensuring that the computational cost of a Gibbs
step scales reasonably with the instance size. Search throughput can be
increased by batching parallel chains within a single accelerator as well as by
distributing them across multiple accelerators. As a further enhancement, a
heuristic based on unit propagation running on CPU is periodically applied to
the sampled assignments. Our approach, which we term RbmSAT, is a new design
point in the algorithm-hardware co-design space for MaxSAT. We present timed
results on a subset of problem instances from the annual MaxSAT Evaluation's
Incomplete Unweighted Track for the years 2018 to 2021. When allotted the same
running time and CPU compute budget (but no TPUs), RbmSAT outperforms other
participating solvers on problems drawn from three out of the four years'
competitions. Given the same running time on a TPU cluster for which RbmSAT is
uniquely designed, it outperforms all solvers on problems drawn from all four
years.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02102" title="Abstract">arXiv:2311.02102</a> [<a href="/pdf/2311.02102" title="Download PDF">pdf</a>, <a href="/ps/2311.02102" title="Download PostScript">ps</a>, <a href="/format/2311.02102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Notion of Explainable Artificial Intelligence -- An Empirical  Investigation from A Users Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haque%2C+A+B">AKM Bahalul Haque</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+A+K+M+N">A.K.M. Najmul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Mikalef%2C+P">Patrick Mikalef</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 Pages, 3 Figures, 1 Table , Accepted version for publication in European Conference on Information Systems (ECIS), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The growing attention to artificial intelligence-based applications has led
to research interest in explainability issues. This emerging research attention
on explainable AI (XAI) advocates the need to investigate end user-centric
explainable AI. Thus, this study aims to investigate usercentric explainable AI
and considered recommendation systems as the study context. We conducted focus
group interviews to collect qualitative data on the recommendation system. We
asked participants about the end users' comprehension of a recommended item,
its probable explanation, and their opinion of making a recommendation
explainable. Our findings reveal that end users want a non-technical and
tailor-made explanation with on-demand supplementary information. Moreover, we
also observed users requiring an explanation about personal data usage,
detailed user feedback, and authentic and reliable explanations. Finally, we
propose a synthesized framework that aims at involving the end user in the
development process for requirements collection and validation.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02103" title="Abstract">arXiv:2311.02103</a> [<a href="/pdf/2311.02103" title="Download PDF">pdf</a>, <a href="/format/2311.02103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relax: Composable Abstractions for End-to-End Dynamic Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+R">Ruihang Lai</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Junru Shao</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+S">Siyuan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Lyubomirsky%2C+S+S">Steven S. Lyubomirsky</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+B">Bohan Hou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Wuwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zihao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hongyi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yuchen Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiawei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Lesheng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yaxing Cai</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Ziheng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sunghyun Park</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+P">Prakalp Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Roesch%2C+J+G">Jared G. Roesch</a>, 
<a href="/search/cs?searchtype=author&query=Mowry%2C+T+C">Todd C. Mowry</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianqi Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Programming Languages (cs.PL)

</div>
<p class="mathjax">Dynamic shape computations have become critical in modern machine learning
workloads, especially in emerging large language models. The success of these
models has driven demand for deploying them to a diverse set of backend
environments. In this paper, we present Relax, a compiler abstraction for
optimizing end-to-end dynamic machine learning workloads. Relax introduces
first-class symbolic shape annotations to track dynamic shape computations
globally across the program. It also introduces a cross-level abstraction that
encapsulates computational graphs, loop-level tensor programs, and library
calls in a single representation to enable cross-level optimizations. We build
an end-to-end compilation framework using the proposed approach to optimize
dynamic shape models. Experimental results on large language models show that
Relax delivers performance competitive with state-of-the-art hand-optimized
systems across platforms and enables deployment of emerging dynamic models to a
broader set of environments, including mobile phones, embedded devices, and web
browsers.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02104" title="Abstract">arXiv:2311.02104</a> [<a href="/pdf/2311.02104" title="Download PDF">pdf</a>, <a href="/format/2311.02104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Symbolic Policy Learning with Differentiable Symbolic  Expression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiaming Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Shaohui Peng</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+Q">Qi Yi</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruizhi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zidong Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xishan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Ling Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yunji Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep reinforcement learning (DRL) has led to a wide range of advances in
sequential decision-making tasks. However, the complexity of neural network
policies makes it difficult to understand and deploy with limited computational
resources. Currently, employing compact symbolic expressions as symbolic
policies is a promising strategy to obtain simple and interpretable policies.
Previous symbolic policy methods usually involve complex training processes and
pre-trained neural network policies, which are inefficient and limit the
application of symbolic policies. In this paper, we propose an efficient
gradient-based learning method named Efficient Symbolic Policy Learning (ESPL)
that learns the symbolic policy from scratch in an end-to-end way. We introduce
a symbolic network as the search space and employ a path selector to find the
compact symbolic policy. By doing so we represent the policy with a
differentiable symbolic expression and train it in an off-policy manner which
further improves the efficiency. In addition, in contrast with previous
symbolic policies which only work in single-task RL because of complexity, we
expand ESPL on meta-RL to generate symbolic policies for unseen tasks.
Experimentally, we show that our approach generates symbolic policies with
higher performance and greatly improves data efficiency for single-task RL. In
meta-RL, we demonstrate that compared with neural network policies the proposed
symbolic policy achieves higher performance and efficiency and shows the
potential to be interpretable.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02105" title="Abstract">arXiv:2311.02105</a> [<a href="/pdf/2311.02105" title="Download PDF">pdf</a>, <a href="/format/2311.02105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making Harmful Behaviors Unlearnable for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yi Lu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+R">Ruotian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+T">Tao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in process
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Large language models (LLMs) have shown great potential as general-purpose AI
assistants in various domains. To meet the requirements of different
applications, LLMs are often customized by further fine-tuning. However, the
powerful learning ability of LLMs not only enables them to acquire new tasks
but also makes them susceptible to learning undesired behaviors. For example,
even safety-aligned LLMs can be easily fine-tuned into harmful assistants as
the fine-tuning data often contains implicit or explicit harmful content. Can
we train LLMs on harmful data without learning harmful behaviors? This paper
proposes a controllable training framework that makes harmful behaviors
unlearnable during the fine-tuning process. Specifically, we introduce
``security vectors'', a few new parameters that can be separated from the LLM,
to ensure LLM's responses are consistent with the harmful behavior. Security
vectors are activated during fine-tuning, the consistent behavior makes LLM
believe that such behavior has already been learned, there is no need to
further optimize for harmful data. During inference, we can deactivate security
vectors to restore the LLM's normal behavior. The experimental results show
that the security vectors generated by 100 harmful samples are enough to
prevent LLM from learning 1000 harmful samples, while preserving the ability to
learn other useful information.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02106" title="Abstract">arXiv:2311.02106</a> [<a href="/pdf/2311.02106" title="Download PDF">pdf</a>, <a href="/format/2311.02106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Machine Learning Ensemble Methods for Detecting Gravitational  Wave Glitches in LIGO Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Apostol%2C+E">Elena-Simona Apostol</a>, 
<a href="/search/cs?searchtype=author&query=Truic%C4%83%2C+C">Ciprian-Octavian Truic&#x103;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Artificial Intelligence (cs.AI); General Relativity and Quantum Cosmology (gr-qc)

</div>
<p class="mathjax">The phenomenon of Gravitational Wave (GW) analysis has grown in popularity as
technology has advanced and the process of observing gravitational waves has
become more precise. Although the sensitivity and the frequency of observation
of GW signals are constantly improving, the possibility of noise in the
collected GW data remains. In this paper, we propose two new Machine and Deep
learning ensemble approaches (i.e., ShallowWaves and DeepWaves Ensembles) for
detecting different types of noise and patterns in datasets from GW
observatories. Our research also investigates various Machine and Deep Learning
techniques for multi-class classification and provides a comprehensive
benchmark, emphasizing the best results in terms of three commonly used
performance metrics (i.e., accuracy, precision, and recall). We train and test
our models on a dataset consisting of annotated time series from real-world
data collected by the Advanced Laser Interferometer GW Observatory (LIGO). We
empirically show that the best overall accuracy is obtained by the proposed
DeepWaves Ensemble, followed close by the ShallowWaves Ensemble.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02107" title="Abstract">arXiv:2311.02107</a> [<a href="/pdf/2311.02107" title="Download PDF">pdf</a>, <a href="/ps/2311.02107" title="Download PostScript">ps</a>, <a href="/format/2311.02107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Artificial Intelligence in Healthcare: Ethical Considerations  and Assessment Checklist
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ning%2C+Y">Yilin Ning</a>, 
<a href="/search/cs?searchtype=author&query=Teixayavong%2C+S">Salinelat Teixayavong</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+Y">Yuqing Shang</a>, 
<a href="/search/cs?searchtype=author&query=Savulescu%2C+J">Julian Savulescu</a>, 
<a href="/search/cs?searchtype=author&query=Nagaraj%2C+V">Vaishaanth Nagaraj</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+D">Di Miao</a>, 
<a href="/search/cs?searchtype=author&query=Mertens%2C+M">Mayli Mertens</a>, 
<a href="/search/cs?searchtype=author&query=Ting%2C+D+S+W">Daniel Shu Wei Ting</a>, 
<a href="/search/cs?searchtype=author&query=Ong%2C+J+C+L">Jasmine Chiat Ling Ong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingxuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiuwen Cao</a>, 
<a href="/search/cs?searchtype=author&query=Dunn%2C+M">Michael Dunn</a>, 
<a href="/search/cs?searchtype=author&query=Vaughan%2C+R">Roger Vaughan</a>, 
<a href="/search/cs?searchtype=author&query=Ong%2C+M+E+H">Marcus Eng Hock Ong</a>, 
<a href="/search/cs?searchtype=author&query=Sung%2C+J+J">Joseph Jao-Yiu Sung</a>, 
<a href="/search/cs?searchtype=author&query=Topol%2C+E+J">Eric J Topol</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Nan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">The widespread use of ChatGPT and other emerging technology powered by
generative artificial intelligence (AI) has drawn much attention to potential
ethical issues, especially in high-stakes applications such as healthcare.
However, less clear is how to resolve such issues beyond following guidelines
and regulations that are still under discussion and development. On the other
hand, other types of generative AI have been used to synthesize images and
other types of data for research and practical purposes, which have resolved
some ethical issues and exposed other ethical issues, but such technology is
less often the focus of ongoing ethical discussions. Here we highlight gaps in
current ethical discussions of generative AI via a systematic scoping review of
relevant existing research in healthcare, and reduce the gaps by proposing an
ethics checklist for comprehensive assessment and transparent documentation of
ethical discussions in generative AI development. While the checklist can be
readily integrated into the current peer review and publication system to
enhance generative AI research, it may also be used in broader settings to
disclose ethics-related considerations in generative AI-powered products (or
real-life applications of such products) to help users establish reasonable
trust in their capabilities.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02108" title="Abstract">arXiv:2311.02108</a> [<a href="/pdf/2311.02108" title="Download PDF">pdf</a>, <a href="/format/2311.02108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Virtual Reality Training System for Automotive Engines Assembly and  Disassembly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lan%2C+G">Gongjin Lan</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Q">Qiangqiang Lai</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+B">Bing Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zirui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Q">Qi Hao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Automotive engine assembly and disassembly are common and crucial programs in
the automotive industry. Traditional education trains students to learn
automotive engine assembly and disassembly in lecture courses and then to
operate with physical engines, which are generally low effectiveness and high
cost. In this work, we developed a multi-layer structured Virtual Reality (VR)
system to provide students with training in automotive engine (Buick Verano)
assembly and disassembly. We designed the VR training system with The VR
training system is designed to have several major features, including
replaceable engine parts and reusable tools, friendly user interfaces and
guidance, and bottom-up designed multi-layer architecture, which can be
extended to various engine models. The VR system is evaluated with controlled
experiments of two groups of students. The results demonstrate that our VR
training system provides remarkable usability in terms of effectiveness and
efficiency. Currently, our VR system has been demonstrated and employed in the
courses of Chinese colleges to train students in automotive engine assembly and
disassembly. A free-to-use executable file (Microsoft Windows) and open-source
code are available at https://github.com/LadissonLai/SUSTech_VREngine for
facilitating the development of VR systems in the automotive industry. Finally,
a video describing the operations in our VR training system is available at
https://www.youtube.com/watch?v=yZe4YTwwAC4
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02110" title="Abstract">arXiv:2311.02110</a> [<a href="/pdf/2311.02110" title="Download PDF">pdf</a>, <a href="/format/2311.02110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Attribution Explanations for Spiking Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+E">Elisa Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nauta%2C+M">Meike Nauta</a>, 
<a href="/search/cs?searchtype=author&query=Englebienne%2C+G">Gwenn Englebienne</a>, 
<a href="/search/cs?searchtype=author&query=Seifert%2C+C">Christin Seifert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE CogMI 2023, copyright final version IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Third-generation artificial neural networks, Spiking Neural Networks (SNNs),
can be efficiently implemented on hardware. Their implementation on
neuromorphic chips opens a broad range of applications, such as machine
learning-based autonomous control and intelligent biomedical devices. In
critical applications, however, insight into the reasoning of SNNs is
important, thus SNNs need to be equipped with the ability to explain how
decisions are reached. We present \textit{Temporal Spike Attribution} (TSA), a
local explanation method for SNNs. To compute the explanation, we aggregate all
information available in model-internal variables: spike times and model
weights. We evaluate TSA on artificial and real-world time series data and
measure explanation quality w.r.t. multiple quantitative criteria. We find that
TSA correctly identifies a small subset of input features relevant to the
decision (i.e., is output-complete and compact) and generates similar
explanations for similar inputs (i.e., is continuous). Further, our experiments
show that incorporating the notion of \emph{absent} spikes improves explanation
quality. Our work can serve as a starting point for explainable SNNs, with
future implementations on hardware yielding not only predictions but also
explanations in a broad range of application scenarios. Source code is
available at https://github.com/ElisaNguyen/tsa-explanations.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02115" title="Abstract">arXiv:2311.02115</a> [<a href="/pdf/2311.02115" title="Download PDF">pdf</a>, <a href="/format/2311.02115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards objective and systematic evaluation of bias in medical imaging  AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stanley%2C+E+A+M">Emma A.M. Stanley</a>, 
<a href="/search/cs?searchtype=author&query=Souza%2C+R">Raissa Souza</a>, 
<a href="/search/cs?searchtype=author&query=Winder%2C+A">Anthony Winder</a>, 
<a href="/search/cs?searchtype=author&query=Gulve%2C+V">Vedant Gulve</a>, 
<a href="/search/cs?searchtype=author&query=Amador%2C+K">Kimberly Amador</a>, 
<a href="/search/cs?searchtype=author&query=Wilms%2C+M">Matthias Wilms</a>, 
<a href="/search/cs?searchtype=author&query=Forkert%2C+N+D">Nils D. Forkert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Artificial intelligence (AI) models trained using medical images for clinical
tasks often exhibit bias in the form of disparities in performance between
subgroups. Since not all sources of biases in real-world medical imaging data
are easily identifiable, it is challenging to comprehensively assess how those
biases are encoded in models, and how capable bias mitigation methods are at
ameliorating performance disparities. In this article, we introduce a novel
analysis framework for systematically and objectively investigating the impact
of biases in medical images on AI models. We developed and tested this
framework for conducting controlled in silico trials to assess bias in medical
imaging AI using a tool for generating synthetic magnetic resonance images with
known disease effects and sources of bias. The feasibility is showcased by
using three counterfactual bias scenarios to measure the impact of simulated
bias effects on a convolutional neural network (CNN) classifier and the
efficacy of three bias mitigation strategies. The analysis revealed that the
simulated biases resulted in expected subgroup performance disparities when the
CNN was trained on the synthetic datasets. Moreover, reweighing was identified
as the most successful bias mitigation strategy for this setup, and we
demonstrated how explainable AI methods can aid in investigating the
manifestation of bias in the model using this framework. Developing fair AI
models is a considerable challenge given that many and often unknown sources of
biases can be present in medical imaging datasets. In this work, we present a
novel methodology to objectively study the impact of biases and mitigation
strategies on deep learning pipelines, which can support the development of
clinical AI that is robust and responsible.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02116" title="Abstract">arXiv:2311.02116</a> [<a href="/pdf/2311.02116" title="Download PDF">pdf</a>, <a href="/format/2311.02116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resist Label Noise with PGM for Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+Q">Qingqing Ge</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jianxiang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zeyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">While robust graph neural networks (GNNs) have been widely studied for graph
perturbation and attack, those for label noise have received significantly less
attention. Most existing methods heavily rely on the label smoothness
assumption to correct noisy labels, which adversely affects their performance
on heterophilous graphs. Further, they generally perform poorly in high
noise-rate scenarios. To address these problems, in this paper, we propose a
novel probabilistic graphical model (PGM) based framework LNP. Given a noisy
label set and a clean label set, our goal is to maximize the likelihood of
labels in the clean set. We first present LNP-v1, which generates clean labels
based on graphs only in the Bayesian network. To further leverage the
information of clean labels in the noisy label set, we put forward LNP-v2,
which incorporates the noisy label set into the Bayesian network to generate
clean labels. The generative process can then be used to predict labels for
unlabeled nodes. We conduct extensive experiments to show the robustness of LNP
on varying noise types and rates, and also on graphs with different
heterophilies. In particular, we show that LNP can lead to inspiring
performance in high noise-rate situations.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02117" title="Abstract">arXiv:2311.02117</a> [<a href="/pdf/2311.02117" title="Download PDF">pdf</a>, <a href="/format/2311.02117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cooperative Network Learning for Large-Scale and Decentralized Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yiming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yujie Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+Y">Yujie Teng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Fang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%BC%2C+L">Linyuan L&#xfc;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graph research, the systematic study of interconnected data points
represented as graphs, plays a vital role in capturing intricate relationships
within networked systems. However, in the real world, as graphs scale up,
concerns about data security among different data-owning agencies arise,
hindering information sharing and, ultimately, the utilization of graph data.
Therefore, establishing a mutual trust mechanism among graph agencies is
crucial for unlocking the full potential of graphs. Here, we introduce a
Cooperative Network Learning (CNL) framework to ensure secure graph computing
for various graph tasks. Essentially, this CNL framework unifies the local and
global perspectives of GNN computing with distributed data for an agency by
virtually connecting all participating agencies as a global graph without a
fixed central coordinator. Inter-agency computing is protected by various
technologies inherent in our framework, including homomorphic encryption and
secure transmission. Moreover, each agency has a fair right to design or employ
various graph learning models from its local or global perspective. Thus, CNL
can collaboratively train GNN models based on decentralized graphs inferred
from local and global graphs. Experiments on contagion dynamics prediction and
traditional graph tasks (i.e., node classification and link prediction)
demonstrate that our CNL architecture outperforms state-of-the-art GNNs
developed at individual sites, revealing that CNL can provide a reliable, fair,
secure, privacy-preserving, and global perspective to build effective and
personalized models for network applications. We hope this framework will
address privacy concerns in graph-related research and integrate decentralized
graph data structures to benefit the network research community in cooperation
and innovation.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02120" title="Abstract">arXiv:2311.02120</a> [<a href="/pdf/2311.02120" title="Download PDF">pdf</a>, <a href="/ps/2311.02120" title="Download PostScript">ps</a>, <a href="/format/2311.02120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Static Virus Spread Algorithm for DNA Sequence Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaokang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures, submitting to IEEE TNB
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Biomolecules (q-bio.BM)

</div>
<p class="mathjax">DNA is not only the genetic material of life, but also a favorable material
for a new computing model. Various research works based on DNA computing have
been carried out in recent years. DNA sequence design is the foundation of such
research. The sequence quality directly affects the universality, robustness,
and stability of DNA computing. How to design DNA sequences depends on the
biological properties and target requirements, which is a typical combinatorial
optimization problem. In this paper, in order to design DNA sequences with
high-quality, we propose a novel meta-heuristic evolutionary algorithm, termed
the static virus spread algorithm (SVS). Through this algorithm, we focus on
the constraints of universal DNA sequence design and produce a large number of
DNA sequences with non-complementarity and small difference in melting
temperature as the objectives, and fully considering the balanced proportion of
the four bases. The computer simulation and polyacrylamide gel electrophoresis
experiments show that the high-quality DNA sequences designed by this algorithm
are effective, which is expected to provide a convenient tool for sequence
preparation before DNA biochemical operations.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02121" title="Abstract">arXiv:2311.02121</a> [<a href="/pdf/2311.02121" title="Download PDF">pdf</a>, <a href="/format/2311.02121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Monocular Height Estimation from Aerial Images with  Street-view Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+X">Xiaomou Hou</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+W">Wanshui Gan</a>, 
<a href="/search/cs?searchtype=author&query=Yokoya%2C+N">Naoto Yokoya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Accurate height estimation from monocular aerial imagery presents a
significant challenge due to its inherently ill-posed nature. This limitation
is rooted in the absence of adequate geometric constraints available to the
model when training with monocular imagery. Without additional geometric
information to supplement the monocular image data, the model's ability to
provide reliable estimations is compromised.
<br />In this paper, we propose a method that enhances monocular height estimation
by incorporating street-view images. Our insight is that street-view images
provide a distinct viewing perspective and rich structural details of the
scene, serving as geometric constraints to enhance the performance of monocular
height estimation. Specifically, we aim to optimize an implicit 3D scene
representation, density field, with geometry constraints from street-view
images, thereby improving the accuracy and robustness of height estimation. Our
experimental results demonstrate the effectiveness of our proposed method,
outperforming the baseline and offering significant improvements in terms of
accuracy and structural consistency.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02122" title="Abstract">arXiv:2311.02122</a> [<a href="/pdf/2311.02122" title="Download PDF">pdf</a>, <a href="/format/2311.02122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lost Your Style? Navigating with Semantic-Level Approach for  Text-to-Outfit Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jang%2C+J">Junkyu Jang</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+E">Eugene Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sung-Hyuk Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10pages, 2024 WACV Accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Fashion stylists have historically bridged the gap between consumers' desires
and perfect outfits, which involve intricate combinations of colors, patterns,
and materials. Although recent advancements in fashion recommendation systems
have made strides in outfit compatibility prediction and complementary item
retrieval, these systems rely heavily on pre-selected customer choices.
Therefore, we introduce a groundbreaking approach to fashion recommendations:
text-to-outfit retrieval task that generates a complete outfit set based solely
on textual descriptions given by users. Our model is devised at three semantic
levels-item, style, and outfit-where each level progressively aggregates data
to form a coherent outfit recommendation based on textual input. Here, we
leverage strategies similar to those in the contrastive language-image
pretraining model to address the intricate-style matrix within the outfit sets.
Using the Maryland Polyvore and Polyvore Outfit datasets, our approach
significantly outperformed state-of-the-art models in text-video retrieval
tasks, solidifying its effectiveness in the fashion recommendation domain. This
research not only pioneers a new facet of fashion recommendation systems, but
also introduces a method that captures the essence of individual style
preferences through textual descriptions.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02123" title="Abstract">arXiv:2311.02123</a> [<a href="/pdf/2311.02123" title="Download PDF">pdf</a>, <a href="/format/2311.02123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RigLSTM: Recurrent Independent Grid LSTM for Generalizable Sequence  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wenhao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zixuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wei Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Sequential processes in real-world often carry a combination of simple
subsystems that interact with each other in certain forms. Learning such a
modular structure can often improve the robustness against environmental
changes. In this paper, we propose recurrent independent Grid LSTM (RigLSTM),
composed of a group of independent LSTM cells that cooperate with each other,
for exploiting the underlying modular structure of the target task. Our model
adopts cell selection, input feature selection, hidden state selection, and
soft state updating to achieve a better generalization ability on the basis of
the recent Grid LSTM for the tasks where some factors differ between training
and evaluation. Specifically, at each time step, only a fraction of cells are
activated, and the activated cells select relevant inputs and cells to
communicate with. At the end of one time step, the hidden states of the
activated cells are updated by considering the relevance between the inputs and
the hidden states from the last and current time steps. Extensive experiments
on diversified sequential modeling tasks are conducted to show the superior
generalization ability when there exist changes in the testing environment.
Source code is available at \url{https://github.com/ziyuwwang/rig-lstm}.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02125" title="Abstract">arXiv:2311.02125</a> [<a href="/pdf/2311.02125" title="Download PDF">pdf</a>, <a href="/format/2311.02125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using General Value Functions to Learn Domain-Backed Inventory  Management Policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalwar%2C+D">Durgesh Kalwar</a>, 
<a href="/search/cs?searchtype=author&query=Shelke%2C+O">Omkar Shelke</a>, 
<a href="/search/cs?searchtype=author&query=Khadilkar%2C+H">Harshad Khadilkar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
<p class="mathjax">We consider the inventory management problem, where the goal is to balance
conflicting objectives such as availability and wastage of a large range of
products in a store. We propose a reinforcement learning (RL) approach that
utilises General Value Functions (GVFs) to derive domain-backed inventory
replenishment policies. The inventory replenishment decisions are modelled as a
sequential decision making problem, which is challenging due to uncertain
demand and the existence of aggregate (cross-product) constraints. In existing
literature, GVFs have primarily been used for auxiliary task learning. We use
this capability to train GVFs on domain-critical characteristics such as
prediction of stock-out probability and wastage quantity. Using this domain
expertise for more effective exploration, we train an RL agent to compute the
inventory replenishment quantities for a large range of products (up to 6000 in
the reported experiments), which share aggregate constraints such as the total
weight/volume per delivery. Additionally, we show that the GVF predictions can
be used to provide additional domain-backed insights into the decisions
proposed by the RL agent. Finally, since the environment dynamics are fully
transferred, the trained GVFs can be used for faster adaptation to vastly
different business objectives (for example, due to the start of a promotional
period or due to deployment in a new customer environment).
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02126" title="Abstract">arXiv:2311.02126</a> [<a href="/pdf/2311.02126" title="Download PDF">pdf</a>, <a href="/format/2311.02126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PILL: Plug Into LLM with Adapter Expert and Attention Gate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fangyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+T">Tingting Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhengyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yuyu Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Due to the remarkable capabilities of powerful Large Language Models (LLMs)
in effectively following instructions, there has been a growing number of
assistants in the community to assist humans. Recently, significant progress
has been made in the development of Vision Language Models (VLMs), expanding
the capabilities of LLMs and enabling them to execute more diverse
instructions. However, it is foreseeable that models will likely need to handle
tasks involving additional modalities such as speech, video, and others. This
poses a particularly prominent challenge of dealing with the complexity of
mixed modalities. To address this, we introduce a novel architecture called
PILL: Plug Into LLM with adapter expert and attention gate to better decouple
these complex modalities and leverage efficient fine-tuning. We introduce two
modules: Firstly, utilizing Mixture-of-Modality-Adapter-Expert to independently
handle different modalities, enabling better adaptation to downstream tasks
while preserving the expressive capability of the original model. Secondly, by
introducing Modality-Attention-Gating, which enables adaptive control of the
contribution of modality tokens to the overall representation. In addition, we
have made improvements to the Adapter to enhance its learning and expressive
capabilities. Experimental results demonstrate that our approach exhibits
competitive performance compared to other mainstream methods for modality
fusion. For researchers interested in our work, we provide free access to the
code and models at https://github.com/DsaltYfish/PILL.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02127" title="Abstract">arXiv:2311.02127</a> [<a href="/pdf/2311.02127" title="Download PDF">pdf</a>, <a href="/ps/2311.02127" title="Download PostScript">ps</a>, <a href="/format/2311.02127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Systematic Review of Deep Graph Neural Networks: Challenges,  Classification, Architectures, Applications &amp; Potential Utility in  Bioinformatics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malla%2C+A+M">Adil Mudasir Malla</a>, 
<a href="/search/cs?searchtype=author&query=Banka%2C+A+A">Asif Ali Banka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 13 figures, 21 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">In recent years, tasks of machine learning ranging from image processing &amp;
audio/video analysis to natural language understanding have been transformed by
deep learning. The data content in all these scenarios are expressed via
Euclidean space. However, a considerable amount of application data is
structured in non-Euclidean space and is expressed as graphs, e.g. dealing with
complicated interactions &amp; object interdependencies. Modelling physical
systems, learning molecular signatures, identifying protein interactions and
predicting diseases involve utilising a model that can adapt from graph data.
Graph neural networks (GNNs), specified as artificial-neural models, employ
message transmission between graph nodes to represent graph dependencies and
are primarily used in the non-Euclidean domain. Variants of GNN like Graph
Recurrent Networks (GRN), Graph Auto Encoder (GAE), Graph Convolution Networks
(GCN), Graph Adversarial Methods &amp; Graph Reinforcement learning have exhibited
breakthrough productivity on a wide range of tasks, especially in the field of
bioinformatics, in recent years as a result of the rapid collection of
biological network data. Apart from presenting all existing GNN models,
mathematical analysis and comparison of the variants of all types of GNN have
been highlighted in this survey. Graph neural networks are investigated for
their potential real-world applications in various fields, focusing on
Bioinformatics. Furthermore, resources for evaluating graph neural network
models and accessing open-source code &amp; benchmark data sets are included.
Ultimately, we provide some (seven) proposals for future research in this
rapidly evolving domain. GNNs have the potential to be an excellent tool for
solving a wide range of biological challenges in bioinformatics research, as
they are best represented as connected complex graphs.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02129" title="Abstract">arXiv:2311.02129</a> [<a href="/pdf/2311.02129" title="Download PDF">pdf</a>, <a href="/format/2311.02129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Reinforcement Learning for Power Network Topology Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manczak%2C+B">Blazej Manczak</a>, 
<a href="/search/cs?searchtype=author&query=Viebahn%2C+J">Jan Viebahn</a>, 
<a href="/search/cs?searchtype=author&query=van+Hoof%2C+H">Herke van Hoof</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Learning in high-dimensional action spaces is a key challenge in applying
reinforcement learning (RL) to real-world systems. In this paper, we study the
possibility of controlling power networks using RL methods. Power networks are
critical infrastructures that are complex to control. In particular, the
combinatorial nature of the action space poses a challenge to both conventional
optimizers and learned controllers. Hierarchical reinforcement learning (HRL)
represents one approach to address this challenge. More precisely, a HRL
framework for power network topology control is proposed. The HRL framework
consists of three levels of action abstraction. At the highest level, there is
the overall long-term task of power network operation, namely, keeping the
power grid state within security constraints at all times, which is decomposed
into two temporally extended actions: 'do nothing' versus 'propose a topology
change'. At the intermediate level, the action space consists of all
controllable substations. Finally, at the lowest level, the action space
consists of all configurations of the chosen substation. By employing this HRL
framework, several hierarchical power network agents are trained for the IEEE
14-bus network. Whereas at the highest level a purely rule-based policy is
still chosen for all agents in this study, at the intermediate level the policy
is trained using different state-of-the-art RL algorithms. At the lowest level,
either an RL algorithm or a greedy algorithm is used. The performance of the
different 3-level agents is compared with standard baseline (RL or greedy)
approaches. A key finding is that the 3-level agent that employs RL both at the
intermediate and the lowest level outperforms all other agents on the most
difficult task. Our code is publicly available.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02130" title="Abstract">arXiv:2311.02130</a> [<a href="/pdf/2311.02130" title="Download PDF">pdf</a>, <a href="/ps/2311.02130" title="Download PostScript">ps</a>, <a href="/format/2311.02130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Client Orchestration and Cost-Efficient Joint Optimization for  NOMA-Enabled Hierarchical Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bibo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+F">Fang Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xianbin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Donghong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+S">Shu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zhiguo Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Hierarchical federated learning (HFL) shows great advantages over
conventional two-layer federated learning (FL) in reducing network overhead and
interaction latency while still retaining the data privacy of distributed FL
clients. However, the communication and energy overhead still pose a bottleneck
for HFL performance, especially as the number of clients raises dramatically.
To tackle this issue, we propose a non-orthogonal multiple access (NOMA)
enabled HFL system under semi-synchronous cloud model aggregation in this
paper, aiming to minimize the total cost of time and energy at each HFL global
round. Specifically, we first propose a novel fuzzy logic based client
orchestration policy considering client heterogenerity in multiple aspects,
including channel quality, data quantity and model staleness. Subsequently,
given the fuzzy based client-edge association, a joint edge server scheduling
and resource allocation problem is formulated. Utilizing problem decomposition,
we firstly derive the closed-form solution for the edge server scheduling
subproblem via the penalty dual decomposition (PDD) method. Next, a deep
deterministic policy gradient (DDPG) based algorithm is proposed to tackle the
resource allocation subproblem considering time-varying environments. Finally,
extensive simulations demonstrate that the proposed scheme outperforms the
considered benchmarks regarding HFL performance improvement and total cost
reduction.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02132" title="Abstract">arXiv:2311.02132</a> [<a href="/pdf/2311.02132" title="Download PDF">pdf</a>, <a href="/format/2311.02132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource savings from fault-tolerant circuit design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+A+K">Andrew K. Tan</a>, 
<a href="/search/cs?searchtype=author&query=Chuang%2C+I+L">Isaac L. Chuang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Using fault-tolerant constructions, computations performed with unreliable
components can simulate their noiseless counterparts though the introduction of
a modest amount of redundancy. Given the modest overhead required to achieve
fault-tolerance, and the fact that increasing the reliability of basic
components often comes at a cost, are there situations where fault-tolerance
may be more economical? We present a general framework to account for this
overhead cost in order to effectively compare fault-tolerant to
non-fault-tolerant approaches for computation, in the limit of small logical
error rates. Using this detailed accounting, we determine explicit boundaries
at which fault-tolerant designs become more efficient than designs that achieve
comparable reliability through direct consumption of resources. We find that
the fault-tolerant construction is always preferred in the limit of high
reliability in cases where the resources required to construct a basic unit
grows faster than $\log(1 / \epsilon)$ asymptotically for small $\epsilon$.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02133" title="Abstract">arXiv:2311.02133</a> [<a href="/pdf/2311.02133" title="Download PDF">pdf</a>, <a href="/format/2311.02133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Online Dynamics Learning with Initially Unknown Models and  Infeasible Safety Certificates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Capone%2C+A">Alexandre Capone</a>, 
<a href="/search/eess?searchtype=author&query=Cosner%2C+R">Ryan Cosner</a>, 
<a href="/search/eess?searchtype=author&query=Ames%2C+A">Aaron Ames</a>, 
<a href="/search/eess?searchtype=author&query=Hirche%2C+S">Sandra Hirche</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Safety-critical control tasks with high levels of uncertainty are becoming
increasingly common. Typically, techniques that guarantee safety during
learning and control utilize constraint-based safety certificates, which can be
leveraged to compute safe control inputs. However, excessive model uncertainty
can render robust safety certification methods or infeasible, meaning no
control input satisfies the constraints imposed by the safety certificate. This
paper considers a learning-based setting with a robust safety certificate based
on a control barrier function (CBF) second-order cone program. If the control
barrier function certificate is feasible, our approach leverages it to
guarantee safety. Otherwise, our method explores the system dynamics to collect
data and recover the feasibility of the control barrier function constraint. To
this end, we employ a method inspired by well-established tools from Bayesian
optimization. We show that if the sampling frequency is high enough, we recover
the feasibility of the robust CBF certificate, guaranteeing safety. Our
approach requires no prior model and corresponds, to the best of our knowledge,
to the first algorithm that guarantees safety in settings with occasionally
infeasible safety certificates without requiring a backup non-learning-based
controller.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02142" title="Abstract">arXiv:2311.02142</a> [<a href="/pdf/2311.02142" title="Download PDF">pdf</a>, <a href="/format/2311.02142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Training of Discrete Diffusion Models for Graph Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yiming Qin</a>, 
<a href="/search/cs?searchtype=author&query=Vignac%2C+C">Clement Vignac</a>, 
<a href="/search/cs?searchtype=author&query=Frossard%2C+P">Pascal Frossard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generative models for graphs often encounter scalability challenges due to
the inherent need to predict interactions for every node pair. Despite the
sparsity often exhibited by real-world graphs, the unpredictable sparsity
patterns of their adjacency matrices, stemming from their unordered nature,
leads to quadratic computational complexity. In this work, we introduce
SparseDiff, a denoising diffusion model for graph generation that is able to
exploit sparsity during its training phase. At the core of SparseDiff is a
message-passing neural network tailored to predict only a subset of edges
during each forward pass. When combined with a sparsity-preserving noise model,
this model can efficiently work with edge lists representations of graphs,
paving the way for scalability to much larger structures. During the sampling
phase, SparseDiff iteratively populates the adjacency matrix from its prior
state, ensuring prediction of the full graph while controlling memory
utilization. Experimental results show that SparseDiff simultaneously matches
state-of-the-art in generation performance on both small and large graphs,
highlighting the versatility of our method.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02147" title="Abstract">arXiv:2311.02147</a> [<a href="/pdf/2311.02147" title="Download PDF">pdf</a>, <a href="/format/2311.02147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Alignment Problem in Context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Milli%C3%A8re%2C+R">Rapha&#xeb;l Milli&#xe8;re</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">A core challenge in the development of increasingly capable AI systems is to
make them safe and reliable by ensuring their behaviour is consistent with
human values. This challenge, known as the alignment problem, does not merely
apply to hypothetical future AI systems that may pose catastrophic risks; it
already applies to current systems, such as large language models, whose
potential for harm is rapidly increasing. In this paper, I assess whether we
are on track to solve the alignment problem for large language models, and what
that means for the safety of future AI systems. I argue that existing
strategies for alignment are insufficient, because large language models remain
vulnerable to adversarial attacks that can reliably elicit unsafe behaviour. I
offer an explanation of this lingering vulnerability on which it is not simply
a contingent limitation of current language models, but has deep technical ties
to a crucial aspect of what makes these models useful and versatile in the
first place -- namely, their remarkable aptitude to learn "in context" directly
from user instructions. It follows that the alignment problem is not only
unsolved for current AI systems, but may be intrinsically difficult to solve
without severely undermining their capabilities. Furthermore, this assessment
raises concerns about the prospect of ensuring the safety of future and more
capable AI systems.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02171" title="Abstract">arXiv:2311.02171</a> [<a href="/pdf/2311.02171" title="Download PDF">pdf</a>, <a href="/format/2311.02171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergence of Abstract State Representations in Embodied Sequence  Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yun%2C+T">Tian Yun</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zilai Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Handa%2C+K">Kunal Handa</a>, 
<a href="/search/cs?searchtype=author&query=Thapliyal%2C+A+V">Ashish V Thapliyal</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+B">Bo Pang</a>, 
<a href="/search/cs?searchtype=author&query=Pavlick%2C+E">Ellie Pavlick</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chen Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023. Project webpage: <a href="https://abstract-state-seqmodel.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Decision making via sequence modeling aims to mimic the success of language
models, where actions taken by an embodied agent are modeled as tokens to
predict. Despite their promising performance, it remains unclear if embodied
sequence modeling leads to the emergence of internal representations that
represent the environmental state information. A model that lacks abstract
state representations would be liable to make decisions based on surface
statistics which fail to generalize. We take the BabyAI environment, a grid
world in which language-conditioned navigation tasks are performed, and build a
sequence modeling Transformer, which takes a language instruction, a sequence
of actions, and environmental observations as its inputs. In order to
investigate the emergence of abstract state representations, we design a
"blindfolded" navigation task, where only the initial environmental layout, the
language instruction, and the action sequence to complete the task are
available for training. Our probing results show that intermediate
environmental layouts can be reasonably reconstructed from the internal
activations of a trained model, and that language instructions play a role in
the reconstruction accuracy. Our results suggest that many key features of
state representations can emerge via embodied sequence modeling, supporting an
optimistic outlook for applications of sequence modeling objectives to more
complex embodied decision-making domains.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02172" title="Abstract">arXiv:2311.02172</a> [<a href="/pdf/2311.02172" title="Download PDF">pdf</a>, <a href="/format/2311.02172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast and Accurate Approximations of the Optimal Transport in  Semi-Discrete and Discrete Settings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+P+K">Pankaj K. Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Raghvendra%2C+S">Sharath Raghvendra</a>, 
<a href="/search/cs?searchtype=author&query=Shirzadian%2C+P">Pouyan Shirzadian</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+K">Keegan Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">Given a $d$-dimensional continuous (resp. discrete) probability distribution
$\mu$ and a discrete distribution $\nu$, the semi-discrete (resp. discrete)
Optimal Transport (OT) problem asks for computing a minimum-cost plan to
transport mass from $\mu$ to $\nu$; we assume $n$ to be the size of the support
of the discrete distributions, and we assume we have access to an oracle
outputting the mass of $\mu$ inside a constant-complexity region in $O(1)$
time. In this paper, we present three approximation algorithms for the OT
problem.
<br />(i) Semi-discrete additive approximation: For any $\epsilon&gt;0$, we present an
algorithm that computes a semi-discrete transport plan with $\epsilon$-additive
error in $n^{O(d)}\log\frac{C_{\max}}{\epsilon}$ time; here, $C_{\max}$ is the
diameter of the supports of $\mu$ and $\nu$.
<br />(ii) Semi-discrete relative approximation: For any $\epsilon&gt;0$, we present
an algorithm that computes a $(1+\epsilon)$-approximate semi-discrete transport
plan in $n\epsilon^{-O(d)}\log(n)\log^{O(d)}(\log n)$ time; here, we assume the
ground distance is any $L_p$ norm.
<br />(iii) Discrete relative approximation: For any $\epsilon&gt;0$, we present a
Monte-Carlo $(1+\epsilon)$-approximation algorithm that computes a transport
plan under any $L_p$ norm in $n\epsilon^{-O(d)}\log(n)\log^{O(d)}(\log n)$
time; here, we assume that the spread of the supports of $\mu$ and $\nu$ is
polynomially bounded.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02183" title="Abstract">arXiv:2311.02183</a> [<a href="/pdf/2311.02183" title="Download PDF">pdf</a>, <a href="/format/2311.02183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-modal Prominent Fragments Enhancement Aligning Network for  Image-text Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
<p class="mathjax">Image-text retrieval is a widely studied topic in the field of computer
vision due to the exponential growth of multimedia data, whose core concept is
to measure the similarity between images and text. However, most existing
retrieval methods heavily rely on cross-attention mechanisms for cross-modal
fine-grained alignment, which takes into account excessive irrelevant regions
and treats prominent and non-significant words equally, thereby limiting
retrieval accuracy. This paper aims to investigate an alignment approach that
reduces the involvement of non-significant fragments in images and text while
enhancing the alignment of prominent segments. For this purpose, we introduce
the Cross-Modal Prominent Fragments Enhancement Aligning Network(CPFEAN), which
achieves improved retrieval accuracy by diminishing the participation of
irrelevant regions during alignment and relatively increasing the alignment
similarity of prominent words. Additionally, we incorporate prior textual
information into image regions to reduce misalignment occurrences. In practice,
we first design a novel intra-modal fragments relationship reasoning method,
and subsequently employ our proposed alignment mechanism to compute the
similarity between images and text. Extensive quantitative comparative
experiments on MS-COCO and Flickr30K datasets demonstrate that our approach
outperforms state-of-the-art methods by about 5% to 10% in the rSum metric.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02188" title="Abstract">arXiv:2311.02188</a> [<a href="/pdf/2311.02188" title="Download PDF">pdf</a>, <a href="/ps/2311.02188" title="Download PostScript">ps</a>, <a href="/format/2311.02188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Elastic energy storage of spring-driven jumping robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lo%2C+J">John Lo</a>, 
<a href="/search/cs?searchtype=author&query=Parslew%2C+B">Ben Parslew</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Applied Physics (physics.app-ph)

</div>
<p class="mathjax">Spring-driven jumping robots use an energised spring for propulsion, while
the onboard motor only serves as a spring-charging source. A common mechanism
in designing these robots is the rhomboidal linkage, which has been combined
with linear springs (spring-linkage) to create a nonlinear spring, thereby
increasing elastic energy storage and jump height for a given motor force. The
effectiveness of this spring-linkage has been examined for individual designs,
but a generalised design theory of this class of system remains absent. This
paper presents an energetics analysis of the spring-linkage and provides
insight into designing an ideal constant force spring, which stores the maximum
energy for a given motor force. A quasi-static analysis shows that the
force-displacement relationship of the spring-linkage changes with the
orientation and type of the spring, but is independent of the linkage scale.
Combining different types and orientations of springs within the linkage
enables higher elastic energy storage than using single springs. Placing two
translational springs at the diagonals of the rhomboidal linkage creates an
ideal spring that could increase the jump height of prior robots by 50-160%.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02189" title="Abstract">arXiv:2311.02189</a> [<a href="/pdf/2311.02189" title="Download PDF">pdf</a>, <a href="/format/2311.02189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FairSeg: A Large-scale Medical Image Segmentation Dataset for Fairness  Learning with Fair Error-Bound Scaling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yu Tian</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+M">Min Shi</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Kouhana%2C+A">Ava Kouhana</a>, 
<a href="/search/cs?searchtype=author&query=Elze%2C+T">Tobias Elze</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengyu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Fairness in artificial intelligence models has gained significantly more
attention in recent years, especially in the area of medicine, as fairness in
medical models is critical to people's well-being and lives. High-quality
medical fairness datasets are needed to promote fairness learning research.
Existing medical fairness datasets are all for classification tasks, and no
fairness datasets are available for medical segmentation, while medical
segmentation is an equally important clinical task as classifications, which
can provide detailed spatial information on organ abnormalities ready to be
assessed by clinicians. In this paper, we propose the first fairness dataset
for medical segmentation named FairSeg with 10,000 subject samples. In
addition, we propose a fair error-bound scaling approach to reweight the loss
function with the upper error-bound in each identity group. We anticipate that
the segmentation performance equity can be improved by explicitly tackling the
hard cases with high training errors in each identity group. To facilitate fair
comparisons, we propose new equity-scaled segmentation performance metrics,
such as the equity-scaled Dice coefficient, which is calculated as the overall
Dice coefficient divided by one plus the standard deviation of group Dice
coefficients. Through comprehensive experiments, we demonstrate that our fair
error-bound scaling approach either has superior or comparable fairness
performance to the state-of-the-art fairness learning models. The dataset and
code are publicly accessible via
\url{https://github.com/Harvard-Ophthalmology-AI-Lab/FairSeg}.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02191" title="Abstract">arXiv:2311.02191</a> [<a href="/pdf/2311.02191" title="Download PDF">pdf</a>, <a href="/format/2311.02191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SparsePoser: Real-time Full-body Motion Reconstruction from Sparse Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ponton%2C+J+L">Jose Luis Ponton</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+H">Haoran Yun</a>, 
<a href="/search/cs?searchtype=author&query=Aristidou%2C+A">Andreas Aristidou</a>, 
<a href="/search/cs?searchtype=author&query=Andujar%2C+C">Carlos Andujar</a>, 
<a href="/search/cs?searchtype=author&query=Pelechano%2C+N">Nuria Pelechano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in ACM TOG <a href="https://dl.acm.org/doi/10.1145/3625264">this https URL</a> and presented in SIGGRAPH ASIA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Accurate and reliable human motion reconstruction is crucial for creating
natural interactions of full-body avatars in Virtual Reality (VR) and
entertainment applications. As the Metaverse and social applications gain
popularity, users are seeking cost-effective solutions to create full-body
animations that are comparable in quality to those produced by commercial
motion capture systems. In order to provide affordable solutions, though, it is
important to minimize the number of sensors attached to the subject's body.
Unfortunately, reconstructing the full-body pose from sparse data is a heavily
under-determined problem. Some studies that use IMU sensors face challenges in
reconstructing the pose due to positional drift and ambiguity of the poses. In
recent years, some mainstream VR systems have released 6-degree-of-freedom
(6-DoF) tracking devices providing positional and rotational information.
Nevertheless, most solutions for reconstructing full-body poses rely on
traditional inverse kinematics (IK) solutions, which often produce
non-continuous and unnatural poses. In this article, we introduce SparsePoser,
a novel deep learning-based solution for reconstructing a full-body pose from a
reduced set of six tracking devices. Our system incorporates a
convolutional-based autoencoder that synthesizes high-quality continuous human
poses by learning the human motion manifold from motion capture data. Then, we
employ a learned IK component, made of multiple lightweight feed-forward neural
networks, to adjust the hands and feet toward the corresponding trackers. We
extensively evaluate our method on publicly available motion capture datasets
and with real-time live demos. We show that our method outperforms
state-of-the-art techniques using IMU sensors or 6-DoF tracking devices, and
can be used for users with different body dimensions and proportions.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02192" title="Abstract">arXiv:2311.02192</a> [<a href="/pdf/2311.02192" title="Download PDF">pdf</a>, <a href="/format/2311.02192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automating Governing Knowledge Commons and Contextual Integrity (GKC-CI)  Privacy Policy Annotations with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chanenson%2C+J">Jake Chanenson</a>, 
<a href="/search/cs?searchtype=author&query=Pickering%2C+M">Madison Pickering</a>, 
<a href="/search/cs?searchtype=author&query=Apthorpe%2C+N">Noah Apthorpe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 7 figures, 10 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Identifying contextual integrity (CI) and governing knowledge commons (GKC)
parameters in privacy policy texts can facilitate normative privacy analysis.
However, GKC-CI annotation has heretofore required manual or crowdsourced
effort. This paper demonstrates that high-accuracy GKC-CI parameter annotation
of privacy policies can be performed automatically using large language models.
We fine-tune 18 open-source and proprietary models on 21,588 GKC-CI annotations
from 16 ground truth privacy policies. Our best-performing model (fine-tuned
GPT-3.5 Turbo with prompt engineering) has an accuracy of 86%, exceeding the
performance of prior crowdsourcing approaches despite the complexity of privacy
policy texts and the nuance of the GKC-CI annotation task. We apply our
best-performing model to privacy policies from 164 popular online services,
demonstrating the effectiveness of scaling GKC-CI annotation for data
exploration. We make all annotated policies as well as the training data and
scripts needed to fine-tune our best-performing model publicly available for
future research.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02194" title="Abstract">arXiv:2311.02194</a> [<a href="/pdf/2311.02194" title="Download PDF">pdf</a>, <a href="/format/2311.02194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AlberDICE: Addressing Out-Of-Distribution Joint Actions in Offline  Multi-Agent RL via Alternating Stationary Distribution Correction Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Matsunaga%2C+D+E">Daiki E. Matsunaga</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jongmin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+J">Jaeseok Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Leonardos%2C+S">Stefanos Leonardos</a>, 
<a href="/search/cs?searchtype=author&query=Abbeel%2C+P">Pieter Abbeel</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kee-Eung Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 12 figures, Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">One of the main challenges in offline Reinforcement Learning (RL) is the
distribution shift that arises from the learned policy deviating from the data
collection policy. This is often addressed by avoiding out-of-distribution
(OOD) actions during policy improvement as their presence can lead to
substantial performance degradation. This challenge is amplified in the offline
Multi-Agent RL (MARL) setting since the joint action space grows exponentially
with the number of agents. To avoid this curse of dimensionality, existing MARL
methods adopt either value decomposition methods or fully decentralized
training of individual agents. However, even when combined with standard
conservatism principles, these methods can still result in the selection of OOD
joint actions in offline MARL. To this end, we introduce AlberDICE, an offline
MARL algorithm that alternatively performs centralized training of individual
agents based on stationary distribution optimization. AlberDICE circumvents the
exponential complexity of MARL by computing the best response of one agent at a
time while effectively avoiding OOD joint action selection. Theoretically, we
show that the alternating optimization procedure converges to Nash policies. In
the experiments, we demonstrate that AlberDICE significantly outperforms
baseline algorithms on a standard suite of MARL benchmarks.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02198" title="Abstract">arXiv:2311.02198</a> [<a href="/pdf/2311.02198" title="Download PDF">pdf</a>, <a href="/format/2311.02198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imitation Bootstrapped Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hengyuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Mirchandani%2C+S">Suvir Mirchandani</a>, 
<a href="/search/cs?searchtype=author&query=Sadigh%2C+D">Dorsa Sadigh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite the considerable potential of reinforcement learning (RL), robotics
control tasks predominantly rely on imitation learning (IL) owing to its better
sample efficiency. However, given the high cost of collecting extensive
demonstrations, RL is still appealing if it can utilize limited imitation data
for efficient autonomous self-improvement. Existing RL methods that utilize
demonstrations either initialize the replay buffer with demonstrations and
oversample them during RL training, which does not benefit from the
generalization potential of modern IL methods, or pretrain the RL policy with
IL on the demonstrations, which requires additional mechanisms to prevent
catastrophic forgetting during RL fine-tuning. We propose imitation
bootstrapped reinforcement learning (IBRL), a novel framework that first trains
an IL policy on a limited number of demonstrations and then uses it to propose
alternative actions for both online exploration and target value bootstrapping.
IBRL achieves SoTA performance and sample efficiency on 7 challenging sparse
reward continuous control tasks in simulation while learning directly from
pixels. As a highlight of our method, IBRL achieves $6.4\times$ higher success
rate than RLPD, a strong method that combines the idea of oversampling
demonstrations with modern RL improvements, under the budget of 10 demos and
100K interactions in the challenging PickPlaceCan task in the Robomimic
benchmark.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02202" title="Abstract">arXiv:2311.02202</a> [<a href="/pdf/2311.02202" title="Download PDF">pdf</a>, <a href="/format/2311.02202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Collage Transfer: Artistic Reconstruction via Material  Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+G">Ganghun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minji Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yunsu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Minsu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Byoung-Tak Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Collage is a creative art form that uses diverse material scraps as a base
unit to compose a single image. Although pixel-wise generation techniques can
reproduce a target image in collage style, it is not a suitable method due to
the solid stroke-by-stroke nature of the collage form. While some previous
works for stroke-based rendering produced decent sketches and paintings,
collages have received much less attention in research despite their popularity
as a style. In this paper, we propose a method for learning to make collages
via reinforcement learning without the need for demonstrations or collage
artwork data. We design the collage Markov Decision Process (MDP), which allows
the agent to handle various materials and propose a model-based soft
actor-critic to mitigate the agent's training burden derived from the
sophisticated dynamics of collage. Moreover, we devise additional techniques
such as active material selection and complexity-based multi-scale collage to
handle target images at any size and enhance the results' aesthetics by placing
relatively more scraps in areas of high complexity. Experimental results show
that the trained agent appropriately selected and pasted materials to
regenerate the target image into a collage and obtained a higher evaluation
score on content and style than pixel-wise generation methods. Code is
available at https://github.com/northadventure/CollageRL.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02205" title="Abstract">arXiv:2311.02205</a> [<a href="/pdf/2311.02205" title="Download PDF">pdf</a>, <a href="/format/2311.02205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Introduction to Natural Language Processing Techniques and Framework  for Clinical Implementation in Radiation Oncology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khanmohammadi%2C+R">Reza Khanmohammadi</a>, 
<a href="/search/cs?searchtype=author&query=Ghassemi%2C+M+M">Mohammad M. Ghassemi</a>, 
<a href="/search/cs?searchtype=author&query=Verdecchia%2C+K">Kyle Verdecchia</a>, 
<a href="/search/cs?searchtype=author&query=Ghanem%2C+A+I">Ahmed I. Ghanem</a>, 
<a href="/search/cs?searchtype=author&query=Bing%2C+L">Luo Bing</a>, 
<a href="/search/cs?searchtype=author&query=Chetty%2C+I+J">Indrin J. Chetty</a>, 
<a href="/search/cs?searchtype=author&query=Bagher-Ebadian%2C+H">Hassan Bagher-Ebadian</a>, 
<a href="/search/cs?searchtype=author&query=Siddiqui%2C+F">Farzan Siddiqui</a>, 
<a href="/search/cs?searchtype=author&query=Elshaikh%2C+M">Mohamed Elshaikh</a>, 
<a href="/search/cs?searchtype=author&query=Movsas%2C+B">Benjamin Movsas</a>, 
<a href="/search/cs?searchtype=author&query=Thind%2C+K">Kundan Thind</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Natural Language Processing (NLP) is a key technique for developing Medical
Artificial Intelligence (AI) systems that leverage Electronic Health Record
(EHR) data to build diagnostic and prognostic models. NLP enables the
conversion of unstructured clinical text into structured data that can be fed
into AI algorithms. The emergence of the transformer architecture and large
language models (LLMs) has led to remarkable advances in NLP for various
healthcare tasks, such as entity recognition, relation extraction, sentence
similarity, text summarization, and question answering. In this article, we
review the major technical innovations that underpin modern NLP models and
present state-of-the-art NLP applications that employ LLMs in radiation
oncology research. However, these LLMs are prone to many errors such as
hallucinations, biases, and ethical violations, which necessitate rigorous
evaluation and validation before clinical deployment. As such, we propose a
comprehensive framework for assessing the NLP models based on their purpose and
clinical fit, technical performance, bias and trust, legal and ethical
implications, and quality assurance, prior to implementation in clinical
radiation oncology. Our article aims to provide guidance and insights for
researchers and clinicians who are interested in developing and using NLP
models in clinical radiation oncology.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02206" title="Abstract">arXiv:2311.02206</a> [<a href="/pdf/2311.02206" title="Download PDF">pdf</a>, <a href="/format/2311.02206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GDlog: A GPU-Accelerated Deductive Engine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yihao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Shovon%2C+A+R">Ahmedur Rahman Shovon</a>, 
<a href="/search/cs?searchtype=author&query=Gilray%2C+T">Thomas Gilray</a>, 
<a href="/search/cs?searchtype=author&query=Micinski%2C+K">Kristopher Micinski</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sidharth Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Modern deductive database engines (e.g., LogicBlox and Souffl\'e) enable
their users to write declarative queries which compute recursive deductions
over extensional data, leaving their high-performance operationalization (query
planning, semi-na\"ive evaluation, and parallelization) to the engine. Such
engines form the backbone of modern high-throughput applications in static
analysis, security auditing, social-media mining, and business analytics.
State-of-the-art engines are built upon nested loop joins over explicit
representations (e.g., BTrees and tries) and ubiquitously employ range indexing
to accelerate iterated joins. In this work, we present GDlog: a GPU-based
deductive analytics engine (implemented as a CUDA library) which achieves
significant performance improvements (5--10x or more) versus prior systems.
GDlog is powered by a novel range-indexed SIMD datastructure: the hash-indexed
sorted array (HISA). We perform extensive evaluation on GDlog, comparing it
against both CPU and GPU-based hash tables and Datalog engines, and using it to
support a range of large-scale deductive queries including reachability, same
generation, and context-sensitive program analysis. Our experiments show that
GDlog achieves performance competitive with modern SIMD hash tables and beats
prior work by an order of magnitude in runtime while offering more favorable
memory footprint.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02209" title="Abstract">arXiv:2311.02209</a> [<a href="/pdf/2311.02209" title="Download PDF">pdf</a>, <a href="/format/2311.02209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Model-Based Synthetic Stock Price Time Series Generation Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Haibei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Vyetrenko%2C+S">Svitlana Vyetrenko</a>, 
<a href="/search/cs?searchtype=author&query=Balch%2C+T">Tucker Balch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Databases (cs.DB)

</div>
<p class="mathjax">The Ornstein-Uhlenbeck (OU) process, a mean-reverting stochastic process, has
been widely applied as a time series model in various domains. This paper
describes the design and implementation of a model-based synthetic time series
model based on a multivariate OU process and the Arbitrage Pricing Theory (APT)
for generating synthetic pricing data for a complex market of interacting
stocks. The objective is to create a group of synthetic stock price time series
that reflects the correlation between individual stocks and clusters of stocks
in how a real market behaves. We demonstrate the method using the Standard and
Poor's (S&amp;P) 500 universe of stocks as an example.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02211" title="Abstract">arXiv:2311.02211</a> [<a href="/pdf/2311.02211" title="Download PDF">pdf</a>, <a href="/format/2311.02211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rock Climbing Route Generation and Grading as Computational Creativity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roberts%2C+J">Jesse Roberts</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Other Computer Science (cs.OH)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we bridge work in rock climbing route generation and grading
into the computational creativity community. We provide the necessary
background to situate that literature and demonstrate the domain's intellectual
merit in the computational creativity community. We provide a guiding set of
desiderata for future work in this area. We propose an approach to
computational route grading. Finally, we identify important gaps in the
literature and consider how they may be filled. This paper thus also serves as
a pilot study, planting a flag for our ongoing research in this domain.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02213" title="Abstract">arXiv:2311.02213</a> [<a href="/pdf/2311.02213" title="Download PDF">pdf</a>, <a href="/format/2311.02213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Composite Latent Space Bayesian Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maus%2C+N">Natalie Maus</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z+J">Zhiyuan Jerry Lin</a>, 
<a href="/search/cs?searchtype=author&query=Balandat%2C+M">Maximilian Balandat</a>, 
<a href="/search/cs?searchtype=author&query=Bakshy%2C+E">Eytan Bakshy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Bayesian Optimization (BO) is a technique for sample-efficient black-box
optimization that employs probabilistic models to identify promising input
locations for evaluation. When dealing with composite-structured functions,
such as f=g o h, evaluating a specific location x yields observations of both
the final outcome f(x) = g(h(x)) as well as the intermediate output(s) h(x).
Previous research has shown that integrating information from these
intermediate outputs can enhance BO performance substantially. However,
existing methods struggle if the outputs h(x) are high-dimensional. Many
relevant problems fall into this setting, including in the context of
generative AI, molecular design, or robotics. To effectively tackle these
challenges, we introduce Joint Composite Latent Space Bayesian Optimization
(JoCo), a novel framework that jointly trains neural network encoders and
probabilistic models to adaptively compress high-dimensional input and output
spaces into manageable latent representations. This enables viable BO on these
compressed representations, allowing JoCo to outperform other state-of-the-art
methods in high-dimensional BO on a wide variety of simulated and real-world
problems.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02215" title="Abstract">arXiv:2311.02215</a> [<a href="/pdf/2311.02215" title="Download PDF">pdf</a>, <a href="/format/2311.02215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards model-free RL algorithms that scale well with unstructured data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Modayil%2C+J">Joseph Modayil</a>, 
<a href="/search/cs?searchtype=author&query=Abbas%2C+Z">Zaheer Abbas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Conventional reinforcement learning (RL) algorithms exhibit broad generality
in their theoretical formulation and high performance on several challenging
domains when combined with powerful function approximation. However, developing
RL algorithms that perform well across problems with unstructured observations
at scale remains challenging because most function approximation methods rely
on externally provisioned knowledge about the structure of the input for good
performance (e.g. convolutional networks, graph neural networks, tile-coding).
A common practice in RL is to evaluate algorithms on a single problem, or on
problems with limited variation in the observation scale. RL practitioners lack
a systematic way to study how well a single RL algorithm performs when
instantiated across a range of problem scales, and they lack function
approximation techniques that scale well with unstructured observations.
<br />We address these limitations by providing environments and algorithms to
study scaling for unstructured observation vectors and flat action spaces. We
introduce a family of combinatorial RL problems with an exponentially large
state space and high-dimensional dynamics but where linear computation is
sufficient to learn a (nonlinear) value function estimate for performant
control. We provide an algorithm that constructs reward-relevant general value
function (GVF) questions to find and exploit predictive structure directly from
the experience stream. In an empirical evaluation of the approach on synthetic
problems, we observe a sample complexity that scales linearly with the
observation size. The proposed algorithm reliably outperforms a conventional
deep RL algorithm on these scaling problems, and they exhibit several desirable
auxiliary properties. These results suggest new algorithmic mechanisms by which
algorithms can learn at scale from unstructured data.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02216" title="Abstract">arXiv:2311.02216</a> [<a href="/pdf/2311.02216" title="Download PDF">pdf</a>, <a href="/format/2311.02216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Numerical Reasoning Capabilities of Language Models: A  Comprehensive Analysis on Tabular Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akhtar%2C+M">Mubashara Akhtar</a>, 
<a href="/search/cs?searchtype=author&query=Shankarampeta%2C+A">Abhilash Shankarampeta</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+V">Vivek Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Patil%2C+A">Arpit Patil</a>, 
<a href="/search/cs?searchtype=author&query=Cocarascu%2C+O">Oana Cocarascu</a>, 
<a href="/search/cs?searchtype=author&query=Simperl%2C+E">Elena Simperl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023 (Findings)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Numbers are crucial for various real-world domains such as finance,
economics, and science. Thus, understanding and reasoning with numbers are
essential skills for language models to solve different tasks. While different
numerical benchmarks have been introduced in recent years, they are limited to
specific numerical aspects mostly. In this paper, we propose a hierarchical
taxonomy for numerical reasoning skills with more than ten reasoning types
across four levels: representation, number sense, manipulation, and complex
reasoning. We conduct a comprehensive evaluation of state-of-the-art models to
identify reasoning challenges specific to them. Henceforth, we develop a
diverse set of numerical probes employing a semi-automated approach. We focus
on the tabular Natural Language Inference (TNLI) task as a case study and
measure models' performance shifts. Our results show that no model consistently
excels across all numerical reasoning types. Among the probed models, FlanT5
(few-/zero-shot) and GPT-3.5 (few-shot) demonstrate strong overall numerical
reasoning skills compared to other models. Label-flipping probes indicate that
models often exploit dataset artifacts to predict the correct labels.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02217" title="Abstract">arXiv:2311.02217</a> [<a href="/pdf/2311.02217" title="Download PDF">pdf</a>, <a href="/format/2311.02217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear difference operators with sequence coefficients having  infinite-dimentional solution spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abramov%2C+S">Sergei Abramov</a>, 
<a href="/search/cs?searchtype=author&query=Pogudin%2C+G">Gleb Pogudin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In memory of Marko Petkov\v{s}ek
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM Communications in Computer Algebra, vol 57, issue 1, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>

</div>
<p class="mathjax">The notion of lacunary infinite numerical sequence is introduced. It is shown
that for an arbitrary linear difference operator L with coefficients belonging
to the set R of infinite numerical sequences, a criterion (i.e., a necessary
and sufficient condition) for the infinite dimensionality of its space $V_L$ of
solutions belonging to R is the presence of a lacunary sequence in $V_L$.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02219" title="Abstract">arXiv:2311.02219</a> [<a href="/pdf/2311.02219" title="Download PDF">pdf</a>, <a href="/ps/2311.02219" title="Download PostScript">ps</a>, <a href="/format/2311.02219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the dimension of the solution space of linear difference equations  over the ring of infinite sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abramov%2C+S">Sergei Abramov</a>, 
<a href="/search/cs?searchtype=author&query=Pogudin%2C+G">Gleb Pogudin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In memory of Marko Petkov\v{s}ek
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>

</div>
<p class="mathjax">For a linear difference equation with the coefficients being computable
sequences, we establish algorithmic undecidability of the problem of
determining the dimension of the solution space including the case when some
additional prior information on the dimension is available.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02221" title="Abstract">arXiv:2311.02221</a> [<a href="/pdf/2311.02221" title="Download PDF">pdf</a>, <a href="/format/2311.02221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structured Neural Networks for Density Estimation and Causal Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+A+Q">Asic Q. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+R">Ruian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Baptista%2C+R">Ricardo Baptista</a>, 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+R+G">Rahul G. Krishnan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages with 5 figures, to be published in Neural Information Processing Systems 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Injecting structure into neural networks enables learning functions that
satisfy invariances with respect to subsets of inputs. For instance, when
learning generative models using neural networks, it is advantageous to encode
the conditional independence structure of observed variables, often in the form
of Bayesian networks. We propose the Structured Neural Network (StrNN), which
injects structure through masking pathways in a neural network. The masks are
designed via a novel relationship we explore between neural network
architectures and binary matrix factorization, to ensure that the desired
independencies are respected. We devise and study practical algorithms for this
otherwise NP-hard design problem based on novel objectives that control the
model architecture. We demonstrate the utility of StrNN in three applications:
(1) binary and Gaussian density estimation with StrNN, (2) real-valued density
estimation with Structured Autoregressive Flows (StrAFs) and Structured
Continuous Normalizing Flows (StrCNF), and (3) interventional and
counterfactual analysis with StrAFs for causal inference. Our work opens up new
avenues for learning neural networks that enable data-efficient generative
modeling and the use of normalizing flows for causal effect estimation.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02224" title="Abstract">arXiv:2311.02224</a> [<a href="/pdf/2311.02224" title="Download PDF">pdf</a>, <a href="/format/2311.02224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structural Properties of Search Trees with 2-way Comparisons
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atalig%2C+S">Sunny Atalig</a>, 
<a href="/search/cs?searchtype=author&query=Chrobak%2C+M">Marek Chrobak</a>, 
<a href="/search/cs?searchtype=author&query=Mousavian%2C+E">Erfan Mousavian</a>, 
<a href="/search/cs?searchtype=author&query=Sgall%2C+J">Jiri Sgall</a>, 
<a href="/search/cs?searchtype=author&query=Vesely%2C+P">Pavel Vesely</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Optimal 3-way comparison search trees (3WCST's) can be computed using
standard dynamic programming in time O(n^3), and this can be further improved
to O(n^2) by taking advantage of the Monge property. In contrast, the fastest
algorithm in the literature for computing optimal 2-way comparison search trees
(2WCST's) runs in time O(n^4). To shed light on this discrepancy, we study
structure properties of 2WCST's. On one hand, we show some new threshold bounds
involving key weights that can be helpful in deciding which type of comparison
should be at the root of the optimal tree. On the other hand, we also show that
the standard techniques for speeding up dynamic programming (the Monge property
/ quadrangle inequality) do not apply to 2WCST's.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02225" title="Abstract">arXiv:2311.02225</a> [<a href="/pdf/2311.02225" title="Download PDF">pdf</a>, <a href="/format/2311.02225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-scale Time-stepping of Partial Differential Equations with  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hemmasian%2C+A">AmirPouya Hemmasian</a>, 
<a href="/search/cs?searchtype=author&query=Farimani%2C+A+B">Amir Barati Farimani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Developing fast surrogates for Partial Differential Equations (PDEs) will
accelerate design and optimization in almost all scientific and engineering
applications. Neural networks have been receiving ever-increasing attention and
demonstrated remarkable success in computational modeling of PDEs, however;
their prediction accuracy is not at the level of full deployment. In this work,
we utilize the transformer architecture, the backbone of numerous
state-of-the-art AI models, to learn the dynamics of physical systems as the
mixing of spatial patterns learned by a convolutional autoencoder. Moreover, we
incorporate the idea of multi-scale hierarchical time-stepping to increase the
prediction speed and decrease accumulated error over time. Our model achieves
similar or better results in predicting the time-evolution of Navier-Stokes
equations compared to the powerful Fourier Neural Operator (FNO) and two
transformer-based neural operators OFormer and Galerkin Transformer.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02227" title="Abstract">arXiv:2311.02227</a> [<a href="/pdf/2311.02227" title="Download PDF">pdf</a>, <a href="/format/2311.02227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> State-wise Safe Reinforcement Learning With Pixel Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+S+S">Simon Sinong Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yixuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+R">Ruochen Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qi Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Reinforcement Learning(RL) in the context of safe exploration has long
grappled with the challenges of the delicate balance between maximizing rewards
and minimizing safety violations, the complexities arising from contact-rich or
non-smooth environments, and high-dimensional pixel observations. Furthermore,
incorporating state-wise safety constraints in the exploration and learning
process, where the agent is prohibited from accessing unsafe regions without
prior knowledge, adds an additional layer of complexity. In this paper, we
propose a novel pixel-observation safe RL algorithm that efficiently encodes
state-wise safety constraints with unknown hazard regions through the
introduction of a latent barrier function learning mechanism. As a joint
learning framework, our approach first involves constructing a latent dynamics
model with low-dimensional latent spaces derived from pixel observations.
Subsequently, we build and learn a latent barrier function on top of the latent
dynamics and conduct policy optimization simultaneously, thereby improving both
safety and the total expected return. Experimental evaluations on the
safety-gym benchmark suite demonstrate that our proposed method significantly
reduces safety violations throughout the training process and demonstrates
faster safety convergence compared to existing methods while achieving
competitive results in reward return.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02228" title="Abstract">arXiv:2311.02228</a> [<a href="/pdf/2311.02228" title="Download PDF">pdf</a>, <a href="/format/2311.02228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Behavioral-aware Crowd Management System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yixin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tianyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Elmalaki%2C+S">Salma Elmalaki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Instances of casualties resulting from large crowds persist, highlighting the
existing limitations of current crowd management practices. One notable
drawback is the insufficient provision for disadvantaged individuals who may
require additional time to evacuate due to their slower running speed.
Moreover, the existing escape strategies may fall short of ensuring the safety
of all individuals during a crowd surge. To address these pressing concerns,
this paper proposes two crowd management methodologies. Firstly, we advocate
for the implementation of a fair evacuation strategy following a surge event,
which takes into account the diverse needs of all individuals, ensuring
inclusivity and mitigating potential risks. Secondly, we propose a preventative
approach involving the adjustment of attraction locations and switching between
stage performances in large-crowded events to minimize the occurrence of surges
and enhance crowd dispersion. To assess the effectiveness of our proposals, we
used high-fidelity crowd management simulators. Our findings demonstrate the
positive impact of the fair evacuation strategy on safety measures and
inclusivity, which increases fairness by 41.8% on average. Furthermore, the
adjustment of attraction locations and stage performances has shown a
significant reduction in the incidence of surges by 34% on average, thereby
enhancing overall crowd safety.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02231" title="Abstract">arXiv:2311.02231</a> [<a href="/pdf/2311.02231" title="Download PDF">pdf</a>, <a href="/ps/2311.02231" title="Download PostScript">ps</a>, <a href="/format/2311.02231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Gronwall Inequality Based Approach to Transient Stability Assessment  for Power Grids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Q">Qian Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Gan%2C+D">Deqiang Gan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper proposes a novel Gronwall inequality-based method for transient
stability assessment for power systems. The challenges of applying such methods
to power systems are how to construct the differential inequality and how to
treat its nonlinearity. By leveraging partial derivatives, a rotor angle
difference inequality model is established, and the difficulty of nonlinearity
of this model is solved by piecewise linearization. Based on our method, the
upper bound of the rotor angle difference is given analytically, which can be
used to estimate the stability boundary, i.e. the critical clearing time (CCT)
of power systems. A case study on the IEEE 9-bus system shows the accuracy of
the approach in early warning of transient instability for power grids.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02234" title="Abstract">arXiv:2311.02234</a> [<a href="/pdf/2311.02234" title="Download PDF">pdf</a>, <a href="/format/2311.02234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synchronous Observer Design for Inertial Navigation Systems with  Almost-Global Convergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=van+Goor%2C+P">Pieter van Goor</a>, 
<a href="/search/eess?searchtype=author&query=Hamel%2C+T">Tarek Hamel</a>, 
<a href="/search/eess?searchtype=author&query=Mahony%2C+R">Robert Mahony</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 4 figures, pre-print
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">An Inertial Navigation System (INS) is a system that integrates acceleration
and angular velocity readings from an Inertial Measurement Unit (IMU), along
with other sensors such as GNSS position, GNSS velocity, and magnetometer, to
estimate the attitude, velocity, and position of a vehicle. This paper shows
that the INS problem can be analysed using the automorphism group of the
extended special Euclidean group: a group we term the extended similarity
group. By exploiting this novel geometric framework, we propose an observer
architecture with synchronous error dynamics; that is, the error is stationary
if the observer correction terms are set to zero. In turn, this enables us to
derive a modular, or plug-and-play, observer design for INS that allows
different sensors to be added or removed depending on what is available in the
vehicle sensor suite. We prove both almost-global asymptotic and local
exponential stability of the error dynamics for the common scenario of at least
IMU and GNSS position. To the authors' knowledge, this is the first non-linear
observer design with almost global convergence guarantees or with plug-and-play
modular capability. A simulation with extreme initial error demonstrates the
almost-global robustness of the system. Real-world capability is demonstrated
on data from a fixed-wing UAV, and the solution is compared to the
state-of-the-art ArduPilot INS.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02236" title="Abstract">arXiv:2311.02236</a> [<a href="/pdf/2311.02236" title="Download PDF">pdf</a>, <a href="/format/2311.02236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Fine-Tuning of Vision-Language Models for Domain Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vogt-Lowell%2C+K">Kevin Vogt-Lowell</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+N">Noah Lee</a>, 
<a href="/search/cs?searchtype=author&query=Tsiligkaridis%2C+T">Theodoros Tsiligkaridis</a>, 
<a href="/search/cs?searchtype=author&query=Vaillant%2C+M">Marc Vaillant</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In proceedings of the 27th IEEE High Performance Extreme Computing Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Transfer learning enables the sharing of common knowledge among models for a
variety of downstream tasks, but traditional methods suffer in limited training
data settings and produce narrow models incapable of effectively generalizing
under distribution shifts. Foundation models have recently demonstrated
impressive zero-shot inference capabilities and robustness under distribution
shifts. However, zero-shot evaluation for these models has been predominantly
confined to benchmarks with simple distribution shifts, limiting our
understanding of their effectiveness under the more realistic shifts found in
practice. Moreover, common fine-tuning methods for these models have yet to be
evaluated against vision models in few-shot scenarios where training data is
limited. To address these gaps, we present a new recipe for few-shot
fine-tuning of the popular vision-language foundation model CLIP and evaluate
its performance on challenging benchmark datasets with realistic distribution
shifts from the WILDS collection. Our experimentation demonstrates that, while
zero-shot CLIP fails to match performance of trained vision models on more
complex benchmarks, few-shot CLIP fine-tuning outperforms its vision-only
counterparts in terms of in-distribution and out-of-distribution accuracy at
all levels of training data availability. This provides a strong incentive for
adoption of foundation models within few-shot learning applications operating
with real-world data. Code is available at
$\href{https://github.com/mit-ll/robust-vision-language-finetuning}{\text{https://github.com/mit-ll/robust-vision-language-finetuning}}$.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02237" title="Abstract">arXiv:2311.02237</a> [<a href="/pdf/2311.02237" title="Download PDF">pdf</a>, <a href="/format/2311.02237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Authorship Identification in Cultural Heritage Applications:  Analysis of a New Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Setzu%2C+M">Mattia Setzu</a>, 
<a href="/search/cs?searchtype=author&query=Corbara%2C+S">Silvia Corbara</a>, 
<a href="/search/cs?searchtype=author&query=Monreale%2C+A">Anna Monreale</a>, 
<a href="/search/cs?searchtype=author&query=Moreo%2C+A">Alejandro Moreo</a>, 
<a href="/search/cs?searchtype=author&query=Sebastiani%2C+F">Fabrizio Sebastiani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">While a substantial amount of work has recently been devoted to enhance the
performance of computational Authorship Identification (AId) systems, little to
no attention has been paid to endowing AId systems with the ability to explain
the reasons behind their predictions. This lacking substantially hinders the
practical employment of AId methodologies, since the predictions returned by
such systems are hardly useful unless they are supported with suitable
explanations. In this paper, we explore the applicability of existing
general-purpose eXplainable Artificial Intelligence (XAI) techniques to AId,
with a special focus on explanations addressed to scholars working in cultural
heritage. In particular, we assess the relative merits of three different types
of XAI techniques (feature ranking, probing, factuals and counterfactual
selection) on three different AId tasks (authorship attribution, authorship
verification, same-authorship verification) by running experiments on real AId
data. Our analysis shows that, while these techniques make important first
steps towards explainable Authorship Identification, more work remains to be
done in order to provide tools that can be profitably integrated in the
workflows of scholars.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02239" title="Abstract">arXiv:2311.02239</a> [<a href="/pdf/2311.02239" title="Download PDF">pdf</a>, <a href="/ps/2311.02239" title="Download PostScript">ps</a>, <a href="/format/2311.02239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using DUCK-Net for Polyp Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dumitru%2C+R">Razvan-Gabriel Dumitru</a>, 
<a href="/search/cs?searchtype=author&query=Peteleaza%2C+D">Darius Peteleaza</a>, 
<a href="/search/cs?searchtype=author&query=Craciun%2C+C">Catalin Craciun</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sci Rep 13, 9803 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper presents a novel supervised convolutional neural network
architecture, "DUCK-Net", capable of effectively learning and generalizing from
small amounts of medical images to perform accurate segmentation tasks. Our
model utilizes an encoder-decoder structure with a residual downsampling
mechanism and a custom convolutional block to capture and process image
information at multiple resolutions in the encoder segment. We employ data
augmentation techniques to enrich the training set, thus increasing our model's
performance. While our architecture is versatile and applicable to various
segmentation tasks, in this study, we demonstrate its capabilities specifically
for polyp segmentation in colonoscopy images. We evaluate the performance of
our method on several popular benchmark datasets for polyp segmentation,
Kvasir-SEG, CVC-ClinicDB, CVC-ColonDB, and ETIS-LARIBPOLYPDB showing that it
achieves state-of-the-art results in terms of mean Dice coefficient, Jaccard
index, Precision, Recall, and Accuracy. Our approach demonstrates strong
generalization capabilities, achieving excellent performance even with limited
training data. The code is publicly available on GitHub:
https://github.com/RazvanDu/DUCK-Net
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02240" title="Abstract">arXiv:2311.02240</a> [<a href="/pdf/2311.02240" title="Download PDF">pdf</a>, <a href="/format/2311.02240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Machine Unlearning Benchmarks: Forgetting the Personal  Identities in Facial Recognition Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+D">Dasol Choi</a>, 
<a href="/search/cs?searchtype=author&query=Na%2C+D">Dongbin Na</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Machine unlearning is a crucial tool for enabling a classification model to
forget specific data that are used in the training time. Recently, various
studies have presented machine unlearning algorithms and evaluated their
methods on several datasets. However, most of the current machine unlearning
algorithms have been evaluated solely on traditional computer vision datasets
such as CIFAR-10, MNIST, and SVHN. Furthermore, previous studies generally
evaluate the unlearning methods in the class-unlearning setup. Most previous
work first trains the classification models and then evaluates the machine
unlearning performance of machine unlearning algorithms by forgetting selected
image classes (categories) in the experiments. Unfortunately, these
class-unlearning settings might not generalize to real-world scenarios. In this
work, we propose a machine unlearning setting that aims to unlearn specific
instance that contains personal privacy (identity) while maintaining the
original task of a given model. Specifically, we propose two machine unlearning
benchmark datasets, MUFAC and MUCAC, that are greatly useful to evaluate the
performance and robustness of a machine unlearning algorithm. In our benchmark
datasets, the original model performs facial feature recognition tasks: face
age estimation (multi-class classification) and facial attribute classification
(binary class classification), where a class does not depend on any single
target subject (personal identity), which can be a realistic setting. Moreover,
we also report the performance of the state-of-the-art machine unlearning
methods on our proposed benchmark datasets. All the datasets, source codes, and
trained models are publicly available at
https://github.com/ndb796/MachineUnlearning.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02242" title="Abstract">arXiv:2311.02242</a> [<a href="/pdf/2311.02242" title="Download PDF">pdf</a>, <a href="/format/2311.02242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Democratic Policy Development using Collective Dialogues and AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Konya%2C+A">Andrew Konya</a>, 
<a href="/search/cs?searchtype=author&query=Schirch%2C+L">Lisa Schirch</a>, 
<a href="/search/cs?searchtype=author&query=Irwin%2C+C">Colin Irwin</a>, 
<a href="/search/cs?searchtype=author&query=Ovadya%2C+A">Aviv Ovadya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Report produced as part of OpenAI Democratic inputs to AI grant program (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">We design and test an efficient democratic process for developing policies
that reflect informed public will. The process combines AI-enabled collective
dialogues that make deliberation democratically viable at scale with
bridging-based ranking for automated consensus discovery. A GPT4-powered
pipeline translates points of consensus into representative policy clauses from
which an initial policy is assembled. The initial policy is iteratively refined
with the input of experts and the public before a final vote and evaluation. We
test the process three times with the US public, developing policy guidelines
for AI assistants related to medical advice, vaccine information, and wars &amp;
conflicts. We show the process can be run in two weeks with 1500+ participants
for around $10,000, and that it generates policy guidelines with strong public
support across demographic divides. We measure 75-81% support for the policy
guidelines overall, and no less than 70-75% support across demographic splits
spanning age, gender, religion, race, education, and political party. Overall,
this work demonstrates an end-to-end proof of concept for a process we believe
can help AI labs develop common-ground policies, governing bodies break
political gridlock, and diplomats accelerate peace deals.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02243" title="Abstract">arXiv:2311.02243</a> [<a href="/pdf/2311.02243" title="Download PDF">pdf</a>, <a href="/format/2311.02243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equal Opportunity of Coverage in Fair Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fangxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Ruocheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kay Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023 main conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We study fair machine learning (ML) under predictive uncertainty to enable
reliable and trustworthy decision-making. The seminal work of ``equalized
coverage'' proposed an uncertainty-aware fairness notion. However, it does not
guarantee equal coverage rates across more fine-grained groups (e.g.,
low-income females) conditioning on the true label and is biased in the
assessment of uncertainty. To tackle these limitations, we propose a new
uncertainty-aware fairness -- Equal Opportunity of Coverage (EOC) -- that aims
to achieve two properties: (1) coverage rates for different groups with similar
outcomes are close, and (2) the coverage rate for the entire population remains
at a predetermined level. Further, the prediction intervals should be narrow to
be informative. We propose Binned Fair Quantile Regression (BFQR), a
distribution-free post-processing method to improve EOC with reasonable width
for any trained ML models. It first calibrates a hold-out set to bound
deviation from EOC, then leverages conformal prediction to maintain EOC on a
test set, meanwhile optimizing prediction interval width. Experimental results
demonstrate the effectiveness of our method in improving EOC. Our code is
publicly available at https://github.com/fangxin-wang/bfqr .
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02247" title="Abstract">arXiv:2311.02247</a> [<a href="/pdf/2311.02247" title="Download PDF">pdf</a>, <a href="/format/2311.02247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PRISM: Progressive Restoration for Scene Graph-based Image Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jahoda%2C+P">Pavel Jahoda</a>, 
<a href="/search/cs?searchtype=author&query=Farshad%2C+A">Azade Farshad</a>, 
<a href="/search/cs?searchtype=author&query=Yeganeh%2C+Y">Yousef Yeganeh</a>, 
<a href="/search/cs?searchtype=author&query=Adeli%2C+E">Ehsan Adeli</a>, 
<a href="/search/cs?searchtype=author&query=Navab%2C+N">Nassir Navab</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Scene graphs have emerged as accurate descriptive priors for image generation
and manipulation tasks, however, their complexity and diversity of the shapes
and relations of objects in data make it challenging to incorporate them into
the models and generate high-quality results. To address these challenges, we
propose PRISM, a novel progressive multi-head image manipulation approach to
improve the accuracy and quality of the manipulated regions in the scene. Our
image manipulation framework is trained using an end-to-end denoising masked
reconstruction proxy task, where the masked regions are progressively unmasked
from the outer regions to the inner part. We take advantage of the outer part
of the masked area as they have a direct correlation with the context of the
scene. Moreover, our multi-head architecture simultaneously generates detailed
object-specific regions in addition to the entire image to produce
higher-quality images. Our model outperforms the state-of-the-art methods in
the semantic image manipulation task on the CLEVR and Visual Genome datasets.
Our results demonstrate the potential of our approach for enhancing the quality
and precision of scene graph-based image manipulation.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02248" title="Abstract">arXiv:2311.02248</a> [<a href="/pdf/2311.02248" title="Download PDF">pdf</a>, <a href="/format/2311.02248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COSMIC: Data Efficient Instruction-tuning For Speech In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jing Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gaur%2C+Y">Yashesh Gaur</a>, 
<a href="/search/cs?searchtype=author&query=Sivasankaran%2C+S">Sunit Sivasankaran</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shujie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinyu Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We present a data and cost efficient way of incorporating the speech modality
into a large language model (LLM). The resulting multi-modal LLM is a
COntextual Speech Model with Instruction-following/in-context-learning
Capabilities - COSMIC. Speech comprehension test question-answer (SQA) pairs
are generated using GPT-3.5 based on the speech transcriptions as a part of the
supervision for the instruction tuning. With fewer than 20M trainable
parameters and as little as 450 hours of English speech data for SQA
generation, COSMIC exhibits emergent instruction-following and in-context
learning capabilities in speech-to-text tasks. The model is able to follow the
given text instructions to generate text response even on the unseen EN$\to$X
speech-to-text translation (S2TT) task with zero-shot setting. We evaluate the
model's in-context learning via various tasks such as EN$\to$X S2TT and
few-shot domain adaptation. And instruction-following capabilities are
evaluated through a contextual biasing benchmark. Our results demonstrate the
efficacy of the proposed low cost recipe for building a speech LLM and that
with the new instruction-tuning data.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02249" title="Abstract">arXiv:2311.02249</a> [<a href="/pdf/2311.02249" title="Download PDF">pdf</a>, <a href="/format/2311.02249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monitoring Inactivity of Single Older Adults at Home
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Longfei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fisher%2C+R+B">Robert B. Fisher</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 11 figures, paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">A new application for real-time monitoring of the lack of movement in older
adults' own homes is proposed, aiming to support people's lives and
independence in their later years. A lightweight camera monitoring system,
based on an RGB-D camera and a compact computer processor, was developed and
piloted in community homes to observe the daily behavior of older adults.
Instances of body inactivity were detected in everyday scenarios anonymously
and unobtrusively. These events can be explained at a higher level, such as a
loss of consciousness or physiological deterioration. The accuracy of the
inactivity monitoring system is assessed, and statistics of inactivity events
related to the daily behavior of the older adults are provided. The results
demonstrate that our method performs accurately in inactivity detection across
various environments, including low room lighting, TV flickering, and different
camera views.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02251" title="Abstract">arXiv:2311.02251</a> [<a href="/pdf/2311.02251" title="Download PDF">pdf</a>, <a href="/ps/2311.02251" title="Download PostScript">ps</a>, <a href="/format/2311.02251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Potential of Wearable Sensors for Assessing Patient Acuity in  Intensive Care Unit (ICU)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sena%2C+J">Jessica Sena</a>, 
<a href="/search/cs?searchtype=author&query=Mostafiz%2C+M+T">Mohammad Tahsin Mostafiz</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Davidson%2C+A">Andrea Davidson</a>, 
<a href="/search/cs?searchtype=author&query=Bandyopadhyay%2C+S">Sabyasachi Bandyopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Yuanfang%2C+R">Ren Yuanfang</a>, 
<a href="/search/cs?searchtype=author&query=Ozrazgat-Baslanti%2C+T">Tezcan Ozrazgat-Baslanti</a>, 
<a href="/search/cs?searchtype=author&query=Shickel%2C+B">Benjamin Shickel</a>, 
<a href="/search/cs?searchtype=author&query=Loftus%2C+T">Tyler Loftus</a>, 
<a href="/search/cs?searchtype=author&query=Schwartz%2C+W+R">William Robson Schwartz</a>, 
<a href="/search/cs?searchtype=author&query=Bihorac%2C+A">Azra Bihorac</a>, 
<a href="/search/cs?searchtype=author&query=Rashidi%2C+P">Parisa Rashidi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Acuity assessments are vital in critical care settings to provide timely
interventions and fair resource allocation. Traditional acuity scores rely on
manual assessments and documentation of physiological states, which can be
time-consuming, intermittent, and difficult to use for healthcare providers.
Furthermore, such scores do not incorporate granular information such as
patients' mobility level, which can indicate recovery or deterioration in the
ICU. We hypothesized that existing acuity scores could be potentially improved
by employing Artificial Intelligence (AI) techniques in conjunction with
Electronic Health Records (EHR) and wearable sensor data. In this study, we
evaluated the impact of integrating mobility data collected from wrist-worn
accelerometers with clinical data obtained from EHR for developing an AI-driven
acuity assessment score. Accelerometry data were collected from 86 patients
wearing accelerometers on their wrists in an academic hospital setting. The
data was analyzed using five deep neural network models: VGG, ResNet,
MobileNet, SqueezeNet, and a custom Transformer network. These models
outperformed a rule-based clinical score (SOFA= Sequential Organ Failure
Assessment) used as a baseline, particularly regarding the precision,
sensitivity, and F1 score. The results showed that while a model relying solely
on accelerometer data achieved limited performance (AUC 0.50, Precision 0.61,
and F1-score 0.68), including demographic information with the accelerometer
data led to a notable enhancement in performance (AUC 0.69, Precision 0.75, and
F1-score 0.67). This work shows that the combination of mobility and patient
information can successfully differentiate between stable and unstable states
in critically ill patients.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02253" title="Abstract">arXiv:2311.02253</a> [<a href="/pdf/2311.02253" title="Download PDF">pdf</a>, <a href="/format/2311.02253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wilf%2C+A">Alex Wilf</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+A+T">Alex Tianyi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P+P">Paul Pu Liang</a>, 
<a href="/search/cs?searchtype=author&query=Obolenskiy%2C+A">Alexander Obolenskiy</a>, 
<a href="/search/cs?searchtype=author&query=Fried%2C+D">Daniel Fried</a>, 
<a href="/search/cs?searchtype=author&query=Morency%2C+L">Louis-Philippe Morency</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2310.13011">arXiv:2310.13011</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the era of large scale pretrained models, Knowledge Distillation (KD)
serves an important role in transferring the wisdom of computationally heavy
teacher models to lightweight, efficient student models while preserving
performance. Traditional KD paradigms, however, assume readily available access
to teacher models for frequent inference -- a notion increasingly at odds with
the realities of costly, often proprietary, large scale models. Addressing this
gap, our paper considers how to minimize the dependency on teacher model
inferences in KD in a setting we term Few Teacher Inference Knowledge
Distillation (FTI KD). We observe that prevalent KD techniques and state of the
art data augmentation strategies fall short in this constrained setting.
Drawing inspiration from educational principles that emphasize learning through
comparison, we propose Comparative Knowledge Distillation (CKD), which
encourages student models to understand the nuanced differences in a teacher
model's interpretations of samples. Critically, CKD provides additional
learning signals to the student without making additional teacher calls. We
also extend the principle of CKD to groups of samples, enabling even more
efficient learning from limited teacher calls. Empirical evaluation across
varied experimental settings indicates that CKD consistently outperforms state
of the art data augmentation and KD techniques.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02256" title="Abstract">arXiv:2311.02256</a> [<a href="/pdf/2311.02256" title="Download PDF">pdf</a>, <a href="/ps/2311.02256" title="Download PostScript">ps</a>, <a href="/format/2311.02256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Recognition of Oil Leakage Area Based on Logical Semantic  Discrimination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weiying Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Che Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhen Wei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sizhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xun Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Implementing precise detection of oil leaks in peak load equipment through
image analysis can significantly enhance inspection quality and ensure the
system's safety and reliability. However, challenges such as varying shapes of
oil-stained regions, background noise, and fluctuating lighting conditions
complicate the detection process. To address this, the integration of logical
rule-based discrimination into image recognition has been proposed. This
approach involves recognizing the spatial relationships among objects to
semantically segment images of oil spills using a Mask RCNN network. The
process begins with histogram equalization to enhance the original image,
followed by the use of Mask RCNN to identify the preliminary positions and
outlines of oil tanks, the ground, and areas of potential oil contamination.
Subsequent to this identification, the spatial relationships between these
objects are analyzed. Logical rules are then applied to ascertain whether the
suspected areas are indeed oil spills. This method's effectiveness has been
confirmed by testing on images captured from peak power equipment in the field.
The results indicate that this approach can adeptly tackle the challenges in
identifying oil-contaminated areas, showing a substantial improvement in
accuracy compared to existing methods.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02259" title="Abstract">arXiv:2311.02259</a> [<a href="/pdf/2311.02259" title="Download PDF">pdf</a>, <a href="/format/2311.02259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vanquishing volumetric locking in quadratic NURBS-based discretizations  of nearly-incompressible linear elasticity: CAS elements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Casquero%2C+H">Hugo Casquero</a>, 
<a href="/search/cs?searchtype=author&query=Golestanian%2C+M">Mahmoud Golestanian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2311.00101">arXiv:2311.00101</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Quadratic NURBS-based discretizations of the Galerkin method suffer from
volumetric locking when applied to nearly-incompressible linear elasticity.
Volumetric locking causes not only smaller displacements than expected, but
also large-amplitude spurious oscillations of normal stresses.
Continuous-assumed-strain (CAS) elements have been recently introduced to
remove membrane locking in quadratic NURBS-based discretizations of linear
plane curved Kirchhoff rods (Casquero et al., CMAME, 2022). In this work, we
propose two generalizations of CAS elements (named CAS1 and CAS2 elements) to
overcome volumetric locking in quadratic NURBS-based discretizations of
nearly-incompressible linear elasticity. CAS1 elements linearly interpolate the
strains at the knots in each direction for the term in the variational form
involving the first Lam\'e parameter while CAS2 elements linearly interpolate
the dilatational strains at the knots in each direction. For both element
types, a displacement vector with C1 continuity across element boundaries
results in assumed strains with C0 continuity across element boundaries. In
addition, the implementation of the two locking treatments proposed in this
work does not require any additional global or element matrix operations such
as matrix inversions or matrix multiplications. The locking treatments are
applied at the element level and the nonzero pattern of the global stiffness
matrix is preserved. The numerical examples solved in this work show that CAS1
and CAS2 elements, using either two or three Gauss-Legrendre quadrature points
per direction, are effective locking treatments since they not only result in
more accurate displacements for coarse meshes, but also remove the spurious
oscillations of normal stresses.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02262" title="Abstract">arXiv:2311.02262</a> [<a href="/pdf/2311.02262" title="Download PDF">pdf</a>, <a href="/format/2311.02262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingru Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+C">Chandan Singh</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Liyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaodong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianfeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tuo Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In human-written articles, we often leverage the subtleties of text style,
such as bold and italics, to guide the attention of readers. These textual
emphases are vital for the readers to grasp the conveyed information. When
interacting with large language models (LLMs), we have a similar need -
steering the model to pay closer attention to user-specified information, e.g.,
an instruction. Existing methods, however, are constrained to process plain
text and do not support such a mechanism. This motivates us to introduce PASTA
- Post-hoc Attention STeering Approach, a method that allows LLMs to read text
with user-specified emphasis marks. To this end, PASTA identifies a small
subset of attention heads and applies precise attention reweighting on them,
directing the model attention to user-specified parts. Like prompting, PASTA is
applied at inference time and does not require changing any model parameters.
Experiments demonstrate that PASTA can substantially enhance an LLM's ability
to follow user instructions or integrate new knowledge from user inputs,
leading to a significant performance improvement on a variety of tasks, e.g.,
an average accuracy improvement of 22% for LLAMA-7B. Our code is publicly
available at https://github.com/QingruZhang/PASTA .
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02263" title="Abstract">arXiv:2311.02263</a> [<a href="/pdf/2311.02263" title="Download PDF">pdf</a>, <a href="/format/2311.02263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> List Decoding of Tanner and Expander Amplified Codes from Distance  Certificates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeronimo%2C+F+G">Fernando Granha Jeronimo</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+S">Shashank Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Tulsiani%2C+M">Madhur Tulsiani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> FOCS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">We develop new list decoding algorithms for Tanner codes and
distance-amplified codes based on bipartite spectral expanders. We show that
proofs exhibiting lower bounds on the minimum distance of these codes can be
used as certificates discoverable by relaxations in the Sum-of-Squares (SoS)
semidefinite programming hierarchy. Combining these certificates with certain
entropic proxies to ensure that the solutions to the relaxations cover the
entire list, then leads to algorithms for list decoding several families of
codes up to the Johnson bound.
<br />We prove the following:
<br />- We show that the LDPC Tanner codes of Sipser-Spielman [IEEE Trans. Inf.
Theory 1996] and Z\'{e}mor [IEEE Trans. Inf. Theory 2001] with alphabet size
$q$, block-length $n$ and distance $\delta$, based on an expander graph with
degree $d$, can be list-decoded up to distance $\mathcal{J}_q(\delta) -
\epsilon$ in time $n^{O_{d,q}(1/\epsilon^4)}$, where $\mathcal{J}_q(\delta)$
denotes the Johnson bound.
<br />- We show that the codes obtained via the expander-based distance
amplification procedure of Alon, Edmonds and Luby [FOCS 1995] can be
list-decoded close to the Johnson bound using the SoS hierarchy, by reducing
the list decoding problem to unique decoding of the base code. In particular,
starting from \emph{any} base code unique-decodable up to distance $\delta$,
one can obtain near-MDS codes with rate $R$ and distance $1-R - \epsilon$,
list-decodable up to the Johnson bound in time $n^{O_{\epsilon, \delta}(1)}$.
<br />- We show that the locally testable codes of Dinur et al. [STOC 2022] with
alphabet size $q$, block-length $n$ and distance $\delta$ based on a square
Cayley complex with generator sets of size $d$, can be list-decoded up to
distance $\mathcal{J}_q(\delta) - \epsilon$ in time
$n^{O_{d,q}(1/\epsilon^{4})}$, where $\mathcal{J}_q(\delta)$ denotes the
Johnson bound.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02265" title="Abstract">arXiv:2311.02265</a> [<a href="/pdf/2311.02265" title="Download PDF">pdf</a>, <a href="/format/2311.02265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Not all layers are equally as important: Every Layer Counts BERT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Charpentier%2C+L+G+G">Lucas Georges Gabriel Charpentier</a>, 
<a href="/search/cs?searchtype=author&query=Samuel%2C+D">David Samuel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper introduces a novel modification of the transformer architecture,
tailored for the data-efficient pretraining of language models. This aspect is
evaluated by participating in the BabyLM challenge, where our solution won both
the \textsc{strict} and \textsc{strict-small} tracks. Our approach allows each
transformer layer to select which outputs of previous layers to process. The
empirical results verify the potential of this simple modification and show
that not all layers are equally as important.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02268" title="Abstract">arXiv:2311.02268</a> [<a href="/pdf/2311.02268" title="Download PDF">pdf</a>, <a href="/ps/2311.02268" title="Download PostScript">ps</a>, <a href="/format/2311.02268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMs-augmented Contextual Bandit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baheri%2C+A">Ali Baheri</a>, 
<a href="/search/cs?searchtype=author&query=Alm%2C+C+O">Cecilia O. Alm</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the Foundation Models for Decision Making workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Contextual bandits have emerged as a cornerstone in reinforcement learning,
enabling systems to make decisions with partial feedback. However, as contexts
grow in complexity, traditional bandit algorithms can face challenges in
adequately capturing and utilizing such contexts. In this paper, we propose a
novel integration of large language models (LLMs) with the contextual bandit
framework. By leveraging LLMs as an encoder, we enrich the representation of
the context, providing the bandit with a denser and more informative view.
Preliminary results on synthetic datasets demonstrate the potential of this
approach, showing notable improvements in cumulative rewards and reductions in
regret compared to traditional bandit algorithms. This integration not only
showcases the capabilities of LLMs in reinforcement learning but also opens the
door to a new era of contextually-aware decision systems.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02270" title="Abstract">arXiv:2311.02270</a> [<a href="/pdf/2311.02270" title="Download PDF">pdf</a>, <a href="/format/2311.02270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regularized Linear Regression for Binary Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akhtiamov%2C+D">Danil Akhtiamov</a>, 
<a href="/search/cs?searchtype=author&query=Ghane%2C+R">Reza Ghane</a>, 
<a href="/search/cs?searchtype=author&query=Hassibi%2C+B">Babak Hassibi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Regularized linear regression is a promising approach for binary
classification problems in which the training set has noisy labels since the
regularization term can help to avoid interpolating the mislabeled data points.
In this paper we provide a systematic study of the effects of the
regularization strength on the performance of linear classifiers that are
trained to solve binary classification problems by minimizing a regularized
least-squares objective. We consider the over-parametrized regime and assume
that the classes are generated from a Gaussian Mixture Model (GMM) where a
fraction $c&lt;\frac{1}{2}$ of the training data is mislabeled. Under these
assumptions, we rigorously analyze the classification errors resulting from the
application of ridge, $\ell_1$, and $\ell_\infty$ regression. In particular, we
demonstrate that ridge regression invariably improves the classification error.
We prove that $\ell_1$ regularization induces sparsity and observe that in many
cases one can sparsify the solution by up to two orders of magnitude without
any considerable loss of performance, even though the GMM has no underlying
sparsity structure. For $\ell_\infty$ regularization we show that, for large
enough regularization strength, the optimal weights concentrate around two
values of opposite sign. We observe that in many cases the corresponding
"compression" of each weight to a single bit leads to very little loss in
performance. These latter observations can have significant practical
ramifications.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02271" title="Abstract">arXiv:2311.02271</a> [<a href="/pdf/2311.02271" title="Download PDF">pdf</a>, <a href="/format/2311.02271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FaMeSumm: Investigating and Improving Faithfulness of Medical  Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Nan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yusen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+P">Prasenjit Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main Conference of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Summaries of medical text shall be faithful by being consistent and factual
with source inputs, which is an important but understudied topic for safety and
efficiency in healthcare. In this paper, we investigate and improve
faithfulness in summarization on a broad range of medical summarization tasks.
Our investigation reveals that current summarization models often produce
unfaithful outputs for medical input text. We then introduce FAMESUMM, a
framework to improve faithfulness by fine-tuning pre-trained language models
based on medical knowledge. FAMESUMM performs contrastive learning on designed
sets of faithful and unfaithful summaries, and it incorporates medical terms
and their contexts to encourage faithful generation of medical terms. We
conduct comprehensive experiments on three datasets in two languages: health
question and radiology report summarization datasets in English, and a
patient-doctor dialogue dataset in Chinese. Results demonstrate that FAMESUMM
is flexible and effective by delivering consistent improvements over mainstream
language models such as BART, T5, mT5, and PEGASUS, yielding state-of-the-art
performances on metrics for faithfulness and general quality. Human evaluation
by doctors also shows that FAMESUMM generates more faithful outputs. Our code
is available at https: //github.com/psunlpgroup/FaMeSumm.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02272" title="Abstract">arXiv:2311.02272</a> [<a href="/pdf/2311.02272" title="Download PDF">pdf</a>, <a href="/format/2311.02272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling Cross-Language Data Integration and Scalable Analytics in  Decentralized Finance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Flynn%2C+C">Conor Flynn</a>, 
<a href="/search/cs?searchtype=author&query=Bennett%2C+K+P">Kristin P. Bennett</a>, 
<a href="/search/cs?searchtype=author&query=Erickson%2C+J+S">John S. Erickson</a>, 
<a href="/search/cs?searchtype=author&query=Green%2C+A">Aaron Green</a>, 
<a href="/search/cs?searchtype=author&query=Seneviratne%2C+O">Oshani Seneviratne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">With the agile development process of most academic and corporate entities,
designing a robust computational back-end system that can support their
ever-changing data needs is a constantly evolving challenge. We propose the
implementation of a data and language-agnostic system design that handles
different data schemes and sources while subsequently providing researchers and
developers a way to connect to it that is supported by a vast majority of
programming languages. To validate the efficacy of a system with this proposed
architecture, we integrate various data sources throughout the decentralized
finance (DeFi) space, specifically from DeFi lending protocols, retrieving tens
of millions of data points to perform analytics through this system. We then
access and process the retrieved data through several different programming
languages (R-Lang, Python, and Java). Finally, we analyze the performance of
the proposed architecture in relation to other high-performance systems and
explore how this system performs under a high computational load.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02274" title="Abstract">arXiv:2311.02274</a> [<a href="/pdf/2311.02274" title="Download PDF">pdf</a>, <a href="/format/2311.02274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Patch-based Selection and Refinement for Early Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kasichainula%2C+K">Kishore Kasichainula</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+Y">Yaoxin Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Baoxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+J">Jae-Sun Seo</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yu Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Early object detection (OD) is a crucial task for the safety of many dynamic
systems. Current OD algorithms have limited success for small objects at a long
distance. To improve the accuracy and efficiency of such a task, we propose a
novel set of algorithms that divide the image into patches, select patches with
objects at various scales, elaborate the details of a small object, and detect
it as early as possible. Our approach is built upon a transformer-based network
and integrates the diffusion model to improve the detection accuracy. As
demonstrated on BDD100K, our algorithms enhance the mAP for small objects from
1.03 to 8.93, and reduce the data volume in computation by more than 77\%. The
source code is available at
\href{https://github.com/destiny301/dpr}{https://github.com/destiny301/dpr}
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02277" title="Abstract">arXiv:2311.02277</a> [<a href="/pdf/2311.02277" title="Download PDF">pdf</a>, <a href="/format/2311.02277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HASHI: Highly Adaptable Seafood Handling Instrument for Manipulation in  Industrial Settings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Allison%2C+A">Austin Allison</a>, 
<a href="/search/cs?searchtype=author&query=Hanson%2C+N">Nathaniel Hanson</a>, 
<a href="/search/cs?searchtype=author&query=Wicke%2C+S">Sebastian Wicke</a>, 
<a href="/search/cs?searchtype=author&query=Pad%C4%B1r%2C+T">Ta&#x15f;k&#x131;n Pad&#x131;r</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The seafood processing industry provides fertile ground for robotics to
impact the future-of-work from multiple perspectives including productivity,
worker safety, and quality of work life. The robotics research challenge is the
realization of flexible and reliable manipulation of soft, deformable,
slippery, spiky and scaly objects. In this paper, we propose a novel robot end
effector, called HASHI, that employs chopstick-like appendages for precise and
dexterous manipulation. This gripper is capable of in-hand manipulation by
rotating its two constituent sticks relative to each other and offers control
of objects in all three axes of rotation by imitating human use of chopsticks.
HASHI delicately positions and orients food through embedded 6-axis
force-torque sensors. We derive and validate the kinematic model for HASHI, as
well as demonstrate grip force and torque readings from the sensorization of
each chopstick. We also evaluate the versatility of HASHI through grasping
trials of a variety of real and simulated food items with varying geometry,
weight, and firmness.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02278" title="Abstract">arXiv:2311.02278</a> [<a href="/pdf/2311.02278" title="Download PDF">pdf</a>, <a href="/format/2311.02278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine learning&#x27;s own Industrial Revolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yuan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Song Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingjing Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Machine learning is expected to enable the next Industrial Revolution.
However, lacking standardized and automated assembly networks, ML faces
significant challenges to meet ever-growing enterprise demands and empower
broad industries. In the Perspective, we argue that ML needs to first complete
its own Industrial Revolution, elaborate on how to best achieve its goals, and
discuss new opportunities to enable rapid translation from ML's innovation
frontier to mass production and utilization.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02279" title="Abstract">arXiv:2311.02279</a> [<a href="/pdf/2311.02279" title="Download PDF">pdf</a>, <a href="/format/2311.02279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithms for Proportional Representation in Parliament in Divisor and  Multiplicative Form
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rojas%2C+R">Raul Rojas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Applications (stat.AP)

</div>
<p class="mathjax">We consider three algorithms for allocating parliamentary seats by
proportional representation. The usual approach to describing such algorithms
is to compute a quota of votes that each party uses to "acquire''
representatives. This kind of description follows a divisor method, since the
number of representatives for a party is equal to the number of votes for that
party, divided by the quota. We show that a simple multiplicative form with
different rounding methods produces algorithms equivalent to the divisor
methods. The multiplicative form is intuitive and easier to understand for a
wider audience.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02282" title="Abstract">arXiv:2311.02282</a> [<a href="/pdf/2311.02282" title="Download PDF">pdf</a>, <a href="/format/2311.02282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Multi-Modal Representation Learning for Spark Plug Fault  Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Modarres%2C+A">Ardavan Modarres</a>, 
<a href="/search/cs?searchtype=author&query=Eivaghi%2C+V+M">Vahid Mohammad-Zadeh Eivaghi</a>, 
<a href="/search/cs?searchtype=author&query=Shoorehdeli%2C+M+A">Mahdi Aliyari Shoorehdeli</a>, 
<a href="/search/cs?searchtype=author&query=Moosavian%2C+A">Ashkan Moosavian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Due to the incapability of one sensory measurement to provide enough
information for condition monitoring of some complex engineered industrial
mechanisms and also for overcoming the misleading noise of a single sensor,
multiple sensors are installed to improve the condition monitoring of some
industrial equipment. Therefore, an efficient data fusion strategy is demanded.
In this research, we presented a Denoising Multi-Modal Autoencoder with a
unique training strategy based on contrastive learning paradigm, both being
utilized for the first time in the machine health monitoring realm. The
presented approach, which leverages the merits of both supervised and
unsupervised learning, not only achieves excellent performance in fusing
multiple modalities (or views) of data into an enriched common representation
but also takes data fusion to the next level wherein one of the views can be
omitted during inference time with very slight performance reduction, or even
without any reduction at all. The presented methodology enables multi-modal
fault diagnosis systems to perform more robustly in case of sensor failure
occurrence, and one can also intentionally omit one of the sensors (the more
expensive one) in order to build a more cost-effective condition monitoring
system without sacrificing performance for practical purposes. The
effectiveness of the presented methodology is examined on a real-world private
multi-modal dataset gathered under non-laboratory conditions from a complex
engineered mechanism, an inline four-stroke spark-ignition engine, aiming for
spark plug fault diagnosis. This dataset, which contains the accelerometer and
acoustic signals as two modalities, has a very slight amount of fault, and
achieving good performance on such a dataset promises that the presented method
can perform well on other equipment as well.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02283" title="Abstract">arXiv:2311.02283</a> [<a href="/pdf/2311.02283" title="Download PDF">pdf</a>, <a href="/format/2311.02283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Objectives Are All You Need: Solving Deceptive Problems Without Explicit  Diversity Maintenance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boldi%2C+R">Ryan Boldi</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Li Ding</a>, 
<a href="/search/cs?searchtype=author&query=Spector%2C+L">Lee Spector</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at the Workshop on Agent Learning in Open-Endedness (ALOE) at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Navigating deceptive domains has often been a challenge in machine learning
due to search algorithms getting stuck at sub-optimal local optima. Many
algorithms have been proposed to navigate these domains by explicitly
maintaining diversity or equivalently promoting exploration, such as Novelty
Search or other so-called Quality Diversity algorithms. In this paper, we
present an approach with promise to solve deceptive domains without explicit
diversity maintenance by optimizing a potentially large set of defined
objectives. These objectives can be extracted directly from the environment by
sub-aggregating the raw performance of individuals in a variety of ways. We use
lexicase selection to optimize for these objectives as it has been shown to
implicitly maintain population diversity. We compare this technique with a
varying number of objectives to a commonly used quality diversity algorithm,
MAP-Elites, on a set of discrete optimization as well as reinforcement learning
domains with varying degrees of deception. We find that decomposing objectives
into many objectives and optimizing them outperforms MAP-Elites on the
deceptive domains that we explore. Furthermore, we find that this technique
results in competitive performance on the diversity-focused metrics of QD-Score
and Coverage, without explicitly optimizing for these things. Our ablation
study shows that this technique is robust to different subaggregation
techniques. However, when it comes to non-deceptive, or ``illumination"
domains, quality diversity techniques generally outperform our objective-based
framework with respect to exploration (but not exploitation), hinting at
potential directions for future work.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02287" title="Abstract">arXiv:2311.02287</a> [<a href="/pdf/2311.02287" title="Download PDF">pdf</a>, <a href="/format/2311.02287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Ground Reaction Force from Inertial Sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+B">Bowen Song</a>, 
<a href="/search/cs?searchtype=author&query=Paolieri%2C+M">Marco Paolieri</a>, 
<a href="/search/cs?searchtype=author&query=Stewart%2C+H+E">Harper E. Stewart</a>, 
<a href="/search/cs?searchtype=author&query=Golubchik%2C+L">Leana Golubchik</a>, 
<a href="/search/cs?searchtype=author&query=McNitt-Gray%2C+J+L">Jill L. McNitt-Gray</a>, 
<a href="/search/cs?searchtype=author&query=Misra%2C+V">Vishal Misra</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+D">Devavrat Shah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The study of ground reaction forces (GRF) is used to characterize the
mechanical loading experienced by individuals in movements such as running,
which is clinically applicable to identify athletes at risk for stress-related
injuries. Our aim in this paper is to determine if data collected with inertial
measurement units (IMUs), that can be worn by athletes during outdoor runs, can
be used to predict GRF with sufficient accuracy to allow the analysis of its
derived biomechanical variables (e.g., contact time and loading rate).
<br />In this paper, we consider lightweight approaches in contrast to
state-of-the-art prediction using LSTM neural networks. Specifically, we
compare use of LSTMs to k-Nearest Neighbors (KNN) regression as well as propose
a novel solution, SVD Embedding Regression (SER), using linear regression
between singular value decomposition embeddings of IMUs data (input) and GRF
data (output). We evaluate the accuracy of these techniques when using training
data collected from different athletes, from the same athlete, or both, and we
explore the use of acceleration and angular velocity data from sensors at
different locations (sacrum and shanks). Our results illustrate that simple
machine learning methods such as SER and KNN can be similarly accurate or more
accurate than LSTM neural networks, with much faster training times and
hyperparameter optimization; in particular, SER and KNN are more accurate when
personal training data are available, and KNN comes with benefit of providing
provenance of prediction. Notably, the use of personal data reduces prediction
errors of all methods for most biomechanical variables.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02288" title="Abstract">arXiv:2311.02288</a> [<a href="/pdf/2311.02288" title="Download PDF">pdf</a>, <a href="/format/2311.02288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OverHear: Headphone based Multi-sensor Keystroke Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wijewickrama%2C+R">Raveen Wijewickrama</a>, 
<a href="/search/cs?searchtype=author&query=Abbasihafshejani%2C+M">Maryam Abbasihafshejani</a>, 
<a href="/search/cs?searchtype=author&query=Maiti%2C+A">Anindya Maiti</a>, 
<a href="/search/cs?searchtype=author&query=Jadliwala%2C+M">Murtuza Jadliwala</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Human-Computer Interaction (cs.HC); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Headphones, traditionally limited to audio playback, have evolved to
integrate sensors like high-definition microphones and accelerometers. While
these advancements enhance user experience, they also introduce potential
eavesdropping vulnerabilities, with keystroke inference being our concern in
this work. To validate this threat, we developed OverHear, a keystroke
inference framework that leverages both acoustic and accelerometer data from
headphones. The accelerometer data, while not sufficiently detailed for
individual keystroke identification, aids in clustering key presses by hand
position. Concurrently, the acoustic data undergoes analysis to extract Mel
Frequency Cepstral Coefficients (MFCC), aiding in distinguishing between
different keystrokes. These features feed into machine learning models for
keystroke prediction, with results further refined via dictionary-based word
prediction methods. In our experimental setup, we tested various keyboard types
under different environmental conditions. We were able to achieve top-5 key
prediction accuracy of around 80% for mechanical keyboards and around 60% for
membrane keyboards with top-100 word prediction accuracies over 70% for all
keyboard types. The results highlight the effectiveness and limitations of our
approach in the context of real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02291" title="Abstract">arXiv:2311.02291</a> [<a href="/pdf/2311.02291" title="Download PDF">pdf</a>, <a href="/format/2311.02291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of the Various Methodologies Towards making Artificial  Intelligence More Explainable
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dasgupta%2C+S">Sopam Dasgupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Machines are being increasingly used in decision-making processes, resulting
in the realization that decisions need explanations. Unfortunately, an
increasing number of these deployed models are of a 'black-box' nature where
the reasoning behind the decisions is unknown. Hence, there is a need for
clarity behind the reasoning of these decisions. As humans, we would want these
decisions to be presented to us in an explainable manner. However, explanations
alone are insufficient. They do not necessarily tell us how to achieve an
outcome but merely tell us what achieves the given outcome. For this reason, my
research focuses on explainability/interpretability and how it extends to
counterfactual thinking.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02294" title="Abstract">arXiv:2311.02294</a> [<a href="/pdf/2311.02294" title="Download PDF">pdf</a>, <a href="/format/2311.02294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMs grasp morality in concept
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pock%2C+M">Mark Pock</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+A">Andre Ye</a>, 
<a href="/search/cs?searchtype=author&query=Moore%2C+J">Jared Moore</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at NeurIPS 2023 Moral Pyschology and Moral Philosophy workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Work in AI ethics and fairness has made much progress in regulating LLMs to
reflect certain values, such as fairness, truth, and diversity. However, it has
taken the problem of how LLMs might 'mean' anything at all for granted. Without
addressing this, it is not clear what imbuing LLMs with such values even means.
In response, we provide a general theory of meaning that extends beyond humans.
We use this theory to explicate the precise nature of LLMs as meaning-agents.
We suggest that the LLM, by virtue of its position as a meaning-agent, already
grasps the constructions of human society (e.g. morality, gender, and race) in
concept. Consequently, under certain ethical frameworks, currently popular
methods for model alignment are limited at best and counterproductive at worst.
Moreover, unaligned models may help us better develop our moral and social
philosophy.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02296" title="Abstract">arXiv:2311.02296</a> [<a href="/pdf/2311.02296" title="Download PDF">pdf</a>, <a href="/ps/2311.02296" title="Download PostScript">ps</a>, <a href="/format/2311.02296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survey of Simulators for Aerial Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dimmig%2C+C+A">Cora A. Dimmig</a>, 
<a href="/search/cs?searchtype=author&query=Silano%2C+G">Giuseppe Silano</a>, 
<a href="/search/cs?searchtype=author&query=McGuire%2C+K">Kimberly McGuire</a>, 
<a href="/search/cs?searchtype=author&query=Gabellieri%2C+C">Chiara Gabellieri</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B6nig%2C+W">Wolfgang H&#xf6;nig</a>, 
<a href="/search/cs?searchtype=author&query=Moore%2C+J">Joseph Moore</a>, 
<a href="/search/cs?searchtype=author&query=Kobilarov%2C+M">Marin Kobilarov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Uncrewed Aerial Vehicle (UAV) research faces challenges with safety,
scalability, costs, and ecological impact when conducting hardware testing.
High-fidelity simulators offer a vital solution by replicating real-world
conditions to enable the development and evaluation of novel perception and
control algorithms. However, the large number of available simulators poses a
significant challenge for researchers to determine which simulator best suits
their specific use-case, based on each simulator's limitations and
customization readiness. This paper analyzes existing UAV simulators and
decision factors for their selection, aiming to enhance the efficiency and
safety of research endeavors.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02300" title="Abstract">arXiv:2311.02300</a> [<a href="/pdf/2311.02300" title="Download PDF">pdf</a>, <a href="/format/2311.02300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Successive Model-Agnostic Meta-Learning for Few-Shot Fault Time Series  Prognosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hai Su</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jiajun Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Songsen Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Meta learning is a promising technique for solving few-shot fault prediction
problems, which have attracted the attention of many researchers in recent
years. Existing meta-learning methods for time series prediction, which
predominantly rely on random and similarity matching-based task partitioning,
face three major limitations: (1) feature exploitation inefficiency; (2)
suboptimal task data allocation; and (3) limited robustness with small samples.
To overcome these limitations, we introduce a novel 'pseudo meta-task'
partitioning scheme that treats a continuous time period of a time series as a
meta-task, composed of multiple successive short time periods. Employing
continuous time series as pseudo meta-tasks allows our method to extract more
comprehensive features and relationships from the data, resulting in more
accurate predictions. Moreover, we introduce a differential algorithm to
enhance the robustness of our method across different datasets. Through
extensive experiments on several fault and time series prediction datasets, we
demonstrate that our approach substantially enhances prediction performance and
generalization capability under both few-shot and general conditions.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02303" title="Abstract">arXiv:2311.02303</a> [<a href="/pdf/2311.02303" title="Download PDF">pdf</a>, <a href="/format/2311.02303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MFTCoder: Boosting Code LLMs with Multitask Fine-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bingchang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaoyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+C">Cong Liao</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Z">Zi Gong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Z">Zhichao Lei</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+M">Ming Liang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dajun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+M">Min Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hailian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianguo Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Code LLMs have emerged as a specialized research field, with remarkable
studies dedicated to enhancing model's coding capabilities through fine-tuning
on pre-trained models. Previous fine-tuning approaches were typically tailored
to specific downstream tasks or scenarios, which meant separate fine-tuning for
each task, requiring extensive training resources and posing challenges in
terms of deployment and maintenance. Furthermore, these approaches failed to
leverage the inherent interconnectedness among different code-related tasks. To
overcome these limitations, we present a multi-task fine-tuning framework,
MFTcoder, that enables simultaneous and parallel fine-tuning on multiple tasks.
By incorporating various loss functions, we effectively address common
challenges in multi-task learning, such as data imbalance, varying difficulty
levels, and inconsistent convergence speeds. Extensive experiments have
conclusively demonstrated that our multi-task fine-tuning approach outperforms
both individual fine-tuning on single tasks and fine-tuning on a mixed ensemble
of tasks. Moreover, MFTcoder offers efficient training capabilities, including
efficient data tokenization modes and PEFT fine-tuning, resulting in
significantly improved speed compared to traditional fine-tuning methods.
MFTcoder seamlessly integrates with several mainstream open-source LLMs, such
as CodeLLama and Qwen. Leveraging the CodeLLama foundation, our MFTcoder
fine-tuned model, \textsc{CodeFuse-CodeLLama-34B}, achieves an impressive
pass@1 score of 74.4\% on the HumaneEval benchmark, surpassing GPT-4
performance (67\%, zero-shot). MFTCoder is open-sourced at
\url{https://github.com/codefuse-ai/MFTCOder}
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02304" title="Abstract">arXiv:2311.02304</a> [<a href="/pdf/2311.02304" title="Download PDF">pdf</a>, <a href="/format/2311.02304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imitating and Finetuning Model Predictive Control for Robust and  Symmetric Quadrupedal Locomotion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Youm%2C+D">Donghoon Youm</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+H">Hyunyoung Jung</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyeongjun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hwangbo%2C+J">Jemin Hwangbo</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Hae-Won Park</a>, 
<a href="/search/cs?searchtype=author&query=Ha%2C+S">Sehoon Ha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Control of legged robots is a challenging problem that has been investigated
by different approaches, such as model-based control and learning algorithms.
This work proposes a novel Imitating and Finetuning Model Predictive Control
(IFM) framework to take the strengths of both approaches. Our framework first
develops a conventional model predictive controller (MPC) using Differential
Dynamic Programming and Raibert heuristic, which serves as an expert policy.
Then we train a clone of the MPC using imitation learning to make the
controller learnable. Finally, we leverage deep reinforcement learning with
limited exploration for further finetuning the policy on more challenging
terrains. By conducting comprehensive simulation and hardware experiments, we
demonstrate that the proposed IFM framework can significantly improve the
performance of the given MPC controller on rough, slippery, and conveyor
terrains that require careful coordination of footsteps. We also showcase that
IFM can efficiently produce more symmetric, periodic, and energy-efficient
gaits compared to Vanilla RL with a minimal burden of reward shaping.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02305" title="Abstract">arXiv:2311.02305</a> [<a href="/pdf/2311.02305" title="Download PDF">pdf</a>, <a href="/format/2311.02305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OSM vs HD Maps: Map Representations for Trajectory Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+J">Jing-Yan Liao</a>, 
<a href="/search/cs?searchtype=author&query=Doshi%2C+P">Parth Doshi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zihan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Paz%2C+D">David Paz</a>, 
<a href="/search/cs?searchtype=author&query=Christensen%2C+H">Henrik Christensen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">While High Definition (HD) Maps have long been favored for their precise
depictions of static road elements, their accessibility constraints and
susceptibility to rapid environmental changes impede the widespread deployment
of autonomous driving, especially in the motion forecasting task. In this
context, we propose to leverage OpenStreetMap (OSM) as a promising alternative
to HD Maps for long-term motion forecasting. The contributions of this work are
threefold: firstly, we extend the application of OSM to long-horizon
forecasting, doubling the forecasting horizon compared to previous studies.
Secondly, through an expanded receptive field and the integration of
intersection priors, our OSM-based approach exhibits competitive performance,
narrowing the gap with HD Map-based models. Lastly, we conduct an exhaustive
context-aware analysis, providing deeper insights in motion forecasting across
diverse scenarios as well as conducting class-aware comparisons. This research
not only advances long-term motion forecasting with coarse map representations
but additionally offers a potential scalable solution within the domain of
autonomous driving.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02310" title="Abstract">arXiv:2311.02310</a> [<a href="/pdf/2311.02310" title="Download PDF">pdf</a>, <a href="/format/2311.02310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Narrowing the Gap between Zero- and Few-shot Machine Translation by  Matching Styles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+W">Weiting Tan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haoran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Lingfeng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S+S">Shuyue Stella Li</a>, 
<a href="/search/cs?searchtype=author&query=Murray%2C+K">Kenton Murray</a>, 
<a href="/search/cs?searchtype=author&query=Koehn%2C+P">Philipp Koehn</a>, 
<a href="/search/cs?searchtype=author&query=Van+Durme%2C+B">Benjamin Van Durme</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yunmo Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models trained primarily in a monolingual setting have
demonstrated their ability to generalize to machine translation using zero- and
few-shot examples with in-context learning. However, even though zero-shot
translations are relatively good, there remains a discernible gap comparing
their performance with the few-shot setting. In this paper, we investigate the
factors contributing to this gap and find that this gap can largely be closed
(for about 70%) by matching the writing styles of the target corpus.
Additionally, we explore potential approaches to enhance zero-shot baselines
without the need for parallel demonstration examples, providing valuable
insights into how these methods contribute to improving translation metrics.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02311" title="Abstract">arXiv:2311.02311</a> [<a href="/pdf/2311.02311" title="Download PDF">pdf</a>, <a href="/format/2311.02311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Brief Survey of Open Radio Access Network (O-RAN) Security
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yi-Zih Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T+Y">Terrance Yu-Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+P">Po-Jung Su</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chi-Ting Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Open Radio Access Network (O-RAN), a novel architecture that separates the
traditional radio access network (RAN) into multiple disaggregated components,
leads a revolution in the telecommunication ecosystems. Compared to the
traditional RAN, the proposed O-RAN paradigm is more flexible and more
cost-effective for the operators, vendors, and the public. The key design
considerations of O-RAN include virtualization and intelligent capabilities in
order to meet the new requirements of 5G. However, because of the open nature
and the newly imported techniques in O-RAN architecture, the assessment of the
security in O-RAN architecture during its early development stage is crucial.
This project aims to present an investigation of the current ORAN architecture
from several attack surfaces, including (1) Architectural openness, (2) Cloud
and Virtualization, (3) Network slicing, and (4) Machine Learning. The existing
attack surfaces and corresponding mitigation methods of these attacks are also
surveyed and provided in this report, serving as a guiding principle and
valuable recommendation for the O-RAN implementers and framework designers.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02313" title="Abstract">arXiv:2311.02313</a> [<a href="/pdf/2311.02313" title="Download PDF">pdf</a>, <a href="/format/2311.02313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LISNeRF Mapping: LiDAR-based Implicit Mapping via Semantic Neural Fields  for Large-Scale 3D Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhiliu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large-scale semantic mapping is crucial for outdoor autonomous agents to
fulfill high-level tasks such as planning and navigation. This paper proposes a
novel method for large-scale 3D semantic reconstruction through implicit
representations from LiDAR measurements alone. We firstly leverages an
octree-based and hierarchical structure to store implicit features, then these
implicit features are decoded to semantic information and signed distance value
through shallow Multilayer Perceptrons (MLPs). We adopt off-the-shelf
algorithms to predict the semantic labels and instance IDs of point cloud. Then
we jointly optimize the implicit features and MLPs parameters with
self-supervision paradigm for point cloud geometry and pseudo-supervision
pradigm for semantic and panoptic labels. Subsequently, Marching Cubes
algorithm is exploited to subdivide and visualize the scenes in the inferring
stage. For scenarios with memory constraints, a map stitching strategy is also
developed to merge sub-maps into a complete map. As far as we know, our method
is the first work to reconstruct semantic implicit scenes from LiDAR-only
input. Experiments on three real-world datasets, SemanticKITTI, SemanticPOSS
and nuScenes, demonstrate the effectiveness and efficiency of our framework
compared to current state-of-the-art 3D mapping methods.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02314" title="Abstract">arXiv:2311.02314</a> [<a href="/pdf/2311.02314" title="Download PDF">pdf</a>, <a href="/format/2311.02314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Thermal Face Image Classification using Deep Learning Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+P">Prosenjit Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Zaman%2C+A">ANK Zaman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages. Link of the Conference: <a href="https://american-cse.org/index.html/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Thermal images have various applications in security, medical and industrial
domains. This paper proposes a practical deep-learning approach for thermal
image classification. Accurate and efficient classification of thermal images
poses a significant challenge across various fields due to the complex image
content and the scarcity of annotated datasets. This work uses a convolutional
neural network (CNN) architecture, specifically ResNet-50 and VGGNet-19, to
extract features from thermal images. This work also applied Kalman filter on
thermal input images for image denoising. The experimental results demonstrate
the effectiveness of the proposed approach in terms of accuracy and efficiency.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02315" title="Abstract">arXiv:2311.02315</a> [<a href="/pdf/2311.02315" title="Download PDF">pdf</a>, <a href="/format/2311.02315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counting Manatee Aggregations using Deep Neural Networks and Anisotropic  Gaussian Kernel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+Y">Yiran Pang</a>, 
<a href="/search/cs?searchtype=author&query=Ulus%2C+C">Cihan Ulus</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xingquan Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 8 figures, 2 tables, 3 algorithms, and it has been accepted for publication in Scientific Reports
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Manatees are aquatic mammals with voracious appetites. They rely on sea grass
as the main food source, and often spend up to eight hours a day grazing. They
move slow and frequently stay in group (i.e. aggregations) in shallow water to
search for food, making them vulnerable to environment change and other risks.
Accurate counting manatee aggregations within a region is not only biologically
meaningful in observing their habit, but also crucial for designing safety
rules for human boaters, divers, etc., as well as scheduling nursing,
intervention, and other plans. In this paper, we propose a deep learning based
crowd counting approach to automatically count number of manatees within a
region, by using low quality images as input. Because manatees have unique
shape and they often stay in shallow water in groups, water surface reflection,
occlusion, camouflage etc. making it difficult to accurately count manatee
numbers. To address the challenges, we propose to use Anisotropic Gaussian
Kernel (AGK), with tunable rotation and variances, to ensure that density
functions can maximally capture shapes of individual manatees in different
aggregations. After that, we apply AGK kernel to different types of deep neural
networks primarily designed for crowd counting, including VGG, SANet, Congested
Scene Recognition network (CSRNet), MARUNet etc. to learn manatee densities and
calculate number of manatees in the scene. By using generic low quality images
extracted from surveillance videos, our experiment results and comparison show
that AGK kernel based manatee counting achieves minimum Mean Absolute Error
(MAE) and Root Mean Square Error (RMSE). The proposed method works particularly
well for counting manatee aggregations in environments with complex background.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02316" title="Abstract">arXiv:2311.02316</a> [<a href="/pdf/2311.02316" title="Download PDF">pdf</a>, <a href="/format/2311.02316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Learning of Representations for Space Generates  Multi-Modular Grid Cells
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schaeffer%2C+R">Rylan Schaeffer</a>, 
<a href="/search/cs?searchtype=author&query=Khona%2C+M">Mikail Khona</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Tzuhsuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Eyzaguirre%2C+C">Crist&#xf3;bal Eyzaguirre</a>, 
<a href="/search/cs?searchtype=author&query=Koyejo%2C+S">Sanmi Koyejo</a>, 
<a href="/search/cs?searchtype=author&query=Fiete%2C+I+R">Ila Rani Fiete</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">To solve the spatial problems of mapping, localization and navigation, the
mammalian lineage has developed striking spatial representations. One important
spatial representation is the Nobel-prize winning grid cells: neurons that
represent self-location, a local and aperiodic quantity, with seemingly bizarre
non-local and spatially periodic activity patterns of a few discrete periods.
Why has the mammalian lineage learnt this peculiar grid representation?
Mathematical analysis suggests that this multi-periodic representation has
excellent properties as an algebraic code with high capacity and intrinsic
error-correction, but to date, there is no satisfactory synthesis of core
principles that lead to multi-modular grid cells in deep recurrent neural
networks. In this work, we begin by identifying key insights from four families
of approaches to answering the grid cell question: coding theory, dynamical
systems, function optimization and supervised deep learning. We then leverage
our insights to propose a new approach that combines the strengths of all four
approaches. Our approach is a self-supervised learning (SSL) framework -
including data, data augmentations, loss functions and a network architecture -
motivated from a normative perspective, without access to supervised position
information or engineering of particular readout representations as needed in
previous approaches. We show that multiple grid cell modules can emerge in
networks trained on our SSL framework and that the networks and emergent
representations generalize well outside their training distribution. This work
contains insights for neuroscientists interested in the origins of grid cells
as well as machine learning researchers interested in novel SSL frameworks.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02317" title="Abstract">arXiv:2311.02317</a> [<a href="/pdf/2311.02317" title="Download PDF">pdf</a>, <a href="/ps/2311.02317" title="Download PostScript">ps</a>, <a href="/format/2311.02317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Machine Learning Classifier Approaches, and their Accuracy  for the Detection of Cyberattacks on 5G IoT Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rosic%2C+A">Adem Rosic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">As 5G continues to expand its coverage and use. Innovative ideas/technologies
continue to be implemented within. New vulnerabilities appear, thus resulting
in new methods of mitigation and detection to occur. With the architecture that
5G can implement, DDoS (Distributed Denial of Service) is at a higher risk.
There are many methods and approaches to help combat this challenge, most of
which are implemented in networks containing Wi-Fi (Wireless Fidelity). This
article aims to discuss the possible approaches that could be included in 5G
technology. The method we will discuss involves Machine Learning. We have used
three classifiers to test on datasets (Na\"ive Bayes, UltraBoost, LogitBoost)
with multiple cross-folds, verifying which would have the highest accuracy with
multiple factors (such as the cross-folds, verifying whether the number of
folds affects accuracy), expanding upon [25] by using feature selection to
obtain more accurate results.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02319" title="Abstract">arXiv:2311.02319</a> [<a href="/pdf/2311.02319" title="Download PDF">pdf</a>, <a href="/format/2311.02319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Robustness, Connectivity and Giant Component Size of Random K-out  Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elumar%2C+E+C">Eray Can Elumar</a>, 
<a href="/search/cs?searchtype=author&query=Sood%2C+M">Mansi Sood</a>, 
<a href="/search/cs?searchtype=author&query=Ya%C4%9Fan%2C+O">Osman Ya&#x11f;an</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2103.01471">arXiv:2103.01471</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Random K-out graphs are garnering interest in designing distributed systems
including secure sensor networks, anonymous crypto-currency networks, and
differentially-private decentralized learning. In these security-critical
applications, it is important to model and analyze the resilience of the
network to node failures and adversarial captures. Motivated by this, we
analyze how the connectivity properties of random K-out graphs vary with the
network parameters $K$, the number of nodes ($n$), and the number of nodes that
get failed or compromised ($\gamma_n$). In particular, we study the conditions
for achieving \emph{connectivity} {with high probability} and for the existence
of a \emph{giant component} with formal guarantees on the size of the largest
connected component in terms of the parameters $n,~K$, and $\gamma_n$. Next, we
analyze the property of \emph{$r$-robustness} which is a stronger property than
connectivity and leads to resilient consensus in the presence of malicious
nodes. We derive conditions on $K$ and $n$ under which the random K-out graph
achieves r-robustness with high probability. We also provide extensive
numerical simulations and compare our results on random K-out graphs with known
results on Erd\H{o}s-R\'enyi (ER) graphs.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02321" title="Abstract">arXiv:2311.02321</a> [<a href="/pdf/2311.02321" title="Download PDF">pdf</a>, <a href="/format/2311.02321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying Context-Dependent Translations for Evaluation Set Production
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wicks%2C+R">Rachel Wicks</a>, 
<a href="/search/cs?searchtype=author&query=Post%2C+M">Matt Post</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WMT 2023 Proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">A major impediment to the transition to context-aware machine translation is
the absence of good evaluation metrics and test sets. Sentences that require
context to be translated correctly are rare in test sets, reducing the utility
of standard corpus-level metrics such as COMET or BLEU. On the other hand,
datasets that annotate such sentences are also rare, small in scale, and
available for only a few languages. To address this, we modernize, generalize,
and extend previous annotation pipelines to produce CTXPRO, a tool that
identifies subsets of parallel documents containing sentences that require
context to correctly translate five phenomena: gender, formality, and animacy
for pronouns, verb phrase ellipsis, and ambiguous noun inflections. The input
to the pipeline is a set of hand-crafted, per-language, linguistically-informed
rules that select contextual sentence pairs using coreference, part-of-speech,
and morphological features provided by state-of-the-art tools. We apply this
pipeline to seven languages pairs (EN into and out-of DE, ES, FR, IT, PL, PT,
and RU) and two datasets (OpenSubtitles and WMT test sets), and validate its
performance using both overlap with previous work and its ability to
discriminate a contextual MT system from a sentence-based one. We release the
CTXPRO pipeline and data as open source.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02324" title="Abstract">arXiv:2311.02324</a> [<a href="/pdf/2311.02324" title="Download PDF">pdf</a>, <a href="/format/2311.02324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bounded and Unbiased Composite Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+R">Ruoxi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+P">Pei-Wei Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Hassan%2C+M+U">Muneeb Ul Hassan</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+M">Minhui Xue</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinjun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 45th IEEE Symposium on Security and Privacy (IEEE S&amp;P)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The objective of differential privacy (DP) is to protect privacy by producing
an output distribution that is indistinguishable between any two neighboring
databases. However, traditional differentially private mechanisms tend to
produce unbounded outputs in order to achieve maximum disturbance range, which
is not always in line with real-world applications. Existing solutions attempt
to address this issue by employing post-processing or truncation techniques to
restrict the output results, but at the cost of introducing bias issues. In
this paper, we propose a novel differentially private mechanism which uses a
composite probability density function to generate bounded and unbiased outputs
for any numerical input data. The composition consists of an activation
function and a base function, providing users with the flexibility to define
the functions according to the DP constraints. We also develop an optimization
algorithm that enables the iterative search for the optimal hyper-parameter
setting without the need for repeated experiments, which prevents additional
privacy overhead. Furthermore, we evaluate the utility of the proposed
mechanism by assessing the variance of the composite probability density
function and introducing two alternative metrics that are simpler to compute
than variance estimation. Our extensive evaluation on three benchmark datasets
demonstrates consistent and significant improvement over the traditional
Laplace and Gaussian mechanisms. The proposed bounded and unbiased composite
differentially private mechanism will underpin the broader DP arsenal and
foster future privacy-preserving studies.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02326" title="Abstract">arXiv:2311.02326</a> [<a href="/pdf/2311.02326" title="Download PDF">pdf</a>, <a href="/format/2311.02326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FragXsiteDTI: Revealing Responsible Segments in Drug-Target Interaction  with Transformer-Driven Interpretation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yalabadi%2C+A+K">Ali Khodabandeh Yalabadi</a>, 
<a href="/search/cs?searchtype=author&query=Yazdani-Jahromi%2C+M">Mehdi Yazdani-Jahromi</a>, 
<a href="/search/cs?searchtype=author&query=Yousefi%2C+N">Niloofar Yousefi</a>, 
<a href="/search/cs?searchtype=author&query=Tayebi%2C+A">Aida Tayebi</a>, 
<a href="/search/cs?searchtype=author&query=Abdidizaji%2C+S">Sina Abdidizaji</a>, 
<a href="/search/cs?searchtype=author&query=Garibay%2C+O+O">Ozlem Ozmen Garibay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the NeurIPS workshop (AI4D3) - 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Drug-Target Interaction (DTI) prediction is vital for drug discovery, yet
challenges persist in achieving model interpretability and optimizing
performance. We propose a novel transformer-based model, FragXsiteDTI, that
aims to address these challenges in DTI prediction. Notably, FragXsiteDTI is
the first DTI model to simultaneously leverage drug molecule fragments and
protein pockets. Our information-rich representations for both proteins and
drugs offer a detailed perspective on their interaction. Inspired by the
Perceiver IO framework, our model features a learnable latent array, initially
interacting with protein binding site embeddings using cross-attention and
later refined through self-attention and used as a query to the drug fragments
in the drug's cross-attention transformer block. This learnable query array
serves as a mediator and enables seamless information translation, preserving
critical nuances in drug-protein interactions. Our computational results on
three benchmarking datasets demonstrate the superior predictive power of our
model over several state-of-the-art models. We also show the interpretability
of our model in terms of the critical components of both target proteins and
drug molecules within drug-target pairs.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02327" title="Abstract">arXiv:2311.02327</a> [<a href="/pdf/2311.02327" title="Download PDF">pdf</a>, <a href="/format/2311.02327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ECMD: An Event-Centric Multisensory Driving Dataset for SLAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peiyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+W">Weipeng Guan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Feng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yihan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+W">Weisong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+L">Li-Ta Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+P">Peng Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Databases (cs.DB)

</div>
<p class="mathjax">Leveraging multiple sensors enhances complex environmental perception and
increases resilience to varying luminance conditions and high-speed motion
patterns, achieving precise localization and mapping. This paper proposes,
ECMD, an event-centric multisensory dataset containing 81 sequences and
covering over 200 km of various challenging driving scenarios including
high-speed motion, repetitive scenarios, dynamic objects, etc. ECMD provides
data from two sets of stereo event cameras with different resolutions (640*480,
346*260), stereo industrial cameras, an infrared camera, a top-installed
mechanical LiDAR with two slanted LiDARs, two consumer-level GNSS receivers,
and an onboard IMU. Meanwhile, the ground-truth of the vehicle was obtained
using a centimeter-level high-accuracy GNSS-RTK/INS navigation system. All
sensors are well-calibrated and temporally synchronized at the hardware level,
with recording data simultaneously. We additionally evaluate several
state-of-the-art SLAM algorithms for benchmarking visual and LiDAR SLAM and
identifying their limitations. The dataset is available at
https://arclab-hku.github.io/ecmd/.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02328" title="Abstract">arXiv:2311.02328</a> [<a href="/pdf/2311.02328" title="Download PDF">pdf</a>, <a href="/format/2311.02328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Operator Learning Framework for Spatiotemporal Super-resolution of  Scientific Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duruisseaux%2C+V">Valentin Duruisseaux</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+A">Amit Chakraborty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In numerous contexts, high-resolution solutions to partial differential
equations are required to capture faithfully essential dynamics which occur at
small spatiotemporal scales, but these solutions can be very difficult and slow
to obtain using traditional methods due to limited computational resources. A
recent direction to circumvent these computational limitations is to use
machine learning techniques for super-resolution, to reconstruct
high-resolution numerical solutions from low-resolution simulations which can
be obtained more efficiently. The proposed approach, the Super Resolution
Operator Network (SROpNet), frames super-resolution as an operator learning
problem and draws inspiration from existing architectures to learn continuous
representations of solutions to parametric differential equations from
low-resolution approximations, which can then be evaluated at any desired
location. In addition, no restrictions are imposed on the locations of (the
fixed number of) spatiotemporal sensors at which the low-resolution
approximations are provided, thereby enabling the consideration of a broader
spectrum of problems arising in practice, for which many existing
super-resolution approaches are not well-suited.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02329" title="Abstract">arXiv:2311.02329</a> [<a href="/pdf/2311.02329" title="Download PDF">pdf</a>, <a href="/format/2311.02329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complex Organ Mask Guided Radiology Report Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tiancheng%2C+G">Gu Tiancheng</a>, 
<a href="/search/cs?searchtype=author&query=Dongnan%2C+L">Liu Dongnan</a>, 
<a href="/search/cs?searchtype=author&query=Zhiyuan%2C+L">Li Zhiyuan</a>, 
<a href="/search/cs?searchtype=author&query=Weidong%2C+C">Cai Weidong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 images. Accepted by WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The goal of automatic report generation is to generate a clinically accurate
and coherent phrase from a single given X-ray image, which could alleviate the
workload of traditional radiology reporting.However, in a real-world scenario,
radiologists frequently face the challenge of producing extensive reports
derived from numerous medical images, thereby medical report generation from
multi-image perspective is needed.In this paper, we propose the Complex Organ
Mask Guided (termed as COMG) report generation model, which incorporates masks
from multiple organs (e.g., bones, lungs, heart, and mediastinum), to provide
more detailed information and guide the model's attention to these crucial body
regions. Specifically, we leverage prior knowledge of the disease corresponding
to each organ in the fusion process to enhance the disease identification phase
during the report generation process. Additionally, cosine similarity loss is
introduced as target function to ensure the convergence of cross-modal
consistency and facilitate model optimization.Experimental results on two
public datasets show that COMG achieves a 11.4% and 9.7% improvement in terms
of BLEU@4 scores over the SOTA model KiUT on IU-Xray and MIMIC, respectively.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02331" title="Abstract">arXiv:2311.02331</a> [<a href="/pdf/2311.02331" title="Download PDF">pdf</a>, <a href="/format/2311.02331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NODLINK: An Online System for Fine-Grained APT Attack Detection and  Investigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shaofei Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+F">Feng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xusheng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+F">Fei Shao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiedong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiangqun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Ding Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The final version of this paper is going to appear in the Conference on Network and Distributed System Security Symposium (NDSS'24), 26 Feb - 1 Mar 2024, San Diego, California
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Advanced Persistent Threats (APT) attacks have plagued modern enterprises,
causing significant financial losses. To counter these attacks, researchers
propose techniques that capture the complex and stealthy scenarios of APT
attacks by using provenance graphs to model system entities and their
dependencies. Particularly, to accelerate attack detection and reduce financial
losses, online provenance-based detection systems that detect and investigate
APT attacks under the constraints of timeliness and limited resources are in
dire need. Unfortunately, existing online systems usually sacrifice detection
granularity to reduce computational complexity and produce provenance graphs
with more than 100,000 nodes, posing challenges for security admins to
interpret the detection results. In this paper, we design and implement
NodLink, the first online detection system that maintains high detection
accuracy without sacrificing detection granularity. Our insight is that the APT
attack detection process in online provenance-based detection systems can be
modeled as a Steiner Tree Problem (STP), which has efficient online
approximation algorithms that recover concise attack-related provenance graphs
with a theoretically bounded error. To utilize STP approximation algorithm
frameworks for APT attack detection, we propose a novel design of in-memory
cache, an efficient attack screening method, and a new STP approximation
algorithm that is more efficient than the conventional one in APT attack
detection while maintaining the same complexity. We evaluate NodLink in a
production environment. The open-world experiment shows that NodLink
outperforms two state-of-the-art (SOTA) online provenance analysis systems by
achieving magnitudes higher detection and investigation accuracy while having
the same or higher throughput.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02332" title="Abstract">arXiv:2311.02332</a> [<a href="/pdf/2311.02332" title="Download PDF">pdf</a>, <a href="/format/2311.02332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Machine Learning for Clinically-Assistive Imaging-Based  Biomedical Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Warner%2C+E">Elisa Warner</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Joonsang Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+W">William Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Syeda-Mahmood%2C+T">Tanveer Syeda-Mahmood</a>, 
<a href="/search/cs?searchtype=author&query=Kahn%2C+C">Charles Kahn</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+A">Arvind Rao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Machine learning (ML) applications in medical artificial intelligence (AI)
systems have shifted from traditional and statistical methods to increasing
application of deep learning models and even more recently generative models.
Recent years have seen a rise in the discovery of widely-available deep
learning architectures that support multimodal data integration, particularly
with images. The incorporation of multiple modalities into these models is a
thriving research topic, presenting its own unique challenges. In this work, we
discuss five challenges to multimodal AI as it pertains to ML (representation,
fusion, alignment, translation, and co-learning) and survey recent approaches
to addressing these challenges in the context of medical image-based clinical
decision support models. We conclude with a discussion of the future of the
field, suggesting directions that should be elucidated further for successful
clinical models and their translation to the clinical setting.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02333" title="Abstract">arXiv:2311.02333</a> [<a href="/pdf/2311.02333" title="Download PDF">pdf</a>, <a href="/format/2311.02333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Natural Language of DNA using Encoder-Decoder  Foundation Models with Byte-level Precision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malusare%2C+A">Aditya Malusare</a>, 
<a href="/search/cs?searchtype=author&query=Kothandaraman%2C+H">Harish Kothandaraman</a>, 
<a href="/search/cs?searchtype=author&query=Tamboli%2C+D">Dipesh Tamboli</a>, 
<a href="/search/cs?searchtype=author&query=Lanman%2C+N+A">Nadia A. Lanman</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+V">Vaneet Aggarwal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Genomics (q-bio.GN)

</div>
<p class="mathjax">This paper presents the Ensemble Nucleotide Byte-level Encoder-Decoder
(ENBED) foundation model, analyzing DNA sequences at byte-level precision with
an encoder-decoder Transformer architecture. ENBED uses a sub-quadratic
implementation of attention to develop an efficient model capable of
sequence-to-sequence transformations, generalizing previous genomic models with
encoder-only or decoder-only architectures. We use Masked Language Modeling to
pre-train the foundation model using reference genome sequences and apply it in
the following downstream tasks: (1) identification of enhancers, promotors and
splice sites, (2) identification of biological function annotations of genomic
sequences, (3) recognition of sequences containing base call mismatches and
insertion/deletion errors, an advantage over tokenization schemes involving
multiple base pairs, which lose the ability to analyze with byte-level
precision, and (4) generating mutations of the Influenza virus using the
encoder-decoder architecture and validating them against real-world
observations. In each of these tasks, we demonstrate significant improvement as
compared to the existing state-of-the-art results.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02337" title="Abstract">arXiv:2311.02337</a> [<a href="/pdf/2311.02337" title="Download PDF">pdf</a>, <a href="/format/2311.02337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STOW: Discrete-Frame Segmentation and Tracking of Unseen Objects for  Warehouse Picking Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Muru Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Grotz%2C+M">Markus Grotz</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+K">Kaichun Mo</a>, 
<a href="/search/cs?searchtype=author&query=Fox%2C+D">Dieter Fox</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CoRL 2023, project page: <a href="https://sites.google.com/view/stow-corl23">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Segmentation and tracking of unseen object instances in discrete frames pose
a significant challenge in dynamic industrial robotic contexts, such as
distribution warehouses. Here, robots must handle object rearrangement,
including shifting, removal, and partial occlusion by new items, and track
these items after substantial temporal gaps. The task is further complicated
when robots encounter objects not learned in their training sets, which
requires the ability to segment and track previously unseen items. Considering
that continuous observation is often inaccessible in such settings, our task
involves working with a discrete set of frames separated by indefinite periods
during which substantial changes to the scene may occur. This task also
translates to domestic robotic applications, such as rearrangement of objects
on a table. To address these demanding challenges, we introduce new synthetic
and real-world datasets that replicate these industrial and household
scenarios. We also propose a novel paradigm for joint segmentation and tracking
in discrete frames along with a transformer module that facilitates efficient
inter-frame communication. The experiments we conduct show that our approach
significantly outperforms recent methods. For additional results and videos,
please visit \href{https://sites.google.com/view/stow-corl23}{website}. Code
and dataset will be released.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02338" title="Abstract">arXiv:2311.02338</a> [<a href="/pdf/2311.02338" title="Download PDF">pdf</a>, <a href="/ps/2311.02338" title="Download PostScript">ps</a>, <a href="/format/2311.02338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Potato Leaf Disease Classification using Deep Learning: A Convolutional  Neural Network Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tambe%2C+U+Y">Utkarsh Yashwant Tambe</a>, 
<a href="/search/cs?searchtype=author&query=Shobanadevi%2C+A">A. Shobanadevi</a>, 
<a href="/search/cs?searchtype=author&query=Shanthini%2C+A">A. Shanthini</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+H">Hsiu-Chun Hsu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the International Conference on Recent Trends in Data Science and its Applications (ICRTDA 2023), 6 pages, 6 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this study, a Convolutional Neural Network (CNN) is used to classify
potato leaf illnesses using Deep Learning. The suggested approach entails
preprocessing the leaf image data, training a CNN model on that data, and
assessing the model's success on a test set. The experimental findings show
that the CNN model, with an overall accuracy of 99.1%, is highly accurate in
identifying two kinds of potato leaf diseases, including Early Blight, Late
Blight, and Healthy. The suggested method may offer a trustworthy and effective
remedy for identifying potato diseases, which is essential for maintaining food
security and minimizing financial losses in agriculture. The model can
accurately recognize the various disease types even when there are severe
infections present. This work highlights the potential of deep learning methods
for categorizing potato diseases, which can help with effective and automated
disease management in potato farming.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02339" title="Abstract">arXiv:2311.02339</a> [<a href="/pdf/2311.02339" title="Download PDF">pdf</a>, <a href="/format/2311.02339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Progress Metrics in DAG-based Consensus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q">Quan Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Henderson%2C+J">James Henderson</a>, 
<a href="/search/cs?searchtype=author&query=Lysenko%2C+E">Egor Lysenko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Lachesis protocol~\cite{lachesis2021} leverages a DAG of events to allow
nodes to reach fast consensus of events. This work introduces DAG progress
metrics to drive the nodes to emit new events more effectively. With these
metrics, nodes can select event timing and can choose previous events as
parents for their own new events. Our results show that our event timing and
parent selection methods can help reaching consensus quicker and thus can
reduce lower time to finality significantly.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02340" title="Abstract">arXiv:2311.02340</a> [<a href="/pdf/2311.02340" title="Download PDF">pdf</a>, <a href="/format/2311.02340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MC-Stereo: Multi-peak Lookup and Cascade Search Range for Stereo  Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+M">Miaojie Feng</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Junda Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+H">Hao Jia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Longliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Gangwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xin Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to 3DV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Stereo matching is a fundamental task in scene comprehension. In recent
years, the method based on iterative optimization has shown promise in stereo
matching. However, the current iteration framework employs a single-peak
lookup, which struggles to handle the multi-peak problem effectively.
Additionally, the fixed search range used during the iteration process limits
the final convergence effects. To address these issues, we present a novel
iterative optimization architecture called MC-Stereo. This architecture
mitigates the multi-peak distribution problem in matching through the
multi-peak lookup strategy, and integrates the coarse-to-fine concept into the
iterative framework via the cascade search range. Furthermore, given that
feature representation learning is crucial for successful learnbased stereo
matching, we introduce a pre-trained network to serve as the feature extractor,
enhancing the front end of the stereo matching pipeline. Based on these
improvements, MC-Stereo ranks first among all publicly available methods on the
KITTI-2012 and KITTI-2015 benchmarks, and also achieves state-of-the-art
performance on ETH3D. The code will be open sourced after the publication of
this paper.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02341" title="Abstract">arXiv:2311.02341</a> [<a href="/pdf/2311.02341" title="Download PDF">pdf</a>, <a href="/ps/2311.02341" title="Download PostScript">ps</a>, <a href="/format/2311.02341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing English Writing Proficiency in China&#x27;s Polytechnic Students An  In-Depth Literature Review on the Application of the Input Hypothesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wei Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Having good English writing skills is extremely important for students in
polytechnic institutions. However, a lot of students in technical schools have
difficulties in reaching high levels of skill. The Input Hypothesis, created by
Stephen Krashen, suggests that people learn languages well when they receive
information that's a little harder than what they already know but still
understandable. This research paper wants to study how the Input Hypothesis can
help polytechnic students improve their English writing skills. The study will
include real-life observations and experiments from the previous research. We
will look at data from polytechnic students who are receiving special writing
instruction to see if the Input Hypothesis actually helps improve their writing
skills. The paper can better inform polytechnic students, faculty members, and
support staff and even members of the larger community about the attributions,
the processes, and the possible outcomes of second language development for
polytechnic students.
<br />Keywords: English writing skills, Polytechnic students, Input hypothesis,
Comprehensible input
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02342" title="Abstract">arXiv:2311.02342</a> [<a href="/pdf/2311.02342" title="Download PDF">pdf</a>, <a href="/format/2311.02342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proposal-Level Unsupervised Domain Adaptation for Open World Unbiased  Detector
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuanyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Z">Zhongqi Yue</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+X">Xian-Sheng Hua</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Open World Object Detection (OWOD) combines open-set object detection with
incremental learning capabilities to handle the challenge of the open and
dynamic visual world. Existing works assume that a foreground predictor trained
on the seen categories can be directly transferred to identify the unseen
categories' locations by selecting the top-k most confident foreground
predictions. However, the assumption is hardly valid in practice. This is
because the predictor is inevitably biased to the known categories, and fails
under the shift in the appearance of the unseen categories. In this work, we
aim to build an unbiased foreground predictor by re-formulating the task under
Unsupervised Domain Adaptation, where the current biased predictor helps form
the domains: the seen object locations and confident background locations as
the source domain, and the rest ambiguous ones as the target domain. Then, we
adopt the simple and effective self-training method to learn a predictor based
on the domain-invariant foreground features, hence achieving unbiased
prediction robust to the shift in appearance between the seen and unseen
categories. Our approach's pipeline can adapt to various detection frameworks
and UDA methods, empirically validated by OWOD evaluation, where we achieve
state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02343" title="Abstract">arXiv:2311.02343</a> [<a href="/pdf/2311.02343" title="Download PDF">pdf</a>, <a href="/format/2311.02343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable Diffusion Reference Only: Image Prompt and Blueprint Jointly  Guided Multi-Condition Diffusion Model for Secondary Painting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ai%2C+H">Hao Ai</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+L">Lu Sheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Stable Diffusion and ControlNet have achieved excellent results in the field
of image generation and synthesis. However, due to the granularity and method
of its control, the efficiency improvement is limited for professional artistic
creations such as comics and animation production whose main work is secondary
painting. In the current workflow, fixing characters and image styles often
need lengthy text prompts, and even requires further training through
TextualInversion, DreamBooth or other methods, which is very complicated and
expensive for painters. Therefore, we present a new method in this paper,
Stable Diffusion Reference Only, a images-to-image self-supervised model that
uses only two types of conditional images for precise control generation to
accelerate secondary painting. The first type of conditional image serves as an
image prompt, supplying the necessary conceptual and color information for
generation. The second type is blueprint image, which controls the visual
structure of the generated image. It is natively embedded into the original
UNet, eliminating the need for ControlNet. We released all the code for the
module and pipeline, and trained a controllable character line art coloring
model at https://github.com/aihao2000/stable-diffusion-reference-only, that
achieved state-of-the-art results in this field. This verifies the
effectiveness of the structure and greatly improves the production efficiency
of animations, comics, and fanworks.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02344" title="Abstract">arXiv:2311.02344</a> [<a href="/pdf/2311.02344" title="Download PDF">pdf</a>, <a href="/format/2311.02344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> You Only Forward Once: Prediction and Rationalization in A Single  Forward Pass
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Han Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+J">Junwen Duan</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Z">Zhe Qu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianxin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 5 figures, and 11 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Unsupervised rationale extraction aims to extract concise and contiguous text
snippets to support model predictions without any annotated rationale. Previous
studies have used a two-phase framework known as the Rationalizing Neural
Prediction (RNP) framework, which follows a generate-then-predict paradigm.
They assumed that the extracted explanation, called rationale, should be
sufficient to predict the golden label. However, the assumption above deviates
from the original definition and is too strict to perform well. Furthermore,
these two-phase models suffer from the interlocking problem and spurious
correlations. To solve the above problems, we propose a novel single-phase
framework called You Only Forward Once (YOFO), derived from a relaxed version
of rationale where rationales aim to support model predictions rather than make
predictions. In our framework, A pre-trained language model like BERT is
deployed to simultaneously perform prediction and rationalization with less
impact from interlocking or spurious correlations. Directly choosing the
important tokens in an unsupervised manner is intractable. Instead of directly
choosing the important tokens, YOFO gradually removes unimportant tokens during
forward propagation. Through experiments on the BeerAdvocate and Hotel Review
datasets, we demonstrate that our model is able to extract rationales and make
predictions more accurately compared to RNP-based models. We observe an
improvement of up to 18.4\% in token-level F1 compared to previous
state-of-the-art methods. We also conducted analyses and experiments to explore
the extracted rationales and token decay strategies. The results show that YOFO
can extract precise and important rationales while removing unimportant tokens
in the middle part of the model.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02345" title="Abstract">arXiv:2311.02345</a> [<a href="/pdf/2311.02345" title="Download PDF">pdf</a>, <a href="/format/2311.02345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perturbation-based Active Learning for Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+F">Fan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Surdeanu%2C+M">Mihai Surdeanu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 2023 Widening Natural Language Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Building a question answering (QA) model with less annotation costs can be
achieved by utilizing active learning (AL) training strategy. It selects the
most informative unlabeled training data to update the model effectively.
Acquisition functions for AL are used to determine how informative each
training example is, such as uncertainty or diversity based sampling. In this
work, we propose a perturbation-based active learning acquisition strategy and
demonstrate it is more effective than existing commonly used strategies.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02346" title="Abstract">arXiv:2311.02346</a> [<a href="/pdf/2311.02346" title="Download PDF">pdf</a>, <a href="/ps/2311.02346" title="Download PostScript">ps</a>, <a href="/format/2311.02346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Dynamic Simulation Framework for Coupled  Neuromusculoskeletal-Exoskeletal Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+W">Wei Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoxu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qining Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+H">Hongbin Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jian Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 50 pages, 11 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The modeling and simulation of coupled neuromusculoskeletal-exoskeletal
systems play a crucial role in human biomechanical analysis, as well as in the
design and control of exoskeletons. However, conventional dynamic simulation
frameworks have limitations due to their reliance on experimental data and
their inability to capture comprehensive biomechanical signals and dynamic
responses. To address these challenges, we introduce an optimization-based
dynamic simulation framework that integrates a complete neuromusculoskeletal
feedback loop, rigid-body dynamics, human-exoskeleton interaction, and
foot-ground contact. Without relying on experimental measurements or empirical
data, our framework employs a stepwise optimization process to determine muscle
reflex parameters, taking into account multidimensional criteria. This allows
the framework to generate a full range of kinematic and biomechanical signals,
including muscle activations, muscle forces, joint torques, etc., which are
typically challenging to measure experimentally. To validate the effectiveness
of the framework, we compare the simulated results with experimental data
obtained from a healthy subject wearing an exoskeleton while walking at
different speeds (0.9, 1.0, and 1.1 m/s) and terrains (flat and uphill). The
results demonstrate that our framework can effectively and accurately capture
the qualitative differences in muscle activity associated with different
functions, as well as the evolutionary patterns of muscle activity and
kinematic signals under varying walking conditions. The simulation framework we
propose has the potential to facilitate gait analysis and performance
evaluation of coupled human-exoskeleton systems, as well as enable efficient
and cost-effective testing of novel exoskeleton designs and control strategies.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02348" title="Abstract">arXiv:2311.02348</a> [<a href="/pdf/2311.02348" title="Download PDF">pdf</a>, <a href="/format/2311.02348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometrically Higher Order Unfitted Space-Time Methods for PDEs on  Moving Domains: Geometry Error Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Heimann%2C+F">Fabian Heimann</a>, 
<a href="/search/math?searchtype=author&query=Lehrenfeld%2C+C">Christoph Lehrenfeld</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In [Heimann, Lehrenfeld, Preu{\ss}, SIAM J. Sci. Comp. 45(2), 2023, B139 -
B165] new geometrically unfitted space-time Finite Element methods for partial
differential equations posed on moving domains of higher order accuracy in
space and time have been introduced. For geometrically higher order accuracy a
parametric mapping on a background space-time tensor-product mesh has been
used. In this paper, we concentrate on the geometrical accuracy of the
approximation and derive error bounds for the distance between the realized and
an ideal mapping in different norms and derive results for the space-time
regularity of the parametric mapping. These results are important for the error
analysis of corresponding unfitted space-time finite element methods.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02349" title="Abstract">arXiv:2311.02349</a> [<a href="/pdf/2311.02349" title="Download PDF">pdf</a>, <a href="/format/2311.02349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample Complexity of Opinion Formation on Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haolin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Rajaraman%2C+R">Rajmohan Rajaraman</a>, 
<a href="/search/cs?searchtype=author&query=Sundaram%2C+R">Ravi Sundaram</a>, 
<a href="/search/cs?searchtype=author&query=Vullikanti%2C+A">Anil Vullikanti</a>, 
<a href="/search/cs?searchtype=author&query=Wasim%2C+O">Omer Wasim</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haifeng Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Consider public health officials aiming to spread awareness about a new
vaccine in a community interconnected by a social network. How can they
distribute information with minimal resources, ensuring community-wide
understanding that aligns with the actual facts? This concern mirrors numerous
real-world situations. In this paper, we initialize the study of sample
complexity in opinion formation to solve this problem. Our model is built on
the recognized opinion formation game, where we regard each agent's opinion as
a data-derived model parameter, not just a real number as in prior studies.
Such an extension offers a wider understanding of opinion formation and ties
closely with federated learning. Through this formulation, we characterize the
sample complexity bounds for any network and also show asymptotically tight
bounds for specific network structures. Intriguingly, we discover optimal
strategies often allocate samples inversely to the degree, hinting at vital
policy implications. Our findings are empirically validated on both synthesized
and real-world networks.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02351" title="Abstract">arXiv:2311.02351</a> [<a href="/pdf/2311.02351" title="Download PDF">pdf</a>, <a href="/format/2311.02351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Software in P2P way: a software model without central software and  enabling any software to join or leave freely
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hong Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The P2P model encompasses a network of equal peers, whether in hardware or
software, operating autonomously without central control, allowing individual
peer failure while ensuring high availability. Nevertheless, current P2P
technologies primarily focus on hardware-level resilience, often referred to as
P2P networks, which do not safeguard against software failures. This paper
introduces a pioneering Peer-to-Peer (P2P) software model aimed at enhancing
software-level high availability. Diverging from prevalent hardware-centric P2P
technologies, this model accentuates the decentralized nature of various
software components, or "software peers," which function independently,
enabling seamless network entry and exit without relying on central software.
The model's collaborative approach cultivates a network topology with multiple
autonomous processing paths, ensuring continuous operation through dynamic task
allocation in a distributed manner. By surpassing the limitations of
traditional redundancy methods, this P2P model provides an adaptive and
scalable solution for achieving robust availability. Validation results
underscore the model's effectiveness in enhancing the probabilities of
successful task processing while ensuring high availability.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02355" title="Abstract">arXiv:2311.02355</a> [<a href="/pdf/2311.02355" title="Download PDF">pdf</a>, <a href="/format/2311.02355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TreeSwap: Data Augmentation for Machine Translation via Dependency  Subtree Swapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nagy%2C+A">Attila Nagy</a>, 
<a href="/search/cs?searchtype=author&query=Lakatos%2C+D">Dorina Lakatos</a>, 
<a href="/search/cs?searchtype=author&query=Barta%2C+B">Botond Barta</a>, 
<a href="/search/cs?searchtype=author&query=%C3%81cs%2C+J">Judit &#xc1;cs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Data augmentation methods for neural machine translation are particularly
useful when limited amount of training data is available, which is often the
case when dealing with low-resource languages. We introduce a novel
augmentation method, which generates new sentences by swapping objects and
subjects across bisentences. This is performed simultaneously based on the
dependency parse trees of the source and target sentences. We name this method
TreeSwap. Our results show that TreeSwap achieves consistent improvements over
baseline models in 4 language pairs in both directions on resource-constrained
datasets. We also explore domain-specific corpora, but find that our method
does not make significant improvements on law, medical and IT data. We report
the scores of similar augmentation methods and find that TreeSwap performs
comparably. We also analyze the generated sentences qualitatively and find that
the augmentation produces a correct translation in most cases. Our code is
available on Github.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02356" title="Abstract">arXiv:2311.02356</a> [<a href="/pdf/2311.02356" title="Download PDF">pdf</a>, <a href="/format/2311.02356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MATA*: Combining Learnable Node Matching with A* Algorithm for  Approximate Graph Edit Distance Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junfeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Min Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shuai Ma</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Lujia Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CIKM23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph Edit Distance (GED) is a general and domain-agnostic metric to measure
graph similarity, widely used in graph search or retrieving tasks. However, the
exact GED computation is known to be NP-complete. For instance, the widely used
A* algorithms explore the entire search space to find the optimal solution
which inevitably suffers scalability issues. Learning-based methods apply graph
representation techniques to learn the GED by formulating a regression task,
which can not recover the edit path and lead to inaccurate GED approximation
(i.e., the predicted GED is smaller than the exact). To this end, in this work,
we present a data-driven hybrid approach MATA* for approximate GED computation
based on Graph Neural Networks (GNNs) and A* algorithms, which models from the
perspective of learning to match nodes instead of directly regressing GED.
Specifically, aware of the structure-dominant operations (i.e.,node and edge
insertion/deletion) property in GED computation, a structure-enhanced GNN is
firstly designed to jointly learn local and high-order structural information
for node embeddings for node matchings. Second, top-k candidate nodes are
produced via a differentiable top-k operation to enable the training for node
matchings, which is adhering to another property of GED, i.e., multiple optimal
node matchings. Third, benefiting from the candidate nodes, MATA* only performs
on the promising search directions, reaching the solution efficiently. Finally,
extensive experiments show the superiority of MATA* as it significantly
outperforms the combinatorial search-based, learning-based and hybrid methods
and scales well to large-size graphs.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02357" title="Abstract">arXiv:2311.02357</a> [<a href="/pdf/2311.02357" title="Download PDF">pdf</a>, <a href="/format/2311.02357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Deep Nonnegative Matrix Factorization for Community  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuecheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jialong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zibin Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Recently, nonnegative matrix factorization (NMF) has been widely adopted for
community detection, because of its better interpretability. However, the
existing NMF-based methods have the following three problems: 1) they directly
transform the original network into community membership space, so it is
difficult for them to capture the hierarchical information; 2) they often only
pay attention to the topology of the network and ignore its node attributes; 3)
it is hard for them to learn the global structure information necessary for
community detection. Therefore, we propose a new community detection algorithm,
named Contrastive Deep Nonnegative Matrix Factorization (CDNMF). Firstly, we
deepen NMF to strengthen its capacity for information extraction. Subsequently,
inspired by contrastive learning, our algorithm creatively constructs network
topology and node attributes as two contrasting views. Furthermore, we utilize
a debiased negative sampling layer and learn node similarity at the community
level, thereby enhancing the suitability of our model for community detection.
We conduct experiments on three public real graph datasets and the proposed
model has achieved better results than state-of-the-art methods. Code available
at https://github.com/6lyc/CDNMF.git.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02362" title="Abstract">arXiv:2311.02362</a> [<a href="/pdf/2311.02362" title="Download PDF">pdf</a>, <a href="/format/2311.02362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoy Effect in Search Interaction: A Pilot Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Nuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiqun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sakai%2C+T">Tetsuya Sakai</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiao-Ming Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In recent years, the influence of cognitive effects and biases on users'
thinking, behaving, and decision-making has garnered increasing attention in
the field of interactive information retrieval. The decoy effect, one of the
main empirically confirmed cognitive biases, refers to the shift in preference
between two choices when a third option (the decoy) which is inferior to one of
the initial choices is introduced. However, it is not clear how the decoy
effect influences user interactions with and evaluations on Search Engine
Result Pages (SERPs). To bridge this gap, our study seeks to understand how the
decoy effect at the document level influences users' interaction behaviors on
SERPs, such as clicks, dwell time, and usefulness perceptions. We conducted
experiments on two publicly available user behavior datasets and the findings
reveal that, compared to cases where no decoy is present, the probability of a
document being clicked could be improved and its usefulness score could be
higher, should there be a decoy associated with the document.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02369" title="Abstract">arXiv:2311.02369</a> [<a href="/pdf/2311.02369" title="Download PDF">pdf</a>, <a href="/format/2311.02369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TACNET: Temporal Audio Source Counting Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmadnejad%2C+A">Amirreza Ahmadnejad</a>, 
<a href="/search/cs?searchtype=author&query=Darviishani%2C+A+M">Ahmad Mahmmodian Darviishani</a>, 
<a href="/search/cs?searchtype=author&query=Asadi%2C+M+M">Mohmmad Mehrdad Asadi</a>, 
<a href="/search/cs?searchtype=author&query=Saffariyeh%2C+S">Sajjad Saffariyeh</a>, 
<a href="/search/cs?searchtype=author&query=Yousef%2C+P">Pedram Yousef</a>, 
<a href="/search/cs?searchtype=author&query=Fatemizadeh%2C+E">Emad Fatemizadeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In this paper, we introduce the Temporal Audio Source Counting Network
(TaCNet), an innovative architecture that addresses limitations in audio source
counting tasks. TaCNet operates directly on raw audio inputs, eliminating
complex preprocessing steps and simplifying the workflow. Notably, it excels in
real-time speaker counting, even with truncated input windows. Our extensive
evaluation, conducted using the LibriCount dataset, underscores TaCNet's
exceptional performance, positioning it as a state-of-the-art solution for
audio source counting tasks. With an average accuracy of 74.18 percentage over
11 classes, TaCNet demonstrates its effectiveness across diverse scenarios,
including applications involving Chinese and Persian languages. This
cross-lingual adaptability highlights its versatility and potential impact.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02373" title="Abstract">arXiv:2311.02373</a> [<a href="/pdf/2311.02373" title="Download PDF">pdf</a>, <a href="/format/2311.02373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Trojan Horses to Castle Walls: Unveiling Bilateral Backdoor Effects  in Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhuoshi Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuguang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Gaowen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+B">Bingquan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H+V">H. Vicky Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Kompella%2C+R+R">Ramana Rao Kompella</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sijia Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">While state-of-the-art diffusion models (DMs) excel in image generation,
concerns regarding their security persist. Earlier research highlighted DMs'
vulnerability to backdoor attacks, but these studies placed stricter
requirements than conventional methods like 'BadNets' in image classification.
This is because the former necessitates modifications to the diffusion sampling
and training procedures. Unlike the prior work, we investigate whether
generating backdoor attacks in DMs can be as simple as BadNets, i.e., by only
contaminating the training dataset without tampering the original diffusion
process. In this more realistic backdoor setting, we uncover bilateral backdoor
effects that not only serve an adversarial purpose (compromising the
functionality of DMs) but also offer a defensive advantage (which can be
leveraged for backdoor defense). Specifically, we find that a BadNets-like
backdoor attack remains effective in DMs for producing incorrect images
(misaligned with the intended text conditions), and thereby yielding incorrect
predictions when DMs are used as classifiers. Meanwhile, backdoored DMs exhibit
an increased ratio of backdoor triggers, a phenomenon we refer to as `trigger
amplification', among the generated images. We show that this latter insight
can be used to enhance the detection of backdoor-poisoned training data. Even
under a low backdoor poisoning ratio, studying the backdoor effects of DMs is
also valuable for designing anti-backdoor image classifiers. Last but not
least, we establish a meaningful linkage between backdoor attacks and the
phenomenon of data replications by exploring DMs' inherent data memorization
tendencies. The codes of our work are available at
https://github.com/OPTML-Group/BiBadDiff.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02376" title="Abstract">arXiv:2311.02376</a> [<a href="/pdf/2311.02376" title="Download PDF">pdf</a>, <a href="/ps/2311.02376" title="Download PostScript">ps</a>, <a href="/format/2311.02376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligent Reflecting Surface-Aided Wireless Communication with Movable  Elements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+G">Guojie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingqing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dognhui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+J">Jiangbo Si</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yunlong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Al-Dhahir%2C+N">Naofal Al-Dhahir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Intelligent reflecting surface (IRS) has been recognized as a powerful
technology for boosting communication performance. To reduce manufacturing and
control costs, it is preferable to consider discrete phase shifts (DPSs) for
IRS, which are set by default as uniformly distributed in the range of $[ -
\pi,\pi )$ in the literature. Such setting, however, cannot achieve a desirable
performance over the general Rician fading where the channel phase concentrates
in a narrow range with a higher probability. Motivated by this drawback, we in
this paper design optimal non-uniform DPSs for IRS to achieve a desirable
performance level. The fundamental challenge is the \textit{possible offset in
phase distribution across different cascaded source-element-destination
channels}, if adopting conventional IRS where the position of each element is
fixed. Such phenomenon leads to different patterns of optimal non-uniform DPSs
for each IRS element and thus causes huge manufacturing costs especially when
the number of IRS elements is large. Driven by the recently emerging fluid
antenna system (or movable antenna technology), we demonstrate that if the
position of each IRS element can be flexibly adjusted, the above phase
distribution offset can be surprisingly eliminated, leading to the same pattern
of DPSs for each IRS element. Armed with this, we then determine the form of
unified non-uniform DPSs based on a low-complexity iterative algorithm.
Simulations show that our proposed design significantly improves the system
performance compared to competitive benchmarks.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02378" title="Abstract">arXiv:2311.02378</a> [<a href="/pdf/2311.02378" title="Download PDF">pdf</a>, <a href="/ps/2311.02378" title="Download PostScript">ps</a>, <a href="/format/2311.02378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MTS-DVGAN: Anomaly Detection in Cyber-Physical Systems using a Dual  Variational Generative Adversarial Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haili Sun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Lansheng Han</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Cai Fu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongle Liu</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+X">Xiang Long</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 14 figures, 8 tables. Accepted by Computers &amp; Security
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computers &amp; Security, 2023, 103570
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">Deep generative models are promising in detecting novel cyber-physical
attacks, mitigating the vulnerability of Cyber-physical systems (CPSs) without
relying on labeled information. Nonetheless, these generative models face
challenges in identifying attack behaviors that closely resemble normal data,
or deviate from the normal data distribution but are in close proximity to the
manifold of the normal cluster in latent space. To tackle this problem, this
article proposes a novel unsupervised dual variational generative adversarial
model named MST-DVGAN, to perform anomaly detection in multivariate time series
data for CPS security. The central concept is to enhance the model's
discriminative capability by widening the distinction between reconstructed
abnormal samples and their normal counterparts. Specifically, we propose an
augmented module by imposing contrastive constraints on the reconstruction
process to obtain a more compact embedding. Then, by exploiting the
distribution property and modeling the normal patterns of multivariate time
series, a variational autoencoder is introduced to force the generative
adversarial network (GAN) to generate diverse samples. Furthermore, two
augmented loss functions are designed to extract essential characteristics in a
self-supervised manner through mutual guidance between the augmented samples
and original samples. Finally, a specific feature center loss is introduced for
the generator network to enhance its stability. Empirical experiments are
conducted on three public datasets, namely SWAT, WADI and NSL_KDD. Comparing
with the state-of-the-art methods, the evaluation results show that the
proposed MTS-DVGAN is more stable and can achieve consistent performance
improvement.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02379" title="Abstract">arXiv:2311.02379</a> [<a href="/pdf/2311.02379" title="Download PDF">pdf</a>, <a href="/format/2311.02379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Reinforcement Learning of Robotic Manipulations via  Feedback from Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+K">Kun Chu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xufeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+C">Cornelius Weber</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengdi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wermter%2C+S">Stefan Wermter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CoRL 2023 Workshop (oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Reinforcement Learning (RL) plays an important role in the robotic
manipulation domain since it allows self-learning from trial-and-error
interactions with the environment. Still, sample efficiency and reward
specification seriously limit its potential. One possible solution involves
learning from expert guidance. However, obtaining a human expert is impractical
due to the high cost of supervising an RL agent, and developing an automatic
supervisor is a challenging endeavor. Large Language Models (LLMs) demonstrate
remarkable abilities to provide human-like feedback on user inputs in natural
language. Nevertheless, they are not designed to directly control low-level
robotic motions, as their pretraining is based on vast internet data rather
than specific robotics data. In this paper, we introduce the Lafite-RL
(Language agent feedback interactive Reinforcement Learning) framework, which
enables RL agents to learn robotic tasks efficiently by taking advantage of
LLMs' timely feedback. Our experiments conducted on RLBench tasks illustrate
that, with simple prompt design in natural language, the Lafite-RL agent
exhibits improved learning capabilities when guided by an LLM. It outperforms
the baseline in terms of both learning efficiency and success rate,
underscoring the efficacy of the rewards provided by an LLM.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02380" title="Abstract">arXiv:2311.02380</a> [<a href="/pdf/2311.02380" title="Download PDF">pdf</a>, <a href="/format/2311.02380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On implicit interpolation models for nonlinear anisotropic magnetic  material behavior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mandlmayr%2C+M">Michael Mandlmayr</a>, 
<a href="/search/math?searchtype=author&query=Egger%2C+H">Herbert Egger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Implicit models for magnetic coenergy have been proposed by Pera et al. to
describe the anisotropic nonlinear material behavior of electrical steel
sheets. This approach aims at predicting magnetic response for any direction of
excitation by interpolating measured of B--H curves in the rolling and
transverse directions. In an analogous manner, an implicit model for magnetic
energy is proposed. We highlight some mathematical properties of these implicit
models and discuss their numerical realization, outline the computation of
magnetic material laws via implicit differentiation, and discuss the potential
use for finite element analysis in the context of nonlinear magnetostatics.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02382" title="Abstract">arXiv:2311.02382</a> [<a href="/pdf/2311.02382" title="Download PDF">pdf</a>, <a href="/format/2311.02382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultra-Long Sequence Distributed Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lyngaas%2C+I">Isaac Lyngaas</a>, 
<a href="/search/cs?searchtype=author&query=Tsaris%2C+A">Aristeidis Tsaris</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dash%2C+S">Sajal Dash</a>, 
<a href="/search/cs?searchtype=author&query=Shekar%2C+M+C">Mayanka Chandra Shekar</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+T">Tao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+H">Hong-Jun Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Wahib%2C+M">Mohamed Wahib</a>, 
<a href="/search/cs?searchtype=author&query=Gouley%2C+J">John Gouley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Transformer models trained on long sequences often achieve higher accuracy
than short sequences. Unfortunately, conventional transformers struggle with
long sequence training due to the overwhelming computation and memory
requirements. Existing methods for long sequence training offer limited speedup
and memory reduction, and may compromise accuracy. This paper presents a novel
and efficient distributed training method, the Long Short-Sequence Transformer
(LSS Transformer), for training transformer with long sequences. It distributes
a long sequence into segments among GPUs, with each GPU computing a partial
self-attention for its segment. Then, it uses a fused communication and a novel
double gradient averaging technique to avoid the need to aggregate partial
self-attention and minimize communication overhead. We evaluated the
performance between LSS Transformer and the state-of-the-art Nvidia sequence
parallelism on a Wikipedia enwik8 dataset. Results show that our proposed
method lead to 5.6x faster and 10.2x more memory-efficient implementation
compared to state-of-the-art sequence parallelism on 144 Nvidia V100 GPUs.
Moreover, our algorithm scales to an extreme sequence length of 50,112 at 3,456
GPUs, achieving 161% super-linear parallel efficiency and a throughput of 32
petaflops.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02384" title="Abstract">arXiv:2311.02384</a> [<a href="/pdf/2311.02384" title="Download PDF">pdf</a>, <a href="/format/2311.02384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Case of Transparent Cache Invalidation in Web Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+Y">Yunhong Ji</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yongluan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Ke Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Application-level caches are widely adopted by web applications to minimize
the response time of user requests as well as to reduce the burden on the
system backend, such as the database servers. In the state of practice,
developers have to take care of the data freshness of application-level caches
manually. Given the growing complexities of today's web applications, it
becomes increasingly challenging for developers to understand, reason about,
and implement cache invalidation methods. Furthermore, according to our survey
of open-source web application projects and engineers, it is indeed challenging
to map database updates with cache entries at the application level. Therefore,
we propose a design to handle data validity in a transparent and precise
manner, without requiring any intervention from developers. Its main idea is to
modify the DBMS to provide necessary information for cache management and
enhance the cache with an invalidation index to identify and invalidate
outdated data automatically and efficiently. Based on the design, we further
provide two specific solutions. Our preliminary experiments indicate that our
solutions could effectively achieve transparent cache invalidation while
maintaining cost-effectiveness.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02389" title="Abstract">arXiv:2311.02389</a> [<a href="/pdf/2311.02389" title="Download PDF">pdf</a>, <a href="/format/2311.02389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiplayer Homicidal Chauffeur Reach-Avoid Games: A Pursuit Enclosure  Function Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yan%2C+R">Rui Yan</a>, 
<a href="/search/eess?searchtype=author&query=Duan%2C+X">Xiaoming Duan</a>, 
<a href="/search/eess?searchtype=author&query=Zou%2C+R">Rui Zou</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+X">Xin He</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+Z">Zongying Shi</a>, 
<a href="/search/eess?searchtype=author&query=Bullo%2C+F">Francesco Bullo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Computer Science and Game Theory (cs.GT); Robotics (cs.RO)

</div>
<p class="mathjax">This paper presents a multiplayer Homicidal Chauffeur reach-avoid
differential game, which involves Dubins-car pursuers and simple-motion
evaders. The goal of the pursuers is to cooperatively protect a planar convex
region from the evaders, who strive to reach the region. We propose a
cooperative strategy for the pursuers based on subgames for multiple pursuers
against one evader and optimal task allocation. We introduce pursuit enclosure
functions (PEFs) and propose a new enclosure region pursuit (ERP) winning
approach that supports forward analysis for the strategy synthesis in the
subgames. We show that if a pursuit coalition is able to defend the region
against an evader under the ERP winning, then no more than two pursuers in the
coalition are necessarily needed. We also propose a steer-to-ERP approach to
certify the ERP winning and synthesize the ERP winning strategy. To implement
the strategy, we introduce a positional PEF and provide the necessary
parameters, states, and strategies that ensure the ERP winning for both one
pursuer and two pursuers against one evader. Additionally, we formulate a
binary integer program using the subgame outcomes to maximize the captured
evaders in the ERP winning for the pursuit task allocation. Finally, we propose
a multiplayer receding-horizon strategy where the ERP winnings are checked in
each horizon, the task is allocated, and the strategies of the pursuers are
determined. Numerical examples are provided to illustrate the results.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02390" title="Abstract">arXiv:2311.02390</a> [<a href="/pdf/2311.02390" title="Download PDF">pdf</a>, <a href="/format/2311.02390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-based Self-healing Solutions Applied to Cellular Networks: An  Overview
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farmani%2C+J">Jaleh Farmani</a>, 
<a href="/search/cs?searchtype=author&query=Zadeh%2C+A+K">Amirreza Khalil Zadeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this article, we provide an overview of machine learning (ML) methods,
both classical and deep variants, that are used to implement self-healing for
cell outages in cellular networks. Self-healing is a promising approach to
network management, which aims to detect and compensate for cell outages in an
autonomous way. This technology aims to decrease the expenses associated with
the installation and maintenance of existing 4G and 5G, i.e. emerging 6G
networks by simplifying operational tasks through its ability to heal itself.
We provide an overview of the basic concepts and taxonomy for SON,
self-healing, and ML techniques, in network management. Moreover, we review the
state-of-the-art in literature for cell outages, with a particular emphasis on
ML-based approaches.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02392" title="Abstract">arXiv:2311.02392</a> [<a href="/pdf/2311.02392" title="Download PDF">pdf</a>, <a href="/format/2311.02392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Level Distillation and Feature Denoising for Cross-Domain Few-Shot  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Runqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianzhuang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kanezaki%2C+A">Asako Kanezaki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The conventional few-shot classification aims at learning a model on a large
labeled base dataset and rapidly adapting to a target dataset that is from the
same distribution as the base dataset. However, in practice, the base and the
target datasets of few-shot classification are usually from different domains,
which is the problem of cross-domain few-shot classification. We tackle this
problem by making a small proportion of unlabeled images in the target domain
accessible in the training stage. In this setup, even though the base data are
sufficient and labeled, the large domain shift still makes transferring the
knowledge from the base dataset difficult. We meticulously design a cross-level
knowledge distillation method, which can strengthen the ability of the model to
extract more discriminative features in the target dataset by guiding the
network's shallow layers to learn higher-level information. Furthermore, in
order to alleviate the overfitting in the evaluation stage, we propose a
feature denoising operation which can reduce the feature redundancy and
mitigate overfitting. Our approach can surpass the previous state-of-the-art
method, Dynamic-Distillation, by 5.44% on 1-shot and 1.37% on 5-shot
classification tasks on average in the BSCD-FSL benchmark. The implementation
code will be available at https://github.com/jarucezh/cldfd.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02393" title="Abstract">arXiv:2311.02393</a> [<a href="/pdf/2311.02393" title="Download PDF">pdf</a>, <a href="/format/2311.02393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Learning of Unsupervised Monocular Depth from Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chawla%2C+H">Hemang Chawla</a>, 
<a href="/search/cs?searchtype=author&query=Varma%2C+A">Arnav Varma</a>, 
<a href="/search/cs?searchtype=author&query=Arani%2C+E">Elahe Arani</a>, 
<a href="/search/cs?searchtype=author&query=Zonooz%2C+B">Bahram Zonooz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Spatial scene understanding, including monocular depth estimation, is an
important problem in various applications, such as robotics and autonomous
driving. While improvements in unsupervised monocular depth estimation have
potentially allowed models to be trained on diverse crowdsourced videos, this
remains underexplored as most methods utilize the standard training protocol,
wherein the models are trained from scratch on all data after new data is
collected. Instead, continual training of models on sequentially collected data
would significantly reduce computational and memory costs. Nevertheless, naive
continual training leads to catastrophic forgetting, where the model
performance deteriorates on older domains as it learns on newer domains,
highlighting the trade-off between model stability and plasticity. While
several techniques have been proposed to address this issue in image
classification, the high-dimensional and spatiotemporally correlated outputs of
depth estimation make it a distinct challenge. To the best of our knowledge, no
framework or method currently exists focusing on the problem of continual
learning in depth estimation. Thus, we introduce a framework that captures the
challenges of continual unsupervised depth estimation (CUDE), and define the
necessary metrics to evaluate model performance. We propose a rehearsal-based
dual-memory method, MonoDepthCL, which utilizes spatiotemporal consistency for
continual learning in depth estimation, even when the camera intrinsics are
unknown.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02394" title="Abstract">arXiv:2311.02394</a> [<a href="/pdf/2311.02394" title="Download PDF">pdf</a>, <a href="/format/2311.02394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuroEvoBench: Benchmarking Evolutionary Optimizers for Deep Learning  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lange%2C+R+T">Robert Tjarko Lange</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yujin Tang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yingtao Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 20 figures, 37th Conference on Neural Information Processing Systems (NeurIPS 2023) Track on Datasets and Benchmarks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently, the Deep Learning community has become interested in evolutionary
optimization (EO) as a means to address hard optimization problems, e.g.
meta-learning through long inner loop unrolls or optimizing non-differentiable
operators. One core reason for this trend has been the recent innovation in
hardware acceleration and compatible software - making distributed population
evaluations much easier than before. Unlike for gradient descent-based methods
though, there is a lack of hyperparameter understanding and best practices for
EO - arguably due to severely less 'graduate student descent' and benchmarking
being performed for EO methods. Additionally, classical benchmarks from the
evolutionary community provide few practical insights for Deep Learning
applications. This poses challenges for newcomers to hardware-accelerated EO
and hinders significant adoption. Hence, we establish a new benchmark of EO
methods (NeuroEvoBench) tailored toward Deep Learning applications and
exhaustively evaluate traditional and meta-learned EO. We investigate core
scientific questions including resource allocation, fitness shaping,
normalization, regularization &amp; scalability of EO. The benchmark is
open-sourced at https://github.com/neuroevobench/neuroevobench under Apache-2.0
license.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02396" title="Abstract">arXiv:2311.02396</a> [<a href="/pdf/2311.02396" title="Download PDF">pdf</a>, <a href="/format/2311.02396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Precise Robotic Needle-Threading with Tactile Perception and  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhenjun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wenqiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+S">Siqiong Yao</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jieji Ren</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+T">Tutian Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yutong Li</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+G">Guoying Gu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This work presents a novel tactile perception-based method, named T-NT, for
performing the needle-threading task, an application of deformable linear
object (DLO) manipulation. This task is divided into two main stages: Tail-end
Finding and Tail-end Insertion. In the first stage, the agent traces the
contour of the thread twice using vision-based tactile sensors mounted on the
gripper fingers. The two-run tracing is to locate the tail-end of the thread.
<br />In the second stage, it employs a tactile-guided reinforcement learning (RL)
model to drive the robot to insert the thread into the target needle eyelet.
The RL model is trained in a Unity-based simulated environment. The simulation
environment supports tactile rendering which can produce realistic tactile
images and thread modeling. During insertion, the position of the poke point
and the center of the eyelet are obtained through a pre-trained segmentation
model, Grounded-SAM, which predicts the masks for both the needle eye and
thread imprints. These positions are then fed into the reinforcement learning
model, aiding in a smoother transition to real-world applications. Extensive
experiments on real robots are conducted to demonstrate the efficacy of our
method. More experiments and videos can be found in the supplementary materials
and on the website: https://sites.google.com/view/tac-needlethreading.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02398" title="Abstract">arXiv:2311.02398</a> [<a href="/pdf/2311.02398" title="Download PDF">pdf</a>, <a href="/format/2311.02398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CDR-Adapter: Learning Adapters to Dig Out More Transferring Ability for  Cross-Domain Recommendation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yanyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+W+K+V">Wai Kin Victor Chan</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Li Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yun Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, 5 tables, Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval Workshop on eCommerce
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Data sparsity and cold-start problems are persistent challenges in
recommendation systems. Cross-domain recommendation (CDR) is a promising
solution that utilizes knowledge from the source domain to improve the
recommendation performance in the target domain. Previous CDR approaches have
mainly followed the Embedding and Mapping (EMCDR) framework, which involves
learning a mapping function to facilitate knowledge transfer. However, these
approaches necessitate re-engineering and re-training the network structure to
incorporate transferrable knowledge, which can be computationally expensive and
may result in catastrophic forgetting of the original knowledge. In this paper,
we present a scalable and efficient paradigm to address data sparsity and
cold-start issues in CDR, named CDR-Adapter, by decoupling the original
recommendation model from the mapping function, without requiring
re-engineering the network structure. Specifically, CDR-Adapter is a novel
plug-and-play module that employs adapter modules to align feature
representations, allowing for flexible knowledge transfer across different
domains and efficient fine-tuning with minimal training costs. We conducted
extensive experiments on the benchmark dataset, which demonstrated the
effectiveness of our approach over several state-of-the-art CDR approaches.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02399" title="Abstract">arXiv:2311.02399</a> [<a href="/pdf/2311.02399" title="Download PDF">pdf</a>, <a href="/ps/2311.02399" title="Download PostScript">ps</a>, <a href="/format/2311.02399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entropy Aware Training for Fast and Accurate Distributed GNN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deshmukh%2C+D">Dhruv Deshmukh</a> (1), 
<a href="/search/cs?searchtype=author&query=Gupta%2C+G+R">Gagan Raj Gupta</a> (1), 
<a href="/search/cs?searchtype=author&query=Chawla%2C+M">Manisha Chawla</a> (1), 
<a href="/search/cs?searchtype=author&query=Jatala%2C+V">Vishwesh Jatala</a> (1), 
<a href="/search/cs?searchtype=author&query=Haldar%2C+A">Anirban Haldar</a> (1) ((1) Department of CSE, IIT Bhilai, India)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures, 5 tables, accepted at ICDM'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Several distributed frameworks have been developed to scale Graph Neural
Networks (GNNs) on billion-size graphs. On several benchmarks, we observe that
the graph partitions generated by these frameworks have heterogeneous data
distributions and class imbalance, affecting convergence, and resulting in
lower performance than centralized implementations. We holistically address
these challenges and develop techniques that reduce training time and improve
accuracy. We develop an Edge-Weighted partitioning technique to improve the
micro average F1 score (accuracy) by minimizing the total entropy. Furthermore,
we add an asynchronous personalization phase that adapts each compute-host's
model to its local data distribution. We design a class-balanced sampler that
considerably speeds up convergence. We implemented our algorithms on the
DistDGL framework and observed that our training techniques scale much better
than the existing training approach. We achieved a (2-3x) speedup in training
time and 4\% improvement on average in micro-F1 scores on 5 large graph
benchmarks compared to the standard baselines.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02400" title="Abstract">arXiv:2311.02400</a> [<a href="/pdf/2311.02400" title="Download PDF">pdf</a>, <a href="/format/2311.02400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Plate to Production: Artificial Intelligence in Modern  Consumer-Driven Food Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Min%2C+W">Weiqing Min</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pengfei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Leyi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Mingyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Ying Jin</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+Y">Yifan Yi</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+M">Min Wen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shuqiang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+R">Ramesh Jain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Global food systems confront the urgent challenge of supplying sustainable,
nutritious diets in the face of escalating demands. The advent of Artificial
Intelligence (AI) is bringing in a personal choice revolution, wherein
AI-driven individual decisions transform food systems from dinner tables, to
the farms, and back to our plates. In this context, AI algorithms refine
personal dietary choices, subsequently shaping agricultural outputs, and
promoting an optimized feedback loop from consumption to cultivation.
Initially, we delve into AI tools and techniques spanning the food supply
chain, and subsequently assess how AI subfields$\unicode{x2013}$encompassing
machine learning, computer vision, and speech recognition$\unicode{x2013}$are
harnessed within the AI-enabled Food System (AIFS) framework, which
increasingly leverages Internet of Things, multimodal sensors and real-time
data exchange. We spotlight the AIFS framework, emphasizing its fusion of AI
with technologies such as digitalization, big data analytics, biotechnology,
and IoT extensively used in modern food systems in every component. This
paradigm shifts the conventional "farm to fork" narrative to a cyclical
"consumer-driven farm to fork" model for better achieving sustainable,
nutritious diets. This paper explores AI's promise and the intrinsic challenges
it poses within the food domain. By championing stringent AI governance,
uniform data architectures, and cross-disciplinary partnerships, we argue that
AI, when synergized with consumer-centric strategies, holds the potential to
steer food systems toward a sustainable trajectory. We furnish a comprehensive
survey for the state-of-the-art in diverse facets of food systems, subsequently
pinpointing gaps and advocating for the judicious and efficacious deployment of
emergent AI methodologies.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02401" title="Abstract">arXiv:2311.02401</a> [<a href="/pdf/2311.02401" title="Download PDF">pdf</a>, <a href="/format/2311.02401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BarcodeBERT: Transformers for Biodiversity Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arias%2C+P+M">Pablo Millan Arias</a>, 
<a href="/search/cs?searchtype=author&query=Sadjadi%2C+N">Niousha Sadjadi</a>, 
<a href="/search/cs?searchtype=author&query=Safari%2C+M">Monireh Safari</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Z">ZeMing Gong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A+T">Austin T. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lowe%2C+S+C">Scott C. Lowe</a>, 
<a href="/search/cs?searchtype=author&query=Haurum%2C+J+B">Joakim Bruslund Haurum</a>, 
<a href="/search/cs?searchtype=author&query=Zarubiieva%2C+I">Iuliia Zarubiieva</a>, 
<a href="/search/cs?searchtype=author&query=Steinke%2C+D">Dirk Steinke</a>, 
<a href="/search/cs?searchtype=author&query=Kari%2C+L">Lila Kari</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+A+X">Angel X. Chang</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+G+W">Graham W. Taylor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main text: 5 pages, Total: 9 pages, 2 figures, accepted at the 4th Workshop on Self-Supervised Learning: Theory and Practice (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Understanding biodiversity is a global challenge, in which DNA barcodes -
short snippets of DNA that cluster by species - play a pivotal role. In
particular, invertebrates, a highly diverse and under-explored group, pose
unique taxonomic complexities. We explore machine learning approaches,
comparing supervised CNNs, fine-tuned foundation models, and a DNA
barcode-specific masking strategy across datasets of varying complexity. While
simpler datasets and tasks favor supervised CNNs or fine-tuned transformers,
challenging species-level identification demands a paradigm shift towards
self-supervised pretraining. We propose BarcodeBERT, the first self-supervised
method for general biodiversity analysis, leveraging a 1.5 M invertebrate DNA
barcode reference library. This work highlights how dataset specifics and
coverage impact model selection, and underscores the role of self-supervised
pretraining in achieving high-accuracy DNA barcode-based identification at the
species and genus level. Indeed, without the fine-tuning step, BarcodeBERT
pretrained on a large DNA barcode dataset outperforms DNABERT and DNABERT-2 on
multiple downstream classification tasks. The code repository is available at
https://github.com/Kari-Genomics-Lab/BarcodeBERT
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02402" title="Abstract">arXiv:2311.02402</a> [<a href="/pdf/2311.02402" title="Download PDF">pdf</a>, <a href="/format/2311.02402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid quantum image classification and federated learning for hepatic  steatosis diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lusnig%2C+L">Luca Lusnig</a>, 
<a href="/search/cs?searchtype=author&query=Sagingalieva%2C+A">Asel Sagingalieva</a>, 
<a href="/search/cs?searchtype=author&query=Surmach%2C+M">Mikhail Surmach</a>, 
<a href="/search/cs?searchtype=author&query=Protasevich%2C+T">Tatjana Protasevich</a>, 
<a href="/search/cs?searchtype=author&query=Michiu%2C+O">Ovidiu Michiu</a>, 
<a href="/search/cs?searchtype=author&query=McLoughlin%2C+J">Joseph McLoughlin</a>, 
<a href="/search/cs?searchtype=author&query=Mansell%2C+C">Christopher Mansell</a>, 
<a href="/search/cs?searchtype=author&query=Petris%2C+G+d">Graziano de&#x27; Petris</a>, 
<a href="/search/cs?searchtype=author&query=Bonazza%2C+D">Deborah Bonazza</a>, 
<a href="/search/cs?searchtype=author&query=Zanconati%2C+F">Fabrizio Zanconati</a>, 
<a href="/search/cs?searchtype=author&query=Melnikov%2C+A">Alexey Melnikov</a>, 
<a href="/search/cs?searchtype=author&query=Cavalli%2C+F">Fabio Cavalli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Quantum Physics (quant-ph)

</div>
<p class="mathjax">With the maturity achieved by deep learning techniques, intelligent systems
that can assist physicians in the daily interpretation of clinical images can
play a very important role. In addition, quantum techniques applied to deep
learning can enhance this performance, and federated learning techniques can
realize privacy-friendly collaborative learning among different participants,
solving privacy issues due to the use of sensitive data and reducing the number
of data to be collected for each individual participant. We present in this
study a hybrid quantum neural network that can be used to quantify
non-alcoholic liver steatosis and could be useful in the diagnostic process to
determine a liver's suitability for transplantation; at the same time, we
propose a federated learning approach based on a classical deep learning
solution to solve the same problem, but using a reduced data set in each part.
The liver steatosis image classification accuracy of the hybrid quantum neural
network, the hybrid quantum ResNet model, consisted of 5 qubits and more than
100 variational gates, reaches 97%, which is 1.8% higher than its classical
counterpart, ResNet. Crucially, that even with a reduced dataset, our hybrid
approach consistently outperformed its classical counterpart, indicating
superior generalization and less potential for overfitting in medical
applications. In addition, a federated approach with multiple clients, up to
32, despite the lower accuracy, but still higher than 90%, would allow using,
for each participant, a very small dataset, i.e., up to one-thirtieth. Our
work, based over real-word clinical data can be regarded as a scalable and
collaborative starting point, could thus fulfill the need for an effective and
reliable computer-assisted system that facilitates the daily diagnostic work of
the clinical pathologist.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02405" title="Abstract">arXiv:2311.02405</a> [<a href="/pdf/2311.02405" title="Download PDF">pdf</a>, <a href="/ps/2311.02405" title="Download PostScript">ps</a>, <a href="/format/2311.02405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SplitMAC: Wireless Split Learning over Multiple Access Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seonjung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+Y">Yongjeong Oh</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+Y">Yo-Seb Jeon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper presents a novel split learning (SL) framework, referred to as
SplitMAC, which reduces the latency of SL by leveraging simultaneous uplink
transmission over multiple access channels. The key strategy is to divide
devices into multiple groups and allow the devices within the same group to
simultaneously transmit their smashed data and device-side models over the
multiple access channels. The optimization problem of device grouping to
minimize SL latency is formulated, and the benefit of device grouping in
reducing the uplink latency of SL is theoretically derived. By examining a
two-device grouping case, two asymptotically-optimal algorithms are devised for
device grouping in low and high signal-to-noise ratio (SNR) scenarios,
respectively, while providing proofs of their optimality. By merging these
algorithms, a near-optimal device grouping algorithm is proposed to cover a
wide range of SNR. Simulation results demonstrate that our SL framework with
the proposed device grouping algorithm is superior to existing SL frameworks in
reducing SL latency.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02406" title="Abstract">arXiv:2311.02406</a> [<a href="/pdf/2311.02406" title="Download PDF">pdf</a>, <a href="/format/2311.02406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ECO-DKF: Event-Triggered and Certifiable Optimal Distributed Kalman  Filter under Unknown Correlations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sebasti%C3%A1n%2C+E">Eduardo Sebasti&#xe1;n</a>, 
<a href="/search/eess?searchtype=author&query=Montijano%2C+E">Eduardo Montijano</a>, 
<a href="/search/eess?searchtype=author&query=Sag%C3%BC%C3%A9s%2C+C">Carlos Sag&#xfc;&#xe9;s</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for publication at IEEE Transactions on Automatic Control
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents ECO-DKF, the first Event-Triggered and Certifiable
Optimal Distributed Kalman Filter. Our algorithm addresses two major issues
inherent to Distributed Kalman Filters: (i) fully distributed and scalable
optimal estimation and (ii) reduction of the communication bandwidth usage. The
first requires to solve an NP-hard optimisation problem, forcing relaxations
that lose optimality guarantees over the original problem. Using only
information from one-hop neighbours, we propose a tight Semi-Definite
Programming relaxation that allows to certify locally and online if the relaxed
solution is the optimum of the original NP-hard problem. In that case, ECO-DKF
is optimal in the square error sense under scalability and event-triggered
one-hop communications restrictions. Additionally, ECO-DKF is a globally
asymptotically stable estimator. To address the second issue, we propose an
event-triggered scheme from the relaxed optimisation output. The consequence is
a broadcasting-based algorithm that saves communication bandwidth, avoids
individual communication links and multiple information exchanges within
instants, and preserves the optimality and stability properties of the filter.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02407" title="Abstract">arXiv:2311.02407</a> [<a href="/pdf/2311.02407" title="Download PDF">pdf</a>, <a href="/format/2311.02407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The equivalence of dynamic and strategic stability under regularized  learning in games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boone%2C+V">Victor Boone</a>, 
<a href="/search/cs?searchtype=author&query=Mertikopoulos%2C+P">Panayotis Mertikopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 8 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper, we examine the long-run behavior of regularized, no-regret
learning in finite games. A well-known result in the field states that the
empirical frequencies of no-regret play converge to the game's set of coarse
correlated equilibria; however, our understanding of how the players' actual
strategies evolve over time is much more limited - and, in many cases,
non-existent. This issue is exacerbated further by a series of recent results
showing that only strict Nash equilibria are stable and attracting under
regularized learning, thus making the relation between learning and pointwise
solution concepts particularly elusive. In lieu of this, we take a more general
approach and instead seek to characterize the \emph{setwise} rationality
properties of the players' day-to-day play. To that end, we focus on one of the
most stringent criteria of setwise strategic stability, namely that any
unilateral deviation from the set in question incurs a cost to the deviator - a
property known as closedness under better replies (club). In so doing, we
obtain a far-reaching equivalence between strategic and dynamic stability: a
product of pure strategies is closed under better replies if and only if its
span is stable and attracting under regularized learning. In addition, we
estimate the rate of convergence to such sets, and we show that methods based
on entropic regularization (like the exponential weights algorithm) converge at
a geometric rate, while projection-based methods converge within a finite
number of iterations, even with bandit, payoff-based feedback.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02408" title="Abstract">arXiv:2311.02408</a> [<a href="/pdf/2311.02408" title="Download PDF">pdf</a>, <a href="/format/2311.02408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Citance-Contextualized Summarization of Scientific Papers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Syed%2C+S">Shahbaz Syed</a>, 
<a href="/search/cs?searchtype=author&query=Hakimi%2C+A+D">Ahmad Dawar Hakimi</a>, 
<a href="/search/cs?searchtype=author&query=Al-Khatib%2C+K">Khalid Al-Khatib</a>, 
<a href="/search/cs?searchtype=author&query=Potthast%2C+M">Martin Potthast</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Current approaches to automatic summarization of scientific papers generate
informative summaries in the form of abstracts. However, abstracts are not
intended to show the relationship between a paper and the references cited in
it. We propose a new contextualized summarization approach that can generate an
informative summary conditioned on a given sentence containing the citation of
a reference (a so-called ``citance''). This summary outlines the content of the
cited paper relevant to the citation location. Thus, our approach extracts and
models the citances of a paper, retrieves relevant passages from cited papers,
and generates abstractive summaries tailored to each citance. We evaluate our
approach using $\textbf{Webis-Context-SciSumm-2023}$, a new dataset containing
540K~computer science papers and 4.6M~citances therein.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02413" title="Abstract">arXiv:2311.02413</a> [<a href="/pdf/2311.02413" title="Download PDF">pdf</a>, <a href="/format/2311.02413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> P2O-Calib: Camera-LiDAR Calibration Using Point-Pair Spatial Occlusion  Relationship
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Su Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shini Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xuchong Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IROS 2023. Presentation page: <a href="https://events.infovaya.com/presentation?id=103943">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE/RSJ International Conference on Intelligent Robots and
  Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The accurate and robust calibration result of sensors is considered as an
important building block to the follow-up research in the autonomous driving
and robotics domain. The current works involving extrinsic calibration between
3D LiDARs and monocular cameras mainly focus on target-based and target-less
methods. The target-based methods are often utilized offline because of
restrictions, such as additional target design and target placement limits. The
current target-less methods suffer from feature indeterminacy and feature
mismatching in various environments. To alleviate these limitations, we propose
a novel target-less calibration approach which is based on the 2D-3D edge point
extraction using the occlusion relationship in 3D space. Based on the extracted
2D-3D point pairs, we further propose an occlusion-guided point-matching method
that improves the calibration accuracy and reduces computation costs. To
validate the effectiveness of our approach, we evaluate the method performance
qualitatively and quantitatively on real images from the KITTI dataset. The
results demonstrate that our method outperforms the existing target-less
methods and achieves low error and high robustness that can contribute to the
practical applications relying on high-quality Camera-LiDAR calibration.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02415" title="Abstract">arXiv:2311.02415</a> [<a href="/pdf/2311.02415" title="Download PDF">pdf</a>, <a href="/format/2311.02415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Division Based Integrated Sensing, Communication, and Computing in  Integrated Satellite-Terrestrial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiangming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hua Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhaohui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+Q">Quoc-Viet Pham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we investigate time-division based framework for integrated
sensing, communication, and computing in integrated satellite-terrestrial
networks. We consider a scenario, where Internet-of-Things devices on the
ground operate with sensing and communication in a time-division manner, and
can process the sensing results locally, at the edge, or in the cloud via the
satellite communication link. Based on the proposed framework, we formulate a
multi-dimensional optimization problem to maximize the utility performance of
sensing, communication, and computing abilities. After decomposing the original
optimization problem into two subproblems, we first derive the closed-form
solution of the optimal task partitioning strategy for terrestrial users and
satellite users. Then, we develop the joint subframe allocation and task
partitioning strategy to optimize the overall performance, by means of which
the Pareto optimal solutions can be obtained along the Pareto frontier.
Extensive simulations are provided to demonstrated the effectiveness of the
proposed strategy, which is 10% to 60% superior compared with the benchmarks.
Also, the trade-off between the multidimensional resource and multi-functional
performance is analyzed from the perspective of network design.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02416" title="Abstract">arXiv:2311.02416</a> [<a href="/pdf/2311.02416" title="Download PDF">pdf</a>, <a href="/ps/2311.02416" title="Download PostScript">ps</a>, <a href="/format/2311.02416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expressive Power of Hypergraph Lambek Grammars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pshenitsyn%2C+T">Tikhon Pshenitsyn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">Hypergraph Lambek grammars (HL-grammars) is a novel logical approach to
generating graph languages based on the hypergraph Lambek calculus. In this
paper, we establish a precise relation between HL-grammars and hypergraph
grammars based on the double pushout (DPO) approach: we prove that HL-grammars
generate the same class of languages as DPO grammars with the linear
restriction on lengths of derivations. This can be viewed as a complete
description of the expressive power of HL-grammars and also as an analogue of
the Pentus theorem, which states that Lambek grammars generate the same class
of languages as context-free grammars. As a corollary, we prove that
HL-grammars subsume contextual hyperedge replacement grammars.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02420" title="Abstract">arXiv:2311.02420</a> [<a href="/pdf/2311.02420" title="Download PDF">pdf</a>, <a href="/format/2311.02420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical Recovery of a Time-Dependent Potential in Subdiffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jin%2C+B">Bangti Jin</a>, 
<a href="/search/math?searchtype=author&query=Shin%2C+K">Kwancheol Shin</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+Z">Zhi Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">In this work we investigate an inverse problem of recovering a time-dependent
potential in a semilinear subdiffusion model from an integral measurement of
the solution over the domain. The model involves the Djrbashian--Caputo
fractional derivative in time. Theoretically, we prove a novel conditional
Lipschitz stability result, and numerically, we develop an easy-to-implement
fixed point iteration for recovering the unknown coefficient. In addition, we
establish rigorous error bounds on the discrete approximation. These results
are obtained by crucially using smoothing properties of the solution operators
and suitable choice of a weighted $L^p(0,T)$ norm. The efficiency and accuracy
of the scheme are showcased on several numerical experiments in one- and
two-dimensions.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02421" title="Abstract">arXiv:2311.02421</a> [<a href="/pdf/2311.02421" title="Download PDF">pdf</a>, <a href="/format/2311.02421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital Twins for Human-Robot Collaboration: A Future Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaaban%2C+M">Mohamad Shaaban</a>, 
<a href="/search/cs?searchtype=author&query=Carf%C3%AC%2C+A">Alessandro Carf&#xec;</a>, 
<a href="/search/cs?searchtype=author&query=Mastrogiovanni%2C+F">Fulvio Mastrogiovanni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">As collaborative robot (Cobot) adoption in many sectors grows, so does the
interest in integrating digital twins in human-robot collaboration (HRC).
Virtual representations of physical systems (PT) and assets, known as digital
twins, can revolutionize human-robot collaboration by enabling real-time
simulation, monitoring, and control. In this article, we present a review of
the state-of-the-art and our perspective on the future of digital twins (DT) in
human-robot collaboration. We argue that DT will be crucial in increasing the
efficiency and effectiveness of these systems by presenting compelling evidence
and a concise vision of the future of DT in human-robot collaboration, as well
as insights into the possible advantages and challenges associated with their
integration.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02423" title="Abstract">arXiv:2311.02423</a> [<a href="/pdf/2311.02423" title="Download PDF">pdf</a>, <a href="/format/2311.02423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Payoff-based learning with matrix multiplicative weights in quantum  games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lotidis%2C+K">Kyriakos Lotidis</a>, 
<a href="/search/cs?searchtype=author&query=Mertikopoulos%2C+P">Panayotis Mertikopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Bambos%2C+N">Nicholas Bambos</a>, 
<a href="/search/cs?searchtype=author&query=Blanchet%2C+J">Jose Blanchet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 21 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Quantum Physics (quant-ph)

</div>
<p class="mathjax">In this paper, we study the problem of learning in quantum games - and other
classes of semidefinite games - with scalar, payoff-based feedback. For
concreteness, we focus on the widely used matrix multiplicative weights (MMW)
algorithm and, instead of requiring players to have full knowledge of the game
(and/or each other's chosen states), we introduce a suite of
minimal-information matrix multiplicative weights (3MW) methods tailored to
different information frameworks. The main difficulty to attaining convergence
in this setting is that, in contrast to classical finite games, quantum games
have an infinite continuum of pure states (the quantum equivalent of pure
strategies), so standard importance-weighting techniques for estimating payoff
vectors cannot be employed. Instead, we borrow ideas from bandit convex
optimization and we design a zeroth-order gradient sampler adapted to the
semidefinite geometry of the problem at hand. As a first result, we show that
the 3MW method with deterministic payoff feedback retains the
$\mathcal{O}(1/\sqrt{T})$ convergence rate of the vanilla, full information MMW
algorithm in quantum min-max games, even though the players only observe a
single scalar. Subsequently, we relax the algorithm's information requirements
even further and we provide a 3MW method that only requires players to observe
a random realization of their payoff observable, and converges to equilibrium
at an $\mathcal{O}(T^{-1/4})$ rate. Finally, going beyond zero-sum games, we
show that a regularized variant of the proposed 3MW method guarantees local
convergence with high probability to all equilibria that satisfy a certain
first-order stability condition.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02427" title="Abstract">arXiv:2311.02427</a> [<a href="/pdf/2311.02427" title="Download PDF">pdf</a>, <a href="/format/2311.02427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Succinct Data Structure for Graphs with $d$-Dimensional  $t$-Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balakrishnan%2C+G">Girish Balakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+S">Sankardeep Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Jo%2C+S">Seungbum Jo</a>, 
<a href="/search/cs?searchtype=author&query=Narayanaswamy%2C+N+S">N S Narayanaswamy</a>, 
<a href="/search/cs?searchtype=author&query=Sadakane%2C+K">Kunihiko Sadakane</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Erd\H{o}s and West (Discrete Mathematics'85) considered the class of $n$
vertex intersection graphs which have a {\em $d$-dimensional} {\em
$t$-representation}, that is, each vertex of a graph in the class has an
associated set consisting of at most $t$ $d$-dimensional axis-parallel boxes.
In particular, for a graph $G$ and for each $d \geq 1$, they consider $i_d(G)$
to be the minimum $t$ for which $G$ has such a representation. For fixed $t$
and $d$, they consider the class of $n$ vertex labeled graphs for which $i_d(G)
\leq t$, and prove an upper bound of $(2nt+\frac{1}{2})d \log n - (n -
\frac{1}{2})d \log(4\pi t)$ on the logarithm of size of the class.
<br />In this work, for fixed $t$ and $d$ we consider the class of $n$ vertex
unlabeled graphs which have a {\em $d$-dimensional $t$-representation}, denoted
by $\mathcal{G}_{t,d}$. We address the problem of designing a succinct data
structure for the class $\mathcal{G}_{t,d}$ in an attempt to generalize the
relatively recent results on succinct data structures for interval graphs
(Algorithmica'21). To this end, for each $n$ such that $td^2$ is in $o(n / \log
n)$, we first prove a lower bound of $(2dt-1)n \log n - O(ndt \log \log
n)$-bits on the size of any data structure for encoding an arbitrary graph that
belongs to $\mathcal{G}_{t,d}$.
<br />We then present a $((2dt-1)n \log n + dt\log t + o(ndt \log n))$-bit data
structure for $\mathcal{G}_{t,d}$ that supports navigational queries
efficiently. Contrasting this data structure with our lower bound argument, we
show that for each fixed $t$ and $d$, and for all $n \geq 0$ when $td^2$ is in
$o(n/\log n)$ our data structure for $\mathcal{G}_{t,d}$ is succinct.
<br />As a byproduct, we also obtain succinct data structures for graphs of bounded
boxicity (denoted by $d$ and $t = 1$) and graphs of bounded interval number
(denoted by $t$ and $d=1$) when $td^2$ is in $o(n/\log n)$.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02428" title="Abstract">arXiv:2311.02428</a> [<a href="/pdf/2311.02428" title="Download PDF">pdf</a>, <a href="/format/2311.02428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task Arithmetic with LoRA for Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chitale%2C+R">Rajas Chitale</a>, 
<a href="/search/cs?searchtype=author&query=Vaidya%2C+A">Ankit Vaidya</a>, 
<a href="/search/cs?searchtype=author&query=Kane%2C+A">Aditya Kane</a>, 
<a href="/search/cs?searchtype=author&query=Ghotkar%2C+A">Archana Ghotkar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Continual learning refers to the problem where the training data is available
in sequential chunks, termed "tasks". The majority of progress in continual
learning has been stunted by the problem of catastrophic forgetting, which is
caused by sequential training of the model on streams of data. Moreover, it
becomes computationally expensive to sequentially train large models multiple
times. To mitigate both of these problems at once, we propose a novel method to
continually train transformer-based vision models using low-rank adaptation and
task arithmetic. Our method completely bypasses the problem of catastrophic
forgetting, as well as reducing the computational requirement for training
models on each task. When aided with a small memory of 10 samples per class,
our method achieves performance close to full-set finetuning. We present
rigorous ablations to support the prowess of our method.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02432" title="Abstract">arXiv:2311.02432</a> [<a href="/pdf/2311.02432" title="Download PDF">pdf</a>, <a href="/format/2311.02432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> P-Age: Pexels Dataset for Robust Spatio-Temporal Apparent Age  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali%2C+A">Abid Ali</a>, 
<a href="/search/cs?searchtype=author&query=Marisetty%2C+A">Ashish Marisetty</a>, 
<a href="/search/cs?searchtype=author&query=Bremond%2C+F">Francois Bremond</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Age estimation is a challenging task that has numerous applications. In this
paper, we propose a new direction for age classification that utilizes a
video-based model to address challenges such as occlusions, low-resolution, and
lighting conditions. To address these challenges, we propose AgeFormer which
utilizes spatio-temporal information on the dynamics of the entire body
dominating face-based methods for age classification. Our novel two-stream
architecture uses TimeSformer and EfficientNet as backbones, to effectively
capture both facial and body dynamics information for efficient and accurate
age estimation in videos. Furthermore, to fill the gap in predicting age in
real-world situations from videos, we construct a video dataset called Pexels
Age (P-Age) for age classification. The proposed method achieves superior
results compared to existing face-based age estimation methods and is evaluated
in situations where the face is highly occluded, blurred, or masked. The method
is also cross-tested on a variety of challenging video datasets such as
Charades, Smarthome, and Thumos-14.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02433" title="Abstract">arXiv:2311.02433</a> [<a href="/pdf/2311.02433" title="Download PDF">pdf</a>, <a href="/format/2311.02433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can ChatGPT support software verification?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jan%C3%9Fen%2C+C">Christian Jan&#xdf;en</a>, 
<a href="/search/cs?searchtype=author&query=Richter%2C+C">Cedric Richter</a>, 
<a href="/search/cs?searchtype=author&query=Wehrheim%2C+H">Heike Wehrheim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Formal Languages and Automata Theory (cs.FL); Machine Learning (cs.LG); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Large language models have become increasingly effective in software
engineering tasks such as code generation, debugging and repair. Language
models like ChatGPT can not only generate code, but also explain its inner
workings and in particular its correctness. This raises the question whether we
can utilize ChatGPT to support formal software verification.
<br />In this paper, we take some first steps towards answering this question. More
specifically, we investigate whether ChatGPT can generate loop invariants. Loop
invariant generation is a core task in software verification, and the
generation of valid and useful invariants would likely help formal verifiers.
To provide some first evidence on this hypothesis, we ask ChatGPT to annotate
106 C programs with loop invariants. We check validity and usefulness of the
generated invariants by passing them to two verifiers, Frama-C and CPAchecker.
Our evaluation shows that ChatGPT is able to produce valid and useful
invariants allowing Frama-C to verify tasks that it could not solve before.
Based on our initial insights, we propose ways of combining ChatGPT (or large
language models in general) and software verifiers, and discuss current
limitations and open issues.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02436" title="Abstract">arXiv:2311.02436</a> [<a href="/pdf/2311.02436" title="Download PDF">pdf</a>, <a href="/ps/2311.02436" title="Download PostScript">ps</a>, <a href="/format/2311.02436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Power Flow Solutions via Noise-Resilient Quantum-Inspired  Interior-Point Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Amani%2C+F">Farshad Amani</a>, 
<a href="/search/eess?searchtype=author&query=Kargarian%2C+A">Amin Kargarian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents three quantum interior-point methods (QIPMs) tailored to
tackle the DC optimal power flow (DCOPF) problem using noisy intermediate-scale
quantum devices. The optimization model is redefined as a linearly constrained
quadratic optimization. By incorporating the Harrow-Hassidim-Lloyd (HHL)
quantum algorithm into the IPM framework, Newton's direction is determined
through the resolution of linear equation systems. To mitigate the impact of
HHL error and quantum noise on Newton's direction calculation, we present a
noise-tolerant quantum IPM (NT-QIPM) approach. This approach provides
high-quality OPF solutions even in scenarios where inexact solutions to the
linear equation systems result in approximated Newton's directions. Moreover,
to enhance performance in cases of slow convergence and uphold the feasibility
of OPF outcomes upon convergence, we propose a hybrid strategy, classically
augmented NT-QIPM. This technique is designed to expedite convergence relative
to classical IPM while maintaining the solution accuracy. The efficacy of the
proposed quantum IPM variants is studied through comprehensive simulations and
error analyses on 3-bus, 5-bus, 118-bus, and 300-bus systems, highlighting
their potential and promise in addressing challenging OPF scenarios. By
modeling the errors and incorporating quantum computer noise, we simulate the
proposed algorithms on both Qiskit and classical computers to gain a deeper
understanding of the effectiveness and feasibility of our methods under
realistic conditions.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02438" title="Abstract">arXiv:2311.02438</a> [<a href="/pdf/2311.02438" title="Download PDF">pdf</a>, <a href="/ps/2311.02438" title="Download PostScript">ps</a>, <a href="/format/2311.02438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the stable Cholesky factorization-based method for the maximum  correntropy criterion Kalman filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kulikova%2C+M+V">Maria V. Kulikova</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IFAC-PapersOnLine, 53(2): 482-487, 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper continues the research devoted to the design of numerically stable
square-root implementations for the maximum correntropy criterion Kalman
filtering (MCC-KF). In contrast to the previously obtained results, here we
reveal the first robust (with respect to round-off errors) method within the
Cholesky factorization-based approach. The method is formulated in terms of
square-root factors of the {\it covariance} matrices, i.e. it belongs to the
covariance-type filtering methodology. Additionally, a numerically stable
orthogonal transformation is utilized at each iterate of the algorithm for
accurate propagation of the Cholesky factors involved. The results of numerical
experiments illustrate a superior performance of the novel MCC-KF
implementation compared to both the conventional algorithm and its previously
published Cholesky-based variant.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02440" title="Abstract">arXiv:2311.02440</a> [<a href="/pdf/2311.02440" title="Download PDF">pdf</a>, <a href="/ps/2311.02440" title="Download PostScript">ps</a>, <a href="/format/2311.02440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Factored-form Kalman-like implementations under maximum correntropy  criterion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kulikova%2C+M+V">Maria V. Kulikova</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Signal Processing, 160: 328-338, 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">The maximum correntropy criterion (MCC) methodology is recognized to be a
robust filtering strategy with respect to outliers and shown to outperform the
classical Kalman filter (KF) for estimation accuracy in the presence of
non-Gaussian noise. However, the numerical stability of the newly proposed
MCC-KF estimators in finite precision arithmetic is seldom addressed. In this
paper, a family of {\it factored-form} (square-root) algorithms is derived for
the MCC-KF and its improved variant, respectively. The family traditionally
consists of three factored-form implementations: (i) Cholesky
factorization-based algorithms, (ii) modified Cholesky, i.e. UD-based methods,
and (iii) the recently established SVD-based filtering. All these strategies
are commonly recognized to enhance the numerical robustness of conventional
filtering with respect to roundoff errors and, hence, they are the preferred
implementations when solving applications with high reliability requirements.
Previously, only Cholesky-based IMCC-KF algorithms have been designed. This
paper enriches a factored-form family by introducing the UD- and SVD-based
methods as well. A special attention is paid to {\it array} algorithms that are
proved to be the most numerically stable and, additionally, suitable for
parallel implementations. The theoretical properties are discussed and
numerical comparison is presented for determining the most reliable
implementations.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02446" title="Abstract">arXiv:2311.02446</a> [<a href="/pdf/2311.02446" title="Download PDF">pdf</a>, <a href="/format/2311.02446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Robust Sequential Recommenders through Confident Soft Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shiguang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+X">Xin Xin</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+P">Pengjie Ren</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhumin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jun Ma</a>, 
<a href="/search/cs?searchtype=author&query=de+Rijke%2C+M">Maarten de Rijke</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhaochun Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Sequential recommenders that are trained on implicit feedback are usually
learned as a multi-class classification task through softmax-based loss
functions on one-hot class labels. However, one-hot training labels are sparse
and may lead to biased training and sub-optimal performance. Dense, soft labels
have been shown to help improve recommendation performance. But how to generate
high-quality and confident soft labels from noisy sequential interactions
between users and items is still an open question.
<br />We propose a new learning framework for sequential recommenders, CSRec, which
introduces confident soft labels to provide robust guidance when learning from
user-item interactions. CSRec contains a teacher module that generates
high-quality and confident soft labels and a student module that acts as the
target recommender and is trained on the combination of dense, soft labels and
sparse, one-hot labels.
<br />We propose and compare three approaches to constructing the teacher module:
(i) model-level, (ii) data-level, and (iii) training-level. To evaluate the
effectiveness and generalization ability of CSRec, we conduct experiments using
various state-of-the-art sequential recommendation models as the target student
module on four benchmark datasets. Our experimental results demonstrate that
CSRec is effective in training better performing sequential recommenders.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02447" title="Abstract">arXiv:2311.02447</a> [<a href="/pdf/2311.02447" title="Download PDF">pdf</a>, <a href="/format/2311.02447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantized-but-uncoded Distributed Detection (QDD) with Unreliable  Reporting Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Lei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Viswanathan%2C+R">Ramanarayanan Viswanathan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figure, submitted to IEEE T-IT
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Distributed detection primarily centers around two approaches: Unquantized
Distributed Detection (UDD), where each sensor reports its complete observation
to the fusion center (FC), and quantized-and-Coded DD (CDD), where each sensor
first partitions the observation space and then reports to the FC a codeword.
In this paper, we introduce Quantized-but-uncoded DD (QDD), where each sensor,
after quantization, transmits a summarized value, instead of a codeword, to the
FC. We show that QDD well adapts to the constraint of transmission power when
compared to CDD, albeit with increased complexity in parameter selection.
Moreover, we establish that, in the presence of independent observations, QDD
upholds a necessary condition inherent in CDD. Specifically, the optimal sensor
decision rules are the likelihood ratio quantizers (LRQ), irrelevant to the
channel conditions. In the context of a single-sensor scenario involving binary
decision at the sensor, we find that the optimal sensor rule in QDD is in
general no longer ``channel blind", a feature presented in CDD. In addition, we
compare these systems numerically under the same transmission power and
bandwidth, while assuming additive white Gaussian noise (AWGN) in both sensing
and reporting stages. Finally, we present some potential directions for future
research.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02451" title="Abstract">arXiv:2311.02451</a> [<a href="/pdf/2311.02451" title="Download PDF">pdf</a>, <a href="/ps/2311.02451" title="Download PostScript">ps</a>, <a href="/format/2311.02451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utilizing Imperfect Resolution of Near-Field Beamforming: A Hybrid-NOMA  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zhiguo Ding</a>, 
<a href="/search/cs?searchtype=author&query=Poor%2C+H+V">H. Vincent Poor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This letter studies how the imperfect resolution of near-field beamforming,
the key feature of near-field communications, can be used to improve the
throughput and connectivity of wireless networks. In particular, a hybrid
non-orthogonal multiple access (NOMA) transmission strategy is developed to use
preconfigured near-field beams for serving additional users. An energy
consumption minimization problem is first formulated and then solved by using
different successive interference cancellation strategies. Both analytical and
simulation results are presented to illustrate the impact of the resolution of
near-field beamforming on the design of hybrid NOMA transmission.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02454" title="Abstract">arXiv:2311.02454</a> [<a href="/pdf/2311.02454" title="Download PDF">pdf</a>, <a href="/format/2311.02454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing the Performance of Pneu-net Actuators Using a Torsion  Resistant Strain Limiting Layer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Good%2C+I+S">Ian Sullivan Good</a>, 
<a href="/search/cs?searchtype=author&query=Balaji%2C+S">Srivatsan Balaji</a>, 
<a href="/search/cs?searchtype=author&query=Lipton%2C+J+I">Jeffrey Ian Lipton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 10 figures, submitted to Robosoft 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Pneunets are the primary form of soft robotic grippers. A key limitation to
their wider adoption is their inability to grasp larger payloads due to objects
slipping out of grasps. We have overcome this limitation by introducing a
torsionally rigid strain limiting layer (TRL). This reduces out-of-plane
bending while maintaining the gripper's softness and in-plane flexibility. We
characterize the design space of the strain limiting layer for a Pneu-net
gripper using simulation and experiment and map bending angle and relative grip
strength. We found that the use of our TRL reduced out-of-plane bending by up
to 97.7% in testing compared to a benchmark Pneu-net gripper from the Soft
Robotics Toolkit. We demonstrate a lifting capacity of 5kg when loading using
the TRL. We also see a relative improvement in peak grip force of 3N and
stiffness of 1200N/m compared to 1N and 150N/m for a Pneu-net gripper without
our TRL at equal pressures. Finally, we test the TRL gripper on a suite of six
YCB objects above the demonstrated capability of a traditional Pneu-net
gripper. We show success on all but one demonstrating significant increased
capabilities.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02455" title="Abstract">arXiv:2311.02455</a> [<a href="/pdf/2311.02455" title="Download PDF">pdf</a>, <a href="/format/2311.02455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-based Multi-instance Mixed Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Engelmann%2C+J+P">Jan P. Engelmann</a>, 
<a href="/search/cs?searchtype=author&query=Palma%2C+A">Alessandro Palma</a>, 
<a href="/search/cs?searchtype=author&query=Tomczak%2C+J+M">Jakub M. Tomczak</a>, 
<a href="/search/cs?searchtype=author&query=Theis%2C+F+J">Fabian J Theis</a>, 
<a href="/search/cs?searchtype=author&query=Casale%2C+F+P">Francesco Paolo Casale</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Genomics (q-bio.GN); Quantitative Methods (q-bio.QM); Applications (stat.AP)

</div>
<p class="mathjax">Predicting patient features from single-cell data can unveil cellular states
implicated in health and disease. Linear models and average cell type
expressions are typically favored for this task for their efficiency and
robustness, but they overlook the rich cell heterogeneity inherent in
single-cell data. To address this gap, we introduce GMIL, a framework
integrating Generalized Linear Mixed Models (GLMM) and Multiple Instance
Learning (MIL), upholding the advantages of linear models while modeling
cell-state heterogeneity. By leveraging predefined cell embeddings, GMIL
enhances computational efficiency and aligns with recent advancements in
single-cell representation learning. Our empirical results reveal that GMIL
outperforms existing MIL models in single-cell datasets, uncovering new
associations and elucidating biological mechanisms across different domains.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02460" title="Abstract">arXiv:2311.02460</a> [<a href="/pdf/2311.02460" title="Download PDF">pdf</a>, <a href="/format/2311.02460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extracting Network Structures from Corporate Organization Charts Using  Heuristic Image Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sayama%2C+H">Hiroki Sayama</a>, 
<a href="/search/cs?searchtype=author&query=Yamanoi%2C+J">Junichi Yamanoi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 12 figures, 1 table; to be published in "Data Science and Security: Proceedings of IDSCS 2023" (Springer)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY)

</div>
<p class="mathjax">Organizational structure of corporations has potential to provide
implications for dynamics and performance of corporate operations. However,
this subject has remained unexplored because of the lack of readily available
organization network datasets. To overcome the this gap, we developed a new
heuristic image-processing method to extract and reconstruct organization
network data from published organization charts. Our method analyzes a PDF file
of a corporate organization chart and detects text labels, boxes, connecting
lines, and other objects through multiple steps of heuristically implemented
image processing. The detected components are reorganized together into a
Python's NetworkX Graph object for visualization, validation and further
network analysis. We applied the developed method to the organization charts of
all the listed firms in Japan shown in the ``Organization Chart/System Diagram
Handbook'' published by Diamond, Inc., from 2008 to 2011. Out of the 10,008
organization chart PDF files, our method was able to reconstruct 4,606
organization networks (data acquisition success rate: 46%). For each
reconstructed organization network, we measured several network diagnostics,
which will be used for further statistical analysis to investigate their
potential correlations with corporate behavior and performance.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02461" title="Abstract">arXiv:2311.02461</a> [<a href="/pdf/2311.02461" title="Download PDF">pdf</a>, <a href="/format/2311.02461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPHEAR: Spherical Head Registration for Complete Statistical 3D Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bazavan%2C+E+G">Eduard Gabriel Bazavan</a>, 
<a href="/search/cs?searchtype=author&query=Zanfir%2C+A">Andrei Zanfir</a>, 
<a href="/search/cs?searchtype=author&query=Alldieck%2C+T">Thiemo Alldieck</a>, 
<a href="/search/cs?searchtype=author&query=Szente%2C+T+A">Teodor Alexandru Szente</a>, 
<a href="/search/cs?searchtype=author&query=Zanfir%2C+M">Mihai Zanfir</a>, 
<a href="/search/cs?searchtype=author&query=Sminchisescu%2C+C">Cristian Sminchisescu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published at the International Conference on 3D Vision 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present \emph{SPHEAR}, an accurate, differentiable parametric statistical
3D human head model, enabled by a novel 3D registration method based on
spherical embeddings. We shift the paradigm away from the classical Non-Rigid
Registration methods, which operate under various surface priors, increasing
reconstruction fidelity and minimizing required human intervention.
Additionally, SPHEAR is a \emph{complete} model that allows not only to sample
diverse synthetic head shapes and facial expressions, but also gaze directions,
high-resolution color textures, surface normal maps, and hair cuts represented
in detail, as strands. SPHEAR can be used for automatic realistic visual data
generation, semantic annotation, and general reconstruction tasks. Compared to
state-of-the-art approaches, our components are fast and memory efficient, and
experiments support the validity of our design choices and the accuracy of
registration, reconstruction and generation techniques.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02462" title="Abstract">arXiv:2311.02462</a> [<a href="/pdf/2311.02462" title="Download PDF">pdf</a>, <a href="/format/2311.02462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Levels of AGI: Operationalizing Progress on the Path to AGI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morris%2C+M+R">Meredith Ringel Morris</a>, 
<a href="/search/cs?searchtype=author&query=Sohl-dickstein%2C+J">Jascha Sohl-dickstein</a>, 
<a href="/search/cs?searchtype=author&query=Fiedel%2C+N">Noah Fiedel</a>, 
<a href="/search/cs?searchtype=author&query=Warkentin%2C+T">Tris Warkentin</a>, 
<a href="/search/cs?searchtype=author&query=Dafoe%2C+A">Allan Dafoe</a>, 
<a href="/search/cs?searchtype=author&query=Faust%2C+A">Aleksandra Faust</a>, 
<a href="/search/cs?searchtype=author&query=Farabet%2C+C">Clement Farabet</a>, 
<a href="/search/cs?searchtype=author&query=Legg%2C+S">Shane Legg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">We propose a framework for classifying the capabilities and behavior of
Artificial General Intelligence (AGI) models and their precursors. This
framework introduces levels of AGI performance, generality, and autonomy. It is
our hope that this framework will be useful in an analogous way to the levels
of autonomous driving, by providing a common language to compare models, assess
risks, and measure progress along the path to AGI. To develop our framework, we
analyze existing definitions of AGI, and distill six principles that a useful
ontology for AGI should satisfy. These principles include focusing on
capabilities rather than mechanisms; separately evaluating generality and
performance; and defining stages along the path toward AGI, rather than
focusing on the endpoint. With these principles in mind, we propose 'Levels of
AGI' based on depth (performance) and breadth (generality) of capabilities, and
reflect on how current systems fit into this ontology. We discuss the
challenging requirements for future benchmarks that quantify the behavior and
capabilities of AGI models against these levels. Finally, we discuss how these
levels of AGI interact with deployment considerations such as autonomy and
risk, and emphasize the importance of carefully selecting Human-AI Interaction
paradigms for responsible and safe deployment of highly capable AI systems.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02466" title="Abstract">arXiv:2311.02466</a> [<a href="/pdf/2311.02466" title="Download PDF">pdf</a>, <a href="/format/2311.02466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-State Brain Network Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hang Yin</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yao Su</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinyue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hartvigsen%2C+T">Thomas Hartvigsen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanhua Li</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+X">Xiangnan Kong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a regular paper at IEEE BigData 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Brain network discovery aims to find nodes and edges from the spatio-temporal
signals obtained by neuroimaging data, such as fMRI scans of human brains.
Existing methods tend to derive representative or average brain networks,
assuming observed signals are generated by only a single brain activity state.
However, the human brain usually involves multiple activity states, which
jointly determine the brain activities. The brain regions and their
connectivity usually exhibit intricate patterns that are difficult to capture
with only a single-state network. Recent studies find that brain parcellation
and connectivity change according to the brain activity state. We refer to such
brain networks as multi-state, and this mixture can help us understand human
behavior. Thus, compared to a single-state network, a multi-state network can
prevent us from losing crucial information of cognitive brain network. To
achieve this, we propose a new model called MNGL (Multi-state Network Graphical
Lasso), which successfully models multi-state brain networks by combining CGL
(coherent graphical lasso) with GMM (Gaussian Mixture Model). Using both
synthetic and real world ADHD 200 fMRI datasets, we demonstrate that MNGL
outperforms recent state-of-the-art alternatives by discovering more
explanatory and realistic results.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02475" title="Abstract">arXiv:2311.02475</a> [<a href="/pdf/2311.02475" title="Download PDF">pdf</a>, <a href="/format/2311.02475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained Equation Learner Networks for Precision-Preserving  Extrapolation of Robotic Skills
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perez-Villeda%2C+H">Hector Perez-Villeda</a>, 
<a href="/search/cs?searchtype=author&query=Piater%2C+J">Justus Piater</a>, 
<a href="/search/cs?searchtype=author&query=Saveriano%2C+M">Matteo Saveriano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 10 figures. To be submitted to IEEE Transactions on Robotics (T-RO)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In Programming by Demonstration, the robot learns novel skills from human
demonstrations. After learning, the robot should be able not only to reproduce
the skill, but also to generalize it to shifted domains without collecting new
training data. Adaptation to similar domains has been investigated in the
literature; however, an open problem is how to adapt learned skills to
different conditions that are outside of the data distribution, and, more
important, how to preserve the precision of the desired adaptations. This paper
presents a novel supervised learning framework called Constrained Equation
Learner Networks that addresses the trajectory adaptation problem in
Programming by Demonstrations from a constrained regression perspective. While
conventional approaches for constrained regression use one kind of basis
function, e.g., Gaussian, we exploit Equation Learner Networks to learn a set
of analytical expressions and use them as basis functions. These basis
functions are learned from demonstration with the objective to minimize
deviations from the training data while imposing constraints that represent the
desired adaptations, like new initial or final points or maintaining the
trajectory within given bounds. Our approach addresses three main difficulties
in adapting robotic trajectories: 1) minimizing the distortion of the
trajectory for new adaptations; 2) preserving the precision of the adaptations;
and 3) dealing with the lack of intuition about the structure of basis
functions. We validate our approach both in simulation and in real experiments
in a set of robotic tasks that require adaptation due to changes in the
environment, and we compare obtained results with two existing approaches.
Performed experiments show that Constrained Equation Learner Networks
outperform state of the art approaches by increasing generalization and
adaptability of robotic skills.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02476" title="Abstract">arXiv:2311.02476</a> [<a href="/pdf/2311.02476" title="Download PDF">pdf</a>, <a href="/format/2311.02476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forecasting Success of Computer Science Professors and Students Based on  Their Academic and Personal Backgrounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalhor%2C+G">Ghazal Kalhor</a>, 
<a href="/search/cs?searchtype=author&query=Bahrak%2C+B">Behnam Bahrak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">After completing their undergraduate studies, many computer science (CS)
students apply for competitive graduate programs in North America. Their
long-term goal is often to be hired by one of the big five tech companies or to
become a faculty member. Therefore, being aware of the role of admission
criteria may help them choose the best path towards their goals. In this paper,
we analyze the influence of students' previous universities on their chances of
being accepted to prestigious North American universities and returning to
academia as professors in the future. Our findings demonstrate that the ranking
of their prior universities is a significant factor in achieving their goals.
We then illustrate that there is a bias in the undergraduate institutions of
students admitted to the top 25 computer science programs. Finally, we employ
machine learning models to forecast the success of professors at these
universities. We achieved an RMSE of 7.85 for this prediction task.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02482" title="Abstract">arXiv:2311.02482</a> [<a href="/pdf/2311.02482" title="Download PDF">pdf</a>, <a href="/format/2311.02482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized zero-shot audio-to-intent classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elluru%2C+V+R">Veera Raghavendra Elluru</a>, 
<a href="/search/cs?searchtype=author&query=Kulshreshtha%2C+D">Devang Kulshreshtha</a>, 
<a href="/search/cs?searchtype=author&query=Paturi%2C+R">Rohit Paturi</a>, 
<a href="/search/cs?searchtype=author&query=Bodapati%2C+S">Sravan Bodapati</a>, 
<a href="/search/cs?searchtype=author&query=Ronanki%2C+S">Srikanth Ronanki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Spoken language understanding systems using audio-only data are gaining
popularity, yet their ability to handle unseen intents remains limited. In this
study, we propose a generalized zero-shot audio-to-intent classification
framework with only a few sample text sentences per intent. To achieve this, we
first train a supervised audio-to-intent classifier by making use of a
self-supervised pre-trained model. We then leverage a neural audio synthesizer
to create audio embeddings for sample text utterances and perform generalized
zero-shot classification on unseen intents using cosine similarity. We also
propose a multimodal training strategy that incorporates lexical information
into the audio representation to improve zero-shot performance. Our multimodal
training approach improves the accuracy of zero-shot intent classification on
unseen intents of SLURP by 2.75% and 18.2% for the SLURP and internal
goal-oriented dialog datasets, respectively, compared to audio-only training.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02485" title="Abstract">arXiv:2311.02485</a> [<a href="/pdf/2311.02485" title="Download PDF">pdf</a>, <a href="/format/2311.02485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Quantification of Deep Learning for Spatiotemporal Data:  Challenges and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+W">Wenchong He</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhe Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Oral presentation in UDM-KDD'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the advancement of GPS, remote sensing, and computational simulations,
large amounts of geospatial and spatiotemporal data are being collected at an
increasing speed. Such emerging spatiotemporal big data assets, together with
the recent progress of deep learning technologies, provide unique opportunities
to transform society. However, it is widely recognized that deep learning
sometimes makes unexpected and incorrect predictions with unwarranted
confidence, causing severe consequences in high-stake decision-making
applications (e.g., disaster management, medical diagnosis, autonomous
driving). Uncertainty quantification (UQ) aims to estimate a deep learning
model's confidence. This paper provides a brief overview of UQ of deep learning
for spatiotemporal data, including its unique challenges and existing methods.
We particularly focus on the importance of uncertainty sources. We identify
several future research directions for spatiotemporal data.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02489" title="Abstract">arXiv:2311.02489</a> [<a href="/pdf/2311.02489" title="Download PDF">pdf</a>, <a href="/format/2311.02489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does Code Review Speed Matter for Practitioners?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kudrjavets%2C+G">Gunnar Kudrjavets</a> (University of Groningen), 
<a href="/search/cs?searchtype=author&query=Rastogi%2C+A">Ayushi Rastogi</a> (University of Groningen)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 7 figures. To be published in Empirical Software Engineering An International Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Increasing code velocity is a common goal for a variety of software projects.
The efficiency of the code review process significantly impacts how fast the
code gets merged into the final product and reaches the customers. We conducted
a survey to study the code velocity-related beliefs and practices in place. We
analyzed 75 completed surveys from 39 participants from the industry and 36
from the open-source community. Our critical findings are (a) the industry and
open-source community hold a similar set of beliefs, (b) quick reaction time is
of utmost importance and applies to the tooling infrastructure and the behavior
of other engineers, (c) time-to-merge is the essential code review metric to
improve, (d) engineers have differing opinions about the benefits of increased
code velocity for their career growth, and (e) the controlled application of
the commit-then-review model can increase code velocity. Our study supports the
continued need to invest in and improve code velocity regardless of the
underlying organizational ecosystem.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02490" title="Abstract">arXiv:2311.02490</a> [<a href="/pdf/2311.02490" title="Download PDF">pdf</a>, <a href="/format/2311.02490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Convergence Rates of Anderson Acceleration for a Large Class of  Fixed-Point Iterations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Garner%2C+C">Casey Garner</a>, 
<a href="/search/math?searchtype=author&query=Lerman%2C+G">Gilad Lerman</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+T">Teng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper studies Anderson acceleration (AA) for fixed-point methods
${x}^{(k+1)}=q({x}^{(k)})$. It provides the first proof that when the operator
$q$ is linear and symmetric, AA improves the root-linear convergence factor
over the fixed-point iterations. When $q$ is nonlinear, yet has a symmetric
Jacobian at the solution, a slightly modified AA algorithm is proved to have an
analogous root-linear convergence factor improvement over fixed-point
iterations. Simulations verify our observations. Furthermore, experiments with
different data models demonstrate AA is significantly superior to the standard
fixed-point methods for Tyler's M-estimation.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02492" title="Abstract">arXiv:2311.02492</a> [<a href="/pdf/2311.02492" title="Download PDF">pdf</a>, <a href="/format/2311.02492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forecasting Post-Wildfire Vegetation Recovery in California using a  Convolutional Long Short-Term Memory Tensor Regression Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiahe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaodi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be included in the 6th Workshop on Artificial Intelligence for Humanitarian Assistance and Disaster Response at the 37th Conference on Neural Information Processing Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The study of post-wildfire plant regrowth is essential for developing
successful ecosystem recovery strategies. Prior research mainly examines key
ecological and biogeographical factors influencing post-fire succession. This
research proposes a novel approach for predicting and analyzing post-fire plant
recovery. We develop a Convolutional Long Short-Term Memory Tensor Regression
(ConvLSTMTR) network that predicts future Normalized Difference Vegetation
Index (NDVI) based on short-term plant growth data after fire containment. The
model is trained and tested on 104 major California wildfires occurring between
2013 and 2020, each with burn areas exceeding 3000 acres. The integration of
ConvLSTM with tensor regression enables the calculation of an overall logistic
growth rate k using predicted NDVI. Overall, our k-value predictions
demonstrate impressive performance, with 50% of predictions exhibiting an
absolute error of 0.12 or less, and 75% having an error of 0.24 or less.
Finally, we employ Uniform Manifold Approximation and Projection (UMAP) and KNN
clustering to identify recovery trends, offering insights into regions with
varying rates of recovery. This study pioneers the combined use of tensor
regression and ConvLSTM, and introduces the application of UMAP for clustering
similar wildfires. This advances predictive ecological modeling and could
inform future post-fire vegetation management strategies.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02493" title="Abstract">arXiv:2311.02493</a> [<a href="/pdf/2311.02493" title="Download PDF">pdf</a>, <a href="/ps/2311.02493" title="Download PostScript">ps</a>, <a href="/format/2311.02493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A scientometric-inspired framework to analyze EurekAlert! press releases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Orduna-Malea%2C+E">Enrique Orduna-Malea</a>, 
<a href="/search/cs?searchtype=author&query=Costas%2C+R">Rodrigo Costas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 5 tables, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">Press releases about scholarly news are brief statements provided in advance
to the press, including a description of the most relevant findings of one or
more accepted scientific publications, usually under the condition that
journalists will adhere to an embargo until the publication date. The existence
of centralized platforms such as EurekAlert! allows press releases to be
disseminated online as independent news articles. Press releases can include
additional material (e.g., interviews, commentaries, explanatory tables,
figures, media, recommended readings), which turn them into online objects with
analytical value of their own. The objective of this work is to illustrate how
press releases can be quantitatively analyzed applying similar tools and
approaches as those applied in scientometric research (SCI). To achieve this
goal, a scientometric inspired analytical framework is proposed based on the
formulation of spaces of interaction of objects, actors, and impacts. As such,
the framework proposed considers press releases as science communication (SCO)
objects, produced by different SCO actors (e.g., journalists), and the subject
of receiving impact (e.g., tweets, links). To carry out this analysis, all
press releases published by EurekAlert! from 1996 until 2021 (455,703 press
releases), all tweets including at least one URL referring to a EurekAlert!
press release (1,364,563 tweets), and all webpages with at least one URL
referring to a EurekAlert! press release (54,089,233 webpages) have been
studied. We argue that the large volume of press releases published and their
online dissemination make these objects relevant in the measurement of SCO-SCI
interactions.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02495" title="Abstract">arXiv:2311.02495</a> [<a href="/pdf/2311.02495" title="Download PDF">pdf</a>, <a href="/ps/2311.02495" title="Download PostScript">ps</a>, <a href="/format/2311.02495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Quantification in Multivariable Regression for Material  Property Prediction with Bayesian Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=li%2C+L">Longze li</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+J">Jiang Chang</a>, 
<a href="/search/cs?searchtype=author&query=Vakanski%2C+A">Aleksandar Vakanski</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+M">Min Xian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Materials Science (cond-mat.mtrl-sci)

</div>
<p class="mathjax">With the increased use of data-driven approaches and machine learning-based
methods in material science, the importance of reliable uncertainty
quantification (UQ) of the predicted variables for informed decision-making
cannot be overstated. UQ in material property prediction poses unique
challenges, including the multi-scale and multi-physics nature of advanced
materials, intricate interactions between numerous factors, limited
availability of large curated datasets for model training, etc. Recently,
Bayesian Neural Networks (BNNs) have emerged as a promising approach for UQ,
offering a probabilistic framework for capturing uncertainties within neural
networks. In this work, we introduce an approach for UQ within physics-informed
BNNs, which integrates knowledge from governing laws in material modeling to
guide the models toward physically consistent predictions. To evaluate the
effectiveness of this approach, we present case studies for predicting the
creep rupture life of steel alloys. Experimental validation with three datasets
of collected measurements from creep tests demonstrates the ability of BNNs to
produce accurate point and uncertainty estimates that are competitive or exceed
the performance of the conventional method of Gaussian Process Regression.
Similarly, we evaluated the suitability of BNNs for UQ in an active learning
application and reported competitive performance. The most promising framework
for creep life prediction is BNNs based on Markov Chain Monte Carlo
approximation of the posterior distribution of network parameters, as it
provided more reliable results in comparison to BNNs based on variational
inference approximation or related NNs with probabilistic outputs. The codes
are available at:
https://github.com/avakanski/Creep-uncertainty-quantification.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02496" title="Abstract">arXiv:2311.02496</a> [<a href="/pdf/2311.02496" title="Download PDF">pdf</a>, <a href="/format/2311.02496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LocoMuJoCo: A Comprehensive Imitation Learning Benchmark for Locomotion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Al-Hafez%2C+F">Firas Al-Hafez</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+G">Guoping Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Jan Peters</a>, 
<a href="/search/cs?searchtype=author&query=Tateo%2C+D">Davide Tateo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://github.com/robfiras/loco-mujoco">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Imitation Learning (IL) holds great promise for enabling agile locomotion in
embodied agents. However, many existing locomotion benchmarks primarily focus
on simplified toy tasks, often failing to capture the complexity of real-world
scenarios and steering research toward unrealistic domains. To advance research
in IL for locomotion, we present a novel benchmark designed to facilitate
rigorous evaluation and comparison of IL algorithms. This benchmark encompasses
a diverse set of environments, including quadrupeds, bipeds, and
musculoskeletal human models, each accompanied by comprehensive datasets, such
as real noisy motion capture data, ground truth expert data, and ground truth
sub-optimal data, enabling evaluation across a spectrum of difficulty levels.
To increase the robustness of learned agents, we provide an easy interface for
dynamics randomization and offer a wide range of partially observable tasks to
train agents across different embodiments. Finally, we provide handcrafted
metrics for each task and ship our benchmark with state-of-the-art baseline
algorithms to ease evaluation and enable fast benchmarking.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02499" title="Abstract">arXiv:2311.02499</a> [<a href="/pdf/2311.02499" title="Download PDF">pdf</a>, <a href="/ps/2311.02499" title="Download PostScript">ps</a>, <a href="/format/2311.02499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Chat GPT solve a Linguistics Exam?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ronan%2C+P">Patricia Ronan</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+G">Gerold Schneider</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures, presentation at ISLE (International Society for the Linguistics of English) 7, 2023, Brisbane
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The present study asks if ChatGPT4, the version of ChatGPT which uses the
language model GPT4, can successfully solve introductory linguistic exams.
Previous exam questions of an Introduction to Linguistics course at a German
university are used to test this. The exam questions were fed into ChatGPT4
with only minimal preprocessing. The results show that the language model is
very successful in the interpretation even of complex and nested tasks. It
proved surprisingly successful in the task of broad phonetic transcription, but
performed less well in the analysis of morphemes and phrases. In simple cases
it performs sufficiently well, but rarer cases, particularly with missing
one-to-one correspondence, are currently treated with mixed results. The model
is not yet able to deal with visualisations, such as the analysis or generation
of syntax trees. More extensive preprocessing, which translates these tasks
into text data, allow the model to also solve these tasks successfully.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02500" title="Abstract">arXiv:2311.02500</a> [<a href="/pdf/2311.02500" title="Download PDF">pdf</a>, <a href="/format/2311.02500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Laser-Camera Scanning for High-Precision Fruit Localization in  Robotic Harvesting: System Design and Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaixiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+P">Pengyu Chu</a>, 
<a href="/search/cs?searchtype=author&query=Lammers%2C+K">Kyle Lammers</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhaojian Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+R">Renfu Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Robust and effective fruit detection and localization is essential for
robotic harvesting systems. While extensive research efforts have been devoted
to improving fruit detection, less emphasis has been placed on the fruit
localization aspect, which is a crucial yet challenging task due to limited
depth accuracy from existing sensor measurements in the natural orchard
environment with variable lighting conditions and foliage/branch occlusions. In
this paper, we present the system design and calibration of an Active
LAser-Camera Scanner (ALACS), a novel perception module for robust and
high-precision fruit localization. The hardware of ALACS mainly consists of a
red line laser, an RGB camera, and a linear motion slide, which are seamlessly
integrated into an active scanning scheme where a dynamic-targeting
laser-triangulation principle is employed. A high-fidelity extrinsic model is
developed to pair the laser illumination and the RGB camera, enabling precise
depth computation when the target is captured by both sensors. A random sample
consensus-based robust calibration scheme is then designed to calibrate the
model parameters based on collected data. Comprehensive evaluations are
conducted to validate the system model and calibration scheme. The results show
that the proposed calibration method can detect and remove data outliers to
achieve robust parameter computation, and the calibrated ALACS system is able
to achieve high-precision localization with millimeter-level accuracy.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02502" title="Abstract">arXiv:2311.02502</a> [<a href="/pdf/2311.02502" title="Download PDF">pdf</a>, <a href="/format/2311.02502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAAIP: Multi-Agent Adversarial Interaction Priors for imitation from  fighting demonstrations for physics-based characters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Younes%2C+M">Mohamed Younes</a>, 
<a href="/search/cs?searchtype=author&query=Kijak%2C+E">Ewa Kijak</a>, 
<a href="/search/cs?searchtype=author&query=Kulpa%2C+R">Richard Kulpa</a>, 
<a href="/search/cs?searchtype=author&query=Malinowski%2C+S">Simon Malinowski</a>, 
<a href="/search/cs?searchtype=author&query=Multon%2C+F">Franck Multon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SCA'23, Supplementary video: <a href="https://youtu.be/wQfIiw_rQ3w">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM SIGGRAPH / Eurographics Symposium on Computer Animation (SCA),
  August 4-6, 2023, Los Angeles, CA, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Simulating realistic interaction and motions for physics-based characters is
of great interest for interactive applications, and automatic secondary
character animation in the movie and video game industries. Recent works in
reinforcement learning have proposed impressive results for single character
simulation, especially the ones that use imitation learning based techniques.
However, imitating multiple characters interactions and motions requires to
also model their interactions. In this paper, we propose a novel Multi-Agent
Generative Adversarial Imitation Learning based approach that generalizes the
idea of motion imitation for one character to deal with both the interaction
and the motions of the multiple physics-based characters. Two unstructured
datasets are given as inputs: 1) a single-actor dataset containing motions of a
single actor performing a set of motions linked to a specific application, and
2) an interaction dataset containing a few examples of interactions between
multiple actors. Based on these datasets, our system trains control policies
allowing each character to imitate the interactive skills associated with each
actor, while preserving the intrinsic style. This approach has been tested on
two different fighting styles, boxing and full-body martial art, to demonstrate
the ability of the method to imitate different styles.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02503" title="Abstract">arXiv:2311.02503</a> [<a href="/pdf/2311.02503" title="Download PDF">pdf</a>, <a href="/format/2311.02503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MapSeg: Segmentation guided structured model for online HD map  construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Mingchao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yin Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Linghai Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The development of online high-definition maps is significant since they
provide real-time, accurate, and updatable geographic information for
location-based applications, such as autonomous driving and intelligent
transportation, thus improving the performance and reliability of these
applications. Previous works, such as VectorMapNet and MapTR, show that direct
model generation of vectorized HD maps is a promising solution. However, these
methods did not take into account the usage of global semantic information to
improve map construction accuracy. To address this limitation, we propose a
segmentation-guided structured model (MapSeg) for online HD map construction.
Specifically, we added a UV segmentation module (USM) and a BEV segmentation
module (BSM) based on the MapTR structure, enabling the model to better capture
the semantic information.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02506" title="Abstract">arXiv:2311.02506</a> [<a href="/pdf/2311.02506" title="Download PDF">pdf</a>, <a href="/format/2311.02506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Hierarchical Transformers for Pedestrian Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kiruga%2C+A">Amani Kiruga</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xi Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Computer Vision and Pattern Recognition Conference Workshop (CVPRW) 2023 AVA: Accessibility, Vision, and Autonomy Meet
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose a methodology to address the challenge of instance segmentation in
autonomous systems, specifically targeting accessibility and inclusivity. Our
approach utilizes a non-hierarchical Vision Transformer variant, EVA-02,
combined with a Cascade Mask R-CNN mask head. Through fine-tuning on the AVA
instance segmentation challenge dataset, we achieved a promising mean Average
Precision (mAP) of 52.68\% on the test set. Our results demonstrate the
efficacy of ViT-based architectures in enhancing vision capabilities and
accommodating the unique needs of individuals with disabilities.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02507" title="Abstract">arXiv:2311.02507</a> [<a href="/pdf/2311.02507" title="Download PDF">pdf</a>, <a href="/ps/2311.02507" title="Download PostScript">ps</a>, <a href="/format/2311.02507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear orbital stability of discrete shock profiles for systems of  conservation laws
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Coeuret%2C+L">Lucas Coeuret</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 75 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">We prove the linear orbital stability of spectrally stable stationary
discrete shock profiles for conservative finite difference schemes applied to
systems of conservation laws. The proof relies on a precise description of the
pointwise asymptotic behavior of the Green's function associated with those
discrete shock profiles, improving on the result of Godillon [God03]. The main
novelty of this stability result is that it applies for a fairly large family
of schemes that introduce some artificial viscosity and most importantly, that
we do not impose any weakness assumption on the shock.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02508" title="Abstract">arXiv:2311.02508</a> [<a href="/pdf/2311.02508" title="Download PDF">pdf</a>, <a href="/format/2311.02508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dissipative quadratizations of polynomial ODE systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cai%2C+Y">Yubo Cai</a>, 
<a href="/search/eess?searchtype=author&query=Pogudin%2C+G">Gleb Pogudin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Symbolic Computation (cs.SC); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Quadratization refers to a transformation of an arbitrary system of
polynomial ordinary differential equations to a system with at most quadratic
right-hand side. Such a transformation unveils new variables and model
structures that facilitate model analysis, simulation, and control and offers a
convenient parameterization for data-driven approaches. Quadratization
techniques have found applications in diverse fields, including systems theory,
fluid mechanics, chemical reaction modeling, and mathematical analysis.
<br />In this study, we focus on quadratizations that preserve the stability
properties of the original model, specifically dissipativity at given
equilibria. This preservation is desirable in many applications of
quadratization including reachability analysis and synthetic biology. We
establish the existence of dissipativity-preserving quadratizations, develop an
algorithm for their computation, and demonstrate it in several case studies.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02510" title="Abstract">arXiv:2311.02510</a> [<a href="/pdf/2311.02510" title="Download PDF">pdf</a>, <a href="/format/2311.02510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anthropomorphic Grasping with Neural Object Shape Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hidalgo-Carvajal%2C+D">Diego Hidalgo-Carvajal</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hanzhi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bettelani%2C+G+C">Gemma C. Bettelani</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+J">Jaesug Jung</a>, 
<a href="/search/cs?searchtype=author&query=Zavaglia%2C+M">Melissa Zavaglia</a>, 
<a href="/search/cs?searchtype=author&query=Busse%2C+L">Laura Busse</a>, 
<a href="/search/cs?searchtype=author&query=Naceri%2C+A">Abdeldjallil Naceri</a>, 
<a href="/search/cs?searchtype=author&query=Leutenegger%2C+S">Stefan Leutenegger</a>, 
<a href="/search/cs?searchtype=author&query=Haddadin%2C+S">Sami Haddadin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to RA-L 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The progressive prevalence of robots in human-suited environments has given
rise to a myriad of object manipulation techniques, in which dexterity plays a
paramount role. It is well-established that humans exhibit extraordinary
dexterity when handling objects. Such dexterity seems to derive from a robust
understanding of object properties (such as weight, size, and shape), as well
as a remarkable capacity to interact with them. Hand postures commonly
demonstrate the influence of specific regions on objects that need to be
grasped, especially when objects are partially visible. In this work, we
leverage human-like object understanding by reconstructing and completing their
full geometry from partial observations, and manipulating them using a 7-DoF
anthropomorphic robot hand. Our approach has significantly improved the
grasping success rates of baselines with only partial reconstruction by nearly
30% and achieved over 150 successful grasps with three different object
categories. This demonstrates our approach's consistent ability to predict and
execute grasping postures based on the completed object shapes from various
directions and positions in real-world scenarios. Our work opens up new
possibilities for enhancing robotic applications that require precise grasping
and manipulation skills of real-world reconstructed objects.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02511" title="Abstract">arXiv:2311.02511</a> [<a href="/pdf/2311.02511" title="Download PDF">pdf</a>, <a href="/ps/2311.02511" title="Download PostScript">ps</a>, <a href="/format/2311.02511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EU COST Action on future generation optical wireless communication  technologies, 2nd White paper
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghassemlooy%2C+Z">Z. Ghassemlooy</a>, 
<a href="/search/cs?searchtype=author&query=Khalighi%2C+M+A">M. A. Khalighi</a>, 
<a href="/search/cs?searchtype=author&query=Zvanovec%2C+S">S. Zvanovec</a>, 
<a href="/search/cs?searchtype=author&query=Shrestha%2C+A">A. Shrestha</a>, 
<a href="/search/cs?searchtype=author&query=Ortega%2C+B">B. Ortega</a>, 
<a href="/search/cs?searchtype=author&query=Petkovic%2C+M">M. Petkovic</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+X">X. Pang</a>, 
<a href="/search/cs?searchtype=author&query=Sirtori%2C+C">C. Sirtori</a>, 
<a href="/search/cs?searchtype=author&query=Orsucci%2C+D">D. Orsucci</a>, 
<a href="/search/cs?searchtype=author&query=Shrestha%2C+A">A. Shrestha</a>, 
<a href="/search/cs?searchtype=author&query=Moll%2C+F">F. Moll</a>, 
<a href="/search/cs?searchtype=author&query=Cossu%2C+G">G. Cossu</a>, 
<a href="/search/cs?searchtype=author&query=Spirito%2C+V">V. Spirito</a>, 
<a href="/search/cs?searchtype=author&query=Ninos%2C+M+P">M. P. Ninos</a>, 
<a href="/search/cs?searchtype=author&query=Ciaramella%2C+E">E. Ciaramella</a>, 
<a href="/search/cs?searchtype=author&query=Bas%2C+J">J. Bas</a>, 
<a href="/search/cs?searchtype=author&query=Amay%2C+M">M. Amay</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">S. Huang</a>, 
<a href="/search/cs?searchtype=author&query=Safari%2C+M">M. Safari</a>, 
<a href="/search/cs?searchtype=author&query=Gutema%2C+T">T. Gutema</a>, 
<a href="/search/cs?searchtype=author&query=Popoola%2C+W">W. Popoola</a>, 
<a href="/search/cs?searchtype=author&query=Matus%2C+V">Vicente Matus</a>, 
<a href="/search/cs?searchtype=author&query=Rabadan%2C+J">Jose Rabadan</a>, 
<a href="/search/cs?searchtype=author&query=Perez-Jimenez%2C+R">Rafael Perez-Jimenez</a>, 
<a href="/search/cs?searchtype=author&query=Panayirci%2C+E">E. Panayirci</a>, 
<a href="/search/cs?searchtype=author&query=Diamantoulakis%2C+P+D">P. D. Diamantoulakis</a>, 
<a href="/search/cs?searchtype=author&query=Haas%2C+H">H. Haas</a>, 
<a href="/search/cs?searchtype=author&query=Ijeh%2C+I+C">I. C. Ijeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP); Optics (physics.optics); Quantum Physics (quant-ph)

</div>
<p class="mathjax">NEWFOCUS is an EU COST Action targeted at exploring radical solutions that
could influence the design of future wireless networks. The project aims to
address some of the challenges associated with optical wireless communication
(OWC) and to establish it as a complementary technology to the radio frequency
(RF)-based wireless systems in order to meet the demanding requirements of the
fifth generation (5G) and the future sixth generation (6G) backhaul and access
networks. Only 6G will be able to widely serve the exponential growth in
connected devices (i.e., more than 500 billion) in 2030, real-time holographic
communication, future virtual reality, etc. Space is emerging as the new
frontier in 5 and 6G and beyond communication networks, where it offers
high-speed wireless coverage to remote areas both in lands and sees. This
activity is supported by the recent development of low-altitude Earth orbit
satellite mega-constellations. The focus of this 2nd White Paper is on the use
of OWC as an enabling technology for medium- and long-range links for
deployment in (i) smart-cities and intelligent transportation systems; (ii)
first- and last-mile access and backhaul/fronthaul wireless networks; (iii)
hybrid free-space optics/RF adaptive wireless connections; (iv)
space-to-ground, inter-satellite, ground-to-air, and air-to-air communications;
and (v) underwater communications.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02512" title="Abstract">arXiv:2311.02512</a> [<a href="/pdf/2311.02512" title="Download PDF">pdf</a>, <a href="/ps/2311.02512" title="Download PostScript">ps</a>, <a href="/format/2311.02512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cryptanalysis of Nikooghadam et al.&#x27;s lightweight authentication  protocol for Internet of Drones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jafarian%2C+I">Iman Jafarian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The Internet of Drones has emerged as a transformative technology with
applications spanning various domains, including surveillance, delivery
services, and disaster management. Secure communication between controller
users and drones is paramount to ensure the transmitted data's confidentiality,
integrity, and authenticity. Key agreement protocols are crucial in
establishing secure communication channels between users and drones, enabling
them to exchange sensitive information and control their operations securely.
Recently Nikooghadam et al. proposed a lightweight mutual authentication and
key agreement protocol for the Internet of drones. In this article, we provide
a descriptive analysis of their proposed scheme and prove that Nikooghadam et
al.'s scheme is vulnerable to user tracking attacks and stolen verifier
attacks.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02516" title="Abstract">arXiv:2311.02516</a> [<a href="/pdf/2311.02516" title="Download PDF">pdf</a>, <a href="/format/2311.02516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forward $&#x3c7;^2$ Divergence Based Variational Importance Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengrui Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yule Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weihan Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+A">Anqi Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation (stat.CO); Machine Learning (stat.ML)

</div>
<p class="mathjax">Maximizing the log-likelihood is a crucial aspect of learning latent variable
models, and variational inference (VI) stands as the commonly adopted method.
However, VI can encounter challenges in achieving a high log-likelihood when
dealing with complicated posterior distributions. In response to this
limitation, we introduce a novel variational importance sampling (VIS) approach
that directly estimates and maximizes the log-likelihood. VIS leverages the
optimal proposal distribution, achieved by minimizing the forward $\chi^2$
divergence, to enhance log-likelihood estimation. We apply VIS to various
popular latent variable models, including mixture models, variational
auto-encoders, and partially observable generalized linear models. Results
demonstrate that our approach consistently outperforms state-of-the-art
baselines, both in terms of log-likelihood and model parameter estimation.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02520" title="Abstract">arXiv:2311.02520</a> [<a href="/pdf/2311.02520" title="Download PDF">pdf</a>, <a href="/ps/2311.02520" title="Download PostScript">ps</a>, <a href="/format/2311.02520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-Source Shortest Paths with Negative Real Weights in  $\tilde{O}(mn^{8/9})$ Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fineman%2C+J+T">Jeremy T. Fineman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">This paper presents a randomized algorithm for the problem of single-source
shortest paths on directed graphs with real (both positive and negative) edge
weights. Given an input graph with $n$ vertices and $m$ edges, the algorithm
completes in $\tilde{O}(mn^{8/9})$ time with high probability. For
real-weighted graphs, this result constitutes the first asymptotic improvement
over the classic $O(mn)$-time algorithm variously attributed to Shimbel,
Bellman, Ford, and Moore.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02523" title="Abstract">arXiv:2311.02523</a> [<a href="/pdf/2311.02523" title="Download PDF">pdf</a>, <a href="/format/2311.02523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniTSFace: Unified Threshold Integrated Sample-to-Sample Loss for Face  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qiufu Li</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xi Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiancan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Linlin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+J">Jinming Duan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Neurips 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Sample-to-class-based face recognition models can not fully explore the
cross-sample relationship among large amounts of facial images, while
sample-to-sample-based models require sophisticated pairing processes for
training. Furthermore, neither method satisfies the requirements of real-world
face verification applications, which expect a unified threshold separating
positive from negative facial pairs. In this paper, we propose a unified
threshold integrated sample-to-sample based loss (USS loss), which features an
explicit unified threshold for distinguishing positive from negative pairs.
Inspired by our USS loss, we also derive the sample-to-sample based softmax and
BCE losses, and discuss their relationship. Extensive evaluation on multiple
benchmark datasets, including MFR, IJB-C, LFW, CFP-FP, AgeDB, and MegaFace,
demonstrates that the proposed USS loss is highly efficient and can work
seamlessly with sample-to-class-based losses. The embedded loss (USS and
sample-to-class Softmax loss) overcomes the pitfalls of previous approaches and
the trained facial model UniTSFace exhibits exceptional performance,
outperforming state-of-the-art methods, such as CosFace, ArcFace, VPL,
AnchorFace, and UNPG. Our code is available.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02525" title="Abstract">arXiv:2311.02525</a> [<a href="/pdf/2311.02525" title="Download PDF">pdf</a>, <a href="/format/2311.02525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QOCO: A QoE-Oriented Computation Offloading Algorithm based on Deep  Reinforcement Learning for Mobile Edge Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahmati%2C+I">Iman Rahmati</a>, 
<a href="/search/cs?searchtype=author&query=Shah-Mansouri%2C+H">Hamed Shah-Mansouri</a>, 
<a href="/search/cs?searchtype=author&query=Movaghar%2C+A">Ali Movaghar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the realm of mobile edge computing (MEC), efficient computation task
offloading plays a pivotal role in ensuring a seamless quality of experience
(QoE) for users. Maintaining a high QoE is paramount in today's interconnected
world, where users demand responsive and reliable services. This challenge
stands as one of the most primary key factors contributing to handling dynamic
and uncertain mobile environment. In this study, we delve into computation
offloading in MEC systems, where strict task processing deadlines and energy
constraints can adversely affect the system performance. We formulate the
computation task offloading problem as a Markov decision process (MDP) to
maximize the long-term QoE of each user individually. We propose a
decentralized QoE-oriented computation offloading (QOCO) algorithm based on
deep reinforcement learning (DRL) that empowers mobile devices to make their
offloading decisions without requiring knowledge of decisions made by other
devices. Through numerical studies, we evaluate the performance of QOCO.
Simulation results validate that the QOCO algorithm efficiently exploits the
computational resources of edge nodes. Consequently, it can complete 14% more
tasks and reduce task delay and energy consumption by 9% and 6%, respectively.
These together contribute to a significant improvement of at least 37% in
average QoE compared to an existing algorithm.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02527" title="Abstract">arXiv:2311.02527</a> [<a href="/pdf/2311.02527" title="Download PDF">pdf</a>, <a href="/format/2311.02527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear Parameter-Varying Modeling for Soft Pneumatic Actuators and  Data-Driven Parameter Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wu-Te Yang</a>, 
<a href="/search/cs?searchtype=author&query=Stuart%2C+H">Hannah Stuart</a>, 
<a href="/search/cs?searchtype=author&query=Kurkcu%2C+B">Burak Kurkcu</a>, 
<a href="/search/cs?searchtype=author&query=Tomizuka%2C+M">Masayoshi Tomizuka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Accurately modeling soft robots remains a challenge due to their inherent
nonlinear behavior and parameter variations. This paper presents a novel
approach to modeling soft pneumatic actuators using a nonlinear
parameter-varying framework. The research begins by introducing Ludwick's Law,
providing a more accurate representation of the complex mechanical behavior
exhibited by soft materials. Three key material properties, namely Young's
modulus, tensile stress, and mixed viscosity, are utilized to estimate the
parameter inside the nonlinear model using the least squares method.
Subsequently, a nonlinear dynamic model for soft actuators is constructed by
applying Ludwick's Law. To validate the accuracy and effectiveness of the
proposed method, experimental validations are performed. We perform several
experiments, demonstrating the model's capabilities in predicting the dynamical
behavior of soft pneumatic actuators. In conclusion, this work contributes to
the advancement of soft pneumatic actuator modeling that represents their
nonlinear behavior.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02531" title="Abstract">arXiv:2311.02531</a> [<a href="/pdf/2311.02531" title="Download PDF">pdf</a>, <a href="/format/2311.02531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of accessibility of open-source EHRs for visually impaired  users
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moncy%2C+M+M">Megha M. Moncy</a>, 
<a href="/search/cs?searchtype=author&query=Pilli%2C+M">Manya Pilli</a>, 
<a href="/search/cs?searchtype=author&query=Somasundaram%2C+M">Manasi Somasundaram</a>, 
<a href="/search/cs?searchtype=author&query=Purkayastha%2C+S">Saptarshi Purkayastha</a>, 
<a href="/search/cs?searchtype=author&query=Fulton%2C+C+R">Cathy R. Fulton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at the American Medical Informatics Association (AMIA) Symposium 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This study investigates the accessibility of open-source electronic health
record (EHR) systems for individuals who are visually impaired or blind.
Ensuring the accessibility of EHRs to visually impaired users is critical for
the diversity, equity, and inclusion of all users. The study used a combination
of automated and manual accessibility testing techniques like screen readers to
evaluate the accessibility of three widely used open-source EHR systems. Our
assessment focused on the performance of three popular screen readers,
including JAWS (Windows), NVDA (Windows), and Apple VoiceOver (OSX). The
evaluation revealed that although each of the three systems was partially
accessible, there is room for improvement, particularly regarding keyboard
navigation and screen reader compatibility. The study concludes with
recommendations for making EHR systems more inclusive for all users and more
accessible.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02535" title="Abstract">arXiv:2311.02535</a> [<a href="/pdf/2311.02535" title="Download PDF">pdf</a>, <a href="/format/2311.02535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TokenMotion: Motion-Guided Vision Transformer for Video Camouflaged  Object Detection Via Learnable Token Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zifan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Tavakoli%2C+E+B">Erfan Bank Tavakoli</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Meida Chen</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+S">Suya You</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+R">Raghuveer Rao</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+S">Sanjeev Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+F">Fengbo Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The area of Video Camouflaged Object Detection (VCOD) presents unique
challenges in the field of computer vision due to texture similarities between
target objects and their surroundings, as well as irregular motion patterns
caused by both objects and camera movement. In this paper, we introduce
TokenMotion (TMNet), which employs a transformer-based model to enhance VCOD by
extracting motion-guided features using a learnable token selection. Evaluated
on the challenging MoCA-Mask dataset, TMNet achieves state-of-the-art
performance in VCOD. It outperforms the existing state-of-the-art method by a
12.8% improvement in weighted F-measure, an 8.4% enhancement in S-measure, and
a 10.7% boost in mean IoU. The results demonstrate the benefits of utilizing
motion-guided features via learnable token selection within a transformer-based
framework to tackle the intricate task of VCOD.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02536" title="Abstract">arXiv:2311.02536</a> [<a href="/pdf/2311.02536" title="Download PDF">pdf</a>, <a href="/format/2311.02536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augment the Pairs: Semantics-Preserving Image-Caption Pair Augmentation  for Grounding-Based Vision and Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jingru Yi</a>, 
<a href="/search/cs?searchtype=author&query=Uzkent%2C+B">Burak Uzkent</a>, 
<a href="/search/cs?searchtype=author&query=Ignat%2C+O">Oana Ignat</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zili Li</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+A">Amanmeet Garg</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Linda Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Grounding-based vision and language models have been successfully applied to
low-level vision tasks, aiming to precisely locate objects referred in
captions. The effectiveness of grounding representation learning heavily relies
on the scale of the training dataset. Despite being a useful data enrichment
strategy, data augmentation has received minimal attention in existing vision
and language tasks as augmentation for image-caption pairs is non-trivial. In
this study, we propose a robust phrase grounding model trained with
text-conditioned and text-unconditioned data augmentations. Specifically, we
apply text-conditioned color jittering and horizontal flipping to ensure
semantic consistency between images and captions. To guarantee image-caption
correspondence in the training samples, we modify the captions according to
pre-defined keywords when applying horizontal flipping. Additionally, inspired
by recent masked signal reconstruction, we propose to use pixel-level masking
as a novel form of data augmentation. While we demonstrate our data
augmentation method with MDETR framework, the proposed approach is applicable
to common grounding-based vision and language tasks with other frameworks.
Finally, we show that image encoder pretrained on large-scale image and
language datasets (such as CLIP) can further improve the results. Through
extensive experiments on three commonly applied datasets: Flickr30k, referring
expressions and GQA, our method demonstrates advanced performance over the
state-of-the-arts with various metrics. Code can be found in
https://github.com/amzn/augment-the-pairs-wacv2024.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02537" title="Abstract">arXiv:2311.02537</a> [<a href="/pdf/2311.02537" title="Download PDF">pdf</a>, <a href="/ps/2311.02537" title="Download PostScript">ps</a>, <a href="/format/2311.02537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contract Design With Safety Inspections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fallah%2C+A">Alireza Fallah</a>, 
<a href="/search/cs?searchtype=author&query=Jordan%2C+M+I">Michael I. Jordan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)

</div>
<p class="mathjax">We study the role of regulatory inspections in a contract design problem in
which a principal interacts separately with multiple agents. Each agent's
hidden action includes a dimension that determines whether they undertake an
extra costly step to adhere to safety protocols. The principal's objective is
to use payments combined with a limited budget for random inspections to
incentivize agents towards safety-compliant actions that maximize the
principal's utility. We first focus on the single-agent setting with linear
contracts and present an efficient algorithm that characterizes the optimal
linear contract, which includes both payment and random inspection. We further
investigate how the optimal contract changes as the inspection cost or the cost
of adhering to safety protocols vary. Notably, we demonstrate that the agent's
compensation increases if either of these costs escalates. However, while the
probability of inspection decreases with rising inspection costs, it
demonstrates nonmonotonic behavior as a function of the safety action costs.
Lastly, we explore the multi-agent setting, where the principal's challenge is
to determine the best distribution of inspection budgets among all agents. We
propose an efficient approach based on dynamic programming to find an
approximately optimal allocation of inspection budget across contracts. We also
design a random sequential scheme to determine the inspector's assignments,
ensuring each agent is inspected at most once and at the desired probability.
Finally, we present a case study illustrating that a mere difference in the
cost of inspection across various agents can drive the principal's decision to
forego inspecting a significant fraction of them, concentrating its entire
budget on those that are less costly to inspect.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02538" title="Abstract">arXiv:2311.02538</a> [<a href="/pdf/2311.02538" title="Download PDF">pdf</a>, <a href="/format/2311.02538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dense Video Captioning: A Survey of Techniques, Datasets and Evaluation  Protocols
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qasim%2C+I">Iqra Qasim</a>, 
<a href="/search/cs?searchtype=author&query=Horsch%2C+A">Alexander Horsch</a>, 
<a href="/search/cs?searchtype=author&query=Prasad%2C+D+K">Dilip K. Prasad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Untrimmed videos have interrelated events, dependencies, context, overlapping
events, object-object interactions, domain specificity, and other semantics
that are worth highlighting while describing a video in natural language. Owing
to such a vast diversity, a single sentence can only correctly describe a
portion of the video. Dense Video Captioning (DVC) aims at detecting and
describing different events in a given video. The term DVC originated in the
2017 ActivityNet challenge, after which considerable effort has been made to
address the challenge. Dense Video Captioning is divided into three sub-tasks:
(1) Video Feature Extraction (VFE), (2) Temporal Event Localization (TEL), and
(3) Dense Caption Generation (DCG). This review aims to discuss all the studies
that claim to perform DVC along with its sub-tasks and summarize their results.
We also discuss all the datasets that have been used for DVC. Lastly, we
highlight some emerging challenges and future trends in the field.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02542" title="Abstract">arXiv:2311.02542</a> [<a href="/pdf/2311.02542" title="Download PDF">pdf</a>, <a href="/format/2311.02542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VR-NeRF: High-Fidelity Virtualized Walkable Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Linning Xu</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+V">Vasu Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Laney%2C+W">William Laney</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+T">Tony Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+A">Aayush Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Changil Kim</a>, 
<a href="/search/cs?searchtype=author&query=Bul%C3%B2%2C+S+R">Samuel Rota Bul&#xf2;</a>, 
<a href="/search/cs?searchtype=author&query=Porzi%2C+L">Lorenzo Porzi</a>, 
<a href="/search/cs?searchtype=author&query=Kontschieder%2C+P">Peter Kontschieder</a>, 
<a href="/search/cs?searchtype=author&query=Bo%C5%BEi%C4%8D%2C+A">Alja&#x17e; Bo&#x17e;i&#x10d;</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zollh%C3%B6fer%2C+M">Michael Zollh&#xf6;fer</a>, 
<a href="/search/cs?searchtype=author&query=Richardt%2C+C">Christian Richardt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGGRAPH Asia 2023; Project page: <a href="https://vr-nerf.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We present an end-to-end system for the high-fidelity capture, model
reconstruction, and real-time rendering of walkable spaces in virtual reality
using neural radiance fields. To this end, we designed and built a custom
multi-camera rig to densely capture walkable spaces in high fidelity and with
multi-view high dynamic range images in unprecedented quality and density. We
extend instant neural graphics primitives with a novel perceptual color space
for learning accurate HDR appearance, and an efficient mip-mapping mechanism
for level-of-detail rendering with anti-aliasing, while carefully optimizing
the trade-off between quality and speed. Our multi-GPU renderer enables
high-fidelity volume rendering of our neural radiance field model at the full
VR resolution of dual 2K$\times$2K at 36 Hz on our custom demo machine. We
demonstrate the quality of our results on our challenging high-fidelity
datasets, and compare our method and datasets to existing baselines. We release
our dataset on our project website.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02544" title="Abstract">arXiv:2311.02544</a> [<a href="/pdf/2311.02544" title="Download PDF">pdf</a>, <a href="/ps/2311.02544" title="Download PostScript">ps</a>, <a href="/format/2311.02544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear Multi-objective Reinforcement Learning with Provable  Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+N">Nianli Peng</a>, 
<a href="/search/cs?searchtype=author&query=Fain%2C+B">Brandon Fain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We describe RA-E3 (Reward-Aware Explicit Explore or Exploit), an algorithm
with provable guarantees for solving a single or multi-objective Markov
Decision Process (MDP) where we want to maximize the expected value of a
nonlinear function over accumulated rewards. This allows us to model
fairness-aware welfare optimization for multi-objective reinforcement learning
as well as risk-aware reinforcement learning with nonlinear Von
Neumann-Morgenstern utility functions in the single objective setting. RA-E3
extends the classic E3 algorithm that solves MDPs with scalar rewards and
linear preferences. We first state a distinct reward-aware version of value
iteration that calculates a non-stationary policy that is approximately optimal
for a given model of the environment. This sub-procedure is based on an
extended form of Bellman optimality for nonlinear optimization that explicitly
considers time and current accumulated reward. We then describe how to use this
optimization procedure in a larger algorithm that must simultaneously learn a
model of the environment. The algorithm learns an approximately optimal policy
in time that depends polynomially on the MDP size, desired approximation, and
smoothness of the nonlinear function, and exponentially on the number of
objectives.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02546" title="Abstract">arXiv:2311.02546</a> [<a href="/pdf/2311.02546" title="Download PDF">pdf</a>, <a href="/ps/2311.02546" title="Download PostScript">ps</a>, <a href="/format/2311.02546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preliminary Analysis on Second-Order Convergence for Biased Policy  Gradient Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mu%2C+S">Siqiao Mu</a>, 
<a href="/search/cs?searchtype=author&query=Klabjan%2C+D">Diego Klabjan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Although the convergence of policy gradient algorithms to first-order
stationary points is well-established, the objective functions of reinforcement
learning problems are typically highly nonconvex. Therefore, recent work has
focused on two extensions: ``global" convergence guarantees under regularity
assumptions on the function structure, and second-order guarantees for escaping
saddle points and convergence to true local minima. Our work expands on the
latter approach, avoiding the restrictive assumptions of the former that may
not apply to general objective functions. Existing results on vanilla policy
gradient only consider an unbiased gradient estimator, but practical
implementations under the infinite-horizon discounted setting, including both
Monte-Carlo methods and actor-critic methods, involve gradient descent updates
with a biased gradient estimator. We present preliminary results on the
convergence of biased policy gradient algorithms to second-order stationary
points, leveraging proof techniques from nonconvex optimization. In our next
steps we aim to provide the first finite-time second-order convergence analysis
for actor-critic algorithms.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02549" title="Abstract">arXiv:2311.02549</a> [<a href="/pdf/2311.02549" title="Download PDF">pdf</a>, <a href="/format/2311.02549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D-Aware Talking-Head Video Motion Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+H">Haomiao Ni</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiachen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Y">Yuan Xue</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S+X">Sharon X. Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Motion transfer of talking-head videos involves generating a new video with
the appearance of a subject video and the motion pattern of a driving video.
Current methodologies primarily depend on a limited number of subject images
and 2D representations, thereby neglecting to fully utilize the multi-view
appearance features inherent in the subject video. In this paper, we propose a
novel 3D-aware talking-head video motion transfer network, Head3D, which fully
exploits the subject appearance information by generating a
visually-interpretable 3D canonical head from the 2D subject frames with a
recurrent network. A key component of our approach is a self-supervised 3D head
geometry learning module, designed to predict head poses and depth maps from 2D
subject video frames. This module facilitates the estimation of a 3D head in
canonical space, which can then be transformed to align with driving video
frames. Additionally, we employ an attention-based fusion network to combine
the background and other details from subject frames with the 3D subject head
to produce the synthetic target video. Our extensive experiments on two public
talking-head video datasets demonstrate that Head3D outperforms both 2D and 3D
prior arts in the practical cross-identity setting, with evidence showing it
can be readily adapted to the pose-controllable novel view synthesis task.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02551" title="Abstract">arXiv:2311.02551</a> [<a href="/pdf/2311.02551" title="Download PDF">pdf</a>, <a href="/ps/2311.02551" title="Download PostScript">ps</a>, <a href="/format/2311.02551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-dimensional Bid Learning for Energy Storage Bidding in Energy  Markets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jinyu Liu</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+H">Hongye Guo</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+Q">Qinghu Tang</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+E">En Lu</a>, 
<a href="/search/eess?searchtype=author&query=Cai%2C+Q">Qiuna Cai</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Q">Qixin Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, Accepted by the 15th International Conference on Applied Energy (ICAE2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)

</div>
<p class="mathjax">With the growing penetration of renewable energy resource, electricity market
prices have exhibited greater volatility. Therefore, it is important for Energy
Storage Systems(ESSs) to leverage the multidimensional nature of energy market
bids to maximize profitability. However, current learning methods cannot fully
utilize the high-dimensional price-quantity bids in the energy markets. To
address this challenge, we modify the common reinforcement learning(RL) process
by proposing a new bid representation method called Neural Network Embedded
Bids (NNEBs). NNEBs refer to market bids that are represented by monotonic
neural networks with discrete outputs. To achieve effective learning of NNEBs,
we first learn a neural network as a strategic mapping from the market price to
ESS power output with RL. Then, we re-train the network with two training
modifications to make the network output monotonic and discrete. Finally, the
neural network is equivalently converted into a high-dimensional bid for
bidding. We conducted experiments over real-world market datasets. Our studies
show that the proposed method achieves 18% higher profit than the baseline and
up to 78% profit of the optimal market bidder.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02552" title="Abstract">arXiv:2311.02552</a> [<a href="/pdf/2311.02552" title="Download PDF">pdf</a>, <a href="/format/2311.02552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IPVNet: Learning Implicit Point-Voxel Features for Open-Surface 3D  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arshad%2C+M+S">Mohammad Samiul Arshad</a>, 
<a href="/search/cs?searchtype=author&query=Beksi%2C+W+J">William J. Beksi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the Journal of Visual Communication and Image Representation. arXiv admin note: substantial text overlap with <a href="/abs/2210.15059">arXiv:2210.15059</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Reconstruction of 3D open surfaces (e.g., non-watertight meshes) is an
underexplored area of computer vision. Recent learning-based implicit
techniques have removed previous barriers by enabling reconstruction in
arbitrary resolutions. Yet, such approaches often rely on distinguishing
between the inside and outside of a surface in order to extract a zero level
set when reconstructing the target. In the case of open surfaces, this
distinction often leads to artifacts such as the artificial closing of surface
gaps. However, real-world data may contain intricate details defined by salient
surface gaps. Implicit functions that regress an unsigned distance field have
shown promise in reconstructing such open surfaces. Nonetheless, current
unsigned implicit methods rely on a discretized representation of the raw data.
This not only bounds the learning process to the representation's resolution,
but it also introduces outliers in the reconstruction. To enable accurate
reconstruction of open surfaces without introducing outliers, we propose a
learning-based implicit point-voxel model (IPVNet). IPVNet predicts the
unsigned distance between a surface and a query point in 3D space by leveraging
both raw point cloud data and its discretized voxel counterpart. Experiments on
synthetic and real-world public datasets demonstrates that IPVNet outperforms
the state of the art while producing far fewer outliers in the resulting
reconstruction.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02554" title="Abstract">arXiv:2311.02554</a> [<a href="/pdf/2311.02554" title="Download PDF">pdf</a>, <a href="/format/2311.02554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pilot-Based Key Distribution and Encryption for Secure Coherent Passive  Optical Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haide Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Ji Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Qingxin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+J">Jianrui Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yongqing Liao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Changyuan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhaohui Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been submitted to the Journal of Lightwave Technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The security issues of passive optical networks (PONs) have always been a
concern due to broadcast transmission. Physical-layer security enhancement for
the coherent PON should be as significant as improving transmission
performance. In this paper, we propose the advanced encryption standard (AES)
algorithm and geometric constellation shaping four-level pulse amplitude
modulation (GCS-PAM4) pilot-based key distribution for secure coherent PON. The
first bit of the GCS-PAM4 pilot is used for the hardware-efficient carrier
phase recovery (CPR), while the second bit is utilized for key distribution
without occupying the additional overhead. The key bits are encoded by the
polar code to ensure error-free distribution. Frequent key updates are
permitted for every codeword to improve the security of coherent PON. The
experimental results of the 200-Gbps secure coherent PON using digital
subcarrier multiplexing show that the GCS-PAM4 pilot-based key distribution
could be error-free at upstream transmission without occupying the additional
overhead and the eavesdropping would be prevented by AES algorithm at
downstream transmission. Moreover, there is almost no performance penalty on
the CPR using the GCS-PAM4 pilot compared to the binary phase shift keying
pilot.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02558" title="Abstract">arXiv:2311.02558</a> [<a href="/pdf/2311.02558" title="Download PDF">pdf</a>, <a href="/format/2311.02558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent 3D Map Reconstruction and Change Detection in Microgravity  with Free-Flying Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dinkel%2C+H">Holly Dinkel</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+J">Julia Di</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+J">Jamie Santos</a>, 
<a href="/search/cs?searchtype=author&query=Albee%2C+K">Keenan Albee</a>, 
<a href="/search/cs?searchtype=author&query=Borges%2C+P">Paulo Borges</a>, 
<a href="/search/cs?searchtype=author&query=Moreira%2C+M">Marina Moreira</a>, 
<a href="/search/cs?searchtype=author&query=Alexandrov%2C+O">Oleg Alexandrov</a>, 
<a href="/search/cs?searchtype=author&query=Coltin%2C+B">Brian Coltin</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+T">Trey Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures, Manuscript presented at the 74th International Astronautical Congress, IAC 2023, Baku, Azerbaijan, 2 - 6 October 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Assistive free-flyer robots autonomously caring for future crewed outposts --
such as NASA's Astrobee robots on the International Space Station (ISS) -- must
be able to detect day-to-day interior changes to track inventory, detect and
diagnose faults, and monitor the outpost status. This work presents a framework
for multi-agent cooperative mapping and change detection to enable robotic
maintenance of space outposts. One agent is used to reconstruct a 3D model of
the environment from sequences of images and corresponding depth information.
Another agent is used to periodically scan the environment for inconsistencies
against the 3D model. Change detection is validated after completing the
surveys using real image and pose data collected by Astrobee robots in a ground
testing environment and from microgravity aboard the ISS. This work outlines
the objectives, requirements, and algorithmic modules for the multi-agent
reconstruction system, including recommendations for its use by assistive
free-flyers aboard future microgravity outposts.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02559" title="Abstract">arXiv:2311.02559</a> [<a href="/pdf/2311.02559" title="Download PDF">pdf</a>, <a href="/format/2311.02559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rotation Invariant Transformer for Recognizing Object in UAVs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuoyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+M">Mang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+B">Bo Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM MM2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recognizing a target of interest from the UAVs is much more challenging than
the existing object re-identification tasks across multiple city cameras. The
images taken by the UAVs usually suffer from significant size difference when
generating the object bounding boxes and uncertain rotation variations.
Existing methods are usually designed for city cameras, incapable of handing
the rotation issue in UAV scenarios. A straightforward solution is to perform
the image-level rotation augmentation, but it would cause loss of useful
information when inputting the powerful vision transformer as patches. This
motivates us to simulate the rotation operation at the patch feature level,
proposing a novel rotation invariant vision transformer (RotTrans). This
strategy builds on high-level features with the help of the specificity of the
vision transformer structure, which enhances the robustness against large
rotation differences. In addition, we design invariance constraint to establish
the relationship between the original feature and the rotated features,
achieving stronger rotation invariance. Our proposed transformer tested on the
latest UAV datasets greatly outperforms the current state-of-the-arts, which is
5.9\% and 4.8\% higher than the highest mAP and Rank1. Notably, our model also
performs competitively for the person re-identification task on traditional
city cameras. In particular, our solution wins the first place in the UAV-based
person re-recognition track in the Multi-Modal Video Reasoning and Analyzing
Competition held in ICCV 2021. Code is available at
https://github.com/whucsy/RotTrans.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02560" title="Abstract">arXiv:2311.02560</a> [<a href="/pdf/2311.02560" title="Download PDF">pdf</a>, <a href="/format/2311.02560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Treasure Hunt: Content-based Time Series Retrieval System for  Discovering Insights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeh%2C+C+M">Chin-Chia Michael Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huiyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xin Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yujie Fan</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+V">Vivian Lai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Der%2C+A">Audrey Der</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Z">Zhongfang Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Time series data is ubiquitous across various domains such as finance,
healthcare, and manufacturing, but their properties can vary significantly
depending on the domain they originate from. The ability to perform
Content-based Time Series Retrieval (CTSR) is crucial for identifying unknown
time series examples. However, existing CTSR works typically focus on
retrieving time series from a single domain database, which can be inadequate
if the user does not know the source of the query time series. This limitation
motivates us to investigate the CTSR problem in a scenario where the database
contains time series from multiple domains. To facilitate this investigation,
we introduce a CTSR benchmark dataset that comprises time series data from a
variety of domains, such as motion, power demand, and traffic. This dataset is
sourced from a publicly available time series classification dataset archive,
making it easily accessible to researchers in the field. We compare several
popular methods for modeling and retrieving time series data using this
benchmark dataset. Additionally, we propose a novel distance learning model
that outperforms the existing methods. Overall, our study highlights the
importance of addressing the CTSR problem across multiple domains and provides
a useful benchmark dataset for future research.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02561" title="Abstract">arXiv:2311.02561</a> [<a href="/pdf/2311.02561" title="Download PDF">pdf</a>, <a href="/format/2311.02561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ego-Network Transformer for Subsequence Classification in Time Series  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeh%2C+C+M">Chin-Chia Michael Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huiyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yujie Fan</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xin Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+V">Vivian Lai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Z">Zhongfang Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Keogh%2C+E">Eamonn Keogh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Time series classification is a widely studied problem in the field of time
series data mining. Previous research has predominantly focused on scenarios
where relevant or foreground subsequences have already been extracted, with
each subsequence corresponding to a single label. However, real-world time
series data often contain foreground subsequences that are intertwined with
background subsequences. Successfully classifying these relevant subsequences
requires not only distinguishing between different classes but also accurately
identifying the foreground subsequences amidst the background. To address this
challenge, we propose a novel subsequence classification method that represents
each subsequence as an ego-network, providing crucial nearest neighbor
information to the model. The ego-networks of all subsequences collectively
form a time series subsequence graph, and we introduce an algorithm to
efficiently construct this graph. Furthermore, we have demonstrated the
significance of enforcing temporal consistency in the prediction of adjacent
subsequences for the subsequence classification problem. To evaluate the
effectiveness of our approach, we conducted experiments using 128 univariate
and 30 multivariate time series datasets. The experimental results demonstrate
the superior performance of our method compared to alternative approaches.
Specifically, our method outperforms the baseline on 104 out of 158 datasets.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02563" title="Abstract">arXiv:2311.02563</a> [<a href="/pdf/2311.02563" title="Download PDF">pdf</a>, <a href="/format/2311.02563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time Series Synthesis Using the Matrix Profile for Anonymization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Der%2C+A">Audrey Der</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+C+M">Chin-Chia Michael Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huiyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Z">Zhongfang Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Keogh%2C+E">Eamonn Keogh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Publishing and sharing data is crucial for the data mining community,
allowing collaboration and driving open innovation. However, many researchers
cannot release their data due to privacy regulations or fear of leaking
confidential business information. To alleviate such issues, we propose the
Time Series Synthesis Using the Matrix Profile (TSSUMP) method, where
synthesized time series can be released in lieu of the original data. The
TSSUMP method synthesizes time series by preserving similarity join information
(i.e., Matrix Profile) while reducing the correlation between the synthesized
and the original time series. As a result, neither the values for the
individual time steps nor the local patterns (or shapes) from the original data
can be recovered, yet the resulting data can be used for downstream tasks that
data analysts are interested in. We concentrate on similarity joins because
they are one of the most widely applied time series data mining routines across
different data mining tasks. We test our method on a case study of ECG and
gender masking prediction. In this case study, the gender information is not
only removed from the synthesized time series, but the synthesized time series
also preserves enough information from the original time series. As a result,
unmodified data mining tools can obtain near-identical performance on the
synthesized time series as on the original time series.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02564" title="Abstract">arXiv:2311.02564</a> [<a href="/pdf/2311.02564" title="Download PDF">pdf</a>, <a href="/ps/2311.02564" title="Download PostScript">ps</a>, <a href="/format/2311.02564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relation Extraction Model Based on Semantic Enhancement Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Peiyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Junping Du</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Yingxia Shao</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Z">Zeli Guan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Relational extraction is one of the basic tasks related to information
extraction in the field of natural language processing, and is an important
link and core task in the fields of information extraction, natural language
understanding, and information retrieval. None of the existing relation
extraction methods can effectively solve the problem of triple overlap. The
CasAug model proposed in this paper based on the CasRel framework combined with
the semantic enhancement mechanism can solve this problem to a certain extent.
The CasAug model enhances the semantics of the identified possible subjects by
adding a semantic enhancement mechanism, First, based on the semantic coding of
possible subjects, pre-classify the possible subjects, and then combine the
subject lexicon to calculate the semantic similarity to obtain the similar
vocabulary of possible subjects. According to the similar vocabulary obtained,
each word in different relations is calculated through the attention mechanism.
For the contribution of the possible subject, finally combine the relationship
pre-classification results to weight the enhanced semantics of each
relationship to find the enhanced semantics of the possible subject, and send
the enhanced semantics combined with the possible subject to the object and
relationship extraction module. Complete the final relation triplet extraction.
The experimental results show that, compared with the baseline model, the
CasAug model proposed in this paper has improved the effect of relation
extraction, and CasAug's ability to deal with overlapping problems and extract
multiple relations is also better than the baseline model, indicating that the
semantic enhancement mechanism proposed in this paper It can further reduce the
judgment of redundant relations and alleviate the problem of triple overlap.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02565" title="Abstract">arXiv:2311.02565</a> [<a href="/pdf/2311.02565" title="Download PDF">pdf</a>, <a href="/format/2311.02565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KITS: Inductive Spatio-Temporal Kriging with Increment Training Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qianxiong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+C">Cheng Long</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+S">Sijie Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhishuai Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Sensors are commonly deployed to perceive the environment. However, due to
the high cost, sensors are usually sparsely deployed. Kriging is the tailored
task to infer the unobserved nodes (without sensors) using the observed source
nodes (with sensors). The essence of kriging task is transferability. Recently,
several inductive spatio-temporal kriging methods have been proposed based on
graph neural networks, being trained based on a graph built on top of observed
nodes via pretext tasks such as masking nodes out and reconstructing them.
However, the graph in training is inevitably much sparser than the graph in
inference that includes all the observed and unobserved nodes. The learned
pattern cannot be well generalized for inference, denoted as graph gap. To
address this issue, we first present a novel Increment training strategy:
instead of masking nodes (and reconstructing them), we add virtual nodes into
the training graph so as to mitigate the graph gap issue naturally.
Nevertheless, the empty-shell virtual nodes without labels could have
bad-learned features and lack supervision signals. To solve these issues, we
pair each virtual node with its most similar observed node and fuse their
features together; to enhance the supervision signal, we construct reliable
pseudo labels for virtual nodes. As a result, the learned pattern of virtual
nodes could be safely transferred to real unobserved nodes for reliable
kriging. We name our new Kriging model with Increment Training Strategy as
KITS. Extensive experiments demonstrate that KITS consistently outperforms
existing kriging methods by large margins, e.g., the improvement over MAE score
could be as high as 18.33%.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02566" title="Abstract">arXiv:2311.02566</a> [<a href="/pdf/2311.02566" title="Download PDF">pdf</a>, <a href="/ps/2311.02566" title="Download PostScript">ps</a>, <a href="/format/2311.02566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topic model based on co-occurrence word networks for unbalanced short  text datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chengjie Ma</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Junping Du</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+M">Meiyu Liang</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Z">Zeli Guan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We propose a straightforward solution for detecting scarce topics in
unbalanced short-text datasets. Our approach, named CWUTM (Topic model based on
co-occurrence word networks for unbalanced short text datasets), Our approach
addresses the challenge of sparse and unbalanced short text topics by
mitigating the effects of incidental word co-occurrence. This allows our model
to prioritize the identification of scarce topics (Low-frequency topics).
Unlike previous methods, CWUTM leverages co-occurrence word networks to capture
the topic distribution of each word, and we enhanced the sensitivity in
identifying scarce topics by redefining the calculation of node activity and
normalizing the representation of both scarce and abundant topics to some
extent. Moreover, CWUTM adopts Gibbs sampling, similar to LDA, making it easily
adaptable to various application scenarios. Our extensive experimental
validation on unbalanced short-text datasets demonstrates the superiority of
CWUTM compared to baseline approaches in discovering scarce topics. According
to the experimental results the proposed model is effective in early and
accurate detection of emerging topics or unexpected events on social platforms.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02570" title="Abstract">arXiv:2311.02570</a> [<a href="/pdf/2311.02570" title="Download PDF">pdf</a>, <a href="/format/2311.02570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BanMANI: A Dataset to Identify Manipulated Social Media News in Bangla
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kamruzzaman%2C+M">Mahammed Kamruzzaman</a>, 
<a href="/search/cs?searchtype=author&query=Shovon%2C+M+M+I">Md. Minul Islam Shovon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+G+L">Gene Louis Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Initial work has been done to address fake news detection and
misrepresentation of news in the Bengali language. However, no work in Bengali
yet addresses the identification of specific claims in social media news that
falsely manipulates a related news article. At this point, this problem has
been tackled in English and a few other languages, but not in the Bengali
language. In this paper, we curate a dataset of social media content labeled
with information manipulation relative to reference articles, called BanMANI.
The dataset collection method we describe works around the limitations of the
available NLP tools in Bangla. We expect these techniques will carry over to
building similar datasets in other low-resource languages. BanMANI forms the
basis both for evaluating the capabilities of existing NLP systems and for
training or fine-tuning new models specifically on this task. In our analysis,
we find that this task challenges current LLMs both under zero-shot and
fine-tuned settings.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02571" title="Abstract">arXiv:2311.02571</a> [<a href="/pdf/2311.02571" title="Download PDF">pdf</a>, <a href="/ps/2311.02571" title="Download PostScript">ps</a>, <a href="/format/2311.02571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Link residual closeness of graphs with fixed parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Leyou Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengli Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bo Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Completed June 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Link residual closeness is a newly proposed measure for network
vulnerability. In this model, vertices are perfectly reliable and the links
fail independently of each other. It measures the vulnerability even when the
removal of links does not disconnect the graph. In this paper, we characterize
those graphs that maximize the link residual closeness over the connected
graphs with fixed order and one parameters such as connectivity, edge
connectivity, bipartiteness, independence number, matching number, chromatic
number, number of vertices and number of cut edges.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02572" title="Abstract">arXiv:2311.02572</a> [<a href="/pdf/2311.02572" title="Download PDF">pdf</a>, <a href="/format/2311.02572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiple Object Tracking based on Occlusion-Aware Embedding Consistency  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yaoqi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+A">Axi Niu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Q">Qingsen Yan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jinqiu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanning Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The Joint Detection and Embedding (JDE) framework has achieved remarkable
progress for multiple object tracking. Existing methods often employ extracted
embeddings to re-establish associations between new detections and previously
disrupted tracks. However, the reliability of embeddings diminishes when the
region of the occluded object frequently contains adjacent objects or clutters,
especially in scenarios with severe occlusion. To alleviate this problem, we
propose a novel multiple object tracking method based on visual embedding
consistency, mainly including: 1) Occlusion Prediction Module (OPM) and 2)
Occlusion-Aware Association Module (OAAM). The OPM predicts occlusion
information for each true detection, facilitating the selection of valid
samples for consistency learning of the track's visual embedding. The OAAM
leverages occlusion cues and visual embeddings to generate two separate
embeddings for each track, guaranteeing consistency in both unoccluded and
occluded detections. By integrating these two modules, our method is capable of
addressing track interruptions caused by occlusion in online tracking
scenarios. Extensive experimental results demonstrate that our approach
achieves promising performance levels in both unoccluded and occluded tracking
scenarios.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02573" title="Abstract">arXiv:2311.02573</a> [<a href="/pdf/2311.02573" title="Download PDF">pdf</a>, <a href="/format/2311.02573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Group Testing for Accurate and Efficient Range-Based Near Neighbor  Search : An Adaptive Binary Splitting Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mittal%2C+K">Kashish Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+H">Harsh Shah</a>, 
<a href="/search/cs?searchtype=author&query=Rajwade%2C+A">Ajit Rajwade</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages (including Appendix)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This work presents an adaptive group testing framework for the range-based
high dimensional near neighbor search problem. The proposed method detects
high-similarity vectors from an extensive collection of high dimensional
vectors, where each vector represents an image descriptor. Our method
efficiently marks each item in the collection as neighbor or non-neighbor on
the basis of a cosine distance threshold without exhaustive search. Like other
methods in the domain of large scale retrieval, our approach exploits the
assumption that most of the items in the collection are unrelated to the query.
Unlike other methods, it does not assume a large difference between the cosine
similarity of the query vector with the least related neighbor and that with
the least unrelated non-neighbor. Following the procedure of binary splitting,
a multi-stage adaptive group testing algorithm, we split the set of items to be
searched into half at each step, and perform dot product tests on smaller and
smaller subsets, many of which we are able to prune away. We experimentally
show that our method achieves a speed-up over exhaustive search by a factor of
more than ten with an accuracy same as that of exhaustive search, on a variety
of large datasets. We present a theoretical analysis of the expected number of
distance computations per query and the probability that a pool with a certain
number of members will be pruned. In this way, our method exploits very useful
and practical distributional properties unlike other methods. In our method,
all required data structures are created purely offline. Moreover, our method
does not impose any strong assumptions on the number of true near neighbors, is
adaptible to streaming settings where new vectors are dynamically added to the
database, and does not require any parameter tuning.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02576" title="Abstract">arXiv:2311.02576</a> [<a href="/pdf/2311.02576" title="Download PDF">pdf</a>, <a href="/format/2311.02576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Feasible Dynamic Grasping: Leveraging Gaussian Process Distance  Field, SE(3) Equivariance and Riemannian Mixture Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+H+J">Ho Jin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Figueroa%2C+N">Nadia Figueroa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this paper, we present a novel approach towards feasible dynamic grasping
by leveraging Gaussian Process Distance Fields (GPDF), SE(3) equivariance, and
Riemannian Mixture Models. We seek to improve the grasping capabilities of
robots in dynamic tasks where objects may be moving. The proposed method
combines object shape reconstruction, grasp sampling, and grasp pose selection
to enable effective grasping in such scenarios. By utilizing GPDF, the approach
accurately models the shape and physical properties of objects, allowing for
precise grasp planning. SE(3) equivariance ensures that the sampled grasp poses
are equivariant to the object's pose. Additionally, Riemannian Gaussian Mixture
Models are employed to test reachability, providing a feasible and adaptable
grasping strategy. The sampled feasible grasp poses are used as targets for
novel task or joint space reactive controllers formulated by Gaussian Mixture
Models and Gaussian Processes, respectively. Experimental results demonstrate
the effectiveness of the proposed approach in generating feasible grasp poses
and successful grasping in dynamic environments.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02578" title="Abstract">arXiv:2311.02578</a> [<a href="/pdf/2311.02578" title="Download PDF">pdf</a>, <a href="/format/2311.02578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Sequencing of Documents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gervers%2C+M">Michael Gervers</a>, 
<a href="/search/cs?searchtype=author&query=Tilahun%2C+G">Gelila Tilahun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We outline an unsupervised method for temporal rank ordering of sets of
historical documents, namely American State of the Union Addresses and DEEDS, a
corpus of medieval English property transfer documents. Our method relies upon
effectively capturing the gradual change in word usage via a bandwidth estimate
for the non-parametric Generalized Linear Models (Fan, Heckman, and Wand,
1995). The number of possible rank orders needed to search through possible
cost functions related to the bandwidth can be quite large, even for a small
set of documents. We tackle this problem of combinatorial optimization using
the Simulated Annealing algorithm, which allows us to obtain the optimal
document temporal orders. Our rank ordering method significantly improved the
temporal sequencing of both corpora compared to a randomly sequenced baseline.
This unsupervised approach should enable the temporal ordering of undated
document sets.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02579" title="Abstract">arXiv:2311.02579</a> [<a href="/pdf/2311.02579" title="Download PDF">pdf</a>, <a href="/format/2311.02579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> mahaNLP: A Marathi Natural Language Processing Library
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Magdum%2C+V">Vidula Magdum</a>, 
<a href="/search/cs?searchtype=author&query=Dhekane%2C+O">Omkar Dhekane</a>, 
<a href="/search/cs?searchtype=author&query=Hiwarkhedkar%2C+S">Sharayu Hiwarkhedkar</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+S">Saloni Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+R">Raviraj Joshi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IJCNLP-AACL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present mahaNLP, an open-source natural language processing (NLP) library
specifically built for the Marathi language. It aims to enhance the support for
the low-resource Indian language Marathi in the field of NLP. It is an
easy-to-use, extensible, and modular toolkit for Marathi text analysis built on
state-of-the-art MahaBERT-based transformer models. Our work holds significant
importance as other existing Indic NLP libraries provide basic Marathi
processing support and rely on older models with restricted performance. Our
toolkit stands out by offering a comprehensive array of NLP tasks, encompassing
both fundamental preprocessing tasks and advanced NLP tasks like sentiment
analysis, NER, hate speech detection, and sentence completion. This paper
focuses on an overview of the mahaNLP framework, its features, and its usage.
This work is a part of the L3Cube MahaNLP initiative, more information about it
can be found at https://github.com/l3cube-pune/MarathiNLP .
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02581" title="Abstract">arXiv:2311.02581</a> [<a href="/pdf/2311.02581" title="Download PDF">pdf</a>, <a href="/format/2311.02581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Yet Another Generative Model For Room Impulse Response Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sungho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+H">Hyeong-Seok Choi</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kyogu Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WASPAA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Recent neural room impulse response (RIR) estimators typically comprise an
encoder for reference audio analysis and a generator for RIR synthesis.
Especially, it is the performance of the generator that directly influences the
overall estimation quality. In this context, we explore an alternate generator
architecture for improved performance. We first train an autoencoder with
residual quantization to learn a discrete latent token space, where each token
represents a small time-frequency patch of the RIR. Then, we cast the RIR
estimation problem as a reference-conditioned autoregressive token generation
task, employing transformer variants that operate across frequency, time, and
quantization depth axes. This way, we address the standard blind estimation
task and additional acoustic matching problem, which aims to find an RIR that
matches the source signal to the target signal's reverberation characteristics.
Experimental results show that our system is preferable to other baselines
across various evaluation metrics.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02582" title="Abstract">arXiv:2311.02582</a> [<a href="/pdf/2311.02582" title="Download PDF">pdf</a>, <a href="/ps/2311.02582" title="Download PostScript">ps</a>, <a href="/format/2311.02582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RecAGT: Shard Testable Codes with Adaptive Group Testing for Malicious  Nodes Identification in Sharding Permissioned Blockchain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dongyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lingzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Can Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 23rd International Conference on Algorithms and Architectures for Parallel Processing (ICA3PP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Recently, permissioned blockchain has been extensively explored in various
fields, such as asset management, supply chain, healthcare, and many others.
Many scholars are dedicated to improving its verifiability, scalability, and
performance based on sharding techniques, including grouping nodes and handling
cross-shard transactions. However, they ignore the node vulnerability problem,
i.e., there is no guarantee that nodes will not be maliciously controlled
throughout their life cycle. Facing this challenge, we propose RecAGT, a novel
identification scheme aimed at reducing communication overhead and identifying
potential malicious nodes. First, shard testable codes are designed to encode
the original data in case of a leak of confidential data. Second, a new
identity proof protocol is presented as evidence against malicious behavior.
Finally, adaptive group testing is chosen to identify malicious nodes. Notably,
our work focuses on the internal operation within the committee and can thus be
applied to any sharding permissioned blockchains. Simulation results show that
our proposed scheme can effectively identify malicious nodes with low
communication and computational costs.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02583" title="Abstract">arXiv:2311.02583</a> [<a href="/pdf/2311.02583" title="Download PDF">pdf</a>, <a href="/format/2311.02583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SSL-DG: Rethinking and Fusing Semi-supervised Learning and Domain  Generalization in Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zanting Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep learning-based medical image segmentation is an essential yet
challenging task in clinical practice, which arises from restricted access to
annotated data coupled with the occurrence of domain shifts. Previous attempts
have focused on isolated solutions, while disregarding their
inter-connectedness. In this paper, we rethink the relationship between
semi-supervised learning (SSL) and domain generalization (DG), which are the
cutting-edge approaches to address the annotated data-driven constraints and
the domain shift issues. Inspired by class-level representation, we show that
unseen target data can be represented by a linear combination of source data,
which can be achieved by simple data augmentation. The augmented data enrich
domain distributions while having semantic consistency, aligning with the
principles of consistency-based SSL. Accordingly, we propose SSL-DG, fusing DG
and SSL, to achieve cross-domain generalization with limited annotations.
Specifically, the global and focal region augmentation, together with an
augmentation scale-balancing mechanism, are used to construct a mask-based
domain diffusion augmentation module to significantly enrich domain diversity.
In order to obtain consistent predictions for the same source data in different
networks, we use uncertainty estimation and a deep mutual learning strategy to
enforce the consistent constraint. Extensive experiments including ablation
studies are designed to validate the proposed SSL-DG. The results demonstrate
that our SSL-DG significantly outperforms state-of-the-art solutions in two
challenging DG tasks with limited annotations. Code is available at
https://github.com/yezanting/SSL-DG.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02589" title="Abstract">arXiv:2311.02589</a> [<a href="/pdf/2311.02589" title="Download PDF">pdf</a>, <a href="/ps/2311.02589" title="Download PostScript">ps</a>, <a href="/format/2311.02589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impossibilities for Obviously Strategy-Proof Mechanisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ron%2C+S">Shiri Ron</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We explore the approximation power of deterministic obviously strategy-proof
mechanisms in auctions, where the objective is welfare maximization. A trivial
ascending auction on the grand bundle guarantees an approximation of
$\min\{m,n\}$ for all valuation classes, where $m$ is the number of items and
$n$ is the number of bidders. We focus on two classes of valuations considered
"simple": additive valuations and unit-demand valuations. For additive
valuations, Bade and Gonczarowski [EC'17] have shown that exact welfare
maximization is impossible. No impossibilities are known for unit-demand
valuations.
<br />We show that if bidders' valuations are additive or unit-demand, then no
obviously strategy-proof mechanism gives an approximation better than
$\min\{m,n\}$. Thus, the aforementioned trivial ascending auction on the grand
bundle is the optimal obviously strategy-proof mechanism. These results
illustrate a stark separation between the power of dominant-strategy and
obviously strategy-proof mechanisms. The reason for it is that for both of
these classes the dominant-strategy VCG mechanism does not only optimize the
welfare exactly, but is also "easy" both from a computation and communication
perspective.
<br />In addition, we prove tight impossibilities for unknown single-minded bidders
in a multi-unit auction and in a combinatorial auction. We show that in these
environments as well, a trivial ascending auction on the grand bundle is
optimal.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02597" title="Abstract">arXiv:2311.02597</a> [<a href="/pdf/2311.02597" title="Download PDF">pdf</a>, <a href="/format/2311.02597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FloodBrain: Flood Disaster Reporting by Web-based Retrieval Augmented  Generation with an LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Colverd%2C+G">Grace Colverd</a>, 
<a href="/search/cs?searchtype=author&query=Darm%2C+P">Paul Darm</a>, 
<a href="/search/cs?searchtype=author&query=Silverberg%2C+L">Leonard Silverberg</a>, 
<a href="/search/cs?searchtype=author&query=Kasmanoff%2C+N">Noah Kasmanoff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Version is the one submitted to Artificial Intelligence for Humanitarian Assistance and Disaster Response Workshop @Neurips2023. All authors contributed equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Fast disaster impact reporting is crucial in planning humanitarian
assistance. Large Language Models (LLMs) are well known for their ability to
write coherent text and fulfill a variety of tasks relevant to impact
reporting, such as question answering or text summarization. However, LLMs are
constrained by the knowledge within their training data and are prone to
generating inaccurate, or "hallucinated", information. To address this, we
introduce a sophisticated pipeline embodied in our tool FloodBrain
(floodbrain.com), specialized in generating flood disaster impact reports by
extracting and curating information from the web. Our pipeline assimilates
information from web search results to produce detailed and accurate reports on
flood events. We test different LLMs as backbones in our tool and compare their
generated reports to human-written reports on different metrics. Similar to
other studies, we find a notable correlation between the scores assigned by
GPT-4 and the scores given by human evaluators when comparing our generated
reports to human-authored ones. Additionally, we conduct an ablation study to
test our single pipeline components and their relevancy for the final reports.
With our tool, we aim to advance the use of LLMs for disaster impact reporting
and reduce the time for coordination of humanitarian efforts in the wake of
flood disasters.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02598" title="Abstract">arXiv:2311.02598</a> [<a href="/pdf/2311.02598" title="Download PDF">pdf</a>, <a href="/format/2311.02598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Camera Calibration via Homography Estimation with GNNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%27Amicantonio%2C+G">Giacomo D&#x27;Amicantonio</a>, 
<a href="/search/cs?searchtype=author&query=Bondarev%2C+E">Egor Bondarev</a>, 
<a href="/search/cs?searchtype=author&query=De+With%2C+P+H+N">Peter H.N. De With</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Over the past few decades, a significant rise of camera-based applications
for traffic monitoring has occurred. Governments and local administrations are
increasingly relying on the data collected from these cameras to enhance road
safety and optimize traffic conditions. However, for effective data
utilization, it is imperative to ensure accurate and automated calibration of
the involved cameras. This paper proposes a novel approach to address this
challenge by leveraging the topological structure of intersections. We propose
a framework involving the generation of a set of synthetic intersection
viewpoint images from a bird's-eye-view image, framed as a graph of virtual
cameras to model these images. Using the capabilities of Graph Neural Networks,
we effectively learn the relationships within this graph, thereby facilitating
the estimation of a homography matrix. This estimation leverages the
neighbourhood representation for any real-world camera and is enhanced by
exploiting multiple images instead of a single match. In turn, the homography
matrix allows the retrieval of extrinsic calibration parameters. As a result,
the proposed framework demonstrates superior performance on both synthetic
datasets and real-world cameras, setting a new state-of-the-art benchmark.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02599" title="Abstract">arXiv:2311.02599</a> [<a href="/pdf/2311.02599" title="Download PDF">pdf</a>, <a href="/format/2311.02599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Class and Domain Augmentations for Single-Source Open-Domain  Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bele%2C+P">Prathmesh Bele</a>, 
<a href="/search/cs?searchtype=author&query=Bundele%2C+V">Valay Bundele</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+A">Avigyan Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+A">Ankit Jha</a>, 
<a href="/search/cs?searchtype=author&query=Roig%2C+G">Gemma Roig</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+B">Biplab Banerjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Single-source open-domain generalization (SS-ODG) addresses the challenge of
labeled source domains with supervision during training and unlabeled novel
target domains during testing. The target domain includes both known classes
from the source domain and samples from previously unseen classes. Existing
techniques for SS-ODG primarily focus on calibrating source-domain classifiers
to identify open samples in the target domain. However, these methods struggle
with visually fine-grained open-closed data, often misclassifying open samples
as closed-set classes. Moreover, relying solely on a single source domain
restricts the model's ability to generalize. To overcome these limitations, we
propose a novel framework called SODG-Net that simultaneously synthesizes novel
domains and generates pseudo-open samples using a learning-based objective, in
contrast to the ad-hoc mixing strategies commonly found in the literature. Our
approach enhances generalization by diversifying the styles of known class
samples using a novel metric criterion and generates diverse pseudo-open
samples to train a unified and confident multi-class classifier capable of
handling both open and closed-set data. Extensive experimental evaluations
conducted on multiple benchmarks consistently demonstrate the superior
performance of SODG-Net compared to the literature.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02601" title="Abstract">arXiv:2311.02601</a> [<a href="/pdf/2311.02601" title="Download PDF">pdf</a>, <a href="/format/2311.02601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Implicit Neural Representations from Point Clouds via  Energy-Based Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yamauchi%2C+R">Ryutaro Yamauchi</a>, 
<a href="/search/cs?searchtype=author&query=Sakurai%2C+J">Jinya Sakurai</a>, 
<a href="/search/cs?searchtype=author&query=Furukawa%2C+R">Ryo Furukawa</a>, 
<a href="/search/cs?searchtype=author&query=Matsubayashi%2C+T">Tatsushi Matsubayashi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Reconstructing a continuous surface from an unoritented 3D point cloud is a
fundamental task in 3D shape processing. In recent years, several methods have
been proposed to address this problem using implicit neural representations
(INRs). In this study, we propose a method to optimize INRs using energy-based
models (EBMs). By employing the absolute value of the coordinate-based neural
networks as the energy function, the INR can be optimized through the
estimation of the point cloud distribution by the EBM. In addition, appropriate
parameter settings of the EBM enable the model to consider the magnitude of
point cloud noise. Our experiments confirmed that the proposed method is more
robust against point cloud noise than conventional surface reconstruction
methods.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02602" title="Abstract">arXiv:2311.02602</a> [<a href="/pdf/2311.02602" title="Download PDF">pdf</a>, <a href="/format/2311.02602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Get the Ball Rolling: Alerting Autonomous Robots When to Help to Close  the Healthcare Loop
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jiaxin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yanyao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+Z">Ziyuan Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yufeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+W">Wenjuan Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">To facilitate the advancement of research in healthcare robots without human
intervention or commands, we introduce the Autonomous Helping Challenge, along
with a crowd-sourcing large-scale dataset. The goal is to create healthcare
robots that possess the ability to determine when assistance is necessary,
generate useful sub-tasks to aid in planning, carry out these plans through a
physical robot, and receive feedback from the environment in order to generate
new tasks and continue the process. Besides the general challenge in open-ended
scenarios, Autonomous Helping focuses on three specific challenges: autonomous
task generation, the gap between the current scene and static commonsense, and
the gap between language instruction and the real world. Additionally, we
propose Helpy, a potential approach to close the healthcare loop in the
learning-free setting.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02608" title="Abstract">arXiv:2311.02608</a> [<a href="/pdf/2311.02608" title="Download PDF">pdf</a>, <a href="/format/2311.02608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-based 3D Point Cloud Classification: A Systematic Survey  and Outlook
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Changshuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+S">Shengwei Tian</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+B">Baoli Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+X">Xin Ning</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiao Bai</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Displays 102456 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, point cloud representation has become one of the research
hotspots in the field of computer vision, and has been widely used in many
fields, such as autonomous driving, virtual reality, robotics, etc. Although
deep learning techniques have achieved great success in processing regular
structured 2D grid image data, there are still great challenges in processing
irregular, unstructured point cloud data. Point cloud classification is the
basis of point cloud analysis, and many deep learning-based methods have been
widely used in this task. Therefore, the purpose of this paper is to provide
researchers in this field with the latest research progress and future trends.
First, we introduce point cloud acquisition, characteristics, and challenges.
Second, we review 3D data representations, storage formats, and commonly used
datasets for point cloud classification. We then summarize deep learning-based
methods for point cloud classification and complement recent research work.
Next, we compare and analyze the performance of the main methods. Finally, we
discuss some challenges and future directions for point cloud classification.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02612" title="Abstract">arXiv:2311.02612</a> [<a href="/pdf/2311.02612" title="Download PDF">pdf</a>, <a href="/format/2311.02612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Grounding Potential of VQA-oriented GPT-4V for Zero-shot  Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiangning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuhai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Z">Zhucun Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yabiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large Multimodal Model (LMM) GPT-4V(ision) endows GPT-4 with visual grounding
capabilities, making it possible to handle certain tasks through the Visual
Question Answering (VQA) paradigm. This paper explores the potential of
VQA-oriented GPT-4V in the recently popular visual Anomaly Detection (AD) and
is the first to conduct qualitative and quantitative evaluations on the popular
MVTec AD and VisA datasets. Considering that this task requires both
image-/pixel-level evaluations, the proposed GPT-4V-AD framework contains three
components: 1) Granular Region Division, 2) Prompt Designing, 3)
Text2Segmentation for easy quantitative evaluation, and have made some
different attempts for comparative analysis. The results show that GPT-4V can
achieve certain results in the zero-shot AD task through a VQA paradigm, such
as achieving image-level 77.1/88.0 and pixel-level 68.0/76.6 AU-ROCs on MVTec
AD and VisA datasets, respectively. However, its performance still has a
certain gap compared to the state-of-the-art zero-shot method, e.g., WinCLIP
ann CLIP-AD, and further research is needed. This study provides a baseline
reference for the research of VQA-oriented LMM in the zero-shot AD task, and we
also post several possible future works. Code is available at
\url{https://github.com/zhangzjn/GPT-4V-AD}.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02616" title="Abstract">arXiv:2311.02616</a> [<a href="/pdf/2311.02616" title="Download PDF">pdf</a>, <a href="/format/2311.02616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Divide &amp; Conquer for Entailment-aware Multi-hop Evidence Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+F">Fan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Surdeanu%2C+M">Mihai Surdeanu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NAACL-HLT SRW 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Lexical and semantic matches are commonly used as relevance measurements for
information retrieval. Together they estimate the semantic equivalence between
the query and the candidates. However, semantic equivalence is not the only
relevance signal that needs to be considered when retrieving evidences for
multi-hop questions. In this work, we demonstrate that textual entailment
relation is another important relevance dimension that should be considered. To
retrieve evidences that are either semantically equivalent to or entailed by
the question simultaneously, we divide the task of evidence retrieval for
multi-hop question answering (QA) into two sub-tasks, i.e., semantic textual
similarity and inference similarity retrieval. We propose two ensemble models,
EAR and EARnest, which tackle each of the sub-tasks separately and then jointly
re-rank sentences with the consideration of the diverse relevance signals.
Experimental results on HotpotQA verify that our models not only significantly
outperform all the single retrieval models it is based on, but is also more
effective than two intuitive ensemble baseline models.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02617" title="Abstract">arXiv:2311.02617</a> [<a href="/pdf/2311.02617" title="Download PDF">pdf</a>, <a href="/format/2311.02617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TFNet: Tuning Fork Network with Neighborhood Pixel Aggregation for  Improved Building Footprint Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Waseem%2C+M+A">Muhammad Ahmad Waseem</a>, 
<a href="/search/cs?searchtype=author&query=Tahir%2C+M">Muhammad Tahir</a>, 
<a href="/search/cs?searchtype=author&query=Khalid%2C+Z">Zubair Khalid</a>, 
<a href="/search/cs?searchtype=author&query=Uppal%2C+M">Momin Uppal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper considers the problem of extracting building footprints from
satellite imagery -- a task that is critical for many urban planning and
decision-making applications. While recent advancements in deep learning have
made great strides in automated detection of building footprints,
state-of-the-art methods available in existing literature often generate
erroneous results for areas with densely connected buildings. Moreover, these
methods do not incorporate the context of neighborhood images during training
thus generally resulting in poor performance at image boundaries. In light of
these gaps, we propose a novel Tuning Fork Network (TFNet) design for deep
semantic segmentation that not only performs well for widely-spaced building
but also has good performance for buildings that are closely packed together.
The novelty of TFNet architecture lies in a a single encoder followed by two
parallel decoders to separately reconstruct the building footprint and the
building edge. In addition, the TFNet design is coupled with a novel
methodology of incorporating neighborhood information at the tile boundaries
during the training process. This methodology further improves performance,
especially at the tile boundaries. For performance comparisons, we utilize the
SpaceNet2 and WHU datasets, as well as a dataset from an area in Lahore,
Pakistan that captures closely connected buildings. For all three datasets, the
proposed methodology is found to significantly outperform benchmark methods.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02621" title="Abstract">arXiv:2311.02621</a> [<a href="/pdf/2311.02621" title="Download PDF">pdf</a>, <a href="/format/2311.02621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AIOps-Driven Enhancement of Log Anomaly Detection in Unsupervised  Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dave%2C+D">Daksh Dave</a>, 
<a href="/search/cs?searchtype=author&query=Sawhney%2C+G">Gauransh Sawhney</a>, 
<a href="/search/cs?searchtype=author&query=Khut%2C+D">Dhruv Khut</a>, 
<a href="/search/cs?searchtype=author&query=Nawale%2C+S">Sahil Nawale</a>, 
<a href="/search/cs?searchtype=author&query=Aggrawal%2C+P">Pushkar Aggrawal</a>, 
<a href="/search/cs?searchtype=author&query=Bhavathankar%2C+P">Prasenjit Bhavathankar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 figure, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Information Theory (cs.IT)

</div>
<p class="mathjax">Artificial intelligence operations (AIOps) play a pivotal role in
identifying, mitigating, and analyzing anomalous system behaviors and alerts.
However, the research landscape in this field remains limited, leaving
significant gaps unexplored. This study introduces a novel hybrid framework
through an innovative algorithm that incorporates an unsupervised strategy.
This strategy integrates Principal Component Analysis (PCA) and Artificial
Neural Networks (ANNs) and uses a custom loss function to substantially enhance
the effectiveness of log anomaly detection. The proposed approach encompasses
the utilization of both simulated and real-world datasets, including logs from
SockShop and Hadoop Distributed File System (HDFS). The experimental results
are highly promising, demonstrating significant reductions in pseudo-positives.
Moreover, this strategy offers notable advantages, such as the ability to
process logs in their raw, unprocessed form, and the potential for further
enhancements. The successful implementation of this approach showcases a
remarkable reduction in anomalous logs, thus unequivocally establishing the
efficacy of the proposed methodology. Ultimately, this study makes a
substantial contribution to the advancement of log anomaly detection within
AIOps platforms, addressing the critical need for effective and efficient log
analysis in modern and complex systems.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02622" title="Abstract">arXiv:2311.02622</a> [<a href="/pdf/2311.02622" title="Download PDF">pdf</a>, <a href="/ps/2311.02622" title="Download PostScript">ps</a>, <a href="/format/2311.02622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Networks Are Implicit Decision Trees: The Hierarchical Simplicity  Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zhehang Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Neural networks exhibit simplicity bias; they rely on simpler features while
ignoring equally predictive but more complex features. In this work, we
introduce a novel approach termed imbalanced label coupling to investigate
scenarios where simple and complex features exhibit different levels of
predictive power. In these cases, complex features still contribute to
predictions. The trained networks make predictions in alignment with the
ascending complexity of input features according to how they correlate with the
label in the training set, irrespective of the underlying predictive power. For
instance, even when simple spurious features distort predictions in CIFAR-10,
most cats are predicted to be dogs, and most trucks are predicted to be
automobiles! This observation provides direct evidence that the neural network
learns core features in the presence of spurious features. We empirically show
that last-layer retraining with target data distribution is effective, yet
insufficient to fully recover core features when spurious features are
perfectly correlated with the target labels in our synthetic dataset. We hope
our research contributes to a deeper understanding of the implicit bias of
neural networks.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02625" title="Abstract">arXiv:2311.02625</a> [<a href="/pdf/2311.02625" title="Download PDF">pdf</a>, <a href="/ps/2311.02625" title="Download PostScript">ps</a>, <a href="/format/2311.02625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New structure of channel coding: serial concatenation of Polar codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mensouri%2C+M">Mohammed Mensouri</a>, 
<a href="/search/cs?searchtype=author&query=Eddahibi%2C+M">Mustapha Eddahibi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">In this paper, we introduce a new coding and decoding structure for enhancing
the reliability and performance of polar codes, specifically at low error
rates. We achieve this by concatenating two polar codes in series to create
robust error-correcting codes. The primary objective here is to optimize the
behavior of individual elementary codes within polar codes. In this structure,
we incorporate interleaving, a technique that rearranges bits to maximize the
separation between originally neighboring symbols. This rearrangement is
instrumental in converting error clusters into distributed errors across the
entire sequence. To evaluate their performance, we proposed to model a
communication system with seven components: an information source, a channel
encoder, a modulator, a channel, a demodulator, a channel decoder, and a
destination. This work focuses on evaluating the bit error rate (BER) of codes
for different block lengths and code rates. Next, we compare the bit error rate
(BER) performance between our proposed method and polar codes.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02628" title="Abstract">arXiv:2311.02628</a> [<a href="/pdf/2311.02628" title="Download PDF">pdf</a>, <a href="/format/2311.02628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SparseLock: Securing Neural Network Models in Deep Learning Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+N">Nivedita Shrivastava</a>, 
<a href="/search/cs?searchtype=author&query=Sarangi%2C+S+R">Smruti R. Sarangi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Securing neural networks (NNs) against model extraction and parameter
exfiltration attacks is an important problem primarily because modern NNs take
a lot of time and resources to build and train. We observe that there are no
countermeasures (CMs) against recently proposed attacks on sparse NNs and there
is no single CM that effectively protects against all types of known attacks
for both sparse as well as dense NNs. In this paper, we propose SparseLock, a
comprehensive CM that protects against all types of attacks including some of
the very recently proposed ones for which no CM exists as of today. We rely on
a novel compression algorithm and binning strategy. Our security guarantees are
based on the inherent hardness of bin packing and inverse bin packing problems.
We also perform a battery of statistical and information theory based tests to
successfully show that we leak very little information and side channels in our
architecture are akin to random sources. In addition, we show a performance
benefit of 47.13% over the nearest competing secure architecture.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02629" title="Abstract">arXiv:2311.02629</a> [<a href="/pdf/2311.02629" title="Download PDF">pdf</a>, <a href="/format/2311.02629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pointer Networks with Q-Learning for OP Combinatorial Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barro%2C+A">Alessandro Barro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">The Orienteering Problem (OP) presents a unique challenge in combinatorial
optimization, emphasized by its widespread use in logistics, delivery, and
transportation planning. Given the NP-hard nature of OP, obtaining optimal
solutions is inherently complex. While Pointer Networks (Ptr-Nets) have
exhibited prowess in various combinatorial tasks, their performance in the
context of OP leaves room for improvement. Recognizing the potency of
Q-learning, especially when paired with deep neural structures, this research
unveils the Pointer Q-Network (PQN). This innovative method combines Ptr-Nets
and Q-learning, effectively addressing the specific challenges presented by OP.
We deeply explore the architecture and efficiency of PQN, showcasing its
superior capability in managing OP situations.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02630" title="Abstract">arXiv:2311.02630</a> [<a href="/pdf/2311.02630" title="Download PDF">pdf</a>, <a href="/ps/2311.02630" title="Download PostScript">ps</a>, <a href="/format/2311.02630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The New Frontier of Cybersecurity: Emerging Threats and Innovations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dave%2C+D">Daksh Dave</a>, 
<a href="/search/cs?searchtype=author&query=Sawhney%2C+G">Gauransh Sawhney</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+P">Pushkar Aggarwal</a>, 
<a href="/search/cs?searchtype=author&query=Silswal%2C+N">Nitish Silswal</a>, 
<a href="/search/cs?searchtype=author&query=Khut%2C+D">Dhruv Khut</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">In today's digitally interconnected world, cybersecurity threats have reached
unprecedented levels, presenting a pressing concern for individuals,
organizations, and governments. This study employs a qualitative research
approach to comprehensively examine the diverse threats of cybersecurity and
their impacts across various sectors. Four primary categories of threats are
identified and analyzed, encompassing malware attacks, social engineering
attacks, network vulnerabilities, and data breaches. The research delves into
the consequences of these threats on individuals, organizations, and society at
large. The findings reveal a range of key emerging threats in cybersecurity,
including advanced persistent threats, ransomware attacks, Internet of Things
(IoT) vulnerabilities, and social engineering exploits. Consequently, it is
evident that emerging cybersecurity threats pose substantial risks to both
organizations and individuals. The sophistication and diversity of these
emerging threats necessitate a multi-layered approach to cybersecurity. This
approach should include robust security measures, comprehensive employee
training, and regular security audits. The implications of these emerging
threats are extensive, with potential consequences such as financial loss,
reputational damage, and compromised personal information. This study
emphasizes the importance of implementing effective measures to mitigate these
threats. It highlights the significance of using strong passwords, encryption
methods, and regularly updating software to bolster cyber defenses.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02631" title="Abstract">arXiv:2311.02631</a> [<a href="/pdf/2311.02631" title="Download PDF">pdf</a>, <a href="/format/2311.02631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Critical Perceptual Pre-trained Model for Complex Trajectory Recovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dedong Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhishuai Li</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+L">Lei Bai</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Q">Qingyuan Gong</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lijun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ketter%2C+W">Wolfgang Ketter</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ACM SIGSPATIAL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The trajectory on the road traffic is commonly collected at a low sampling
rate, and trajectory recovery aims to recover a complete and continuous
trajectory from the sparse and discrete inputs. Recently, sequential language
models have been innovatively adopted for trajectory recovery in a pre-trained
manner: it learns road segment representation vectors, which will be used in
the downstream tasks. However, existing methods are incapable of handling
complex trajectories: when the trajectory crosses remote road segments or makes
several turns, which we call critical nodes, the quality of learned
representations deteriorates, and the recovered trajectories skip the critical
nodes. This work is dedicated to offering a more robust trajectory recovery for
complex trajectories. Firstly, we define the trajectory complexity based on the
detour score and entropy score and construct the complexity-aware semantic
graphs correspondingly. Then, we propose a Multi-view Graph and Complexity
Aware Transformer (MGCAT) model to encode these semantics in trajectory
pre-training from two aspects: 1) adaptively aggregate the multi-view graph
features considering trajectory pattern, and 2) higher attention to critical
nodes in a complex trajectory. Such that, our MGCAT is perceptual when handling
the critical scenario of complex trajectories. Extensive experiments are
conducted on large-scale datasets. The results prove that our method learns
better representations for trajectory recovery, with 5.22% higher F1-score
overall and 8.16% higher F1-score for complex trajectories particularly. The
code is available at https://github.com/bonaldli/ComplexTraj.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02633" title="Abstract">arXiv:2311.02633</a> [<a href="/pdf/2311.02633" title="Download PDF">pdf</a>, <a href="/format/2311.02633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Background Also Matters: Background-Aware Motion-Guided Objects  Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kara%2C+S">Sandra Kara</a>, 
<a href="/search/cs?searchtype=author&query=Ammar%2C+H">Hejer Ammar</a>, 
<a href="/search/cs?searchtype=author&query=Chabot%2C+F">Florian Chabot</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+Q">Quoc-Cuong Pham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at WACV2024 (IEEE/CVF Winter conference on Applications of Computer Vision)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent works have shown that objects discovery can largely benefit from the
inherent motion information in video data. However, these methods lack a proper
background processing, resulting in an over-segmentation of the non-object
regions into random segments. This is a critical limitation given the
unsupervised setting, where object segments and noise are not distinguishable.
To address this limitation we propose BMOD, a Background-aware Motion-guided
Objects Discovery method. Concretely, we leverage masks of moving objects
extracted from optical flow and design a learning mechanism to extend them to
the true foreground composed of both moving and static objects. The background,
a complementary concept of the learned foreground class, is then isolated in
the object discovery process. This enables a joint learning of the objects
discovery task and the object/non-object separation. The conducted experiments
on synthetic and real-world datasets show that integrating our background
handling with various cutting-edge methods brings each time a considerable
improvement. Specifically, we improve the objects discovery performance with a
large margin, while establishing a strong baseline for object/non-object
separation.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02636" title="Abstract">arXiv:2311.02636</a> [<a href="/pdf/2311.02636" title="Download PDF">pdf</a>, <a href="/format/2311.02636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compact Data Structures for Network Telemetry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feibish%2C+S+L">Shir Landau Feibish</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zaoxing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Rexford%2C+J">Jennifer Rexford</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Collecting and analyzing of network traffic data (network telemetry) plays a
critical role in managing modern networks. Network administrators analyze their
traffic to troubleshoot performance and reliability problems, and to detect and
block cyberattacks. However, conventional traffic-measurement techniques offer
limited visibility into network conditions and rely on offline analysis.
Fortunately, network devices such as switches and network interface cards, are
increasingly programmable at the packet level, enabling flexible analysis of
the traffic in place, as the packets fly by. However, to operate at high speed,
these devices have limited memory and computational resources, leading to
trade-offs between accuracy and overhead. In response, an exciting research
area emerged, bringing ideas from compact data structures and streaming
algorithms to bear on important networking telemetry applications and the
unique characteristics of high-speed network devices. In this paper, we review
the research on compact data structures for network telemetry and discuss
promising directions for future research.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02640" title="Abstract">arXiv:2311.02640</a> [<a href="/pdf/2311.02640" title="Download PDF">pdf</a>, <a href="/format/2311.02640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing the Promise and Pitfalls of ChatGPT for Automated Code  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+F+A">Muhammad Fawad Akbar Khan</a>, 
<a href="/search/cs?searchtype=author&query=Ramsdell%2C+M">Max Ramsdell</a>, 
<a href="/search/cs?searchtype=author&query=Falor%2C+E">Erik Falor</a>, 
<a href="/search/cs?searchtype=author&query=Karimi%2C+H">Hamid Karimi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents a comprehensive evaluation of the code generation
capabilities of ChatGPT, a prominent large language model, compared to human
programmers. A novel dataset of 131 code-generation prompts across 5 categories
was curated to enable robust analysis. Code solutions were generated by both
ChatGPT and humans for all prompts, resulting in 262 code samples. A meticulous
manual assessment methodology prioritized evaluating correctness,
comprehensibility, and security using 14 established code quality metrics. The
key findings reveal ChatGPT's strengths in crafting concise, efficient code
with advanced constructs, showcasing strengths in data analysis tasks (93.1%
accuracy) but limitations in visual-graphical challenges. Comparative analysis
with human code highlights ChatGPT's inclination towards modular design and
superior error handling. Additionally, machine learning models effectively
distinguished ChatGPT from human code with up to 88% accuracy, suggesting
detectable coding style disparities. By providing profound insights into
ChatGPT's code generation capabilities and limitations through quantitative
metrics and qualitative analysis, this study makes valuable contributions
toward advancing AI-based programming assistants. The curated dataset and
methodology offer a robust foundation for future research in this nascent
domain. All data and codes are available on
https://github.com/DSAatUSU/ChatGPT-promises-and-pitfalls.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02641" title="Abstract">arXiv:2311.02641</a> [<a href="/pdf/2311.02641" title="Download PDF">pdf</a>, <a href="/format/2311.02641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PotholeGuard: A Pothole Detection Approach by Point Cloud Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nawale%2C+S">Sahil Nawale</a>, 
<a href="/search/cs?searchtype=author&query=Khut%2C+D">Dhruv Khut</a>, 
<a href="/search/cs?searchtype=author&query=Dave%2C+D">Daksh Dave</a>, 
<a href="/search/cs?searchtype=author&query=Sawhney%2C+G">Gauransh Sawhney</a>, 
<a href="/search/cs?searchtype=author&query=Aggrawal%2C+P">Pushkar Aggrawal</a>, 
<a href="/search/cs?searchtype=author&query=Devadakar%2C+D+K">Dr. Kailas Devadakar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Pothole detection is crucial for road safety and maintenance, traditionally
relying on 2D image segmentation. However, existing 3D Semantic Pothole
Segmentation research often overlooks point cloud sparsity, leading to
suboptimal local feature capture and segmentation accuracy. Our research
presents an innovative point cloud-based pothole segmentation architecture. Our
model efficiently identifies hidden features and uses a feedback mechanism to
enhance local characteristics, improving feature presentation. We introduce a
local relationship learning module to understand local shape relationships,
enhancing structural insights. Additionally, we propose a lightweight adaptive
structure for refining local point features using the K nearest neighbor
algorithm, addressing point cloud density differences and domain selection.
Shared MLP Pooling is integrated to learn deep aggregation features,
facilitating semantic data exploration and segmentation guidance. Extensive
experiments on three public datasets confirm PotholeGuard's superior
performance over state-of-the-art methods. Our approach offers a promising
solution for robust and accurate 3D pothole segmentation, with applications in
road maintenance and safety.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02642" title="Abstract">arXiv:2311.02642</a> [<a href="/pdf/2311.02642" title="Download PDF">pdf</a>, <a href="/format/2311.02642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Approach for Multi-Object Tracking with Two-Stage Min-Cost Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huining Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yalong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xianlin Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Feng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhipeng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The minimum network flow algorithm is widely used in multi-target tracking.
However, the majority of the present methods concentrate exclusively on
minimizing cost functions whose values may not indicate accurate solutions
under occlusions. In this paper, by exploiting the properties of tracklets
intersections and low-confidence detections, we develop a two-stage tracking
pipeline with an intersection mask that can accurately locate inaccurate
tracklets which are corrected in the second stage. Specifically, we employ the
minimum network flow algorithm with high-confidence detections as input in the
first stage to obtain the candidate tracklets that need correction. Then we
leverage the intersection mask to accurately locate the inaccurate parts of
candidate tracklets. The second stage utilizes low-confidence detections that
may be attributed to occlusions for correcting inaccurate tracklets. This
process constructs a graph of nodes in inaccurate tracklets and low-confidence
nodes and uses it for the second round of minimum network flow calculation. We
perform sufficient experiments on popular MOT benchmark datasets and achieve
78.4 MOTA on the test set of MOT16, 79.2 on MOT17, and 76.4 on MOT20, which
shows that the proposed method is effective.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02647" title="Abstract">arXiv:2311.02647</a> [<a href="/pdf/2311.02647" title="Download PDF">pdf</a>, <a href="/format/2311.02647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Approach for an Affective Computing-Driven Quality of Experience  (QoE) Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%A8gue%2C+J">Joshua B&#xe8;gue</a>, 
<a href="/search/cs?searchtype=author&query=Labiod%2C+M+A">Mohamed Aymen Labiod</a>, 
<a href="/search/cs?searchtype=author&query=Melloulk%2C+A">Abdelhamid Melloulk</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Communications Magazine, vol. 61, no. 10, pp. 54-60, October
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Multimedia (cs.MM)

</div>
<p class="mathjax">In human interactions, emotion recognition is crucial. For this reason, the
topic of computer-vision approaches for automatic emotion recognition is
currently being extensively researched. Processing multi-channel
electroencephalogram (EEG) information is one of the most researched methods
for automatic emotion recognition. This paper presents a new model for an
affective computing-driven Quality of Experience (QoE) prediction. In order to
validate the proposed model, a publicly available dataset is used. The dataset
contains EEG, ECG, and respiratory data and is focused on a multimedia QoE
assessment context. The EEG data are retained on which the differential entropy
and the power spectral density are calculated with an observation window of
three seconds. These two features were extracted to train several deep-learning
models to investigate the possibility of predicting QoE with five different
factors. The performance of these models is compared, and the best model is
optimized to improve the results. The best results were obtained with an
LSTM-based model, presenting an F1-score from 68% to 78%. An analysis of the
model and its features shows that the Delta frequency band is the least
necessary, that two electrodes have a higher importance, and that two other
electrodes have a very low impact on the model's performances.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02648" title="Abstract">arXiv:2311.02648</a> [<a href="/pdf/2311.02648" title="Download PDF">pdf</a>, <a href="/format/2311.02648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Drone-Enabled Load Management for Solar Small Cell Networks in Next-Gen  Communications Optimization for Solar Small Cells
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dave%2C+D">Daksh Dave</a>, 
<a href="/search/cs?searchtype=author&query=Khut%2C+D">Dhruv Khut</a>, 
<a href="/search/cs?searchtype=author&query=Nawale%2C+S">Sahil Nawale</a>, 
<a href="/search/cs?searchtype=author&query=Aggrawal%2C+P">Pushkar Aggrawal</a>, 
<a href="/search/cs?searchtype=author&query=Rastogi%2C+D">Disha Rastogi</a>, 
<a href="/search/cs?searchtype=author&query=Devadkar%2C+K">Kailas Devadkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 1 table, 1 algorithm
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, the cellular industry has witnessed a major evolution in
communication technologies. It is evident that the Next Generation of cellular
networks(NGN) will play a pivotal role in the acceptance of emerging IoT
applications supporting high data rates, better Quality of Service(QoS), and
reduced latency. However, the deployment of NGN will introduce a power overhead
on the communication infrastructure. Addressing the critical energy constraints
in 5G and beyond, this study introduces an innovative load transfer method
using drone-carried airborne base stations (BSs) for stable and secure power
reallocation within a green micro-grid network. This method effectively manages
energy deficit by transferring aerial BSs from high to low-energy cells,
depending on user density and the availability of aerial BSs, optimizing power
distribution in advanced cellular networks. The complexity of the proposed
system is significantly lower as compared to existing power cable transmission
systems currently employed in powering the BSs. Furthermore, our proposed
algorithm has been shown to reduce BS power outages while requiring a minimum
number of drone exchanges. We have conducted a thorough review on real-world
dataset to prove the efficacy of our proposed approach to support BS during
high load demand times
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02649" title="Abstract">arXiv:2311.02649</a> [<a href="/pdf/2311.02649" title="Download PDF">pdf</a>, <a href="/format/2311.02649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Face Video Coding Techniques and Standardization Efforts: A  Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bolin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yan Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generative Face Video Coding (GFVC) techniques can exploit the compact
representation of facial priors and the strong inference capability of deep
generative models, achieving high-quality face video communication in ultra-low
bandwidth scenarios. This paper conducts a comprehensive survey on the recent
advances of the GFVC techniques and standardization efforts, which could be
applicable to ultra low bitrate communication, user-specified
animation/filtering and metaverse-related functionalities. In particular, we
generalize GFVC systems within one coding framework and summarize different
GFVC algorithms with their corresponding visual representations. Moreover, we
review the GFVC standardization activities that are specified with supplemental
enhancement information messages. Finally, we discuss fundamental challenges
and broad applications on GFVC techniques and their standardization potentials,
as well as envision their future trends. The project page can be found at
https://github.com/Berlin0610/Awesome-Generative-Face-Video-Coding.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02650" title="Abstract">arXiv:2311.02650</a> [<a href="/pdf/2311.02650" title="Download PDF">pdf</a>, <a href="/format/2311.02650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ephemeral Rollups are All you Need
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Picco%2C+G">Gabriele Picco</a>, 
<a href="/search/cs?searchtype=author&query=Fortugno%2C+A">Andrea Fortugno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">In the realm of open and composable gaming, we envision platforms where users
actively expand, create, engage, and immerse themselves in a rich world of
entertainment. One promising avenue for achieving this vision is through fully
on-chain (FOC) games, where both game state and logic reside on the blockchain,
maximizing composability. However, we must grapple with inherent limitations
and trade-offs, particularly in terms of costs and scalability. This paper
proposes BOLT, a framework that leverages the Solana Virtual Machine (SVM) to
scale FOC games without state fragmentation or compromised trust assumptions.
The framework introduces a systematic approach for discovering, utilizing, and
publishing modular pieces of logic as components deeply rooted in the
Entity-Component-System (ECS) pattern. To enhance scalability and resource
optimization, we introduce the concept of Ephemeral Rollups (ERs) that overcome
the tradeoffs of L2s horizontal scaling. These dedicated runtimes can be
customized to provide higher operational speed, configurable ticking
mechanisms, provable sessions and gasless transactions without
composability-scalability tradeoffs.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02651" title="Abstract">arXiv:2311.02651</a> [<a href="/pdf/2311.02651" title="Download PDF">pdf</a>, <a href="/ps/2311.02651" title="Download PostScript">ps</a>, <a href="/format/2311.02651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compute at Scale -- A Broad Investigation into the Data Center Industry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pilz%2C+K">Konstantin Pilz</a>, 
<a href="/search/cs?searchtype=author&query=Heim%2C+L">Lennart Heim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This report characterizes the data center industry and its importance for AI
development. Data centers are industrial facilities that efficiently provide
compute at scale and thus constitute the engine rooms of today's digital
economy. As large-scale AI training and inference become increasingly
computationally expensive, they are dominantly executed from this designated
infrastructure. Key features of data centers include large-scale compute
clusters that require extensive cooling and consume large amounts of power, the
need for fast connectivity both within the data center and to the internet, and
an emphasis on security and reliability. The global industry is valued at
approximately $250B and is expected to double over the next seven years. There
are likely about 500 large (above 10 MW) data centers globally, with the US,
Europe, and China constituting the most important markets. The report further
covers important actors, business models, main inputs, and typical locations of
data centers.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02656" title="Abstract">arXiv:2311.02656</a> [<a href="/pdf/2311.02656" title="Download PDF">pdf</a>, <a href="/format/2311.02656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Region of Interest (ROI) based adaptive cross-layer system for real-time  video streaming over Vehicular Ad-hoc NETworks (VANETs)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Labiod%2C+M+A">Mohamed Aymen Labiod</a>, 
<a href="/search/cs?searchtype=author&query=Gharbi%2C+M">Mohamed Gharbi</a>, 
<a href="/search/cs?searchtype=author&query=Coudoux%2C+F">Fran&#xe7;ois-Xavier Coudoux</a>, 
<a href="/search/cs?searchtype=author&query=Corlay%2C+P">Patrick Corlay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Nowadays, real-time vehicle applications increasingly rely on video
acquisition and processing to detect or even identify vehicles and obstacles in
the driving environment. In this letter, we propose an algorithm that allows
reinforcing these operations by improving end-to-end video transmission quality
in a vehicular context. The proposed low complexity solution gives highest
priority to the scene regions of interest (ROI) on which the perception of the
driving environment is based on. This is done by applying an adaptive
cross-layer mapping of the ROI visual data packets at the IEEE 802.11p MAC
layer. Realistic VANET simulation results demonstrate that for HEVC compressed
video communications, the proposed system offers PSNR gains up to 11dB on the
ROI part.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02657" title="Abstract">arXiv:2311.02657</a> [<a href="/pdf/2311.02657" title="Download PDF">pdf</a>, <a href="/format/2311.02657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GSC: Generalizable Service Coordination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohammadi%2C+F">Farzad Mohammadi</a>, 
<a href="/search/cs?searchtype=author&query=Shah-Mansouri%2C+V">Vahid Shah-Mansouri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Services with distributed and interdependent components are becoming a
popular option for harnessing dispersed resources available on cloud and edge
networks. However, effective deployment and management of these services,
namely service coordination, is a challenging task. Service coordination
comprises the placement and scalability of components and scheduling incoming
traffic requesting for services between deployed instances. Due to the online
nature of the problem and the success of Deep Reinforcement Learning (DRL)
methods, previous works considered DRL agents for solving service coordination
problems, yet these solutions have to be retrained for every unseen scenario.
Other works have tried to tackle this shortcoming by incorporating Graph Neural
Networks (GNN) into their solutions, but they often focus on specific aspects
(and disregard others) or cannot operate in dynamic and practical situations
where there is no labeled dataset and feedback from the network might be
delayed. In response to these challenges, we present GSC, a generalizable
service coordinator that jointly considers service placement, scaling, and
traffic scheduling. GSC can operate in unseen situations without significant
performance degradation and outperforms existing state-of-the-art solutions by
40%, as determined by simulating real-world network situations.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02659" title="Abstract">arXiv:2311.02659</a> [<a href="/pdf/2311.02659" title="Download PDF">pdf</a>, <a href="/ps/2311.02659" title="Download PostScript">ps</a>, <a href="/format/2311.02659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Patterned non-determinism in communication complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gavinsky%2C+D">Dmytro Gavinsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">We define and study the model of patterned non-determinism in bipartite
communication complexity, denoted by $PNP^{X\leftrightarrow Y}$. It generalises
the known models $UP^{X\leftrightarrow Y}$ and $FewP^{X\leftrightarrow Y}$
through relaxing the constraints on the witnessing structure of the underlying
$NP^{X\leftrightarrow Y}$-protocol. It is shown that for the case of total
functions $PNP^{X\leftrightarrow Y}$ equals $P^{X\leftrightarrow Y}$ (similarly
to $UP^{X\leftrightarrow Y}$ and $FewP^{X\leftrightarrow Y}$). Moreover, the
corresponding exhaustive witness-searching problem -- determining the full set
of witnesses that lead to the acceptance of a given input pair -- also has an
efficient deterministic protocol.
<br />The possibility of efficient exhaustive $PNP^{X\leftrightarrow Y}$-search is
used to analyse certain three-party communication regime (under the "number in
hand" input partition): The corresponding three-party model is shown to be as
strong qualitatively as the weakest among its two-party amplifications obtained
by allowing free communication between a pair of players.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02660" title="Abstract">arXiv:2311.02660</a> [<a href="/pdf/2311.02660" title="Download PDF">pdf</a>, <a href="/format/2311.02660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-enhanced Self-training for Cross-domain Constituency Parsing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianling Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Meishan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+P">Peiming Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP 2023 main conf
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Self-training has proven to be an effective approach for cross-domain tasks,
and in this study, we explore its application to cross-domain constituency
parsing. Traditional self-training methods rely on limited and potentially
low-quality raw corpora. To overcome this limitation, we propose enhancing
self-training with the large language model (LLM) to generate domain-specific
raw corpora iteratively. For the constituency parsing, we introduce grammar
rules that guide the LLM in generating raw corpora and establish criteria for
selecting pseudo instances. Our experimental results demonstrate that
self-training for constituency parsing, equipped with an LLM, outperforms
traditional methods regardless of the LLM's performance. Moreover, the
combination of grammar rules and confidence criteria for pseudo-data selection
yields the highest performance in the cross-domain constituency parsing.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02661" title="Abstract">arXiv:2311.02661</a> [<a href="/pdf/2311.02661" title="Download PDF">pdf</a>, <a href="/format/2311.02661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CCMR: High Resolution Optical Flow Estimation via Coarse-to-Fine  Context-Guided Motion Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jahedi%2C+A">Azin Jahedi</a>, 
<a href="/search/cs?searchtype=author&query=Luz%2C+M">Maximilian Luz</a>, 
<a href="/search/cs?searchtype=author&query=Rivinius%2C+M">Marc Rivinius</a>, 
<a href="/search/cs?searchtype=author&query=Bruhn%2C+A">Andr&#xe9;s Bruhn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Attention-based motion aggregation concepts have recently shown their
usefulness in optical flow estimation, in particular when it comes to handling
occluded regions. However, due to their complexity, such concepts have been
mainly restricted to coarse-resolution single-scale approaches that fail to
provide the detailed outcome of high-resolution multi-scale networks. In this
paper, we hence propose CCMR: a high-resolution coarse-to-fine approach that
leverages attention-based motion grouping concepts to multi-scale optical flow
estimation. CCMR relies on a hierarchical two-step attention-based
context-motion grouping strategy that first computes global multi-scale context
features and then uses them to guide the actual motion grouping. As we iterate
both steps over all coarse-to-fine scales, we adapt cross covariance image
transformers to allow for an efficient realization while maintaining
scale-dependent properties. Experiments and ablations demonstrate that our
efforts of combining multi-scale and attention-based concepts pay off. By
providing highly detailed flow fields with strong improvements in both occluded
and non-occluded regions, our CCMR approach not only outperforms both the
corresponding single-scale attention-based and multi-scale attention-free
baselines by up to 23.0% and 21.6%, respectively, it also achieves
state-of-the-art results, ranking first on KITTI 2015 and second on MPI Sintel
Clean and Final. Code and trained models are available at
https://github.com/cv-stuttgart /CCMR.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02663" title="Abstract">arXiv:2311.02663</a> [<a href="/pdf/2311.02663" title="Download PDF">pdf</a>, <a href="/ps/2311.02663" title="Download PostScript">ps</a>, <a href="/format/2311.02663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards finite element exterior calculus over manifolds: commuting  projections, geometric variational crimes, and approximation errors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Licht%2C+M+W">Martin W. Licht</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Contribution to ENUMATH Proceedings 2023. 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We survey recent contributions to finite element exterior calculus over
manifolds and surfaces within a comprehensive formalism for the error analysis
of vector-valued partial differential equations over manifolds. Our primary
focus is on uniformly bounded commuting projections over manifolds: these
projections map from Sobolev de Rham complexes onto finite element de Rham
complexes, commute with the differential operators, and satisfy uniform bounds
in Lebesgue norms. They enable the Galerkin theory of Hilbert complexes for a
large range of intrinsic finite element methods over manifolds. However, these
intrinsic finite element methods are generally not computable and thus
primarily of theoretical interest. This leads to our second point: estimating
the geometric variational crime incurred by transitioning to computable
approximate problems. Lastly, our third point addresses how to estimate the
approximation error of the intrinsic finite element method in terms of the mesh
size. If the solution is not continuous, then such an estimate is achieved via
modified Cl\'ement or Scott-Zhang interpolants that facilitate a broken
Bramble--Hilbert lemma.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02664" title="Abstract">arXiv:2311.02664</a> [<a href="/pdf/2311.02664" title="Download PDF">pdf</a>, <a href="/format/2311.02664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced adaptive cross-layer scheme for low latency HEVC streaming over  Vehicular Ad-hoc Networks (VANETs)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Labiod%2C+M+A">Mohamed Aymen Labiod</a>, 
<a href="/search/cs?searchtype=author&query=Gharbi%2C+M">Mohamed Gharbi</a>, 
<a href="/search/cs?searchtype=author&query=Coudoux%2C+F">Fran&#xe7;ois-Xavier Coudoux</a>, 
<a href="/search/cs?searchtype=author&query=Corlay%2C+P">Patrick Corlay</a>, 
<a href="/search/cs?searchtype=author&query=Doghmane%2C+N">Noureddine Doghmane</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Vehicular Communications, Volume 15, 2019, Pages 28-39, ISSN
  2214-2096,
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Vehicular communication has become a reality guided by various applications.
Among those, high video quality delivery with low latency constraints required
by real-time applications constitutes a very challenging task. By dint of its
never-before-achieved compression level, the new High-Efficiency Video Coding
(HEVC) is very promising for real-time video streaming through Vehicular Ad-hoc
Networks (VANET). However, these networks have variable channel quality and
limited bandwidth. Therefore, ensuring satisfactory video quality on such
networks is a major challenge. In this work, a low complexity cross-layer
mechanism is proposed to improve end-to-end performances of HEVC video
streaming in VANET under low delay constraints. The idea is to assign to each
packet of the transmitted video the most appropriate Access Category (AC) queue
on the Medium Access Control (MAC) layer, considering the temporal prediction
structure of the video encoding process, the importance of the frame and the
state of the network traffic load. Simulation results demonstrate that for
different targeted low-delay video communication scenarios, the proposed
mechanism offers significant improvements regarding video quality at the
reception and end-to-end delay compared to the Enhanced Distributed Channel
Access (EDCA) adopted in the 802.11p. Both Quality of Service (QoS) and Quality
of Experience (QoE) evaluations have been also carried out to validate the
proposed approach.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02665" title="Abstract">arXiv:2311.02665</a> [<a href="/pdf/2311.02665" title="Download PDF">pdf</a>, <a href="/format/2311.02665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital Typhoon: Long-term Satellite Image Dataset for the  Spatio-Temporal Modeling of Tropical Cyclones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kitamoto%2C+A">Asanobu Kitamoto</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jared Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Vuillod%2C+B">Bastien Vuillod</a>, 
<a href="/search/cs?searchtype=author&query=Gautier%2C+L">Lucas Gautier</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yingtao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Clanuwat%2C+T">Tarin Clanuwat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023 Datasets and Benchmarks Track (Spotlight)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">This paper presents the official release of the Digital Typhoon dataset, the
longest typhoon satellite image dataset for 40+ years aimed at benchmarking
machine learning models for long-term spatio-temporal data. To build the
dataset, we developed a workflow to create an infrared typhoon-centered image
for cropping using Lambert azimuthal equal-area projection referring to the
best track data. We also address data quality issues such as inter-satellite
calibration to create a homogeneous dataset. To take advantage of the dataset,
we organized machine learning tasks by the types and targets of inference, with
other tasks for meteorological analysis, societal impact, and climate change.
The benchmarking results on the analysis, forecasting, and reanalysis for the
intensity suggest that the dataset is challenging for recent deep learning
models, due to many choices that affect the performance of various models. This
dataset reduces the barrier for machine learning researchers to meet
large-scale real-world events called tropical cyclones and develop machine
learning models that may contribute to advancing scientific knowledge on
tropical cyclones as well as solving societal and sustainability issues such as
disaster reduction and climate change. The dataset is publicly available at
<a href="http://agora.ex.nii.ac.jp/digital-typhoon/dataset/">this http URL</a> and
https://github.com/kitamoto-lab/digital-typhoon/.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02667" title="Abstract">arXiv:2311.02667</a> [<a href="/pdf/2311.02667" title="Download PDF">pdf</a>, <a href="/format/2311.02667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Race Against the Machine: a Fully-annotated, Open-design Dataset of  Autonomous and Piloted High-speed Flight
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bosello%2C+M">Michael Bosello</a>, 
<a href="/search/cs?searchtype=author&query=Aguiari%2C+D">Davide Aguiari</a>, 
<a href="/search/cs?searchtype=author&query=Keuter%2C+Y">Yvo Keuter</a>, 
<a href="/search/cs?searchtype=author&query=Pallotta%2C+E">Enrico Pallotta</a>, 
<a href="/search/cs?searchtype=author&query=Kiade%2C+S">Sara Kiade</a>, 
<a href="/search/cs?searchtype=author&query=Caminati%2C+G">Gyordan Caminati</a>, 
<a href="/search/cs?searchtype=author&query=Pinzarrone%2C+F">Flavio Pinzarrone</a>, 
<a href="/search/cs?searchtype=author&query=Halepota%2C+J">Junaid Halepota</a>, 
<a href="/search/cs?searchtype=author&query=Panerati%2C+J">Jacopo Panerati</a>, 
<a href="/search/cs?searchtype=author&query=Pau%2C+G">Giovanni Pau</a> (Technology Innovation Institute)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Unmanned aerial vehicles, and multi-rotors in particular, can now perform
dexterous tasks in impervious environments, from infrastructure monitoring to
emergency deliveries. Autonomous drone racing has emerged as an ideal benchmark
to develop and evaluate these capabilities. Its challenges include accurate and
robust visual-inertial odometry during aggressive maneuvers, complex
aerodynamics, and constrained computational resources. As researchers
increasingly channel their efforts into it, they also need the tools to timely
and equitably compare their results and advances. With this dataset, we want to
(i) support the development of new methods and (ii) establish quantitative
comparisons for approaches coming from the broader robotics, controls, and
artificial intelligence communities. We want to provide a one-stop resource
that is comprehensive of (i) aggressive autonomous and piloted flight, (ii)
high-resolution, high-frequency visual, inertial, and motion capture data,
(iii) commands and control inputs, (iv) multiple light settings, and (v)
corner-level labeling of drone racing gates. We also release the complete
specifications to recreate our flight platform, using commercial off-the-shelf
components and the open-source flight controller Betaflight. Our dataset,
open-source scripts, and drone design are available at:
https://github.com/tii-racing/drone-racing-dataset.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02668" title="Abstract">arXiv:2311.02668</a> [<a href="/pdf/2311.02668" title="Download PDF">pdf</a>, <a href="/format/2311.02668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic control of convertible fixed-wing aircraft with vectorized  thrust
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=de+Oliveira%2C+T+L">Tomas Lopes de Oliveira</a>, 
<a href="/search/eess?searchtype=author&query=Anglade%2C+A">Andre Anglade</a>, 
<a href="/search/eess?searchtype=author&query=Hamel%2C+T">Tarek Hamel</a>, 
<a href="/search/eess?searchtype=author&query=Samson%2C+C">Claude Samson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, to appear in Proceedings of IFAC World Congress 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper is an addition to an article previously published by three of the
authors that addresses the control of convertible fixed-wing aircraft with
vectorized thrust. The control solution here developed extends the one
presented in the former paper by complementing it with a strategy for the
hovering flight and a control policy to handle the transition phase between low
and high airspeed. An estimator of the air velocity required in all flight
phases is also proposed. Realistic simulation results on a tri-tilt rotor
Unmanned Aerial Vehicle (UAV) illustrate and assess the methodology.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02673" title="Abstract">arXiv:2311.02673</a> [<a href="/pdf/2311.02673" title="Download PDF">pdf</a>, <a href="/format/2311.02673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Commutativity Simplifies Proofs of Parameterized Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farzan%2C+A">Azadeh Farzan</a>, 
<a href="/search/cs?searchtype=author&query=Klumpp%2C+D">Dominik Klumpp</a>, 
<a href="/search/cs?searchtype=author&query=Podelski%2C+A">Andreas Podelski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages (26 excluding references), 8 figures, 1 table; preprint of the paper that is conditionally accepted at POPL'2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Commutativity has proven to be a powerful tool in reasoning about concurrent
programs. Recent work has shown that a commutativity-based reduction of a
program may admit simpler proofs than the program itself. The framework of
lexicographical program reductions was introduced to formalize a broad class of
reductions. Approaches based on this framework, however, were limited to
program models with a fixed number of threads. In this paper, we show that it
is possible to define an effective parametric family of program reductions that
can be used to find simple proofs for parameterized programs, i.e., programs
with an unbounded number of threads. We show that reductions are indeed useful
for the simplification of proofs of parameterized programs, in a sense that can
be made precise: A reduction of a parameterized program may admit a proof which
uses fewer or less sophisticated ghost variables. The reduction may therefore
be within reach of an automated verification technique, even when the original
parameterized program is not. We introduce a notion of reductions for
parameterized programs such that the reduction $\mathcal{R}$ of a parameterized
program $\mathcal{P}$ is again a parameterized program (the thread template of
$\mathcal{R}$ is obtained by source-to-source transformation of the thread
template of $\mathcal{P}$). Consequently, existing techniques for the
verification of parameterized programs can be directly applied to $\mathcal{R}$
instead of $\mathcal{P}$. We define an appropriate family of pairwise
preference orders which can be used to produce different lexicographical
reductions. To determine whether this theoretical foundation amounts to a
usable solution in practice, we have implemented the approach, based on a
recently proposed framework for parameterized program verification. The results
of our preliminary experiments on a representative set of examples are
encouraging.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02677" title="Abstract">arXiv:2311.02677</a> [<a href="/pdf/2311.02677" title="Download PDF">pdf</a>, <a href="/format/2311.02677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forming a symmetric, unreduced, tridiagonal matrix with a given spectrum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dieci%2C+L">Luca Dieci</a>, 
<a href="/search/math?searchtype=author&query=Pugliese%2C+A">Alessandro Pugliese</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Given a set of $n$ distinct real numbers, our goal is to form a symmetric,
unreduced, tridiagonal, matrix with those numbers as eigenvalues. We give an
algorithm which is a stable implementation of a naive algorithm forming the
characteristic polynomial and then using a technique of Schmeisser.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02679" title="Abstract">arXiv:2311.02679</a> [<a href="/pdf/2311.02679" title="Download PDF">pdf</a>, <a href="/format/2311.02679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regret Analysis of Learning-Based Linear Quadratic Gaussian Control with  Additive Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Athrey%2C+A">Archith Athrey</a>, 
<a href="/search/eess?searchtype=author&query=Mazhar%2C+O">Othmane Mazhar</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+M">Meichen Guo</a>, 
<a href="/search/eess?searchtype=author&query=De+Schutter%2C+B">Bart De Schutter</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+S">Shengling Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we analyze the regret incurred by a computationally efficient
exploration strategy, known as naive exploration, for controlling unknown
partially observable systems within the Linear Quadratic Gaussian (LQG)
framework. We introduce a two-phase control algorithm called LQG-NAIVE, which
involves an initial phase of injecting Gaussian input signals to obtain a
system model, followed by a second phase of an interplay between naive
exploration and control in an episodic fashion. We show that LQG-NAIVE achieves
a regret growth rate of $\tilde{\mathcal{O}}(\sqrt{T})$, i.e.,
$\mathcal{O}(\sqrt{T})$ up to logarithmic factors after $T$ time steps, and we
validate its performance through numerical simulations. Additionally, we
propose LQG-IF2E, which extends the exploration signal to a `closed-loop'
setting by incorporating the Fisher Information Matrix (FIM). We provide
compelling numerical evidence of the competitive performance of LQG-IF2E
compared to LQG-NAIVE.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02684" title="Abstract">arXiv:2311.02684</a> [<a href="/pdf/2311.02684" title="Download PDF">pdf</a>, <a href="/format/2311.02684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Octavius: Mitigating Task Interference in MLLMs via MoE
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zeren Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziqin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huayang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhenfei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Si Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+L">Lu Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jing Shao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent studies have demonstrated Large Language Models (LLMs) can extend
their zero-shot generalization capabilities to multimodal learning through
instruction tuning. As more modalities and downstream tasks are introduced,
negative conflicts and interference may have a worse impact on performance.
While this phenomenon has been overlooked in previous work, we propose a novel
and extensible framework, called \mname, for comprehensive studies and
experimentation on multimodal learning with Multimodal Large Language Models
(MLLMs). Specifically, we combine the well-known Mixture-of-Experts (MoE) and
one of the representative PEFT techniques, \emph{i.e.,} LoRA, designing a novel
LLM-based decoder, called LoRA-MoE, for multimodal learning. The experimental
results (about 20\% improvement) have shown the effectiveness and versatility
of our design in various 2D and 3D downstream tasks. Code and corresponding
dataset will be available soon.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02687" title="Abstract">arXiv:2311.02687</a> [<a href="/pdf/2311.02687" title="Download PDF">pdf</a>, <a href="/format/2311.02687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Architecture Matters: Uncovering Implicit Mechanisms in Graph  Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiaojun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zeming Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yisen Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">With the prosperity of contrastive learning for visual representation
learning (VCL), it is also adapted to the graph domain and yields promising
performance. However, through a systematic study of various graph contrastive
learning (GCL) methods, we observe that some common phenomena among existing
GCL methods that are quite different from the original VCL methods, including
1) positive samples are not a must for GCL; 2) negative samples are not
necessary for graph classification, neither for node classification when
adopting specific normalization modules; 3) data augmentations have much less
influence on GCL, as simple domain-agnostic augmentations (e.g., Gaussian
noise) can also attain fairly good performance. By uncovering how the implicit
inductive bias of GNNs works in contrastive learning, we theoretically provide
insights into the above intriguing properties of GCL. Rather than directly
porting existing VCL methods to GCL, we advocate for more attention toward the
unique architecture of graph learning and consider its implicit influence when
designing GCL methods. Code is available at https:
//github.com/PKU-ML/ArchitectureMattersGCL.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02691" title="Abstract">arXiv:2311.02691</a> [<a href="/pdf/2311.02691" title="Download PDF">pdf</a>, <a href="/ps/2311.02691" title="Download PostScript">ps</a>, <a href="/format/2311.02691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Age of Information Analysis for CR-NOMA Aided Uplink Systems with  Randomly Arrived Packets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yanshi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yanglin Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zhiguo Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Momiao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lei Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper studies the application of cognitive radio inspired non-orthogonal
multiple access (CR-NOMA) to reduce age of information (AoI) for uplink
transmission. In particular, a time division multiple access (TDMA) based
legacy network is considered, where each user is allocated with a dedicated
time slot to transmit its status update information. The CR-NOMA is implemented
as an add-on to the TDMA legacy network, which enables each user to have more
opportunities to transmit by sharing other user's time slots. A rigorous
analytical framework is developed to obtain the expressions for AoIs achieved
by CR-NOMA with and without re-transmission, by taking the randomness of the
status update generating process into consideration. Numerical results are
presented to verify the accuracy of the developed analysis. It is shown that
the AoI can be significantly reduced by applying CR-NOMA compared to TDMA.
Moreover, the use of re-transmission is helpful to reduce AoI, especially when
the status arrival rate is low.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02692" title="Abstract">arXiv:2311.02692</a> [<a href="/pdf/2311.02692" title="Download PDF">pdf</a>, <a href="/format/2311.02692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChEF: A Comprehensive Evaluation Framework for Standardized Assessment  of Multimodal Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhelun Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhipin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Hongxing Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhenfei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+L">Lu Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jing Shao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 26 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multimodal Large Language Models (MLLMs) have shown impressive abilities in
interacting with visual content with myriad potential downstream tasks.
However, even though a list of benchmarks has been proposed, the capabilities
and limitations of MLLMs are still not comprehensively understood, due to a
lack of a standardized and holistic evaluation framework. To this end, we
present the first Comprehensive Evaluation Framework (ChEF) that can
holistically profile each MLLM and fairly compare different MLLMs. First, we
structure ChEF as four modular components, i.e., Scenario as scalable
multimodal datasets, Instruction as flexible instruction retrieving formulae,
Inferencer as reliable question answering strategies, and Metric as indicative
task-specific score functions. Based on them, ChEF facilitates versatile
evaluations in a standardized framework, and new evaluations can be built by
designing new Recipes (systematic selection of these four components). Notably,
current MLLM benchmarks can be readily summarized as recipes of ChEF. Second,
we introduce 6 new recipes to quantify competent MLLMs' desired capabilities
(or called desiderata, i.e., calibration, in-context learning, instruction
following, language performance, hallucination, and robustness) as reliable
agents that can perform real-world multimodal interactions. Third, we conduct a
large-scale evaluation of 9 prominent MLLMs on 9 scenarios and 6 desiderata.
Our evaluation summarized over 20 valuable observations concerning the
generalizability of MLLMs across various scenarios and the composite capability
of MLLMs required for multimodal interactions. We will publicly release all the
detailed implementations for further analysis, as well as an easy-to-use
modular toolkit for the integration of new recipes and models, so that ChEF can
be a growing evaluation framework for the MLLM community.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02697" title="Abstract">arXiv:2311.02697</a> [<a href="/pdf/2311.02697" title="Download PDF">pdf</a>, <a href="/format/2311.02697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SinClave: Hardware-assisted Singletons for TEEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gregor%2C+F">Franz Gregor</a>, 
<a href="/search/cs?searchtype=author&query=Krahn%2C+R">Robert Krahn</a>, 
<a href="/search/cs?searchtype=author&query=Quoc%2C+D+L">Do Le Quoc</a>, 
<a href="/search/cs?searchtype=author&query=Fetzer%2C+C">Christof Fetzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">For trusted execution environments (TEEs), remote attestation permits
establishing trust in software executed on a remote host. It requires that the
measurement of a remote TEE is both complete and fresh: We need to measure all
aspects that might determine the behavior of an application, and this
measurement has to be reasonably fresh. Performing measurements only at the
start of a TEE simplifies the attestation but enables "reuse" attacks of
enclaves. We demonstrate how to perform such reuse attacks for different TEE
frameworks. We also show how to address this issue by enforcing freshness -
through the concept of a singleton enclave - and completeness of the
measurements. Completeness of measurements is not trivial since the secrets
provisioned to an enclave and the content of the filesystem can both affect the
behavior of the software, i.e., can be used to mount reuse attacks. We present
mechanisms to include measurements of these two components in the remote
attestation. Our evaluation based on real-world applications shows that our
approach incurs only negligible overhead ranging from 1.03% to 13.2%.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02699" title="Abstract">arXiv:2311.02699</a> [<a href="/pdf/2311.02699" title="Download PDF">pdf</a>, <a href="/ps/2311.02699" title="Download PostScript">ps</a>, <a href="/format/2311.02699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nepali Video Captioning using CNN-RNN Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Subedi%2C+B">Bipesh Subedi</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Saugat Singh</a>, 
<a href="/search/cs?searchtype=author&query=Bal%2C+B+K">Bal Krishna Bal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures, 3 tables. Presented in the International Conference on Technologies for Computer, Electrical, Electronics &amp; Communication (ICT-CEEL 2023), Bhaktapur, Nepal
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In proceedings of the International Conference on Technologies for
  Computer, Electrical, Electronics &amp; Communication (ICT-CEEL 2023), Bhaktapur,
  Nepal. Part-1 94-99
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">This article presents a study on Nepali video captioning using deep neural
networks. Through the integration of pre-trained CNNs and RNNs, the research
focuses on generating precise and contextually relevant captions for Nepali
videos. The approach involves dataset collection, data preprocessing, model
implementation, and evaluation. By enriching the MSVD dataset with Nepali
captions via Google Translate, the study trains various CNN-RNN architectures.
The research explores the effectiveness of CNNs (e.g., EfficientNetB0,
ResNet101, VGG16) paired with different RNN decoders like LSTM, GRU, and
BiLSTM. Evaluation involves BLEU and METEOR metrics, with the best model being
EfficientNetB0 + BiLSTM with 1024 hidden dimensions, achieving a BLEU-4 score
of 17 and METEOR score of 46. The article also outlines challenges and future
directions for advancing Nepali video captioning, offering a crucial resource
for further research in this area.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02700" title="Abstract">arXiv:2311.02700</a> [<a href="/pdf/2311.02700" title="Download PDF">pdf</a>, <a href="/format/2311.02700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generative Multi-Resolution Pyramid and Normal-Conditioning 3D Cloth  Draping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laczk%C3%B3%2C+H">Hunor Laczk&#xf3;</a>, 
<a href="/search/cs?searchtype=author&query=Madadi%2C+M">Meysam Madadi</a>, 
<a href="/search/cs?searchtype=author&query=Escalera%2C+S">Sergio Escalera</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+J">Jordi Gonzalez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV24, IEEE copyright
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">RGB cloth generation has been deeply studied in the related literature,
however, 3D garment generation remains an open problem. In this paper, we build
a conditional variational autoencoder for 3D garment generation and draping. We
propose a pyramid network to add garment details progressively in a canonical
space, i.e. unposing and unshaping the garments w.r.t. the body. We study
conditioning the network on surface normal UV maps, as an intermediate
representation, which is an easier problem to optimize than 3D coordinates. Our
results on two public datasets, CLOTH3D and CAPE, show that our model is
robust, controllable in terms of detail generation by the use of
multi-resolution pyramids, and achieves state-of-the-art results that can
highly generalize to unseen garments, poses, and shapes even when training with
small amounts of data.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02701" title="Abstract">arXiv:2311.02701</a> [<a href="/pdf/2311.02701" title="Download PDF">pdf</a>, <a href="/format/2311.02701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error bounds for the approximation of matrix functions with rational  Krylov methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Simunec%2C+I">Igor Simunec</a> (Scuola Normale Superiore)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We obtain an expression for the error in the approximation of $f(A)
\boldsymbol{b}$ and $\boldsymbol{b}^T f(A) \boldsymbol{b}$ with rational Krylov
methods, where $A$ is a symmetric matrix, $\boldsymbol{b}$ is a vector and the
function $f$ admits an integral representation. The error expression is
obtained by linking the matrix function error with the error in the approximate
solution of shifted linear systems using the same rational Krylov subspace, and
it can be exploited to derive both a priori and a posteriori error bounds. The
error bounds are a generalization of the ones given in [T. Chen, A. Greenbaum,
C. Musco, C. Musco, SIAM J. Matrix Anal. Appl., 43 (2022), pp. 787--811]
(<a href="/abs/2106.09806">arXiv:2106.09806</a>) for the Lanczos method for matrix functions. A technique
that we employ in the rational Krylov context can also be applied to refine the
bounds for the Lanczos case.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02702" title="Abstract">arXiv:2311.02702</a> [<a href="/pdf/2311.02702" title="Download PDF">pdf</a>, <a href="/format/2311.02702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extraction of Atypical Aspects from Customer Reviews: Datasets and  Experiments with Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nannaware%2C+S">Smita Nannaware</a>, 
<a href="/search/cs?searchtype=author&query=Al-Hossami%2C+E">Erfan Al-Hossami</a>, 
<a href="/search/cs?searchtype=author&query=Bunescu%2C+R">Razvan Bunescu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the Knowledge-aware and Conversational Recommender Systems Workshop (KaRS) @ RecSys, September 19, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">A restaurant dinner may become a memorable experience due to an unexpected
aspect enjoyed by the customer, such as an origami-making station in the
waiting area. If aspects that are atypical for a restaurant experience were
known in advance, they could be leveraged to make recommendations that have the
potential to engender serendipitous experiences, further increasing user
satisfaction. Although relatively rare, whenever encountered, atypical aspects
often end up being mentioned in reviews due to their memorable quality.
Correspondingly, in this paper we introduce the task of detecting atypical
aspects in customer reviews. To facilitate the development of extraction
models, we manually annotate benchmark datasets of reviews in three domains -
restaurants, hotels, and hair salons, which we use to evaluate a number of
language models, ranging from fine-tuning the instruction-based text-to-text
transformer Flan-T5 to zero-shot and few-shot prompting of GPT-3.5.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02703" title="Abstract">arXiv:2311.02703</a> [<a href="/pdf/2311.02703" title="Download PDF">pdf</a>, <a href="/format/2311.02703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Trustworthy Identity Tracing via Multi-attribute Synergistic  Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Decheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiahao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Ruimin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+W">Wenbin Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Identity tracing is a technology that uses the selection and collection of
identity attributes of the object to be tested to discover its true identity,
and it is one of the most important foundational issues in the field of social
security prevention. However, traditional identity recognition technologies
based on single attributes have difficulty achieving ultimate recognition
accuracy, where deep learning-based model always lacks interpretability.
Multivariate attribute collaborative identification is a possible key way to
overcome the mentioned recognition errors and low data quality problems. In
this paper, we propose the Trustworthy Identity Tracing (TIT) task and a
Multi-attribute Synergistic Identification based TIT framework. We first
established a novel identity model based on identity entropy theoretically. The
individual conditional identity entropy and core identification set are defined
to reveal the intrinsic mechanism of multivariate attribute collaborative
identification. Based on the proposed identity model, we propose a trustworthy
identity tracing framework (TITF) with multi-attribute synergistic
identification to determine the identity of unknown objects, which can optimize
the core identification set and provide an interpretable identity tracing
process. Actually, the essence of identity tracing is revealed to be the
process of the identity entropy value converging to zero. To cope with the lack
of test data, we construct a dataset of 1000 objects to simulate real-world
scenarios, where 20 identity attributes are labeled to trace unknown object
identities. The experiment results conducted on the mentioned dataset show the
proposed TITF algorithm can achieve satisfactory identification performance.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02707" title="Abstract">arXiv:2311.02707</a> [<a href="/pdf/2311.02707" title="Download PDF">pdf</a>, <a href="/format/2311.02707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Study of Uncertainty in Polygon Annotation and the Impact  of Quality Assurance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zimmermann%2C+E">Eric Zimmermann</a>, 
<a href="/search/cs?searchtype=author&query=Szeto%2C+J">Justin Szeto</a>, 
<a href="/search/cs?searchtype=author&query=Ratle%2C+F">Frederic Ratle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023 DataComp Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Polygons are a common annotation format used for quickly annotating objects
in instance segmentation tasks. However, many real-world annotation projects
request near pixel-perfect labels. While strict pixel guidelines may appear to
be the solution to a successful project, practitioners often fail to assess the
feasibility of the work requested, and overlook common factors that may
challenge the notion of quality. This paper aims to examine and quantify the
inherent uncertainty for polygon annotations and the role that quality
assurance plays in minimizing its effect. To this end, we conduct an analysis
on multi-rater polygon annotations for several objects from the MS-COCO
dataset. The results demonstrate that the reliability of a polygon annotation
is dependent on a reviewing procedure, as well as the scene and shape
complexity.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02708" title="Abstract">arXiv:2311.02708</a> [<a href="/pdf/2311.02708" title="Download PDF">pdf</a>, <a href="/format/2311.02708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Highly Connected Steiner Subgraph -- Parameterized Algorithms and  Applications to Hitting Set Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eiben%2C+E">Eduard Eiben</a>, 
<a href="/search/cs?searchtype=author&query=Majumdar%2C+D">Diptapriyo Majumdar</a>, 
<a href="/search/cs?searchtype=author&query=Ramanujan%2C+M+S">M. S. Ramanujan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preliminary version appeared in MFCS-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Given a simple connected undirected graph G = (V, E), a set X \subseteq V(G),
and integers k and p, STEINER SUBGRAPH EXTENSION problem asks if there exists a
set S \supseteq X with at most k vertices such that G[S] is p-edge-connected.
This is a natural generalization of a well-studied problem STEINER TREE (set
p=1 and X as the set of all terminals). In this paper, we initiate the study of
STEINER SUBGRAPH EXTENSION from the perspective of parameterized complexity and
give a fixed-parameter algorithm parameterized by k and p on graphs of bounded
degeneracy. In case we remove the assumption of the input graph being bounded
degenerate, then the STEINER SUBGRAPH EXTENSION problem becomes W[1]-hard.
Besides being an independent advance on the parameterized complexity of network
design problems, our result has natural applications. In particular, we use our
result to obtain singly exponential-time FPT algorithms for several vertex
deletion problem studied in the literature, where the goal is to delete a
smallest set of vertices such that (i) the resulting graph belongs to a
specific hereditary graph class, and (ii) the deleted set of vertices induces a
p-edge-connected subgraph of the input graph.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02709" title="Abstract">arXiv:2311.02709</a> [<a href="/pdf/2311.02709" title="Download PDF">pdf</a>, <a href="/format/2311.02709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking a Benchmark: How Reliable is MS-COCO?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zimmermann%2C+E">Eric Zimmermann</a>, 
<a href="/search/cs?searchtype=author&query=Szeto%2C+J">Justin Szeto</a>, 
<a href="/search/cs?searchtype=author&query=Pasquero%2C+J">Jerome Pasquero</a>, 
<a href="/search/cs?searchtype=author&query=Ratle%2C+F">Frederic Ratle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023 DataComp Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Benchmark datasets are used to profile and compare algorithms across a
variety of tasks, ranging from image classification to segmentation, and also
play a large role in image pretraining algorithms. Emphasis is placed on
results with little regard to the actual content within the dataset. It is
important to question what kind of information is being learned from these
datasets and what are the nuances and biases within them. In the following
work, Sama-COCO, a re-annotation of MS-COCO, is used to discover potential
biases by leveraging a shape analysis pipeline. A model is trained and
evaluated on both datasets to examine the impact of different annotation
conditions. Results demonstrate that annotation styles are important and that
annotation pipelines should closely consider the task of interest. The dataset
is made publicly available at https://www.sama.com/sama-coco-dataset/ .
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02715" title="Abstract">arXiv:2311.02715</a> [<a href="/pdf/2311.02715" title="Download PDF">pdf</a>, <a href="/format/2311.02715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Correlated Auxiliary Feedback in Parameterized Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verma%2C+A">Arun Verma</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Z">Zhongxiang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+Y">Yao Shu</a>, 
<a href="/search/cs?searchtype=author&query=Low%2C+B+K+H">Bryan Kian Hsiang Low</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We study a novel variant of the parameterized bandits problem in which the
learner can observe additional auxiliary feedback that is correlated with the
observed reward. The auxiliary feedback is readily available in many real-life
applications, e.g., an online platform that wants to recommend the best-rated
services to its users can observe the user's rating of service (rewards) and
collect additional information like service delivery time (auxiliary feedback).
In this paper, we first develop a method that exploits auxiliary feedback to
build a reward estimator with tight confidence bounds, leading to a smaller
regret. We then characterize the regret reduction in terms of the correlation
coefficient between reward and its auxiliary feedback. Experimental results in
different settings also verify the performance gain achieved by our proposed
method.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02719" title="Abstract">arXiv:2311.02719</a> [<a href="/pdf/2311.02719" title="Download PDF">pdf</a>, <a href="/format/2311.02719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Estimation for Safety-critical Scene Segmentation via  Fine-grained Reward Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongzheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yueyao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Scheppach%2C+M">Markus Scheppach</a>, 
<a href="/search/cs?searchtype=author&query=Yip%2C+H+C">Hon Chi Yip</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Q">Qi Dou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Uncertainty estimation plays an important role for future reliable deployment
of deep segmentation models in safety-critical scenarios such as medical
applications. However, existing methods for uncertainty estimation have been
limited by the lack of explicit guidance for calibrating the prediction risk
and model confidence. In this work, we propose a novel fine-grained reward
maximization (FGRM) framework, to address uncertainty estimation by directly
utilizing an uncertainty metric related reward function with a reinforcement
learning based model tuning algorithm. This would benefit the model uncertainty
estimation through direct optimization guidance for model calibration.
Specifically, our method designs a new uncertainty estimation reward function
using the calibration metric, which is maximized to fine-tune an evidential
learning pre-trained segmentation model for calibrating prediction risk.
Importantly, we innovate an effective fine-grained parameter update scheme,
which imposes fine-grained reward-weighting of each network parameter according
to the parameter importance quantified by the fisher information matrix. To the
best of our knowledge, this is the first work exploring reward optimization for
model uncertainty estimation in safety-critical vision tasks. The effectiveness
of our method is demonstrated on two large safety-critical surgical scene
segmentation datasets under two different uncertainty estimation settings. With
real-time one forward pass at inference, our method outperforms
state-of-the-art methods by a clear margin on all the calibration metrics of
uncertainty estimation, while maintaining a high task accuracy for the
segmentation results. Code is available at
\url{https://github.com/med-air/FGRM}.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02732" title="Abstract">arXiv:2311.02732</a> [<a href="/pdf/2311.02732" title="Download PDF">pdf</a>, <a href="/format/2311.02732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving High Dimensional Partial Differential Equations Using Tensor  Neural Network and A Posteriori Error Estimators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+Y">Yifan Wang</a>, 
<a href="/search/math?searchtype=author&query=Lin%2C+Z">Zhongshuo Lin</a>, 
<a href="/search/math?searchtype=author&query=Liao%2C+Y">Yangfei Liao</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+H">Haochen Liu</a>, 
<a href="/search/math?searchtype=author&query=Xie%2C+H">Hehu Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 31 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we first propose a new type of tensor neural network and the
corresponding machine learning method to solve high-dimensional boundary value
problems with Dirichlet or Neumann type of boundary conditions and eigenvalue
problems of the second order elliptic operator. The most important advantage of
the proposed network is that when calculating the loss function, the high
dimensional integration can be computed with high accuracy using fixed
quadrature points within tolerable computational complexity. Based on the
theory of a posteriori error estimation, a machine learning method which use a
posteriori error estimator as the loss function is designed to select optimal
network parameters adaptively. The theoretical analysis and numerical examples
are provided to validate the proposed methods.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02733" title="Abstract">arXiv:2311.02733</a> [<a href="/pdf/2311.02733" title="Download PDF">pdf</a>, <a href="/format/2311.02733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AV-Lip-Sync+: Leveraging AV-HuBERT to Exploit Multimodal Inconsistency  for Video Deepfake Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shahzad%2C+S+A">Sahibzada Adil Shahzad</a>, 
<a href="/search/cs?searchtype=author&query=Hashmi%2C+A">Ammarah Hashmi</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yan-Tsung Peng</a>, 
<a href="/search/cs?searchtype=author&query=Tsao%2C+Y">Yu Tsao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hsin-Min Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Multimodal manipulations (also known as audio-visual deepfakes) make it
difficult for unimodal deepfake detectors to detect forgeries in multimedia
content. To avoid the spread of false propaganda and fake news, timely
detection is crucial. The damage to either modality (i.e., visual or audio) can
only be discovered through multi-modal models that can exploit both pieces of
information simultaneously. Previous methods mainly adopt uni-modal video
forensics and use supervised pre-training for forgery detection. This study
proposes a new method based on a multi-modal self-supervised-learning (SSL)
feature extractor to exploit inconsistency between audio and visual modalities
for multi-modal video forgery detection. We use the transformer-based SSL
pre-trained Audio-Visual HuBERT (AV-HuBERT) model as a visual and acoustic
feature extractor and a multi-scale temporal convolutional neural network to
capture the temporal correlation between the audio and visual modalities. Since
AV-HuBERT only extracts visual features from the lip region, we also adopt
another transformer-based video model to exploit facial features and capture
spatial and temporal artifacts caused during the deepfake generation process.
Experimental results show that our model outperforms all existing models and
achieves new state-of-the-art performance on the FakeAVCeleb and DeepfakeTIMIT
datasets.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02734" title="Abstract">arXiv:2311.02734</a> [<a href="/pdf/2311.02734" title="Download PDF">pdf</a>, <a href="/format/2311.02734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ISAR: A Benchmark for Single- and Few-Shot Object Instance Segmentation  and Re-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gorlo%2C+N">Nicolas Gorlo</a>, 
<a href="/search/cs?searchtype=author&query=Blomqvist%2C+K">Kenneth Blomqvist</a>, 
<a href="/search/cs?searchtype=author&query=Milano%2C+F">Francesco Milano</a>, 
<a href="/search/cs?searchtype=author&query=Siegwart%2C+R">Roland Siegwart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, to be published in IEEE WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Most object-level mapping systems in use today make use of an upstream
learned object instance segmentation model. If we want to teach them about a
new object or segmentation class, we need to build a large dataset and retrain
the system. To build spatial AI systems that can quickly be taught about new
objects, we need to effectively solve the problem of single-shot object
detection, instance segmentation and re-identification. So far there is neither
a method fulfilling all of these requirements in unison nor a benchmark that
could be used to test such a method. Addressing this, we propose ISAR, a
benchmark and baseline method for single- and few-shot object Instance
Segmentation And Re-identification, in an effort to accelerate the development
of algorithms that can robustly detect, segment, and re-identify objects from a
single or a few sparse training examples. We provide a semi-synthetic dataset
of video sequences with ground-truth semantic annotations, a standardized
evaluation pipeline, and a baseline method. Our benchmark aligns with the
emerging research trend of unifying Multi-Object Tracking, Video Object
Segmentation, and Re-identification.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02736" title="Abstract">arXiv:2311.02736</a> [<a href="/pdf/2311.02736" title="Download PDF">pdf</a>, <a href="/format/2311.02736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JRDB-Traj: A Dataset and Benchmark for Trajectory Forecasting in Crowds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saadatnejad%2C+S">Saeed Saadatnejad</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Rezatofighi%2C+H">Hamid Rezatofighi</a>, 
<a href="/search/cs?searchtype=author&query=Alahi%2C+A">Alexandre Alahi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Predicting future trajectories is critical in autonomous navigation,
especially in preventing accidents involving humans, where a predictive agent's
ability to anticipate in advance is of utmost importance. Trajectory
forecasting models, employed in fields such as robotics, autonomous vehicles,
and navigation, face challenges in real-world scenarios, often due to the
isolation of model components. To address this, we introduce a novel dataset
for end-to-end trajectory forecasting, facilitating the evaluation of models in
scenarios involving less-than-ideal preceding modules such as tracking. This
dataset, an extension of the JRDB dataset, provides comprehensive data,
including the locations of all agents, scene images, and point clouds, all from
the robot's perspective. The objective is to predict the future positions of
agents relative to the robot using raw sensory input data. It bridges the gap
between isolated models and practical applications, promoting a deeper
understanding of navigation dynamics. Additionally, we introduce a novel metric
for assessing trajectory forecasting models in real-world scenarios where
ground-truth identities are inaccessible, addressing issues related to
undetected or over-detected agents. Researchers are encouraged to use our
benchmark for model evaluation and benchmarking.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02737" title="Abstract">arXiv:2311.02737</a> [<a href="/pdf/2311.02737" title="Download PDF">pdf</a>, <a href="/format/2311.02737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CIRCLE: Multi-Turn Query Clarifications with Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Erbacher%2C+P">Pierre Erbacher</a>, 
<a href="/search/cs?searchtype=author&query=Soulier%2C+L">Laure Soulier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Users often have trouble formulating their information needs into words on
the first try when searching online. This can lead to frustration, as they may
have to reformulate their queries when retrieved information is not relevant.
This can be due to a lack of familiarity with the specific terminology related
to their search topic, or because queries are ambiguous and related to multiple
topics. Most modern search engines have interactive features that suggest
clarifications or similar queries based on what others have searched for.
However, the proposed models are either based on a single interaction or
evaluated on search logs, hindering the naturalness of the interactions. In
this paper, we introduce CIRCLE, a generative model for multi-turn query
Clarifications wIth ReinforCement LEarning that leverages multi-turn
interactions through a user simulation framework. Our model aims at generating
a diverse set of query clarifications using a pretrained language model
fine-tuned using reinforcement learning. We evaluate it against well
established google suggestions using a user simulation framework.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02738" title="Abstract">arXiv:2311.02738</a> [<a href="/pdf/2311.02738" title="Download PDF">pdf</a>, <a href="/format/2311.02738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scenario Diffusion: Controllable Driving Scenario Generation With  Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pronovost%2C+E">Ethan Pronovost</a>, 
<a href="/search/cs?searchtype=author&query=Ganesina%2C+M+R">Meghana Reddy Ganesina</a>, 
<a href="/search/cs?searchtype=author&query=Hendy%2C+N">Noureldin Hendy</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zeyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Morales%2C+A">Andres Morales</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+N">Nicholas Roy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
<p class="mathjax">Automated creation of synthetic traffic scenarios is a key part of validating
the safety of autonomous vehicles (AVs). In this paper, we propose Scenario
Diffusion, a novel diffusion-based architecture for generating traffic
scenarios that enables controllable scenario generation. We combine latent
diffusion, object detection and trajectory regression to generate distributions
of synthetic agent poses, orientations and trajectories simultaneously. To
provide additional control over the generated scenario, this distribution is
conditioned on a map and sets of tokens describing the desired scenario. We
show that our approach has sufficient expressive capacity to model diverse
traffic patterns and generalizes to different geographical regions.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02741" title="Abstract">arXiv:2311.02741</a> [<a href="/pdf/2311.02741" title="Download PDF">pdf</a>, <a href="/format/2311.02741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Independently from Causality in Multi-Agent Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pina%2C+R">Rafael Pina</a>, 
<a href="/search/cs?searchtype=author&query=De+Silva%2C+V">Varuna De Silva</a>, 
<a href="/search/cs?searchtype=author&query=Artaud%2C+C">Corentin Artaud</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 12th International Conference on Pattern Recognition Applications and Methods (ICPRAM 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Multi-Agent Reinforcement Learning (MARL) comprises an area of growing
interest in the field of machine learning. Despite notable advances, there are
still problems that require investigation. The lazy agent pathology is a famous
problem in MARL that denotes the event when some of the agents in a MARL team
do not contribute to the common goal, letting the teammates do all the work. In
this work, we aim to investigate this problem from a causality-based
perspective. We intend to create the bridge between the fields of MARL and
causality and argue about the usefulness of this link. We study a fully
decentralised MARL setup where agents need to learn cooperation strategies and
show that there is a causal relation between individual observations and the
team reward. The experiments carried show how this relation can be used to
improve independent agents in MARL, resulting not only on better performances
as a team but also on the rise of more intelligent behaviours on individual
agents.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02745" title="Abstract">arXiv:2311.02745</a> [<a href="/pdf/2311.02745" title="Download PDF">pdf</a>, <a href="/format/2311.02745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The madness of people: rational learning in feedback-evolving games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paarporn%2C+K">Keith Paarporn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Systems and Control (eess.SY); Populations and Evolution (q-bio.PE)

</div>
<p class="mathjax">The replicator equation in evolutionary game theory describes the change in a
population's behaviors over time given suitable incentives. It arises when
individuals make decisions using a simple learning process - imitation. A
recent emerging framework builds upon this standard model by incorporating
game-environment feedback, in which the population's actions affect a shared
environment, and in turn, the changing environment shapes incentives for future
behaviors. In this paper, we investigate game-environment feedback when
individuals instead use a boundedly rational learning rule known as logit
learning. We characterize the resulting system's complete set of fixed points
and their local stability properties, and how the level of rationality
determines overall environmental outcomes in comparison to imitative learning
rules. We identify a large parameter space for which logit learning exhibits a
wide range of dynamics as the rationality parameter is increased from low to
high. Notably, we identify a bifurcation point at which the system exhibits
stable limit cycles. When the population is highly rational, the limit cycle
collapses and a tragedy of the commons becomes stable.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02746" title="Abstract">arXiv:2311.02746</a> [<a href="/pdf/2311.02746" title="Download PDF">pdf</a>, <a href="/format/2311.02746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Staged Reinforcement Learning for Complex Tasks through Decomposed  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pina%2C+R">Rafael Pina</a>, 
<a href="/search/cs?searchtype=author&query=Artaud%2C+C">Corentin Artaud</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaolan Liu</a>, 
<a href="/search/cs?searchtype=author&query=De+Silva%2C+V">Varuna De Silva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Intelligent Systems and Pattern Recognition 2023 (ISPR 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Reinforcement Learning (RL) is an area of growing interest in the field of
artificial intelligence due to its many notable applications in diverse fields.
Particularly within the context of intelligent vehicle control, RL has made
impressive progress. However, currently it is still in simulated controlled
environments where RL can achieve its full super-human potential. Although how
to apply simulation experience in real scenarios has been studied, how to
approximate simulated problems to the real dynamic problems is still a
challenge. In this paper, we discuss two methods that approximate RL problems
to real problems. In the context of traffic junction simulations, we
demonstrate that, if we can decompose a complex task into multiple sub-tasks,
solving these tasks first can be advantageous to help minimising possible
occurrences of catastrophic events in the complex task. From a multi-agent
perspective, we introduce a training structuring mechanism that exploits the
use of experience learned under the popular paradigm called Centralised
Training Decentralised Execution (CTDE). This experience can then be leveraged
in fully decentralised settings that are conceptually closer to real settings,
where agents often do not have access to a central oracle and must be treated
as isolated independent units. The results show that the proposed approaches
improve agents performance in complex tasks related to traffic junctions,
minimising potential safety-critical problems that might happen in these
scenarios. Although still in simulation, the investigated situations are
conceptually closer to real scenarios and thus, with these results, we intend
to motivate further research in the subject.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02747" title="Abstract">arXiv:2311.02747</a> [<a href="/pdf/2311.02747" title="Download PDF">pdf</a>, <a href="/format/2311.02747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention Modules Improve Image-Level Anomaly Detection for Industrial  Inspection: A DifferNet Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Silva%2C+A+L+B+V+e">Andr&#xe9; Luiz Buarque Vieira e Silva</a>, 
<a href="/search/cs?searchtype=author&query=Sim%C3%B5es%2C+F">Francisco Sim&#xf5;es</a>, 
<a href="/search/cs?searchtype=author&query=Kowerko%2C+D">Danny Kowerko</a>, 
<a href="/search/cs?searchtype=author&query=Schlosser%2C+T">Tobias Schlosser</a>, 
<a href="/search/cs?searchtype=author&query=Battisti%2C+F">Felipe Battisti</a>, 
<a href="/search/cs?searchtype=author&query=Teichrieb%2C+V">Veronica Teichrieb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Within (semi-)automated visual industrial inspection, learning-based
approaches for assessing visual defects, including deep neural networks, enable
the processing of otherwise small defect patterns in pixel size on
high-resolution imagery. The emergence of these often rarely occurring defect
patterns explains the general need for labeled data corpora. To alleviate this
issue and advance the current state of the art in unsupervised visual
inspection, this work proposes a DifferNet-based solution enhanced with
attention modules: AttentDifferNet. It improves image-level detection and
classification capabilities on three visual anomaly detection datasets for
industrial inspection: InsPLAD-fault, MVTec AD, and Semiconductor Wafer. In
comparison to the state of the art, AttentDifferNet achieves improved results,
which are, in turn, highlighted throughout our quali-quantitative study. Our
quantitative evaluation shows an average improvement - compared to DifferNet -
of 1.77 +/- 0.25 percentage points in overall AUROC considering all three
datasets, reaching SOTA results in InsPLAD-fault, an industrial inspection
in-the-wild dataset. As our variants to AttentDifferNet show great prospects in
the context of currently investigated approaches, a baseline is formulated,
emphasizing the importance of attention for industrial anomaly detection both
in the wild and in controlled environments.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02748" title="Abstract">arXiv:2311.02748</a> [<a href="/pdf/2311.02748" title="Download PDF">pdf</a>, <a href="/ps/2311.02748" title="Download PostScript">ps</a>, <a href="/format/2311.02748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pyclipse, a library for deidentification of free-text clinical notes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moore%2C+C">Callandra Moore</a>, 
<a href="/search/cs?searchtype=author&query=Ranisau%2C+J">Jonathan Ranisau</a>, 
<a href="/search/cs?searchtype=author&query=Nelson%2C+W">Walter Nelson</a>, 
<a href="/search/cs?searchtype=author&query=Petch%2C+J">Jeremy Petch</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+A">Alistair Johnson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Automated deidentification of clinical text data is crucial due to the high
cost of manual deidentification, which has been a barrier to sharing clinical
text and the advancement of clinical natural language processing. However,
creating effective automated deidentification tools faces several challenges,
including issues in reproducibility due to differences in text processing,
evaluation methods, and a lack of consistency across clinical domains and
institutions. To address these challenges, we propose the pyclipse framework, a
unified and configurable evaluation procedure to streamline the comparison of
deidentification algorithms. Pyclipse serves as a single interface for running
open-source deidentification algorithms on local clinical data, allowing for
context-specific evaluation. To demonstrate the utility of pyclipse, we compare
six deidentification algorithms across four public and two private clinical
text datasets. We find that algorithm performance consistently falls short of
the results reported in the original papers, even when evaluated on the same
benchmark dataset. These discrepancies highlight the complexity of accurately
assessing and comparing deidentification algorithms, emphasizing the need for a
reproducible, adjustable, and extensible framework like pyclipse. Our framework
lays the foundation for a unified approach to evaluate and improve
deidentification tools, ultimately enhancing patient protection in clinical
natural language processing.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02749" title="Abstract">arXiv:2311.02749</a> [<a href="/pdf/2311.02749" title="Download PDF">pdf</a>, <a href="/format/2311.02749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Point-cloud to Mesh Reconstruction for Deformable Object Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mansour%2C+E+A">Elham Amin Mansour</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hehui Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Katzschmann%2C+R+K">Robert K. Katzschmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages with appendix,16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">The world around us is full of soft objects that we as humans learn to
perceive and deform with dexterous hand movements from a young age. In order
for a Robotic hand to be able to control soft objects, it needs to acquire
online state feedback of the deforming object. While RGB-D cameras can collect
occluded information at a rate of 30 Hz, the latter does not represent a
continuously trackable object surface. Hence, in this work, we developed a
method that can create deforming meshes of deforming point clouds at a speed of
above 50 Hz for different categories of objects. The reconstruction of meshes
from point clouds has been long studied in the field of Computer graphics under
3D reconstruction and 4D reconstruction, however both lack the speed and
generalizability needed for robotics applications. Our model is designed using
a point cloud auto-encoder and a Real-NVP architecture. The latter is a
continuous flow neural network with manifold-preservation properties. Our model
takes a template mesh which is the mesh of an object in its canonical state and
then deforms the template mesh to match a deformed point cloud of the object.
Our method can perform mesh reconstruction and tracking at a rate of 58 Hz for
deformations of six different ycb categories. An instance of a downstream
application can be the control algorithm for a robotic hand that requires
online feedback from the state of a manipulated object which would allow online
grasp adaptation in a closed-loop manner. Furthermore, the tracking capacity
that our method provides can help in the system identification of deforming
objects in a marker-free approach. In future work, we will extend our method to
more categories of objects and real world deforming point clouds
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02756" title="Abstract">arXiv:2311.02756</a> [<a href="/pdf/2311.02756" title="Download PDF">pdf</a>, <a href="/format/2311.02756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Run-to-Run Adaptive Nonlinear Feedforward Control of Electromechanical  Switching Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Moya-Lasheras%2C+E">Eduardo Moya-Lasheras</a> (1), 
<a href="/search/eess?searchtype=author&query=Ramirez-Laboreo%2C+E">Edgar Ramirez-Laboreo</a> (1), 
<a href="/search/eess?searchtype=author&query=Serrano-Seco%2C+E">Eloy Serrano-Seco</a> (1) ((1) Universidad de Zaragoza)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Feedforward control can greatly improve the response time and control
accuracy of any mechatronic system. However, in order to compensate for the
effects of modeling errors or disturbances, it is imperative that this type of
control works in conjunction with some form of feedback. In this paper, we
present a new adaptive feedforward control scheme for electromechanical systems
in which real-time measurements or estimates of the position and its
derivatives are not technically or economically feasible. This is the case, for
example, of commercial electromechanical switching devices such as solenoid
actuators. Our proposal consists of two blocks: on the one hand, a feedforward
controller based on differential flatness theory; on the other, an iterative
adaptation law that exploits the repetitive operation of these devices to
modify the controller parameters cycle by cycle. As shown, this law can be fed
with any available measurement of the system, with the only requirement that it
can be processed and converted into an indicator of the performance of any
given operation. Simulated and experimental results show that our proposal is
effective in dealing with a long-standing control problem in electromechanics:
the soft-landing control of electromechanical switching devices.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02757" title="Abstract">arXiv:2311.02757</a> [<a href="/pdf/2311.02757" title="Download PDF">pdf</a>, <a href="/format/2311.02757" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ELEGANT: Certified Defense on the Fairness of Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yushun Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Binchi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+H">Hanghang Tong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jundong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Machine Learning (stat.ML)

</div>
<p class="mathjax">Graph Neural Networks (GNNs) have emerged as a prominent graph learning model
in various graph-based tasks over the years. Nevertheless, due to the
vulnerabilities of GNNs, it has been empirically proved that malicious
attackers could easily corrupt the fairness level of their predictions by
adding perturbations to the input graph data. In this paper, we take crucial
steps to study a novel problem of certifiable defense on the fairness level of
GNNs. Specifically, we propose a principled framework named ELEGANT and present
a detailed theoretical certification analysis for the fairness of GNNs. ELEGANT
takes any GNNs as its backbone, and the fairness level of such a backbone is
theoretically impossible to be corrupted under certain perturbation budgets for
attackers. Notably, ELEGANT does not have any assumption over the GNN structure
or parameters, and does not require re-training the GNNs to realize
certification. Hence it can serve as a plug-and-play framework for any
optimized GNNs ready to be deployed. We verify the satisfactory effectiveness
of ELEGANT in practice through extensive experiments on real-world datasets
across different backbones of GNNs, where ELEGANT is also demonstrated to be
beneficial for GNN debiasing. Open-source code can be found at
https://github.com/yushundong/ELEGANT.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02758" title="Abstract">arXiv:2311.02758</a> [<a href="/pdf/2311.02758" title="Download PDF">pdf</a>, <a href="/format/2311.02758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M4BRAM: Mixed-Precision Matrix-Matrix Multiplication in FPGA Block RAMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuzong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dotzel%2C+J">Jordan Dotzel</a>, 
<a href="/search/cs?searchtype=author&query=Abdelfattah%2C+M+S">Mohamed S. Abdelfattah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 12 figures, 3 tables, IEEE ICFPT 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Mixed-precision quantization is a popular approach for compressing deep
neural networks (DNNs). However, it is challenging to scale the performance
efficiently with mixed-precision DNNs given the current FPGA architecture and
conventional accelerator dataflows. In this work, we enhance the FPGA's
capability for accelerating mixed-precision DNNs by proposing M4BRAM, a novel
compute-in-block RAM (BRAM) architecture that can compute mixed-precision
matrix-matrix multiplication. On the precision side, M4BRAM supports a wide
range of mixed-precision DNN configurations -- the weight precision can be
2/4/8 bits while the activation precision can vary from 2 to 8 bits. On the
dataflow side, M4BRAM leverages a novel in-BRAM data duplication scheme to
achieve high hardware utilization. Moreover, during M4BRAM computation, other
FPGA resources can seamlessly access its data without the need for a separate
buffer. Hence, unlike prior compute-in-BRAM proposals, M4BRAM can
simultaneously perform mixed-precision computation and maintain full
functionality as a memory unit to \textit{truly} complement the existing
compute resources on FPGAs. Experiments show that adding M4BRAM to a tiled DNN
accelerator can achieve an average speedup of 2.16$\times$ across various DNNs
on the ImageNet classification task while incurring a negligible accuracy loss
of $&lt;$ 0.5%. Compared to the same tiled accelerator that employs a prior
compute-in-BRAM architecture, M4BRAM delivers 1.43$\times$ higher performance
on average across various DNNs.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02760" title="Abstract">arXiv:2311.02760</a> [<a href="/pdf/2311.02760" title="Download PDF">pdf</a>, <a href="/format/2311.02760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Question Answering with Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bl%C3%BCbaum%2C+L">Lukas Bl&#xfc;baum</a>, 
<a href="/search/cs?searchtype=author&query=Heindorf%2C+S">Stefan Heindorf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Causal questions inquire about causal relationships between different events
or phenomena. Specifically, they often aim to determine whether there is a
relationship between two phenomena, or to identify all causes/effects of a
phenomenon. Causal questions are important for a variety of use cases,
including virtual assistants and search engines. However, many current
approaches to causal question answering cannot provide explanations or evidence
for their answers. Hence, in this paper, we aim to answer causal questions with
CauseNet, a large-scale dataset of causal relations and their provenance data.
Inspired by recent, successful applications of reinforcement learning to
knowledge graph tasks, such as link prediction and fact-checking, we explore
the application of reinforcement learning on CauseNet for causal question
answering. We introduce an Actor-Critic based agent which learns to search
through the graph to answer causal questions. We bootstrap the agent with a
supervised learning procedure to deal with large action spaces and sparse
rewards. Our evaluation shows that the agent successfully prunes the search
space to answer binary causal questions by visiting less than 30 nodes per
question compared to over 3,000 nodes by a naive breadth-first search. Our
ablation study indicates that our supervised learning strategy provides a
strong foundation upon which our reinforcement learning agent improves. The
paths returned by our agent explain the mechanisms by which a cause produces an
effect. Moreover, for each edge on a path, CauseNet stores its original source
on the web allowing for easy verification of paths.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02761" title="Abstract">arXiv:2311.02761</a> [<a href="/pdf/2311.02761" title="Download PDF">pdf</a>, <a href="/format/2311.02761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-Shot Strategic Classification Under Unknown Costs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rosenfeld%2C+E">Elan Rosenfeld</a>, 
<a href="/search/cs?searchtype=author&query=Rosenfeld%2C+N">Nir Rosenfeld</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT); Machine Learning (stat.ML)

</div>
<p class="mathjax">A primary goal in strategic classification is to learn decision rules which
are robust to strategic input manipulation. Earlier works assume that strategic
responses are known; while some recent works address the important challenge of
unknown responses, they exclusively study sequential settings which allow
multiple model deployments over time. But there are many
domains$\unicode{x2014}$particularly in public policy, a common motivating
use-case$\unicode{x2014}$where multiple deployments are unrealistic, or where
even a single bad round is undesirable. To address this gap, we initiate the
study of strategic classification under unknown responses in the one-shot
setting, which requires committing to a single classifier once. Focusing on the
users' cost function as the source of uncertainty, we begin by proving that for
a broad class of costs, even a small mis-estimation of the true cost can entail
arbitrarily low accuracy in the worst case. In light of this, we frame the
one-shot task as a minimax problem, with the goal of identifying the classifier
with the smallest worst-case risk over an uncertainty set of possible costs.
Our main contribution is efficient algorithms for both the full-batch and
stochastic settings, which we prove converge (offline) to the minimax optimal
solution at the dimension-independent rate of
$\tilde{\mathcal{O}}(T^{-\frac{1}{2}})$. Our analysis reveals important
structure stemming from the strategic nature of user responses, particularly
the importance of dual norm regularization with respect to the cost function.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02762" title="Abstract">arXiv:2311.02762</a> [<a href="/pdf/2311.02762" title="Download PDF">pdf</a>, <a href="/format/2311.02762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Sparse 3D Convolution Network with VDB
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Fangjun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+A">Anyong Mao</a>, 
<a href="/search/cs?searchtype=author&query=Sifakis%2C+E">Eftychios Sifakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We proposed a new Convolution Neural Network implementation optimized for
sparse 3D data inference. This implementation uses NanoVDB as the data
structure to store the sparse tensor. It leaves a relatively small memory
footprint while maintaining high performance. We demonstrate that this
architecture is around 20 times faster than the state-of-the-art dense CNN
model on a high-resolution 3D object classification network.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02765" title="Abstract">arXiv:2311.02765</a> [<a href="/pdf/2311.02765" title="Download PDF">pdf</a>, <a href="/ps/2311.02765" title="Download PostScript">ps</a>, <a href="/format/2311.02765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rule Learning as Machine Translation using the Atomic Knowledge Bank
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%86s%C3%B8y%2C+K">Kristoffer &#xc6;s&#xf8;y</a>, 
<a href="/search/cs?searchtype=author&query=Ozaki%2C+A">Ana Ozaki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Machine learning models, and in particular language models, are being applied
to various tasks that require reasoning. While such models are good at
capturing patterns their ability to reason in a trustable and controlled manner
is frequently questioned. On the other hand, logic-based rule systems allow for
controlled inspection and already established verification methods. However it
is well-known that creating such systems manually is time-consuming and prone
to errors. We explore the capability of transformers to translate sentences
expressing rules in natural language into logical rules. We see reasoners as
the most reliable tools for performing logical reasoning and focus on
translating language into the format expected by such tools. We perform
experiments using the DKET dataset from the literature and create a dataset for
language to logic translation based on the Atomic knowledge bank.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02766" title="Abstract">arXiv:2311.02766</a> [<a href="/pdf/2311.02766" title="Download PDF">pdf</a>, <a href="/format/2311.02766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Riemannian Laplace Approximation with the Fisher Metric
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hanlin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Hartmann%2C+M">Marcelo Hartmann</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+B">Bernardo Williams</a>, 
<a href="/search/cs?searchtype=author&query=Girolami%2C+M">Mark Girolami</a>, 
<a href="/search/cs?searchtype=author&query=Klami%2C+A">Arto Klami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">The Laplace's method approximates a target density with a Gaussian
distribution at its mode. It is computationally efficient and asymptotically
exact for Bayesian inference due to the Bernstein-von Mises theorem, but for
complex targets and finite-data posteriors it is often too crude an
approximation. A recent generalization of the Laplace Approximation transforms
the Gaussian approximation according to a chosen Riemannian geometry providing
a richer approximation family, while still retaining computational efficiency.
However, as shown here, its properties heavily depend on the chosen metric,
indeed the metric adopted in previous work results in approximations that are
overly narrow as well as being biased even at the limit of infinite data. We
correct this shortcoming by developing the approximation family further,
deriving two alternative variants that are exact at the limit of infinite data,
extending the theoretical analysis of the method, and demonstrating practical
improvements in a range of experiments.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02767" title="Abstract">arXiv:2311.02767</a> [<a href="/pdf/2311.02767" title="Download PDF">pdf</a>, <a href="/ps/2311.02767" title="Download PostScript">ps</a>, <a href="/format/2311.02767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Structured Knowledge Production: A Case Study of  Wikidata&#x27;s Representation Injustice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+J+J">Jeffrey Jun-jie Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C+C">Charles Chuankai Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Wikidata is a multi-language knowledge base that is being edited and
maintained by editors from different language communities. Due to the
structured nature of its content, the contributions are in various forms,
including manual edit, tool-assisted edits, automated edits, etc, with the
majority of edits being the import from wiki-internal or external datasets. Due
to the outstanding power of bots and tools reflecting from their large volume
of edits, knowledge contributions within Wikidata can easily cause epistemic
injustice due to internal and external reasons. In this case study, we compared
the coverage and edit history of human pages in two countries. By shedding
light on these disparities and offering actionable solutions, our study aims to
enhance the fairness and inclusivity of knowledge representation within
Wikidata, ultimately contributing to a more equitable and comprehensive global
knowledge base.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02771" title="Abstract">arXiv:2311.02771</a> [<a href="/pdf/2311.02771" title="Download PDF">pdf</a>, <a href="/ps/2311.02771" title="Download PostScript">ps</a>, <a href="/format/2311.02771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Two-Dimensional Reed--Solomon Codes Correcting Insertions and  Deletions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Con%2C+R">Roni Con</a>, 
<a href="/search/cs?searchtype=author&query=Shpilka%2C+A">Amir Shpilka</a>, 
<a href="/search/cs?searchtype=author&query=Tamo%2C+I">Itzhak Tamo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2107.05699">arXiv:2107.05699</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Constructing Reed--Solomon (RS) codes that can correct insertions and
deletions (insdel errors) has been considered in numerous recent works. For the
special case of two-dimensional RS-codes, it is known [CST23] that an $[n,2]_q$
RS-code that can correct from $n-3$ insdel errors satisfies that
$q=\Omega(n^3)$. On the other hand, there are several known constructions of
$[n,2]_q$ RS-codes that can correct from $n-3$ insdel errors, where the
smallest field size is $q=O(n^4)$. In this short paper, we construct $[n,2]_q$
Reed--Solomon codes that can correct $n-3$ insdel errors with $q=O(n^3)$,
thereby resolving the minimum field size needed for such codes.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02772" title="Abstract">arXiv:2311.02772</a> [<a href="/pdf/2311.02772" title="Download PDF">pdf</a>, <a href="/ps/2311.02772" title="Download PostScript">ps</a>, <a href="/format/2311.02772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention or Convolution: Transformer Encoders in Audio Language Models  for Inference Efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeon%2C+S">Sungho Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+C">Ching-Feng Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Inan%2C+H">Hakan Inan</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+W">Wei-Ning Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Rungta%2C+R">Rashi Rungta</a>, 
<a href="/search/cs?searchtype=author&query=Mehdad%2C+Y">Yashar Mehdad</a>, 
<a href="/search/cs?searchtype=author&query=Bikel%2C+D">Daniel Bikel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In this paper, we show that a simple self-supervised pre-trained audio model
can achieve comparable inference efficiency to more complicated pre-trained
models with speech transformer encoders. These speech transformers rely on
mixing convolutional modules with self-attention modules. They achieve
state-of-the-art performance on ASR with top efficiency. We first show that
employing these speech transformers as an encoder significantly improves the
efficiency of pre-trained audio models as well. However, our study shows that
we can achieve comparable efficiency with advanced self-attention solely. We
demonstrate that this simpler approach is particularly beneficial with a
low-bit weight quantization technique of a neural network to improve
efficiency. We hypothesize that it prevents propagating the errors between
different quantized modules compared to recent speech transformers mixing
quantized convolution and the quantized self-attention modules.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02774" title="Abstract">arXiv:2311.02774</a> [<a href="/pdf/2311.02774" title="Download PDF">pdf</a>, <a href="/ps/2311.02774" title="Download PostScript">ps</a>, <a href="/format/2311.02774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A stronger connection between the asymptotic rank conjecture and the set  cover conjecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pratt%2C+K">Kevin Pratt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We give a short proof that Strassen's asymptotic rank conjecture implies that
for every $\varepsilon &gt; 0$ there exists a $(3/2^{2/3} + \varepsilon)^n$-time
algorithm for set cover on a universe of size $n$ with sets of bounded size.
This strengthens and simplifies a recent result of Bj\"orklund and Kaski that
Strassen's asymptotic rank conjecture implies that the set cover conjecture is
false. From another perspective, we show that the set cover conjecture implies
that a particular family of tensors $T_n \in \mathbb{C}^N \otimes \mathbb{C}^N
\otimes \mathbb{C}^N$ has asymptotic rank greater than $N^{1.08}$. Furthermore,
if one could improve a known upper bound of $\frac{1}{2}8^n$ on the tensor rank
of $T_n$ to $\frac{2}{9 \cdot n}8^n$ for any $n$, then the set cover conjecture
is false.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02775" title="Abstract">arXiv:2311.02775</a> [<a href="/pdf/2311.02775" title="Download PDF">pdf</a>, <a href="/format/2311.02775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChaTA: Towards an Intelligent Question-Answer Teaching Assistant using  Open-Source LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hicke%2C+Y">Yann Hicke</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+A">Anmol Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Q">Qianou Ma</a>, 
<a href="/search/cs?searchtype=author&query=Denny%2C+P">Paul Denny</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">To address the challenges of scalable and intelligent question-answering
(QA), we introduce an innovative solution that leverages open-source Large
Language Models (LLMs) to ensure data privacy. We use models from the LLaMA-2
family and augmentations including retrieval augmented generation (RAG),
supervised fine-tuning (SFT), and an alternative to reinforcement learning with
human feedback (RLHF). We perform our experiments on a Piazza dataset from an
introductory CS course with 10k QA pairs and 1.5k pairs of preferences data and
conduct both human evaluations and automatic LLM evaluations on a small subset.
We find preliminary evidence that modeling techniques collectively enhance the
quality of answers by 33%, and RAG is an impactful addition. This work paves
the way for the development of ChaTA, an intelligent QA assistant customizable
for courses with an online QA platform.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02777" title="Abstract">arXiv:2311.02777</a> [<a href="/pdf/2311.02777" title="Download PDF">pdf</a>, <a href="/format/2311.02777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Generalization Strategies for Morpheme Glossing in an Endangered  Language Documentation Context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ginn%2C+M">Michael Ginn</a>, 
<a href="/search/cs?searchtype=author&query=Palmer%2C+A">Alexis Palmer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Generalization is of particular importance in resource-constrained settings,
where the available training data may represent only a small fraction of the
distribution of possible texts. We investigate the ability of morpheme labeling
models to generalize by evaluating their performance on unseen genres of text,
and we experiment with strategies for closing the gap between performance on
in-distribution and out-of-distribution data. Specifically, we use weight decay
optimization, output denoising, and iterative pseudo-labeling, and achieve a 2%
improvement on a test set containing texts from unseen genres. All experiments
are performed using texts written in the Mayan language Uspanteko.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02778" title="Abstract">arXiv:2311.02778</a> [<a href="/pdf/2311.02778" title="Download PDF">pdf</a>, <a href="/format/2311.02778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MuSHRoom: Multi-Sensor Hybrid Room Dataset for Joint 3D Reconstruction  and Novel View Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xuqian Ren</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Dingding Cai</a>, 
<a href="/search/cs?searchtype=author&query=Tuominen%2C+T">Tuuli Tuominen</a>, 
<a href="/search/cs?searchtype=author&query=Kannala%2C+J">Juho Kannala</a>, 
<a href="/search/cs?searchtype=author&query=Rahtu%2C+E">Esa Rahtu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Metaverse technologies demand accurate, real-time, and immersive modeling on
consumer-grade hardware for both non-human perception (e.g.,
drone/robot/autonomous car navigation) and immersive technologies like AR/VR,
requiring both structural accuracy and photorealism. However, there exists a
knowledge gap in how to apply geometric reconstruction and photorealism
modeling (novel view synthesis) in a unified framework.
<br />To address this gap and promote the development of robust and immersive
modeling and rendering with consumer-grade devices, first, we propose a
real-world Multi-Sensor Hybrid Room Dataset (MuSHRoom). Our dataset presents
exciting challenges and requires state-of-the-art methods to be cost-effective,
robust to noisy data and devices, and can jointly learn 3D reconstruction and
novel view synthesis, instead of treating them as separate tasks, making them
ideal for real-world applications. Second, we benchmark several famous
pipelines on our dataset for joint 3D mesh reconstruction and novel view
synthesis. Finally, in order to further improve the overall performance, we
propose a new method that achieves a good trade-off between the two tasks. Our
dataset and benchmark show great potential in promoting the improvements for
fusing 3D reconstruction and high-quality rendering in a robust and
computationally efficient end-to-end fashion.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02781" title="Abstract">arXiv:2311.02781</a> [<a href="/pdf/2311.02781" title="Download PDF">pdf</a>, <a href="/format/2311.02781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Architecting Intermediate Layers for Efficient Composition of Data  Management and Machine Learning Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abeysinghe%2C+S">Supun Abeysinghe</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Essertel%2C+G">Gregory Essertel</a>, 
<a href="/search/cs?searchtype=author&query=Rompf%2C+T">Tiark Rompf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Modern data analytics workloads combine relational data processing with
machine learning (ML). Most DBMS handle these workloads by offloading these ML
operations to external specialized ML systems. While both DBMS and ML systems
go to great lengths to optimize performance for their specific workloads,
significant performance is lost when used in combination, due to data movement
across system boundaries, conversions between incompatible internal data
formats, and the lack of cross system optimizations.
<br />A key idea to remove these bottlenecks is to integrate existing data
manipulation systems with ML systems by building a common intermediate layer
(IR). Although this idea has been explored before (Weld, Delite), previous such
attempts require significant re-engineering of prior systems and still fall
short in achieving best-of-breed performance for individual tasks (e.g., SQL,
Deep Learning). Specifically, they rely on re-implementing existing systems
using a generic set of operators and fail to match best-of-breed individual
performance due to the inability to recover high-level optimizations from this
generic IR through compiler analysis.
<br />We present Flern, the first intermediate-layer integration between DB and ML
systems that are best-of-breed individually, competitive with the best compiled
query engines such as HyPer on comprehensive relational benchmarks (TPC-H) and
competitive with TensorFlow and PyTorch in state-of-the-art ML models (e.g.,
DeepSpeech, SqueezeNet, Transformers) and also represents a new
state-of-the-art for integration. A key realization is to architect
intermediate layers based on generative programming capabilities, which
preserves high-level contextual information for cross optimizations and enables
the construction of a variety of complex structures and cross system
optimizations with minimal effort.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02782" title="Abstract">arXiv:2311.02782</a> [<a href="/pdf/2311.02782" title="Download PDF">pdf</a>, <a href="/format/2311.02782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Generic Anomaly Detection and Understanding: Large-scale  Visual-linguistic Model (GPT-4V) Takes the Lead
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yunkang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaohao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaonan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Weiming Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress. Evaluated GPT-4V on 4 modalities, 9 tasks, and 15 datasets. The first three authors contribute equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Anomaly detection is a crucial task across different domains and data types.
However, existing anomaly detection models are often designed for specific
domains and modalities. This study explores the use of GPT-4V(ision), a
powerful visual-linguistic model, to address anomaly detection tasks in a
generic manner. We investigate the application of GPT-4V in multi-modality,
multi-domain anomaly detection tasks, including image, video, point cloud, and
time series data, across multiple application areas, such as industrial,
medical, logical, video, 3D anomaly detection, and localization tasks. To
enhance GPT-4V's performance, we incorporate different kinds of additional cues
such as class information, human expertise, and reference images as
prompts.Based on our experiments, GPT-4V proves to be highly effective in
detecting and explaining global and fine-grained semantic patterns in
zero/one-shot anomaly detection. This enables accurate differentiation between
normal and abnormal instances. Although we conducted extensive evaluations in
this study, there is still room for future evaluation to further exploit
GPT-4V's generic anomaly detection capacity from different aspects. These
include exploring quantitative metrics, expanding evaluation benchmarks,
incorporating multi-round interactions, and incorporating human feedback loops.
Nevertheless, GPT-4V exhibits promising performance in generic anomaly
detection and understanding, thus opening up a new avenue for anomaly
detection.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02786" title="Abstract">arXiv:2311.02786</a> [<a href="/pdf/2311.02786" title="Download PDF">pdf</a>, <a href="/ps/2311.02786" title="Download PostScript">ps</a>, <a href="/format/2311.02786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mobility as a Resource (MaaR) for resilient human-centric automation: a  vision paper
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Waller%2C+S+T">S. Travis Waller</a>, 
<a href="/search/eess?searchtype=author&query=Polydoropoulou%2C+A">Amalia Polydoropoulou</a>, 
<a href="/search/eess?searchtype=author&query=Tassiulas%2C+L">Leandros Tassiulas</a>, 
<a href="/search/eess?searchtype=author&query=Ziliaskopoulos%2C+A">Athanasios Ziliaskopoulos</a>, 
<a href="/search/eess?searchtype=author&query=Jian%2C+S">Sisi Jian</a>, 
<a href="/search/eess?searchtype=author&query=Wagenknecht%2C+S">Susann Wagenknecht</a>, 
<a href="/search/eess?searchtype=author&query=Hirte%2C+G">Georg Hirte</a>, 
<a href="/search/eess?searchtype=author&query=Bednarz%2C+T">Tomasz Bednarz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">As a consequence of commoditization, mobility is moving from a product (i.e.,
traditional modes and vehicles), to a service (i.e., Mobility as a Service,
MaaS); MaaS is the current state of transport research and emerging practice.
However, as it is observed in other fields (e.g. computing) we argue that
mobility will evolve from a service to a resource (Mobility as a Resource,
MaaR); MaaR is the envisioned inevitable state, which will emerge for societal
movement. Further, due to increasing scarcity of shared mobility spaces across
traditional and emerging modes of mobility, the commoditization process must be
viewed within the critical need for ethical and equitable solutions for the
traveling public (i.e., research is needed to avoid hyper-market driven
outcomes for society from the ongoing commoditization process). The evolution
of mobility into a resource requires novel conceptual frameworks, technologies,
processes and perspectives of analysis. A key component of the future MaaR
system is the technological capacity to observe, allocate and manage (in
real-time) the smallest envisionable units of mobility (i.e., atomic units of
mobility capacity) while providing prioritized attention to human movement and
ethical metrics related to access, consumption and impact. This paper proposes
an initial design of new paradigms which synthesize and advance methodologies
relating to highly dynamic capacity reservation systems for automated travel
integrated with the mixed interaction of non-automated traffic flow management,
travel network optimization, demand behavior forecasting, and progressive
mobility planning that spans equity, sustainability, and resilience.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02787" title="Abstract">arXiv:2311.02787</a> [<a href="/pdf/2311.02787" title="Download PDF">pdf</a>, <a href="/format/2311.02787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Make a Donut: Language-Guided Hierarchical EMD-Space Planning for  Zero-shot Deformable Object Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yang You</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+B">Bokui Shen</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+C">Congyue Deng</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+H">Haoran Geng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">He Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guibas%2C+L">Leonidas Guibas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deformable object manipulation stands as one of the most captivating yet
formidable challenges in robotics. While previous techniques have predominantly
relied on learning latent dynamics through demonstrations, typically
represented as either particles or images, there exists a pertinent limitation:
acquiring suitable demonstrations, especially for long-horizon tasks, can be
elusive. Moreover, basing learning entirely on demonstrations can hamper the
model's ability to generalize beyond the demonstrated tasks. In this work, we
introduce a demonstration-free hierarchical planning approach capable of
tackling intricate long-horizon tasks without necessitating any training. We
employ large language models (LLMs) to articulate a high-level, stage-by-stage
plan corresponding to a specified task. For every individual stage, the LLM
provides both the tool's name and the Python code to craft intermediate subgoal
point clouds. With the tool and subgoal for a particular stage at our disposal,
we present a granular closed-loop model predictive control strategy. This
leverages Differentiable Physics with Point-to-Point correspondence
(DiffPhysics-P2P) loss in the earth mover distance (EMD) space, applied
iteratively. Experimental findings affirm that our technique surpasses multiple
benchmarks in dough manipulation, spanning both short and long horizons.
Remarkably, our model demonstrates robust generalization capabilities to novel
and previously unencountered complex tasks without any preliminary
demonstrations. We further substantiate our approach with experimental trials
on real-world robotic platforms.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02790" title="Abstract">arXiv:2311.02790</a> [<a href="/pdf/2311.02790" title="Download PDF">pdf</a>, <a href="/format/2311.02790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CausalCite: A Causal Formulation of Paper Citations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+I">Ishan Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhijing Jin</a>, 
<a href="/search/cs?searchtype=author&query=Mokhtarian%2C+E">Ehsan Mokhtarian</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Siyuan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kiyavash%2C+N">Negar Kiyavash</a>, 
<a href="/search/cs?searchtype=author&query=Sachan%2C+M">Mrinmaya Sachan</a>, 
<a href="/search/cs?searchtype=author&query=Schoelkopf%2C+B">Bernhard Schoelkopf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Evaluating the significance of a paper is pivotal yet challenging for the
scientific community. While the citation count is the most commonly used proxy
for this purpose, they are widely criticized for failing to accurately reflect
a paper's true impact. In this work, we propose a causal inference method,
TextMatch, which adapts the traditional matching framework to high-dimensional
text embeddings. Specifically, we encode each paper using the text embeddings
by large language models (LLMs), extract similar samples by cosine similarity,
and synthesize a counterfactual sample by the weighted average of similar
papers according to their similarity values. We apply the resulting metric,
called CausalCite, as a causal formulation of paper citations. We show its
effectiveness on various criteria, such as high correlation with paper impact
as reported by scientific experts on a previous dataset of 1K papers,
(test-of-time) awards for past papers, and its stability across various
sub-fields of AI. We also provide a set of findings that can serve as suggested
ways for future researchers to use our metric for a better understanding of a
paper's quality. Our code and data are at
https://github.com/causalNLP/causal-cite.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02791" title="Abstract">arXiv:2311.02791</a> [<a href="/pdf/2311.02791" title="Download PDF">pdf</a>, <a href="/format/2311.02791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MirrorCalib: Utilizing Human Pose Information for Mirror-based Virtual  Camera Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+L">Longyun Liao</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+A">Andrew Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Rong Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we present the novel task of estimating the extrinsic
parameters of a virtual camera with respect to a real camera with one single
fixed planar mirror. This task poses a significant challenge in cases where
objects captured lack overlapping views from both real and mirrored cameras. To
address this issue, prior knowledge of a human body and 2D joint locations are
utilized to estimate the camera extrinsic parameters when a person is in front
of a mirror. We devise a modified eight-point algorithm to obtain an initial
estimation from 2D joint locations. The 2D joint locations are then refined
subject to human body constraints. Finally, a RANSAC algorithm is employed to
remove outliers by comparing their epipolar distances to a predetermined
threshold. MirrorCalib is evaluated on both synthetic and real datasets and
achieves a rotation error of 0.62{\deg}/1.82{\deg} and a translation error of
37.33/69.51 mm on the synthetic/real dataset, which outperforms the
state-of-art method.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02793" title="Abstract">arXiv:2311.02793</a> [<a href="/pdf/2311.02793" title="Download PDF">pdf</a>, <a href="/format/2311.02793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Photovoltaic Hosting Capacity of Distribution Networks with  Coordinated Inverter Control -- A Case Study of the EPRI J1 Feeder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dalal%2C+D">Dhaval Dalal</a>, 
<a href="/search/eess?searchtype=author&query=Sondharangalla%2C+M">Madhura Sondharangalla</a>, 
<a href="/search/eess?searchtype=author&query=Ayyanar%2C+R">Raja Ayyanar</a>, 
<a href="/search/eess?searchtype=author&query=Pal%2C+A">Anamitra Pal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Adding photovoltaic (PV) systems in distribution networks, while desirable
for reducing the carbon footprint, can lead to voltage violations under high
solar-low load conditions. The inability of traditional volt-VAr control in
eliminating all the violations is also well-known. This paper presents a novel
coordinated inverter control methodology that leverages system-wide situational
awareness to significantly improve hosting capacity (HC). The methodology
employs a real-time voltage-reactive power (VQ) sensitivity matrix in an
iterative linear optimizer to calculate the minimum reactive power intervention
from PV inverters needed for mitigating over-voltage without resorting to
active power curtailing or requiring step voltage regulator setting changes.
The algorithm is validated using the EPRI J1 feeder under an extensive set of
realistic use cases and is shown to provide 3x improvement in HC under all
scenarios.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02795" title="Abstract">arXiv:2311.02795</a> [<a href="/pdf/2311.02795" title="Download PDF">pdf</a>, <a href="/format/2311.02795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PermutEx: Feature-Extraction-Based Permutation -- A New Diffusion Scheme  for Image Encryption Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+S">Muhammad Shahbaz Khan</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+J">Jawad Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Al-Dubai%2C+A">Ahmed Al-Dubai</a>, 
<a href="/search/cs?searchtype=author&query=Jaroucheh%2C+Z">Zakwan Jaroucheh</a>, 
<a href="/search/cs?searchtype=author&query=Pitropakis%2C+N">Nikolaos Pitropakis</a>, 
<a href="/search/cs?searchtype=author&query=Buchanan%2C+W+J">William J. Buchanan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Traditional permutation schemes mostly focus on random scrambling of pixels,
often neglecting the intrinsic image information that could enhance diffusion
in image encryption algorithms. This paper introduces PermutEx, a
feature-extraction-based permutation method that utilizes inherent image
features to scramble pixels effectively. Unlike random permutation schemes,
PermutEx extracts the spatial frequency and local contrast features of the
image and ranks each pixel based on this information, identifying which pixels
are more important or information-rich based on texture and edge information.
In addition, a unique permutation key is generated using the Logistic-Sine Map
based on chaotic behavior. The ranked pixels are permuted in conjunction with
this unique key, effectively permuting the original image into a scrambled
version. Experimental results indicate that the proposed method effectively
disrupts the correlation in information-rich areas within the image resulting
in a correlation value of 0.000062. The effective scrambling of pixels,
resulting in nearly zero correlation, makes this method suitable to be used as
diffusion in image encryption algorithms.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02797" title="Abstract">arXiv:2311.02797</a> [<a href="/pdf/2311.02797" title="Download PDF">pdf</a>, <a href="/format/2311.02797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Construction of N-bit-delay Almost Instantaneous  Fixed-to-Variable-Length Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sugiura%2C+R">Ryosuke Sugiura</a>, 
<a href="/search/cs?searchtype=author&query=Nishino%2C+M">Masaaki Nishino</a>, 
<a href="/search/cs?searchtype=author&query=Yasuda%2C+N">Norihito Yasuda</a>, 
<a href="/search/cs?searchtype=author&query=Kamamoto%2C+Y">Yutaka Kamamoto</a>, 
<a href="/search/cs?searchtype=author&query=Moriya%2C+T">Takehiro Moriya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE Trans. IT on 31st Oct. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">This paper presents an optimal construction of $N$-bit-delay almost
instantaneous fixed-to-variable-length (AIFV) codes, the general form of binary
codes we can make when finite bits of decoding delay are allowed. The presented
method enables us to optimize lossless codes among a broader class of codes
compared to the conventional FV and AIFV codes. The paper first discusses the
problem of code construction, which contains some essential partial problems,
and defines three classes of optimality to clarify how far we can solve the
problems. The properties of the optimal codes are analyzed theoretically,
showing the sufficient conditions for achieving the optimum. Then, we propose
an algorithm for constructing $N$-bit-delay AIFV codes for given stationary
memory-less sources. The optimality of the constructed codes is discussed both
theoretically and empirically. They showed shorter expected code lengths when
$N\ge 3$ than the conventional AIFV-$m$ and extended Huffman codes. Moreover,
in the random numbers simulation, they performed higher compression efficiency
than the 32-bit-precision range codes under reasonable conditions.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02798" title="Abstract">arXiv:2311.02798</a> [<a href="/pdf/2311.02798" title="Download PDF">pdf</a>, <a href="/format/2311.02798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From molecules to scaffolds to functional groups: building  context-dependent molecular representation via multi-channel learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yue Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jialu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+T">Tingjun Hou</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+C">Chang-Yu Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiaowei Jia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Chemical Physics (physics.chem-ph); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Reliable molecular property prediction is essential for various scientific
endeavors and industrial applications, such as drug discovery. However, the
scarcity of data, combined with the highly non-linear causal relationships
between physicochemical and biological properties and conventional molecular
featurization schemes, complicates the development of robust molecular machine
learning models. Self-supervised learning (SSL) has emerged as a popular
solution, utilizing large-scale, unannotated molecular data to learn a
foundational representation of chemical space that might be advantageous for
downstream tasks. Yet, existing molecular SSL methods largely overlook
domain-specific knowledge, such as molecular similarity and scaffold
importance, as well as the context of the target application when operating
over the large chemical space. This paper introduces a novel learning framework
that leverages the knowledge of structural hierarchies within molecular
structures, embeds them through separate pre-training tasks over distinct
channels, and employs a task-specific channel selection to compose a
context-dependent representation. Our approach demonstrates competitive
performance across various molecular property benchmarks and establishes some
state-of-the-art results. It further offers unprecedented advantages in
particularly challenging yet ubiquitous scenarios like activity cliffs with
enhanced robustness and generalizability compared to other baselines.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02799" title="Abstract">arXiv:2311.02799</a> [<a href="/pdf/2311.02799" title="Download PDF">pdf</a>, <a href="/format/2311.02799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Dynamic Model for the Decomposition of Skin Conductance and  the Inference of Sudomotor Nerve Activities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+H+S">Hui Sophie Wang</a>, 
<a href="/search/eess?searchtype=author&query=Marsella%2C+S">Stacy Marsella</a>, 
<a href="/search/eess?searchtype=author&query=Pavel%2C+M">Misha Pavel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> added author emails
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">In behavioral health informatics, inferring an individual's psychological
state from physiological and behavioral data is fundamental. A key
physiological signal in this endeavor is electrodermal activity (EDA), often
quantified as skin conductance (SC), known for its sensitivity to a variety of
psychological stimuli. Traditional methods to analyze skin conductance, such as
the trough-to-peak method, often result in imprecise estimations due to
overlapping skin conductance responses. While various mathematical models have
been proposed to improve the analysis, many of them do not incorporate the
tonic level in the dynamic system. This paper introduces a novel fourth order
dynamic system to model the temporal dynamics of skin conductance, unifying
both the tonic level and phasic response. Applied to a large dataset with over
200 participants, majority of the models achieved an $R^2$ value above 0.99.
Furthermore, this work offers a unique three-component decomposition of skin
conductance, shedding light on its temporal dynamics. Comparative evaluations
highlight the model's capability to differentiate arousal levels and maintain
an appropriate sparsity level for the estimated sudomotor nerve activities
signal. The code of the proposed model and algorithm are available for open
access.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02800" title="Abstract">arXiv:2311.02800</a> [<a href="/pdf/2311.02800" title="Download PDF">pdf</a>, <a href="/format/2311.02800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kivi: Verification for Cluster Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bingzhe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+G">Gangmuk Lim</a>, 
<a href="/search/cs?searchtype=author&query=Beckett%2C+R">Ryan Beckett</a>, 
<a href="/search/cs?searchtype=author&query=Godfrey%2C+P+B">P. Brighten Godfrey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Modern cloud infrastructure is powered by cluster management systems such as
Kubernetes and Docker Swarm. While these systems seek to minimize users'
operational burden, the complex, dynamic, and non-deterministic nature of these
systems makes them hard to reason about, potentially leading to failures
ranging from performance degradation to outages. We present Kivi, the first
system for verifying controllers and their configurations in cluster management
systems. Kivi focuses on the popular system Kubernetes, and models its
controllers and events into processes whereby their interleavings are
exhaustively checked via model checking. Central to handling autoscaling and
large-scale deployments is our design that seeks to find violations in a
smaller and reduced topology. We also develop several model optimizations in
Kivi to scale to large clusters. We show that Kivi is effective and accurate in
finding issues in realistic and complex scenarios and showcase two new issues
in Kubernetes controller source code.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02801" title="Abstract">arXiv:2311.02801</a> [<a href="/pdf/2311.02801" title="Download PDF">pdf</a>, <a href="/format/2311.02801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Intersection of Self-Correction and Trust in Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krishna%2C+S">Satyapriya Krishna</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Working Paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have demonstrated remarkable capabilities in
performing complex cognitive tasks. However, their complexity and lack of
transparency have raised several trustworthiness concerns, including the
propagation of misinformation and toxicity. Recent research has explored the
self-correction capabilities of LLMs to enhance their performance. In this
work, we investigate whether these self-correction capabilities can be
harnessed to improve the trustworthiness of LLMs. We conduct experiments
focusing on two key aspects of trustworthiness: truthfulness and toxicity. Our
findings reveal that self-correction can lead to improvements in toxicity and
truthfulness, but the extent of these improvements varies depending on the
specific aspect of trustworthiness and the nature of the task. Interestingly,
our study also uncovers instances of "self-doubt" in LLMs during the
self-correction process, introducing a new set of challenges that need to be
addressed.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02802" title="Abstract">arXiv:2311.02802</a> [<a href="/pdf/2311.02802" title="Download PDF">pdf</a>, <a href="/format/2311.02802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incorporating Worker Perspectives into MTurk Annotation Practices for  NLP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+O">Olivia Huang</a>, 
<a href="/search/cs?searchtype=author&query=Fleisig%2C+E">Eve Fleisig</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+D">Dan Klein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Current practices regarding data collection for natural language processing
on Amazon Mechanical Turk (MTurk) often rely on a combination of studies on
data quality and heuristics shared among NLP researchers. However, without
considering the perspectives of MTurk workers, these approaches are susceptible
to issues regarding workers' rights and poor response quality. We conducted a
critical literature review and a survey of MTurk workers aimed at addressing
open questions regarding best practices for fair payment, worker privacy, data
quality, and considering worker incentives. We found that worker preferences
are often at odds with received wisdom among NLP researchers. Surveyed workers
preferred reliable, reasonable payments over uncertain, very high payments;
reported frequently lying on demographic questions; and expressed frustration
at having work rejected with no explanation. We also found that workers view
some quality control methods, such as requiring minimum response times or
Master's qualifications, as biased and largely ineffective. Based on the survey
results, we provide recommendations on how future NLP studies may better
account for MTurk workers' experiences in order to respect workers' rights and
improve data quality.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02803" title="Abstract">arXiv:2311.02803</a> [<a href="/pdf/2311.02803" title="Download PDF">pdf</a>, <a href="/format/2311.02803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast and Interpretable Face Identification for Out-Of-Distribution Data  Using Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phan%2C+H">Hai Phan</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+C">Cindy Le</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+V">Vu Le</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yihui He</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+A+T">Anh Totti Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 15 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Most face identification approaches employ a Siamese neural network to
compare two images at the image embedding level. Yet, this technique can be
subject to occlusion (e.g. faces with masks or sunglasses) and
out-of-distribution data. DeepFace-EMD (Phan et al. 2022) reaches
state-of-the-art accuracy on out-of-distribution data by first comparing two
images at the image level, and then at the patch level. Yet, its later
patch-wise re-ranking stage admits a large $O(n^3 \log n)$ time complexity (for
$n$ patches in an image) due to the optimal transport optimization. In this
paper, we propose a novel, 2-image Vision Transformers (ViTs) that compares two
images at the patch level using cross-attention. After training on 2M pairs of
images on CASIA Webface (Yi et al. 2014), our model performs at a comparable
accuracy as DeepFace-EMD on out-of-distribution data, yet at an inference speed
more than twice as fast as DeepFace-EMD (Phan et al. 2022). In addition, via a
human study, our model shows promising explainability through the visualization
of cross-attention. We believe our work can inspire more explorations in using
ViTs for face identification.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02804" title="Abstract">arXiv:2311.02804</a> [<a href="/pdf/2311.02804" title="Download PDF">pdf</a>, <a href="/ps/2311.02804" title="Download PostScript">ps</a>, <a href="/format/2311.02804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Last fall degree of semi-local polynomial systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+M+A">Ming-Deh A. Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Number Theory (math.NT)

</div>
<p class="mathjax">We study the last fall degrees of {\em semi-local} polynomial systems, and
the computational complexity of solving such systems for closed-point and
rational-point solutions, where the systems are defined over a finite field. A
semi-local polynomial system specifies an algebraic set which is the image of a
global linear transformation of a direct product of local affine algebraic
sets. As a special but interesting case, polynomial systems that arise from
Weil restriction of algebraic sets in an affine space of low dimension are
semi-local. Such systems have received considerable attention due to their
application in cryptography. Our main results bound the last fall degree of a
semi-local polynomial system in terms of the number of closed point solutions,
and yield an efficient algorithm for finding all rational-point solutions when
the prime characteristic of the finite field and the number of rational
solutions are small. Our results on solving semi-local systems imply an
improvement on a previously known polynomial-time attack on the HFE (Hidden
Field Equations) cryptosystems. The attacks implied in our results extend to
public key encryption functions which are based on semi-local systems where
either the number of closed point solutions is small, or the characteristic of
the field is small. It remains plausible to construct public key cryptosystems
based on semi-local systems over a finite field of large prime characteristic
with exponential number of closed point solutions. Such a method is presented
in the paper, followed by further cryptanalysis involving the isomorphism of
polynomials (IP) problem, as well as a concrete public key encryption scheme
which is secure against all the attacks discussed in this paper.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02805" title="Abstract">arXiv:2311.02805</a> [<a href="/pdf/2311.02805" title="Download PDF">pdf</a>, <a href="/format/2311.02805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tailoring Self-Rationalizers with Multi-Reward Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramnath%2C+S">Sahana Ramnath</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+B">Brihi Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Hallinan%2C+S">Skyler Hallinan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Ximing Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L+H">Liunian Harold Li</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+A">Aaron Chan</a>, 
<a href="/search/cs?searchtype=author&query=Hessel%2C+J">Jack Hessel</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yejin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiang Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LMs) are capable of generating free-text rationales to
aid question answering. However, prior work 1) suggests that useful
self-rationalization is emergent only at significant scales (e.g., 175B
parameter GPT-3); and 2) focuses largely on downstream performance, ignoring
the semantics of the rationales themselves, e.g., are they faithful, true, and
helpful for humans? In this work, we enable small-scale LMs (approx. 200x
smaller than GPT-3) to generate rationales that not only improve downstream
task performance, but are also more plausible, consistent, and diverse,
assessed both by automatic and human evaluation. Our method, MaRio
(Multi-rewArd RatIOnalization), is a multi-reward conditioned
self-rationalization algorithm that optimizes multiple distinct properties like
plausibility, diversity and consistency. Results on five difficult
question-answering datasets StrategyQA, QuaRel, OpenBookQA, NumerSense and QASC
show that not only does MaRio improve task accuracy, but it also improves the
self-rationalization quality of small LMs across the aforementioned axes better
than a supervised fine-tuning (SFT) baseline. Extensive human evaluations
confirm that MaRio rationales are preferred vs. SFT rationales, as well as
qualitative improvements in plausibility and consistency.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02807" title="Abstract">arXiv:2311.02807</a> [<a href="/pdf/2311.02807" title="Download PDF">pdf</a>, <a href="/format/2311.02807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QualEval: Qualitative Evaluation for Model Improvement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Murahari%2C+V">Vishvak Murahari</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+A">Ameet Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+P">Peter Clark</a>, 
<a href="/search/cs?searchtype=author&query=Rajpurohit%2C+T">Tanmay Rajpurohit</a>, 
<a href="/search/cs?searchtype=author&query=Sabharwal%2C+A">Ashish Sabharwal</a>, 
<a href="/search/cs?searchtype=author&query=Narasimhan%2C+K">Karthik Narasimhan</a>, 
<a href="/search/cs?searchtype=author&query=Kalyan%2C+A">Ashwin Kalyan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Quantitative evaluation metrics have traditionally been pivotal in gauging
the advancements of artificial intelligence systems, including large language
models (LLMs). However, these metrics have inherent limitations. Given the
intricate nature of real-world tasks, a single scalar to quantify and compare
is insufficient to capture the fine-grained nuances of model behavior. Metrics
serve only as a way to compare and benchmark models, and do not yield
actionable diagnostics, thus making the model improvement process challenging.
Model developers find themselves amid extensive manual efforts involving
sifting through vast datasets and attempting hit-or-miss adjustments to
training data or setups. In this work, we address the shortcomings of
quantitative metrics by proposing QualEval, which augments quantitative scalar
metrics with automated qualitative evaluation as a vehicle for model
improvement. QualEval uses a powerful LLM reasoner and our novel flexible
linear programming solver to generate human-readable insights that when
applied, accelerate model improvement. The insights are backed by a
comprehensive dashboard with fine-grained visualizations and
human-interpretable analyses. We corroborate the faithfulness of QualEval by
demonstrating that leveraging its insights, for example, improves the absolute
performance of the Llama 2 model by up to 15% points relative on a challenging
dialogue task (DialogSum) when compared to baselines. QualEval successfully
increases the pace of model development, thus in essence serving as a
data-scientist-in-a-box. Given the focus on critiquing and improving current
evaluation metrics, our method serves as a refreshingly new technique for both
model evaluation and improvement.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02809" title="Abstract">arXiv:2311.02809</a> [<a href="/pdf/2311.02809" title="Download PDF">pdf</a>, <a href="/format/2311.02809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proactive Robot Control for Collaborative Manipulation Using Human  Intent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rysbek%2C+Z">Zhanibek Rysbek</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Siyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Shervedani%2C+A+M">Afagh Mehri Shervedani</a>, 
<a href="/search/cs?searchtype=author&query=Zefran%2C+M">Milos Zefran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Collaborative manipulation task often requires negotiation using explicit or
implicit communication. An important example is determining where to move when
the goal destination is not uniquely specified, and who should lead the motion.
This work is motivated by the ability of humans to communicate the desired
destination of motion through back-and-forth force exchanges. Inherent to these
exchanges is also the ability to dynamically assign a role to each participant,
either taking the initiative or deferring to the partner's lead. In this paper,
we propose a hierarchical robot control framework that emulates human behavior
in communicating a motion destination to a human collaborator and in responding
to their actions. At the top level, the controller consists of a set of
finite-state machines corresponding to different levels of commitment of the
robot to its desired goal configuration. The control architecture is loosely
based on the human strategy observed in the human-human experiments, and the
key component is a real-time intent recognizer that helps the robot respond to
human actions. We describe the details of the control framework, and feature
engineering and training process of the intent recognition. The proposed
controller was implemented on a UR10e robot (Universal Robots) and evaluated
through human studies. The experiments show that the robot correctly recognizes
and responds to human input, communicates its intent clearly, and resolves
conflict. We report success rates and draw comparisons with human-human
experiments to demonstrate the effectiveness of the approach.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02811" title="Abstract">arXiv:2311.02811</a> [<a href="/pdf/2311.02811" title="Download PDF">pdf</a>, <a href="/format/2311.02811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contour Algorithm for Connectivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+h">hihui Du</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+O+A">Oliver Alvarado Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fuhuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Dindoost%2C+M">Mohammad Dindoost</a>, 
<a href="/search/cs?searchtype=author&query=Bader%2C+D+A">David A. Bader</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30th IEEE International Conference on High Performance Computing, Data, and Analytics, Goa, India, December 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Finding connected components in a graph is a fundamental problem in graph
analysis. In this work, we present a novel minimum-mapping based Contour
algorithm to efficiently solve the connectivity problem. We prove that the
Contour algorithm with two or higher order operators can identify all connected
components of an undirected graph within $\mathcal{O}(\log d_{max})$
iterations, with each iteration involving $\mathcal{O}(m)$ work, where
$d_{max}$ represents the largest diameter among all components in the given
graph, and $m$ is the total number of edges in the graph. Importantly, each
iteration is highly parallelizable, making use of the efficient minimum-mapping
operator applied to all edges. To further enhance its practical performance, we
optimize the Contour algorithm through asynchronous updates, early convergence
checking, eliminating atomic operations, and choosing more efficient mapping
operators. Our implementation of the Contour algorithm has been integrated into
the open-source framework Arachne. Arachne extends Arkouda for large-scale
interactive graph analytics, providing a Python API powered by the
high-productivity parallel language Chapel. Experimental results on both
real-world and synthetic graphs demonstrate the superior performance of our
proposed Contour algorithm compared to state-of-the-art large-scale parallel
algorithm FastSV and the fastest shared memory algorithm ConnectIt. On average,
Contour achieves a speedup of 7.3x and 1.4x compared to FastSV and ConnectIt,
respectively. All code for the Contour algorithm and the Arachne framework is
publicly available on GitHub ( https://github.com/Bears-R-Us/arkouda-njit ),
ensuring transparency and reproducibility of our work.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02815" title="Abstract">arXiv:2311.02815</a> [<a href="/pdf/2311.02815" title="Download PDF">pdf</a>, <a href="/format/2311.02815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient, Self-Supervised Human Pose Estimation with Inductive Prior  Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoo%2C+N">Nobline Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Russakovsky%2C+O">Olga Russakovsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCVW 2023 Publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The goal of 2D human pose estimation (HPE) is to localize anatomical
landmarks, given an image of a person in a pose. SOTA techniques make use of
thousands of labeled figures (finetuning transformers or training deep CNNs),
acquired using labor-intensive crowdsourcing. On the other hand,
self-supervised methods re-frame the HPE task as a reconstruction problem,
enabling them to leverage the vast amount of unlabeled visual data, though at
the present cost of accuracy. In this work, we explore ways to improve
self-supervised HPE. We (1) analyze the relationship between reconstruction
quality and pose estimation accuracy, (2) develop a model pipeline that
outperforms the baseline which inspired our work, using less than one-third the
amount of training data, and (3) offer a new metric suitable for
self-supervised settings that measures the consistency of predicted body part
length proportions. We show that a combination of well-engineered
reconstruction losses and inductive priors can help coordinate pose learning
alongside reconstruction in a self-supervised paradigm.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02816" title="Abstract">arXiv:2311.02816</a> [<a href="/pdf/2311.02816" title="Download PDF">pdf</a>, <a href="/format/2311.02816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> APGL4SR: A Generic Framework with Adaptive and Personalized Global  Collaborative Information in Sequential Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+M">Mingjia Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Likang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sirui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruiming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+D">Defu Lian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Enhong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The sequential recommendation system has been widely studied for its
promising effectiveness in capturing dynamic preferences buried in users'
sequential behaviors. Despite the considerable achievements, existing methods
usually focus on intra-sequence modeling while overlooking exploiting global
collaborative information by inter-sequence modeling, resulting in inferior
recommendation performance. Therefore, previous works attempt to tackle this
problem with a global collaborative item graph constructed by pre-defined
rules. However, these methods neglect two crucial properties when capturing
global collaborative information, i.e., adaptiveness and personalization,
yielding sub-optimal user representations. To this end, we propose a
graph-driven framework, named Adaptive and Personalized Graph Learning for
Sequential Recommendation (APGL4SR), that incorporates adaptive and
personalized global collaborative information into sequential recommendation
systems. Specifically, we first learn an adaptive global graph among all items
and capture global collaborative information with it in a self-supervised
fashion, whose computational burden can be further alleviated by the proposed
SVD-based accelerator. Furthermore, based on the graph, we propose to extract
and utilize personalized item correlations in the form of relative positional
encoding, which is a highly compatible manner of personalizing the utilization
of global collaborative information. Finally, the entire framework is optimized
in a multi-task learning paradigm, thus each part of APGL4SR can be mutually
reinforced. As a generic framework, APGL4SR can outperform other baselines with
significant margins. The code is available at
https://github.com/Graph-Team/APGL4SR.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02817" title="Abstract">arXiv:2311.02817</a> [<a href="/pdf/2311.02817" title="Download PDF">pdf</a>, <a href="/format/2311.02817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe-VLN: Collision Avoidance for Vision-and-Language Navigation of  Autonomous Robots Operating in Continuous Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+L">Lu Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Dongliang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Liang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Feitian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Ye Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+E">Erwei Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The task of vision-and-language navigation in continuous environments
(VLN-CE) aims at training an autonomous agent to perform low-level actions to
navigate through 3D continuous surroundings using visual observations and
language instructions. The significant potential of VLN-CE for mobile robots
has been demonstrated across a large number of studies. However, most existing
works in VLN-CE focus primarily on transferring the standard discrete
vision-and-language navigation (VLN) methods to continuous environments,
overlooking the problem of collisions. Such oversight often results in the
agent deviating from the planned path or, in severe instances, the agent being
trapped in obstacle areas and failing the navigational task. To address the
above-mentioned issues, this paper investigates various collision scenarios
within VLN-CE and proposes a classification method to predicate the underlying
causes of collisions. Furthermore, a new VLN-CE algorithm, named Safe-VLN, is
proposed to bolster collision avoidance capabilities including two key
components, i.e., a waypoint predictor and a navigator. In particular, the
waypoint predictor leverages a simulated 2D LiDAR occupancy mask to prevent the
predicted waypoints from being situated in obstacle-ridden areas. The
navigator, on the other hand, employs the strategy of `re-selection after
collision' to prevent the robot agent from becoming ensnared in a cycle of
perpetual collisions. The proposed Safe-VLN is evaluated on the R2R-CE, the
results of which demonstrate an enhanced navigational performance and a
statistically significant reduction in collision incidences.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02818" title="Abstract">arXiv:2311.02818</a> [<a href="/pdf/2311.02818" title="Download PDF">pdf</a>, <a href="/format/2311.02818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Signal Processing Meets SGD: From Momentum to Filter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zhipeng Yao</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+G">Guisong Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dazhou Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2010.07468">arXiv:2010.07468</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In the field of deep learning, Stochastic Gradient Descent (SGD) and its
momentum-based variants are the predominant choices for optimization
algorithms. Despite all that, these momentum strategies, which accumulate
historical gradients by using a fixed $\beta$ hyperparameter to smooth the
optimization processing, often neglect the potential impact of the variance of
historical gradients on the current gradient estimation. In the gradient
variance during training, fluctuation indicates the objective function does not
meet the Lipschitz continuity condition at all time, which raises the
troublesome optimization problem. This paper aims to explore the potential
benefits of reducing the variance of historical gradients to make optimizer
converge to flat solutions. Moreover, we proposed a new optimization method
based on reducing the variance. We employed the Wiener filter theory to enhance
the first moment estimation of SGD, notably introducing an adaptive weight to
optimizer. Specifically, the adaptive weight dynamically changes along with
temporal fluctuation of gradient variance during deep learning model training.
Experimental results demonstrated our proposed adaptive weight optimizer, SGDF
(Stochastic Gradient Descent With Filter), can achieve satisfactory performance
compared with state-of-the-art optimizers.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02819" title="Abstract">arXiv:2311.02819</a> [<a href="/pdf/2311.02819" title="Download PDF">pdf</a>, <a href="/format/2311.02819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Exploration of Multimodality and Data Augmentation for Dementia  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kaiying Lin</a>, 
<a href="/search/cs?searchtype=author&query=Washington%2C+P">Peter Washington</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Dementia is a progressive neurological disorder that profoundly affects the
daily lives of older adults, impairing abilities such as verbal communication
and cognitive function. Early diagnosis is essential for enhancing both
lifespan and quality of life for affected individuals. Despite its importance,
diagnosing dementia is complex and often necessitates a multimodal approach
incorporating diverse clinical data types. In this study, we fine-tune Wav2vec
and Word2vec baseline models using two distinct data types: audio recordings
and text transcripts. We experiment with four conditions: original datasets
versus datasets purged of short sentences, each with and without data
augmentation. Our results indicate that synonym-based text data augmentation
generally enhances model performance, underscoring the importance of data
volume for achieving generalizable performance. Additionally, models trained on
text data frequently excel and can further improve the performance of other
modalities when combined. Audio and timestamp data sometimes offer marginal
improvements. We provide a qualitative error analysis of the sentence
archetypes that tend to be misclassified under each condition, providing
insights into the effects of altering data modality and augmentation decisions.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02820" title="Abstract">arXiv:2311.02820</a> [<a href="/pdf/2311.02820" title="Download PDF">pdf</a>, <a href="/format/2311.02820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mesh Neural Cellular Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pajouheshgar%2C+E">Ehsan Pajouheshgar</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yitao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Mordvintsev%2C+A">Alexander Mordvintsev</a>, 
<a href="/search/cs?searchtype=author&query=Niklasson%2C+E">Eyvind Niklasson</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%BCsstrunk%2C+S">Sabine S&#xfc;sstrunk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">Modeling and synthesizing textures are essential for enhancing the realism of
virtual environments. Methods that directly synthesize textures in 3D offer
distinct advantages to the UV-mapping-based methods as they can create seamless
textures and align more closely with the ways textures form in nature. We
propose Mesh Neural Cellular Automata (MeshNCA), a method for directly
synthesizing dynamic textures on 3D meshes without requiring any UV maps.
MeshNCA is a generalized type of cellular automata that can operate on a set of
cells arranged on a non-grid structure such as vertices of a 3D mesh. While
only being trained on an Icosphere mesh, MeshNCA shows remarkable
generalization and can synthesize textures on any mesh in real time after the
training. Additionally, it accommodates multi-modal supervision and can be
trained using different targets such as images, text prompts, and motion vector
fields. Moreover, we conceptualize a way of grafting trained MeshNCA instances,
enabling texture interpolation. Our MeshNCA model enables real-time 3D texture
synthesis on meshes and allows several user interactions including texture
density/orientation control, a grafting brush, and motion speed/direction
control. Finally, we implement the forward pass of our MeshNCA model using the
WebGL shading language and showcase our trained models in an online interactive
demo which is accessible on personal computers and smartphones. Our demo and
the high resolution version of this PDF are available at
https://meshnca.github.io/.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02826" title="Abstract">arXiv:2311.02826</a> [<a href="/pdf/2311.02826" title="Download PDF">pdf</a>, <a href="/format/2311.02826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InstructPix2NeRF: Instructed 3D Portrait Editing from a Single Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianhui Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shilong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zidong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yikai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+K">Kaiwen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jinghui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianmin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://github.com/mybabyyh/InstructPix2NeRF">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the success of Neural Radiance Field (NeRF) in 3D-aware portrait
editing, a variety of works have achieved promising results regarding both
quality and 3D consistency. However, these methods heavily rely on per-prompt
optimization when handling natural language as editing instructions. Due to the
lack of labeled human face 3D datasets and effective architectures, the area of
human-instructed 3D-aware editing for open-world portraits in an end-to-end
manner remains under-explored. To solve this problem, we propose an end-to-end
diffusion-based framework termed InstructPix2NeRF, which enables instructed
3D-aware portrait editing from a single open-world image with human
instructions. At its core lies a conditional latent 3D diffusion process that
lifts 2D editing to 3D space by learning the correlation between the paired
images' difference and the instructions via triplet data. With the help of our
proposed token position randomization strategy, we could even achieve
multi-semantic editing through one single pass with the portrait identity
well-preserved. Besides, we further propose an identity consistency module that
directly modulates the extracted identity signals into our diffusion process,
which increases the multi-view 3D identity consistency. Extensive experiments
verify the effectiveness of our method and show its superiority against strong
baselines quantitatively and qualitatively.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02831" title="Abstract">arXiv:2311.02831</a> [<a href="/pdf/2311.02831" title="Download PDF">pdf</a>, <a href="/format/2311.02831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SemanticTopoLoop: Semantic Loop Closure With 3D Topological Graph Based  on Quadric-Level Object Map
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhenzhong Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Loop closure, as one of the crucial components in SLAM, plays an essential
role in correcting the accumulated errors. Traditional appearance-based
methods, such as bag-of-words models, are often limited by local 2D features
and the volume of training data, making them less versatile and robust in
real-world scenarios, leading to missed detections or false positives
detections in loop closure. To address these issues, we first propose a
object-level data association method based on multi-level verification, which
can associate 2D semantic features of current frame with 3D objects landmarks
of map. Next, taking advantage of these association relations, we introduce a
semantic loop closure method based on quadric-level object map topology, which
represents scenes through the topological graph of objects and achieves
accurate loop closure at a wide field of view by comparing differences in the
topological graphs. Finally, we integrate these two methods into a complete
object-aware SLAM system. Qualitative experiments and ablation studies
demonstrate the effectiveness and robustness of the proposed object-level data
association algorithm. Quantitative experiments show that our semantic loop
closure method outperforms existing state-of-the-art methods in terms of
precision, recall and localization accuracy metrics.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02832" title="Abstract">arXiv:2311.02832</a> [<a href="/pdf/2311.02832" title="Download PDF">pdf</a>, <a href="/format/2311.02832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prioritized Propagation in Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Minjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+C">Caihua Shan</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Ming Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph neural networks (GNNs) have recently received significant attention.
Learning node-wise message propagation in GNNs aims to set personalized
propagation steps for different nodes in the graph. Despite the success,
existing methods ignore node priority that can be reflected by node influence
and heterophily. In this paper, we propose a versatile framework PPro, which
can be integrated with most existing GNN models and aim to learn prioritized
node-wise message propagation in GNNs. Specifically, the framework consists of
three components: a backbone GNN model, a propagation controller to determine
the optimal propagation steps for nodes, and a weight controller to compute the
priority scores for nodes. We design a mutually enhanced mechanism to compute
node priority, optimal propagation step and label prediction. We also propose
an alternative optimization strategy to learn the parameters in the backbone
GNN model and two parametric controllers. We conduct extensive experiments to
compare our framework with other 11 state-of-the-art competitors on 8 benchmark
datasets. Experimental results show that our framework can lead to superior
performance in terms of propagation strategies and node representations.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02833" title="Abstract">arXiv:2311.02833</a> [<a href="/pdf/2311.02833" title="Download PDF">pdf</a>, <a href="/format/2311.02833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CESAR: Control Envelope Synthesis via Angelic Refinements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kabra%2C+A">Aditi Kabra</a>, 
<a href="/search/eess?searchtype=author&query=Laurent%2C+J">Jonathan Laurent</a>, 
<a href="/search/eess?searchtype=author&query=Mitsch%2C+S">Stefan Mitsch</a>, 
<a href="/search/eess?searchtype=author&query=Platzer%2C+A">Andr&#xe9; Platzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents a synthesis approach for provably correct control
envelopes for hybrid systems rooted in hybrid systems game theory. The
resulting control envelopes fill in the blanks for a hybrid systems sketch
specifying the desired shape of a family of controllers, the possible control
actions, and the system's differential equations. In order to maximize the
flexibility of the control envelope, the resulting conditions saying which
control action can be chosen when are as permissive as possible while
establishing a desired safety condition from the available assumptions, which
are augmented if needed. Safety of the control envelope stems from the
systematic refinement of the optimal game and is justified by formal
deductions, while optimality is shown via a dual game characterization. The
resulting algorithm, Control Envelope Synthesis via Angelic Refinements
(CESAR), is demonstrated in a range of safe control synthesis examples with
different control challenges.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02834" title="Abstract">arXiv:2311.02834</a> [<a href="/pdf/2311.02834" title="Download PDF">pdf</a>, <a href="/format/2311.02834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAME: Competitively Learning a Mixture-of-Experts Model for First-stage  Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yinqiong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yixing Fan</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+K">Keping Bi</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiafeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">The first-stage retrieval aims to retrieve a subset of candidate documents
from a huge collection both effectively and efficiently. Since various matching
patterns can exist between queries and relevant documents, previous work tries
to combine multiple retrieval models to find as many relevant results as
possible. The constructed ensembles, whether learned independently or jointly,
do not care which component model is more suitable to an instance during
training. Thus, they cannot fully exploit the capabilities of different types
of retrieval models in identifying diverse relevance patterns. Motivated by
this observation, in this paper, we propose a Mixture-of-Experts (MoE) model
consisting of representative matching experts and a novel competitive learning
mechanism to let the experts develop and enhance their expertise during
training. Specifically, our MoE model shares the bottom layers to learn common
semantic representations and uses differently structured upper layers to
represent various types of retrieval experts. Our competitive learning
mechanism has two stages: (1) a standardized learning stage to train the
experts equally to develop their capabilities to conduct relevance matching;
(2) a specialized learning stage where the experts compete with each other on
every training instance and get rewards and updates according to their
performance to enhance their expertise on certain types of samples.
Experimental results on three retrieval benchmark datasets show that our method
significantly outperforms the state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02835" title="Abstract">arXiv:2311.02835</a> [<a href="/pdf/2311.02835" title="Download PDF">pdf</a>, <a href="/ps/2311.02835" title="Download PostScript">ps</a>, <a href="/format/2311.02835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flexible Multi-Generator Model with Fused Spatiotemporal Graph for  Trajectory Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+P">Peiyuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+F">Fengxia Han</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+H">Hao Deng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Trajectory prediction plays a vital role in automotive radar systems,
facilitating precise tracking and decision-making in autonomous driving.
Generative adversarial networks with the ability to learn a distribution over
future trajectories tend to predict out-of-distribution samples, which
typically occurs when the distribution of forthcoming paths comprises a blend
of various manifolds that may be disconnected. To address this issue, we
propose a trajectory prediction framework, which can capture the social
interaction variations and model disconnected manifolds of pedestrian
trajectories. Our framework is based on a fused spatiotemporal graph to better
model the complex interactions of pedestrians in a scene, and a multi-generator
architecture that incorporates a flexible generator selector network on
generated trajectories to learn a distribution over multiple generators. We
show that our framework achieves state-of-the-art performance compared with
several baselines on different challenging datasets.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02837" title="Abstract">arXiv:2311.02837</a> [<a href="/pdf/2311.02837" title="Download PDF">pdf</a>, <a href="/ps/2311.02837" title="Download PostScript">ps</a>, <a href="/format/2311.02837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-User Multi-IoT-Device Symbiotic Radio: A Novel Massive Access  Scheme for Cellular IoT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Ying-Chang Liang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Sumei Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 12 figures, Conference J. Wang and Y.-C. Liang, Transmit beamforming design for multiuser multi-IoT-device symbiotic radios, in Proc. IEEE ICC, Rome, Italy, May 2023, pp. 1-6
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Symbiotic radio (SR) is a promising technique to support cellular
Internet-of-Things (IoT) by forming a mutualistic relationship between IoT and
cellular transmissions. In this paper, we propose a novel multi-user
multi-IoT-device SR system to enable massive access in cellular IoT. In the
considered system, the base station (BS) transmits information to multiple
cellular users, and a number of IoT devices simultaneously backscatter their
information to these users via the cellular signal. The cellular users jointly
decode the information from the BS and IoT devices. Noting that the reflective
links from the IoT devices can be regarded as the channel uncertainty of the
direct links, we apply the robust design method to design the beamforming
vectors at the BS. Specifically, the transmit power is minimized under the
cellular transmission outage probability constraints and IoT transmission sum
rate constraints. The algorithm based on semi-definite programming and
difference-of-convex programming is proposed to solve the power minimization
problem. Moreover, we consider a special case where each cellular user is
associated with several adjacent IoT devices and propose a direction of arrival
(DoA)-based transmit beamforming design approach. The DoA-based approach
requires only the DoA and angular spread (AS) of the direct links instead of
the instantaneous channel state information (CSI) of the reflective link
channels, leading to a significant reduction in the channel feedback overhead.
Simulation results have substantiated the multi-user multi-IoT-device SR system
and the effectiveness of the proposed beamforming approaches. It is shown that
the DoA-based beamforming approach achieves comparable performance as the
CSI-based approach in the special case when the ASs are small.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02839" title="Abstract">arXiv:2311.02839</a> [<a href="/pdf/2311.02839" title="Download PDF">pdf</a>, <a href="/ps/2311.02839" title="Download PostScript">ps</a>, <a href="/format/2311.02839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cell-Probe Lower Bound for Accessible Interval Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+S">Sankardeep Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Engels%2C+C">Christian Engels</a>, 
<a href="/search/cs?searchtype=author&query=Jo%2C+S">Seungbum Jo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingmou Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We spot a hole in the area of succinct data structures for graph classes from
a universe of size at most $n^n$. Very often, the input graph is labeled by the
user in an arbitrary and easy-to-use way, and the data structure for the graph
relabels the input graph in some way. For any access, the user needs to store
these labels or compute the new labels in an online manner. This might require
more bits than the information-theoretic minimum of the original graph class,
hence, defeating the purpose of succinctness. Given this, the data structure
designer must allow the user to access the data structure with the original
labels, i.e., relabeling is not allowed. We call such a graph data structure
``accessible''. In this paper, we study the complexity of such accessible data
structures for interval graphs, a graph class with information-theoretic
minimum less than $n\log n$ bits.
<br />- We formalize the concept of "accessibility" (which was implicitly assumed),
and propose the "universal interval representation", for interval graphs.
<br />- Any data structure for interval graphs in universal interval
representation, which supports both adjacency and degree query simultaneously
with time cost $t_1$ and $t_2$ respectively, must consume at least
$\log_2(n!)+n/(\log n)^{O(t_1+t_2)}$ bits of space. This is also the first
lower bound for graph classes with information-theoretic minimum less than
$n\log_2n$ bits.
<br />- We provide efficient succinct data structures for interval graphs in
universal interval representation supporting adjacency query and degree query
individually in constant time and space costs. Therefore, two upper bounds
together with the lower bound show that the two elementary queries for interval
graphs are incompatible with each other in the context of succinct data
structure. To the best of our knowledge, this is the first proof of such
incompatibility phenomenon.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02840" title="Abstract">arXiv:2311.02840</a> [<a href="/pdf/2311.02840" title="Download PDF">pdf</a>, <a href="/format/2311.02840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Saturn: Efficient Multi-Large-Model Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nagrecha%2C+K">Kabir Nagrecha</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Arun Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 1 figure, 2 tables. Accepted to BayLearn 2023. Abstract of this paper: <a href="https://adalabucsd.github.io/papers/TR_2023_Saturn.pdf">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In this paper, we propose Saturn, a new data system to improve the efficiency
of multi-large-model training (e.g., during model selection/hyperparameter
optimization). We first identify three key interconnected systems challenges
for users building large models in this setting -- parallelism technique
selection, distribution of GPUs over jobs, and scheduling. We then formalize
these as a joint problem, and build a new system architecture to tackle these
challenges simultaneously. Our evaluations show that our joint-optimization
approach yields 39-49% lower model selection runtimes than typical current DL
practice.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02847" title="Abstract">arXiv:2311.02847</a> [<a href="/pdf/2311.02847" title="Download PDF">pdf</a>, <a href="/format/2311.02847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kinematic-aware Prompting for Generalizable Articulated Object  Manipulation with LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+W">Wenke Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+X">Xincheng Pang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhigang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+D">Di Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generalizable articulated object manipulation is essential for home-assistant
robots. Recent efforts focus on imitation learning from demonstrations or
reinforcement learning in simulation, however, due to the prohibitive costs of
real-world data collection and precise object simulation, it still remains
challenging for these works to achieve broad adaptability across diverse
articulated objects. Recently, many works have tried to utilize the strong
in-context learning ability of Large Language Models (LLMs) to achieve
generalizable robotic manipulation, but most of these researches focus on
high-level task planning, sidelining low-level robotic control. In this work,
building on the idea that the kinematic structure of the object determines how
we can manipulate it, we propose a kinematic-aware prompting framework that
prompts LLMs with kinematic knowledge of objects to generate low-level motion
trajectory waypoints, supporting various object manipulation. To effectively
prompt LLMs with the kinematic structure of different objects, we design a
unified kinematic knowledge parser, which represents various articulated
objects as a unified textual description containing kinematic joints and
contact location. Building upon this unified description, a kinematic-aware
planner model is proposed to generate precise 3D manipulation waypoints via a
designed kinematic-aware chain-of-thoughts prompting method. Our evaluation
spanned 48 instances across 16 distinct categories, revealing that our
framework not only outperforms traditional methods on 8 seen categories but
also shows a powerful zero-shot capability for 8 unseen articulated object
categories. Moreover, the real-world experiments on 7 different object
categories prove our framework's adaptability in practical scenarios. Code is
released at
\href{https://github.com/xwinks/LLM_articulated_object_manipulation}{here}.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02848" title="Abstract">arXiv:2311.02848</a> [<a href="/pdf/2311.02848" title="Download PDF">pdf</a>, <a href="/format/2311.02848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consistent4D: Consistent 360&#xb0; Dynamic Object Generation from  Monocular Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yanqin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Weimin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yao Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technique report. Project page: <a href="https://consistent4d.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we present Consistent4D, a novel approach for generating 4D
dynamic objects from uncalibrated monocular videos. Uniquely, we cast the
360-degree dynamic object reconstruction as a 4D generation problem,
eliminating the need for tedious multi-view data collection and camera
calibration. This is achieved by leveraging the object-level 3D-aware image
diffusion model as the primary supervision signal for training Dynamic Neural
Radiance Fields (DyNeRF). Specifically, we propose a Cascade DyNeRF to
facilitate stable convergence and temporal continuity under the supervision
signal which is discrete along the time axis. To achieve spatial and temporal
consistency, we further introduce an Interpolation-driven Consistency Loss. It
is optimized by minimizing the discrepancy between rendered frames from DyNeRF
and interpolated frames from a pre-trained video interpolation model. Extensive
experiments show that our Consistent4D can perform competitively to prior art
alternatives, opening up new possibilities for 4D dynamic object generation
from monocular videos, whilst also demonstrating advantage for conventional
text-to-3D generation tasks. Our project page is
https://consistent4d.github.io/.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02849" title="Abstract">arXiv:2311.02849</a> [<a href="/pdf/2311.02849" title="Download PDF">pdf</a>, <a href="/format/2311.02849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Co-training and Co-distillation for Quality Improvement and Compression  of Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hayeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+R">Rui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jongpil Kim</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+D">Davis Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongbo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+S+J">Sung Ju Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+A">Alexander Min</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Knowledge Distillation (KD) compresses computationally expensive pre-trained
language models (PLMs) by transferring their knowledge to smaller models,
allowing their use in resource-constrained or real-time settings. However, most
smaller models fail to surpass the performance of the original larger model,
resulting in sacrificing performance to improve inference speed. To address
this issue, we propose Co-Training and Co-Distillation (CTCD), a novel
framework that improves performance and inference speed together by co-training
two models while mutually distilling knowledge. The CTCD framework successfully
achieves this based on two significant findings: 1) Distilling knowledge from
the smaller model to the larger model during co-training improves the
performance of the larger model. 2) The enhanced performance of the larger
model further boosts the performance of the smaller model. The CTCD framework
shows promise as it can be combined with existing techniques like architecture
design or data augmentation, replacing one-way KD methods, to achieve further
performance improvement. Extensive ablation studies demonstrate the
effectiveness of CTCD, and the small model distilled by CTCD outperforms the
original larger model by a significant margin of 1.66 on the GLUE benchmark.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02850" title="Abstract">arXiv:2311.02850</a> [<a href="/pdf/2311.02850" title="Download PDF">pdf</a>, <a href="/format/2311.02850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IR-STP: Enhancing Autonomous Driving with Interaction Reasoning in  Spatio-Temporal Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingbing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jie Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+L">Lu Gan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongji Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+X">Xiaodong Mei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Ming Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures, submitted to IEEE-TITS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Considerable research efforts have been devoted to the development of motion
planning algorithms, which form a cornerstone of the autonomous driving system
(ADS). However, obtaining an interactive and secure trajectory for the ADS
remains a formidable task, especially in scenarios with significant interaction
complexities. Many contemporary prediction-based planning methods frequently
overlook interaction modeling, leading to less effective planning performance.
This paper introduces a novel prediction-based interactive planning framework
that explicitly and mathematically models interactions among traffic entities
during the planning process. Our method incorporates interaction reasoning into
spatio-temporal (s-t) planning by defining interaction conditions and
constraints. Furthermore, it records and continually updates interaction
relations for each planned state throughout the forward search. We assess the
performance of our approach alongside state-of-the-art methods using a series
of experiments conducted in both single and multi-modal scenarios. These
experiments encompass variations in the accuracy of prediction outcomes and
different degrees of planner aggressiveness. The experimental findings
demonstrate the effectiveness and robustness of our method, yielding insights
applicable to the wider field of autonomous driving. For the community's
reference, our code is accessible at
https://github.com/ChenYingbing/IR-STP-Planner.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02851" title="Abstract">arXiv:2311.02851</a> [<a href="/pdf/2311.02851" title="Download PDF">pdf</a>, <a href="/format/2311.02851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Machine Translation with Large Language Models: A Preliminary  Study with Cooperative Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+J">Jiali Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fandong Meng</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yongjing Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Contemporary translation engines built upon the encoder-decoder framework
have reached a high level of development, while the emergence of Large Language
Models (LLMs) has disrupted their position by offering the potential for
achieving superior translation quality. Therefore, it is crucial to understand
in which scenarios LLMs outperform traditional NMT systems and how to leverage
their strengths. In this paper, we first conduct a comprehensive analysis to
assess the strengths and limitations of various commercial NMT systems and
MT-oriented LLMs. Our findings indicate that neither NMT nor MT-oriented LLMs
alone can effectively address all the translation issues, but MT-oriented LLMs
can serve as a promising complement to the NMT systems. Building upon these
insights, we explore hybrid methods and propose Cooperative Decoding (CoDec),
which treats NMT systems as a pretranslation model and MT-oriented LLMs as a
supplemental solution to handle complex scenarios beyond the capability of NMT
alone. The results on the WMT22 test sets and a newly collected test set
WebCrawl demonstrate the effectiveness and efficiency of CoDec, highlighting
its potential as a robust solution for combining NMT systems with MT-oriented
LLMs in machine translation.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02856" title="Abstract">arXiv:2311.02856</a> [<a href="/pdf/2311.02856" title="Download PDF">pdf</a>, <a href="/ps/2311.02856" title="Download PostScript">ps</a>, <a href="/format/2311.02856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Hotplug Caching Schemes Using PDAs and t-Designs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajput%2C+C">Charul Rajput</a>, 
<a href="/search/cs?searchtype=author&query=Rajan%2C+B+S">B. Sundar Rajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, no figures or tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We consider a coded caching system in which some users are offline at the
time of delivery. Such systems are called hotplug coded caching systems
\cite{MT2022}, \cite{MT2023}. A placement delivery array (PDA) is a well-known
tool for constructing a coded caching scheme for dedicated caches. In this
paper, we introduce the concept of PDAs for hotplug coded caching schemes and
refer to it as hotplug placement delivery array (HpPDA). We give an algorithm
to describe the placement and the delivery phase of a hotplug coded caching
scheme using HpPDA. We show that an existing hotplug coded caching scheme given
by Y. Ma and D. Tuninetti \cite{MT2022} corresponds to a class of HpPDAs, and
then propose a method to further improve the rate of that scheme. Additionally,
we construct a class of HpPDA using $t$-designs, which gives a scheme for those
memory points that were not covered by existing hotplug caching systems.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02861" title="Abstract">arXiv:2311.02861</a> [<a href="/pdf/2311.02861" title="Download PDF">pdf</a>, <a href="/format/2311.02861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Less than One-shot: Named Entity Recognition via Extremely Weak  Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+L">Letian Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+J">Jingbo Shang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We study the named entity recognition (NER) problem under the extremely weak
supervision (XWS) setting, where only one example entity per type is given in a
context-free way. While one can see that XWS is lighter than one-shot in terms
of the amount of supervision, we propose a novel method X-NER that can
outperform the state-of-the-art one-shot NER methods. We first mine entity
spans that are similar to the example entities from an unlabelled training
corpus. Instead of utilizing entity span representations from language models,
we find it more effective to compare the context distributions before and after
the span is replaced by the entity example. We then leverage the top-ranked
spans as pseudo-labels to train an NER tagger. Extensive experiments and
analyses on 4 NER datasets show the superior end-to-end NER performance of
X-NER, outperforming the state-of-the-art few-shot methods with 1-shot
supervision and ChatGPT annotations significantly. Finally, our X-NER possesses
several notable properties, such as inheriting the cross-lingual abilities of
the underlying language models.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02862" title="Abstract">arXiv:2311.02862</a> [<a href="/pdf/2311.02862" title="Download PDF">pdf</a>, <a href="/format/2311.02862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generate Complete Logging Statements with an Efficient End-to-End  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaoyuan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhipeng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Songqiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xuan%2C+J">Jifeng Xuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Logs are significant in modern software systems, aiding in various
maintenance tasks. To make better use of these logs, many methods have been
proposed to help developers draft suitable logging statements. However, these
methods only help developers either locate logging positions or write partial
content of logging statements, or cannot efficiently help in generating and
inserting complete logging statements. To address their limitations, we
introduce a new method to better support the automated end-to-end generation of
logging statements. Our end-to-end method consists of two steps, first
utilizing token classification to locate where to insert a logging statement,
and then employing a Seq2Seq model to generate a complete logging statement
with a log level and a log message for that position. We evaluate our proposed
method on the previously used benchmark and a self-constructed new benchmark.
The experimental results show that our method outperforms the state-of-the-art
approach a lot regarding both generation speed and quality.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02863" title="Abstract">arXiv:2311.02863</a> [<a href="/pdf/2311.02863" title="Download PDF">pdf</a>, <a href="/format/2311.02863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Shift -- Multi-Objective Loss Function for Improved Anomaly  Fall Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Denkovski%2C+S">Stefan Denkovski</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S+S">Shehroz S. Khan</a>, 
<a href="/search/cs?searchtype=author&query=Mihailidis%2C+A">Alex Mihailidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Falls are a major cause of injuries and deaths among older adults worldwide.
Accurate fall detection can help reduce potential injuries and additional
health complications. Different types of video modalities can be used in a home
setting to detect falls, including RGB, Infrared, and Thermal cameras. Anomaly
detection frameworks using autoencoders and their variants can be used for fall
detection due to the data imbalance that arises from the rarity and diversity
of falls. However, the use of reconstruction error in autoencoders can limit
the application of networks' structures that propagate information. In this
paper, we propose a new multi-objective loss function called Temporal Shift,
which aims to predict both future and reconstructed frames within a window of
sequential frames. The proposed loss function is evaluated on a
semi-naturalistic fall detection dataset containing multiple camera modalities.
The autoencoders were trained on normal activities of daily living (ADL)
performed by older adults and tested on ADLs and falls performed by young
adults. Temporal shift shows significant improvement to a baseline 3D
Convolutional autoencoder, an attention U-Net CAE, and a multi-modal neural
network. The greatest improvement was observed in an attention U-Net model
improving by 0.20 AUC ROC for a single camera when compared to reconstruction
alone. With significant improvement across different models, this approach has
the potential to be widely adopted and improve anomaly detection capabilities
in other settings besides fall detection.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02865" title="Abstract">arXiv:2311.02865</a> [<a href="/pdf/2311.02865" title="Download PDF">pdf</a>, <a href="/format/2311.02865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-Efficient Multidimensional Constellation Based on Leech Lattice  for Visible Light Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jia-Ning Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ru-Han Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Longguang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jing Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, a 24-dimensional geometrically-shaped constellation design
based on Leech lattice is presented for indoor visible light communications
(VLCs) with a peak-and an average-intensity input constraints. Firstly, by
leveraging tools from large deviation theory, we characterize second-order
asymptotics of the optimal constellation shaping region under aforementioned
intensity constraints, which further refine our previous results in [Chen. et.
al, 2020]. Within the optimal geometrical shaping region, we develop an
energy-efficient 24-dimensional constellation design, where a significant
coding gain brought by the Leech lattice and the nearly-maximum shaping gain
are incorporated by using a strategy called coarsely shaping and finely coding.
Fast algorithms for constellation mapping and demodulation are presented as
well. Numerical results verifies the superiority of our results as compared
with existing methods.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02868" title="Abstract">arXiv:2311.02868</a> [<a href="/pdf/2311.02868" title="Download PDF">pdf</a>, <a href="/ps/2311.02868" title="Download PostScript">ps</a>, <a href="/format/2311.02868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample Complexity Bounds for Estimating Probability Divergences under  Invariances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tahmasebi%2C+B">Behrooz Tahmasebi</a>, 
<a href="/search/cs?searchtype=author&query=Jegelka%2C+S">Stefanie Jegelka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Group-invariant probability distributions appear in many data-generative
models in machine learning, such as graphs, point clouds, and images. In
practice, one often needs to estimate divergences between such distributions.
In this work, we study how the inherent invariances, with respect to any smooth
action of a Lie group on a manifold, improve sample complexity when estimating
the Wasserstein distance, the Sobolev Integral Probability Metrics (Sobolev
IPMs), the Maximum Mean Discrepancy (MMD), and also the complexity of the
density estimation problem (in the $L^2$ and $L^\infty$ distance). Our results
indicate a two-fold gain: (1) reducing the sample complexity by a
multiplicative factor corresponding to the group size (for finite groups) or
the normalized volume of the quotient space (for groups of positive dimension);
(2) improving the exponent in the convergence rate (for groups of positive
dimension). These results are completely new for groups of positive dimension
and extend recent bounds for finite group actions.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02869" title="Abstract">arXiv:2311.02869</a> [<a href="/pdf/2311.02869" title="Download PDF">pdf</a>, <a href="/format/2311.02869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightweight equivariant interaction graph neural network for accurate  and efficient interatomic potential and force predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ziduo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+T">Tiejun Dong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yifan Li</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Q">Qiujie Lv</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C+Y">Calvin Yu-Chian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Lei Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">In modern computational materials science, deep learning has shown the
capability to predict interatomic potentials, thereby supporting and
accelerating conventional simulations. However, existing models typically
sacrifice either accuracy or efficiency. Moreover, lightweight models are
highly demanded for offering simulating systems on a considerably larger scale
at reduced computational costs. A century ago, Felix Bloch demonstrated how
leveraging the equivariance of the translation operation on a crystal lattice
(with geometric symmetry) could significantly reduce the computational cost of
determining wavefunctions and accurately calculate material properties. Here,
we introduce a lightweight equivariant interaction graph neural network
(LEIGNN) that can enable accurate and efficient interatomic potential and force
predictions in crystals. Rather than relying on higher-order representations,
LEIGNN employs a scalar-vector dual representation to encode equivariant
features. By extracting both local and global structures from vector
representations and learning geometric symmetry information, our model remains
lightweight while ensuring prediction accuracy and robustness through the
equivariance. Our results show that LEIGNN consistently outperforms the
prediction performance of the representative baselines and achieves significant
efficiency across diverse datasets, which include catalysts, molecules, and
organic isomers. Finally, to further validate the predicted interatomic
potentials from our model, we conduct classical molecular dynamics (MD) and ab
initio MD simulation across various systems, including solid, liquid, and gas.
It is found that LEIGNN can achieve the accuracy of ab initio MD and retain the
computational efficiency of classical MD across all examined systems,
demonstrating its accuracy, efficiency, and universality.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02872" title="Abstract">arXiv:2311.02872</a> [<a href="/pdf/2311.02872" title="Download PDF">pdf</a>, <a href="/format/2311.02872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FocusTune: Tuning Visual Localization through Focus-Guided Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+S+T">Son Tung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Fontan%2C+A">Alejandro Fontan</a>, 
<a href="/search/cs?searchtype=author&query=Milford%2C+M">Michael Milford</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+T">Tobias Fischer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose FocusTune, a focus-guided sampling technique to improve the
performance of visual localization algorithms. FocusTune directs a scene
coordinate regression model towards regions critical for 3D point triangulation
by exploiting key geometric constraints. Specifically, rather than uniformly
sampling points across the image for training the scene coordinate regression
model, we instead re-project 3D scene coordinates onto the 2D image plane and
sample within a local neighborhood of the re-projected points. While our
proposed sampling strategy is generally applicable, we showcase FocusTune by
integrating it with the recently introduced Accelerated Coordinate Encoding
(ACE) model. Our results demonstrate that FocusTune both improves or matches
state-of-the-art performance whilst keeping ACE's appealing low storage and
compute requirements, for example reducing translation error from 25 to 19 and
17 to 15 cm for single and ensemble models, respectively, on the Cambridge
Landmarks dataset. This combination of high performance and low compute and
storage requirements is particularly promising for applications in areas like
mobile robotics and augmented reality. We made our code available at
\url{https://github.com/sontung/focus-tune}.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02873" title="Abstract">arXiv:2311.02873</a> [<a href="/pdf/2311.02873" title="Download PDF">pdf</a>, <a href="/format/2311.02873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OVIR-3D: Open-Vocabulary 3D Instance Retrieval Without Training on 3D  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shiyang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">Haonan Chang</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+E+P">Eric Pu Jing</a>, 
<a href="/search/cs?searchtype=author&query=Boularias%2C+A">Abdeslam Boularias</a>, 
<a href="/search/cs?searchtype=author&query=Bekris%2C+K">Kostas Bekris</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This work presents OVIR-3D, a straightforward yet effective method for
open-vocabulary 3D object instance retrieval without using any 3D data for
training. Given a language query, the proposed method is able to return a
ranked set of 3D object instance segments based on the feature similarity of
the instance and the text query. This is achieved by a multi-view fusion of
text-aligned 2D region proposals into 3D space, where the 2D region proposal
network could leverage 2D datasets, which are more accessible and typically
larger than 3D datasets. The proposed fusion process is efficient as it can be
performed in real-time for most indoor 3D scenes and does not require
additional training in 3D space. Experiments on public datasets and a real
robot show the effectiveness of the method and its potential for applications
in robot navigation and manipulation.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02877" title="Abstract">arXiv:2311.02877</a> [<a href="/pdf/2311.02877" title="Download PDF">pdf</a>, <a href="/format/2311.02877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inner-IoU: More Effective Intersection over Union Loss with Auxiliary  Bounding Box
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Cong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuaijie Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the rapid development of detectors, Bounding Box Regression (BBR) loss
function has constantly updated and optimized. However, the existing IoU-based
BBR still focus on accelerating convergence by adding new loss terms, ignoring
the limitations of IoU loss term itself. Although theoretically IoU loss can
effectively describe the state of bounding box regression,in practical
applications, it cannot adjust itself according to different detectors and
detection tasks, and does not have strong generalization. Based on the above,
we first analyzed the BBR model and concluded that distinguishing different
regression samples and using different scales of auxiliary bounding boxes to
calculate losses can effectively accelerate the bounding box regression
process. For high IoU samples, using smaller auxiliary bounding boxes to
calculate losses can accelerate convergence, while larger auxiliary bounding
boxes are suitable for low IoU samples. Then, we propose Inner-IoU loss, which
calculates IoU loss through auxiliary bounding boxes. For different datasets
and detectors, we introduce a scaling factor ratio to control the scale size of
the auxiliary bounding boxes for calculating losses. Finally, integrate
Inner-IoU into the existing IoU-based loss functions for simulation and
comparative experiments. The experiment result demonstrate a further
enhancement in detection performance with the utilization of the method
proposed in this paper, verifying the effectiveness and generalization ability
of Inner IoU loss.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02879" title="Abstract">arXiv:2311.02879</a> [<a href="/pdf/2311.02879" title="Download PDF">pdf</a>, <a href="/format/2311.02879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Active Learning in Meta-Learning: Enhancing Context Set  Labeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bae%2C+W">Wonho Bae</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sutherland%2C+D+J">Danica J. Sutherland</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Most meta-learning methods assume that the (very small) context set used to
establish a new task at test time is passively provided. In some settings,
however, it is feasible to actively select which points to label; the potential
gain from a careful choice is substantial, but the setting requires major
differences from typical active learning setups. We clarify the ways in which
active meta-learning can be used to label a context set, depending on which
parts of the meta-learning process use active learning. Within this framework,
we propose a natural algorithm based on fitting Gaussian mixtures for selecting
which points to label; though simple, the algorithm also has theoretical
motivation. The proposed algorithm outperforms state-of-the-art active learning
methods when used with various meta-learning algorithms across several
benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02880" title="Abstract">arXiv:2311.02880</a> [<a href="/pdf/2311.02880" title="Download PDF">pdf</a>, <a href="/format/2311.02880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultiSPANS: A Multi-range Spatial-Temporal Transformer Network for  Traffic Forecast via Structural Entropy Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+D">Dongcheng Zou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Senzhang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuefeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuandong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chunyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+K">Kehua Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures, conference. The work has been accepted by WSDM2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Traffic forecasting is a complex multivariate time-series regression task of
paramount importance for traffic management and planning. However, existing
approaches often struggle to model complex multi-range dependencies using local
spatiotemporal features and road network hierarchical knowledge. To address
this, we propose MultiSPANS. First, considering that an individual recording
point cannot reflect critical spatiotemporal local patterns, we design
multi-filter convolution modules for generating informative ST-token embeddings
to facilitate attention computation. Then, based on ST-token and
spatial-temporal position encoding, we employ the Transformers to capture
long-range temporal and spatial dependencies. Furthermore, we introduce
structural entropy theory to optimize the spatial attention mechanism.
Specifically, The structural entropy minimization algorithm is used to generate
optimal road network hierarchies, i.e., encoding trees. Based on this, we
propose a relative structural entropy-based position encoding and a multi-head
attention masking scheme based on multi-layer encoding trees. Extensive
experiments demonstrate the superiority of the presented framework over several
state-of-the-art methods in real-world traffic datasets, and the longer
historical windows are effectively utilized. The code is available at
https://github.com/SELGroup/MultiSPANS.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02883" title="Abstract">arXiv:2311.02883</a> [<a href="/pdf/2311.02883" title="Download PDF">pdf</a>, <a href="/format/2311.02883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SQLPrompt: In-Context Text-to-SQL with Minimal Labeled Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+R">Ruoxi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Arik%2C+S+%C3%96">Sercan &#xd6;. Arik</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+R">Rajarishi Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Nakhost%2C+H">Hootan Nakhost</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Hanjun Dai</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+P">Pengcheng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Pfister%2C+T">Tomas Pfister</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Text-to-SQL aims to automate the process of generating SQL queries on a
database from natural language text. In this work, we propose "SQLPrompt",
tailored to improve the few-shot prompting capabilities of Text-to-SQL for
Large Language Models (LLMs). Our methods include innovative prompt design,
execution-based consistency decoding strategy which selects the SQL with the
most consistent execution outcome among other SQL proposals, and a method that
aims to improve performance by diversifying the SQL proposals during
consistency selection with different prompt designs ("MixPrompt") and
foundation models ("MixLLMs"). We show that \emph{SQLPrompt} outperforms
previous approaches for in-context learning with few labeled data by a large
margin, closing the gap with finetuning state-of-the-art with thousands of
labeled data.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02884" title="Abstract">arXiv:2311.02884</a> [<a href="/pdf/2311.02884" title="Download PDF">pdf</a>, <a href="/format/2311.02884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-Empowered Semantic Communication Systems with a Shared  Knowledge Base
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+P">Peng Yi</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+X">Xin Kang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Ying-Chang Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, Journal, accepted by IEEE TWC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning-empowered semantic communication is regarded as a promising
candidate for future 6G networks. Although existing semantic communication
systems have achieved superior performance compared to traditional methods, the
end-to-end architecture adopted by most semantic communication systems is
regarded as a black box, leading to the lack of explainability. To tackle this
issue, in this paper, a novel semantic communication system with a shared
knowledge base is proposed for text transmissions. Specifically, a textual
knowledge base constructed by inherently readable sentences is introduced into
our system. With the aid of the shared knowledge base, the proposed system
integrates the message and corresponding knowledge from the shared knowledge
base to obtain the residual information, which enables the system to transmit
fewer symbols without semantic performance degradation. In order to make the
proposed system more reliable, the semantic self-information and the source
entropy are mathematically defined based on the knowledge base. Furthermore,
the knowledge base construction algorithm is developed based on a
similarity-comparison method, in which a pre-configured threshold can be
leveraged to control the size of the knowledge base. Moreover, the simulation
results have demonstrated that the proposed approach outperforms existing
baseline methods in terms of transmitted data size and sentence similarity.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02887" title="Abstract">arXiv:2311.02887</a> [<a href="/pdf/2311.02887" title="Download PDF">pdf</a>, <a href="/format/2311.02887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stacked Autoencoder Based Feature Extraction and Superpixel Generation  for Multifrequency PolSAR Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gadhiya%2C+T">Tushar Gadhiya</a>, 
<a href="/search/cs?searchtype=author&query=Tangirala%2C+S">Sumanth Tangirala</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+A+K">Anil K. Roy</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Pattern Recognition and Machine Intelligence: 8th International
  Conference, PReMI 2019, Tezpur, India, December 17-20, 2019, Proceedings,
  Part II, Dec 2019, Pages 331-339
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper we are proposing classification algorithm for multifrequency
Polarimetric Synthetic Aperture Radar (PolSAR) image. Using PolSAR
decomposition algorithms 33 features are extracted from each frequency band of
the given image. Then, a two-layer autoencoder is used to reduce the
dimensionality of input feature vector while retaining useful features of the
input. This reduced dimensional feature vector is then applied to generate
superpixels using simple linear iterative clustering (SLIC) algorithm. Next, a
robust feature representation is constructed using both pixel as well as
superpixel information. Finally, softmax classifier is used to perform
classification task. The advantage of using superpixels is that it preserves
spatial information between neighbouring PolSAR pixels and therefore minimises
the effect of speckle noise during classification. Experiments have been
conducted on Flevoland dataset and the proposed method was found to be superior
to other methods available in the literature.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02891" title="Abstract">arXiv:2311.02891</a> [<a href="/pdf/2311.02891" title="Download PDF">pdf</a>, <a href="/format/2311.02891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaFlood: Adaptive Flood Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bae%2C+W">Wonho Bae</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yi Ren</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+M+O">Mohamad Osama Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Tung%2C+F">Frederick Tung</a>, 
<a href="/search/cs?searchtype=author&query=Sutherland%2C+D+J">Danica J. Sutherland</a>, 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+G+L">Gabriel L. Oliveira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Although neural networks are conventionally optimized towards zero training
loss, it has been recently learned that targeting a non-zero training loss
threshold, referred to as a flood level, often enables better test time
generalization. Current approaches, however, apply the same constant flood
level to all training samples, which inherently assumes all the samples have
the same difficulty. We present AdaFlood, a novel flood regularization method
that adapts the flood level of each training sample according to the difficulty
of the sample. Intuitively, since training samples are not equal in difficulty,
the target training loss should be conditioned on the instance. Experiments on
datasets covering four diverse input modalities - text, images, asynchronous
event sequences, and tabular - demonstrate the versatility of AdaFlood across
data domains and noise levels.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02892" title="Abstract">arXiv:2311.02892</a> [<a href="/pdf/2311.02892" title="Download PDF">pdf</a>, <a href="/format/2311.02892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human as Points: Explicit Point-based 3D Human Reconstruction from  Single-view RGB Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yingzhi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qijian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Junhui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yebin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The latest trends in the research field of single-view human reconstruction
devote to learning deep implicit functions constrained by explicit body shape
priors. Despite the remarkable performance improvements compared with
traditional processing pipelines, existing learning approaches still show
different aspects of limitations in terms of flexibility, generalizability,
robustness, and/or representation capability. To comprehensively address the
above issues, in this paper, we investigate an explicit point-based human
reconstruction framework called HaP, which adopts point clouds as the
intermediate representation of the target geometric structure. Technically, our
approach is featured by fully-explicit point cloud estimation, manipulation,
generation, and refinement in the 3D geometric space, instead of an implicit
learning process that can be ambiguous and less controllable. The overall
workflow is carefully organized with dedicated designs of the corresponding
specialized learning components as well as processing procedures. Extensive
experiments demonstrate that our framework achieves quantitative performance
improvements of 20% to 40% over current state-of-the-art methods, and better
qualitative results. Our promising results may indicate a paradigm rollback to
the fully-explicit and geometry-centric algorithm design, which enables to
exploit various powerful point cloud modeling architectures and processing
techniques. We will make our code and data publicly available at
https://github.com/yztang4/HaP.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02894" title="Abstract">arXiv:2311.02894</a> [<a href="/pdf/2311.02894" title="Download PDF">pdf</a>, <a href="/ps/2311.02894" title="Download PostScript">ps</a>, <a href="/format/2311.02894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and Performance Analysis of a Class of Generalized Predictive  Controllers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+F">Feilong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The design and structure of generalized predictive control (GPC) are not
simple and intuitive. The performance analysis does not deeply analyze how the
controller parameters affect the system characteristics and the relationship
between the tracking error caused by the noise and the selected controller
parameters. This paper proposes a generalized predictive control, and its
design is simple and intuitive for unnecessary solving the Diophantine
equation. Then the relationship between desired output, disturbance, and system
output is analyzed by the characteristic equation and steady-state analysis.
Based on this, the study presents research findings on the steady state of the
system and verifies them through simulations. Furthermore, this paper
introduces GPC with disturbance compensation and incremental generalized
minimum variance control (IGMVC) with disturbance compensation. The conditions
for the elimination of disturbance are presented in theory and simulation for
the first time.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02900" title="Abstract">arXiv:2311.02900</a> [<a href="/pdf/2311.02900" title="Download PDF">pdf</a>, <a href="/format/2311.02900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Initialisation of Autonomous Aircraft Visual Inspection Systems via  CNN-Based Camera Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oh%2C+X">Xueyan Oh</a>, 
<a href="/search/cs?searchtype=author&query=Loh%2C+L">Leonard Loh</a>, 
<a href="/search/cs?searchtype=author&query=Foong%2C+S">Shaohui Foong</a>, 
<a href="/search/cs?searchtype=author&query=Koh%2C+Z+B+A">Zhong Bao Andy Koh</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+K+L">Kow Leong Ng</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+P+K">Poh Kang Tan</a>, 
<a href="/search/cs?searchtype=author&query=Toh%2C+P+L+P">Pei Lin Pearlin Toh</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+U">U-Xuan Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by 2021 IEEE International Conference on Robotics and Automation (ICRA) with DOI: 10.1109/ICRA48506.2021.9561575
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">General Visual Inspection is a manual inspection process regularly used to
detect and localise obvious damage on the exterior of commercial aircraft.
There has been increasing demand to perform this process at the boarding gate
to minimize the downtime of the aircraft and automating this process is desired
to reduce the reliance on human labour. This automation typically requires the
first step of estimating a camera's pose with respect to the aircraft for
initialisation. However, localisation methods often require infrastructure,
which can be very challenging when performed in uncontrolled outdoor
environments and within the limited turnover time (approximately 2 hours) on an
airport tarmac. In addition, access to commercial aircraft can be very
restricted, causing development and testing of solutions to be a challenge.
Hence, this paper proposes an on-site infrastructure-less initialisation
method, by using the same pan-tilt-zoom camera used for the inspection task to
estimate its own pose. This is achieved using a Deep Convolutional Neural
Network trained with only synthetic images to regress the camera's pose. We
apply domain randomisation when generating our dataset for training our network
and improve prediction accuracy by introducing a new component to an existing
loss function that leverages on known aircraft geometry to relate position and
orientation. Experiments are conducted and we have successfully regressed
camera poses with a median error of 0.22 m and 0.73 degrees.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02903" title="Abstract">arXiv:2311.02903</a> [<a href="/pdf/2311.02903" title="Download PDF">pdf</a>, <a href="/format/2311.02903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HDGL: A hierarchical dynamic graph representation learning model for  brain disorder classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jalali%2C+P">Parniyan Jalali</a>, 
<a href="/search/cs?searchtype=author&query=Safayani%2C+M">Mehran Safayani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">The human brain can be considered as complex networks, composed of various
regions that continuously exchange their information with each other, forming
the brain network graph, from which nodes and edges are extracted using
resting-state functional magnetic resonance imaging (rs-fMRI). Therefore, this
graph can potentially depict abnormal patterns that have emerged under the
influence of brain disorders. So far, numerous studies have attempted to find
embeddings for brain network graphs and subsequently classify samples with
brain disorders from healthy ones, which include limitations such as: not
considering the relationship between samples, not utilizing phenotype
information, lack of temporal analysis, using static functional connectivity
(FC) instead of dynamic ones and using a fixed graph structure. We propose a
hierarchical dynamic graph representation learning (HDGL) model, which is the
first model designed to address all the aforementioned challenges. HDGL
consists of two levels, where at the first level, it constructs brain network
graphs and learns their spatial and temporal embeddings, and at the second
level, it forms population graphs and performs classification after embedding
learning. Furthermore, based on how these two levels are trained, four methods
have been introduced, some of which are suggested for reducing memory
complexity. We evaluated the performance of the proposed model on the ABIDE and
ADHD-200 datasets, and the results indicate the improvement of this model
compared to several state-of-the-art models in terms of various evaluation
metrics.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02904" title="Abstract">arXiv:2311.02904</a> [<a href="/pdf/2311.02904" title="Download PDF">pdf</a>, <a href="/ps/2311.02904" title="Download PostScript">ps</a>, <a href="/format/2311.02904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sharp error analysis for averaging Crank-Nicolson schemes with  corrections for subdiffusion with nonsmooth solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yin%2C+B">Baoli Yin</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+H">Hong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Thanks to the singularity of the solution of linear subdiffusion problems,
most time-stepping methods on uniform meshes can result in $O(\tau)$ accuracy
where $\tau$ denotes the time step. The present work aims to discover the
reason why some type of Crank-Nicolson schemes (the averaging Crank-Nicolson
scheme) for the subdiffusion can only yield $O(\tau^\alpha)$$(\alpha&lt;1)$
accuracy, which is much lower than the desired. The existing well developed
error analysis for the subdiffusion, which has been successfully applied to
many time-stepping methods such as the fractional BDF-$p (1\leq p\leq 6)$, all
requires singular points be out of the path of contour integrals involved. The
averaging Crank-Nicolson scheme in this work is quite natural but fails to meet
this requirement. By resorting to the residue theorem, some novel sharp error
analysis is developed in this study, upon which correction methods are further
designed to obtain the optimal $O(\tau^2)$ accuracy. All results are verified
by numerical tests.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02907" title="Abstract">arXiv:2311.02907</a> [<a href="/pdf/2311.02907" title="Download PDF">pdf</a>, <a href="/format/2311.02907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning for Safety Testing: Lessons from A Mobile Robot  Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huck%2C+T+P">Tom P. Huck</a>, 
<a href="/search/cs?searchtype=author&query=Kaiser%2C+M">Martin Kaiser</a>, 
<a href="/search/cs?searchtype=author&query=Cronrath%2C+C">Constantin Cronrath</a>, 
<a href="/search/cs?searchtype=author&query=Lennartson%2C+B">Bengt Lennartson</a>, 
<a href="/search/cs?searchtype=author&query=Kr%C3%B6ger%2C+T">Torsten Kr&#xf6;ger</a>, 
<a href="/search/cs?searchtype=author&query=Asfour%2C+T">Tamim Asfour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Safety-critical robot systems need thorough testing to expose design flaws
and software bugs which could endanger humans. Testing in simulation is
becoming increasingly popular, as it can be applied early in the development
process and does not endanger any real-world operators. However, not all
safety-critical flaws become immediately observable in simulation. Some may
only become observable under certain critical conditions. If these conditions
are not covered, safety flaws may remain undetected. Creating critical tests is
therefore crucial. In recent years, there has been a trend towards using
Reinforcement Learning (RL) for this purpose. Guided by domain-specific reward
functions, RL algorithms are used to learn critical test strategies. This paper
presents a case study in which the collision avoidance behavior of a mobile
robot is subjected to RL-based testing. The study confirms prior research which
shows that RL can be an effective testing tool. However, the study also
highlights certain challenges associated with RL-based testing, namely (i) a
possible lack of diversity in test conditions and (ii) the phenomenon of reward
hacking where the RL agent behaves in undesired ways due to a misalignment of
reward and test specification. The challenges are illustrated with data and
examples from the experiments, and possible mitigation strategies are
discussed.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02908" title="Abstract">arXiv:2311.02908</a> [<a href="/pdf/2311.02908" title="Download PDF">pdf</a>, <a href="/format/2311.02908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monocular UAV Localisation with Deep Learning and Uncertainty  Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oh%2C+X">Xueyan Oh</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+R">Ryan Lim</a>, 
<a href="/search/cs?searchtype=author&query=Loh%2C+L">Leonard Loh</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C+H">Chee How Tan</a>, 
<a href="/search/cs?searchtype=author&query=Foong%2C+S">Shaohui Foong</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+U">U-Xuan Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by IEEE Robotics and Automation Letters (Volume: 7, Issue: 3, July 2022) with DOI: <a href="https://doi.org/10.1109/LRA.2022.3186750">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this paper, we propose a ground-based monocular UAV localisation system
that detects and localises an LED marker attached to the underside of a UAV.
Our system removes the need for extensive infrastructure and calibration unlike
existing technologies such as UWB, radio frequency and multi-camera systems
often used for localisation in GPS-denied environment. To improve deployablity
for real-world applications without the need to collect extensive real dataset,
we train a CNN on synthetic binary images as opposed to using real images in
existing monocular UAV localisation methods, and factor in the camera's zoom to
allow tracking of UAVs flying at further distances. We propose NoisyCutout
algorithm for augmenting synthetic binary images to simulate binary images
processed from real images and show that it improves localisation accuracy as
compared to using existing salt-and-pepper and Cutout augmentation methods. We
also leverage uncertainty propagation to modify the CNN's loss function and
show that this also improves localisation accuracy. Real-world experiments are
conducted to evaluate our methods and we achieve an overall 3D RMSE of
approximately 0.41m.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02909" title="Abstract">arXiv:2311.02909</a> [<a href="/pdf/2311.02909" title="Download PDF">pdf</a>, <a href="/format/2311.02909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Matrix-Based Sampling for Graph Neural Network Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tripathy%2C+A">Alok Tripathy</a>, 
<a href="/search/cs?searchtype=author&query=Yelick%2C+K">Katherine Yelick</a>, 
<a href="/search/cs?searchtype=author&query=Buluc%2C+A">Aydin Buluc</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Performance (cs.PF)

</div>
<p class="mathjax">The primary contribution of this paper is new methods for reducing
communication in the sampling step for distributed GNN training. Here, we
propose a matrix-based bulk sampling approach that expresses sampling as a
sparse matrix multiplication (SpGEMM) and samples multiple minibatches at once.
When the input graph topology does not fit on a single device, our method
distributes the graph and use communication-avoiding SpGEMM algorithms to scale
GNN minibatch sampling, enabling GNN training on much larger graphs than those
that can fit into a single device memory. When the input graph topology (but
not the embeddings) fits in the memory of one GPU, our approach (1) performs
sampling without communication, (2) amortizes the overheads of sampling a
minibatch, and (3) can represent multiple sampling algorithms by simply using
different matrix constructions. In addition to new methods for sampling, we
show that judiciously replicating feature data with a simple all-to-all
exchange can outperform current methods for the feature extraction step in
distributed GNN training. We provide experimental results on the largest Open
Graph Benchmark (OGB) datasets on $128$ GPUs, and show that our pipeline is
$2.5\times$ faster Quiver (a distributed extension to PyTorch-Geometric) on a
$3$-layer GraphSAGE network. On datasets outside of OGB, we show a $8.46\times$
speedup on $128$ GPUs in-per epoch time. Finally, we show scaling when the
graph is distributed across GPUs and scaling for both node-wise and layer-wise
sampling algorithms
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02910" title="Abstract">arXiv:2311.02910</a> [<a href="/pdf/2311.02910" title="Download PDF">pdf</a>, <a href="/ps/2311.02910" title="Download PostScript">ps</a>, <a href="/format/2311.02910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Deep Facial Expression Recognition: An Extensive Protocol  with Balanced Dataset in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tutuianu%2C+G+I">Gianmarco Ipinze Tutuianu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Alam%C3%A4ki%2C+A">Ari Alam&#xe4;ki</a>, 
<a href="/search/cs?searchtype=author&query=Kauttonen%2C+J">Janne Kauttonen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> * Equal contribution
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Facial expression recognition (FER) is a crucial part of human-computer
interaction. Existing FER methods achieve high accuracy and generalization
based on different open-source deep models and training approaches. However,
the performance of these methods is not always good when encountering practical
settings, which are seldom explored. In this paper, we collected a new
in-the-wild facial expression dataset for cross-domain validation. Twenty-three
commonly used network architectures were implemented and evaluated following a
uniform protocol. Moreover, various setups, in terms of input resolutions,
class balance management, and pre-trained strategies, were verified to show the
corresponding performance contribution. Based on extensive experiments on three
large-scale FER datasets and our practical cross-validation, we ranked network
architectures and summarized a set of recommendations on deploying deep FER
methods in real scenarios. In addition, potential ethical rules, privacy
issues, and regulations were discussed in practical FER applications such as
marketing, education, and entertainment business.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02912" title="Abstract">arXiv:2311.02912</a> [<a href="/pdf/2311.02912" title="Download PDF">pdf</a>, <a href="/format/2311.02912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imitation Learning based Alternative Multi-Agent Proximal Policy  Optimization for Well-Formed Swarm-Oriented Pursuit Avoidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sizhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Y">Yuming Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rongpeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhifeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Honggang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures, 2023 IEEE the 9th International Conference on Computer and Communications (ICCC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Multi-Robot System (MRS) has garnered widespread research interest and
fostered tremendous interesting applications, especially in cooperative control
fields. Yet little light has been shed on the compound ability of formation,
monitoring and defence in decentralized large-scale MRS for pursuit avoidance,
which puts stringent requirements on the capability of coordination and
adaptability. In this paper, we put forward a decentralized Imitation learning
based Alternative Multi-Agent Proximal Policy Optimization (IA-MAPPO) algorithm
to provide a flexible and communication-economic solution to execute the
pursuit avoidance task in well-formed swarm. In particular, a
policy-distillation based MAPPO executor is firstly devised to capably
accomplish and swiftly switch between multiple formations in a centralized
manner. Furthermore, we utilize imitation learning to decentralize the
formation controller, so as to reduce the communication overheads and enhance
the scalability. Afterwards, alternative training is leveraged to compensate
the performance loss incurred by decentralization. The simulation results
validate the effectiveness of IA-MAPPO and extensive ablation experiments
further show the performance comparable to a centralized solution with
significant decrease in communication overheads.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02916" title="Abstract">arXiv:2311.02916</a> [<a href="/pdf/2311.02916" title="Download PDF">pdf</a>, <a href="/format/2311.02916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Virtual Action Actor-Critic Framework for Exploration (Student Abstract)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+B">Bumgeun Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taeyoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lai-Dang%2C+Q">Quoc-Vinh Lai-Dang</a>, 
<a href="/search/cs?searchtype=author&query=Har%2C+D">Dongsoo Har</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Efficient exploration for an agent is challenging in reinforcement learning
(RL). In this paper, a novel actor-critic framework namely virtual action
actor-critic (VAAC), is proposed to address the challenge of efficient
exploration in RL. This work is inspired by humans' ability to imagine the
potential outcomes of their actions without actually taking them. In order to
emulate this ability, VAAC introduces a new actor called virtual actor (VA),
alongside the conventional actor-critic framework. Unlike the conventional
actor, the VA takes the virtual action to anticipate the next state without
interacting with the environment. With the virtual policy following a Gaussian
distribution, the VA is trained to maximize the anticipated novelty of the
subsequent state resulting from a virtual action. If any next state resulting
from available actions does not exhibit high anticipated novelty, training the
VA leads to an increase in the virtual policy entropy. Hence, high virtual
policy entropy represents that there is no room for exploration. The proposed
VAAC aims to maximize a modified Q function, which combines cumulative rewards
and the negative sum of virtual policy entropy. Experimental results show that
the VAAC improves the exploration performance compared to existing algorithms.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02917" title="Abstract">arXiv:2311.02917</a> [<a href="/pdf/2311.02917" title="Download PDF">pdf</a>, <a href="/ps/2311.02917" title="Download PostScript">ps</a>, <a href="/format/2311.02917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RIS-Enabled Anti-Interference in LoRa Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zhaokun Liang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+G">Guofa Cai</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiguang He</a>, 
<a href="/search/cs?searchtype=author&query=Kaddoum%2C+G">Georges Kaddoum</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chongwen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Debbah%2C+M">Merouane Debbah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">It has been proved that a long-range (LoRa) system can achieve long-distance
and low-power. However, the performance of LoRa systems can be severely
degraded by fading. In addition, LoRa technology typically adopts an
ALOHA-based access mechanism, which inevitably produces interfering signals for
the target user. To overcome the effects of fading and interference, we
introduce a reconfigurable intelligent surface (RIS) to LoRa systems. In this
context, both non-coherent and coherent detections are considered and their bit
error rate (BER) performance analyses are conducted. Moreover, we derive the
closed-form BER expressions for the proposed system over Nakagami-m fading
channels. Simulation results are used to verify the accuracy of our proposed
analytical results. It is shown that the proposed system outperforms the
RIS-free LoRa system, and the RIS-aided LoRa system adopting blind
transmission. Furthermore, the impacts of the spreading factor (SF), the number
of reflecting elements, and the Nakagami-m fading parameters are investigated.
It is shown that increasing the number of reflecting elements can remarkably
enhance the BER performance, which is an affective measure for the proposed
system to balance the trade-off between data rate and coverage range. We
further observe that the BER performance of the proposed system is more
sensitive to the fading parameter m at high signal-to-noise ratios.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02918" title="Abstract">arXiv:2311.02918</a> [<a href="/pdf/2311.02918" title="Download PDF">pdf</a>, <a href="/ps/2311.02918" title="Download PostScript">ps</a>, <a href="/format/2311.02918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assistance-Transmission Tradeoff for RIS-assisted Symbiotic Radios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qianqian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Ying-Chang Liang</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+Y">Yiyang Pei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">This paper studies the reconfigurable intelligent surface (RIS)-assisted
symbiotic radio (SR) system, where an RIS acts as a secondary transmitter to
transmit its information by leveraging the primary signal as its RF carrier and
simultaneously assists the primary transmission. Conventionally, all reflecting
elements of the RIS are used to transmit the secondary signal, which, however,
would limit its capability for assisting the primary transmission. To address
this issue, we propose a novel RIS partitioning scheme, where the RIS is
partitioned into two sub-surfaces, one to assist the primary transmission and
the other to transmit the secondary signal. Naturally, there exists a
fundamental tradeoff between the assistance and transmission capabilities of
RIS regarding the surface partitioning strategy. Considering the coupling
effect between the primary and secondary transmissions, we focus on the
detection of the composite signal formed by the primary and secondary ones,
based on which we propose a novel two-step detector. Then, we formulate the
assistance-transmission tradeoff problem to minimize the bit error rate (BER)
of the composite signal by jointly optimizing the surface partitioning strategy
and the phase shifts of the two sub-surfaces, such that the overall BER of
RIS-assisted SR is minimized. By solving this problem, we show that the
optimized surface partitioning strategy depends on the channel strength ratio
of the direct link to the reflected link. Finally, extensive simulations show
that our proposed RIS partitioning scheme outperforms the conventional schemes
which use all reflecting elements for either assistance or transmission.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02921" title="Abstract">arXiv:2311.02921</a> [<a href="/pdf/2311.02921" title="Download PDF">pdf</a>, <a href="/format/2311.02921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge2Node: Reducing Edge Prediction to Node Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahmati%2C+Z">Zahed Rahmati</a>, 
<a href="/search/cs?searchtype=author&query=Rahmati%2C+A">Ali Rahmati</a>, 
<a href="/search/cs?searchtype=author&query=Kazemi%2C+D">Dariush Kazemi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Despite the success of graph neural network models in node classification,
edge prediction (the task of predicting missing or potential relationships
between nodes in a graph) remains a challenging problem for these models. A
common approach for edge prediction is to first obtain the embeddings of two
nodes, and then a predefined scoring function is used to predict the existence
of an edge between the two nodes. In this paper, we introduce a new approach
called E2N (Edge2Node) which directly obtains an embedding for each edge,
without the need for a scoring function. To do this, we create a new graph H
based on the graph G given for the edge prediction task, and then reduce the
edge prediction task on G to a node classification task on H. Our E2N method
can be easily applied to any edge prediction task with superior performance and
lower computational costs.
<br />For the ogbl-ddi and ogbl-collab datasets, our E2N method outperforms the
state-of-the-art methods listed on the leaderboards. Our experiments on the
ogbl-ddi dataset achieved a Hits@20 score of 98.79% on the validation set and
98.11% on the test set. On the ogbl-collab dataset, we achieved a Hits@50 score
of 95.46% on the validation set and 95.15% on the test set.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02922" title="Abstract">arXiv:2311.02922</a> [<a href="/pdf/2311.02922" title="Download PDF">pdf</a>, <a href="/format/2311.02922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Truly Scale-Equivariant Deep Nets with Fourier Layers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+A">Md Ashiqur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+R+A">Raymond A. Yeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In computer vision, models must be able to adapt to changes in image
resolution to effectively carry out tasks such as image segmentation; This is
known as scale-equivariance. Recent works have made progress in developing
scale-equivariant convolutional neural networks, e.g., through weight-sharing
and kernel resizing. However, these networks are not truly scale-equivariant in
practice. Specifically, they do not consider anti-aliasing as they formulate
the down-scaling operation in the continuous domain. To address this
shortcoming, we directly formulate down-scaling in the discrete domain with
consideration of anti-aliasing. We then propose a novel architecture based on
Fourier layers to achieve truly scale-equivariant deep nets, i.e., absolute
zero equivariance-error. Following prior works, we test this model on
MNIST-scale and STL-10 datasets. Our proposed model achieves competitive
classification performance while maintaining zero equivariance-error.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02924" title="Abstract">arXiv:2311.02924</a> [<a href="/pdf/2311.02924" title="Download PDF">pdf</a>, <a href="/ps/2311.02924" title="Download PostScript">ps</a>, <a href="/format/2311.02924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AttentioNet: Monitoring Student Attention Type in Learning with  EEG-Based Measurement System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verma%2C+D">Dhruv Verma</a>, 
<a href="/search/cs?searchtype=author&query=Bhalla%2C+S">Sejal Bhalla</a>, 
<a href="/search/cs?searchtype=author&query=Santosh%2C+S+V+S">S. V. Sai Santosh</a>, 
<a href="/search/cs?searchtype=author&query=Yadav%2C+S">Saumya Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Parnami%2C+A">Aman Parnami</a>, 
<a href="/search/cs?searchtype=author&query=Shukla%2C+J">Jainendra Shukla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, Accepted in AFFECTIVE COMPUTING + INTELLIGENT INTERACTION Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Student attention is an indispensable input for uncovering their goals,
intentions, and interests, which prove to be invaluable for a multitude of
research areas, ranging from psychology to interactive systems. However, most
existing methods to classify attention fail to model its complex nature. To
bridge this gap, we propose AttentioNet, a novel Convolutional Neural
Network-based approach that utilizes Electroencephalography (EEG) data to
classify attention into five states: Selective, Sustained, Divided,
Alternating, and relaxed state. We collected a dataset of 20 subjects through
standard neuropsychological tasks to elicit different attentional states. The
average across-student accuracy of our proposed model at this configuration is
92.3% (SD=3.04), which is well-suited for end-user applications. Our transfer
learning-based approach for personalizing the model to individual subjects
effectively addresses the issue of individual variability in EEG signals,
resulting in improved performance and adaptability of the model for real-world
applications. This represents a significant advancement in the field of
EEG-based classification. Experimental results demonstrate that AttentioNet
outperforms a popular EEGnet baseline (p-value &lt; 0.05) in both
subject-independent and subject-dependent settings, confirming the
effectiveness of our proposed approach despite the limitations of our dataset.
These results highlight the promising potential of AttentioNet for attention
classification using EEG data.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02926" title="Abstract">arXiv:2311.02926</a> [<a href="/pdf/2311.02926" title="Download PDF">pdf</a>, <a href="/format/2311.02926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Image Semantic Communication Model for Artificial Intelligent  Internet of Things
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+L+P">Li Ping Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+S">Sikai Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Huijie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X+S">Xuemin Sherman Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaoniu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the rapid development of Artificial Intelligent Internet of Things
(AIoT), the image data from AIoT devices has been witnessing the explosive
increasing. In this paper, a novel deep image semantic communication model is
proposed for the efficient image communication in AIoT. Particularly, at the
transmitter side, a high-precision image semantic segmentation algorithm is
proposed to extract the semantic information of the image to achieve
significant compression of the image data. At the receiver side, a semantic
image restoration algorithm based on Generative Adversarial Network (GAN) is
proposed to convert the semantic image to a real scene image with detailed
information. Simulation results demonstrate that the proposed image semantic
communication model can improve the image compression ratio and recovery
accuracy by 71.93% and 25.07% on average in comparison with WebP and CycleGAN,
respectively. More importantly, our demo experiment shows that the proposed
model reduces the total delay by 95.26% in the image communication, when
comparing with the original image transmission.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02928" title="Abstract">arXiv:2311.02928</a> [<a href="/pdf/2311.02928" title="Download PDF">pdf</a>, <a href="/ps/2311.02928" title="Download PostScript">ps</a>, <a href="/format/2311.02928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pilot Design and Signal Detection for Symbiotic Radio over OFDM Carriers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qianqian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+R">Ruizhe Long</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+Y">Yiyang Pei</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Ying-Chang Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for publication in IEEE Transactions on Wireless Communications
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Wireless Communications, early access, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Symbiotic radio (SR) is a promising solution to achieve high spectrum- and
energy-efficiency due to its spectrum sharing and low-power consumption
properties, in which the secondary system achieves data transmissions by
backscattering the signal originating from the primary system. In this paper,
we are interested in the pilot design and signal detection when the primary
transmission adopts orthogonal frequency division multiplexing (OFDM). In
particular, to preserve the channel orthogonality among the OFDM sub-carriers,
each secondary symbol is designed to span an entire OFDM symbol. The comb-type
pilot structure is employed by the primary transmission, while the preamble
pilot structure is used by the secondary transmission. With the designed pilot
structures, the primary signal can be detected via the conventional methods by
treating the secondary signal as a part of the composite channel, i.e., the
effective channel of the primary transmission. Furthermore, the secondary
signal can be extracted from the estimated composite channel with the help of
the detected primary signal. The bit error rate (BER) performance with both
perfect and estimated CSI, the diversity orders of the primary and secondary
transmissions, and the sensitivity to symbol synchronization error are
analyzed. Simulation results show that the performance of the primary
transmission is enhanced thanks to the backscatter link established by the
secondary transmission. More importantly, even without the direct link, the
primary and secondary transmissions can be supported via only the backscatter
link.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02929" title="Abstract">arXiv:2311.02929</a> [<a href="/pdf/2311.02929" title="Download PDF">pdf</a>, <a href="/format/2311.02929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoK: Evaluations in Industrial Intrusion Detection Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lamberts%2C+O">Olav Lamberts</a>, 
<a href="/search/cs?searchtype=author&query=Wolsing%2C+K">Konrad Wolsing</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+E">Eric Wagner</a>, 
<a href="/search/cs?searchtype=author&query=Pennekamp%2C+J">Jan Pennekamp</a>, 
<a href="/search/cs?searchtype=author&query=Bauer%2C+J">Jan Bauer</a>, 
<a href="/search/cs?searchtype=author&query=Wehrle%2C+K">Klaus Wehrle</a>, 
<a href="/search/cs?searchtype=author&query=Henze%2C+M">Martin Henze</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Systems Research (JSys) Volume 3(1) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Industrial systems are increasingly threatened by cyberattacks with
potentially disastrous consequences. To counter such attacks, industrial
intrusion detection systems strive to timely uncover even the most
sophisticated breaches. Due to its criticality for society, this fast-growing
field attracts researchers from diverse backgrounds, resulting in 130 new
detection approaches in 2021 alone. This huge momentum facilitates the
exploration of diverse promising paths but likewise risks fragmenting the
research landscape and burying promising progress. Consequently, it needs sound
and comprehensible evaluations to mitigate this risk and catalyze efforts into
sustainable scientific progress with real-world applicability. In this paper,
we therefore systematically analyze the evaluation methodologies of this field
to understand the current state of industrial intrusion detection research. Our
analysis of 609 publications shows that the rapid growth of this research field
has positive and negative consequences. While we observe an increased use of
public datasets, publications still only evaluate 1.3 datasets on average, and
frequently used benchmarking metrics are ambiguous. At the same time, the
adoption of newly developed benchmarking metrics sees little advancement.
Finally, our systematic analysis enables us to provide actionable
recommendations for all actors involved and thus bring the entire research
field forward.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02937" title="Abstract">arXiv:2311.02937</a> [<a href="/pdf/2311.02937" title="Download PDF">pdf</a>, <a href="/format/2311.02937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Marker-Based Localisation System Using an Active PTZ Camera and  CNN-Based Ellipse Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oh%2C+X">Xueyan Oh</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+R">Ryan Lim</a>, 
<a href="/search/cs?searchtype=author&query=Foong%2C+S">Shaohui Foong</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+U">U-Xuan Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by IEEE/ASME Transactions on Mechatronics with DOI: <a href="https://doi.org/10.1109/TMECH.2023.3274363">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Localisation in GPS-denied environments is challenging and many existing
solutions have infrastructural and on-site calibration requirements. This paper
tackles these challenges by proposing a localisation system that is
infrastructure-free and does not require on-site calibration, using a single
active PTZ camera to detect, track and localise a circular LED marker. We
propose to use a CNN trained using only synthetic images to detect the LED
marker as an ellipse and show that our approach is more robust than using
traditional ellipse detection without requiring tuning of parameters for
feature extraction. We also propose to leverage the predicted elliptical angle
as a measure of uncertainty of the CNN's predictions and show how it can be
used in a filter to improve marker range estimation and 3D localisation. We
evaluate our system's performance through localisation of a UAV in real-world
flight experiments and show that it can outperform alternative methods for
localisation in GPS-denied environments. We also demonstrate our system's
performance in indoor and outdoor environments.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02938" title="Abstract">arXiv:2311.02938</a> [<a href="/pdf/2311.02938" title="Download PDF">pdf</a>, <a href="/format/2311.02938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Multi-Level Graph Neural Networks for Session-based  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fuyun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xingyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+L">Lei Lyu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Multimedia, February 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Session-based recommendation (SBR) aims to predict the next item at a certain
time point based on anonymous user behavior sequences. Existing methods
typically model session representation based on simple item transition
information. However, since session-based data consists of limited users'
short-term interactions, modeling session representation by capturing fixed
item transition information from a single dimension suffers from data sparsity.
In this paper, we propose a novel contrastive multi-level graph neural networks
(CM-GNN) to better exploit complex and high-order item transition information.
Specifically, CM-GNN applies local-level graph convolutional network (L-GCN)
and global-level network (G-GCN) on the current session and all the sessions
respectively, to effectively capture pairwise relations over all the sessions
by aggregation strategy. Meanwhile, CM-GNN applies hyper-level graph
convolutional network (H-GCN) to capture high-order information among all the
item transitions. CM-GNN further introduces an attention-based fusion module to
learn pairwise relation-based session representation by fusing the item
representations generated by L-GCN and G-GCN. CM-GNN averages the item
representations obtained by H-GCN to obtain high-order relation-based session
representation. Moreover, to convert the high-order item transition information
into the pairwise relation-based session representation, CM-GNN maximizes the
mutual information between the representations derived from the fusion module
and the average pool layer by contrastive learning paradigm. We conduct
extensive experiments on multiple widely used benchmark datasets to validate
the efficacy of the proposed method. The encouraging results demonstrate that
our proposed method outperforms the state-of-the-art SBR techniques.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02940" title="Abstract">arXiv:2311.02940</a> [<a href="/pdf/2311.02940" title="Download PDF">pdf</a>, <a href="/format/2311.02940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Pursuit of Human Labeling: A New Perspective on Unsupervised  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gadetsky%2C+A">Artyom Gadetsky</a>, 
<a href="/search/cs?searchtype=author&query=Brbic%2C+M">Maria Brbic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 camera-ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We present HUME, a simple model-agnostic framework for inferring human
labeling of a given dataset without any external supervision. The key insight
behind our approach is that classes defined by many human labelings are
linearly separable regardless of the representation space used to represent a
dataset. HUME utilizes this insight to guide the search over all possible
labelings of a dataset to discover an underlying human labeling. We show that
the proposed optimization objective is strikingly well-correlated with the
ground truth labeling of the dataset. In effect, we only train linear
classifiers on top of pretrained representations that remain fixed during
training, making our framework compatible with any large pretrained and
self-supervised model. Despite its simplicity, HUME outperforms a supervised
linear classifier on top of self-supervised representations on the STL-10
dataset by a large margin and achieves comparable performance on the CIFAR-10
dataset. Compared to the existing unsupervised baselines, HUME achieves
state-of-the-art performance on four benchmark image classification datasets
including the large-scale ImageNet-1000 dataset. Altogether, our work provides
a fundamentally new view to tackle unsupervised learning by searching for
consistent labelings between different representation spaces.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02945" title="Abstract">arXiv:2311.02945</a> [<a href="/pdf/2311.02945" title="Download PDF">pdf</a>, <a href="/format/2311.02945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PhoGPT: Generative Pre-training for Vietnamese
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+Q">Dat Quoc Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+L+T">Linh The Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+C">Chi Tran</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+N">Dung Ngoc Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+N">Nhung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+H">Thien Huu Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Phung%2C+D">Dinh Phung</a>, 
<a href="/search/cs?searchtype=author&query=Bui%2C+H">Hung Bui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhoGPT Technical Report - 4 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We open-source a state-of-the-art 7.5B-parameter generative model series
named PhoGPT for Vietnamese, which includes the base pre-trained monolingual
model PhoGPT-7B5 and its instruction-following variant, PhoGPT-7B5-Instruct. In
addition, we also demonstrate its superior performance compared to previous
open-source models through a human evaluation experiment. GitHub:
https://github.com/VinAIResearch/PhoGPT
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02947" title="Abstract">arXiv:2311.02947</a> [<a href="/pdf/2311.02947" title="Download PDF">pdf</a>, <a href="/ps/2311.02947" title="Download PostScript">ps</a>, <a href="/format/2311.02947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-view learning for automatic classification of multi-wavelength  auroral images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qiuju Yang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hang Su</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lili Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yixuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Ze-Jun Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Auroral classification plays a crucial role in polar research. However,
current auroral classification studies are predominantly based on images taken
at a single wavelength, typically 557.7 nm. Images obtained at other
wavelengths have been comparatively overlooked, and the integration of
information from multiple wavelengths remains an underexplored area. This
limitation results in low classification rates for complex auroral patterns.
Furthermore, these studies, whether employing traditional machine learning or
deep learning approaches, have not achieved a satisfactory trade-off between
accuracy and speed. To address these challenges, this paper proposes a
lightweight auroral multi-wavelength fusion classification network, MLCNet,
based on a multi-view approach. Firstly, we develop a lightweight feature
extraction backbone, called LCTNet, to improve the classification rate and cope
with the increasing amount of auroral observation data. Secondly, considering
the existence of multi-scale spatial structures in auroras, we design a novel
multi-scale reconstructed feature module named MSRM. Finally, to highlight the
discriminative information between auroral classes, we propose a lightweight
attention feature enhancement module called LAFE. The proposed method is
validated using observational data from the Arctic Yellow River Station during
2003-2004. Experimental results demonstrate that the fusion of multi-wavelength
information effectively improves the auroral classification performance. In
particular, our approach achieves state-of-the-art classification accuracy
compared to previous auroral classification studies, and superior results in
terms of accuracy and computational efficiency compared to existing multi-view
methods.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02948" title="Abstract">arXiv:2311.02948</a> [<a href="/pdf/2311.02948" title="Download PDF">pdf</a>, <a href="/format/2311.02948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simultaneous Time Synchronization and Mutual Localization for  Multi-robot System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+X">Xiangyong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yingjian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kaiwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+F">Fei Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Mutual localization stands as a foundational component within various domains
of multi-robot systems.
<br />Nevertheless, in relative pose estimation, time synchronization is usually
underappreciated and rarely addressed, although it significantly influences
estimation accuracy.
<br />In this paper, we introduce time synchronization into mutual localization to
recover the time offset and relative poses between robots simultaneously.
<br />Under a constant velocity assumption in a short time, we fuse time offset
estimation with our previous bearing-based mutual localization by a novel error
representation.
<br />Based on the error model, we formulate a joint optimization problem and
utilize semi-definite relaxation (SDR) to furnish a lossless relaxation.
<br />By solving the relaxed problem, time synchronization and relative pose
estimation can be achieved when time drift between robots is limited.
<br />To enhance the application range of time offset estimation, we further
propose an iterative method to recover the time offset from coarse to fine.
<br />Comparisons between the proposed method and the existing ones through
extensive simulation tests present prominent benefits of time synchronization
on mutual localization.
<br />Moreover, real-world experiments are conducted to show the practicality and
robustness.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02955" title="Abstract">arXiv:2311.02955</a> [<a href="/pdf/2311.02955" title="Download PDF">pdf</a>, <a href="/ps/2311.02955" title="Download PostScript">ps</a>, <a href="/format/2311.02955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An operator-splitting optimization approach for phase-field simulation  of equilibrium shapes of crystals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhou%2C+Z">Zeyu Zhou</a>, 
<a href="/search/math?searchtype=author&query=Huang%2C+W">Wen Huang</a>, 
<a href="/search/math?searchtype=author&query=Jiang%2C+W">Wei Jiang</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Z">Zhen Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Computing equilibrium shapes of crystals (ESC) is a challenging problem in
materials science that involves minimizing an orientation-dependent (i.e.,
anisotropic) surface energy functional subject to a prescribed mass constraint.
The highly nonlinear and singular anisotropic terms in the problem make it very
challenging from both the analytical and numerical aspects. Especially, when
the strength of anisotropy is very strong (i.e., strongly anisotropic cases),
the ESC will form some singular, sharp corners even if the surface energy
function is smooth. Traditional numerical approaches, such as the $H^{-1}$
gradient flow, are unable to produce true sharp corners due to the necessary
addition of a high-order regularization term that penalizes sharp corners and
rounds them off. In this paper, we propose a new numerical method based on the
Davis-Yin splitting (DYS) optimization algorithm to predict the ESC instead of
using gradient flow approaches. We discretize the infinite-dimensional
phase-field energy functional in the absence of regularization terms and
transform it into a finite-dimensional constraint minimization problem. The
resulting optimization problem is solved using the DYS method which
automatically guarantees the mass-conservation and bound-preserving properties.
We also prove the global convergence of the proposed algorithm. These desired
properties are numerically observed. In particular, the proposed method can
produce real sharp corners with satisfactory accuracy. Finally, we present
numerous numerical results to demonstrate that the ESC can be well simulated
under different types of anisotropic surface energies, which also confirms the
effectiveness and efficiency of the proposed method.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02956" title="Abstract">arXiv:2311.02956</a> [<a href="/pdf/2311.02956" title="Download PDF">pdf</a>, <a href="/format/2311.02956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Context Learning for Knowledge Base Question Answering for Unmanned  Systems based on Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yunlong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yaming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jianfei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Li Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+R">Rui Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Runner up of the CCKS 2023 question answering with knowledge graph inference for unmanned systems evaluation task, accepted as an evaluation paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Knowledge Base Question Answering (KBQA) aims to answer factoid questions
based on knowledge bases. However, generating the most appropriate knowledge
base query code based on Natural Language Questions (NLQ) poses a significant
challenge in KBQA. In this work, we focus on the CCKS2023 Competition of
Question Answering with Knowledge Graph Inference for Unmanned Systems.
Inspired by the recent success of large language models (LLMs) like ChatGPT and
GPT-3 in many QA tasks, we propose a ChatGPT-based Cypher Query Language (CQL)
generation framework to generate the most appropriate CQL based on the given
NLQ. Our generative framework contains six parts: an auxiliary model predicting
the syntax-related information of CQL based on the given NLQ, a proper noun
matcher extracting proper nouns from the given NLQ, a demonstration example
selector retrieving similar examples of the input sample, a prompt constructor
designing the input template of ChatGPT, a ChatGPT-based generation model
generating the CQL, and an ensemble model to obtain the final answers from
diversified outputs. With our ChatGPT-based CQL generation framework, we
achieved the second place in the CCKS 2023 Question Answering with Knowledge
Graph Inference for Unmanned Systems competition, achieving an F1-score of
0.92676.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02957" title="Abstract">arXiv:2311.02957</a> [<a href="/pdf/2311.02957" title="Download PDF">pdf</a>, <a href="/format/2311.02957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe and Efficient Trajectory Optimization for Autonomous Vehicles using  B-spline with Incremental Path Flattening
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jongseo Choi</a>, 
<a href="/search/cs?searchtype=author&query=Chin%2C+H">Hyuntai Chin</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Hyunwoo Park</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+D">Daehyeok Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sanghyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Baek%2C+D">Doosan Baek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 20 figures, 3 tables, 2 algorithms
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">B-spline-based trajectory optimization has been widely used in the field of
robot navigation, as the convex hull property of the B-spline curve guarantees
its dynamical feasibility with a small number of control variables. Several
recent works demonstrated that a holonomic system like a drone, which has
simple dynamical feasibility constraints, fully utilizes the B-spline property
for trajectory optimization. Nevertheless, it is still challenging to leverage
the B-splined-based optimization algorithm to generate a collision-free
trajectory for autonomous vehicles because their complex vehicle kinodynamic
constraints make it difficult to use the convex hull property. In this paper,
we propose a novel incremental path flattening method with a new swept volume
method that enables a B-splined-based trajectory optimization algorithm to
incorporate vehicle kinematic collision avoidance constraints. Furthermore, a
curvature constraint is added with other feasibility constraints (e.g. velocity
and acceleration) for the vehicle kinodynamic constraints. Our experimental
results demonstrate that our method outperforms state-of-the-art baselines in
various simulated environments and verifies its valid tracking performance with
an autonomous vehicle in a real-world scenario.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02960" title="Abstract">arXiv:2311.02960</a> [<a href="/pdf/2311.02960" title="Download PDF">pdf</a>, <a href="/format/2311.02960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Deep Representation Learning via Layerwise Feature  Compression and Discrimination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Yaras%2C+C">Can Yaras</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhihui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Balzano%2C+L">Laura Balzano</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Q">Qing Qu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 58 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Optimization and Control (math.OC)

</div>
<p class="mathjax">Over the past decade, deep learning has proven to be a highly effective tool
for learning meaningful features from raw data. However, it remains an open
question how deep networks perform hierarchical feature learning across layers.
In this work, we attempt to unveil this mystery by investigating the structures
of intermediate features. Motivated by our empirical findings that linear
layers mimic the roles of deep layers in nonlinear networks for feature
learning, we explore how deep linear networks transform input data into output
by investigating the output (i.e., features) of each layer after training in
the context of multi-class classification problems. Toward this goal, we first
define metrics to measure within-class compression and between-class
discrimination of intermediate features, respectively. Through theoretical
analysis of these two metrics, we show that the evolution of features follows a
simple and quantitative pattern from shallow to deep layers when the input data
is nearly orthogonal and the network weights are minimum-norm, balanced, and
approximate low-rank: Each layer of the linear network progressively compresses
within-class features at a geometric rate and discriminates between-class
features at a linear rate with respect to the number of layers that data have
passed through. To the best of our knowledge, this is the first quantitative
characterization of feature evolution in hierarchical representations of deep
linear networks. Empirically, our extensive experiments not only validate our
theoretical results numerically but also reveal a similar pattern in deep
nonlinear networks which aligns well with recent empirical studies. Moreover,
we demonstrate the practical implications of our results in transfer learning.
Our code is available at \url{https://github.com/Heimine/PNC_DLN}.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02961" title="Abstract">arXiv:2311.02961</a> [<a href="/pdf/2311.02961" title="Download PDF">pdf</a>, <a href="/format/2311.02961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapting Pre-trained Generative Models for Extractive Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mallick%2C+P">Prabir Mallick</a>, 
<a href="/search/cs?searchtype=author&query=Nayak%2C+T">Tapas Nayak</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+I">Indrajit Bhattacharya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in GEM workshop @ EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Pre-trained Generative models such as BART, T5, etc. have gained prominence
as a preferred method for text generation in various natural language
processing tasks, including abstractive long-form question answering (QA) and
summarization. However, the potential of generative models in extractive QA
tasks, where discriminative models are commonly employed, remains largely
unexplored. Discriminative models often encounter challenges associated with
label sparsity, particularly when only a small portion of the context contains
the answer. The challenge is more pronounced for multi-span answers. In this
work, we introduce a novel approach that uses the power of pre-trained
generative models to address extractive QA tasks by generating indexes
corresponding to context tokens or sentences that form part of the answer.
Through comprehensive evaluations on multiple extractive QA datasets, including
MultiSpanQA, BioASQ, MASHQA, and WikiQA, we demonstrate the superior
performance of our proposed approach compared to existing state-of-the-art
models.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02962" title="Abstract">arXiv:2311.02962</a> [<a href="/pdf/2311.02962" title="Download PDF">pdf</a>, <a href="/format/2311.02962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval-Augmented Code Generation for Universal Information Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yucan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zixuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xiaolong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yantao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yutao Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenxuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+P">Pan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+L">Long Bai</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiafeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Information Extraction (IE) aims to extract structural knowledge (e.g.,
entities, relations, events) from natural language texts, which brings
challenges to existing methods due to task-specific schemas and complex text
expressions. Code, as a typical kind of formalized language, is capable of
describing structural knowledge under various schemas in a universal way. On
the other hand, Large Language Models (LLMs) trained on both codes and texts
have demonstrated powerful capabilities of transforming texts into codes, which
provides a feasible solution to IE tasks. Therefore, in this paper, we propose
a universal retrieval-augmented code generation framework based on LLMs, called
Code4UIE, for IE tasks. Specifically, Code4UIE adopts Python classes to define
task-specific schemas of various structural knowledge in a universal way. By so
doing, extracting knowledge under these schemas can be transformed into
generating codes that instantiate the predefined Python classes with the
information in texts. To generate these codes more precisely, Code4UIE adopts
the in-context learning mechanism to instruct LLMs with examples. In order to
obtain appropriate examples for different tasks, Code4UIE explores several
example retrieval strategies, which can retrieve examples semantically similar
to the given texts. Extensive experiments on five representative IE tasks
across nine datasets demonstrate the effectiveness of the Code4UIE framework.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02971" title="Abstract">arXiv:2311.02971</a> [<a href="/pdf/2311.02971" title="Download PDF">pdf</a>, <a href="/format/2311.02971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TabRepo: A Large Scale Repository of Tabular Model Evaluations and its  AutoML Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salinas%2C+D">David Salinas</a>, 
<a href="/search/cs?searchtype=author&query=Erickson%2C+N">Nick Erickson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We introduce TabRepo, a new dataset of tabular model evaluations and
predictions. TabRepo contains the predictions and metrics of 1206 models
evaluated on 200 regression and classification datasets. We illustrate the
benefit of our datasets in multiple ways. First, we show that it allows to
perform analysis such as comparing Hyperparameter Optimization against current
AutoML systems while also considering ensembling at no cost by using
precomputed model predictions. Second, we show that our dataset can be readily
leveraged to perform transfer-learning. In particular, we show that applying
standard transfer-learning techniques allows to outperform current
state-of-the-art tabular systems in accuracy, runtime and latency.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02976" title="Abstract">arXiv:2311.02976</a> [<a href="/pdf/2311.02976" title="Download PDF">pdf</a>, <a href="/format/2311.02976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Power Wake-Up Signal Design in 3GPP Release 18
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wagner%2C+S">Sebastian Wagner</a>, 
<a href="/search/cs?searchtype=author&query=Trung%2C+K+L">Kien Le Trung</a>, 
<a href="/search/cs?searchtype=author&query=Knopp%2C+R">Raymond Knopp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in IEEE CSCN 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">This article provides an overview of the Low-Power Wake-Up Signal (LP-WUS)
design in 3GPP Rel-18. A particular focus is the analysis of the different
proposed low-power waveform designs in the Rel-18 study item including coding
and modulation. The performance of the waveforms is compared through numerical
simulations under various channel conditions. Furthermore, a novel coding
scheme is proposed that exploits the WUS repetitions in time-domain to transmit
additional payload and significantly increases spectral efficiency.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02985" title="Abstract">arXiv:2311.02985</a> [<a href="/pdf/2311.02985" title="Download PDF">pdf</a>, <a href="/ps/2311.02985" title="Download PostScript">ps</a>, <a href="/format/2311.02985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Transformer-Based Reverse Dictionary Model for Quality  Estimation of Definitions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Julien%2C+G">Guit&#xe9;-Vinet Julien</a>, 
<a href="/search/cs?searchtype=author&query=Alexandre%2C+B+M">Blondin Mass&#xe9; Alexandre</a>, 
<a href="/search/cs?searchtype=author&query=Fatiha%2C+S">Sadat Fatiha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In the last years, several variants of transformers have emerged. In this
paper, we compare different transformer-based models for solving the reverse
dictionary task and explore their use in the context of a serious game called
The Dictionary Game.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02991" title="Abstract">arXiv:2311.02991</a> [<a href="/pdf/2311.02991" title="Download PDF">pdf</a>, <a href="/ps/2311.02991" title="Download PostScript">ps</a>, <a href="/format/2311.02991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-based Radiotherapy Dose Prediction Guided by Inter-slice Aware  Structure Encoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhenghao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+L">Lu Wen</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jianghong Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuanyuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiliu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xingchen Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep learning (DL) has successfully automated dose distribution prediction in
radiotherapy planning, enhancing both efficiency and quality. However, existing
methods suffer from the over-smoothing problem for their commonly used L1 or L2
loss with posterior average calculations. To alleviate this limitation, we
propose a diffusion model-based method (DiffDose) for predicting the
radiotherapy dose distribution of cancer patients. Specifically, the DiffDose
model contains a forward process and a reverse process. In the forward process,
DiffDose transforms dose distribution maps into pure Gaussian noise by
gradually adding small noise and a noise predictor is simultaneously trained to
estimate the noise added at each timestep. In the reverse process, it removes
the noise from the pure Gaussian noise in multiple steps with the well-trained
noise predictor and finally outputs the predicted dose distribution maps...
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02994" title="Abstract">arXiv:2311.02994</a> [<a href="/pdf/2311.02994" title="Download PDF">pdf</a>, <a href="/format/2311.02994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolution of Collective Decision-Making Mechanisms for Collective  Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaiser%2C+T+K">Tanja Katharina Kaiser</a>, 
<a href="/search/cs?searchtype=author&query=Potten%2C+T">Tristan Potten</a>, 
<a href="/search/cs?searchtype=author&query=Hamann%2C+H">Heiko Hamann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE Congress on Evolutionary Computation (CEC), Chicago, IL, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Neural and Evolutionary Computing (cs.NE); Robotics (cs.RO)

</div>
<p class="mathjax">Autonomous robot swarms must be able to make fast and accurate collective
decisions, but speed and accuracy are known to be conflicting goals. While
collective decision-making is widely studied in swarm robotics research, only
few works on using methods of evolutionary computation to generate collective
decision-making mechanisms exist. These works use task-specific fitness
functions rewarding the accomplishment of the respective collective
decision-making task. But task-independent rewards, such as for prediction
error minimization, may promote the emergence of diverse and innovative
solutions. We evolve collective decision-making mechanisms using a
task-specific fitness function rewarding correct robot opinions, a
task-independent reward for prediction accuracy, and a hybrid fitness function
combining the two previous. In our simulations, we use the collective
perception scenario, that is, robots must collectively determine which of two
environmental features is more frequent. We show that evolution successfully
optimizes fitness in all three scenarios, but that only the task-specific
fitness function and the hybrid fitness function lead to the emergence of
collective decision-making behaviors. In benchmark experiments, we show the
competitiveness of the evolved decision-making mechanisms to the voter model
and the majority rule and analyze the scalability of the decision-making
mechanisms with problem difficulty.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02995" title="Abstract">arXiv:2311.02995</a> [<a href="/pdf/2311.02995" title="Download PDF">pdf</a>, <a href="/format/2311.02995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Enhancement of Low-Light Image Based on Retinex Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenchao Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+B">Bangshu Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Ou%2C+Q">Qiaofeng Ou</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+X">Xiaoyun Long</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jinhao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiabao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+S">Shuyuan Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 66 figures, TCSVT
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Two difficulties here make low-light image enhancement a challenging task;
firstly, it needs to consider not only luminance restoration but also image
contrast, image denoising and color distortion issues simultaneously. Second,
the effectiveness of existing low-light enhancement methods depends on paired
or unpaired training data with poor generalization performance.
<br />To solve these difficult problems, we propose in this paper a new
learning-based Retinex decomposition of zero-shot low-light enhancement method,
called ZERRINNet. To this end, we first designed the N-Net network, together
with the noise loss term, to be used for denoising the original low-light image
by estimating the noise of the low-light image. Moreover, RI-Net is used to
estimate the reflection component and illumination component, and in order to
solve the color distortion and contrast, we use the texture loss term and
segmented smoothing loss to constrain the reflection component and illumination
component. Finally, our method is a zero-reference enhancement method that is
not affected by the training data of paired and unpaired datasets, so our
generalization performance is greatly improved, and in the paper, we have
effectively validated it with a homemade real-life low-light dataset and
additionally with advanced vision tasks, such as face detection, target
recognition, and instance segmentation. We conducted comparative experiments on
a large number of public datasets and the results show that the performance of
our method is competitive compared to the current state-of-the-art methods. The
code is available at:https://github.com/liwenchao0615/ZERRINNet
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02996" title="Abstract">arXiv:2311.02996</a> [<a href="/pdf/2311.02996" title="Download PDF">pdf</a>, <a href="/format/2311.02996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual-information-driven model for crowd simulation using temporal  convolutional network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xuanwen Liang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+E+W+M">Eric Wai Ming Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Crowd simulations play a pivotal role in building design, influencing both
user experience and public safety. While traditional knowledge-driven models
have their merits, data-driven crowd simulation models promise to bring a new
dimension of realism to these simulations. However, most of the existing
data-driven models are designed for specific geometries, leading to poor
adaptability and applicability. A promising strategy for enhancing the
adaptability and realism of data-driven crowd simulation models is to
incorporate visual information, including the scenario geometry and pedestrian
locomotion. Consequently, this paper proposes a novel visual-information-driven
(VID) crowd simulation model. The VID model predicts the pedestrian velocity at
the next time step based on the prior social-visual information and motion data
of an individual. A radar-geometry-locomotion method is established to extract
the visual information of pedestrians. Moreover, a temporal convolutional
network (TCN)-based deep learning model, named social-visual TCN, is developed
for velocity prediction. The VID model is tested on three public pedestrian
motion datasets with distinct geometries, i.e., corridor, corner, and
T-junction. Both qualitative and quantitative metrics are employed to evaluate
the VID model, and the results highlight the improved adaptability of the model
across all three geometric scenarios. Overall, the proposed method demonstrates
effectiveness in enhancing the adaptability of data-driven crowd models.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03000" title="Abstract">arXiv:2311.03000</a> [<a href="/pdf/2311.03000" title="Download PDF">pdf</a>, <a href="/format/2311.03000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strong statistical parity through fair synthetic data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krchova%2C+I">Ivona Krchova</a>, 
<a href="/search/cs?searchtype=author&query=Platzer%2C+M">Michael Platzer</a>, 
<a href="/search/cs?searchtype=author&query=Tiwald%2C+P">Paul Tiwald</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Machine Learning (stat.ML)

</div>
<p class="mathjax">AI-generated synthetic data, in addition to protecting the privacy of
original data sets, allows users and data consumers to tailor data to their
needs. This paper explores the creation of synthetic data that embodies
Fairness by Design, focusing on the statistical parity fairness definition. By
equalizing the learned target probability distributions of the synthetic data
generator across sensitive attributes, a downstream model trained on such
synthetic data provides fair predictions across all thresholds, that is, strong
fair predictions even when inferring from biased, original data. This fairness
adjustment can be either directly integrated into the sampling process of a
synthetic generator or added as a post-processing step. The flexibility allows
data consumers to create fair synthetic data and fine-tune the trade-off
between accuracy and fairness without any previous assumptions on the data or
re-training the synthetic data generator.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03001" title="Abstract">arXiv:2311.03001</a> [<a href="/pdf/2311.03001" title="Download PDF">pdf</a>, <a href="/format/2311.03001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Weighting for Kernel Density Ratios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S">Sangwoong Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+F+C">Frank C. Park</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+G+S">Gunsu S Yun</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+I">Iljung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Noh%2C+Y">Yung-Kyun Noh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Kernel density estimation (KDE) is integral to a range of generative and
discriminative tasks in machine learning. Drawing upon tools from the
multidimensional calculus of variations, we derive an optimal weight function
that reduces bias in standard kernel density estimates for density ratios,
leading to improved estimates of prediction posteriors and
information-theoretic measures. In the process, we shed light on some
fundamental aspects of density estimation, particularly from the perspective of
algorithms that employ KDEs as their main building blocks.
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03002" title="Abstract">arXiv:2311.03002</a> [<a href="/pdf/2311.03002" title="Download PDF">pdf</a>, <a href="/format/2311.03002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating treatment effects from single-arm trials via latent-variable  modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haussmann%2C+M">Manuel Haussmann</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T+M+S">Tran Minh Son Le</a>, 
<a href="/search/cs?searchtype=author&query=Halla-aho%2C+V">Viivi Halla-aho</a>, 
<a href="/search/cs?searchtype=author&query=Kurki%2C+S">Samu Kurki</a>, 
<a href="/search/cs?searchtype=author&query=Leinonen%2C+J">Jussi Leinonen</a>, 
<a href="/search/cs?searchtype=author&query=Koskinen%2C+M">Miika Koskinen</a>, 
<a href="/search/cs?searchtype=author&query=Kaski%2C+S">Samuel Kaski</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%A4hdesm%C3%A4ki%2C+H">Harri L&#xe4;hdesm&#xe4;ki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Randomized controlled trials (RCTs) are the accepted standard for treatment
effect estimation but they can be infeasible due to ethical reasons and
prohibitive costs. Single-arm trials, where all patients belong to the
treatment group, can be a viable alternative but require access to an external
control group. We propose an identifiable deep latent-variable model for this
scenario that can also account for missing covariate observations by modeling
their structured missingness patterns. Our method uses amortized variational
inference to learn both group-specific and identifiable shared latent
representations, which can subsequently be used for (i) patient matching if
treatment outcomes are not available for the treatment group, or for (ii)
direct treatment effect estimation assuming outcomes are available for both
groups. We evaluate the model on a public benchmark as well as on a data set
consisting of a published RCT study and real-world electronic health records.
Compared to previous methods, our results show improved performance both for
direct treatment effect estimation as well as for effect estimation via patient
matching.
</p>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03004" title="Abstract">arXiv:2311.03004</a> [<a href="/pdf/2311.03004" title="Download PDF">pdf</a>, <a href="/format/2311.03004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breaking the Degrees-of-Freedom Limit of Holographic MIMO  Communications: A 3-D Array Topology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+S+S+A">Shuai S. A. Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongjing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tengjiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Da Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chongwen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Sheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shilie Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xianmin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+E">Er-Ping Li</a>, 
<a href="/search/cs?searchtype=author&query=Sha%2C+W+E+I">Wei E. I. Sha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Applied Physics (physics.app-ph)

</div>
<p class="mathjax">The efficacy of holographic multiple-input multiple-output (MIMO)
communications, employing two-dimensional (2-D) planar antenna arrays, is
typically compromised by finite degrees-of-freedom (DOF) stemming from limited
array size. The DOF constraint becomes significant when the element spacing
approaches approximately half a wavelength, thereby restricting the overall
performance of MIMO systems. To break this inherent limitation, we propose a
novel three-dimensional (3-D) array topology that strategically explores the
untapped vertical dimension. We investigate the performance of MIMO systems
utilizing 3-D arrays across different multi-path scenarios, encompassing
Rayleigh channels with varying angular spreads and the 3rd generation
partnership project (3GPP) channels. We subsequently showcase the advantages of
these 3-D arrays over their 2-D counterparts with the same aperture sizes. As a
proof of concept, a practical dipole-based 3-D array, facilitated by an
electromagnetic band-gap (EBG) reflecting surface, is conceived, constructed,
and evaluated. The experimental results align closely with full-wave
simulations, and channel simulations substantiate that the DOF and capacity
constraints of traditional holographic MIMO systems can be surpassed by
adopting such a 3-D array configuration.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03007" title="Abstract">arXiv:2311.03007</a> [<a href="/pdf/2311.03007" title="Download PDF">pdf</a>, <a href="/format/2311.03007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting spatial group error and synchrony for a unicycle tracking  controller
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hampsey%2C+M">Matthew Hampsey</a>, 
<a href="/search/eess?searchtype=author&query=van+Goor%2C+P">Pieter van Goor</a>, 
<a href="/search/eess?searchtype=author&query=Mahony%2C+R">Robert Mahony</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Trajectory tracking for the kinematic unicycle has been heavily studied for
several decades. The unicycle admits a natural $\SE(2)$ symmetry, a key
structure exploited in many of the most successful nonlinear controllers in the
literature. To the author's knowledge however, all prior work has used a
body-fixed, or left-invariant, group error formulation for the study of the
tracking problem. In this paper, we consider the spatial, or right-invariant,
group error in the design of a tracking controller for the kinematic unicycle.
We provide a physical interpretation of the right-invariant error and go on to
show that the associated error dynamics are drift-free, a property that is not
true for the body-fixed error. We exploit this property to propose a simple
nonlinear control scheme for the kinematic unicycle and prove almost-global
asymptotic stability of this control scheme for a class of persistently
exciting trajectories. We also verify performance of this control scheme in
simulation for an example trajectory.
</p>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03008" title="Abstract">arXiv:2311.03008</a> [<a href="/pdf/2311.03008" title="Download PDF">pdf</a>, <a href="/format/2311.03008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Capability of Text-to-Image Diffusion Models with  Structural Edge Guidance for Multi-Spectral Satellite Image Inpainting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Czerkawski%2C+M">Mikolaj Czerkawski</a>, 
<a href="/search/cs?searchtype=author&query=Tachtatzis%2C+C">Christos Tachtatzis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Exploratory analysis from March 2023, currently under review in a letters venue
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The paper investigates the utility of text-to-image inpainting models for
satellite image data. Two technical challenges of injecting structural guiding
signals into the generative process as well as translating the inpainted RGB
pixels to a wider set of MSI bands are addressed by introducing a novel
inpainting framework based on StableDiffusion and ControlNet as well as a novel
method for RGB-to-MSI translation. The results on a wider set of data suggest
that the inpainting synthesized via StableDiffusion suffers from undesired
artefacts and that a simple alternative of self-supervised internal inpainting
achieves higher quality of synthesis.
</p>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03010" title="Abstract">arXiv:2311.03010</a> [<a href="/pdf/2311.03010" title="Download PDF">pdf</a>, <a href="/ps/2311.03010" title="Download PostScript">ps</a>, <a href="/format/2311.03010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Extrapolation Economy Cascadic Multigrid Method for Image  Restoration Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chu%2C+Z">Zhaoteng Chu</a>, 
<a href="/search/math?searchtype=author&query=Yan%2C+Z">Ziqi Yan</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+C">Chenliang Li</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> American Journal of Computational Mathematics, 13, 323-341 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, a new extrapolation economy cascadic multigrid method is
proposed to solve the image restoration model. The new method combines the new
extrapolation formula and quadratic interpolation to design a nonlinear
prolongation operator, which provides more accurate initial values for the fine
grid level. An edge preserving denoising operator is constructed to remove
noise and preserve image edges. The local smoothing operator reduces the
influence of staircase effect. The experiment results show that the new method
not only improves the computational efficiency but also ensures good recovery
quality.
</p>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03016" title="Abstract">arXiv:2311.03016</a> [<a href="/pdf/2311.03016" title="Download PDF">pdf</a>, <a href="/format/2311.03016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design, implementation, and validation of a benchmark generator for  combinatorial interaction testing tools
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bombarda%2C+A">Andrea Bombarda</a>, 
<a href="/search/cs?searchtype=author&query=Gargantini%2C+A">Angelo Gargantini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Combinatorial testing is a widely adopted technique for efficiently detecting
faults in software. The quality of combinatorial test generators plays a
crucial role in achieving effective test coverage. Evaluating combinatorial
test generators remains a challenging task that requires diverse and
representative benchmarks. Having such benchmarks might help developers to test
their tools, and improve their performance. For this reason, in this paper, we
present BenCIGen, a highly configurable generator of benchmarks to be used by
combinatorial test generators, empowering users to customize the type of
benchmarks generated, including constraints and parameters, as well as their
complexity. An initial version of such a tool has been used during the
CT-Competition, held yearly during the International Workshop on Combinatorial
Testing. This paper describes the requirements, the design, the implementation,
and the validation of BenCIGen. Tests for the validation of BenCIGen are
derived from its requirements by using a combinatorial interaction approach.
Moreover, we demonstrate the tool's ability to generate benchmarks that reflect
the characteristics of real software systems. BenCIGen not only facilitates the
evaluation of existing generators but also serves as a valuable resource for
researchers and practitioners seeking to enhance the quality and effectiveness
of combinatorial testing methodologies.
</p>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03017" title="Abstract">arXiv:2311.03017</a> [<a href="/pdf/2311.03017" title="Download PDF">pdf</a>, <a href="/format/2311.03017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COLA: COarse-LAbel multi-source LiDAR semantic segmentation for  autonomous driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanchez%2C+J">Jules Sanchez</a>, 
<a href="/search/cs?searchtype=author&query=Deschaud%2C+J">Jean-Emmanuel Deschaud</a>, 
<a href="/search/cs?searchtype=author&query=Goulette%2C+F">Fran&#xe7;ois Goulette</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">LiDAR semantic segmentation for autonomous driving has been a growing field
of interest in the past few years. Datasets and methods have appeared and
expanded very quickly, but methods have not been updated to exploit this new
availability of data and continue to rely on the same classical datasets.
<br />Different ways of performing LIDAR semantic segmentation training and
inference can be divided into several subfields, which include the following:
domain generalization, the ability to segment data coming from unseen domains ;
source-to-source segmentation, the ability to segment data coming from the
training domain; and pre-training, the ability to create re-usable geometric
primitives.
<br />In this work, we aim to improve results in all of these subfields with the
novel approach of multi-source training. Multi-source training relies on the
availability of various datasets at training time and uses them together rather
than relying on only one dataset.
<br />To overcome the common obstacles found for multi-source training, we
introduce the coarse labels and call the newly created multi-source dataset
COLA. We propose three applications of this new dataset that display systematic
improvement over single-source strategies: COLA-DG for domain generalization
(up to +10%), COLA-S2S for source-to-source segmentation (up to +5.3%), and
COLA-PT for pre-training (up to +12%).
</p>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03021" title="Abstract">arXiv:2311.03021</a> [<a href="/pdf/2311.03021" title="Download PDF">pdf</a>, <a href="/format/2311.03021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting agreement in multi-party dialogue: evaluating speaker  diarisation versus a procedural baseline to enhance user engagement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Addlesee%2C+A">Angus Addlesee</a>, 
<a href="/search/cs?searchtype=author&query=Denley%2C+D">Daniel Denley</a>, 
<a href="/search/cs?searchtype=author&query=Edmondson%2C+A">Andy Edmondson</a>, 
<a href="/search/cs?searchtype=author&query=Gunson%2C+N">Nancie Gunson</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+D+H">Daniel Hern&#xe1;ndez Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Kha%2C+A">Alexandre Kha</a>, 
<a href="/search/cs?searchtype=author&query=Lemon%2C+O">Oliver Lemon</a>, 
<a href="/search/cs?searchtype=author&query=Ndubuisi%2C+J">James Ndubuisi</a>, 
<a href="/search/cs?searchtype=author&query=O%27Reilly%2C+N">Neil O&#x27;Reilly</a>, 
<a href="/search/cs?searchtype=author&query=Perochaud%2C+L">Lia Perochaud</a>, 
<a href="/search/cs?searchtype=author&query=Valeri%2C+R">Rapha&#xeb;l Valeri</a>, 
<a href="/search/cs?searchtype=author&query=Worika%2C+M">Miebaka Worika</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the workshop on advancing GROup UNderstanding and robots aDaptive behaviour (GROUND), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Conversational agents participating in multi-party interactions face
significant challenges in dialogue state tracking, since the identity of the
speaker adds significant contextual meaning. It is common to utilise
diarisation models to identify the speaker. However, it is not clear if these
are accurate enough to correctly identify specific conversational events such
as agreement or disagreement during a real-time interaction. This study uses a
cooperative quiz, where the conversational agent acts as quiz-show host, to
determine whether diarisation or a frequency-and-proximity-based method is more
accurate at determining agreement, and whether this translates to feelings of
engagement from the players. Experimental results show that our procedural
system was more engaging to players, and was more accurate at detecting
agreement, reaching an average accuracy of 0.44 compared to 0.28 for the
diarised system.
</p>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03024" title="Abstract">arXiv:2311.03024</a> [<a href="/pdf/2311.03024" title="Download PDF">pdf</a>, <a href="/format/2311.03024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non Deterministic Pseudorandom Generator for Quantum Key Distribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+A">Arun Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Pandiri%2C+K+R">Kanaka Raju Pandiri</a>, 
<a href="/search/cs?searchtype=author&query=Pandit%2C+A+A">Anupama Arjun Pandit</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+L">Lucy Sharma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Quantum Key Distribution(QKD) thrives to achieve perfect secrecy of One time
Pad (OTP) through quantum processes. One of the crucial components of QKD are
Quantum Random Number Generators(QRNG) for generation of keys. Unfortunately,
these QRNG does not immediately produce usable bits rather it produces raw bits
with high entropy but low uniformity which can be hardly used by any
cryptographic system. A lot of pre-processing is required before the random
numbers generated by QRNG to be usable. This causes a bottle neck in random
number generation rate as well as QKD system relying on it. To avoid this
lacuna of post-processing methods employed as a central part of Quantum Random
Number Generators alternative approaches that satisfy the entropy(non
determinism) and quantum security is explored. Pseudorandom generators based on
quantum secure primitives could be an alternative to the post-processing
problem as PRNGs are way more faster than any random number generator employing
physical randomness (quantum mechanical process in QRNG) as well as it can
provide uniform bits required for cryptography application. In this work we
propose a pseudorandom generator based on post quantum primitives. The central
theme of this random number generator is designing PRNG with non deterministic
entropy generated through hard lattice problem - Learning with errors. We
leverage the non determinism by Gaussian errors of LWE to construct
non-deterministic PRNG satisfying the entropy requirement of QKD. Further, the
paper concludes by evaluating the PRNG through Die-Harder Test.
</p>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03026" title="Abstract">arXiv:2311.03026</a> [<a href="/pdf/2311.03026" title="Download PDF">pdf</a>, <a href="/format/2311.03026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Agreement in Multi-party Conversational AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schauer%2C+L">Laura Schauer</a>, 
<a href="/search/cs?searchtype=author&query=Sweeney%2C+J">Jason Sweeney</a>, 
<a href="/search/cs?searchtype=author&query=Lyttle%2C+C">Charlie Lyttle</a>, 
<a href="/search/cs?searchtype=author&query=Said%2C+Z">Zein Said</a>, 
<a href="/search/cs?searchtype=author&query=Szeles%2C+A">Aron Szeles</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+C">Cale Clark</a>, 
<a href="/search/cs?searchtype=author&query=McAskill%2C+K">Katie McAskill</a>, 
<a href="/search/cs?searchtype=author&query=Wickham%2C+X">Xander Wickham</a>, 
<a href="/search/cs?searchtype=author&query=Byars%2C+T">Tom Byars</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+D+H">Daniel Hern&#xe1;ndez Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Gunson%2C+N">Nancie Gunson</a>, 
<a href="/search/cs?searchtype=author&query=Addlesee%2C+A">Angus Addlesee</a>, 
<a href="/search/cs?searchtype=author&query=Lemon%2C+O">Oliver Lemon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the workshop on advancing GROup UNderstanding and robots aDaptive behaviour (GROUND), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Today, conversational systems are expected to handle conversations in
multi-party settings, especially within Socially Assistive Robots (SARs).
However, practical usability remains difficult as there are additional
challenges to overcome, such as speaker recognition, addressee recognition, and
complex turn-taking. In this paper, we present our work on a multi-party
conversational system, which invites two users to play a trivia quiz game. The
system detects users' agreement or disagreement on a final answer and responds
accordingly. Our evaluation includes both performance and user assessment
results, with a focus on detecting user agreement. Our annotated transcripts
and the code for the proposed system have been released open-source on GitHub.
</p>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03029" title="Abstract">arXiv:2311.03029</a> [<a href="/pdf/2311.03029" title="Download PDF">pdf</a>, <a href="/format/2311.03029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Obstacle- and Occlusion-Responsive Visual Tracking Control for Redundant  Manipulators using Reachability Measure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+M">Mincheul Kang</a>, 
<a href="/search/cs?searchtype=author&query=Ha%2C+J">Junhyoung Ha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">A vision system attached to a manipulator excels at tracing a moving target
object while effectively handling obstacles, overcoming limitations arising
from the camera's confined field of view and occluded line of sight. Meanwhile,
the manipulator may encounter certain challenges, including restricted motion
due to kinematic constraints and the risk of colliding with external obstacles.
These challenges are typically addressed by assigning multiple task objectives
to the manipulator. However, doing so can cause an increased risk of driving
the manipulator to its kinematic limits, leading to failures in object tracking
or obstacle avoidance. To address this issue, we propose a novel visual
tracking control method for a redundant manipulator that takes the kinematic
constraints into account via a reachability measure. Our method employs an
optimization-based controller that considers object tracking, occlusion
avoidance, collision avoidance, and the kinematic constraints represented by
the reachability measure. Subsequently, it determines a suitable joint
configuration through real-time inverse kinematics, accounting for dynamic
obstacle avoidance and the continuity of joint configurations. To validate our
approach, we conducted simulations and hardware experiments involving a moving
target and dynamic obstacles. The results of our evaluations highlight the
significance of incorporating the reachability measure.
</p>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03032" title="Abstract">arXiv:2311.03032</a> [<a href="/pdf/2311.03032" title="Download PDF">pdf</a>, <a href="/format/2311.03032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconfigurable, Transformable Soft Pneumatic Actuator with Tunable 3D  Deformations for Dexterous Soft Robotics Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wong%2C+D+C+Y">Dickson Chiu Yu Wong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingtan Li</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">Shijie Kang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Lifan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hongyu Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Soft Robotics Journal. 12 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Numerous soft actuators based on PneuNet design have already been proposed
and extensively employed across various soft robotics applications in recent
years. Despite their widespread use, a common limitation of most existing
designs is that their action is pre-determined during the fabrication process,
thereby restricting the ability to modify or alter their function during
operation. To address this shortcoming, in this article the design of a
Reconfigurable, Transformable Soft Pneumatic Actuator (RT-SPA) is proposed. The
working principle of the RT-SPA is analogous to the conventional PneuNet. The
key distinction between the two lies in the ability of the RT-SPA to undergo
controlled transformations, allowing for more versatile bending and twisting
motions in various directions. Furthermore, the unique reconfigurable design of
the RT-SPA enables the selection of actuation units with different sizes to
achieve a diverse range of three-dimensional deformations. This versatility
enhances the potential of the RT-SPA for adaptation to a multitude of tasks and
environments, setting it apart from traditional PneuNet. The paper begins with
a detailed description of the design and fabrication of the RT-SPA. Following
this, a series of experiments are conducted to evaluate the performance of the
RT-SPA. Finally, the abilities of the RT-SPA for locomotion, gripping, and
object manipulation are demonstrated to illustrate the versatility of the
RT-SPA across different aspects.
</p>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03033" title="Abstract">arXiv:2311.03033</a> [<a href="/pdf/2311.03033" title="Download PDF">pdf</a>, <a href="/ps/2311.03033" title="Download PostScript">ps</a>, <a href="/format/2311.03033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Words: A Mathematical Framework for Interpreting Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A1lez%2C+J">Javier Gonz&#xe1;lez</a>, 
<a href="/search/cs?searchtype=author&query=Nori%2C+A+V">Aditya V. Nori</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 figures, 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) are powerful AI tools that can generate and
comprehend natural language text and other complex information. However, the
field lacks a mathematical framework to systematically describe, compare and
improve LLMs. We propose Hex a framework that clarifies key terms and concepts
in LLM research, such as hallucinations, alignment, self-verification and
chain-of-thought reasoning. The Hex framework offers a precise and consistent
way to characterize LLMs, identify their strengths and weaknesses, and
integrate new findings. Using Hex, we differentiate chain-of-thought reasoning
from chain-of-thought prompting and establish the conditions under which they
are equivalent. This distinction clarifies the basic assumptions behind
chain-of-thought prompting and its implications for methods that use it, such
as self-verification and prompt programming.
<br />Our goal is to provide a formal framework for LLMs that can help both
researchers and practitioners explore new possibilities for generative AI. We
do not claim to have a definitive solution, but rather a tool for opening up
new research avenues. We argue that our formal definitions and results are
crucial for advancing the discussion on how to build generative AI systems that
are safe, reliable, fair and robust, especially in domains like healthcare and
software engineering.
</p>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03034" title="Abstract">arXiv:2311.03034</a> [<a href="/pdf/2311.03034" title="Download PDF">pdf</a>, <a href="/format/2311.03034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Byzantine Consensus in Abstract MAC Layer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tseng%2C+L">Lewis Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Sardina%2C+C">Callie Sardina</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of our OPODIS 2023 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">This paper studies the design of Byzantine consensus algorithms in an
\textit{asynchronous }single-hop network equipped with the "abstract MAC layer"
[DISC09], which captures core properties of modern wireless MAC protocols.
Newport [PODC14], Newport and Robinson [DISC18], and Tseng and Zhang [PODC22]
study crash-tolerant consensus in the model. In our setting, a Byzantine faulty
node may behave arbitrarily, but it cannot break the guarantees provided by the
underlying abstract MAC layer. To our knowledge, we are the first to study
Byzantine faults in this model.
<br />We harness the power of the abstract MAC layer to develop a Byzantine
approximate consensus algorithm and a Byzantine randomized binary consensus
algorithm. Both of our algorithms require \textit{only} the knowledge of the
upper bound on the number of faulty nodes $f$, and do \textit{not} require the
knowledge of the number of nodes $n$. This demonstrates the "power" of the
abstract MAC layer, as consensus algorithms in traditional message-passing
models require the knowledge of \textit{both} $n$ and $f$. Additionally, we
show that it is necessary to know $f$ in order to reach consensus. Hence, from
this perspective, our algorithms require the minimal knowledge.
<br />The lack of knowledge of $n$ brings the challenge of identifying a quorum
explicitly, which is a common technique in traditional message-passing
algorithms. A key technical novelty of our algorithms is to identify "implicit
quorums" which have the necessary information for reaching consensus. The
quorums are implicit because nodes do not know the identity of the quorums --
such notion is only used in the analysis.
</p>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03035" title="Abstract">arXiv:2311.03035</a> [<a href="/pdf/2311.03035" title="Download PDF">pdf</a>, <a href="/format/2311.03035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GTP-ViT: Efficient Vision Transformers via Graph-based Token Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xuwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yudong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yanping Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhewei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiajun Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Vision Transformers (ViTs) have revolutionized the field of computer vision,
yet their deployments on resource-constrained devices remain challenging due to
high computational demands. To expedite pre-trained ViTs, token pruning and
token merging approaches have been developed, which aim at reducing the number
of tokens involved in the computation. However, these methods still have some
limitations, such as image information loss from pruned tokens and inefficiency
in the token-matching process. In this paper, we introduce a novel Graph-based
Token Propagation (GTP) method to resolve the challenge of balancing model
efficiency and information preservation for efficient ViTs. Inspired by graph
summarization algorithms, GTP meticulously propagates less significant tokens'
information to spatially and semantically connected tokens that are of greater
importance. Consequently, the remaining few tokens serve as a summarization of
the entire token graph, allowing the method to reduce computational complexity
while preserving essential information of eliminated tokens. Combined with an
innovative token selection strategy, GTP can efficiently identify image tokens
to be propagated. Extensive experiments have validated GTP's effectiveness,
demonstrating both efficiency and performance improvements. Specifically, GTP
decreases the computational complexity of both DeiT-S and DeiT-B by up to 26%
with only a minimal 0.3% accuracy drop on ImageNet-1K without finetuning, and
remarkably surpasses the state-of-the-art token merging method on various
backbones at an even faster inference speed. The source code is available at
https://github.com/Ackesnal/GTP-ViT.
</p>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03036" title="Abstract">arXiv:2311.03036</a> [<a href="/pdf/2311.03036" title="Download PDF">pdf</a>, <a href="/format/2311.03036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On regularized polynomial functional regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Holzleitner%2C+M">Markus Holzleitner</a>, 
<a href="/search/math?searchtype=author&query=Pereverzyev%2C+S">Sergei Pereverzyev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
<p class="mathjax">This article offers a comprehensive treatment of polynomial functional
regression, culminating in the establishment of a novel finite sample bound.
This bound encompasses various aspects, including general smoothness
conditions, capacity conditions, and regularization techniques. In doing so, it
extends and generalizes several findings from the context of linear functional
regression as well. We also provide numerical evidence that using higher order
polynomial terms can lead to an improved performance.
</p>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03037" title="Abstract">arXiv:2311.03037</a> [<a href="/pdf/2311.03037" title="Download PDF">pdf</a>, <a href="/format/2311.03037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Validity problems in clinical machine learning by indirect data labeling  using consensus definitions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hagmann%2C+M">Michael Hagmann</a>, 
<a href="/search/cs?searchtype=author&query=Schamoni%2C+S">Shigehiko Schamoni</a>, 
<a href="/search/cs?searchtype=author&query=Riezler%2C+S">Stefan Riezler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023, December 10th, 2023, New Orleans, United States, 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM); Applications (stat.AP); Machine Learning (stat.ML)

</div>
<p class="mathjax">We demonstrate a validity problem of machine learning in the vital
application area of disease diagnosis in medicine. It arises when target labels
in training data are determined by an indirect measurement, and the fundamental
measurements needed to determine this indirect measurement are included in the
input data representation. Machine learning models trained on this data will
learn nothing else but to exactly reconstruct the known target definition. Such
models show perfect performance on similarly constructed test data but will
fail catastrophically on real-world examples where the defining fundamental
measurements are not or only incompletely available. We present a general
procedure allowing identification of problematic datasets and black-box machine
learning models trained on them, and exemplify our detection procedure on the
task of early prediction of sepsis.
</p>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03040" title="Abstract">arXiv:2311.03040</a> [<a href="/pdf/2311.03040" title="Download PDF">pdf</a>, <a href="/format/2311.03040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grouping Local Process Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peeva%2C+V">Viki Peeva</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Aalst%2C+W+M+P">Wil M.P. van der Aalst</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In recent years, process mining emerged as a proven technology to analyze and
improve operational processes. An expanding range of organizations using
process mining in their daily operation brings a broader spectrum of processes
to be analyzed. Some of these processes are highly unstructured, making it
difficult for traditional process discovery approaches to discover a
start-to-end model describing the entire process. Therefore, the subdiscipline
of Local Process Model (LPM) discovery tries to build a set of LPMs, i.e.,
smaller models that explain sub-behaviors of the process. However, like other
pattern mining approaches, LPM discovery algorithms also face the problems of
model explosion and model repetition, i.e., the algorithms may create hundreds
if not thousands of models, and subsets of them are close in structure or
behavior. This work proposes a three-step pipeline for grouping similar LPMs
using various process model similarity measures. We demonstrate the usefulness
of grouping through a real-life case study, and analyze the impact of different
measures, the gravity of repetition in the discovered LPMs, and how it improves
after grouping on multiple real event logs.
</p>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03046" title="Abstract">arXiv:2311.03046</a> [<a href="/pdf/2311.03046" title="Download PDF">pdf</a>, <a href="/format/2311.03046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Antenna Positioning and Beamforming Design for Movable-Antenna Enabled  Multi-user Downlink Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Haoran Qin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhendong Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingqing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+N">Nan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fangjiong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper investigates a multiple input single output (MISO) downlink
communication system in which users are equipped with movable antennas (MAs).
First, We adopt a field-response based channel model to characterize the
downlink channel with respect to MAs' positions. Then, we aim to minimize the
total transmit power by jointly optimizing the MAs' positions and beamforming
matrix. To solve the resulting non-convex problem, we employ an alternating
optimization (AO) algorithm based on penalty method and successive convex
approximation (SCA) to obtain a sub-optimal solution. Numerical results
demonstrate that the MA-enabled communication system perform better than
conventional fixed position antennas.
</p>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03052" title="Abstract">arXiv:2311.03052</a> [<a href="/pdf/2311.03052" title="Download PDF">pdf</a>, <a href="/format/2311.03052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MixUp-MIL: A Study on Linear &amp; Multilinear Interpolation-Based Data  Augmentation for Whole Slide Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gadermayr%2C+M">Michael Gadermayr</a>, 
<a href="/search/cs?searchtype=author&query=Koller%2C+L">Lukas Koller</a>, 
<a href="/search/cs?searchtype=author&query=Tschuchnig%2C+M">Maximilian Tschuchnig</a>, 
<a href="/search/cs?searchtype=author&query=Stangassinger%2C+L+M">Lea Maria Stangassinger</a>, 
<a href="/search/cs?searchtype=author&query=Kreutzer%2C+C">Christina Kreutzer</a>, 
<a href="/search/cs?searchtype=author&query=Couillard-Despres%2C+S">Sebastien Couillard-Despres</a>, 
<a href="/search/cs?searchtype=author&query=Oostingh%2C+G+J">Gertie Janneke Oostingh</a>, 
<a href="/search/cs?searchtype=author&query=Hittmair%2C+A">Anton Hittmair</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> for code and data, see gitlab repo: <a href="https://gitlab.com/mgadermayr/mixupmil.">this https URL</a> arXiv admin note: substantial text overlap with <a href="/abs/2211.05862">arXiv:2211.05862</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">For classifying digital whole slide images in the absence of pixel level
annotation, typically multiple instance learning methods are applied. Due to
the generic applicability, such methods are currently of very high interest in
the research community, however, the issue of data augmentation in this context
is rarely explored. Here we investigate linear and multilinear interpolation
between feature vectors, a data augmentation technique, which proved to be
capable of improving the generalization performance classification networks and
also for multiple instance learning. Experiments, however, have been performed
on only two rather small data sets and one specific feature extraction approach
so far and a strong dependence on the data set has been identified. Here we
conduct a large study incorporating 10 different data set configurations, two
different feature extraction approaches (supervised and self-supervised), stain
normalization and two multiple instance learning architectures. The results
showed an extraordinarily high variability in the effect of the method. We
identified several interesting aspects to bring light into the darkness and
identified novel promising fields of research.
</p>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03053" title="Abstract">arXiv:2311.03053</a> [<a href="/pdf/2311.03053" title="Download PDF">pdf</a>, <a href="/format/2311.03053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masking Hyperspectral Imaging Data with Pretrained Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arbash%2C+E">Elias Arbash</a>, 
<a href="/search/cs?searchtype=author&query=de+Lima+Ribeiro%2C+A">Andr&#xe9;a de Lima Ribeiro</a>, 
<a href="/search/cs?searchtype=author&query=Thiele%2C+S">Sam Thiele</a>, 
<a href="/search/cs?searchtype=author&query=Gnann%2C+N">Nina Gnann</a>, 
<a href="/search/cs?searchtype=author&query=Rasti%2C+B">Behnood Rasti</a>, 
<a href="/search/cs?searchtype=author&query=Fuchs%2C+M">Margret Fuchs</a>, 
<a href="/search/cs?searchtype=author&query=Ghamisi%2C+P">Pedram Ghamisi</a>, 
<a href="/search/cs?searchtype=author&query=Gloaguen%2C+R">Richard Gloaguen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The presence of undesired background areas associated with potential noise
and unknown spectral characteristics degrades the performance of hyperspectral
data processing. Masking out unwanted regions is key to addressing this issue.
Processing only regions of interest yields notable improvements in terms of
computational costs, required memory, and overall performance. The proposed
processing pipeline encompasses two fundamental parts: regions of interest mask
generation, followed by the application of hyperspectral data processing
techniques solely on the newly masked hyperspectral cube. The novelty of our
work lies in the methodology adopted for the preliminary image segmentation. We
employ the Segment Anything Model (SAM) to extract all objects within the
dataset, and subsequently refine the segments with a zero-shot Grounding Dino
object detector, followed by intersection and exclusion filtering steps,
without the need for fine-tuning or retraining. To illustrate the efficacy of
the masking procedure, the proposed method is deployed on three challenging
applications scenarios that demand accurate masking; shredded plastics
characterization, drill core scanning, and litter monitoring. The numerical
evaluation of the proposed masking method on the three applications is provided
along with the used hyperparameters. The scripts for the method will be
available at https://github.com/hifexplo/Masking.
</p>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03054" title="Abstract">arXiv:2311.03054</a> [<a href="/pdf/2311.03054" title="Download PDF">pdf</a>, <a href="/format/2311.03054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnyText: Multilingual Visual Text Generation And Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tuo%2C+Y">Yuxiang Tuo</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+W">Wangmeng Xiang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jun-Yan He</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+Y">Yifeng Geng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuansong Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion model based Text-to-Image has achieved impressive achievements
recently. Although current technology for synthesizing images is highly
advanced and capable of generating images with high fidelity, it is still
possible to give the show away when focusing on the text area in the generated
image. To address this issue, we introduce AnyText, a diffusion-based
multilingual visual text generation and editing model, that focuses on
rendering accurate and coherent text in the image. AnyText comprises a
diffusion pipeline with two primary elements: an auxiliary latent module and a
text embedding module. The former uses inputs like text glyph, position, and
masked image to generate latent features for text generation or editing. The
latter employs an OCR model for encoding stroke data as embeddings, which blend
with image caption embeddings from the tokenizer to generate texts that
seamlessly integrate with the background. We employed text-control diffusion
loss and text perceptual loss for training to further enhance writing accuracy.
AnyText can write characters in multiple languages, to the best of our
knowledge, this is the first work to address multilingual visual text
generation. It is worth mentioning that AnyText can be plugged into existing
diffusion models from the community for rendering or editing text accurately.
After conducting extensive evaluation experiments, our method has outperformed
all other approaches by a significant margin. Additionally, we contribute the
first large-scale multilingual text images dataset, AnyWord-3M, containing 3
million image-text pairs with OCR annotations in multiple languages. Based on
AnyWord-3M dataset, we propose AnyText-benchmark for the evaluation of visual
text generation accuracy and quality. Our project will be open-sourced on
https://github.com/tyxsspa/AnyText to improve and promote the development of
text generation technology.
</p>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03055" title="Abstract">arXiv:2311.03055</a> [<a href="/pdf/2311.03055" title="Download PDF">pdf</a>, <a href="/format/2311.03055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DRAUC: An Instance-wise Distributionally Robust AUC Optimization  Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+S">Siran Dai</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qianqian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhiyong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xiaochun Cao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qingming Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The Area Under the ROC Curve (AUC) is a widely employed metric in long-tailed
classification scenarios. Nevertheless, most existing methods primarily assume
that training and testing examples are drawn i.i.d. from the same distribution,
which is often unachievable in practice. Distributionally Robust Optimization
(DRO) enhances model performance by optimizing it for the local worst-case
scenario, but directly integrating AUC optimization with DRO results in an
intractable optimization problem. To tackle this challenge, methodically we
propose an instance-wise surrogate loss of Distributionally Robust AUC (DRAUC)
and build our optimization framework on top of it. Moreover, we highlight that
conventional DRAUC may induce label bias, hence introducing distribution-aware
DRAUC as a more suitable metric for robust AUC learning. Theoretically, we
affirm that the generalization gap between the training loss and testing error
diminishes if the training set is sufficiently large. Empirically, experiments
on corrupted benchmark datasets demonstrate the effectiveness of our proposed
method. Code is available at: https://github.com/EldercatSAM/DRAUC.
</p>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03057" title="Abstract">arXiv:2311.03057</a> [<a href="/pdf/2311.03057" title="Download PDF">pdf</a>, <a href="/format/2311.03057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GLEN: Generative Retrieval via Lexical Index Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sunkyung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+M">Minjin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jongwuk Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP 2023) main conference. 12 pages, 2 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Generative retrieval shed light on a new paradigm of document retrieval,
aiming to directly generate the identifier of a relevant document for a query.
While it takes advantage of bypassing the construction of auxiliary index
structures, existing studies face two significant challenges: (i) the
discrepancy between the knowledge of pre-trained language models and
identifiers and (ii) the gap between training and inference that poses
difficulty in learning to rank. To overcome these challenges, we propose a
novel generative retrieval method, namely Generative retrieval via LExical
iNdex learning (GLEN). For training, GLEN effectively exploits a dynamic
lexical identifier using a two-phase index learning strategy, enabling it to
learn meaningful lexical identifiers and relevance signals between queries and
documents. For inference, GLEN utilizes collision-free inference, using
identifier weights to rank documents without additional overhead. Experimental
results prove that GLEN achieves state-of-the-art or competitive performance
against existing generative retrieval methods on various benchmark datasets,
e.g., NQ320k, MS MARCO, and BEIR. The code is available at
https://github.com/skleee/GLEN.
</p>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03058" title="Abstract">arXiv:2311.03058</a> [<a href="/pdf/2311.03058" title="Download PDF">pdf</a>, <a href="/format/2311.03058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-shot Bilingual App Reviews Mining with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jialiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Courbis%2C+A">Anne-Lise Courbis</a>, 
<a href="/search/cs?searchtype=author&query=Lambolais%2C+T">Thomas Lambolais</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Binbin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Bernard%2C+P+L">Pierre Louis Bernard</a>, 
<a href="/search/cs?searchtype=author&query=Dray%2C+G">G&#xe9;rard Dray</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for The 35th IEEE International Conference on Tools with Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">App reviews from app stores are crucial for improving software requirements.
A large number of valuable reviews are continually being posted, describing
software problems and expected features. Effectively utilizing user reviews
necessitates the extraction of relevant information, as well as their
subsequent summarization. Due to the substantial volume of user reviews, manual
analysis is arduous. Various approaches based on natural language processing
(NLP) have been proposed for automatic user review mining. However, the
majority of them requires a manually crafted dataset to train their models,
which limits their usage in real-world scenarios. In this work, we propose
Mini-BAR, a tool that integrates large language models (LLMs) to perform
zero-shot mining of user reviews in both English and French. Specifically,
Mini-BAR is designed to (i) classify the user reviews, (ii) cluster similar
reviews together, (iii) generate an abstractive summary for each cluster and
(iv) rank the user review clusters. To evaluate the performance of Mini-BAR, we
created a dataset containing 6,000 English and 6,000 French annotated user
reviews and conducted extensive experiments. Preliminary results demonstrate
the effectiveness and efficiency of Mini-BAR in requirement engineering by
analyzing bilingual app reviews. (Replication package containing the code,
dataset, and experiment setups on https://github.com/Jl-wei/mini-bar )
</p>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03059" title="Abstract">arXiv:2311.03059</a> [<a href="/pdf/2311.03059" title="Download PDF">pdf</a>, <a href="/ps/2311.03059" title="Download PostScript">ps</a>, <a href="/format/2311.03059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximal Consistent Subsystems of Max-T Fuzzy Relational Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baaj%2C+I">Isma&#xef;l Baaj</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">In this article, we study the inconsistency of a system of $\max-T$ fuzzy
relational equations of the form $A \Box_{T}^{\max} x = b$, where $T$ is a
t-norm among $\min$, the product or Lukasiewicz's t-norm. For an inconsistent
$\max-T$ system, we directly construct a canonical maximal consistent subsystem
(w.r.t the inclusion order). The main tool used to obtain it is the analytical
formula which compute the Chebyshev distance $\Delta = \inf_{c \in \mathcal{C}}
\Vert b - c \Vert$ associated to the inconsistent $\max-T$ system, where
$\mathcal{C}$ is the set of second members of consistent systems defined with
the same matrix $A$. Based on the same analytical formula, we give, for an
inconsistent $\max-\min$ system, an efficient method to obtain all its
consistent subsystems, and we show how to iteratively get all its maximal
consistent subsystems.
</p>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03061" title="Abstract">arXiv:2311.03061</a> [<a href="/pdf/2311.03061" title="Download PDF">pdf</a>, <a href="/format/2311.03061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learned layered coding for Successive Refinement in the Wyner-Ziv  Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joukovsky%2C+B">Boris Joukovsky</a>, 
<a href="/search/cs?searchtype=author&query=De+Weerdt%2C+B">Brent De Weerdt</a>, 
<a href="/search/cs?searchtype=author&query=Deligiannis%2C+N">Nikos Deligiannis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">We propose a data-driven approach to explicitly learn the progressive
encoding of a continuous source, which is successively decoded with increasing
levels of quality and with the aid of correlated side information. This setup
refers to the successive refinement of the Wyner-Ziv coding problem. Assuming
ideal Slepian-Wolf coding, our approach employs recurrent neural networks
(RNNs) to learn layered encoders and decoders for the quadratic Gaussian case.
The models are trained by minimizing a variational bound on the rate-distortion
function of the successively refined Wyner-Ziv coding problem. We demonstrate
that RNNs can explicitly retrieve layered binning solutions akin to scalable
nested quantization. Moreover, the rate-distortion performance of the scheme is
on par with the corresponding monolithic Wyner-Ziv coding approach and is close
to the rate-distortion bound.
</p>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03063" title="Abstract">arXiv:2311.03063</a> [<a href="/pdf/2311.03063" title="Download PDF">pdf</a>, <a href="/format/2311.03063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Step Optimal Tracking Control of Unknown Nonzero-Sum Games based  on Least Squares and Linear Programming: An Application to a Fully-Automated,  Dual-Hormone Artificial Pancreas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tanzanakis%2C+A">Alexandros Tanzanakis</a>, 
<a href="/search/eess?searchtype=author&query=Lygeros%2C+J">John Lygeros</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">We consider the problem of optimal tracking control of unknown discrete-time
nonlinear nonzero-sum games. The related state-of-art literature is mostly
focused on Policy Iteration algorithms and multiple neural network
approximation, which may lead to practical implementation challenges and high
computational burden. To overcome these problems, we propose a novel
Q-function-based multi-step Value Iteration algorithm, which provides the
potential to accelerate convergence speed and improve the quality of solutions,
with an easy-to-realize initialization condition. A critic-only least squares
implementation approach is then employed, which alleviates the computational
complexity of commonly used multiple neural network-based methods. Afterwards,
by introducing the coupled Bellman operator, a novel linear programming
approach is derived, based on which Nash equilibria can be approximately
computed by solving a set of tractable finite-dimensional optimization
problems. We evaluate the tracking control capabilities of the proposed
algorithms to the problem of fully-automated dual-hormone (i.e., insulin and
glucagon) glucose control in Type 1 Diabetes Mellitus. The U.S. FDA-accepted
DMMS.R simulator from the Epsilon Group is used to conduct extensive in-silico
clinical studies on virtual patients under a variety of completely unannounced
meal and exercise scenarios. Simulation results demonstrate the high
reliability and exceptional performance of the proposed multi-step algorithmic
framework to critical complex systems.
</p>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03067" title="Abstract">arXiv:2311.03067</a> [<a href="/pdf/2311.03067" title="Download PDF">pdf</a>, <a href="/format/2311.03067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forest aboveground biomass estimation using GEDI and earth observation  data through attention-based deep learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+W">Wenquan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Mitchard%2C+E+T+A">Edward T.A. Mitchard</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Hancock%2C+S">Steven Hancock</a>, 
<a href="/search/cs?searchtype=author&query=Ryan%2C+C+M">Casey M. Ryan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Accurate quantification of forest aboveground biomass (AGB) is critical for
understanding carbon accounting in the context of climate change. In this
study, we presented a novel attention-based deep learning approach for forest
AGB estimation, primarily utilizing openly accessible EO data, including: GEDI
LiDAR data, C-band Sentinel-1 SAR data, ALOS-2 PALSAR-2 data, and Sentinel-2
multispectral data. The attention UNet (AU) model achieved markedly higher
accuracy for biomass estimation compared to the conventional RF algorithm.
Specifically, the AU model attained an R2 of 0.66, RMSE of 43.66 Mg ha-1, and
bias of 0.14 Mg ha-1, while RF resulted in lower scores of R2 0.62, RMSE 45.87
Mg ha-1, and bias 1.09 Mg ha-1. However, the superiority of the deep learning
approach was not uniformly observed across all tested models. ResNet101 only
achieved an R2 of 0.50, an RMSE of 52.93 Mg ha-1, and a bias of 0.99 Mg ha-1,
while the UNet reported an R2 of 0.65, an RMSE of 44.28 Mg ha-1, and a
substantial bias of 1.84 Mg ha-1. Moreover, to explore the performance of AU in
the absence of spatial information, fully connected (FC) layers were employed
to eliminate spatial information from the remote sensing data. AU-FC achieved
intermediate R2 of 0.64, RMSE of 44.92 Mgha-1, and bias of -0.56 Mg ha-1,
outperforming RF but underperforming AU model using spatial information. We
also generated 10m forest AGB maps across Guangdong for the year 2019 using AU
and compared it with that produced by RF. The AGB distributions from both
models showed strong agreement with similar mean values; the mean forest AGB
estimated by AU was 102.18 Mg ha-1 while that of RF was 104.84 Mg ha-1.
Additionally, it was observed that the AGB map generated by AU provided
superior spatial information. Overall, this research substantiates the
feasibility of employing deep learning for biomass estimation based on
satellite data.
</p>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03071" title="Abstract">arXiv:2311.03071</a> [<a href="/pdf/2311.03071" title="Download PDF">pdf</a>, <a href="/format/2311.03071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OrthoNets: Orthogonal Channel Attention Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salman%2C+H">Hadi Salman</a>, 
<a href="/search/cs?searchtype=author&query=Parks%2C+C">Caleb Parks</a>, 
<a href="/search/cs?searchtype=author&query=Swan%2C+M">Matthew Swan</a>, 
<a href="/search/cs?searchtype=author&query=Gauch%2C+J">John Gauch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE BigData 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE BigData 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Designing an effective channel attention mechanism implores one to find a
lossy-compression method allowing for optimal feature representation. Despite
recent progress in the area, it remains an open problem. FcaNet, the current
state-of-the-art channel attention mechanism, attempted to find such an
information-rich compression using Discrete Cosine Transforms (DCTs). One
drawback of FcaNet is that there is no natural choice of the DCT frequencies.
To circumvent this issue, FcaNet experimented on ImageNet to find optimal
frequencies. We hypothesize that the choice of frequency plays only a
supporting role and the primary driving force for the effectiveness of their
attention filters is the orthogonality of the DCT kernels. To test this
hypothesis, we construct an attention mechanism using randomly initialized
orthogonal filters. Integrating this mechanism into ResNet, we create OrthoNet.
We compare OrthoNet to FcaNet (and other attention mechanisms) on Birds,
MS-COCO, and Places356 and show superior performance. On the ImageNet dataset,
our method competes with or surpasses the current state-of-the-art. Our results
imply that an optimal choice of filter is elusive and generalization can be
achieved with a sufficiently large number of orthogonal filters. We further
investigate other general principles for implementing channel attention, such
as its position in the network and channel groupings.
</p>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03075" title="Abstract">arXiv:2311.03075</a> [<a href="/pdf/2311.03075" title="Download PDF">pdf</a>, <a href="/format/2311.03075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoK: Memorisation in machine learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Usynin%2C+D">Dmitrii Usynin</a>, 
<a href="/search/cs?searchtype=author&query=Knolle%2C+M">Moritz Knolle</a>, 
<a href="/search/cs?searchtype=author&query=Kaissis%2C+G">Georgios Kaissis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Information Theory (cs.IT)

</div>
<p class="mathjax">Quantifying the impact of individual data samples on machine learning models
is an open research problem. This is particularly relevant when complex and
high-dimensional relationships have to be learned from a limited sample of the
data generating distribution, such as in deep learning. It was previously shown
that, in these cases, models rely not only on extracting patterns which are
helpful for generalisation, but also seem to be required to incorporate some of
the training data more or less as is, in a process often termed memorisation.
This raises the question: if some memorisation is a requirement for effective
learning, what are its privacy implications? In this work we unify a broad
range of previous definitions and perspectives on memorisation in ML, discuss
their interplay with model generalisation and their implications of these
phenomena on data privacy. Moreover, we systematise methods allowing
practitioners to detect the occurrence of memorisation or quantify it and
contextualise our findings in a broad range of ML learning settings. Finally,
we discuss memorisation in the context of privacy attacks, differential privacy
(DP) and adversarial actors.
</p>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03076" title="Abstract">arXiv:2311.03076</a> [<a href="/pdf/2311.03076" title="Download PDF">pdf</a>, <a href="/format/2311.03076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SugarViT -- Multi-objective Regression of UAV Images with Vision  Transformers and Deep Label Distribution Learning Demonstrated on Disease  Severity Prediction in Sugar Beet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%C3%BCnder%2C+M">Maurice G&#xfc;nder</a>, 
<a href="/search/cs?searchtype=author&query=Yamati%2C+F+R+I">Facundo Ram&#xf3;n Ispizua Yamati</a>, 
<a href="/search/cs?searchtype=author&query=Alc%C3%A1ntara%2C+A+A+B">Abel Andree Barreta Alc&#xe1;ntara</a>, 
<a href="/search/cs?searchtype=author&query=Mahlein%2C+A">Anne-Katrin Mahlein</a>, 
<a href="/search/cs?searchtype=author&query=Sifa%2C+R">Rafet Sifa</a>, 
<a href="/search/cs?searchtype=author&query=Bauckhage%2C+C">Christian Bauckhage</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to Computers and Electronics in Agriculture
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Remote sensing and artificial intelligence are pivotal technologies of
precision agriculture nowadays. The efficient retrieval of large-scale field
imagery combined with machine learning techniques shows success in various
tasks like phenotyping, weeding, cropping, and disease control. This work will
introduce a machine learning framework for automatized large-scale
plant-specific trait annotation for the use case disease severity scoring for
Cercospora Leaf Spot (CLS) in sugar beet. With concepts of Deep Label
Distribution Learning (DLDL), special loss functions, and a tailored model
architecture, we develop an efficient Vision Transformer based model for
disease severity scoring called SugarViT. One novelty in this work is the
combination of remote sensing data with environmental parameters of the
experimental sites for disease severity prediction. Although the model is
evaluated on this special use case, it is held as generic as possible to also
be applicable to various image-based classification and regression tasks. With
our framework, it is even possible to learn models on multi-objective problems
as we show by a pretraining on environmental metadata.
</p>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03078" title="Abstract">arXiv:2311.03078</a> [<a href="/pdf/2311.03078" title="Download PDF">pdf</a>, <a href="/ps/2311.03078" title="Download PostScript">ps</a>, <a href="/format/2311.03078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BanLemma: A Word Formation Dependent Rule and Dictionary Based Bangla  Lemmatizer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Afrin%2C+S">Sadia Afrin</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+M+S+M">Md. Shahad Mahmud Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+E">Md. Ekramul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+F+A">Faisal Ahamed Khan</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+L+I">Labib Imam Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Mahtab%2C+M+M">MD. Motahar Mahtab</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+N+N">Nazifa Nuha Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Forkan%2C+M">Massud Forkan</a>, 
<a href="/search/cs?searchtype=author&query=Kundu%2C+N">Neelima Kundu</a>, 
<a href="/search/cs?searchtype=author&query=Arif%2C+H">Hakim Arif</a>, 
<a href="/search/cs?searchtype=author&query=Rashid%2C+M+M+O">Mohammad Mamun Or Rashid</a>, 
<a href="/search/cs?searchtype=author&query=Amin%2C+M+R">Mohammad Ruhul Amin</a>, 
<a href="/search/cs?searchtype=author&query=Mohammed%2C+N">Nabeel Mohammed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Lemmatization holds significance in both natural language processing (NLP)
and linguistics, as it effectively decreases data density and aids in
comprehending contextual meaning. However, due to the highly inflected nature
and morphological richness, lemmatization in Bangla text poses a complex
challenge. In this study, we propose linguistic rules for lemmatization and
utilize a dictionary along with the rules to design a lemmatizer specifically
for Bangla. Our system aims to lemmatize words based on their parts of speech
class within a given sentence. Unlike previous rule-based approaches, we
analyzed the suffix marker occurrence according to the morpho-syntactic values
and then utilized sequences of suffix markers instead of entire suffixes. To
develop our rules, we analyze a large corpus of Bangla text from various
domains, sources, and time periods to observe the word formation of inflected
words. The lemmatizer achieves an accuracy of 96.36% when tested against a
manually annotated test dataset by trained linguists and demonstrates
competitive performance on three previously published Bangla lemmatization
datasets. We are making the code and datasets publicly available at
https://github.com/eblict-gigatech/BanLemma in order to contribute to the
further advancement of Bangla NLP.
</p>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03079" title="Abstract">arXiv:2311.03079</a> [<a href="/pdf/2311.03079" title="Download PDF">pdf</a>, <a href="/format/2311.03079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CogVLM: Visual Expert for Pretrained Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weihan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Q">Qingsong Lv</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenmeng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+W">Wenyi Hong</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Ji Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Junhui Ji</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhuoyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xixuan Song</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiazheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juanzi Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuxiao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Ming Ding</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jie Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce CogVLM, a powerful open-source visual language foundation model.
Different from the popular shallow alignment method which maps image features
into the input space of language model, CogVLM bridges the gap between the
frozen pretrained language model and image encoder by a trainable visual expert
module in the attention and FFN layers. As a result, CogVLM enables deep fusion
of vision language features without sacrificing any performance on NLP tasks.
CogVLM-17B achieves state-of-the-art performance on 10 classic cross-modal
benchmarks, including NoCaps, Flicker30k captioning, RefCOCO, RefCOCO+,
RefCOCOg, Visual7W, GQA, ScienceQA, VizWiz VQA and TDIUC, and ranks the 2nd on
VQAv2, OKVQA, TextVQA, COCO captioning, etc., surpassing or matching PaLI-X
55B. Codes and checkpoints are available at https://github.com/THUDM/CogVLM.
</p>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03080" title="Abstract">arXiv:2311.03080</a> [<a href="/pdf/2311.03080" title="Download PDF">pdf</a>, <a href="/format/2311.03080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Isogeometric collocation for solving the biharmonic equation over planar  multi-patch domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kapl%2C+M">Mario Kapl</a>, 
<a href="/search/math?searchtype=author&query=Kosma%C4%8D%2C+A">Alja&#x17e; Kosma&#x10d;</a>, 
<a href="/search/math?searchtype=author&query=Vitrih%2C+V">Vito Vitrih</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present an isogeometric collocation method for solving the biharmonic
equation over planar bilinearly parameterized multi-patch domains. The
developed approach is based on the use of the globally $C^4$-smooth
isogeometric spline space [25] to approximate the solution of the considered
partial differential equation, and proposes as collocation points two different
choices, namely on the one hand the Greville points and on the other hand the
so-called superconvergent points. Several examples demonstrate the potential of
our collocation method for solving the biharmonic equation over planar
multi-patch domains, and numerically study the convergence behavior of the two
types of collocation points with respect to the $L^2$-norm as well as to
equivalents of the $H^s$-seminorms for $1 \leq s \leq 4$.
</p>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03082" title="Abstract">arXiv:2311.03082</a> [<a href="/pdf/2311.03082" title="Download PDF">pdf</a>, <a href="/format/2311.03082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A survey and classification of face alignment methods based on face  models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meher%2C+J">Jagmohan Meher</a>, 
<a href="/search/cs?searchtype=author&query=Allende-Cid%2C+H">Hector Allende-Cid</a>, 
<a href="/search/cs?searchtype=author&query=Nordling%2C+T+E+M">Torbj&#xf6;rn E. M. Nordling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 5 figures, survey paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">A face model is a mathematical representation of the distinct features of a
human face. Traditionally, face models were built using a set of fiducial
points or landmarks, each point ideally located on a facial feature, i.e.,
corner of the eye, tip of the nose, etc. Face alignment is the process of
fitting the landmarks in a face model to the respective ground truth positions
in an input image containing a face. Despite significant research on face
alignment in the past decades, no review analyses various face models used in
the literature. Catering to three types of readers - beginners, practitioners
and researchers in face alignment, we provide a comprehensive analysis of
different face models used for face alignment. We include the interpretation
and training of the face models along with the examples of fitting the face
model to a new face image. We found that 3D-based face models are preferred in
cases of extreme face pose, whereas deep learning-based methods often use
heatmaps. Moreover, we discuss the possible future directions of face models in
the field of face alignment.
</p>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03083" title="Abstract">arXiv:2311.03083</a> [<a href="/pdf/2311.03083" title="Download PDF">pdf</a>, <a href="/format/2311.03083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying the value of information transfer in population-based SHM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hughes%2C+A+J">Aidan J. Hughes</a>, 
<a href="/search/cs?searchtype=author&query=Poole%2C+J">Jack Poole</a>, 
<a href="/search/cs?searchtype=author&query=Dervilis%2C+N">Nikolaos Dervilis</a>, 
<a href="/search/cs?searchtype=author&query=Gardner%2C+P">Paul Gardner</a>, 
<a href="/search/cs?searchtype=author&query=Worden%2C+K">Keith Worden</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the 42nd IMAC: A Conference and Exposition on Structural Dynamics (IMAC-XLII), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP)

</div>
<p class="mathjax">Population-based structural health monitoring (PBSHM), seeks to address some
of the limitations associated with data scarcity that arise in traditional SHM.
A tenet of the population-based approach to SHM is that information can be
shared between sufficiently-similar structures in order to improve predictive
models. Transfer learning techniques, such as domain adaptation, have been
shown to be a highly-useful technology for sharing information between
structures when developing statistical classifiers for PBSHM. Nonetheless,
transfer-learning techniques are not without their pitfalls. In some
circumstances, for example if the data distributions associated with the
structures within a population are dissimilar, applying transfer-learning
methods can be detrimental to classification performance -- this phenomenon is
known as negative transfer. Given the potentially-severe consequences of
negative transfer, it is prudent for engineers to ask the question `when, what,
and how should one transfer between structures?'.
<br />The current paper aims to demonstrate a transfer-strategy decision process
for a classification task for a population of simulated structures in the
context of a representative SHM maintenance problem, supported by domain
adaptation. The transfer decision framework is based upon the concept of
expected value of information transfer. In order to compute the expected value
of information transfer, predictions must be made regarding the classification
(and decision performance) in the target domain following information transfer.
In order to forecast the outcome of transfers, a probabilistic regression is
used here to predict classification performance from a proxy for structural
similarity based on the modal assurance criterion.
</p>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03084" title="Abstract">arXiv:2311.03084</a> [<a href="/pdf/2311.03084" title="Download PDF">pdf</a>, <a href="/format/2311.03084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple yet Efficient Ensemble Approach for AI-generated Text Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abburi%2C+H">Harika Abburi</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+K">Kalyani Roy</a>, 
<a href="/search/cs?searchtype=author&query=Suesserman%2C+M">Michael Suesserman</a>, 
<a href="/search/cs?searchtype=author&query=Pudota%2C+N">Nirmala Pudota</a>, 
<a href="/search/cs?searchtype=author&query=Veeramani%2C+B">Balaji Veeramani</a>, 
<a href="/search/cs?searchtype=author&query=Bowen%2C+E">Edward Bowen</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+S">Sanmitra Bhattacharya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent Large Language Models (LLMs) have demonstrated remarkable capabilities
in generating text that closely resembles human writing across wide range of
styles and genres. However, such capabilities are prone to potential abuse,
such as fake news generation, spam email creation, and misuse in academic
assignments. Hence, it is essential to build automated approaches capable of
distinguishing between artificially generated text and human-authored text. In
this paper, we propose a simple yet efficient solution to this problem by
ensembling predictions from multiple constituent LLMs. Compared to previous
state-of-the-art approaches, which are perplexity-based or uses ensembles with
a number of LLMs, our condensed ensembling approach uses only two constituent
LLMs to achieve comparable performance. Experiments conducted on four benchmark
datasets for generative text classification show performance improvements in
the range of 0.5 to 100\% compared to previous state-of-the-art approaches. We
also study the influence the training data from individual LLMs have on model
performance. We found that substituting commercially-restrictive Generative
Pre-trained Transformer (GPT) data with data generated from other open language
models such as Falcon, Large Language Model Meta AI (LLaMA2), and Mosaic
Pretrained Transformers (MPT) is a feasible alternative when developing
generative text detectors. Furthermore, to demonstrate zero-shot
generalization, we experimented with an English essays dataset, and results
suggest that our ensembling approach can handle new data effectively.
</p>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03087" title="Abstract">arXiv:2311.03087</a> [<a href="/pdf/2311.03087" title="Download PDF">pdf</a>, <a href="/format/2311.03087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Persistent homology for high-dimensional data based on spectral methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Damrich%2C+S">Sebastian Damrich</a>, 
<a href="/search/cs?searchtype=author&query=Berens%2C+P">Philipp Berens</a>, 
<a href="/search/cs?searchtype=author&query=Kobak%2C+D">Dmitry Kobak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 22 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Algebraic Topology (math.AT)

</div>
<p class="mathjax">Persistent homology is a popular computational tool for detecting non-trivial
topology of point clouds, such as the presence of loops or voids. However, many
real-world datasets with low intrinsic dimensionality reside in an ambient
space of much higher dimensionality. We show that in this case vanilla
persistent homology becomes very sensitive to noise and fails to detect the
correct topology. The same holds true for most existing refinements of
persistent homology. As a remedy, we find that spectral distances on the
$k$-nearest-neighbor graph of the data, such as diffusion distance and
effective resistance, allow persistent homology to detect the correct topology
even in the presence of high-dimensional noise. Furthermore, we derive a novel
closed-form expression for effective resistance in terms of the
eigendecomposition of the graph Laplacian, and describe its relation to
diffusion distances. Finally, we apply these methods to several
high-dimensional single-cell RNA-sequencing datasets and show that spectral
distances on the $k$-nearest-neighbor graph allow robust detection of cell
cycle loops.
</p>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03090" title="Abstract">arXiv:2311.03090</a> [<a href="/pdf/2311.03090" title="Download PDF">pdf</a>, <a href="/format/2311.03090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A multi-modal approach to continuous material identification through  tactile sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Egu%C3%ADluz%2C+A+G">Augusto G&#xf3;mez Egu&#xed;luz</a>, 
<a href="/search/cs?searchtype=author&query=Ra%C3%B1%C3%B3%2C+I">Ignacio Ra&#xf1;&#xf3;</a>, 
<a href="/search/cs?searchtype=author&query=Coleman%2C+S+A">Sonya A. Coleman</a>, 
<a href="/search/cs?searchtype=author&query=McGinnity%2C+T+M">T. Martin McGinnity</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Tactile sensing has recently been used in robotics for object identification,
grasping, and material recognition. Most material recognition approaches use
vibration information from a tactile exploration, typically above one second
long, to identify the material. This work proposes a tactile multi-modal
(vibration and thermal) material identification approach based on recursive
Bayesian estimation. Through the frequency response of the vibration induced by
the material and thermal features, like an estimate of the thermal power loss
of the finger, we show that it is possible to identify materials in less than
half a second. Moreover, a comparison between the use of vibration only and
multi-modal identification shows that both recognition time and classification
errors are reduced by adding thermal information.
</p>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03092" title="Abstract">arXiv:2311.03092</a> [<a href="/pdf/2311.03092" title="Download PDF">pdf</a>, <a href="/format/2311.03092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> We will DAG you
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amores-Sesar%2C+I">Ignacio Amores-Sesar</a>, 
<a href="/search/cs?searchtype=author&query=Cachin%2C+C">Christian Cachin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">DAG-based protocols have been proposed as potential solutions to the latency
and throughput limitations of traditional permissionless consensus protocols.
However, their adoption has been hindered by security concerns and a lack of a
solid foundation to guarantee improvements in both throughput and latency. In
this paper, we present a construction that rigorously demonstrates how
DAG-based protocols can achieve superior throughput and latency compared to
chain-based consensus protocols, all while maintaining the same level of
security guarantees.
</p>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03094" title="Abstract">arXiv:2311.03094</a> [<a href="/pdf/2311.03094" title="Download PDF">pdf</a>, <a href="/format/2311.03094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equivariance Is Not All You Need: Characterizing the Utility of  Equivariant Graph Neural Networks for Particle Physics Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thais%2C+S">Savannah Thais</a>, 
<a href="/search/cs?searchtype=author&query=Murnane%2C+D">Daniel Murnane</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper at Knowledge and Logical Reasoning in the Era of Data-driven Learning Workshop at ICML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; High Energy Physics - Experiment (hep-ex)

</div>
<p class="mathjax">Incorporating inductive biases into ML models is an active area of ML
research, especially when ML models are applied to data about the physical
world. Equivariant Graph Neural Networks (GNNs) have recently become a popular
method for learning from physics data because they directly incorporate the
symmetries of the underlying physical system. Drawing from the relevant
literature around group equivariant networks, this paper presents a
comprehensive evaluation of the proposed benefits of equivariant GNNs by using
real-world particle physics reconstruction tasks as an evaluation test-bed. We
demonstrate that many of the theoretical benefits generally associated with
equivariant networks may not hold for realistic systems and introduce
compelling directions for future research that will benefit both the scientific
theory of ML and physics applications.
</p>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03096" title="Abstract">arXiv:2311.03096</a> [<a href="/pdf/2311.03096" title="Download PDF">pdf</a>, <a href="/format/2311.03096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weight-Sharing Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shakerinava%2C+M">Mehran Shakerinava</a>, 
<a href="/search/cs?searchtype=author&query=Sohrabi%2C+M">Motahareh Sohrabi</a>, 
<a href="/search/cs?searchtype=author&query=Ravanbakhsh%2C+S">Siamak Ravanbakhsh</a>, 
<a href="/search/cs?searchtype=author&query=Lacoste-Julien%2C+S">Simon Lacoste-Julien</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our code is available at <a href="https://github.com/motahareh-sohrabi/weight-sharing-regularization">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Weight-sharing is ubiquitous in deep learning. Motivated by this, we
introduce ''weight-sharing regularization'' for neural networks, defined as
$R(w) = \frac{1}{d - 1}\sum_{i &gt; j}^d |w_i - w_j|$. We study the proximal
mapping of $R$ and provide an intuitive interpretation of it in terms of a
physical system of interacting particles. Using this interpretation, we design
a novel parallel algorithm for $\operatorname{prox}_R$ which provides an
exponential speedup over previous algorithms, with a depth of $O(\log^3 d)$.
Our algorithm makes it feasible to train weight-sharing regularized deep neural
networks with proximal gradient descent. Experiments reveal that weight-sharing
regularization enables fully-connected networks to learn convolution-like
filters.
</p>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03098" title="Abstract">arXiv:2311.03098</a> [<a href="/pdf/2311.03098" title="Download PDF">pdf</a>, <a href="/ps/2311.03098" title="Download PostScript">ps</a>, <a href="/format/2311.03098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modularity for lunar exploration: European Moon Rover System Pre-Phase A  Design and Field Test Campaign Results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luna%2C+C">Cristina Luna</a>, 
<a href="/search/cs?searchtype=author&query=Barrientos-D%C3%ADez%2C+J">Jorge Barrientos-D&#xed;ez</a>, 
<a href="/search/cs?searchtype=author&query=Esquer%2C+M">Manuel Esquer</a>, 
<a href="/search/cs?searchtype=author&query=Guerra%2C+A">Alba Guerra</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez-Seoane%2C+M">Marina L&#xf3;pez-Seoane</a>, 
<a href="/search/cs?searchtype=author&query=Colmenarejo%2C+I">I&#xf1;aki Colmenarejo</a>, 
<a href="/search/cs?searchtype=author&query=Gand%C3%ADa%2C+F">Fernando Gand&#xed;a</a>, 
<a href="/search/cs?searchtype=author&query=Kay%2C+S">Steven Kay</a>, 
<a href="/search/cs?searchtype=author&query=Cameron%2C+A">Angus Cameron</a>, 
<a href="/search/cs?searchtype=author&query=Cama%C3%B1es%2C+C">Carmen Cama&#xf1;es</a>, 
<a href="/search/cs?searchtype=author&query=Sard%2C+%C3%8D">&#xcd;&#xf1;igo Sard</a>, 
<a href="/search/cs?searchtype=author&query=Ju%C3%A1rez%2C+D">Danel Ju&#xe1;rez</a>, 
<a href="/search/cs?searchtype=author&query=Orlandi%2C+A">Alessandro Orlandi</a>, 
<a href="/search/cs?searchtype=author&query=Angeletti%2C+F">Federica Angeletti</a>, 
<a href="/search/cs?searchtype=author&query=Papantoniou%2C+V">Vassilios Papantoniou</a>, 
<a href="/search/cs?searchtype=author&query=Papantoniou%2C+A">Ares Papantoniou</a>, 
<a href="/search/cs?searchtype=author&query=Makris%2C+S">Spiros Makris</a>, 
<a href="/search/cs?searchtype=author&query=rebele%2C+B">Bernhard rebele</a>, 
<a href="/search/cs?searchtype=author&query=Wedler%2C+A">Armin Wedler</a>, 
<a href="/search/cs?searchtype=author&query=Reynolds%2C+J">Jennifer Reynolds</a>, 
<a href="/search/cs?searchtype=author&query=Landgraf%2C+M">Markus Landgraf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, Conference paper for the IAC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The European Moon Rover System (EMRS) Pre-Phase A activity is part of the
European Exploration Envelope Programme (E3P) that seeks to develop a versatile
surface mobility solution for future lunar missions. These missions include:
the Polar Explorer (PE), In-Situ Resource Utilization (ISRU), and Astrophysics
Lunar Observatory (ALO) and Lunar Geological Exploration Mission (LGEM).
Therefore, designing a multipurpose rover that can serve these missions is
crucial. The rover needs to be compatible with three different mission
scenarios, each with an independent payload, making flexibility the key driver.
This study focuses on modularity in the rover's locomotion solution and
autonomous on-board system. Moreover, the proposed EMRS solution has been
tested at an analogue facility to prove the modular mobility concept. The tests
involved the rover's mobility in a lunar soil simulant testbed and different
locomotion modes in a rocky and uneven terrain, as well as robustness against
obstacles and excavation of lunar regolith. As a result, the EMRS project has
developed a multipurpose modular rover concept, with power, thermal control,
insulation, and dust protection systems designed for further phases. This paper
highlights the potential of the EMRS system for lunar exploration and the
importance of modularity in rover design.
</p>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03099" title="Abstract">arXiv:2311.03099</a> [<a href="/pdf/2311.03099" title="Download PDF">pdf</a>, <a href="/format/2311.03099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Models are Super Mario: Absorbing Abilities from Homologous  Models as a Free Lunch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Le Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bowen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haiyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongbin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 21 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we uncover that Language Models (LMs), either encoder- or
decoder-based, can obtain new capabilities by assimilating the parameters of
homologous models without retraining or GPUs. Typically, new abilities of LMs
can be imparted by Supervised Fine-Tuning (SFT), reflected in the disparity
between fine-tuned and pre-trained parameters (i.e., delta parameters). We
initially observe that by introducing a novel operation called DARE (Drop And
REscale), most delta parameters can be directly set to zeros without affecting
the capabilities of SFT LMs and larger models can tolerate a higher proportion
of discarded parameters. Based on this observation, we further sparsify delta
parameters of multiple SFT homologous models with DARE and subsequently merge
them into a single model by parameter averaging. We conduct experiments on
eight datasets from the GLUE benchmark with BERT and RoBERTa. We also merge
WizardLM, WizardMath, and Code Alpaca based on Llama 2. Experimental results
show that: (1) The delta parameter value ranges for SFT models are typically
small, often within 0.005, and DARE can eliminate 99% of them effortlessly.
However, once the models are continuously pre-trained, the value ranges can
grow to around 0.03, making DARE impractical. We have also tried to remove
fine-tuned instead of delta parameters and find that a 10% reduction can lead
to drastically decreased performance (even to 0). This highlights that SFT
merely stimulates the abilities via delta parameters rather than injecting new
abilities into LMs; (2) DARE can merge multiple task-specific LMs into one LM
with diverse abilities. For instance, the merger of WizardLM and WizardMath
improves the GSM8K zero-shot accuracy of WizardLM from 2.2 to 66.3, retaining
its instruction-following ability while surpassing WizardMath's original 64.2
performance. Codes are available at https://github.com/yule-BUAA/MergeLM.
</p>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03105" title="Abstract">arXiv:2311.03105</a> [<a href="/pdf/2311.03105" title="Download PDF">pdf</a>, <a href="/ps/2311.03105" title="Download PostScript">ps</a>, <a href="/format/2311.03105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pelvic floor MRI segmentation based on semi-supervised deep learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zuo%2C+J">Jianwei Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhuhui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ashton-Miller%2C+J+A">James A. Ashton-Miller</a>, 
<a href="/search/cs?searchtype=author&query=Delancey%2C+J+O+L">John O.L. Delancey</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiajia Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The semantic segmentation of pelvic organs via MRI has important clinical
significance. Recently, deep learning-enabled semantic segmentation has
facilitated the three-dimensional geometric reconstruction of pelvic floor
organs, providing clinicians with accurate and intuitive diagnostic results.
However, the task of labeling pelvic floor MRI segmentation, typically
performed by clinicians, is labor-intensive and costly, leading to a scarcity
of labels. Insufficient segmentation labels limit the precise segmentation and
reconstruction of pelvic floor organs. To address these issues, we propose a
semi-supervised framework for pelvic organ segmentation. The implementation of
this framework comprises two stages. In the first stage, it performs
self-supervised pre-training using image restoration tasks. Subsequently,
fine-tuning of the self-supervised model is performed, using labeled data to
train the segmentation model. In the second stage, the self-supervised
segmentation model is used to generate pseudo labels for unlabeled data.
Ultimately, both labeled and unlabeled data are utilized in semi-supervised
training. Upon evaluation, our method significantly enhances the performance in
the semantic segmentation and geometric reconstruction of pelvic organs, Dice
coefficient can increase by 2.65% averagely. Especially for organs that are
difficult to segment, such as the uterus, the accuracy of semantic segmentation
can be improved by up to 3.70%.
</p>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03106" title="Abstract">arXiv:2311.03106</a> [<a href="/pdf/2311.03106" title="Download PDF">pdf</a>, <a href="/format/2311.03106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified Multi-modal Unsupervised Representation Learning for  Skeleton-based Action Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shengkai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Daizong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jianfeng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+X">Xiaoye Qu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Junyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Meng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM MM 2023. The code is available at <a href="https://github.com/HuiGuanLab/UmURL">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unsupervised pre-training has shown great success in skeleton-based action
understanding recently. Existing works typically train separate
modality-specific models, then integrate the multi-modal information for action
understanding by a late-fusion strategy. Although these approaches have
achieved significant performance, they suffer from the complex yet redundant
multi-stream model designs, each of which is also limited to the fixed input
skeleton modality. To alleviate these issues, in this paper, we propose a
Unified Multimodal Unsupervised Representation Learning framework, called
UmURL, which exploits an efficient early-fusion strategy to jointly encode the
multi-modal features in a single-stream manner. Specifically, instead of
designing separate modality-specific optimization processes for uni-modal
unsupervised learning, we feed different modality inputs into the same stream
with an early-fusion strategy to learn their multi-modal features for reducing
model complexity. To ensure that the fused multi-modal features do not exhibit
modality bias, i.e., being dominated by a certain modality input, we further
propose both intra- and inter-modal consistency learning to guarantee that the
multi-modal features contain the complete semantics of each modal via feature
decomposition and distinct alignment. In this manner, our framework is able to
learn the unified representations of uni-modal or multi-modal skeleton input,
which is flexible to different kinds of modality input for robust action
understanding in practical cases. Extensive experiments conducted on three
large-scale datasets, i.e., NTU-60, NTU-120, and PKU-MMD II, demonstrate that
UmURL is highly efficient, possessing the approximate complexity with the
uni-modal methods, while achieving new state-of-the-art performance across
various downstream task scenarios in skeleton-based action representation
learning.
</p>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03109" title="Abstract">arXiv:2311.03109</a> [<a href="/pdf/2311.03109" title="Download PDF">pdf</a>, <a href="/format/2311.03109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tensor Golub Kahan based on Einstein product
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hachimi%2C+A+E">Anas El Hachimi</a>, 
<a href="/search/math?searchtype=author&query=Jbilou%2C+K">Khalide Jbilou</a>, 
<a href="/search/math?searchtype=author&query=Hached%2C+M">Mustapha Hached</a>, 
<a href="/search/math?searchtype=author&query=Ratnani%2C+A">Ahmed Ratnani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The Singular Value Decomposition (SVD) of matrices is a widely used tool in
scientific computing. In many applications of machine learning, data analysis,
signal and image processing, the large datasets are structured into tensors,
for which generalizations of SVD have already been introduced, for various
types of tensor-tensor products. In this article, we present innovative methods
for approximating this generalization of SVD to tensors in the framework of the
Einstein tensor product. These singular elements are called singular values and
singular tensors, respectively. The proposed method uses the tensor Lanczos
bidiagonalization applied to the Einstein product. In most applications, as in
the matrix case, the extremal singular values are of special interest. To
enhance the approximation of the largest or the smallest singular triplets
(singular values and left and right singular tensors), a restarted method based
on Ritz augmentation is proposed. Numerical results are proposed to illustrate
the effectiveness of the presented method. In addition, applications to video
compression and facial recognition are presented.
</p>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03113" title="Abstract">arXiv:2311.03113</a> [<a href="/pdf/2311.03113" title="Download PDF">pdf</a>, <a href="/format/2311.03113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Injecting Categorical Labels and Syntactic Information into Biomedical  NER
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Francis%2C+S">Sumam Francis</a>, 
<a href="/search/cs?searchtype=author&query=Moens%2C+M">Marie-Francine Moens</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 18th Conference on Computational Intelligence Methods for Bioinformatics &amp; Biostatistics (CIBB 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a simple approach to improve biomedical named entity recognition
(NER) by injecting categorical labels and Part-of-speech (POS) information into
the model. We use two approaches, in the first approach, we first train a
sequence-level classifier to classify the sentences into categories to obtain
the sentence-level tags (categorical labels). The sequence classifier is
modeled as an entailment problem by modifying the labels as a natural language
template. This helps to improve the accuracy of the classifier. Further, this
label information is injected into the NER model. In this paper, we demonstrate
effective ways to represent and inject these labels and POS attributes into the
NER model. In the second approach, we jointly learn the categorical labels and
NER labels. Here we also inject the POS tags into the model to increase the
syntactic context of the model. Experiments on three benchmark datasets show
that incorporating categorical label information with syntactic context is
quite useful and outperforms baseline BERT-based models.
</p>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03114" title="Abstract">arXiv:2311.03114</a> [<a href="/pdf/2311.03114" title="Download PDF">pdf</a>, <a href="/format/2311.03114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ignoring Time Dependence in Data. A mistake
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Robredo%2C+M">Mikel Robredo</a>, 
<a href="/search/cs?searchtype=author&query=Saarimaki%2C+N">Nyyti Saarimaki</a>, 
<a href="/search/cs?searchtype=author&query=Penaloza%2C+R">Rafael Penaloza</a>, 
<a href="/search/cs?searchtype=author&query=Lenarduzzi%2C+V">Valentina Lenarduzzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Researchers often delve into the connections between different factors
derived from the historical data of software projects. For example, scholars
have devoted their endeavors to the exploration of associations among these
factors. However, a significant portion of these studies has failed to consider
the limitations posed by the temporal interdependencies among these variables
and the potential risks associated with the use of statistical methods
ill-suited for analyzing data with temporal connections. Our goal is to
highlight the consequences of neglecting time dependence during data analysis
in current research. We pinpointed out certain potential problems that arise
when disregarding the temporal aspect in the data, and support our argument
with both theoretical and real examples.
</p>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03115" title="Abstract">arXiv:2311.03115</a> [<a href="/pdf/2311.03115" title="Download PDF">pdf</a>, <a href="/format/2311.03115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RELand: Risk Estimation of Landmines via Interpretable Invariant Risk  Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rubio%2C+M+D">Mateo Dulce Rubio</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+S">Siqi Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Alvarado%2C+D">Didier Alvarado</a>, 
<a href="/search/cs?searchtype=author&query=Moreno%2C+F">Francisco Moreno</a>, 
<a href="/search/cs?searchtype=author&query=Heidari%2C+H">Hoda Heidari</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+F">Fei Fang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">Landmines remain a threat to war-affected communities for years after
conflicts have ended, partly due to the laborious nature of demining tasks.
Humanitarian demining operations begin by collecting relevant information from
the sites to be cleared, which is then analyzed by human experts to determine
the potential risk of remaining landmines. In this paper, we propose RELand
system to support these tasks, which consists of three major components. We (1)
provide general feature engineering and label assigning guidelines to enhance
datasets for landmine risk modeling, which are widely applicable to global
demining routines, (2) formulate landmine presence as a classification problem
and design a novel interpretable model based on sparse feature masking and
invariant risk minimization, and run extensive evaluation under proper
protocols that resemble real-world demining operations to show a significant
improvement over the state-of-the-art, and (3) build an interactive web
interface to suggest priority areas for demining organizations. We are
currently collaborating with a humanitarian demining NGO in Colombia that is
using our system as part of their field operations in two areas recently
prioritized for demining.
</p>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03117" title="Abstract">arXiv:2311.03117</a> [<a href="/pdf/2311.03117" title="Download PDF">pdf</a>, <a href="/format/2311.03117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enriched Presheaf Model of Quantum FPC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsukada%2C+T">Takeshi Tsukada</a>, 
<a href="/search/cs?searchtype=author&query=Asada%2C+K">Kazuyuki Asada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Selinger gave a superoperator model of a first-order quantum programming
language and proved that it is fully definable and hence fully abstract. This
paper proposes an extension of the superoperator model to higher-order programs
based on modules over superoperators or, equivalently, enriched presheaves over
the category of superoperators. The enriched presheaf category can be easily
proved to be a model of intuitionistic linear logic with cofree exponential,
from which one can cave out a model of classical linear logic by a kind of
bi-orthogonality construction. Although the structures of an enriched presheaf
category are usually rather complex, a morphism in the classical model can be
expressed simply as a matrix of completely positive maps. The model inherits
many desirable properties from the superoperator model. A conceptually
interesting property is that our model has only a state whose "total
probability" is bounded by 1, i.e. does not have a state where true and false
each occur with probability 2/3. Another convenient property inherited from the
superoperator model is a $\omega$CPO-enrichment. Remarkably, our model has a
sufficient structure to interpret arbitrary recursive types by the standard
domain theoretic technique. We introduce Quantum FPC, a quantum
$\lambda$-calculus with recursive types, and prove that our model is a fully
abstract model of Quantum FPC.
</p>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03122" title="Abstract">arXiv:2311.03122</a> [<a href="/pdf/2311.03122" title="Download PDF">pdf</a>, <a href="/format/2311.03122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CISRU: a robotics software suite to enable complex rover-rover and  astronaut-rover interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Romero-Azpitarte%2C+S">Silvia Romero-Azpitarte</a>, 
<a href="/search/cs?searchtype=author&query=Guerra%2C+A">Alba Guerra</a>, 
<a href="/search/cs?searchtype=author&query=Alonso%2C+M">Mercedes Alonso</a>, 
<a href="/search/cs?searchtype=author&query=Seoane%2C+M+L">Marina L. Seoane</a>, 
<a href="/search/cs?searchtype=author&query=Olayo%2C+D">Daniel Olayo</a>, 
<a href="/search/cs?searchtype=author&query=Moreno%2C+A">Almudena Moreno</a>, 
<a href="/search/cs?searchtype=author&query=Castellanos%2C+P">Pablo Castellanos</a>, 
<a href="/search/cs?searchtype=author&query=Luna%2C+C">Cristina Luna</a>, 
<a href="/search/cs?searchtype=author&query=Visentin%2C+G">Gianfranco Visentin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference paper for ASTRA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The CISRU project has focused on the development of a software suite for
planetary (and terrestrial) robotics, fully abstracted from the robotic
platform and enabling interaction between rovers and astronauts in complex
tasks and non-structured scenarios. To achieve this, a high level of autonomy
is required, powered by AI and multi-agent autonomous planning systems
inherited from ERGO/ADE and the PERASPERA program. This communication presents
the system developed in CISRU, focusing on the modules of AI-based perception
and the interaction between astronauts and robots.
</p>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03124" title="Abstract">arXiv:2311.03124</a> [<a href="/pdf/2311.03124" title="Download PDF">pdf</a>, <a href="/format/2311.03124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TAMPAR: Visual Tampering Detection for Parcel Logistics in Postal Supply  Chains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naumann%2C+A">Alexander Naumann</a>, 
<a href="/search/cs?searchtype=author&query=Hertlein%2C+F">Felix Hertlein</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%B6rr%2C+L">Laura D&#xf6;rr</a>, 
<a href="/search/cs?searchtype=author&query=Furmans%2C+K">Kai Furmans</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Due to the steadily rising amount of valuable goods in supply chains,
tampering detection for parcels is becoming increasingly important. In this
work, we focus on the use-case last-mile delivery, where only a single RGB
image is taken and compared against a reference from an existing database to
detect potential appearance changes that indicate tampering. We propose a
tampering detection pipeline that utilizes keypoint detection to identify the
eight corner points of a parcel. This permits applying a perspective
transformation to create normalized fronto-parallel views for each visible
parcel side surface. These viewpoint-invariant parcel side surface
representations facilitate the identification of signs of tampering on parcels
within the supply chain, since they reduce the problem to parcel side surface
matching with pair-wise appearance change detection. Experiments with multiple
classical and deep learning-based change detection approaches are performed on
our newly collected TAMpering detection dataset for PARcels, called TAMPAR. We
evaluate keypoint and change detection separately, as well as in a unified
system for tampering detection. Our evaluation shows promising results for
keypoint (Keypoint AP 75.76) and tampering detection (81% accuracy, F1-Score
0.83) on real images. Furthermore, a sensitivity analysis for tampering types,
lens distortion and viewing angles is presented. Code and dataset are available
at https://a-nau.github.io/tampar.
</p>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03127" title="Abstract">arXiv:2311.03127</a> [<a href="/pdf/2311.03127" title="Download PDF">pdf</a>, <a href="/format/2311.03127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Findings of the WMT 2023 Shared Task on Discourse-Level Literary  Translation: A Fresh Orb in the Cosmos of LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Longyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhaopeng Tu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yan Gu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Siyou Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Q">Qingsong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+C">Chenyang Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Liting Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chao-Hong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yufeng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weiyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Graham%2C+Y">Yvette Graham</a>, 
<a href="/search/cs?searchtype=author&query=Webber%2C+B">Bonnie Webber</a>, 
<a href="/search/cs?searchtype=author&query=Koehn%2C+P">Philipp Koehn</a>, 
<a href="/search/cs?searchtype=author&query=Way%2C+A">Andy Way</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yulin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WMT2023 Discourse-Level Literary Translation Shared Task Overview Paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Translating literary works has perennially stood as an elusive dream in
machine translation (MT), a journey steeped in intricate challenges. To foster
progress in this domain, we hold a new shared task at WMT 2023, the first
edition of the Discourse-Level Literary Translation. First, we (Tencent AI Lab
and China Literature Ltd.) release a copyrighted and document-level
Chinese-English web novel corpus. Furthermore, we put forth an
industry-endorsed criteria to guide human evaluation process. This year, we
totally received 14 submissions from 7 academia and industry teams. We employ
both automatic and human evaluations to measure the performance of the
submitted systems. The official ranking of the systems is based on the overall
human judgments. In addition, our extensive analysis reveals a series of
interesting findings on literary and discourse-aware MT. We release data,
system outputs, and leaderboard at
<a href="http://www2.statmt.org/wmt23/literary-translation-task.html.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03128" title="Abstract">arXiv:2311.03128</a> [<a href="/pdf/2311.03128" title="Download PDF">pdf</a>, <a href="/ps/2311.03128" title="Download PostScript">ps</a>, <a href="/format/2311.03128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Differential Evolution on a Quantum Simulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+P">Parthasarathy Srinivasan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">The use of Evolutionary Algorithms (EA) for solving
Mathematical/Computational Optimization Problems is inspired by the biological
processes of Evolution. Few of the primitives involved in the Evolutionary
process/paradigm are selection of 'Fit' individuals (from a population sample)
for retention, cloning, mutation, discarding, breeding, crossover etc. In the
Evolutionary Algorithm abstraction, the individuals are deemed to be solution
candidates to an Optimization problem and additional solution(/sets) are built
by applying analogies to the above primitives (cloning, mutation etc.) by means
of evaluating a 'Fitness' function/criterion. One such algorithm is
Differential Evolution (DE) which can be used to compute the minima of
functions such as the rastrigin function and rosenbrock function. This work is
an attempt to study the result of applying the DE method on these functions
with candidate individuals generated on classical Turing modeled computation
and comparing the same with those on state of the art Quantum computation.The
study benchmarks the convergence of these functions by varying the parameters
initialized and reports timing, convergence, and resource utilization results.
</p>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03136" title="Abstract">arXiv:2311.03136</a> [<a href="/pdf/2311.03136" title="Download PDF">pdf</a>, <a href="/format/2311.03136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The European Moon Rover System: a modular multipurpose rover for future  complex lunar missions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luna%2C+C">Cristina Luna</a>, 
<a href="/search/cs?searchtype=author&query=Esquer%2C+M">Manuel Esquer</a>, 
<a href="/search/cs?searchtype=author&query=Barrientos-D%C3%ADez%2C+J">Jorge Barrientos-D&#xed;ez</a>, 
<a href="/search/cs?searchtype=author&query=Guerra%2C+A">Alba Guerra</a>, 
<a href="/search/cs?searchtype=author&query=Seoane%2C+M+L">Marina L. Seoane</a>, 
<a href="/search/cs?searchtype=author&query=Colmenarejo%2C+I">I&#xf1;aki Colmenarejo</a>, 
<a href="/search/cs?searchtype=author&query=Kay%2C+S">Steven Kay</a>, 
<a href="/search/cs?searchtype=author&query=Cameron%2C+A">Angus Cameron</a>, 
<a href="/search/cs?searchtype=author&query=Cama%C3%B1es%2C+C">Carmen Cama&#xf1;es</a>, 
<a href="/search/cs?searchtype=author&query=Sard%2C+%C3%8D">&#xcd;&#xf1;igo Sard</a>, 
<a href="/search/cs?searchtype=author&query=Ju%C3%A1rez%2C+D">Danel Ju&#xe1;rez</a>, 
<a href="/search/cs?searchtype=author&query=Orlandi%2C+A">Alessandro Orlandi</a>, 
<a href="/search/cs?searchtype=author&query=Angeletti%2C+F">Federica Angeletti</a>, 
<a href="/search/cs?searchtype=author&query=Papatoniou%2C+V">Vassilios Papatoniou</a>, 
<a href="/search/cs?searchtype=author&query=Papantoniou%2C+A">Ares Papantoniou</a>, 
<a href="/search/cs?searchtype=author&query=Makris%2C+S">Spiros Makris</a>, 
<a href="/search/cs?searchtype=author&query=Wedler%2C+A">Armin Wedler</a>, 
<a href="/search/cs?searchtype=author&query=Rebele%2C+B">Bernhard Rebele</a>, 
<a href="/search/cs?searchtype=author&query=Reynolds%2C+J">Jennifer Reynolds</a>, 
<a href="/search/cs?searchtype=author&query=Landgraf%2C+M">Markus Landgraf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference Paper for ASTRA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM)

</div>
<p class="mathjax">This document presents the study conducted during the European Moon Rover
System Pre-Phase A project, in which we have developed a lunar rover system,
with a modular approach, capable of carrying out different missions with
different objectives. This includes excavating and transporting over 200kg of
regolith, building an astrophysical observatory on the far side of the Moon,
placing scientific instrumentation at the lunar south pole, or studying the
volcanic history of our satellite. To achieve this, a modular approach has been
adopted for the design of the platform in terms of locomotion and mobility,
which includes onboard autonomy, of course. A modular platform allows for
accommodating different payloads and allocating them in the most advantageous
positions for the mission they are going to undertake (for example, having
direct access to the lunar surface for the payloads that require it), while
also allowing for the relocation of payloads and reconfiguring the rover design
itself to perform completely different tasks.
</p>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03140" title="Abstract">arXiv:2311.03140</a> [<a href="/pdf/2311.03140" title="Download PDF">pdf</a>, <a href="/format/2311.03140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Animating NeRFs from Texture Space: A Framework for Pose-Dependent  Rendering of Human Performances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Knoll%2C+P">Paul Knoll</a>, 
<a href="/search/cs?searchtype=author&query=Morgenstern%2C+W">Wieland Morgenstern</a>, 
<a href="/search/cs?searchtype=author&query=Hilsmann%2C+A">Anna Hilsmann</a>, 
<a href="/search/cs?searchtype=author&query=Eisert%2C+P">Peter Eisert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Creating high-quality controllable 3D human models from multi-view RGB videos
poses a significant challenge. Neural radiance fields (NeRFs) have demonstrated
remarkable quality in reconstructing and free-viewpoint rendering of static as
well as dynamic scenes. The extension to a controllable synthesis of dynamic
human performances poses an exciting research question. In this paper, we
introduce a novel NeRF-based framework for pose-dependent rendering of human
performances. In our approach, the radiance field is warped around an SMPL body
mesh, thereby creating a new surface-aligned representation. Our representation
can be animated through skeletal joint parameters that are provided to the NeRF
in addition to the viewpoint for pose dependent appearances. To achieve this,
our representation includes the corresponding 2D UV coordinates on the mesh
texture map and the distance between the query point and the mesh. To enable
efficient learning despite mapping ambiguities and random visual variations, we
introduce a novel remapping process that refines the mapped coordinates.
Experiments demonstrate that our approach results in high-quality renderings
for novel-view and novel-pose synthesis.
</p>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03146" title="Abstract">arXiv:2311.03146</a> [<a href="/pdf/2311.03146" title="Download PDF">pdf</a>, <a href="/ps/2311.03146" title="Download PostScript">ps</a>, <a href="/format/2311.03146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling In-Situ Resources Utilisation by leveraging collaborative  robotics and astronaut-robot interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Romero-Azpitarte%2C+S">Silvia Romero-Azpitarte</a>, 
<a href="/search/cs?searchtype=author&query=Luna%2C+C">Cristina Luna</a>, 
<a href="/search/cs?searchtype=author&query=Guerra%2C+A">Alba Guerra</a>, 
<a href="/search/cs?searchtype=author&query=Alonso%2C+M">Mercedes Alonso</a>, 
<a href="/search/cs?searchtype=author&query=Manrique%2C+P+R">Pablo Romeo Manrique</a>, 
<a href="/search/cs?searchtype=author&query=Seoane%2C+M+L">Marina L. Seoane</a>, 
<a href="/search/cs?searchtype=author&query=Olayo%2C+D">Daniel Olayo</a>, 
<a href="/search/cs?searchtype=author&query=Moreno%2C+A">Almudena Moreno</a>, 
<a href="/search/cs?searchtype=author&query=Castellanos%2C+P">Pablo Castellanos</a>, 
<a href="/search/cs?searchtype=author&query=Gand%C3%ADa%2C+F">Fernando Gand&#xed;a</a>, 
<a href="/search/cs?searchtype=author&query=Visentin%2C+G">Gianfranco Visentin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, conference paper for IAC 23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Space exploration and establishing human presence on other planets demand
advanced technology and effective collaboration between robots and astronauts.
Efficient space resource utilization is also vital for extraterrestrial
settlements. The Collaborative In-Situ Resources Utilisation (CISRU) project
has developed a software suite comprising five key modules. The first module
manages multi-agent autonomy, facilitating communication between agents and
mission control. The second focuses on environment perception, employing AI
algorithms for tasks like environment segmentation and object pose estimation.
The third module ensures safe navigation, covering obstacle avoidance, social
navigation with astronauts, and cooperation among robots. The fourth module
addresses manipulation functions, including multi-tool capabilities and
tool-changer design for diverse tasks in In-Situ Resources Utilization (ISRU)
scenarios. Finally, the fifth module controls cooperative behaviour,
incorporating astronaut commands, Mixed Reality interfaces, map fusion, task
supervision, and error control. The suite was tested using an astronaut-rover
interaction dataset in a planetary environment and GMV SPoT analogue
environments. Results demonstrate the advantages of E4 autonomy and AI in space
systems, benefiting astronaut-robot collaboration. This paper details CISRU's
development, field test preparation, and analysis, highlighting its potential
to revolutionize planetary exploration through AI-powered technology.
</p>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03149" title="Abstract">arXiv:2311.03149</a> [<a href="/pdf/2311.03149" title="Download PDF">pdf</a>, <a href="/format/2311.03149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymmetric Masked Distillation for Pre-Training Small Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhiyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Bingkun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+S">Sen Xing</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Gangshan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Limin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Self-supervised foundation models have shown great potential in computer
vision thanks to the pre-training paradigm of masked autoencoding. Scale is a
primary factor influencing the performance of these foundation models. However,
these large foundation models often result in high computational cost that
might limit their deployment. This paper focuses on pre-training relatively
small vision transformer models that could be efficiently adapted to downstream
tasks. Specifically, taking inspiration from knowledge distillation in model
compression, we propose a new asymmetric masked distillation(AMD) framework for
pre-training relatively small models with autoencoding. The core of AMD is to
devise an asymmetric masking strategy, where the teacher model is enabled to
see more context information with a lower masking ratio, while the student
model still with high masking ratio to the original masked pre-training. We
design customized multi-layer feature alignment between the teacher encoder and
student encoder to regularize the pre-training of student MAE. To demonstrate
the effectiveness and versatility of AMD, we apply it to both ImageMAE and
VideoMAE for pre-training relatively small ViT models. AMD achieved 84.6%
classification accuracy on IN1K using the ViT-B model. And AMD achieves 73.3%
classification accuracy using the ViT-B model on the Something-in-Something V2
dataset, a 3.7% improvement over the original ViT-B model from VideoMAE. We
also transfer AMD pre-trained models to downstream tasks and obtain consistent
performance improvement over the standard pre-training.
</p>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03150" title="Abstract">arXiv:2311.03150</a> [<a href="/pdf/2311.03150" title="Download PDF">pdf</a>, <a href="/format/2311.03150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Brain-inspired Theory of Collective Mind Model for Efficient Social  Cooperation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhuoya Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Feifei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiwen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yinqian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yi Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">Social intelligence manifests the capability, often referred to as the Theory
of Mind (ToM), to discern others' behavioral intentions, beliefs, and other
mental states. ToM is especially important in multi-agent and human-machine
interaction environments because each agent needs to understand the mental
states of other agents in order to better respond, interact, and collaborate.
Recent research indicates that the ToM model possesses the capability to infer
beliefs, intentions, and anticipate future observations and actions;
nonetheless, its deployment in tackling intricate tasks remains notably
limited. The challenges arise when the number of agents increases, the
environment becomes more complex, and interacting with the environment and
predicting the mental state of each other becomes difficult and time consuming.
To overcome such limits, we take inspiration from the Theory of Collective Mind
(ToCM) mechanism, predicting observations of all other agents into a unified
but plural representation and discerning how our own actions affect this mental
state representation. Based on this foundation, we construct an imaginative
space to simulate the multi-agent interaction process, thus improving the
efficiency of cooperation among multiple agents in complex decision-making
environments. In various cooperative tasks with different numbers of agents,
the experimental results highlight the superior cooperative efficiency and
performance of our approach compared to the Multi-Agent Reinforcement Learning
(MARL) baselines. We achieve consistent boost on SNN- and DNN-based decision
networks, and demonstrate that ToCM's inferences about others' mental states
can be transferred to new tasks for quickly and flexible adaptation.
</p>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03153" title="Abstract">arXiv:2311.03153</a> [<a href="/pdf/2311.03153" title="Download PDF">pdf</a>, <a href="/format/2311.03153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Architectural Sweet Spots for Modeling Human Label Variation by the  Example of Argument Quality: It&#x27;s Best to Relate Perspectives!
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heinisch%2C+P">Philipp Heinisch</a>, 
<a href="/search/cs?searchtype=author&query=Orlikowski%2C+M">Matthias Orlikowski</a>, 
<a href="/search/cs?searchtype=author&query=Romberg%2C+J">Julia Romberg</a>, 
<a href="/search/cs?searchtype=author&query=Cimiano%2C+P">Philipp Cimiano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023 main conference. First two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Many annotation tasks in natural language processing are highly subjective in
that there can be different valid and justified perspectives on what is a
proper label for a given example. This also applies to the judgment of argument
quality, where the assignment of a single ground truth is often questionable.
At the same time, there are generally accepted concepts behind argumentation
that form a common ground. To best represent the interplay of individual and
shared perspectives, we consider a continuum of approaches ranging from models
that fully aggregate perspectives into a majority label to "share
nothing"-architectures in which each annotator is considered in isolation from
all other annotators. In between these extremes, inspired by models used in the
field of recommender systems, we investigate the extent to which architectures
that include layers to model the relations between different annotators are
beneficial for predicting single-annotator labels. By means of two tasks of
argument quality classification (argument concreteness and validity/novelty of
conclusions), we show that recommender architectures increase the averaged
annotator-individual F$_1$-scores up to $43\%$ over a majority label model. Our
findings indicate that approaches to subjectivity can benefit from relating
individual perspectives.
</p>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03154" title="Abstract">arXiv:2311.03154</a> [<a href="/pdf/2311.03154" title="Download PDF">pdf</a>, <a href="/format/2311.03154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence Analysis of Sequential Federated Learning on Heterogeneous  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yipeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+X">Xinchen Lyu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">There are two categories of methods in Federated Learning (FL) for joint
training across multiple clients: i) parallel FL (PFL), where clients train
models in a parallel manner; and ii) sequential FL (SFL), where clients train
models in a sequential manner. In contrast to that of PFL, the convergence
theory of SFL on heterogeneous data is still lacking. In this paper, we
establish the convergence guarantees of SFL for strongly/general/non-convex
objectives on heterogeneous data. The convergence guarantees of SFL are better
than that of PFL on heterogeneous data with both full and partial client
participation. Experimental results validate the counterintuitive analysis
result that SFL outperforms PFL on extremely heterogeneous data in cross-device
settings.
</p>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03157" title="Abstract">arXiv:2311.03157</a> [<a href="/pdf/2311.03157" title="Download PDF">pdf</a>, <a href="/format/2311.03157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPTuner: A Manual-Reading Database Tuning System via GPT-Guided Bayesian  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lao%2C+J">Jiale Lao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yufei Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunjia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhiyuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wanghu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+M">Mingjie Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianguo Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 14 figures, submit to VLDB2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Modern database management systems (DBMS) expose hundreds of configurable
knobs to control system behaviours. Determining the appropriate values for
these knobs to improve DBMS performance is a long-standing problem in the
database community. As there is an increasing number of knobs to tune and each
knob could be in continuous or categorical values, manual tuning becomes
impractical. Recently, automatic tuning systems using machine learning methods
have shown great potentials. However, existing approaches still incur
significant tuning costs or only yield sub-optimal performance. This is because
they either ignore the extensive domain knowledge available (e.g., DBMS manuals
and forum discussions) and only rely on the runtime feedback of benchmark
evaluations to guide the optimization, or they utilize the domain knowledge in
a limited way. Hence, we propose GPTuner, a manual-reading database tuning
system. Firstly, we develop a Large Language Model (LLM)-based pipeline to
collect and refine heterogeneous knowledge, and propose a prompt ensemble
algorithm to unify a structured view of the refined knowledge. Secondly, using
the structured knowledge, we (1) design a workload-aware and training-free knob
selection strategy, (2) develop a search space optimization technique
considering the value range of each knob, and (3) propose a Coarse-to-Fine
Bayesian Optimization Framework to explore the optimized space. Finally, we
evaluate GPTuner under different benchmarks (TPC-C and TPC-H), metrics
(throughput and latency) as well as DBMS (PostgreSQL and MySQL). Compared to
the state-of-the-art approaches, GPTuner identifies better configurations in
16x less time on average. Moreover, GPTuner achieves up to 30% performance
improvement (higher throughput or lower latency) over the best-performing
alternative.
</p>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03164" title="Abstract">arXiv:2311.03164</a> [<a href="/pdf/2311.03164" title="Download PDF">pdf</a>, <a href="/format/2311.03164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A contract negotiation scheme for safety verification of interconnected  systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tan%2C+X">Xiao Tan</a>, 
<a href="/search/eess?searchtype=author&query=Papachristodoulou%2C+A">Antonis Papachristodoulou</a>, 
<a href="/search/eess?searchtype=author&query=Dimarogonas%2C+D+V">Dimos V. Dimarogonas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper proposes a (control) barrier function synthesis and safety
verification scheme for interconnected nonlinear systems based on
assume-guarantee contracts (AGC) and sum-of-squares (SOS) techniques. It is
well-known that the SOS approach does not scale well for barrier function
synthesis for high-dimensional systems. In this paper, we show that
compositional methods like AGC can mitigate this problem. We formulate the
synthesis problem into a set of small-size problems, which constructs local
contracts for subsystems, and propose a negotiation scheme among the subsystems
at the contract level. The proposed scheme is then implemented numerically on
two examples: vehicle platooning and room temperature regulation.
</p>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03171" title="Abstract">arXiv:2311.03171</a> [<a href="/pdf/2311.03171" title="Download PDF">pdf</a>, <a href="/format/2311.03171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Examination of the Alleged Privacy Threats of Confidence-Ranked  Reconstruction of Census Microdata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez%2C+D">David S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Jebreel%2C+N">Najeeb Jebreel</a>, 
<a href="/search/cs?searchtype=author&query=Domingo-Ferrer%2C+J">Josep Domingo-Ferrer</a>, 
<a href="/search/cs?searchtype=author&query=Muralidhar%2C+K">Krishnamurty Muralidhar</a>, 
<a href="/search/cs?searchtype=author&query=Blanco-Justicia%2C+A">Alberto Blanco-Justicia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 5 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The alleged threat of reconstruction attacks has led the U.S. Census Bureau
(USCB) to replace in the Decennial Census 2020 the traditional statistical
disclosure limitation based on rank swapping with one based on differential
privacy (DP). This has resulted in substantial accuracy loss of the released
statistics. Worse yet, it has been shown that the reconstruction attacks used
as an argument to move to DP are very far from allowing unequivocal
reidentification of the respondents, because in general there are a lot of
reconstructions compatible with the released statistics. In a very recent
paper, a new reconstruction attack has been proposed, whose goal is to indicate
the confidence that a reconstructed record was in the original respondent data.
The alleged risk of serious disclosure entailed by such confidence-ranked
reconstruction has renewed the interest of the USCB to use DP-based solutions.
To forestall the potential accuracy loss in future data releases resulting from
adoption of these solutions, we show in this paper that the proposed
confidence-ranked reconstruction does not threaten privacy. Specifically, we
report empirical results showing that the proposed ranking cannot guide
reidentification or attribute disclosure attacks, and hence it fails to warrant
the USCB's move towards DP. Further, we also demonstrate that, due to the way
the Census data are compiled, processed and released, it is not possible to
reconstruct original and complete records through any methodology, and the
confidence-ranked reconstruction not only is completely ineffective at
accurately reconstructing Census records but is trivially outperformed by an
adequate interpretation of the released aggregate statistics.
</p>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03172" title="Abstract">arXiv:2311.03172</a> [<a href="/pdf/2311.03172" title="Download PDF">pdf</a>, <a href="/format/2311.03172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preserving Privacy in GANs Against Membership Inference Attack
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shateri%2C+M">Mohammadhadi Shateri</a>, 
<a href="/search/cs?searchtype=author&query=Messina%2C+F">Francisco Messina</a>, 
<a href="/search/cs?searchtype=author&query=Labeau%2C+F">Fabrice Labeau</a>, 
<a href="/search/cs?searchtype=author&query=Piantanida%2C+P">Pablo Piantanida</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Signal Processing (eess.SP)

</div>
<p class="mathjax">Generative Adversarial Networks (GANs) have been widely used for generating
synthetic data for cases where there is a limited size real-world dataset or
when data holders are unwilling to share their data samples. Recent works
showed that GANs, due to overfitting and memorization, might leak information
regarding their training data samples. This makes GANs vulnerable to Membership
Inference Attacks (MIAs). Several defense strategies have been proposed in the
literature to mitigate this privacy issue. Unfortunately, defense strategies
based on differential privacy are proven to reduce extensively the quality of
the synthetic data points. On the other hand, more recent frameworks such as
PrivGAN and PAR-GAN are not suitable for small-size training datasets. In the
present work, the overfitting in GANs is studied in terms of the discriminator,
and a more general measure of overfitting based on the Bhattacharyya
coefficient is defined. Then, inspired by Fano's inequality, our first defense
mechanism against MIAs is proposed. This framework, which requires only a
simple modification in the loss function of GANs, is referred to as the maximum
entropy GAN or MEGAN and significantly improves the robustness of GANs to MIAs.
As a second defense strategy, a more heuristic model based on minimizing the
information leaked from generated samples about the training data points is
presented. This approach is referred to as mutual information minimization GAN
(MIMGAN) and uses a variational representation of the mutual information to
minimize the information that a synthetic sample might leak about the whole
training data set. Applying the proposed frameworks to some commonly used data
sets against state-of-the-art MIAs reveals that the proposed methods can reduce
the accuracy of the adversaries to the level of random guessing accuracy with a
small reduction in the quality of the synthetic data samples.
</p>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03174" title="Abstract">arXiv:2311.03174</a> [<a href="/pdf/2311.03174" title="Download PDF">pdf</a>, <a href="/ps/2311.03174" title="Download PostScript">ps</a>, <a href="/format/2311.03174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incremental Approximate Maximum Flow on Undirected Graphs in  Subpolynomial Update Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+den+Brand%2C+J">Jan van den Brand</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kyng%2C+R">Rasmus Kyng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y+P">Yang P. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+R">Richard Peng</a>, 
<a href="/search/cs?searchtype=author&query=Gutenberg%2C+M+P">Maximilian Probst Gutenberg</a>, 
<a href="/search/cs?searchtype=author&query=Sachdeva%2C+S">Sushant Sachdeva</a>, 
<a href="/search/cs?searchtype=author&query=Sidford%2C+A">Aaron Sidford</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, SODA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We provide an algorithm which, with high probability, maintains a
$(1-\epsilon)$-approximate maximum flow on an undirected graph undergoing
$m$-edge additions in amortized $m^{o(1)} \epsilon^{-3}$ time per update. To
obtain this result, we provide a more general algorithm that solves what we
call the incremental, thresholded $p$-norm flow problem that asks to determine
the first edge-insertion in an undirected graph that causes the minimum
$\ell_p$-norm flow to decrease below a given threshold in value. Since we solve
this thresholded problem, our data structure succeeds against an adaptive
adversary that can only see the data structure's output. Furthermore, since our
algorithm holds for $p = 2$, we obtain improved algorithms for dynamically
maintaining the effective resistance between a pair of vertices in an
undirected graph undergoing edge insertions.
<br />Our algorithm builds upon previous dynamic algorithms for approximately
solving the minimum-ratio cycle problem that underlie previous advances on the
maximum flow problem [Chen-Kyng-Liu-Peng-Probst Gutenberg-Sachdeva, FOCS '22]
as well as recent dynamic maximum flow algorithms [v.d.Brand-Liu-Sidford, STOC
'23]. Instead of using interior point methods, which were a key component of
these recent advances, our algorithm uses an optimization method based on
$\ell_p$-norm iterative refinement and the multiplicative weight update method.
This ensures a monotonicity property in the minimum-ratio cycle subproblems
that allows us to apply known data structures and bypass issues arising from
adaptive queries.
</p>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03177" title="Abstract">arXiv:2311.03177</a> [<a href="/pdf/2311.03177" title="Download PDF">pdf</a>, <a href="/format/2311.03177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 1D-Convolutional transformer for Parkinson disease diagnosis from gait
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naimi%2C+S">Safwen Naimi</a>, 
<a href="/search/cs?searchtype=author&query=Bouachir%2C+W">Wassim Bouachir</a>, 
<a href="/search/cs?searchtype=author&query=Bilodeau%2C+G">Guillaume-Alexandre Bilodeau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 Figures, 6 Tables. Accepted for publication in Neural Computing and Applications (NCAA) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents an efficient deep neural network model for diagnosing
Parkinson's disease from gait. More specifically, we introduce a hybrid
ConvNet-Transformer architecture to accurately diagnose the disease by
detecting the severity stage. The proposed architecture exploits the strengths
of both Convolutional Neural Networks and Transformers in a single end-to-end
model, where the former is able to extract relevant local features from
Vertical Ground Reaction Force (VGRF) signal, while the latter allows to
capture long-term spatio-temporal dependencies in data. In this manner, our
hybrid architecture achieves an improved performance compared to using either
models individually. Our experimental results show that our approach is
effective for detecting the different stages of Parkinson's disease from gait
data, with a final accuracy of 88%, outperforming other state-of-the-art AI
methods on the Physionet gait dataset. Moreover, our method can be generalized
and adapted for other classification problems to jointly address the feature
relevance and spatio-temporal dependency problems in 1D signals. Our source
code and pre-trained models are publicly available at
https://github.com/SafwenNaimi/1D-Convolutional-transformer-for-Parkinson-disease-diagnosis-from-gait.
</p>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03178" title="Abstract">arXiv:2311.03178</a> [<a href="/pdf/2311.03178" title="Download PDF">pdf</a>, <a href="/ps/2311.03178" title="Download PostScript">ps</a>, <a href="/format/2311.03178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of the sparse super resolution limit using the Cram&#xe9;r-Rao  lower bound
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hockmann%2C+M">Mathias Hockmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Already since the work by Abbe and Rayleigh the difficulty of super
resolution where one wants to recover a collection of point sources from
low-resolved microscopy measurements is thought to be dependent on whether the
distance between the sources is below or above a certain resolution or
diffraction limit. Even though there has been a number of approaches to define
this limit more rigorously, there is still a gap between the situation where
the task is known to be hard and scenarios where the task is provably simpler.
For instance, an interesting approach for the univariate case using the size of
the Cram\'er-Rao lower bound was introduced in a recent work by Ferreira Da
Costa and Mitra. In this paper, we prove their conjecture on the transition
point between good and worse tractability of super resolution and extend it to
higher dimensions. Specifically, the bivariate statistical analysis allows to
link the findings by the Cram\'er-Rao lower bound to the classical Rayleigh
limit.
</p>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03179" title="Abstract">arXiv:2311.03179</a> [<a href="/pdf/2311.03179" title="Download PDF">pdf</a>, <a href="/format/2311.03179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ArAIEval Shared Task: Persuasion Techniques and Disinformation Detection  in Arabic Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hasanain%2C+M">Maram Hasanain</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+F">Firoj Alam</a>, 
<a href="/search/cs?searchtype=author&query=Mubarak%2C+H">Hamdy Mubarak</a>, 
<a href="/search/cs?searchtype=author&query=Abdaljalil%2C+S">Samir Abdaljalil</a>, 
<a href="/search/cs?searchtype=author&query=Zaghouani%2C+W">Wajdi Zaghouani</a>, 
<a href="/search/cs?searchtype=author&query=Nakov%2C+P">Preslav Nakov</a>, 
<a href="/search/cs?searchtype=author&query=Da+San+Martino%2C+G">Giovanni Da San Martino</a>, 
<a href="/search/cs?searchtype=author&query=Freihat%2C+A+A">Abed Alhakim Freihat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ArabicNLP-23 (EMNLP-23), propaganda, disinformation, misinformation, fake news
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present an overview of the ArAIEval shared task, organized as part of the
first ArabicNLP 2023 conference co-located with EMNLP 2023. ArAIEval offers two
tasks over Arabic text: (i) persuasion technique detection, focusing on
identifying persuasion techniques in tweets and news articles, and (ii)
disinformation detection in binary and multiclass setups over tweets. A total
of 20 teams participated in the final evaluation phase, with 14 and 16 teams
participating in Tasks 1 and 2, respectively. Across both tasks, we observed
that fine-tuning transformer models such as AraBERT was at the core of the
majority of the participating systems. We provide a description of the task
setup, including a description of the dataset construction and the evaluation
setup. We further give a brief overview of the participating systems. All
datasets and evaluation scripts from the shared task are released to the
research community. (https://araieval.gitlab.io/) We hope this will enable
further research on these important tasks in Arabic.
</p>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03184" title="Abstract">arXiv:2311.03184</a> [<a href="/pdf/2311.03184" title="Download PDF">pdf</a>, <a href="/format/2311.03184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nexus at ArAIEval Shared Task: Fine-Tuning Arabic Language Models for  Propaganda and Disinformation Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yunze Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+F">Firoj Alam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> propaganda, disinformation, misinformation, fake news
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">The spread of disinformation and propagandistic content poses a threat to
societal harmony, undermining informed decision-making and trust in reliable
sources. Online platforms often serve as breeding grounds for such content, and
malicious actors exploit the vulnerabilities of audiences to shape public
opinion. Although there have been research efforts aimed at the automatic
identification of disinformation and propaganda in social media content, there
remain challenges in terms of performance. The ArAIEval shared task aims to
further research on these particular issues within the context of the Arabic
language. In this paper, we discuss our participation in these shared tasks. We
competed in subtasks 1A and 2A, where our submitted system secured positions
9th and 10th, respectively. Our experiments consist of fine-tuning transformer
models and using zero- and few-shot learning with GPT-4.
</p>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03186" title="Abstract">arXiv:2311.03186</a> [<a href="/pdf/2311.03186" title="Download PDF">pdf</a>, <a href="/format/2311.03186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-based Counterfactual Generator for Gender Bias Mitigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tokpo%2C+E+K">Ewoenam Kwaku Tokpo</a>, 
<a href="/search/cs?searchtype=author&query=Calders%2C+T">Toon Calders</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Counterfactual Data Augmentation (CDA) has been one of the preferred
techniques for mitigating gender bias in natural language models. CDA
techniques have mostly employed word substitution based on dictionaries.
Although such dictionary-based CDA techniques have been shown to significantly
improve the mitigation of gender bias, in this paper, we highlight some
limitations of such dictionary-based counterfactual data augmentation
techniques, such as susceptibility to ungrammatical compositions, and lack of
generalization outside the set of predefined dictionary words. Model-based
solutions can alleviate these problems, yet the lack of qualitative parallel
training data hinders development in this direction. Therefore, we propose a
combination of data processing techniques and a bi-objective training regime to
develop a model-based solution for generating counterfactuals to mitigate
gender bias. We implemented our proposed solution and performed an empirical
evaluation which shows how our model alleviates the shortcomings of
dictionary-based solutions.
</p>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03189" title="Abstract">arXiv:2311.03189</a> [<a href="/pdf/2311.03189" title="Download PDF">pdf</a>, <a href="/format/2311.03189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Control for Soft-Rigid Robots with Self-Contact using Control  Barrier Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patterson%2C+Z+J">Zach J. Patterson</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+W">Wei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Sologuren%2C+E">Emily Sologuren</a>, 
<a href="/search/cs?searchtype=author&query=Rus%2C+D">Daniela Rus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures, submitted to IEEE Robosoft 2024 Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Incorporating both flexible and rigid components in robot designs offers a
unique solution to the limitations of traditional rigid robotics by enabling
both compliance and strength. This paper explores the challenges and solutions
for controlling soft-rigid hybrid robots, particularly addressing the issue of
self-contact. Conventional control methods prioritize precise state tracking,
inadvertently increasing the system's overall stiffness, which is not always
desirable in interactions with the environment or within the robot itself. To
address this, we investigate the application of Control Barrier Functions
(CBFs) and High Order CBFs to manage self-contact scenarios in serially
connected soft-rigid hybrid robots. Through an analysis based on Piecewise
Constant Curvature (PCC) kinematics, we establish CBFs within a classical
control framework for self-contact dynamics. Our methodology is rigorously
evaluated in both simulation environments and physical hardware systems. The
findings demonstrate that our proposed control strategy effectively regulates
self-contact in soft-rigid hybrid robotic systems, marking a significant
advancement in the field of robotics.
</p>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03191" title="Abstract">arXiv:2311.03191</a> [<a href="/pdf/2311.03191" title="Download PDF">pdf</a>, <a href="/format/2311.03191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepInception: Hypnotize Large Language Model to Be Jailbreaker
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhanke Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jianing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiangchao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tongliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bo Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Despite remarkable success in various applications, large language models
(LLMs) are vulnerable to adversarial jailbreaks that make the safety guardrails
void. However, previous studies for jailbreaks usually resort to brute-force
optimization or extrapolations of a high computation cost, which might not be
practical or effective. In this paper, inspired by the Milgram experiment that
individuals can harm another person if they are told to do so by an
authoritative figure, we disclose a lightweight method, termed as
DeepInception, which can easily hypnotize LLM to be a jailbreaker and unlock
its misusing risks. Specifically, DeepInception leverages the personification
ability of LLM to construct a novel nested scene to behave, which realizes an
adaptive way to escape the usage control in a normal scenario and provides the
possibility for further direct jailbreaks. Empirically, we conduct
comprehensive experiments to show its efficacy. Our DeepInception can achieve
competitive jailbreak success rates with previous counterparts and realize a
continuous jailbreak in subsequent interactions, which reveals the critical
weakness of self-losing on both open/closed-source LLMs like Falcon, Vicuna,
Llama-2, and GPT-3.5/4/4V. Our investigation appeals that people should pay
more attention to the safety aspects of LLMs and a stronger defense against
their misuse risks. The code is publicly available at:
https://github.com/tmlr-group/DeepInception.
</p>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03192" title="Abstract">arXiv:2311.03192</a> [<a href="/pdf/2311.03192" title="Download PDF">pdf</a>, <a href="/format/2311.03192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modelling and Optimization Based Control for Demand Response in Active  Distribution Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Aryandoust%2C+A">Arsam Aryandoust</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">We explore how Demand Response (DR) can effectively provide electricity
system services such as for the management of bi-directional power flows and
the control of voltage deviations in active distribution networks, without
compromising consumer comfort or adversely affecting grid operation in the
transmission network. By translating intricate power system physics into
straightforward control objectives, we design DR control algorithms that can
operate within realistic computational timeframes at scale. We conduct
simulation-based experiments and find that minimizing the Euclidean-Norm of the
total residual load at transformer sub-stations is an effective objective for
harnessing DR for dispatching highly renewable grids. We show that this control
objective can be effectively achieved without optimal power flow calculations
or knowledge about the topology of a grid. Additionally, we find that pursuing
this objective reduces the sum of peak power flows along all lines in an active
distribution network and therefore provides not only smaller voltage
deviations, but also lower transmission losses.
</p>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03194" title="Abstract">arXiv:2311.03194</a> [<a href="/pdf/2311.03194" title="Download PDF">pdf</a>, <a href="/ps/2311.03194" title="Download PostScript">ps</a>, <a href="/format/2311.03194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-shot Learning using Data Augmentation and Time-Frequency  Transformation for Time Series Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+Z">Zhendong Pang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiangpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Teng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep neural networks (DNNs) that tackle the time series classification (TSC)
task have provided a promising framework in signal processing. In real-world
applications, as a data-driven model, DNNs are suffered from insufficient data.
Few-shot learning has been studied to deal with this limitation. In this paper,
we propose a novel few-shot learning framework through data augmentation, which
involves transformation through the time-frequency domain and the generation of
synthetic images through random erasing. Additionally, we develop a
sequence-spectrogram neural network (SSNN). This neural network model composes
of two sub-networks: one utilizing 1D residual blocks to extract features from
the input sequence while the other one employing 2D residual blocks to extract
features from the spectrogram representation. In the experiments, comparison
studies of different existing DNN models with/without data augmentation are
conducted on an amyotrophic lateral sclerosis (ALS) dataset and a wind turbine
fault (WTF) dataset. The experimental results manifest that our proposed method
achieves 93.75% F1 score and 93.33% accuracy on the ALS datasets while 95.48%
F1 score and 95.59% accuracy on the WTF datasets. Our methodology demonstrates
its applicability of addressing the few-shot problems for time series
classification.
</p>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03196" title="Abstract">arXiv:2311.03196</a> [<a href="/pdf/2311.03196" title="Download PDF">pdf</a>, <a href="/format/2311.03196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pseudo-Labeling for Domain-Agnostic Bangla Automatic Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nandi%2C+R+N">Rabindra Nath Nandi</a>, 
<a href="/search/cs?searchtype=author&query=Menon%2C+M+H">Mehadi Hasan Menon</a>, 
<a href="/search/cs?searchtype=author&query=Muntasir%2C+T+A">Tareq Al Muntasir</a>, 
<a href="/search/cs?searchtype=author&query=Sarker%2C+S">Sagor Sarker</a>, 
<a href="/search/cs?searchtype=author&query=Muhtaseem%2C+Q+S">Quazi Sarwar Muhtaseem</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+T">Md. Tariqul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+S+A">Shammur Absar Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+F">Firoj Alam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at BLP-2023 (at EMNLP 2023), ASR, low-resource, out-of-distribution, domain-agnostic
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">One of the major challenges for developing automatic speech recognition (ASR)
for low-resource languages is the limited access to labeled data with
domain-specific variations. In this study, we propose a pseudo-labeling
approach to develop a large-scale domain-agnostic ASR dataset. With the
proposed methodology, we developed a 20k+ hours labeled Bangla speech dataset
covering diverse topics, speaking styles, dialects, noisy environments, and
conversational scenarios. We then exploited the developed corpus to design a
conformer-based ASR system. We benchmarked the trained ASR with publicly
available datasets and compared it with other available models. To investigate
the efficacy, we designed and developed a human-annotated domain-agnostic test
set composed of news, telephony, and conversational data among others. Our
results demonstrate the efficacy of the model trained on psuedo-label data for
the designed test-set along with publicly-available Bangla datasets. The
experimental resources will be publicly
available.(https://github.com/hishab-nlp/Pseudo-Labeling-for-Domain-Agnostic-Bangla-ASR)
</p>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03197" title="Abstract">arXiv:2311.03197</a> [<a href="/pdf/2311.03197" title="Download PDF">pdf</a>, <a href="/format/2311.03197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable Linear Subspace Identification: A Machine Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Di+Natale%2C+L">Loris Di Natale</a>, 
<a href="/search/eess?searchtype=author&query=Zakwan%2C+M">Muhammad Zakwan</a>, 
<a href="/search/eess?searchtype=author&query=Svetozarevic%2C+B">Bratislav Svetozarevic</a>, 
<a href="/search/eess?searchtype=author&query=Heer%2C+P">Philipp Heer</a>, 
<a href="/search/eess?searchtype=author&query=Trecate%2C+G+F">Giancarlo Ferrari Trecate</a>, 
<a href="/search/eess?searchtype=author&query=Jones%2C+C+N">Colin N. Jones</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ECC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine Learning (ML) and linear System Identification (SI) have been
historically developed independently. In this paper, we leverage
well-established ML tools - especially the automatic differentiation framework
- to introduce SIMBa, a family of discrete linear multi-step-ahead state-space
SI methods using backpropagation. SIMBa relies on a novel
Linear-Matrix-Inequality-based free parametrization of Schur matrices to ensure
the stability of the identified model.
<br />We show how SIMBa generally outperforms traditional linear state-space SI
methods, and sometimes significantly, although at the price of a higher
computational burden. This performance gap is particularly remarkable compared
to other SI methods with stability guarantees, where the gain is frequently
above 25% in our investigations, hinting at SIMBa's ability to simultaneously
achieve state-of-the-art fitting performance and enforce stability.
Interestingly, these observations hold for a wide variety of input-output
systems and on both simulated and real-world data, showcasing the flexibility
of the proposed approach. We postulate that this new SI paradigm presents a
great extension potential to identify structured nonlinear models from data,
and we hence open-source SIMBa on https://github.com/Cemempamoi/simba.
</p>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03198" title="Abstract">arXiv:2311.03198</a> [<a href="/pdf/2311.03198" title="Download PDF">pdf</a>, <a href="/format/2311.03198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LCPR: A Multi-Scale Attention-Based LiDAR-Camera Fusion Network for  Place Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zijie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jingyi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+G">Guangming Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Junyi Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Robotics and Automation Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Place recognition is one of the most crucial modules for autonomous vehicles
to identify places that were previously visited in GPS-invalid environments.
Sensor fusion is considered an effective method to overcome the weaknesses of
individual sensors. In recent years, multimodal place recognition fusing
information from multiple sensors has gathered increasing attention. However,
most existing multimodal place recognition methods only use limited
field-of-view camera images, which leads to an imbalance between features from
different modalities and limits the effectiveness of sensor fusion. In this
paper, we present a novel neural network named LCPR for robust multimodal place
recognition, which fuses LiDAR point clouds with multi-view RGB images to
generate discriminative and yaw-rotation invariant representations of the
environment. A multi-scale attention-based fusion module is proposed to fully
exploit the panoramic views from different modalities of the environment and
their correlations. We evaluate our method on the nuScenes dataset, and the
experimental results show that our method can effectively utilize multi-view
camera and LiDAR data to improve the place recognition performance while
maintaining strong robustness to viewpoint changes. Our open-source code and
pre-trained models are available at https://github.com/ZhouZijie77/LCPR .
</p>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03205" title="Abstract">arXiv:2311.03205</a> [<a href="/pdf/2311.03205" title="Download PDF">pdf</a>, <a href="/format/2311.03205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PainSeeker: An Automated Method for Assessing Pain in Rats Through  Facial Expressions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Liu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guang Li</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+D">Dingfan Deng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jinhua Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+Y">Yuan Zong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this letter, we aim to investigate whether laboratory rats' pain can be
automatically assessed through their facial expressions. To this end, we began
by presenting a publicly available dataset called RatsPain, consisting of 1,138
facial images captured from six rats that underwent an orthodontic treatment
operation. Each rat' facial images in RatsPain were carefully selected from
videos recorded either before or after the operation and well labeled by eight
annotators according to the Rat Grimace Scale (RGS). We then proposed a novel
deep learning method called PainSeeker for automatically assessing pain in rats
via facial expressions. PainSeeker aims to seek pain-related facial local
regions that facilitate learning both pain discriminative and head pose robust
features from facial expression images. To evaluate the PainSeeker, we
conducted extensive experiments on the RatsPain dataset. The results
demonstrate the feasibility of assessing rats' pain from their facial
expressions and also verify the effectiveness of the proposed PainSeeker in
addressing this emerging but intriguing problem. The RasPain dataset can be
freely obtained from https://github.com/xhzongyuan/RatsPain.
</p>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03206" title="Abstract">arXiv:2311.03206</a> [<a href="/pdf/2311.03206" title="Download PDF">pdf</a>, <a href="/format/2311.03206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 5G-CT: Automated Deployment and Over-the-Air Testing of End-to-End Open  Radio Access Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bonati%2C+L">Leonardo Bonati</a>, 
<a href="/search/cs?searchtype=author&query=Polese%2C+M">Michele Polese</a>, 
<a href="/search/cs?searchtype=author&query=D%27Oro%2C+S">Salvatore D&#x27;Oro</a>, 
<a href="/search/cs?searchtype=author&query=del+Prever%2C+P+B">Pietro Brach del Prever</a>, 
<a href="/search/cs?searchtype=author&query=Melodia%2C+T">Tommaso Melodia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures, 1 listing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Deploying and testing cellular networks is a complex task due to the
multitude of components involved-from the core to the Radio Access Network
(RAN) and the User Equipments (UEs) -- all of which require integration and
constant monitoring. Interference and the inherent randomness of the wireless
channel further complicate the issue, posing additional challenges for
repeatable and consistent testing. Consequently, both private and public
cellular systems still rely heavily on human intervention for operations such
as network reconfiguration, performance monitoring, and conducting end-to-end
drive tests. This reliance significantly slows the pace of innovation in
cellular systems.
<br />To address these challenges, we introduce 5G-CT, an automation framework
based on OpenShift and the GitOps workflow, capable of deploying a softwarized
end-to-end 5G and O-RAN-compliant system in a matter of seconds. We have
deployed 5G-CT to test the integration and performance of popular open-source
cellular stacks, including OpenAirInterface (OAI), and have collected months of
over-the-air testing results without the need for human intervention. 5G-CT
brings cloud-native Continuous Integration (CI) and Continuous Delivery (CD) to
the RAN, effectively addressing the complexities associated with managing
spectrum, radios, heterogeneous devices, and distributed components. Moreover,
it provides much-needed automation and Continuous Testing (CT) for cellular
networks.
</p>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03207" title="Abstract">arXiv:2311.03207</a> [<a href="/pdf/2311.03207" title="Download PDF">pdf</a>, <a href="/format/2311.03207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Homogenization of Foil Windings with Globally Supported Polynomial Shape  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bundschuh%2C+J">Jonas Bundschuh</a>, 
<a href="/search/cs?searchtype=author&query=Sp%C3%A4ck-Leigsnering%2C+Y">Yvonne Sp&#xe4;ck-Leigsnering</a>, 
<a href="/search/cs?searchtype=author&query=De+Gersem%2C+H">Herbert De Gersem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 Pages. 8 Figures. Accepted for publication at Archives of Electrical Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">In conventional finite element simulations, foil windings with thin foils and
with a large number of turns require many mesh elements. This renders models
quickly computationally infeasible. This paper uses a homogenized foil winding
model and approximates the voltage distribution in the foil winding domain by
globally supported polynomials. This way, the small-scale structure in the foil
winding domain does not have to be resolved by the finite element mesh. The
method is validated successfully for a stand-alone foil winding example and for
a pot inductor example. Moreover, a transformer equipped with a foil winding at
its primary side is simulated using a field-circuit coupled model.
</p>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03210" title="Abstract">arXiv:2311.03210</a> [<a href="/pdf/2311.03210" title="Download PDF">pdf</a>, <a href="/format/2311.03210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Task Offloading with the OpenMP API
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+K+L">Joseph K. L. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+O+T">Oliver T. Brown</a>, 
<a href="/search/cs?searchtype=author&query=Bull%2C+M">Mark Bull</a>, 
<a href="/search/cs?searchtype=author&query=Ruefenacht%2C+M">Martin Ruefenacht</a>, 
<a href="/search/cs?searchtype=author&query=Doerfert%2C+J">Johannes Doerfert</a>, 
<a href="/search/cs?searchtype=author&query=Klemm%2C+M">Michael Klemm</a>, 
<a href="/search/cs?searchtype=author&query=Schulz%2C+M">Martin Schulz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Poster extended abstract for Supercomputing 2023 (SC23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Most of the widely used quantum programming languages and libraries are not
designed for the tightly coupled nature of hybrid quantum-classical algorithms,
which run on quantum resources that are integrated on-premise with classical
HPC infrastructure. We propose a programming model using the API provided by
OpenMP to target quantum devices, which provides an easy-to-use and efficient
interface for HPC applications to utilize quantum compute resources. We have
implemented a variational quantum eigensolver using the programming model,
which has been tested using a classical simulator. We are in the process of
testing on the quantum resources hosted at the Leibniz Supercomputing Centre
(LRZ).
</p>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03212" title="Abstract">arXiv:2311.03212</a> [<a href="/pdf/2311.03212" title="Download PDF">pdf</a>, <a href="/ps/2311.03212" title="Download PostScript">ps</a>, <a href="/format/2311.03212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing a Hair-Clip Inspired Bistable Mechanism for Soft Fish Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zechen Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Lipson%2C+H">Hod Lipson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The Hair clip mechanism (HCM) is an in-plane prestressed bistable mechanism
proposed in our previous research [1]~[5] to enhance the functionality of soft
robotics. HCMs have several advantages, such as high rigidity, high mobility,
good repeatability, and design and fabrication simplicity, compared to existing
soft and compliant robotics. Using our experience with fish robots, this work
delves into designing a novel HCM robotic propulsion system made from PETG
plastic, carbon fiber-reinforced plastic (CFRP), and steel. Detailed derivation
and verification of the HCM theory are given, and the influence of key
parameters like dimensions, material types, and servo motor specifications are
summarized. The designing algorithm offers insight into HCM robotics. It
enables us to search for suitable components, operate robots at a desired
frequency, and achieve high-frequency and high-speed undulatory swimming for
fish robots.
</p>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03213" title="Abstract">arXiv:2311.03213</a> [<a href="/pdf/2311.03213" title="Download PDF">pdf</a>, <a href="/format/2311.03213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing the Maturity of Model Maintenance Techniques for AIOps  Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Y">Yingzhe Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Heng Li</a>, 
<a href="/search/cs?searchtype=author&query=Ming%2C+Z">Zhen Ming</a> (Jack)
<a href="/search/cs?searchtype=author&query=Jiang">Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Hassan%2C+A+E">Ahmed E. Hassan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">AIOps (Artificial Intelligence for IT Operations) solutions leverage the
massive data produced during the operations of large-scale systems and machine
learning models to assist software engineers in their system operations. As
operation data produced in the field are subject to constant evolution from
factors like the changing operational environment and user base, the models in
AIOps solutions need to be constantly maintained after deployment. While prior
works focus on innovative modeling techniques to improve the performance of
AIOps models before releasing them into the field, when and how to maintain
AIOps models remain an under-investigated topic. In this work, we performed a
case study on three large-scale public operation data to assess different model
maintenance approaches regarding their performance, maintenance cost, and
stability. We observed that active model maintenance approaches achieve better
and more stable performance than a stationary approach. Particularly, applying
sophisticated model maintenance approaches (e.g., concept drift detection,
time-based ensembles, or online learning approaches) could provide better
performance, efficiency, and stability than simply retraining AIOps models
periodically. In addition, we observed that, although some maintenance
approaches (e.g., time-based ensemble and online learning) can save model
training time, they significantly sacrifice model testing time, which could
hinder their applications in AIOps solutions where the operation data arrive at
high speed and volume and where instant predictions are required. Our findings
highlight that practitioners should consider the evolution of operation data
and actively maintain AIOps models over time. Our observations can also guide
researchers and practitioners to investigate more efficient and effective model
maintenance techniques that fit in the context of AIOps.
</p>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03216" title="Abstract">arXiv:2311.03216</a> [<a href="/pdf/2311.03216" title="Download PDF">pdf</a>, <a href="/format/2311.03216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mini Minds: Exploring Bebeshka and Zlata Baby Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Proskurina%2C+I">Irina Proskurina</a>, 
<a href="/search/cs?searchtype=author&query=Metzler%2C+G">Guillaume Metzler</a>, 
<a href="/search/cs?searchtype=author&query=Velcin%2C+J">Julien Velcin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CoNLL 2023 BabyLM Challenge
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we describe the University of Lyon 2 submission to the
Strict-Small track of the BabyLM competition. The shared task is created with
an emphasis on small-scale language modelling from scratch on limited-size data
and human language acquisition. Dataset released for the Strict-Small track has
10M words, which is comparable to children's vocabulary size. We approach the
task with an architecture search, minimizing masked language modelling loss on
the data of the shared task. Having found an optimal configuration, we
introduce two small-size language models (LMs) that were submitted for
evaluation, a 4-layer encoder with 8 attention heads and a 6-layer decoder
model with 12 heads which we term Bebeshka and Zlata, respectively. Despite
being half the scale of the baseline LMs, our proposed models achieve
comparable performance. We further explore the applicability of small-scale
language models in tasks involving moral judgment, aligning their predictions
with human values. These findings highlight the potential of compact LMs in
addressing practical language understanding tasks.
</p>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03220" title="Abstract">arXiv:2311.03220</a> [<a href="/pdf/2311.03220" title="Download PDF">pdf</a>, <a href="/format/2311.03220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ALYMPICS: Language Agents Meet Game Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+S">Shaoguang Mao</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yuzhe Cai</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenshan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fengyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+T">Tao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Furu Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">This paper introduces Alympics, a platform that leverages Large Language
Model (LLM) agents to facilitate investigations in game theory. By employing
LLMs and autonomous agents to simulate human behavior and enable multi-agent
collaborations, we can construct realistic and dynamic models of human
interactions for game theory hypothesis formulating and testing. To demonstrate
this, we present and implement a survival game involving unequal competition
for limited resources. Through manipulation of resource availability and agent
personalities, we observe how different agents engage in the competition and
adapt their strategies. The use of LLM agents in game theory research offers
significant advantages, including simulating realistic behavior, providing a
controlled, scalable, and reproducible environment. Our work highlights the
potential of LLM agents in enhancing the understanding of strategic
decision-making within complex socioeconomic contexts. All codes will be made
public soon.
</p>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03221" title="Abstract">arXiv:2311.03221</a> [<a href="/pdf/2311.03221" title="Download PDF">pdf</a>, <a href="/format/2311.03221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segmentation of Drone Collision Hazards in Airborne RADAR Point Clouds  Using PointNet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arroyo%2C+H">Hector Arroyo</a>, 
<a href="/search/cs?searchtype=author&query=Kier%2C+P">Paul Kier</a>, 
<a href="/search/cs?searchtype=author&query=Angus%2C+D">Dylan Angus</a>, 
<a href="/search/cs?searchtype=author&query=Matalonga%2C+S">Santiago Matalonga</a>, 
<a href="/search/cs?searchtype=author&query=Georgiev%2C+S">Svetlozar Georgiev</a>, 
<a href="/search/cs?searchtype=author&query=Goli%2C+M">Mehdi Goli</a>, 
<a href="/search/cs?searchtype=author&query=Dooly%2C+G">Gerard Dooly</a>, 
<a href="/search/cs?searchtype=author&query=Riordan%2C+J">James Riordan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 13 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The integration of unmanned aerial vehicles (UAVs) into shared airspace for
beyond visual line of sight (BVLOS) operations presents significant challenges
but holds transformative potential for sectors like transportation,
construction, energy and defense. A critical prerequisite for this integration
is equipping UAVs with enhanced situational awareness to ensure safe
operations. Current approaches mainly target single object detection or
classification, or simpler sensing outputs that offer limited perceptual
understanding and lack the rapid end-to-end processing needed to convert sensor
data into safety-critical insights. In contrast, our study leverages radar
technology for novel end-to-end semantic segmentation of aerial point clouds to
simultaneously identify multiple collision hazards. By adapting and optimizing
the PointNet architecture and integrating aerial domain insights, our framework
distinguishes five distinct classes: mobile drones (DJI M300 and DJI Mini) and
airplanes (Ikarus C42), and static returns (ground and infrastructure) which
results in enhanced situational awareness for UAVs. To our knowledge, this is
the first approach addressing simultaneous identification of multiple collision
threats in an aerial setting, achieving a robust 94% accuracy. This work
highlights the potential of radar technology to advance situational awareness
in UAVs, facilitating safe and efficient BVLOS operations.
</p>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03223" title="Abstract">arXiv:2311.03223</a> [<a href="/pdf/2311.03223" title="Download PDF">pdf</a>, <a href="/ps/2311.03223" title="Download PostScript">ps</a>, <a href="/format/2311.03223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CarbonFish -- A Bistable Underactuated Compliant Fish Robot capable of  High Frequency Undulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zechen Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Lipson%2C+H">Hod Lipson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The Hair Clip Mechanism HCM represents an innovative in plane prestressed
bistable mechanism, as delineated in our preceding studies, devised to augment
the functional prowess of soft robotics. When juxtaposed with conventional soft
and compliant robotic systems, HCMs exhibit pronounced rigidity, augmented
mobility, reproducible repeatability, and an effective design and fabrication
paradigm. In this research, we investigate the feasibility of utilizing carbon
fiber reinforced plastic CFRP as the foundational material for an HCM based
fish robot, herein referred to as CarbonFish. Our objective centers on
realizing high frequency undulatory motion, thereby laying the groundwork for
accelerated aquatic locomotion in subsequent models. We proffer an exhaustive
design and fabrication schema underpinned by mathematical principles.
Preliminary evaluations of our single actuated CarbonFish have evidenced an
undulation frequency approaching 10 Hz, suggesting its potential to outperform
other biologically inspired aquatic entities as well as real fish.
</p>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03224" title="Abstract">arXiv:2311.03224</a> [<a href="/pdf/2311.03224" title="Download PDF">pdf</a>, <a href="/ps/2311.03224" title="Download PostScript">ps</a>, <a href="/format/2311.03224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Risk Analysis in the Selection of Project Managers Based on ANP and FMEA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Asaadi%2C+A">Armin Asaadi</a>, 
<a href="/search/cs?searchtype=author&query=Atrian%2C+A">Armita Atrian</a>, 
<a href="/search/cs?searchtype=author&query=Hoseini%2C+H+N">Hesam Nik Hoseini</a>, 
<a href="/search/cs?searchtype=author&query=Movahedi%2C+M+M">Mohammad Mahdi Movahedi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Risk Management (q-fin.RM)

</div>
<p class="mathjax">Project managers play a crucial role in the success of projects. The
selection of an appropriate project manager is a primary concern for senior
managers in firms. Typically, this process involves candidate interviews and
assessments of their abilities. There are various criteria for selecting a
project manager, and the importance of each criterion depends on the project
type, its conditions, and the risks associated with their absence in the chosen
candidate. Often, senior managers in engineering companies lack awareness of
the significance of these criteria and the potential risks linked to their
absence. This research aims to identify these risks in selecting project
managers for civil engineering projects, utilizing a combined ANP-FMEA
approach. Through a comprehensive literature review, five risk categories have
been identified: individual skills, power-related issues, knowledge and
expertise, experience, and personality traits. Subsequently, these risks, along
with their respective sub-criteria and internal relationships, were analysed
using the combined ANP-FMEA technique. The results highlighted that the lack of
political influence, absence of construction experience, and deficiency in
project management expertise represent the most substantial risks in selecting
a project manager. Moreover, upon comparison with the traditional FMEA
approach, this study demonstrates the superior ability of the ANP-FMEA model in
differentiating risks and pinpointing factors with elevated risk levels.
</p>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03225" title="Abstract">arXiv:2311.03225</a> [<a href="/pdf/2311.03225" title="Download PDF">pdf</a>, <a href="/format/2311.03225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dichotomies for Tree Minor Containment with Structural Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gima%2C+T">Tatsuya Gima</a>, 
<a href="/search/cs?searchtype=author&query=Kumabe%2C+S">Soh Kumabe</a>, 
<a href="/search/cs?searchtype=author&query=Kurita%2C+K">Kazuhiro Kurita</a>, 
<a href="/search/cs?searchtype=author&query=Okada%2C+Y">Yuto Okada</a>, 
<a href="/search/cs?searchtype=author&query=Otachi%2C+Y">Yota Otachi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 4 figures, WALCOM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">The problem of determining whether a graph $G$ contains another graph $H$ as
a minor, referred to as the minor containment problem, is a fundamental problem
in the field of graph algorithms. While it is NP-complete when $G$ and $H$ are
general graphs, it is sometimes tractable on more restricted graph classes.
This study focuses on the case where both $G$ and $H$ are trees, known as the
tree minor containment problem. Even in this case, the problem is known to be
NP-complete. In contrast, polynomial-time algorithms are known for the case
when both trees are caterpillars or when the maximum degree of $H$ is a
constant. Our research aims to clarify the boundary of tractability and
intractability for the tree minor containment problem. Specifically, we provide
dichotomies for the computational complexities of the problem based on three
structural parameters: the diameter, pathwidth, and path eccentricity.
</p>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03226" title="Abstract">arXiv:2311.03226</a> [<a href="/pdf/2311.03226" title="Download PDF">pdf</a>, <a href="/format/2311.03226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LDM3D-VR: Latent Diffusion Model for 3D VR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stan%2C+G+B+M">Gabriela Ben Melech Stan</a>, 
<a href="/search/cs?searchtype=author&query=Wofk%2C+D">Diana Wofk</a>, 
<a href="/search/cs?searchtype=author&query=Aflalo%2C+E">Estelle Aflalo</a>, 
<a href="/search/cs?searchtype=author&query=Tseng%2C+S">Shao-Yen Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhipeng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Paulitsch%2C+M">Michael Paulitsch</a>, 
<a href="/search/cs?searchtype=author&query=Lal%2C+V">Vasudev Lal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Workshop on Diffusion Models, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Latent diffusion models have proven to be state-of-the-art in the creation
and manipulation of visual outputs. However, as far as we know, the generation
of depth maps jointly with RGB is still limited. We introduce LDM3D-VR, a suite
of diffusion models targeting virtual reality development that includes
LDM3D-pano and LDM3D-SR. These models enable the generation of panoramic RGBD
based on textual prompts and the upscaling of low-resolution inputs to
high-resolution RGBD, respectively. Our models are fine-tuned from existing
pretrained models on datasets containing panoramic/high-resolution RGB images,
depth maps and captions. Both models are evaluated in comparison to existing
related methods.
</p>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03228" title="Abstract">arXiv:2311.03228</a> [<a href="/pdf/2311.03228" title="Download PDF">pdf</a>, <a href="/format/2311.03228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient Self-Supervised Cross-View Training For Sentence Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Limkonchotiwat%2C+P">Peerat Limkonchotiwat</a>, 
<a href="/search/cs?searchtype=author&query=Ponwitayarat%2C+W">Wuttikorn Ponwitayarat</a>, 
<a href="/search/cs?searchtype=author&query=Lowphansirikul%2C+L">Lalita Lowphansirikul</a>, 
<a href="/search/cs?searchtype=author&query=Udomcharoenchaikit%2C+C">Can Udomcharoenchaikit</a>, 
<a href="/search/cs?searchtype=author&query=Chuangsuwanich%2C+E">Ekapol Chuangsuwanich</a>, 
<a href="/search/cs?searchtype=author&query=Nutanong%2C+S">Sarana Nutanong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to TACL. The code and pre-trained models are available at <a href="https://github.com/mrpeerat/SCT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Self-supervised sentence representation learning is the task of constructing
an embedding space for sentences without relying on human annotation efforts.
One straightforward approach is to finetune a pretrained language model (PLM)
with a representation learning method such as contrastive learning. While this
approach achieves impressive performance on larger PLMs, the performance
rapidly degrades as the number of parameters decreases. In this paper, we
propose a framework called Self-supervised Cross-View Training (SCT) to narrow
the performance gap between large and small PLMs. To evaluate the effectiveness
of SCT, we compare it to 5 baseline and state-of-the-art competitors on seven
Semantic Textual Similarity (STS) benchmarks using 5 PLMs with the number of
parameters ranging from 4M to 340M. The experimental results show that STC
outperforms the competitors for PLMs with less than 100M parameters in 18 of 21
cases.
</p>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03230" title="Abstract">arXiv:2311.03230</a> [<a href="/pdf/2311.03230" title="Download PDF">pdf</a>, <a href="/format/2311.03230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balancing Notions of Equity: Approximation Algorithms for Fair Portfolio  of Solutions in Combinatorial Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Swati Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Moondra%2C+J">Jai Moondra</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+M">Mohit Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Inspired by equity considerations, we consider top-$k$ norm, ordered norm,
and symmetric monotonic norm objectives for various combinatorial optimization
problems. Top-$k$ norms and ordered norms have natural interpretations in terms
of minimizing the impact on individuals bearing largest costs. To model
decision-making with multiple equity criteria, we study the notion of
portfolios of solutions with the property that each norm or equity criteria has
an approximately optimal solution in this portfolio. We attempt to characterize
portfolios by their sizes and approximation factor guarantees for various
combinatorial problems. For a given problem, we investigate whether (1) there
exists a single solution that is approximately optimal for all norms, (2) there
exists a small approximately optimal portfolio of size larger than 1, (3) there
exist polynomial time algorithms to find these small portfolios. We study an
algorithmic framework to obtain single solutions that are approximately optimal
for all norms. We show the existence of such a solution for problems such as
$k$-clustering, ordered set cover, scheduling for job completion time
minimization, and scheduling for machine load minimization on identical
machines. We also give efficient algorithms to find these solutions in most
cases, except set cover where we show there is a gap in terms of computational
complexity. Our work improves upon the best-known approximation factor across
all norms for a single solution in $k$-clustering. For uncapacitated facility
location and scheduling for machine load minimization with identical jobs, we
obtain logarithmic sized portfolios, also providing a matching lower bound in
the latter case. Our work results in new open combinatorial questions, which
might be of independent interest.
</p>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03232" title="Abstract">arXiv:2311.03232</a> [<a href="/pdf/2311.03232" title="Download PDF">pdf</a>, <a href="/format/2311.03232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Reactive performance-based Shared Control Framework for Assistive  Robotic Manipulators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruiz-Ruiz%2C+F+J">Francisco J. Ruiz-Ruiz</a>, 
<a href="/search/cs?searchtype=author&query=Urdiales%2C+C">Cristina Urdiales</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Carmona%2C+M">Manuel Fern&#xe1;ndez-Carmona</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez-de-Gabriel%2C+J+M">Jes&#xfa;s M. G&#xf3;mez-de-Gabriel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In Physical Human--Robot Interaction (pHRI) grippers, humans and robots may
contribute simultaneously to actions, so it is necessary to determine how to
combine their commands. Control may be swapped from one to the other within
certain limits, or input commands may be combined according to some criteria.
The Assist-As-Needed (AAN) paradigm focuses on this second approach, as the
controller is expected to provide the minimum required assistance to users.
Some AAN systems rely on predicting human intention to adjust actions. However,
if prediction is too hard, reactive AAN systems may weigh input commands into
an emergent one. This paper proposes a novel AAN reactive control system for a
robot gripper where input commands are weighted by their respective local
performances. Thus, rather than minimizing tracking errors or differences to
expected velocities, humans receive more help depending on their needs. The
system has been tested using a gripper attached to a sensitive robot arm, which
provides evaluation parameters. Tests consisted of completing an on-air planar
path with both arms. After the robot gripped a person's forearm, the path and
current position of the robot were displayed on a screen to provide feedback to
the human. The proposed control has been compared to results without assistance
and to impedance control for benchmarking. A statistical analysis of the
results proves that global performance improved and tracking errors decreased
for ten volunteers with the proposed controller. Besides, unlike impedance
control, the proposed one does not significantly affect exerted forces, command
variation, or disagreement, measured as the angular difference between human
and output command. Results support that the proposed control scheme fits the
AAN paradigm, although future work will require further tests for more complex
environments and tasks.
</p>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03233" title="Abstract">arXiv:2311.03233</a> [<a href="/pdf/2311.03233" title="Download PDF">pdf</a>, <a href="/format/2311.03233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating Scaling Laws: Accelerating Vision Transformer&#x27;s Training via  Adaptive Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anagnostidis%2C+S">Sotiris Anagnostidis</a>, 
<a href="/search/cs?searchtype=author&query=Bachmann%2C+G">Gregor Bachmann</a>, 
<a href="/search/cs?searchtype=author&query=Hofmann%2C+T">Thomas Hofmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In recent years, the state-of-the-art in deep learning has been dominated by
very large models that have been pre-trained on vast amounts of data. The
paradigm is very simple: Investing more computational resources (optimally)
leads to better performance, and even predictably so; neural scaling laws have
been derived that accurately forecast the performance of a network for a
desired level of compute. This leads to the notion of a "compute-optimal"
model, i.e. a model that allocates a given level of compute during training
optimally to maximise performance. In this work, we extend the concept of
optimality by allowing for an "adaptive" model, i.e. a model that can change
its shape during the course of training. By allowing the shape to adapt, we can
optimally traverse between the underlying scaling laws, leading to a
significant reduction in the required compute to reach a given target
performance. We focus on vision tasks and the family of Vision Transformers,
where the patch size as well as the width naturally serve as adaptive shape
parameters. We demonstrate that, guided by scaling laws, we can design
compute-optimal adaptive models that beat their "static" counterparts.
</p>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03235" title="Abstract">arXiv:2311.03235</a> [<a href="/pdf/2311.03235" title="Download PDF">pdf</a>, <a href="/format/2311.03235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> p-Laplacian Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Tuan Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Tam Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V">Vinh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+M">Tan M. Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
<p class="mathjax">$p$-Laplacian regularization, rooted in graph and image signal processing,
introduces a parameter $p$ to control the regularization effect on these data.
Smaller values of $p$ promote sparsity and interpretability, while larger
values encourage smoother solutions. In this paper, we first show that the
self-attention mechanism obtains the minimal Laplacian regularization ($p=2$)
and encourages the smoothness in the architecture. However, the smoothness is
not suitable for the heterophilic structure of self-attention in transformers
where attention weights between tokens that are in close proximity and
non-close ones are assigned indistinguishably. From that insight, we then
propose a novel class of transformers, namely the $p$-Laplacian Transformer
(p-LaT), which leverages $p$-Laplacian regularization framework to harness the
heterophilic features within self-attention layers. In particular, low $p$
values will effectively assign higher attention weights to tokens that are in
close proximity to the current token being processed. We empirically
demonstrate the advantages of p-LaT over the baseline transformers on a wide
range of benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03236" title="Abstract">arXiv:2311.03236</a> [<a href="/pdf/2311.03236" title="Download PDF">pdf</a>, <a href="/format/2311.03236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Out-of-distribution Detection Learning with Unreliable  Out-of-distribution Sources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Haotian Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qizhou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhen Fang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xiaobo Xia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Feng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tongliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bo Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Out-of-distribution (OOD) detection discerns OOD data where the predictor
cannot make valid predictions as in-distribution (ID) data, thereby increasing
the reliability of open-world classification. However, it is typically hard to
collect real out-of-distribution (OOD) data for training a predictor capable of
discerning ID and OOD patterns. This obstacle gives rise to data
generation-based learning methods, synthesizing OOD data via data generators
for predictor training without requiring any real OOD data. Related methods
typically pre-train a generator on ID data and adopt various selection
procedures to find those data likely to be the OOD cases. However, generated
data may still coincide with ID semantics, i.e., mistaken OOD generation
remains, confusing the predictor between ID and OOD data. To this end, we
suggest that generated data (with mistaken OOD generation) can be used to
devise an auxiliary OOD detection task to facilitate real OOD detection.
Specifically, we can ensure that learning from such an auxiliary task is
beneficial if the ID and the OOD parts have disjoint supports, with the help of
a well-designed training procedure for the predictor. Accordingly, we propose a
powerful data generation-based learning method named Auxiliary Task-based OOD
Learning (ATOL) that can relieve the mistaken OOD generation. We conduct
extensive experiments under various OOD detection setups, demonstrating the
effectiveness of our method against its advanced counterparts.
</p>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03240" title="Abstract">arXiv:2311.03240</a> [<a href="/pdf/2311.03240" title="Download PDF">pdf</a>, <a href="/ps/2311.03240" title="Download PostScript">ps</a>, <a href="/format/2311.03240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning-Based Tea Leaf Disease Detection: A Comprehensive  Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+F">Faruk Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Ahad%2C+M+T">Md. Taimur Ahad</a>, 
<a href="/search/cs?searchtype=author&query=Emon%2C+Y+R">Yousuf Rayhan Emon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Tea leaf diseases are a major challenge to agricultural productivity, with
far-reaching implications for yield and quality in the tea industry. The rise
of machine learning has enabled the development of innovative approaches to
combat these diseases. Early detection and diagnosis are crucial for effective
crop management. For predicting tea leaf disease, several automated systems
have already been developed using different image processing techniques. This
paper delivers a systematic review of the literature on machine learning
methodologies applied to diagnose tea leaf disease via image classification. It
thoroughly evaluates the strengths and constraints of various Vision
Transformer models, including Inception Convolutional Vision Transformer
(ICVT), GreenViT, PlantXViT, PlantViT, MSCVT, Transfer Learning Model &amp; Vision
Transformer (TLMViT), IterationViT, IEM-ViT. Moreover, this paper also reviews
models like Dense Convolutional Network (DenseNet), Residual Neural Network
(ResNet)-50V2, YOLOv5, YOLOv7, Convolutional Neural Network (CNN), Deep CNN,
Non-dominated Sorting Genetic Algorithm (NSGA-II), MobileNetv2, and
Lesion-Aware Visual Transformer. These machine-learning models have been tested
on various datasets, demonstrating their real-world applicability. This review
study not only highlights current progress in the field but also provides
valuable insights for future research directions in the machine learning-based
detection and classification of tea leaf diseases.
</p>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03242" title="Abstract">arXiv:2311.03242</a> [<a href="/pdf/2311.03242" title="Download PDF">pdf</a>, <a href="/format/2311.03242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximating Langevin Monte Carlo with ResNet-like Neural Network  architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eigel%2C+M">Martin Eigel</a>, 
<a href="/search/cs?searchtype=author&query=Miranda%2C+C">Charles Miranda</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%BCtte%2C+J">Janina Sch&#xfc;tte</a>, 
<a href="/search/cs?searchtype=author&query=Sommer%2C+D">David Sommer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Probability (math.PR); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">We sample from a given target distribution by constructing a neural network
which maps samples from a simple reference, e.g. the standard normal
distribution, to samples from the target. To that end, we propose using a
neural network architecture inspired by the Langevin Monte Carlo (LMC)
algorithm. Based on LMC perturbation results, we show approximation rates of
the proposed architecture for smooth, log-concave target distributions measured
in the Wasserstein-$2$ distance. The analysis heavily relies on the notion of
sub-Gaussianity of the intermediate measures of the perturbed LMC process. In
particular, we derive bounds on the growth of the intermediate variance proxies
under different assumptions on the perturbations. Moreover, we propose an
architecture similar to deep residual neural networks and derive expressivity
results for approximating the sample to target distribution map.
</p>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03243" title="Abstract">arXiv:2311.03243</a> [<a href="/pdf/2311.03243" title="Download PDF">pdf</a>, <a href="/format/2311.03243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safurai-Csharp: Harnessing Synthetic Data to improve language-specific  Code LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cifarelli%2C+D">Davide Cifarelli</a>, 
<a href="/search/cs?searchtype=author&query=Boiardi%2C+L">Leonardo Boiardi</a>, 
<a href="/search/cs?searchtype=author&query=Puppo%2C+A">Alessandro Puppo</a>, 
<a href="/search/cs?searchtype=author&query=Jovanovic%2C+L">Leon Jovanovic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper introduces Safurai-Csharp, an open-source model designed to
specialize in the generation, completion, and debugging of C# code.
Safurai-Csharp is built upon the novel CodeLlama 34B model and leverages the
EvolInstruct technique, creating a refined and expanded dataset for its
fine-tuning process. The results of its performance, a notable score of 56.33%
on the Manual MultiPL-E benchmark (Zero-Shot, Pass@1), signal its high capacity
to streamline developers' workflows and aid code learning. It shows promise in
setting new stakes in the landscape of open-source C# LLMs and hopes to inspire
more inclusive and wide-ranging development in the field of language-specific
LLMs.
</p>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03245" title="Abstract">arXiv:2311.03245</a> [<a href="/pdf/2311.03245" title="Download PDF">pdf</a>, <a href="/format/2311.03245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error analysis of the Lie splitting for semilinear wave equations with  finite-energy solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ruff%2C+M">Maximilian Ruff</a>, 
<a href="/search/math?searchtype=author&query=Schnaubelt%2C+R">Roland Schnaubelt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">We study time integration schemes for $\dot H^1$-solutions to the
energy-(sub)critical semilinear wave equation on $\mathbb{R}^3$. We show
first-order convergence in $L^2$ for the Lie splitting and convergence order
$3/2$ for a corrected Lie splitting. To our knowledge this includes the first
error analysis performed for scaling-critical dispersive problems. Our approach
is based on discrete-time Strichartz estimates, including one (with a
logarithmic correction) for the case of the forbidden endpoint. Our schemes and
the Strichartz estimates contain frequency cut-offs.
</p>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03246" title="Abstract">arXiv:2311.03246</a> [<a href="/pdf/2311.03246" title="Download PDF">pdf</a>, <a href="/format/2311.03246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Post Hoc Case Based Explanation with Feature Highlighting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kenny%2C+E">Eoin Kenny</a>, 
<a href="/search/cs?searchtype=author&query=Delaney%2C+E">Eoin Delaney</a>, 
<a href="/search/cs?searchtype=author&query=Keane%2C+M">Mark Keane</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Explainable AI (XAI) has been proposed as a valuable tool to assist in
downstream tasks involving human and AI collaboration. Perhaps the most
psychologically valid XAI techniques are case based approaches which display
'whole' exemplars to explain the predictions of black box AI systems. However,
for such post hoc XAI methods dealing with images, there has been no attempt to
improve their scope by using multiple clear feature 'parts' of the images to
explain the predictions while linking back to relevant cases in the training
data, thus allowing for more comprehensive explanations that are faithful to
the underlying model. Here, we address this gap by proposing two general
algorithms (latent and super pixel based) which can isolate multiple clear
feature parts in a test image, and then connect them to the explanatory cases
found in the training data, before testing their effectiveness in a carefully
designed user study. Results demonstrate that the proposed approach
appropriately calibrates a users feelings of 'correctness' for ambiguous
classifications in real world data on the ImageNet dataset, an effect which
does not happen when just showing the explanation without feature highlighting.
</p>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03250" title="Abstract">arXiv:2311.03250</a> [<a href="/pdf/2311.03250" title="Download PDF">pdf</a>, <a href="/format/2311.03250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instructed Language Models with Retrievers Are Powerful Entity Linkers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zilin Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+M">Ming Gong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+L">Linjun Shou</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+J">Jian Pei</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Daxin Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 Main
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generative approaches powered by large language models (LLMs) have
demonstrated emergent abilities in tasks that require complex reasoning
abilities. Yet the generative nature still makes the generated content suffer
from hallucinations, thus unsuitable for entity-centric tasks like entity
linking (EL) requiring precise entity predictions over a large knowledge base.
We present Instructed Generative Entity Linker (INSGENEL), the first approach
that enables casual language models to perform entity linking over knowledge
bases. Several methods to equip language models with EL capability were
proposed in this work, including (i) a sequence-to-sequence training EL
objective with instruction-tuning, (ii) a novel generative EL framework based
on a light-weight potential mention retriever that frees the model from heavy
and non-parallelizable decoding, achieving 4$\times$ speedup without compromise
on linking metrics. INSGENEL outperforms previous generative alternatives with
+6.8 F1 points gain on average, also with a huge advantage in training data
efficiency and training compute consumption. In addition, our skillfully
engineered in-context learning (ICL) framework for EL still lags behind
INSGENEL significantly, reaffirming that the EL task remains a persistent
hurdle for general LLMs.
</p>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03253" title="Abstract">arXiv:2311.03253</a> [<a href="/pdf/2311.03253" title="Download PDF">pdf</a>, <a href="/format/2311.03253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coherent Entity Disambiguation via Modeling Topic and Categorical  Dependency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zilin Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+L">Linjun Shou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+M">Ming Gong</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+J">Jian Pei</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Daxin Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Previous entity disambiguation (ED) methods adopt a discriminative paradigm,
where prediction is made based on matching scores between mention context and
candidate entities using length-limited encoders. However, these methods often
struggle to capture explicit discourse-level dependencies, resulting in
incoherent predictions at the abstract level (e.g. topic or category). We
propose CoherentED, an ED system equipped with novel designs aimed at enhancing
the coherence of entity predictions. Our method first introduces an
unsupervised variational autoencoder (VAE) to extract latent topic vectors of
context sentences. This approach not only allows the encoder to handle longer
documents more effectively, conserves valuable input space, but also keeps a
topic-level coherence. Additionally, we incorporate an external category
memory, enabling the system to retrieve relevant categories for undecided
mentions. By employing step-by-step entity decisions, this design facilitates
the modeling of entity-entity interactions, thereby maintaining maximum
coherence at the category level. We achieve new state-of-the-art results on
popular ED benchmarks, with an average improvement of 1.3 F1 points. Our model
demonstrates particularly outstanding performance on challenging long-text
scenarios.
</p>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03260" title="Abstract">arXiv:2311.03260</a> [<a href="/pdf/2311.03260" title="Download PDF">pdf</a>, <a href="/format/2311.03260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Coupled Oscillators to Graph Neural Networks: Reducing  Over-smoothing via a Kuramoto Model-based Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Tuan Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+M">Tan M. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Honda%2C+H">Hirotada Honda</a>, 
<a href="/search/cs?searchtype=author&query=Sano%2C+T">Takashi Sano</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V">Vinh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nakamura%2C+S">Shugo Nakamura</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">We propose the Kuramoto Graph Neural Network (KuramotoGNN), a novel class of
continuous-depth graph neural networks (GNNs) that employs the Kuramoto model
to mitigate the over-smoothing phenomenon, in which node features in GNNs
become indistinguishable as the number of layers increases. The Kuramoto model
captures the synchronization behavior of non-linear coupled oscillators. Under
the view of coupled oscillators, we first show the connection between Kuramoto
model and basic GNN and then over-smoothing phenomenon in GNNs can be
interpreted as phase synchronization in Kuramoto model. The KuramotoGNN
replaces this phase synchronization with frequency synchronization to prevent
the node features from converging into each other while allowing the system to
reach a stable synchronized state. We experimentally verify the advantages of
the KuramotoGNN over the baseline GNNs and existing methods in reducing
over-smoothing on various graph deep learning benchmark tasks.
</p>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03262" title="Abstract">arXiv:2311.03262</a> [<a href="/pdf/2311.03262" title="Download PDF">pdf</a>, <a href="/format/2311.03262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Finding Optimal (Dynamic) Arborescences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Espada%2C+J">Joaquim Espada</a>, 
<a href="/search/cs?searchtype=author&query=Francisco%2C+A+P">Alexandre P. Francisco</a>, 
<a href="/search/cs?searchtype=author&query=Rocher%2C+T">Tatiana Rocher</a>, 
<a href="/search/cs?searchtype=author&query=Russo%2C+L+M+S">Lu&#xed;s M. S. Russo</a>, 
<a href="/search/cs?searchtype=author&query=Vaz%2C+C">C&#xe1;tia Vaz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Let G = (V, E) be a directed and weighted graph with vertex set V of size n
and edge set E of size m, such that each edge (u, v) \in E has a real-valued
weight w(u, c). An arborescence in G is a subgraph T = (V, E') such that for a
vertex u \in V, the root, there is a unique path in T from u to any other
vertex v \in V. The weight of T is the sum of the weights of its edges. In this
paper, given G, we are interested in finding an arborescence in G with minimum
weight, i.e., an optimal arborescence. Furthermore, when G is subject to
changes, namely edge insertions and deletions, we are interested in efficiently
maintaining a dynamic arborescence in G. This is a well known problem with
applications in several domains such as network design optimization and in
phylogenetic inference. In this paper we revisit algorithmic ideas proposed by
several authors for this problem, we provide detailed pseudo-code as well as
implementation details, and we present experimental results on large scale-free
networks and on phylogenetic inference. Our implementation is publicly
available at \url{https://gitlab.com/espadas/optimal-arborescences}.
</p>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03263" title="Abstract">arXiv:2311.03263</a> [<a href="/pdf/2311.03263" title="Download PDF">pdf</a>, <a href="/format/2311.03263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PROMPT: A Fast and Extensible Memory Profiling Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Ziyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chon%2C+Y">Yebin Chon</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yian Su</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zujun Tan</a>, 
<a href="/search/cs?searchtype=author&query=Apostolakis%2C+S">Sotiris Apostolakis</a>, 
<a href="/search/cs?searchtype=author&query=Campanoni%2C+S">Simone Campanoni</a>, 
<a href="/search/cs?searchtype=author&query=August%2C+D+I">David I. August</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Memory profiling captures programs' dynamic memory behavior, assisting
programmers in debugging, tuning, and enabling advanced compiler optimizations
like speculation-based automatic parallelization. As each use case demands its
unique program trace summary, various memory profiler types have been
developed. Yet, designing practical memory profilers often requires extensive
compiler expertise, adeptness in program optimization, and significant
implementation efforts. This often results in a void where aspirations for fast
and robust profilers remain unfulfilled. To bridge this gap, this paper
presents PROMPT, a pioneering framework for streamlined development of fast
memory profilers. With it, developers only need to specify profiling events and
define the core profiling logic, bypassing the complexities of custom
instrumentation and intricate memory profiling components and optimizations.
Two state-of-the-art memory profilers were ported with PROMPT while all
features preserved. By focusing on the core profiling logic, the code was
reduced by more than 65% and the profiling speed was improved by 5.3x and 7.1x
respectively. To further underscore PROMPT's impact, a tailored memory
profiling workflow was constructed for a sophisticated compiler optimization
client. In just 570 lines of code, this redesigned workflow satisfies the
client's memory profiling needs while achieving more than 90% reduction in
profiling time and improved robustness compared to the original profilers.
</p>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03267" title="Abstract">arXiv:2311.03267</a> [<a href="/pdf/2311.03267" title="Download PDF">pdf</a>, <a href="/ps/2311.03267" title="Download PostScript">ps</a>, <a href="/format/2311.03267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nibbling at Long Cycles: Dynamic (and Static) Edge Coloring in Optimal  Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+S">Sayan Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+M">Mart&#xed;n Costa</a>, 
<a href="/search/cs?searchtype=author&query=Panski%2C+N">Nadav Panski</a>, 
<a href="/search/cs?searchtype=author&query=Solomon%2C+S">Shay Solomon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at SODA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We consider the problem of maintaining a $(1+\epsilon)\Delta$-edge coloring
in a dynamic graph $G$ with $n$ nodes and maximum degree at most $\Delta$. The
state-of-the-art update time is $O_\epsilon(\text{polylog}(n))$, by Duan, He
and Zhang [SODA'19] and by Christiansen [STOC'23], and more precisely $O(\log^7
n/\epsilon^2)$, where $\Delta = \Omega(\log^2 n / \epsilon^2)$.
<br />The following natural question arises: What is the best possible update time
of an algorithm for this task? More specifically, \textbf{ can we bring it all
the way down to some constant} (for constant $\epsilon$)? This question
coincides with the \emph{static} time barrier for the problem: Even for
$(2\Delta-1)$-coloring, there is only a naive $O(m \log \Delta)$-time
algorithm.
<br />We answer this fundamental question in the affirmative, by presenting a
dynamic $(1+\epsilon)\Delta$-edge coloring algorithm with $O(\log^4
(1/\epsilon)/\epsilon^9)$ update time, provided $\Delta =
\Omega_\epsilon(\text{polylog}(n))$. As a corollary, we also get the first
linear time (for constant $\epsilon$) \emph{static} algorithm for
$(1+\epsilon)\Delta$-edge coloring; in particular, we achieve a running time of
$O(m \log (1/\epsilon)/\epsilon^2)$.
<br />We obtain our results by carefully combining a variant of the \textsc{Nibble}
algorithm from Bhattacharya, Grandoni and Wajc [SODA'21] with the subsampling
technique of Kulkarni, Liu, Sah, Sawhney and Tarnawski [STOC'22].
</p>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03268" title="Abstract">arXiv:2311.03268</a> [<a href="/pdf/2311.03268" title="Download PDF">pdf</a>, <a href="/format/2311.03268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Congestion-aware Ride-pooling in Mixed Traffic for Autonomous  Mobility-on-Demand Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Paparella%2C+F">Fabio Paparella</a>, 
<a href="/search/eess?searchtype=author&query=Pedroso%2C+L">Leonardo Pedroso</a>, 
<a href="/search/eess?searchtype=author&query=Hofman%2C+T">Theo Hofman</a>, 
<a href="/search/eess?searchtype=author&query=Salazar%2C+M">Mauro Salazar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper presents a modeling and optimization framework to study
congestion-aware ride-pooling Autonomous Mobility-on-Demand (AMoD) systems,
whereby self-driving robotaxis are providing on-demand mobility, and users
headed in the same direction share the same vehicle for part of their journey.
Specifically, taking a mesoscopic time-invariant perspective and on the
assumption of a large number of travel requests, we first cast the joint
ride-pooling assignment and routing problem as a quadratic program that does
not scale with the number of demands and can be solved with off-the-shelf
convex solvers. Second, we compare the proposed approach with a significantly
simpler decoupled formulation, whereby only the routing is performed in a
congestion-aware fashion, whilst the ride-pooling assignment part is
congestion-unaware. A case study of Sioux Falls reveals that such a
simplification does not significantly alter the solution and that the decisive
factor is indeed the congestion-aware routing. Finally, we solve the latter
problem accounting for the presence of user-centered private vehicle users in a
case study of Manhattan, NYC, characterizing the performance of the car-network
as a function of AMoD penetration rate and percentage of pooled rides within
it. Our results show that AMoD can significantly reduce congestion and travel
times, but only if at least 40% of the users are willing to be pooled together.
Otherwise, for higher AMoD penetration rates and low percentage of pooled
rides, the effect of the additional rebalancing empty-vehicle trips can be even
more detrimental than the benefits stemming from a centralized routing,
worsening congestion and leading to an up to 15% higher average travel time.
</p>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03275" title="Abstract">arXiv:2311.03275</a> [<a href="/pdf/2311.03275" title="Download PDF">pdf</a>, <a href="/format/2311.03275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Latent Attribute Interaction with Transformer on  Heterogeneous Information Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zeyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Q">Qingqing Ge</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+A">Anfeng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiding Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuaiqiang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Heterogeneous graph neural networks (HGNNs) have recently shown impressive
capability in modeling heterogeneous graphs that are ubiquitous in real-world
applications. Due to the diversity of attributes of nodes in different types,
most existing models first align nodes by mapping them into the same
low-dimensional space. However, in this way, they lose the type information of
nodes. In addition, most of them only consider the interactions between nodes
while neglecting the high-order information behind the latent interactions
among different node features. To address these problems, in this paper, we
propose a novel heterogeneous graph model MULAN, including two major
components, i.e., a type-aware encoder and a dimension-aware encoder.
Specifically, the type-aware encoder compensates for the loss of node type
information and better leverages graph heterogeneity in learning node
representations. Built upon transformer architecture, the dimension-aware
encoder is capable of capturing the latent interactions among the diverse node
features. With these components, the information of graph heterogeneity, node
features and graph structure can be comprehensively encoded in node
representations. We conduct extensive experiments on six heterogeneous
benchmark datasets, which demonstrates the superiority of MULAN over other
state-of-the-art competitors and also shows that MULAN is efficient.
</p>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03277" title="Abstract">arXiv:2311.03277</a> [<a href="/pdf/2311.03277" title="Download PDF">pdf</a>, <a href="/ps/2311.03277" title="Download PostScript">ps</a>, <a href="/format/2311.03277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaps in Representations of Hydropower Generation in Steady-State and  Dynamic Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mitra%2C+B">Bhaskar Mitra</a>, 
<a href="/search/eess?searchtype=author&query=Datta%2C+S">Sohom Datta</a>, 
<a href="/search/eess?searchtype=author&query=Kincic%2C+S">Slaven Kincic</a>, 
<a href="/search/eess?searchtype=author&query=Samaan%2C+N">Nader Samaan</a>, 
<a href="/search/eess?searchtype=author&query=Somani%2C+A">Abhishek Somani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In the evolving power system, where new renewable resources continually
displace conventional generation, conventional hydropower resources can be an
important asset that helps to maintain reliability and flexibility. Varying
climatic patterns do affect the operational pattern of hydropower. This would
potentially play a vital role in meeting and delivering energy and meeting
climate policy needs. Hydropower is one of the oldest forms of renewable energy
resources, however, its dependency on water availability and other constraints
are not well represented in power system steady state and dynamic models. This
leads to multiple gaps in operations planning especially due to high
intermittent renewable generation. Operating constraints and lack of
high-quality data often become a barrier to hydropower modeling which leads to
inconsistencies in reliability and operational planning studies resulting in
unintentional blackouts or unforeseen situations. This paper identifies some of
the gaps in hydro-based generation representation in steady-state and dynamic
models and provides recommendations for their mitigation.
</p>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03278" title="Abstract">arXiv:2311.03278</a> [<a href="/pdf/2311.03278" title="Download PDF">pdf</a>, <a href="/format/2311.03278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discretizing Numerical Attributes: An Analysis of Human Perceptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaushik%2C+M">Minakshi Kaushik</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+R">Rahul Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Draheim%2C+D">Dirk Draheim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Machine learning (ML) has employed various discretization methods to
partition numerical attributes into intervals. However, an effective
discretization technique remains elusive in many ML applications, such as
association rule mining. Moreover, the existing discretization techniques do
not reflect best the impact of the independent numerical factor on the
dependent numerical target factor. This research aims to establish a benchmark
approach for numerical attribute partitioning. We conduct an extensive analysis
of human perceptions of partitioning a numerical attribute and compare these
perceptions with the results obtained from our two proposed measures. We also
examine the perceptions of experts in data science, statistics, and engineering
by employing numerical data visualization techniques. The analysis of collected
responses reveals that $68.7\%$ of human responses approximately closely align
with the values generated by our proposed measures. Based on these findings,
our proposed measures may be used as one of the methods for discretizing the
numerical attributes.
</p>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03282" title="Abstract">arXiv:2311.03282</a> [<a href="/pdf/2311.03282" title="Download PDF">pdf</a>, <a href="/ps/2311.03282" title="Download PostScript">ps</a>, <a href="/format/2311.03282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource Allocation for RIS-Empowered Wireless Communications:  Low-Complexity and Robust Designs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+M">Ming Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+W">Wanming Hao</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zhangjie Peng</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+Z">Zheng Chu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingwang Li</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+C">Changsheng You</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+C">Cunhua Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE WCM
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This article delves into advancements in resource allocation techniques
tailored for systems utilizing reconfigurable intelligent surfaces (RIS), with
a primary focus on achieving low-complexity and resilient solutions. The
investigation of low-complexity approaches for RIS holds significant relevance,
primarily owing to the intricate characteristics inherent in RIS-based systems
and the need of deploying large-scale RIS arrays. Concurrently, the exploration
of robust solutions aims to address the issue of hardware impairments occurring
at both the transceivers and RIS components in practical RIS-assisted systems.
In the realm of both low-complexity and robust resource allocation, this
article not only elucidates the fundamental techniques underpinning these
methodologies but also offers comprehensive numerical results for illustrative
purposes. The necessity of adopting resource allocation strategies that are
both low in complexity and resilient is thoroughly established. Ultimately,
this article provides prospective research avenues in the domain of
low-complexity and robust resource allocation techniques tailored for
RIS-assisted systems.
</p>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03284" title="Abstract">arXiv:2311.03284</a> [<a href="/pdf/2311.03284" title="Download PDF">pdf</a>, <a href="/format/2311.03284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Collective Control under Noisy Inputs and Competing Constraints via  Non-Smooth Barrier Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Enwerem%2C+C">Clinton Enwerem</a>, 
<a href="/search/eess?searchtype=author&query=Baras%2C+J+S">John S. Baras</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">We consider the problem of safely coordinating ensembles of identical
autonomous agents to conduct complex missions with conflicting safety
requirements and under noisy control inputs. Using non-smooth control barrier
functions (CBFs) and stochastic model-predictive control as springboards and by
adopting an extrinsic approach where the ensemble is treated as a unified
dynamic entity, we devise a method to synthesize safety-aware control inputs
for uncertain collectives, drawing upon recent developments in Boolean CBF
composition and extensions of CBFs to stochastic systems. Specifically, we
approximate the combined CBF by a smooth function and solve a stochastic
optimization problem, with agent-level forcing terms restricted to the
resulting affine subspace of safe control inputs. For the smoothing step, we
employ a polynomial approximation scheme, providing evidence for its advantage
in generating more conservative yet sufficiently-filtered control signals than
the smoother but more aggressive equivalents realized via an approximation
technique based on the log-sum-exp function. To further demonstrate the utility
of the proposed method, we present bounds for the expected value of the CBF
approximation error, along with results from simulations of a single-integrator
collective under velocity perturbations, comparing these results with those
obtained using a naive state-feedback controller lacking safety filters.
</p>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03285" title="Abstract">arXiv:2311.03285</a> [<a href="/pdf/2311.03285" title="Download PDF">pdf</a>, <a href="/format/2311.03285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> S-LoRA: Serving Thousands of Concurrent LoRA Adapters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sheng%2C+Y">Ying Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Shiyi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dacheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Hooper%2C+C">Coleman Hooper</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+N">Nicholas Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chou%2C+C">Christopher Chou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Banghua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Lianmin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Keutzer%2C+K">Kurt Keutzer</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+J+E">Joseph E. Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Stoica%2C+I">Ion Stoica</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">The "pretrain-then-finetune" paradigm is commonly adopted in the deployment
of large language models. Low-Rank Adaptation (LoRA), a parameter-efficient
fine-tuning method, is often employed to adapt a base model to a multitude of
tasks, resulting in a substantial collection of LoRA adapters derived from one
base model. We observe that this paradigm presents significant opportunities
for batched inference during serving. To capitalize on these opportunities, we
present S-LoRA, a system designed for the scalable serving of many LoRA
adapters. S-LoRA stores all adapters in the main memory and fetches the
adapters used by the currently running queries to the GPU memory. To
efficiently use the GPU memory and reduce fragmentation, S-LoRA proposes
Unified Paging. Unified Paging uses a unified memory pool to manage dynamic
adapter weights with different ranks and KV cache tensors with varying sequence
lengths. Additionally, S-LoRA employs a novel tensor parallelism strategy and
highly optimized custom CUDA kernels for heterogeneous batching of LoRA
computation. Collectively, these features enable S-LoRA to serve thousands of
LoRA adapters on a single GPU or across multiple GPUs with a small overhead.
Compared to state-of-the-art libraries such as HuggingFace PEFT and vLLM (with
naive support of LoRA serving), S-LoRA can improve the throughput by up to 4
times and increase the number of served adapters by several orders of
magnitude. As a result, S-LoRA enables scalable serving of many task-specific
fine-tuned models and offers the potential for large-scale customized
fine-tuning services.
</p>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03287" title="Abstract">arXiv:2311.03287</a> [<a href="/pdf/2311.03287" title="Download PDF">pdf</a>, <a href="/format/2311.03287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Holistic Analysis of Hallucination in GPT-4V(ision): Bias and  Interference Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+C">Chenhang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yiyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shirley Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Linjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">James Zou</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Huaxiu Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">While GPT-4V(ision) impressively models both visual and textual information
simultaneously, it's hallucination behavior has not been systematically
assessed. To bridge this gap, we introduce a new benchmark, namely, the Bias
and Interference Challenges in Visual Language Models (Bingo). This benchmark
is designed to evaluate and shed light on the two common types of
hallucinations in visual language models: bias and interference. Here, bias
refers to the model's tendency to hallucinate certain types of responses,
possibly due to imbalance in its training data. Interference pertains to
scenarios where the judgment of GPT-4V(ision) can be disrupted due to how the
text prompt is phrased or how the input image is presented. We identify a
notable regional bias, whereby GPT-4V(ision) is better at interpreting Western
images or images with English writing compared to images from other countries
or containing text in other languages. Moreover, GPT-4V(ision) is vulnerable to
leading questions and is often confused when interpreting multiple images
together. Popular mitigation approaches, such as self-correction and
chain-of-thought reasoning, are not effective in resolving these challenges. We
also identified similar biases and interference vulnerabilities with LLaVA and
Bard. Our results characterize the hallucination challenges in GPT-4V(ision)
and state-of-the-art visual-language models, and highlight the need for new
solutions. The Bingo benchmark is available at https://github.com/gzcch/Bingo.
</p>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03292" title="Abstract">arXiv:2311.03292</a> [<a href="/pdf/2311.03292" title="Download PDF">pdf</a>, <a href="/ps/2311.03292" title="Download PostScript">ps</a>, <a href="/format/2311.03292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Science from 1963 to 2012
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alvarado%2C+R+C">Rafael C. Alvarado</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Literature (cs.GL)</span>; Digital Libraries (cs.DL)

</div>
<p class="mathjax">Consensus on the definition of data science remains low despite the
widespread establishment of academic programs in the field and continued demand
for data scientists in industry. Definitions range from rebranded statistics to
data-driven science to the science of data to simply the application of machine
learning to so-called big data to solve real world problems. Current efforts to
trace the history of the field in order to clarify its definition, such as
Donoho's "50 Years of Data Science" (Donoho 2017), tend to focus on a short
period when a small group of statisticians adopted the term in an unsuccessful
attempt to rebrand their field in the face of the overshadowing effects of
computational statistics and data mining. Using textual evidence from primary
sources, this essay traces the history of the term to the 1960s, when it was
first used by the US Air Force in a surprisingly similar way to its current
usage, to 2012, the year that Harvard Business Review published the enormously
influential article "Data Scientist: The Sexiest Job of the 21st Century"
(Davenport and Patil 2012), while the American Statistical Association
acknowledged a profound disconnect between statistics and data science. Among
the themes that emerge from this review are (1) the long-standing opposition
between data analysts and data miners that continues to animate the field, (2)
an established definition of the term as the practice of managing and
processing scientific data that has been occluded by recent usage, and (3) the
phenomenon of data impedancethe disproportion between surplus data, indexed by
phrases like data deluge and big data, and the limitations of computational
machinery and methods to process them. This persistent condition appears to
have motivated the use of the term and the field itself since its beginnings.
</p>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03293" title="Abstract">arXiv:2311.03293</a> [<a href="/pdf/2311.03293" title="Download PDF">pdf</a>, <a href="/format/2311.03293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Reusable Manipulation Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+J">Jiayuan Mao</a>, 
<a href="/search/cs?searchtype=author&query=Tenenbaum%2C+J+B">Joshua B. Tenenbaum</a>, 
<a href="/search/cs?searchtype=author&query=Lozano-P%C3%A9rez%2C+T">Tom&#xe1;s Lozano-P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Kaelbling%2C+L+P">Leslie Pack Kaelbling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CoRL 2023. Project page: <a href="https://concepts-ai.com/p/mechanisms/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Humans demonstrate an impressive ability to acquire and generalize
manipulation "tricks." Even from a single demonstration, such as using soup
ladles to reach for distant objects, we can apply this skill to new scenarios
involving different object positions, sizes, and categories (e.g., forks and
hammers). Additionally, we can flexibly combine various skills to devise
long-term plans. In this paper, we present a framework that enables machines to
acquire such manipulation skills, referred to as "mechanisms," through a single
demonstration and self-play. Our key insight lies in interpreting each
demonstration as a sequence of changes in robot-object and object-object
contact modes, which provides a scaffold for learning detailed samplers for
continuous parameters. These learned mechanisms and samplers can be seamlessly
integrated into standard task and motion planners, enabling their compositional
use.
</p>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03300" title="Abstract">arXiv:2311.03300</a> [<a href="/pdf/2311.03300" title="Download PDF">pdf</a>, <a href="/format/2311.03300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Run-to-Run Feedforward Control of Electromechanical Switching  Devices: a Sensitivity-Based Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ramirez-Laboreo%2C+E">Edgar Ramirez-Laboreo</a> (1), 
<a href="/search/eess?searchtype=author&query=Moya-Lasheras%2C+E">Eduardo Moya-Lasheras</a> (1), 
<a href="/search/eess?searchtype=author&query=Serrano-Seco%2C+E">Eloy Serrano-Seco</a> (1) ((1) Universidad de Zaragoza)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Electromechanical switching devices, such as solenoid valves, contactors, and
relays, suffer from undesirable phenomena like clicking, mechanical wear, and
contact bounce. Despite that, they are still widely used in industry due to
their various economic and technical advantages. This has encouraged the
development of controllers aimed at reducing the collisions that occur at the
end of the switching operations. One of the most successful approaches has been
the use of iterative techniques. However, these algorithms typically require a
large number of operations to converge, which is definitely a clear drawback.
This paper presents a strategy to improve the convergence rate of such
controllers. Our proposal, which is based on the sensitivity of the control law
with respect to the parameters, assumes that the performance of the system is
more heavily affected by some parameters than others. Thus, by avoiding
movements in the directions that have less impact, the search algorithm is
expected to drive the system to near-optimal behaviors using fewer operations.
Results obtained by simulation show significant improvement in the convergence
rate of a state-of-the-art run-to-run feedforward controller, which
demonstrates the high potential of the proposal.
</p>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03301" title="Abstract">arXiv:2311.03301</a> [<a href="/pdf/2311.03301" title="Download PDF">pdf</a>, <a href="/format/2311.03301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ziya2: Data-centric Learning is All LLMs Need
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gan%2C+R">Ruyi Gan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Ziwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+R">Renliang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Junyu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaojun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dixiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+K">Kunhao Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+P">Ping Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaxing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yan Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Various large language models (LLMs) have been proposed in recent years,
including closed- and open-source ones, continually setting new records on
multiple benchmarks. However, the development of LLMs still faces several
issues, such as high cost of training models from scratch, and continual
pre-training leading to catastrophic forgetting, etc. Although many such issues
are addressed along the line of research on LLMs, an important yet practical
limitation is that many studies overly pursue enlarging model sizes without
comprehensively analyzing and optimizing the use of pre-training data in their
learning process, as well as appropriate organization and leveraging of such
data in training LLMs under cost-effective settings. In this work, we propose
Ziya2, a model with 13 billion parameters adopting LLaMA2 as the foundation
model, and further pre-trained on 700 billion tokens, where we focus on
pre-training techniques and use data-centric optimization to enhance the
learning process of Ziya2 on different stages. Experiments show that Ziya2
significantly outperforms other models in multiple benchmarks especially with
promising results compared to representative open-source ones. Ziya2 (Base) is
released at https://huggingface.co/IDEA-CCNL/Ziya2-13B-Base and
https://modelscope.cn/models/Fengshenbang/Ziya2-13B-Base/summary.
</p>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03303" title="Abstract">arXiv:2311.03303</a> [<a href="/pdf/2311.03303" title="Download PDF">pdf</a>, <a href="/format/2311.03303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TS-Diffusion: Generating Highly Complex Time Series with Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yangming Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">While current generative models have achieved promising performances in
time-series synthesis, they either make strong assumptions on the data format
(e.g., regularities) or rely on pre-processing approaches (e.g.,
interpolations) to simplify the raw data. In this work, we consider a class of
time series with three common bad properties, including sampling
irregularities, missingness, and large feature-temporal dimensions, and
introduce a general model, TS-Diffusion, to process such complex time series.
Our model consists of three parts under the framework of point process. The
first part is an encoder of the neural ordinary differential equation (ODE)
that converts time series into dense representations, with the jump technique
to capture sampling irregularities and self-attention mechanism to handle
missing values; The second component of TS-Diffusion is a diffusion model that
learns from the representation of time series. These time-series
representations can have a complex distribution because of their high
dimensions; The third part is a decoder of another ODE that generates time
series with irregularities and missing values given their representations. We
have conducted extensive experiments on multiple time-series datasets,
demonstrating that TS-Diffusion achieves excellent results on both conventional
and complex time series and significantly outperforms previous baselines.
</p>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03309" title="Abstract">arXiv:2311.03309</a> [<a href="/pdf/2311.03309" title="Download PDF">pdf</a>, <a href="/format/2311.03309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Structure Learning with Stochastic Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Benjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jennings%2C+J">Joel Jennings</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+W">Wenbo Gong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Discovering the underlying relationships among variables from temporal
observations has been a longstanding challenge in numerous scientific
disciplines, including biology, finance, and climate science. The dynamics of
such systems are often best described using continuous-time stochastic
processes. Unfortunately, most existing structure learning approaches assume
that the underlying process evolves in discrete-time and/or observations occur
at regular time intervals. These mismatched assumptions can often lead to
incorrect learned structures and models. In this work, we introduce a novel
structure learning method, SCOTCH, which combines neural stochastic
differential equations (SDE) with variational inference to infer a posterior
distribution over possible structures. This continuous-time approach can
naturally handle both learning from and predicting observations at arbitrary
time points. Theoretically, we establish sufficient conditions for an SDE and
SCOTCH to be structurally identifiable, and prove its consistency under
infinite data limits. Empirically, we demonstrate that our approach leads to
improved structure learning performance on both synthetic and real-world
datasets compared to relevant baselines under regular and irregular sampling
intervals.
</p>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03311" title="Abstract">arXiv:2311.03311</a> [<a href="/pdf/2311.03311" title="Download PDF">pdf</a>, <a href="/format/2311.03311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unraveling Downstream Gender Bias from Large Language Models: A Study on  AI Educational Writing Assistance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wambsganss%2C+T">Thiemo Wambsganss</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+X">Xiaotian Su</a>, 
<a href="/search/cs?searchtype=author&query=Swamy%2C+V">Vinitra Swamy</a>, 
<a href="/search/cs?searchtype=author&query=Neshaei%2C+S+P">Seyed Parsa Neshaei</a>, 
<a href="/search/cs?searchtype=author&query=Rietsche%2C+R">Roman Rietsche</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%A4ser%2C+T">Tanja K&#xe4;ser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a full paper at EMNLP Findings 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Large Language Models (LLMs) are increasingly utilized in educational tasks
such as providing writing suggestions to students. Despite their potential,
LLMs are known to harbor inherent biases which may negatively impact learners.
Previous studies have investigated bias in models and data representations
separately, neglecting the potential impact of LLM bias on human writing. In
this paper, we investigate how bias transfers through an AI writing support
pipeline. We conduct a large-scale user study with 231 students writing
business case peer reviews in German. Students are divided into five groups
with different levels of writing support: one classroom group with
feature-based suggestions and four groups recruited from Prolific -- a control
group with no assistance, two groups with suggestions from fine-tuned GPT-2 and
GPT-3 models, and one group with suggestions from pre-trained GPT-3.5. Using
GenBit gender bias analysis, Word Embedding Association Tests (WEAT), and
Sentence Embedding Association Test (SEAT) we evaluate the gender bias at
various stages of the pipeline: in model embeddings, in suggestions generated
by the models, and in reviews written by students. Our results demonstrate that
there is no significant difference in gender bias between the resulting peer
reviews of groups with and without LLM suggestions. Our research is therefore
optimistic about the use of AI writing support in the classroom, showcasing a
context where bias in LLMs does not transfer to students' responses.
</p>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03312" title="Abstract">arXiv:2311.03312</a> [<a href="/pdf/2311.03312" title="Download PDF">pdf</a>, <a href="/format/2311.03312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Single 2D Pose with Context is Worth Hundreds for 3D Human Pose  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qitao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Ce Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mengyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The dominant paradigm in 3D human pose estimation that lifts a 2D pose
sequence to 3D heavily relies on long-term temporal clues (i.e., using a
daunting number of video frames) for improved accuracy, which incurs
performance saturation, intractable computation and the non-causal problem.
This can be attributed to their inherent inability to perceive spatial context
as plain 2D joint coordinates carry no visual cues. To address this issue, we
propose a straightforward yet powerful solution: leveraging the readily
available intermediate visual representations produced by off-the-shelf
(pre-trained) 2D pose detectors -- no finetuning on the 3D task is even needed.
The key observation is that, while the pose detector learns to localize 2D
joints, such representations (e.g., feature maps) implicitly encode the
joint-centric spatial context thanks to the regional operations in backbone
networks. We design a simple baseline named Context-Aware PoseFormer to
showcase its effectiveness. Without access to any temporal information, the
proposed method significantly outperforms its context-agnostic counterpart,
PoseFormer, and other state-of-the-art methods using up to hundreds of video
frames regarding both speed and precision. Project page:
https://qitaozhao.github.io/ContextAware-PoseFormer
</p>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03316" title="Abstract">arXiv:2311.03316</a> [<a href="/pdf/2311.03316" title="Download PDF">pdf</a>, <a href="/ps/2311.03316" title="Download PostScript">ps</a>, <a href="/format/2311.03316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Collaborative Filtering Recommendation via Graph Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongyu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Recommendation systems are designed to provide personalized predictions for
items that are most appealing to individual customers. Among various types of
recommendation algorithms, k-nearest neighbor based collaborative filtering
algorithm attracts tremendous attention and are widely used in practice.
However, the k-nearest neighbor scheme can only capture the local relationship
among users and the uniform neighborhood size is also not suitable to represent
the underlying data structure. In this paper, we leverage emerging graph signal
processing (GSP) theory to construct sparse yet high quality graph to enhance
the solution quality and efficiency of collaborative filtering algorithm.
Experimental results show that our method outperforms k-NN based collaborative
filtering algorithm by a large margin on the benchmark data set.
</p>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03318" title="Abstract">arXiv:2311.03318</a> [<a href="/pdf/2311.03318" title="Download PDF">pdf</a>, <a href="/format/2311.03318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Foundation Model for Music Informatics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Won%2C+M">Minz Won</a>, 
<a href="/search/cs?searchtype=author&query=Hung%2C+Y">Yun-Ning Hung</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+D">Duc Le</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Information Retrieval (cs.IR); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This paper investigates foundation models tailored for music informatics, a
domain currently challenged by the scarcity of labeled data and generalization
issues. To this end, we conduct an in-depth comparative study among various
foundation model variants, examining key determinants such as model
architectures, tokenization methods, temporal resolution, data, and model
scalability. This research aims to bridge the existing knowledge gap by
elucidating how these individual factors contribute to the success of
foundation models in music informatics. Employing a careful evaluation
framework, we assess the performance of these models across diverse downstream
tasks in music information retrieval, with a particular focus on token-level
and sequence-level classification. Our results reveal that our model
demonstrates robust performance, surpassing existing models in specific key
metrics. These findings contribute to the understanding of self-supervised
learning in music informatics and pave the way for developing more effective
and versatile foundation models in the field. A pretrained version of our model
is publicly available to foster reproducibility and future research.
</p>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03319" title="Abstract">arXiv:2311.03319</a> [<a href="/pdf/2311.03319" title="Download PDF">pdf</a>, <a href="/format/2311.03319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DAIL: Data Augmentation for In-Context Learning via Self-Paraphrase
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dawei Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Mekala%2C+D">Dheeraj Mekala</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuyao Li</a>, 
<a href="/search/cs?searchtype=author&query=wang%2C+Y">Yulin wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xueqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hogan%2C+W">William Hogan</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+J">Jingbo Shang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Course project for DSC 253 (Advanced Data-Driven Text Mining) at UCSD
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In-Context Learning (ICL) combined with pre-trained large language models has
achieved promising results on various NLP tasks. However, ICL requires
high-quality annotated demonstrations which might not be available in
real-world scenarios. To overcome this limitation, we propose \textbf{D}ata
\textbf{A}ugmentation for \textbf{I}n-Context \textbf{L}earning
(\textbf{DAIL}). DAIL leverages the intuition that large language models are
more familiar with the content generated by themselves. It first utilizes the
language model to generate paraphrases of the test sample and employs majority
voting to determine the final result based on individual predictions. Our
extensive empirical evaluation shows that DAIL outperforms the standard ICL
method and other ensemble-based methods in the low-resource scenario.
Additionally, we explore the use of voting consistency as a confidence score of
the model when the logits of predictions are inaccessible. We believe our work
will stimulate further research on ICL in low-resource settings.
</p>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03320" title="Abstract">arXiv:2311.03320</a> [<a href="/pdf/2311.03320" title="Download PDF">pdf</a>, <a href="/format/2311.03320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tackling Concept Shift in Text Classification using Entailment-style  Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roychowdhury%2C+S">Sumegh Roychowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+K">Karan Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Kasa%2C+S+R">Siva Rajesh Kasa</a>, 
<a href="/search/cs?searchtype=author&query=Murthy%2C+P+S">Prasanna Srinivasa Murthy</a>, 
<a href="/search/cs?searchtype=author&query=Chandra%2C+A">Alok Chandra</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023 - Workshop on Distribution Shifts
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Pre-trained language models (PLMs) have seen tremendous success in text
classification (TC) problems in the context of Natural Language Processing
(NLP). In many real-world text classification tasks, the class definitions
being learned do not remain constant but rather change with time - this is
known as Concept Shift. Most techniques for handling concept shift rely on
retraining the old classifiers with the newly labelled data. However, given the
amount of training data required to fine-tune large DL models for the new
concepts, the associated labelling costs can be prohibitively expensive and
time consuming. In this work, we propose a reformulation, converting vanilla
classification into an entailment-style problem that requires significantly
less data to re-train the text classifier to adapt to new concepts. We
demonstrate the effectiveness of our proposed method on both real world &amp;
synthetic datasets achieving absolute F1 gains upto 7% and 40% respectively in
few-shot settings. Further, upon deployment, our solution also helped save 75%
of labeling costs overall.
</p>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03321" title="Abstract">arXiv:2311.03321</a> [<a href="/pdf/2311.03321" title="Download PDF">pdf</a>, <a href="/format/2311.03321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact Shortest Paths with Rational Weights on the Word RAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karczmarz%2C+A">Adam Karczmarz</a>, 
<a href="/search/cs?searchtype=author&query=Nadara%2C+W">Wojciech Nadara</a>, 
<a href="/search/cs?searchtype=author&query=Soko%C5%82owski%2C+M">Marek Soko&#x142;owski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Exact computation of shortest paths in weighted graphs has been traditionally
studied in one of two settings. First, one can assume that the edge weights are
real numbers and all the performed operations on reals (typically comparisons
and additions) take constant time. Classical Dijkstra's and Bellman-Ford
algorithms have been described in this setting. More efficient exact shortest
paths algorithms have been obtained for integer-weighted graphs. Integrality
assumption not only enables faster algorithms but also allows implementing the
aforementioned algorithms in a much more realistic word RAM model where only
arithmetic operations on $O(\log{n})$-bit integers are performed in constant
time. On the word RAM one can as efficiently exactly encode even
\emph{rational-weighted} instances with $O(\log{n})$-bit numerators and
denominators. However, the known exact real-weighted shortest paths algorithms,
run on such a rational input, can easily encounter intermediate values of
$\Theta(n)$ bits if represented exactly. This leads to a factor-$\Omega(n)$
slowdown on the word RAM. At the same time, the scaling algorithms suited for
integer weights do not produce exact solutions for rational inputs without
dramatically increasing their accuracy.
<br />In this paper, we design randomized exact single-source shortest paths
algorithms for rational-weighted graphs on the word RAM. Most importantly, in
the non-negative case, we obtain a near-linear time algorithm matching
Dijkstra's algorithm running time up to polylogarithmic factors. In presence of
negative weights, we give an $\tilde{O}(n^{2.5})$-time algorithm breaking
through the best known strongly polynomial bound attained by Bellman-Ford for
sufficiently dense graphs.
</p>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03323" title="Abstract">arXiv:2311.03323</a> [<a href="/pdf/2311.03323" title="Download PDF">pdf</a>, <a href="/ps/2311.03323" title="Download PostScript">ps</a>, <a href="/format/2311.03323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Robust Bi-Directional Algorithm For People Count In Crowded Areas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Penke%2C+S">Satyanarayana Penke</a>, 
<a href="/search/cs?searchtype=author&query=Pavuluri%2C+G">Gopikrishna Pavuluri</a>, 
<a href="/search/cs?searchtype=author&query=Kunda%2C+S">Soukhya Kunda</a>, 
<a href="/search/cs?searchtype=author&query=M%2C+S">Satvik M</a>, 
<a href="/search/cs?searchtype=author&query=Y%2C+C">CharanKumar Y</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 Pages, 6 Figures ,Published in International Journal of Pure and Applied Mathematic. Paper link : <a href="https://acadpubl.eu/jsi/2017-116-5-7/articles/6/13.pdf">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">People counting system in crowded places has become a very useful practical
application that can be accomplished in various ways which include many
traditional methods using sensors. Examining the case of real time scenarios,
the algorithm espoused should be steadfast and accurate. People counting
algorithm presented in this paper, is centered on blob assessment, devoted to
yield the count of the people through a path along with the direction of
traversal. The system depicted is often ensconced at the entrance of a building
so that the unmitigated frequency of visitors can be recorded. The core premise
of this work is to extricate count of people inflow and outflow pertaining to a
particular area. The tot-up achieved can be exploited for purpose of statistics
in the circumstances of any calamity occurrence in that zone. Relying upon the
count totaled, the population in that vicinity can be assimilated in order to
take on relevant measures to rescue the people.
</p>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03324" title="Abstract">arXiv:2311.03324</a> [<a href="/pdf/2311.03324" title="Download PDF">pdf</a>, <a href="/ps/2311.03324" title="Download PostScript">ps</a>, <a href="/format/2311.03324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating Primary Substation Boundaries and the Value of Mapping the  Electrical Network Infrastructure of Great Britain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Day%2C+J">Joseph Day</a>, 
<a href="/search/eess?searchtype=author&query=Wilson%2C+I+A+G">I. A. Grant Wilson</a>, 
<a href="/search/eess?searchtype=author&query=Donaldson%2C+D+L">Daniel L. Donaldson</a>, 
<a href="/search/eess?searchtype=author&query=Barbour%2C+E">Edward Barbour</a>, 
<a href="/search/eess?searchtype=author&query=C%C3%A1rdenas%2C+B">Bruno C&#xe1;rdenas</a>, 
<a href="/search/eess?searchtype=author&query=Jones%2C+C+R">Christopher R. Jones</a>, 
<a href="/search/eess?searchtype=author&query=Urquhart%2C+A+J">Andrew J. Urquhart</a>, 
<a href="/search/eess?searchtype=author&query=Garvey%2C+S+D">Seamus D. Garvey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 58 pages, 26 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Localised data aggregation in many countries including Great Britain (GB) is
typically done to a geographical level with polygon boundaries that have a
robust and trusted governance system in place. At a minimum this will mean
there is confidence in a process to create a set of polygons that have unique
identifiers coupled to geographical areas, and the ability to have these
updated through a defined code of practice. Examples found across many
countries are in the delivery of post, such as postcodes and zip codes, and of
the definition of census areas and municipal boundaries. The confidence in
these boundaries allows different data to be aggregated by third parties, which
itself provides greater levels of data over comparable geographical areas to
enhance wider analysis and decision making. Here we combine publicly available
datasets published from the six regional electricity Distribution Network
Operators of GB to produce a new geospatial dataset with 4436 unique polygons
defining the areas served by electrical primary substations. An example is also
presented of the use of these polygons to link postcode level open government
datasets on domestic energy consumption (2015-2020) from the Department of
Energy Security and Net Zero (DESNZ). This results in another dataset with
energy statistics aggregated to the geographical areas served by each primary
substation across Great Britain. Therefore, we believe there is a compelling
argument for countries to set up processes to create and update polygons that
have a meaningful relationship to energy systems. This would allow more
accurate energy systems analysis to be performed, ultimately leading to an
accelerated or potentially lower cost transition to a net-zero world.
</p>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03328" title="Abstract">arXiv:2311.03328</a> [<a href="/pdf/2311.03328" title="Download PDF">pdf</a>, <a href="/format/2311.03328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Asynchrony, Memory, and Communication: Separations and Landscapes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Flocchini%2C+P">Paola Flocchini</a>, 
<a href="/search/cs?searchtype=author&query=Santoro%2C+N">Nicola Santoro</a>, 
<a href="/search/cs?searchtype=author&query=Sudo%2C+Y">Yuichi Sudo</a>, 
<a href="/search/cs?searchtype=author&query=Wada%2C+K">Koichi Wada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Research on distributed computing by a team of identical mobile computational
entities, called robots, operating in a Euclidean space in
$\mathit{Look}$-$\mathit{Compute}$-$\mathit{Move}$ ($\mathit{LCM}$) cycles, has
recently focused on better understanding how the computational power of robots
depends on the interplay between their internal capabilities (i.e., persistent
memory, communication), captured by the four standard computational models
(OBLOT, LUMI, FSTA, and FCOM) and the conditions imposed by the external
environment, controlling the activation of the robots and their synchronization
of their activities, perceived and modeled as an adversarial scheduler.
<br />We consider a set of adversarial asynchronous schedulers ranging from the
classical {\em semi-synchronous} (SSYNCH) and {\em fully asynchronous} (ASYNCH)
settings, including schedulers (emerging when studying the atomicity of the
combination of operations in the $\mathit{LCM}$ cycles) whose adversarial power
is in between those two. We ask the question: what is the computational
relationship between a model $M_1$ under adversarial scheduler $K_1$
($M_1(K_1)$) and a model $M_2$ under scheduler $K_2$ ($M_2(K_2)$)? For example,
are the robots in $M_1(K_1)$ more powerful (i.e., they can solve more problems)
than those in $M_2(K_2)$?
<br />We answer all these questions by providing, through cross-model analysis, a
complete characterization of the computational relationship between the power
of the four models of robots under the considered asynchronous schedulers. In
this process, we also provide qualified answers to several open questions,
including the outstanding one on the proper dominance of \ over \ASY\ in the
case of unrestricted visibility.
</p>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03332" title="Abstract">arXiv:2311.03332</a> [<a href="/pdf/2311.03332" title="Download PDF">pdf</a>, <a href="/ps/2311.03332" title="Download PostScript">ps</a>, <a href="/format/2311.03332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Hard-Constrained Models with One Sample
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Galanis%2C+A">Andreas Galanis</a>, 
<a href="/search/cs?searchtype=author&query=Kalavasis%2C+A">Alkis Kalavasis</a>, 
<a href="/search/cs?searchtype=author&query=Kandiros%2C+A+V">Anthimos Vardis Kandiros</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Abstract shortened to fit arXiv requirements
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">We consider the problem of estimating the parameters of a Markov Random Field
with hard-constraints using a single sample. As our main running examples, we
use the $k$-SAT and the proper coloring models, as well as general $H$-coloring
models; for all of these we obtain both positive and negative results. In
contrast to the soft-constrained case, we show in particular that single-sample
estimation is not always possible, and that the existence of an estimator is
related to the existence of non-satisfiable instances.
<br />Our algorithms are based on the pseudo-likelihood estimator. We show variance
bounds for this estimator using coupling techniques inspired, in the case of
$k$-SAT, by Moitra's sampling algorithm (JACM, 2019); our positive results for
colorings build on this new coupling approach. For $q$-colorings on graphs with
maximum degree $d$, we give a linear-time estimator when $q&gt;d+1$, whereas the
problem is non-identifiable when $q\leq d+1$. For general $H$-colorings, we
show that standard conditions that guarantee sampling, such as Dobrushin's
condition, are insufficient for one-sample learning; on the positive side, we
provide a general condition that is sufficient to guarantee linear-time
learning and obtain applications for proper colorings and permissive models.
For the $k$-SAT model on formulas with maximum degree $d$, we provide a
linear-time estimator when $k\gtrsim 6.45\log d$, whereas the problem becomes
non-identifiable when $k\lesssim \log d$.
</p>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03335" title="Abstract">arXiv:2311.03335</a> [<a href="/pdf/2311.03335" title="Download PDF">pdf</a>, <a href="/format/2311.03335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Image Attention for Zero-Shot Appearance Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alaluf%2C+Y">Yuval Alaluf</a>, 
<a href="/search/cs?searchtype=author&query=Garibi%2C+D">Daniel Garibi</a>, 
<a href="/search/cs?searchtype=author&query=Patashnik%2C+O">Or Patashnik</a>, 
<a href="/search/cs?searchtype=author&query=Averbuch-Elor%2C+H">Hadar Averbuch-Elor</a>, 
<a href="/search/cs?searchtype=author&query=Cohen-Or%2C+D">Daniel Cohen-Or</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://garibida.github.io/cross-image-attention">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Recent advancements in text-to-image generative models have demonstrated a
remarkable ability to capture a deep semantic understanding of images. In this
work, we leverage this semantic knowledge to transfer the visual appearance
between objects that share similar semantics but may differ significantly in
shape. To achieve this, we build upon the self-attention layers of these
generative models and introduce a cross-image attention mechanism that
implicitly establishes semantic correspondences across images. Specifically,
given a pair of images -- one depicting the target structure and the other
specifying the desired appearance -- our cross-image attention combines the
queries corresponding to the structure image with the keys and values of the
appearance image. This operation, when applied during the denoising process,
leverages the established semantic correspondences to generate an image
combining the desired structure and appearance. In addition, to improve the
output image quality, we harness three mechanisms that either manipulate the
noisy latent codes or the model's internal representations throughout the
denoising process. Importantly, our approach is zero-shot, requiring no
optimization or training. Experiments show that our method is effective across
a wide range of object categories and is robust to variations in shape, size,
and viewpoint between the two input images.
</p>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03338" title="Abstract">arXiv:2311.03338</a> [<a href="/pdf/2311.03338" title="Download PDF">pdf</a>, <a href="/format/2311.03338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defending a Target with a Slower Defender against a Faster Attacker
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Das%2C+G">Goutam Das</a>, 
<a href="/search/eess?searchtype=author&query=Dorothy%2C+M">Michael Dorothy</a>, 
<a href="/search/eess?searchtype=author&query=Bell%2C+Z+I">Zachary I. Bell</a>, 
<a href="/search/eess?searchtype=author&query=Shishika%2C+D">Daigo Shishika</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 14 figures, submitted to IEEE ACC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper studies a target-defense game played between a slow defender and a
fast attacker. The attacker wins the game if it reaches the target while
avoiding the defender's capture disk. The defender wins the game by preventing
the attacker from reaching the target, which includes reaching the target and
containing it in the capture disk. Depending on the initial condition, the
attacker must circumnavigate the defender's capture disk, resulting in a
constrained trajectory. This condition produces three phases of the game, which
we analyze to solve for the game of kind. We provide the barrier surface that
divides the state space into attacker-win and defender-win regions, and present
the corresponding strategies that guarantee win for each region. Numerical
experiments demonstrate the theoretical results as well as the comparative
analysis with strategies proposed in related works.
</p>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03339" title="Abstract">arXiv:2311.03339</a> [<a href="/pdf/2311.03339" title="Download PDF">pdf</a>, <a href="/format/2311.03339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FLOGA: A machine learning ready dataset, a benchmark and a novel deep  learning model for burnt area mapping with Sentinel-2
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sdraka%2C+M">Maria Sdraka</a>, 
<a href="/search/cs?searchtype=author&query=Dimakos%2C+A">Alkinoos Dimakos</a>, 
<a href="/search/cs?searchtype=author&query=Malounis%2C+A">Alexandros Malounis</a>, 
<a href="/search/cs?searchtype=author&query=Ntasiou%2C+Z">Zisoula Ntasiou</a>, 
<a href="/search/cs?searchtype=author&query=Karantzalos%2C+K">Konstantinos Karantzalos</a>, 
<a href="/search/cs?searchtype=author&query=Michail%2C+D">Dimitrios Michail</a>, 
<a href="/search/cs?searchtype=author&query=Papoutsis%2C+I">Ioannis Papoutsis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Over the last decade there has been an increasing frequency and intensity of
wildfires across the globe, posing significant threats to human and animal
lives, ecosystems, and socio-economic stability. Therefore urgent action is
required to mitigate their devastating impact and safeguard Earth's natural
resources. Robust Machine Learning methods combined with the abundance of
high-resolution satellite imagery can provide accurate and timely mappings of
the affected area in order to assess the scale of the event, identify the
impacted assets and prioritize and allocate resources effectively for the
proper restoration of the damaged region. In this work, we create and introduce
a machine-learning ready dataset we name FLOGA (Forest wiLdfire Observations
for the Greek Area). This dataset is unique as it comprises of satellite
imagery acquired before and after a wildfire event, it contains information
from Sentinel-2 and MODIS modalities with variable spatial and spectral
resolution, and contains a large number of events where the corresponding burnt
area ground truth has been annotated by domain experts. FLOGA covers the wider
region of Greece, which is characterized by a Mediterranean landscape and
climatic conditions. We use FLOGA to provide a thorough comparison of multiple
Machine Learning and Deep Learning algorithms for the automatic extraction of
burnt areas, approached as a change detection task. We also compare the results
to those obtained using standard specialized spectral indices for burnt area
mapping. Finally, we propose a novel Deep Learning model, namely BAM-CD. Our
benchmark results demonstrate the efficacy of the proposed technique in the
automatic extraction of burnt areas, outperforming all other methods in terms
of accuracy and robustness. Our dataset and code are publicly available at:
https://github.com/Orion-AI-Lab/FLOGA.
</p>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03340" title="Abstract">arXiv:2311.03340</a> [<a href="/pdf/2311.03340" title="Download PDF">pdf</a>, <a href="/format/2311.03340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embedding First Order Logic into Kernel Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diligenti%2C+M">Michelangelo Diligenti</a>, 
<a href="/search/cs?searchtype=author&query=Gori%2C+M">Marco Gori</a>, 
<a href="/search/cs?searchtype=author&query=Maggini%2C+M">Marco Maggini</a>, 
<a href="/search/cs?searchtype=author&query=Rigutini%2C+L">Leonardo Rigutini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 20th International Conference on Inductive Logic Programming (ILP 2010). Florence, Italy. June 27-30 2010
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of The 20th International Conference on Inductive
  Logic Programming (ILP 2010)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">In this paper we propose a general framework to integrate supervised and
unsupervised examples with background knowledge expressed by a collection of
first-order logic clauses into kernel machines. In particular, we consider a
multi-task learning scheme where multiple predicates defined on a set of
objects are to be jointly learned from examples, enforcing a set of FOL
constraints on the admissible configurations of their values. The predicates
are defined on the feature spaces, in which the input objects are represented,
and can be either known a priori or approximated by an appropriate kernel-based
learner. A general approach is presented to convert the FOL clauses into a
continuous implementation that can deal with the outputs computed by the
kernel-based predicates. The learning problem is formulated as a
semi-supervised task that requires the optimization in the primal of a loss
function that combines a fitting loss measure on the supervised examples, a
regularization term, and a penalty term that enforces the constraints on both
the supervised and unsupervised examples. Unfortunately, the penalty term is
not convex and it can hinder the optimization process. However, it is possible
to avoid poor solutions by using a two stage learning schema, in which the
supervised examples are learned first and then the constraints are enforced.
</p>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03345" title="Abstract">arXiv:2311.03345</a> [<a href="/pdf/2311.03345" title="Download PDF">pdf</a>, <a href="/format/2311.03345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long-Term Invariant Local Features via Implicit Cross-Domain  Correspondences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pataki%2C+Z">Zador Pataki</a>, 
<a href="/search/cs?searchtype=author&query=Altillawi%2C+M">Mohammad Altillawi</a>, 
<a href="/search/cs?searchtype=author&query=Kanakis%2C+M">Menelaos Kanakis</a>, 
<a href="/search/cs?searchtype=author&query=Pautrat%2C+R">R&#xe9;mi Pautrat</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+F">Fengyi Shen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>, 
<a href="/search/cs?searchtype=author&query=Pollefeys%2C+M">Marc Pollefeys</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages + 5 pages appendix, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Modern learning-based visual feature extraction networks perform well in
intra-domain localization, however, their performance significantly declines
when image pairs are captured across long-term visual domain variations, such
as different seasonal and daytime variations. In this paper, our first
contribution is a benchmark to investigate the performance impact of long-term
variations on visual localization. We conduct a thorough analysis of the
performance of current state-of-the-art feature extraction networks under
various domain changes and find a significant performance gap between intra-
and cross-domain localization. We investigate different methods to close this
gap by improving the supervision of modern feature extractor networks. We
propose a novel data-centric method, Implicit Cross-Domain Correspondences
(iCDC). iCDC represents the same environment with multiple Neural Radiance
Fields, each fitting the scene under individual visual domains. It utilizes the
underlying 3D representations to generate accurate correspondences across
different long-term visual conditions. Our proposed method enhances
cross-domain localization performance, significantly reducing the performance
gap. When evaluated on popular long-term localization benchmarks, our trained
networks consistently outperform existing methods. This work serves as a
substantial stride toward more robust visual localization pipelines for
long-term deployments, and opens up research avenues in the development of
long-term invariant descriptors.
</p>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03346" title="Abstract">arXiv:2311.03346</a> [<a href="/pdf/2311.03346" title="Download PDF">pdf</a>, <a href="/ps/2311.03346" title="Download PostScript">ps</a>, <a href="/format/2311.03346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decomposing Probability Marginals Beyond Affine Requirements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Matuschke%2C+J">Jannik Matuschke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">Consider the triplet $(E, \mathcal{P}, \pi)$, where $E$ is a finite ground
set, $\mathcal{P} \subseteq 2^E$ is a collection of subsets of $E$ and $\pi :
\mathcal{P} \rightarrow [0,1]$ is a requirement function. Given a vector of
marginals $\rho \in [0, 1]^E$, our goal is to find a distribution for a random
subset $S \subseteq E$ such that $\operatorname{Pr}[e \in S] = \rho_e$ for all
$e \in E$ and $\operatorname{Pr}[P \cap S \neq \emptyset] \geq \pi_P$ for all
$P \in \mathcal{P}$, or to determine that no such distribution exists.
<br />Generalizing results of Dahan, Amin, and Jaillet, we devise a generic
decomposition algorithm that solves the above problem when provided with a
suitable sequence of admissible support candidates (ASCs). We show how to
construct such ASCs for numerous settings, including supermodular requirements,
Hoffman-Schwartz-type lattice polyhedra, and abstract networks where $\pi$
fulfils a conservation law. The resulting algorithm can be carried out
efficiently when $\mathcal{P}$ and $\pi$ can be accessed via appropriate
oracles. For any system allowing the construction of ASCs, our results imply a
simple polyhedral description of the set of marginal vectors for which the
decomposition problem is feasible. Finally, we characterize balanced
hypergraphs as the systems $(E, \mathcal{P})$ that allow the perfect
decomposition of any marginal vector $\rho \in [0,1]^E$, i.e., where we can
always find a distribution reaching the highest attainable probability
$\operatorname{Pr}[P \cap S \neq \emptyset] = \min \{ \sum_{e \in P} \rho_e,
1\}$ for all $P \in \mathcal{P}$.
</p>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03348" title="Abstract">arXiv:2311.03348</a> [<a href="/pdf/2311.03348" title="Download PDF">pdf</a>, <a href="/format/2311.03348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable and Transferable Black-Box Jailbreaks for Language Models via  Persona Modulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+R">Rusheb Shah</a>, 
<a href="/search/cs?searchtype=author&query=Feuillade--Montixi%2C+Q">Quentin Feuillade--Montixi</a>, 
<a href="/search/cs?searchtype=author&query=Pour%2C+S">Soroush Pour</a>, 
<a href="/search/cs?searchtype=author&query=Tagade%2C+A">Arush Tagade</a>, 
<a href="/search/cs?searchtype=author&query=Casper%2C+S">Stephen Casper</a>, 
<a href="/search/cs?searchtype=author&query=Rando%2C+J">Javier Rando</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite efforts to align large language models to produce harmless responses,
they are still vulnerable to jailbreak prompts that elicit unrestricted
behaviour. In this work, we investigate persona modulation as a black-box
jailbreaking method to steer a target model to take on personalities that are
willing to comply with harmful instructions. Rather than manually crafting
prompts for each persona, we automate the generation of jailbreaks using a
language model assistant. We demonstrate a range of harmful completions made
possible by persona modulation, including detailed instructions for
synthesising methamphetamine, building a bomb, and laundering money. These
automated attacks achieve a harmful completion rate of 42.5% in GPT-4, which is
185 times larger than before modulation (0.23%). These prompts also transfer to
Claude 2 and Vicuna with harmful completion rates of 61.0% and 35.9%,
respectively. Our work reveals yet another vulnerability in commercial large
language models and highlights the need for more comprehensive safeguards.
</p>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03351" title="Abstract">arXiv:2311.03351</a> [<a href="/pdf/2311.03351" title="Download PDF">pdf</a>, <a href="/format/2311.03351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uni-O4: Unifying Online and Offline Deep Reinforcement Learning with  Multi-Step On-Policy Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+K">Kun Lei</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhengmao He</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chenhao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+K">Kaizhe Hu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huazhe Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our website: <a href="https://lei-kun.github.io/uni-o4/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Combining offline and online reinforcement learning (RL) is crucial for
efficient and safe learning. However, previous approaches treat offline and
online learning as separate procedures, resulting in redundant designs and
limited performance. We ask: Can we achieve straightforward yet effective
offline and online learning without introducing extra conservatism or
regularization? In this study, we propose Uni-o4, which utilizes an on-policy
objective for both offline and online learning. Owning to the alignment of
objectives in two phases, the RL agent can transfer between offline and online
learning seamlessly. This property enhances the flexibility of the learning
paradigm, allowing for arbitrary combinations of pretraining, fine-tuning,
offline, and online learning. In the offline phase, specifically, Uni-o4
leverages diverse ensemble policies to address the mismatch issues between the
estimated behavior policy and the offline dataset. Through a simple offline
policy evaluation (OPE) approach, Uni-o4 can achieve multi-step policy
improvement safely. We demonstrate that by employing the method above, the
fusion of these two paradigms can yield superior offline initialization as well
as stable and rapid online fine-tuning capabilities. Through real-world robot
tasks, we highlight the benefits of this paradigm for rapid deployment in
challenging, previously unseen real-world environments. Additionally, through
comprehensive evaluations using numerous simulated benchmarks, we substantiate
that our method achieves state-of-the-art performance in both offline and
offline-to-online fine-tuning learning. Our website:
https://lei-kun.github.io/uni-o4/ .
</p>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03352" title="Abstract">arXiv:2311.03352</a> [<a href="/pdf/2311.03352" title="Download PDF">pdf</a>, <a href="/format/2311.03352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Evaluation Metrics of Open-Vocabulary Segmentaion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+T">Tiancheng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangtai Li</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+L">Lu Qi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we highlight a problem of evaluation metrics adopted in the
open-vocabulary segmentation. That is, the evaluation process still heavily
relies on closed-set metrics on zero-shot or cross-dataset pipelines without
considering the similarity between predicted and ground truth categories. To
tackle this issue, we first survey eleven similarity measurements between two
categorical words using WordNet linguistics statistics, text embedding, and
language models by comprehensive quantitative analysis and user study. Built
upon those explored measurements, we designed novel evaluation metrics, namely
Open mIoU, Open AP, and Open PQ, tailored for three open-vocabulary
segmentation tasks. We benchmarked the proposed evaluation metrics on 12
open-vocabulary methods of three segmentation tasks. Even though the relative
subjectivity of similarity distance, we demonstrate that our metrics can still
well evaluate the open ability of the existing open-vocabulary segmentation
methods. We hope that our work can bring with the community new thinking about
how to evaluate the open ability of models. The evaluation code is released in
github.
</p>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03354" title="Abstract">arXiv:2311.03354</a> [<a href="/pdf/2311.03354" title="Download PDF">pdf</a>, <a href="/format/2311.03354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoVLM: Composing Visual Entities and Relationships in Large Language  Models Via Communicative Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junyan Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Delin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yining Hong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenfang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peihao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yikang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chuang Gan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">A remarkable ability of human beings resides in compositional reasoning,
i.e., the capacity to make "infinite use of finite means". However, current
large vision-language foundation models (VLMs) fall short of such compositional
abilities due to their "bag-of-words" behaviors and inability to construct
words that correctly represent visual entities and the relations among the
entities. To this end, we propose CoVLM, which can guide the LLM to explicitly
compose visual entities and relationships among the text and dynamically
communicate with the vision encoder and detection network to achieve
vision-language communicative decoding. Specifically, we first devise a set of
novel communication tokens for the LLM, for dynamic communication between the
visual detection system and the language system. A communication token is
generated by the LLM following a visual entity or a relation, to inform the
detection network to propose regions that are relevant to the sentence
generated so far. The proposed regions-of-interests (ROIs) are then fed back
into the LLM for better language generation contingent on the relevant regions.
The LLM is thus able to compose the visual entities and relationships through
the communication tokens. The vision-to-language and language-to-vision
communication are iteratively performed until the entire sentence is generated.
Our framework seamlessly bridges the gap between visual perception and LLMs and
outperforms previous VLMs by a large margin on compositional reasoning
benchmarks (e.g., ~20% in HICO-DET mAP, ~14% in Cola top-1 accuracy, and ~3% on
ARO top-1 accuracy). We also achieve state-of-the-art performances on
traditional vision-language tasks such as referring expression comprehension
and visual question answering.
</p>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03355" title="Abstract">arXiv:2311.03355</a> [<a href="/pdf/2311.03355" title="Download PDF">pdf</a>, <a href="/format/2311.03355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SegGen: Supercharging Segmentation Models with Text2Mask and Mask2Img  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Hanrong Ye</a>, 
<a href="/search/cs?searchtype=author&query=Kuen%2C+J">Jason Kuen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhe Lin</a>, 
<a href="/search/cs?searchtype=author&query=Price%2C+B">Brian Price</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose SegGen, a highly-effective training data generation method for
image segmentation, which pushes the performance limits of state-of-the-art
segmentation models to a significant extent. SegGen designs and integrates two
data generation strategies: MaskSyn and ImgSyn. (i) MaskSyn synthesizes new
mask-image pairs via our proposed text-to-mask generation model and
mask-to-image generation model, greatly improving the diversity in segmentation
masks for model supervision; (ii) ImgSyn synthesizes new images based on
existing masks using the mask-to-image generation model, strongly improving
image diversity for model inputs. On the highly competitive ADE20K and COCO
benchmarks, our data generation method markedly improves the performance of
state-of-the-art segmentation models in semantic segmentation, panoptic
segmentation, and instance segmentation. Notably, in terms of the ADE20K mIoU,
Mask2Former R50 is largely boosted from 47.2 to 49.9 (+2.7); Mask2Former Swin-L
is also significantly increased from 56.1 to 57.4 (+1.3). These promising
results strongly suggest the effectiveness of our SegGen even when abundant
human-annotated training data is utilized. Moreover, training with our
synthetic data makes the segmentation models more robust towards unseen
domains. Project website: https://seggenerator.github.io
</p>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03356" title="Abstract">arXiv:2311.03356</a> [<a href="/pdf/2311.03356" title="Download PDF">pdf</a>, <a href="/format/2311.03356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GLaMM: Pixel Grounding Large Multimodal Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rasheed%2C+H">Hanoona Rasheed</a>, 
<a href="/search/cs?searchtype=author&query=Maaz%2C+M">Muhammad Maaz</a>, 
<a href="/search/cs?searchtype=author&query=Shaji%2C+S">Sahal Shaji</a>, 
<a href="/search/cs?searchtype=author&query=Shaker%2C+A">Abdelrahman Shaker</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Salman Khan</a>, 
<a href="/search/cs?searchtype=author&query=Cholakkal%2C+H">Hisham Cholakkal</a>, 
<a href="/search/cs?searchtype=author&query=Anwer%2C+R+M">Rao M. Anwer</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+E">Erix Xing</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+F+S">Fahad S. Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report of GLaMM
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Multimodal Models (LMMs) extend Large Language Models to the vision
domain. Initial efforts towards LMMs used holistic images and text prompts to
generate ungrounded textual responses. Very recently, region-level LMMs have
been used to generate visually grounded responses. However, they are limited to
only referring a single object category at a time, require users to specify the
regions in inputs, or cannot offer dense pixel-wise object grounding. In this
work, we present Grounding LMM (GLaMM), the first model that can generate
natural language responses seamlessly intertwined with corresponding object
segmentation masks. GLaMM not only grounds objects appearing in the
conversations but is flexible enough to accept both textual and optional visual
prompts (region of interest) as input. This empowers users to interact with the
model at various levels of granularity, both in textual and visual domains. Due
to the lack of standard benchmarks for the novel setting of generating visually
grounded detailed conversations, we introduce a comprehensive evaluation
protocol with our curated grounded conversations. Our proposed Grounded
Conversation Generation (GCG) task requires densely grounded concepts in
natural scenes at a large-scale. To this end, we propose a densely annotated
Grounding-anything Dataset (GranD) using our proposed automated annotation
pipeline that encompasses 7.5M unique concepts grounded in a total of 810M
regions available with segmentation masks. Besides GCG, GLaMM also performs
effectively on several downstream tasks e.g., referring expression
segmentation, image and region-level captioning and vision-language
conversations. Project Page: https://mbzuai-oryx.github.io/groundingLMM.
</p>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03357" title="Abstract">arXiv:2311.03357</a> [<a href="/pdf/2311.03357" title="Download PDF">pdf</a>, <a href="/format/2311.03357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploitation-Guided Exploration for Semantic Embodied Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wasserman%2C+J">Justin Wasserman</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhary%2C+G">Girish Chowdhary</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhinav Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+U">Unnat Jain</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and results available at <a href="http://xgxvisnav.github.io">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">In the recent progress in embodied navigation and sim-to-robot transfer,
modular policies have emerged as a de facto framework. However, there is more
to compositionality beyond the decomposition of the learning load into modular
components. In this work, we investigate a principled way to syntactically
combine these components. Particularly, we propose Exploitation-Guided
Exploration (XGX) where separate modules for exploration and exploitation come
together in a novel and intuitive manner. We configure the exploitation module
to take over in the deterministic final steps of navigation i.e. when the goal
becomes visible. Crucially, an exploitation module teacher-forces the
exploration module and continues driving an overridden policy optimization.
XGX, with effective decomposition and novel guidance, improves the
state-of-the-art performance on the challenging object navigation task from 70%
to 73%. Along with better accuracy, through targeted analysis, we show that XGX
is also more efficient at goal-conditioned exploration. Finally, we show
sim-to-real transfer to robot hardware and XGX performs over two-fold better
than the best baseline from simulation benchmarking. Project page:
xgxvisnav.github.io
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Tue,  7 Nov 23</h3>
<dl>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02088" title="Abstract">arXiv:2311.02088</a> (cross-list from q-fin.CP) [<a href="/pdf/2311.02088" title="Download PDF">pdf</a>, <a href="/format/2311.02088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combining Deep Learning on Order Books with Reinforcement Learning for  Profitable Trading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Jaddu%2C+K+S">Koti S. Jaddu</a>, 
<a href="/search/q-fin?searchtype=author&query=Bilokon%2C+P+A">Paul A. Bilokon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Finance (q-fin.CP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Portfolio Management (q-fin.PM); Trading and Market Microstructure (q-fin.TR)

</div>
<p class="mathjax">High-frequency trading is prevalent, where automated decisions must be made
quickly to take advantage of price imbalances and patterns in price action that
forecast near-future movements. While many algorithms have been explored and
tested, analytical methods fail to harness the whole nature of the market
environment by focusing on a limited domain. With the evergrowing machine
learning field, many large-scale end-to-end studies on raw data have been
successfully employed to increase the domain scope for profitable trading but
are very difficult to replicate. Combining deep learning on the order books
with reinforcement learning is one way of breaking down large-scale end-to-end
learning into more manageable and lightweight components for reproducibility,
suitable for retail trading.
<br />The following work focuses on forecasting returns across multiple horizons
using order flow imbalance and training three temporal-difference learning
models for five financial instruments to provide trading signals. The
instruments used are two foreign exchange pairs (GBPUSD and EURUSD), two
indices (DE40 and FTSE100), and one commodity (XAUUSD). The performances of
these 15 agents are evaluated through backtesting simulation, and successful
models proceed through to forward testing on a retail trading platform. The
results prove potential but require further minimal modifications for
consistently profitable trading to fully handle retail trading costs, slippage,
and spread fluctuation.
</p>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02090" title="Abstract">arXiv:2311.02090</a> (cross-list from physics.soc-ph) [<a href="/pdf/2311.02090" title="Download PDF">pdf</a>, <a href="/format/2311.02090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ancillary Services in Power System Transition Toward a 100% Non-Fossil  Future: Market Design Challenges in the United States and Europe
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Viola%2C+L">Luigi Viola</a> (1), 
<a href="/search/physics?searchtype=author&query=Nordin%2C+S">Saeed Nordin</a> (2), 
<a href="/search/physics?searchtype=author&query=Dotta%2C+D">Daniel Dotta</a> (1), 
<a href="/search/physics?searchtype=author&query=Hesamzadeh%2C+M+R">Mohammad Reza Hesamzadeh</a> (2), 
<a href="/search/physics?searchtype=author&query=Baldick%2C+R">Ross Baldick</a> (3), 
<a href="/search/physics?searchtype=author&query=Flynn%2C+D">Damian Flynn</a> (4) ((1) University of Campinas, Campinas-SP, Brazil, (2) KTH Royal Institute of Technology, Stockholm, Sweden, (3) University of Texas at Austin, Austin, TX, USA, (4) University College Dublin, Dublin, Ireland)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 64 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; General Economics (econ.GN); Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">The expansion of variable generation has driven a transition toward a 100\%
non-fossil power system. New system needs are challenging system stability and
suggesting the need for a redesign of the ancillary service (AS) markets. This
paper presents a comprehensive and broad review for industrial practitioners
and academic researchers regarding the challenges and potential solutions to
accommodate high shares of variable renewable energy (VRE) generation levels.
We detail the main drivers enabling the energy transition and facilitating the
provision of ASs. A systematic review of the United States and European AS
markets is conducted. We clearly organize the main ASs in a standard taxonomy,
identifying current practices and initiatives to support the increasing VRE
share. Furthermore, we envision the future of modern AS markets, proposing
potential solutions for some remaining fundamental technical and market design
challenges.
</p>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02096" title="Abstract">arXiv:2311.02096</a> (cross-list from physics.acc-ph) [<a href="/pdf/2311.02096" title="Download PDF">pdf</a>, <a href="/format/2311.02096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Autoencoders for Noise Reduction in Industrial LLRF Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Edelen%2C+J+P">J. P. Edelen</a>, 
<a href="/search/physics?searchtype=author&query=Henderson%2C+M+J">M. J. Henderson</a>, 
<a href="/search/physics?searchtype=author&query=Einstein-Curtis%2C+J">J. Einstein-Curtis</a>, 
<a href="/search/physics?searchtype=author&query=Hall%2C+C+C">C. C. Hall</a>, 
<a href="/search/physics?searchtype=author&query=Cruz%2C+J+A+D">J. A. Diaz Cruz</a>, 
<a href="/search/physics?searchtype=author&query=Edelen%2C+A+L">A. L. Edelen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Talk presented at LLRF Workshop 2023 (LLRF2023, arXiv: <a href="/abs/2310.03199">2310.03199</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Accelerator Physics (physics.acc-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Industrial particle accelerators inherently operate in much dirtier
environments than typical research accelerators. This leads to an increase in
noise both in the RF system and in other electronic systems. Combined with the
fact that industrial accelerators are mass produced, there is less attention
given to optimizing the performance of an individual system. As a result,
industrial systems tend to under perform considering their hardware hardware
capabilities. With the growing demand for accelerators for medical
sterilization, food irradiation, cancer treatment, and imaging, improving the
signal processing of these machines will increase the margin for the deployment
of these systems. Our work is focusing on using machine learning techniques to
reduce the noise of RF signals used for pulse-to-pulse feedback in industrial
accelerators. We will review our algorithms, simulation results, and results
working with measured data. We will then discuss next steps for deployment and
testing on an industrial system.
</p>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02119" title="Abstract">arXiv:2311.02119</a> (cross-list from math.OC) [<a href="/pdf/2311.02119" title="Download PDF">pdf</a>, <a href="/format/2311.02119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Sequential Optimization for Switching Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kalwar%2C+D">Durgesh Kalwar</a>, 
<a href="/search/math?searchtype=author&query=S%2C+V+B">Vineeth B. S</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We consider the problem of designing a sequential decision making agent to
maximize an unknown time-varying function which switches with time. At each
step, the agent receives an observation of the function's value at a point
decided by the agent. The observation could be corrupted by noise. The agent is
also constrained to take safe decisions with high probability, i.e., the chosen
points should have a function value greater than a threshold. For this
switching environment, we propose a policy called Adaptive-SafeOpt and evaluate
its performance via simulations. The policy incorporates Bayesian optimization
and change point detection for the safe sequential optimization problem. We
observe that a major challenge in adapting to the switching change is to
identify safe decisions when the change point is detected and prevent
attraction to local optima.
</p>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02124" title="Abstract">arXiv:2311.02124</a> (cross-list from q-bio.BM) [<a href="/pdf/2311.02124" title="Download PDF">pdf</a>, <a href="/format/2311.02124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sliced Denoising: A Physics-Informed Molecular Pre-Training Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Ni%2C+Y">Yuyan Ni</a>, 
<a href="/search/q-bio?searchtype=author&query=Feng%2C+S">Shikun Feng</a>, 
<a href="/search/q-bio?searchtype=author&query=Ma%2C+W">Wei-Ying Ma</a>, 
<a href="/search/q-bio?searchtype=author&query=Ma%2C+Z">Zhi-Ming Ma</a>, 
<a href="/search/q-bio?searchtype=author&query=Lan%2C+Y">Yanyan Lan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">While molecular pre-training has shown great potential in enhancing drug
discovery, the lack of a solid physical interpretation in current methods
raises concerns about whether the learned representation truly captures the
underlying explanatory factors in observed data, ultimately resulting in
limited generalization and robustness. Although denoising methods offer a
physical interpretation, their accuracy is often compromised by ad-hoc noise
design, leading to inaccurate learned force fields. To address this limitation,
this paper proposes a new method for molecular pre-training, called sliced
denoising (SliDe), which is based on the classical mechanical intramolecular
potential theory. SliDe utilizes a novel noise strategy that perturbs bond
lengths, angles, and torsion angles to achieve better sampling over
conformations. Additionally, it introduces a random slicing approach that
circumvents the computationally expensive calculation of the Jacobian matrix,
which is otherwise essential for estimating the force field. By aligning with
physical principles, SliDe shows a 42\% improvement in the accuracy of
estimated force fields compared to current state-of-the-art denoising methods,
and thus outperforms traditional baselines on various molecular property
prediction tasks.
</p>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02143" title="Abstract">arXiv:2311.02143</a> (cross-list from cond-mat.str-el) [<a href="/pdf/2311.02143" title="Download PDF">pdf</a>, <a href="/format/2311.02143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pairing-based graph neural network for simulating quantum materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Luo%2C+D">Di Luo</a>, 
<a href="/search/cond-mat?searchtype=author&query=Dai%2C+D+D">David D. Dai</a>, 
<a href="/search/cond-mat?searchtype=author&query=Fu%2C+L">Liang Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Strongly Correlated Electrons (cond-mat.str-el)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (cs.LG); Computational Physics (physics.comp-ph); Quantum Physics (quant-ph)

</div>
<p class="mathjax">We introduce a pairing-based graph neural network, $\textit{GemiNet}$, for
simulating quantum many-body systems. Our architecture augments a BCS
mean-field wavefunction with a generalized pair amplitude parameterized by a
graph neural network. Variational Monte Carlo with GemiNet simultaneously
provides an accurate, flexible, and scalable method for simulating
many-electron systems. We apply GemiNet to two-dimensional semiconductor
electron-hole bilayers and obtain highly accurate results on a variety of
interaction-induced phases, including the exciton Bose-Einstein condensate,
electron-hole superconductor, and bilayer Wigner crystal. Our study
demonstrates the potential of physically-motivated neural network wavefunctions
for quantum materials simulations.
</p>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02146" title="Abstract">arXiv:2311.02146</a> (cross-list from stat.ML) [<a href="/pdf/2311.02146" title="Download PDF">pdf</a>, <a href="/format/2311.02146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Optimization of Function Networks with Partial Evaluations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Buathong%2C+P">Poompol Buathong</a>, 
<a href="/search/stat?searchtype=author&query=Wan%2C+J">Jiayue Wan</a>, 
<a href="/search/stat?searchtype=author&query=Daulton%2C+S">Samuel Daulton</a>, 
<a href="/search/stat?searchtype=author&query=Astudillo%2C+R">Raul Astudillo</a>, 
<a href="/search/stat?searchtype=author&query=Balandat%2C+M">Maximilian Balandat</a>, 
<a href="/search/stat?searchtype=author&query=Frazier%2C+P+I">Peter I. Frazier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 8 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">Bayesian optimization is a framework for optimizing functions that are costly
or time-consuming to evaluate. Recent work has considered Bayesian optimization
of function networks (BOFN), where the objective function is computed via a
network of functions, each taking as input the output of previous nodes in the
network and additional parameters. Exploiting this network structure has been
shown to yield significant performance improvements. Existing BOFN algorithms
for general-purpose networks are required to evaluate the full network at each
iteration. However, many real-world applications allow evaluating nodes
individually. To take advantage of this opportunity, we propose a novel
knowledge gradient acquisition function for BOFN that chooses which node to
evaluate as well as the inputs for that node in a cost-aware fashion. This
approach can dramatically reduce query costs by allowing the evaluation of part
of the network at a lower cost relative to evaluating the entire network. We
provide an efficient approach to optimizing our acquisition function and show
it outperforms existing BOFN methods and other benchmarks across several
synthetic and real-world problems. Our acquisition function is the first to
enable cost-aware optimization of a broad class of function networks.
</p>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02181" title="Abstract">arXiv:2311.02181</a> (cross-list from math.OC) [<a href="/pdf/2311.02181" title="Download PDF">pdf</a>, <a href="/format/2311.02181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Problems in Learning Multiple Dynamical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Niu%2C+M">Mengjia Niu</a>, 
<a href="/search/math?searchtype=author&query=He%2C+X">Xiaoyu He</a>, 
<a href="/search/math?searchtype=author&query=Rysavy%2C+P">Petr Rysavy</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+Q">Quan Zhou</a>, 
<a href="/search/math?searchtype=author&query=Marecek%2C+J">Jakub Marecek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Clustering of time series is a well-studied problem, with applications
ranging from quantitative, personalized models of metabolism obtained from
metabolite concentrations to state discrimination in quantum information
theory. We consider a variant, where given a set of trajectories and a number
of parts, we jointly partition the set of trajectories and learn linear
dynamical system (LDS) models for each part, so as to minimize the maximum
error across all the models. We present globally convergent methods and EM
heuristics, accompanied by promising computational results.
</p>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02190" title="Abstract">arXiv:2311.02190</a> (cross-list from quant-ph) [<a href="/pdf/2311.02190" title="Download PDF">pdf</a>, <a href="/format/2311.02190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Tensor as an Informational Resource
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Christandl%2C+M">Matthias Christandl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Algebraic Geometry (math.AG); Combinatorics (math.CO)

</div>
<p class="mathjax">A tensor is a multidimensional array of numbers that can be used to store
data, encode a computational relation and represent quantum entanglement. In
this sense a tensor can be viewed as valuable resource whose transformation can
lead to an understanding of structure in data, computational complexity and
quantum information.
<br />In order to facilitate the understanding of this resource, we propose a
family of information-theoretically constructed preorders on tensors, which can
be used to compare tensors with each other and to assess the existence of
transformations between them. The construction places copies of a given tensor
at the edges of a hypergraph and allows transformations at the vertices. A
preorder is then induced by the transformations possible in a given growing
sequence of hypergraphs. The new family of preorders generalises the asymptotic
restriction preorder which Strassen defined in order to study the computational
complexity of matrix multiplication.
<br />We derive general properties of the preorders and their associated asymptotic
notions of tensor rank and view recent results on tensor rank non-additivity,
tensor networks and algebraic complexity in this unifying frame. We hope that
this work will provide a useful vantage point for exploring tensors in applied
mathematics, physics and computer science, but also from a purely mathematical
point of view.
</p>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02204" title="Abstract">arXiv:2311.02204</a> (cross-list from q-bio.PE) [<a href="/pdf/2311.02204" title="Download PDF">pdf</a>, <a href="/format/2311.02204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active risk aversion in SIS epidemics on networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Bizyaeva%2C+A">Anastasia Bizyaeva</a>, 
<a href="/search/q-bio?searchtype=author&query=Arango%2C+M+O">Marcela Ordorica Arango</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhou%2C+Y">Yunxiu Zhou</a>, 
<a href="/search/q-bio?searchtype=author&query=Levin%2C+S">Simon Levin</a>, 
<a href="/search/q-bio?searchtype=author&query=Leonard%2C+N+E">Naomi Ehrich Leonard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Populations and Evolution (q-bio.PE)</span>; Systems and Control (eess.SY); Dynamical Systems (math.DS)

</div>
<p class="mathjax">We present and analyze an actively controlled
Susceptible-Infected-Susceptible (actSIS) model of interconnected populations
to study how risk aversion strategies, such as social distancing, affect
network epidemics. A population using a risk aversion strategy reduces its
contact rate with other populations when it perceives an increase in infection
risk. The network actSIS model relies on two distinct networks. One is a
physical contact network that defines which populations come into contact with
which other populations and thus how infection spreads. The other is a
communication network, such as an online social network, that defines which
populations observe the infection level of which other populations and thus how
information spreads. We prove that the model, with these two networks and
populations using risk aversion strategies, exhibits a transcritical
bifurcation in which an endemic equilibrium emerges. For regular graphs, we
prove that the endemic infection level is uniform across populations and
reduced by the risk aversion strategy, relative to the network SIS endemic
level. We show that when communication is sufficiently sparse, this initially
stable equilibrium loses stability in a secondary bifurcation. Simulations show
that a new stable solution emerges with nonuniform infection levels.
</p>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02250" title="Abstract">arXiv:2311.02250</a> (cross-list from math.OC) [<a href="/pdf/2311.02250" title="Download PDF">pdf</a>, <a href="/ps/2311.02250" title="Download PostScript">ps</a>, <a href="/format/2311.02250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Scenario Generation for Chance-constrained Economic Dispatch  Considering Ambient Wind Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+Q">Qian Zhang</a>, 
<a href="/search/math?searchtype=author&query=Shukla%2C+A">Apurv Shukla</a>, 
<a href="/search/math?searchtype=author&query=Xie%2C+L">Le Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Scenario generation is an effective data-driven method for solving
chance-constrained optimization while ensuring desired risk guarantees with a
finite number of samples. Crucial challenges in deploying this technique in the
real world arise due to the absence of appropriate risk-tuning models tailored
for the desired application. In this paper, we focus on designing efficient
scenario generation schemes for economic dispatch in power systems. We propose
a novel scenario generation method based on filtering scenarios using ambient
wind conditions. These filtered scenarios are deployed incrementally in order
to meet desired risk levels while using minimum resources. In order to study
the performance of the proposed scheme, we illustrate the procedure on case
studies performed for both 24-bus and 118-bus systems with real-world wind
power forecasting data. Numerical results suggest that the proposed
filter-and-increment scenario generation model leads to a precise and efficient
solution for the chance-constrained economic dispatch problem.
</p>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02254" title="Abstract">arXiv:2311.02254</a> (cross-list from eess.IV) [<a href="/pdf/2311.02254" title="Download PDF">pdf</a>, <a href="/format/2311.02254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning-Based and Quality Preserving Super-Resolution of Noisy Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cammarasana%2C+S">Simone Cammarasana</a>, 
<a href="/search/eess?searchtype=author&query=Patan%C3%A8%2C+G">Giuseppe Patan&#xe8;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)

</div>
<p class="mathjax">Several applications require the super-resolution of noisy images and the
preservation of geometrical and texture features. State-of-the-art
super-resolution methods do not account for noise and generally enhance the
output image's artefacts (e.g., aliasing, blurring). We propose a
learning-based method that accounts for the presence of noise and preserves the
properties of the input image, as measured by quantitative metrics (e.g.,
normalised crossed correlation, normalised mean squared error,
peak-signal-to-noise-ration, structural similarity feature-based similarity,
universal image quality). We train our network to up-sample a low-resolution
noisy image while preserving its properties. We perform our tests on the Cineca
Marconi100 cluster, at the 26th position in the top500 list. The experimental
results show that our method outperforms learning-based methods, has comparable
results with standard methods, preserves the properties of the input image as
contours, brightness, and textures, and reduces the artefacts. As average
quantitative metrics, our method has a PSNR value of 23.81 on the
super-resolution of Gaussian noise images with a 2X up-sampling factor. In
contrast, previous work has a PSNR value of 23.09 (standard method) and 21.78
(learning-based method). Our learning-based and quality-preserving
super-resolution improves the high-resolution prediction of noisy images with
respect to state-of-the-art methods with different noise types and up-sampling
factors.
</p>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02258" title="Abstract">arXiv:2311.02258</a> (cross-list from q-bio.NC) [<a href="/pdf/2311.02258" title="Download PDF">pdf</a>, <a href="/format/2311.02258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Time-Invariant Representations for Individual Neurons from  Population Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Mi%2C+L">Lu Mi</a>, 
<a href="/search/q-bio?searchtype=author&query=Le%2C+T">Trung Le</a>, 
<a href="/search/q-bio?searchtype=author&query=He%2C+T">Tianxing He</a>, 
<a href="/search/q-bio?searchtype=author&query=Shlizerman%2C+E">Eli Shlizerman</a>, 
<a href="/search/q-bio?searchtype=author&query=S%C3%BCmb%C3%BCl%2C+U">Uygar S&#xfc;mb&#xfc;l</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Neurons can display highly variable dynamics. While such variability
presumably supports the wide range of behaviors generated by the organism,
their gene expressions are relatively stable in the adult brain. This suggests
that neuronal activity is a combination of its time-invariant identity and the
inputs the neuron receives from the rest of the circuit. Here, we propose a
self-supervised learning based method to assign time-invariant representations
to individual neurons based on permutation-, and population size-invariant
summary of population recordings. We fit dynamical models to neuronal activity
to learn a representation by considering the activity of both the individual
and the neighboring population. Our self-supervised approach and use of
implicit representations enable robust inference against imperfections such as
partial overlap of neurons across sessions, trial-to-trial variability, and
limited availability of molecular (transcriptomic) labels for downstream
supervised tasks. We demonstrate our method on a public multimodal dataset of
mouse cortical neuronal activity and transcriptomic labels. We report &gt; 35%
improvement in predicting the transcriptomic subclass identity and &gt; 20%
improvement in predicting class identity with respect to the state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02266" title="Abstract">arXiv:2311.02266</a> (cross-list from eess.IV) [<a href="/pdf/2311.02266" title="Download PDF">pdf</a>, <a href="/format/2311.02266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-task Learning for Optical Coherence Tomography Angiography (OCTA)  Vessel Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Koz%2C+C">Can Koz</a>, 
<a href="/search/eess?searchtype=author&query=Dalmaz%2C+O">Onat Dalmaz</a>, 
<a href="/search/eess?searchtype=author&query=Dayanc%2C+M">Mertay Dayanc</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Medical Imaging meets NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Optical Coherence Tomography Angiography (OCTA) is a non-invasive imaging
technique that provides high-resolution cross-sectional images of the retina,
which are useful for diagnosing and monitoring various retinal diseases.
However, manual segmentation of OCTA images is a time-consuming and
labor-intensive task, which motivates the development of automated segmentation
methods. In this paper, we propose a novel multi-task learning method for OCTA
segmentation, called OCTA-MTL, that leverages an image-to-DT (Distance
Transform) branch and an adaptive loss combination strategy. The image-to-DT
branch predicts the distance from each vessel voxel to the vessel surface,
which can provide useful shape prior and boundary information for the
segmentation task. The adaptive loss combination strategy dynamically adjusts
the loss weights according to the inverse of the average loss values of each
task, to balance the learning process and avoid the dominance of one task over
the other. We evaluate our method on the ROSE-2 dataset its superiority in
terms of segmentation performance against two baseline methods: a single-task
segmentation method and a multi-task segmentation method with a fixed loss
combination.
</p>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02292" title="Abstract">arXiv:2311.02292</a> (cross-list from quant-ph) [<a href="/pdf/2311.02292" title="Download PDF">pdf</a>, <a href="/ps/2311.02292" title="Download PostScript">ps</a>, <a href="/format/2311.02292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoherence time control by interconnection for finite-level quantum  memory systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Vladimirov%2C+I+G">Igor G. Vladimirov</a>, 
<a href="/search/quant-ph?searchtype=author&query=Petersen%2C+I+R">Ian R. Petersen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 2 figures. arXiv admin note: text overlap with <a href="/abs/2310.17232">arXiv:2310.17232</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper is concerned with open quantum systems whose dynamic variables
have an algebraic structure, similar to that of the Pauli matrices for
finite-level systems. The Hamiltonian and the operators of coupling of the
system to the external bosonic fields depend linearly on the system variables.
The fields are represented by quantum Wiener processes which drive the system
dynamics according to a quasilinear Hudson-Parthasarathy quantum stochastic
differential equation whose drift vector and dispersion matrix are affine and
linear functions of the system variables. This setting includes the
zero-Hamiltonian isolated system dynamics as a particular case, where the
system variables are constant in time, which makes them potentially applicable
as a quantum memory. In a more realistic case of nonvanishing system-field
coupling, we define a memory decoherence time when a mean-square deviation of
the system variables from their initial values becomes relatively significant
as specified by a weighting matrix and a fidelity parameter. We consider the
decoherence time maximization over the energy parameters of the system and
obtain a condition under which the zero Hamiltonian provides a suboptimal
solution. This optimization problem is also discussed for a direct energy
coupling interconnection of such systems.
</p>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02306" title="Abstract">arXiv:2311.02306</a> (cross-list from math.ST) [<a href="/pdf/2311.02306" title="Download PDF">pdf</a>, <a href="/format/2311.02306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heteroskedastic Tensor Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhou%2C+Y">Yuchen Zhou</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+Y">Yuxin Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">Tensor clustering, which seeks to extract underlying cluster structures from
noisy tensor observations, has gained increasing attention. One extensively
studied model for tensor clustering is the tensor block model, which postulates
the existence of clustering structures along each mode and has found broad
applications in areas like multi-tissue gene expression analysis and multilayer
network analysis. However, currently available computationally feasible methods
for tensor clustering either are limited to handling i.i.d. sub-Gaussian noise
or suffer from suboptimal statistical performance, which restrains their
utility in applications that have to deal with heteroskedastic data and/or low
signal-to-noise-ratio (SNR).
<br />To overcome these challenges, we propose a two-stage method, named
$\mathsf{High\text{-}order~HeteroClustering}$ ($\mathsf{HHC}$), which starts by
performing tensor subspace estimation via a novel spectral algorithm called
$\mathsf{Thresholded~Deflated\text{-}HeteroPCA}$, followed by approximate
$k$-means to obtain cluster nodes. Encouragingly, our algorithm provably
achieves exact clustering as long as the SNR exceeds the computational limit
(ignoring logarithmic factors); here, the SNR refers to the ratio of the
pairwise disparity between nodes to the noise level, and the computational
limit indicates the lowest SNR that enables exact clustering with polynomial
runtime. Comprehensive simulation and real-data experiments suggest that our
algorithm outperforms existing algorithms across various settings, delivering
more reliable clustering performance.
</p>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02358" title="Abstract">arXiv:2311.02358</a> (cross-list from eess.IV) [<a href="/pdf/2311.02358" title="Download PDF">pdf</a>, <a href="/ps/2311.02358" title="Download PostScript">ps</a>, <a href="/format/2311.02358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Transfer in Latent Space (DTLS) Wins on Image Super-Resolution --  a Non-Denoising Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hui%2C+C">Chun-Chuen Hui</a>, 
<a href="/search/eess?searchtype=author&query=Siu%2C+W">Wan-Chi Siu</a>, 
<a href="/search/eess?searchtype=author&query=Law%2C+N">Ngai-Fong Law</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Large scale image super-resolution is a challenging computer vision task,
since vast information is missing in a highly degraded image, say for example
forscale x16 super-resolution. Diffusion models are used successfully in recent
years in extreme super-resolution applications, in which Gaussian noise is used
as a means to form a latent photo-realistic space, and acts as a link between
the space of latent vectors and the latent photo-realistic space. There are
quite a few sophisticated mathematical derivations on mapping the statistics of
Gaussian noises making Diffusion Models successful. In this paper we propose a
simple approach which gets away from using Gaussian noise but adopts some basic
structures of diffusion models for efficient image super-resolution.
Essentially, we propose a DNN to perform domain transfer between neighbor
domains, which can learn the differences in statistical properties to
facilitate gradual interpolation with results of reasonable quality. Further
quality improvement is achieved by conditioning the domain transfer with
reference to the input LR image. Experimental results show that our method
outperforms not only state-of-the-art large scale super resolution models, but
also the current diffusion models for image super-resolution. The approach can
readily be extended to other image-to-image tasks, such as image enlightening,
inpainting, denoising, etc.
</p>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02365" title="Abstract">arXiv:2311.02365</a> (cross-list from physics.soc-ph) [<a href="/pdf/2311.02365" title="Download PDF">pdf</a>, <a href="/format/2311.02365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolution of reciprocity with limited payoff memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Glynatsi%2C+N+E">Nikoleta E. Glynatsi</a>, 
<a href="/search/physics?searchtype=author&query=McAvoy%2C+A">Alex McAvoy</a>, 
<a href="/search/physics?searchtype=author&query=Hilbe%2C+C">Christian Hilbe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Direct reciprocity is a mechanism for the evolution of cooperation in
repeated social interactions. According to this literature, individuals
naturally learn to adopt conditionally cooperative strategies if they have
multiple encounters with their partner. Corresponding models have greatly
facilitated our understanding of cooperation, yet they often make strong
assumptions on how individuals remember and process payoff information. For
example, when strategies are updated through social learning, it is commonly
assumed that individuals compare their average payoffs. This would require them
to compute (or remember) their payoffs against everyone else in the population.
To understand how more realistic constraints influence direct reciprocity, we
consider the evolution of conditional behaviors when individuals learn based on
more recent experiences. Even in the most extreme case that they only take into
account their very last interaction, we find that cooperation can still evolve.
However, such individuals adopt less generous strategies, and they tend to
cooperate less often than in the classical setup with average payoffs.
Interestingly, once individuals remember the payoffs of two or three recent
interactions, cooperation rates quickly approach the classical limit. These
findings contribute to a literature that explores which kind of cognitive
capabilities are required for reciprocal cooperation. While our results suggest
that some rudimentary form of payoff memory is necessary, it already suffices
to remember a few interactions.
</p>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02366" title="Abstract">arXiv:2311.02366</a> (cross-list from quant-ph) [<a href="/pdf/2311.02366" title="Download PDF">pdf</a>, <a href="/format/2311.02366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Discrimination Between Two Pure States and Dolinar-Type  Coherent-State Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Katz%2C+I">Itamar Katz</a>, 
<a href="/search/quant-ph?searchtype=author&query=Samorodnitsky%2C+A">Alex Samorodnitsky</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kochman%2C+Y">Yuval Kochman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Trans. Info. Theory. Presented in part in ITW 2020, virtual, Apr. 2021, and in the 58th Allerton conference, Monticello, IL, Sep. 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">We consider the problem of discrimination between two pure quantum states. It
is well known that the optimal measurement under both the error-probability and
log-loss criteria is a projection, while under an ``erasure-distortion''
criterion it is a three-outcome positive operator-valued measure (POVM). These
results were derived separately. We present a unified approach which finds the
optimal measurement under any distortion measure that satisfies a convexity
relation with respect to the Bhattacharyya distance. Namely, whenever the
measure is relatively convex (resp. concave), the measurement is the projection
(resp. three-outcome POVM) above. The three above-mentioned results are
obtained as special cases of this simple derivation. As for further measures
for which our result applies, we prove that Renyi entropies of order $1$ and
above (resp. $1/2$ and below) are relatively convex (resp. concave). A special
setting of great practical interest, is the discrimination between two
coherent-light waveforms. In a remarkable work by Dolinar it was shown that a
simple detector consisting of a photon counter and a feedback-controlled local
oscillator obtains the quantum-optimal error probability. Later it was shown
that the same detector (with the same local signal) is also optimal in the
log-loss sense. By applying a similar convexity approach, we obtain in a
unified manner the optimal signal for a variety of criteria.
</p>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02374" title="Abstract">arXiv:2311.02374</a> (cross-list from math.OC) [<a href="/pdf/2311.02374" title="Download PDF">pdf</a>, <a href="/format/2311.02374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Riemannian stochastic optimization methods avoid strict saddle points
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hsieh%2C+Y">Ya-Ping Hsieh</a>, 
<a href="/search/math?searchtype=author&query=Karimi%2C+M+R">Mohammad Reza Karimi</a>, 
<a href="/search/math?searchtype=author&query=Krause%2C+A">Andreas Krause</a>, 
<a href="/search/math?searchtype=author&query=Mertikopoulos%2C+P">Panayotis Mertikopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Many modern machine learning applications - from online principal component
analysis to covariance matrix identification and dictionary learning - can be
formulated as minimization problems on Riemannian manifolds, and are typically
solved with a Riemannian stochastic gradient method (or some variant thereof).
However, in many cases of interest, the resulting minimization problem is not
geodesically convex, so the convergence of the chosen solver to a desirable
solution - i.e., a local minimizer - is by no means guaranteed. In this paper,
we study precisely this question, that is, whether stochastic Riemannian
optimization algorithms are guaranteed to avoid saddle points with probability
1. For generality, we study a family of retraction-based methods which, in
addition to having a potentially much lower per-iteration cost relative to
Riemannian gradient descent, include other widely used algorithms, such as
natural policy gradient methods and mirror descent in ordinary convex spaces.
In this general setting, we show that, under mild assumptions for the ambient
manifold and the oracle providing gradient information, the policies under
study avoid strict saddle points / submanifolds with probability 1, from any
initial condition. This result provides an important sanity check for the use
of gradient methods on manifolds as it shows that, almost always, the limit
state of a stochastic Riemannian algorithm can only be a local minimizer.
</p>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02426" title="Abstract">arXiv:2311.02426</a> (cross-list from math.OC) [<a href="/pdf/2311.02426" title="Download PDF">pdf</a>, <a href="/format/2311.02426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Long-run Constrained Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pan%2C+S">Shijie Pan</a>, 
<a href="/search/math?searchtype=author&query=Huang%2C+W">Wenjie Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review of AISTATS2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, a novel Follow-the-Perturbed-Leader type algorithm is proposed
and analyzed for solving general long-term constrained optimization problems in
online manner, where the objective and constraints are not necessarily convex.
In each period, random linear perturbation and strongly concave perturbation
are incorporated in primal and dual directions, respectively, to the offline
oracle, and a global minimax point is searched as solution. Based on two
particular definitions of expected static cumulative regret, we derive the
first sublinear $O(T^{8/9})$ regret complexity for this class of problems. The
proposed algorithm is applied to tackle a long-term (risk) constrained river
pollutant source identification problem, demonstrating the validity of the
theoretical results and exhibiting superior performance compared to existing
method.
</p>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02445" title="Abstract">arXiv:2311.02445</a> (cross-list from physics.soc-ph) [<a href="/pdf/2311.02445" title="Download PDF">pdf</a>, <a href="/ps/2311.02445" title="Download PostScript">ps</a>, <a href="/format/2311.02445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-Construction of Opinion Dynamics Considering Structural Inequality:  Interdisciplinary Analysis of Complex Social Stratification, Media Influence,  and Functionalism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kawahata%2C+Y">Yasuko Kawahata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Discussion Paper:Theory of opinion distribution in human relations where trust and distrust mixed(2020)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">This study analyzes the role of meritocracy, media influence, and scheduled
theory from multiple perspectives as mechanisms that maintain inequality in
social classes. Social inequality exists in complex forms in the educational,
media, and political spheres. The study focuses on how inequality in society is
structured and reproduced and how the theory of scheduled harmony justifies
this.
</p>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02467" title="Abstract">arXiv:2311.02467</a> (cross-list from stat.ME) [<a href="/pdf/2311.02467" title="Download PDF">pdf</a>, <a href="/format/2311.02467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Individualized Policy Evaluation and Learning under Clustered Network  Interference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Imai%2C+K">Kosuke Imai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Econometrics (econ.EM)

</div>
<p class="mathjax">While there now exists a large literature on policy evaluation and learning,
much of prior work assumes that the treatment assignment of one unit does not
affect the outcome of another unit. Unfortunately, ignoring interference may
lead to biased policy evaluation and yield ineffective learned policies. For
example, treating influential individuals who have many friends can generate
positive spillover effects, thereby improving the overall performance of an
individualized treatment rule (ITR). We consider the problem of evaluating and
learning an optimal ITR under clustered network (or partial) interference where
clusters of units are sampled from a population and units may influence one
another within each cluster. Under this model, we propose an estimator that can
be used to evaluate the empirical performance of an ITR. We show that this
estimator is substantially more efficient than the standard inverse probability
weighting estimator, which does not impose any assumption about spillover
effects. We derive the finite-sample regret bound for a learned ITR, showing
that the use of our efficient evaluation estimator leads to the improved
performance of learned policies. Finally, we conduct simulation and empirical
studies to illustrate the advantages of the proposed methodology.
</p>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02473" title="Abstract">arXiv:2311.02473</a> (cross-list from math.OC) [<a href="/pdf/2311.02473" title="Download PDF">pdf</a>, <a href="/format/2311.02473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing controllers with predefined convergence-time bound using  bounded time-varying gains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aldana-L%C3%B3pez%2C+R">Rodrigo Aldana-L&#xf3;pez</a>, 
<a href="/search/math?searchtype=author&query=Seeber%2C+R">Richard Seeber</a>, 
<a href="/search/math?searchtype=author&query=Haimovich%2C+H">Hernan Haimovich</a>, 
<a href="/search/math?searchtype=author&query=G%C3%B3mez-Guti%C3%A9rrez%2C+D">David G&#xf3;mez-Guti&#xe9;rrez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a preprint of the chapter: "Designing controllers with predefined convergence-time bound using bounded time-varying gains", published in Sliding-Mode Control and Variable-Structure Systems, Springer Nature Switzerland AG 2023. The final authenticated version is available online at: <a href="https://doi.org/10.1007/978-3-031-37089-2_3">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Book Chapter "Designing controllers with predefined
  convergence-time bound using bounded time-varying gains", publised in
  Sliding-Mode Control and Variable-Structure Systems, Springer Nature
  Switzerland AG 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY); Dynamical Systems (math.DS)

</div>
<p class="mathjax">Recently, there has been a great deal of attention in a class of controllers
based on time-varying gains, called prescribed-time controllers, that steer the
system's state to the origin in the desired time, a priori set by the user,
regardless of the initial condition. Furthermore, such a class of controllers
has been shown to maintain a prescribed-time convergence in the presence of
disturbances even if the disturbance bound is unknown. However, such properties
require a time-varying gain that becomes singular at the terminal time, which
limits its application to scenarios under quantization or measurement noise.
This chapter presents a methodology to design a broader class of controllers,
called predefined-time controllers, with a prescribed convergence-time bound.
Our approach allows designing robust predefined-time controllers based on
time-varying gains while maintaining uniformly bounded time-varying gains. We
analyze the condition for uniform Lyapunov stability under the proposed
time-varying controllers.
</p>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02480" title="Abstract">arXiv:2311.02480</a> (cross-list from eess.IV) [<a href="/pdf/2311.02480" title="Download PDF">pdf</a>, <a href="/format/2311.02480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Strictly Bounded Deep Network for Unpaired Cyclic Translation of  Medical Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rai%2C+S">Swati Rai</a>, 
<a href="/search/eess?searchtype=author&query=Bhatt%2C+J+S">Jignesh S. Bhatt</a>, 
<a href="/search/eess?searchtype=author&query=Patra%2C+S+K">Sarat Kumar Patra</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE Statistical Signal Processing Workshop (SSP), Hanoi,
  Vietnam, 2023, pp. 61-65
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Medical image translation is an ill-posed problem. Unlike existing paired
unbounded unidirectional translation networks, in this paper, we consider
unpaired medical images and provide a strictly bounded network that yields a
stable bidirectional translation. We propose a patch-level concatenated cyclic
conditional generative adversarial network (pCCGAN) embedded with adaptive
dictionary learning. It consists of two cyclically connected CGANs of 47 layers
each; where both generators (each of 32 layers) are conditioned with
concatenation of alternate unpaired patches from input and target modality
images (not ground truth) of the same organ. The key idea is to exploit
cross-neighborhood contextual feature information that bounds the translation
space and boosts generalization. The generators are further equipped with
adaptive dictionaries learned from the contextual patches to reduce possible
degradation. Discriminators are 15-layer deep networks that employ minimax
function to validate the translated imagery. A combined loss function is
formulated with adversarial, non-adversarial, forward-backward cyclic, and
identity losses that further minimize the variance of the proposed learning
machine. Qualitative, quantitative, and ablation analysis show superior results
on real CT and MRI.
</p>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02488" title="Abstract">arXiv:2311.02488</a> (cross-list from eess.IV) [<a href="/pdf/2311.02488" title="Download PDF">pdf</a>, <a href="/format/2311.02488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Network Reconstruction of the Left Atrium using Sparse Catheter  Paths
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Baram%2C+A">Alon Baram</a>, 
<a href="/search/eess?searchtype=author&query=Safran%2C+M">Moshe Safran</a>, 
<a href="/search/eess?searchtype=author&query=Noy%2C+T">Tomer Noy</a>, 
<a href="/search/eess?searchtype=author&query=Geri%2C+N">Naveh Geri</a>, 
<a href="/search/eess?searchtype=author&query=Greenspan%2C+H">Hayit Greenspan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Catheter based radiofrequency ablation for pulmonary vein isolation has
become the first line of treatment for atrial fibrillation in recent years.
This requires a rather accurate map of the left atrial sub-endocardial surface
including the ostia of the pulmonary veins, which requires dense sampling of
the surface and takes more than 10 minutes. The focus of this work is to
provide left atrial visualization early in the procedure to ease procedure
complexity and enable further workflows, such as using catheters that have
difficulty sampling the surface. We propose a dense encoder-decoder network
with a novel regularization term to reconstruct the shape of the left atrium
from partial data which is derived from simple catheter maneuvers. To train the
network, we acquire a large dataset of 3D atria shapes and generate
corresponding catheter trajectories. Once trained, we show that the suggested
network can sufficiently approximate the atrium shape based on a given
trajectory. We compare several network solutions for the 3D atrium
reconstruction. We demonstrate that the solution proposed produces realistic
visualization using partial acquisition within a 3-minute time interval.
Synthetic and human clinical cases are shown.
</p>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02529" title="Abstract">arXiv:2311.02529</a> (cross-list from physics.soc-ph) [<a href="/pdf/2311.02529" title="Download PDF">pdf</a>, <a href="/ps/2311.02529" title="Download PostScript">ps</a>, <a href="/format/2311.02529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detection Method for Social Subsets Consisting of Anti-Network  Construction for Unilateral Preference Behavior on Directed Temporal Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kawahata%2C+Y">Yasuko Kawahata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Discussion Paper of Asatani, Kimitaka, et al. "Communication based on unilateral preference on twitter: Internet luring in japan." Social Informatics: 10th International Conference, SocInfo 2018, St. Petersburg, Russia, September 25-28, 2018, Proceedings, Part I 10. Springer International Publishing, 2018
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">In existing research, as an example of one-sided preference, a conversation
structure in which a person who is assumed to be an adult mainly sends
one-sided messages to a person who is assumed to be a minor was observed. If
subgraphs composed based on such unilateral preferences could be automatically
extracted from the network structure, it would be possible to automatically
detect communication conducted based on specific motivations from a vast amount
of conversation data. In this study, we construct a bottom-up method to detect
subgraphs composed of unilateral preferences in Greedy, and discuss the subset
of unilateral preferences detected in this simulation.
</p>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02557" title="Abstract">arXiv:2311.02557</a> (cross-list from math.OC) [<a href="/pdf/2311.02557" title="Download PDF">pdf</a>, <a href="/format/2311.02557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Minimization of Expected Logarithmic Loss via Stochastic Dual  Averaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tsai%2C+C">Chung-En Tsai</a>, 
<a href="/search/math?searchtype=author&query=Cheng%2C+H">Hao-Chung Cheng</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+Y">Yen-Huan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Quantum Physics (quant-ph)

</div>
<p class="mathjax">Consider the problem of minimizing an expected logarithmic loss over either
the probability simplex or the set of quantum density matrices. This problem
encompasses tasks such as solving the Poisson inverse problem, computing the
maximum-likelihood estimate for quantum state tomography, and approximating
positive semi-definite matrix permanents with the currently tightest
approximation ratio. Although the optimization problem is convex, standard
iteration complexity guarantees for first-order methods do not directly apply
due to the absence of Lipschitz continuity and smoothness in the loss function.
<br />In this work, we propose a stochastic first-order algorithm named $B$-sample
stochastic dual averaging with the logarithmic barrier. For the Poisson inverse
problem, our algorithm attains an $\varepsilon$-optimal solution in $\tilde{O}
(d^2/\varepsilon^2)$ time, matching the state of the art. When computing the
maximum-likelihood estimate for quantum state tomography, our algorithm yields
an $\varepsilon$-optimal solution in $\tilde{O} (d^3/\varepsilon^2)$ time,
where $d$ denotes the dimension. This improves on the time complexities of
existing stochastic first-order methods by a factor of $d^{\omega-2}$ and those
of batch methods by a factor of $d^2$, where $\omega$ denotes the matrix
multiplication exponent. Numerical experiments demonstrate that empirically,
our algorithm outperforms existing methods with explicit complexity guarantees.
</p>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02577" title="Abstract">arXiv:2311.02577</a> (cross-list from math.PR) [<a href="/pdf/2311.02577" title="Download PDF">pdf</a>, <a href="/format/2311.02577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Steady-State Analysis of Queues with Hawkes Arrival and Its Application  to Online Learning for Hawkes Queues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+X">Xinyun Chen</a>, 
<a href="/search/math?searchtype=author&query=Hong%2C+G">Guiyu Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">We investigate the long-run behavior of single-server queues with Hawkes
arrivals and general service distributions and related optimization problems.
In detail, utilizing novel coupling techniques, we establish finite moment
bounds for the stationary distribution of the workload and busy period
processes. In addition, we are able to show that, those queueing processes
converge exponentially fast to their stationary distribution. Based on these
theoretic results, we develop an efficient numerical algorithm to solve the
optimal staffing problem for the Hawkes queues in a data-driven manner.
Numerical results indicate a sharp difference in staffing for Hawkes queues,
compared to the classic GI/GI/1 model, especially in the heavy-traffic regime.
</p>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02586" title="Abstract">arXiv:2311.02586</a> (cross-list from eess.IV) [<a href="/pdf/2311.02586" title="Download PDF">pdf</a>, <a href="/format/2311.02586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthetic Tumor Manipulation: With Radiomics Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Na%2C+I">Inye Na</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+J">Jonghun Kim</a>, 
<a href="/search/eess?searchtype=author&query=Park%2C+H">Hyunjin Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted at NeurIPS 2023 Workshop: Medical Imaging meets NeurIPS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">We introduce RadiomicsFill, a synthetic tumor generator conditioned on
radiomics features, enabling detailed control and individual manipulation of
tumor subregions. This conditioning leverages conventional high-dimensional
features of the tumor (i.e., radiomics features) and thus is biologically
well-grounded. Our model combines generative adversarial networks,
radiomics-feature conditioning, and multi-task learning. Through experiments
with glioma patients, RadiomicsFill demonstrated its capability to generate
diverse, realistic tumors and its fine-tuning ability for specific radiomics
features like 'Pixel Surface' and 'Shape Sphericity'. The ability of
RadiomicsFill to generate an unlimited number of realistic synthetic tumors
offers notable prospects for both advancing medical imaging research and
potential clinical applications.
</p>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02594" title="Abstract">arXiv:2311.02594</a> (cross-list from q-bio.GN) [<a href="/pdf/2311.02594" title="Download PDF">pdf</a>, <a href="/format/2311.02594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> scBeacon: single-cell biomarker extraction via identifying paired cell  clusters across biological conditions with contrastive siamese networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+C">Chenyu Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Jin%2C+K+Y">Kweon Yong Jin</a>, 
<a href="/search/q-bio?searchtype=author&query=Ding%2C+J">Jun Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite the breakthroughs in biomarker discovery facilitated by differential
gene analysis, challenges remain, particularly at the single-cell level.
Traditional methodologies heavily rely on user-supplied cell annotations,
focusing on individually expressed data, often neglecting the critical
interactions between biological conditions, such as healthy versus diseased
states. In response, here we introduce scBeacon, an innovative framework built
upon a deep contrastive siamese network. scBeacon pioneers an unsupervised
approach, adeptly identifying matched cell populations across varied
conditions, enabling a refined differential gene analysis. By utilizing a
VQ-VAE framework, a contrastive siamese network, and a greedy iterative
strategy, scBeacon effectively pinpoints differential genes that hold potential
as key biomarkers. Comprehensive evaluations on a diverse array of datasets
validate scBeacon's superiority over existing single-cell differential gene
analysis tools. Its precision and adaptability underscore its significant role
in enhancing diagnostic accuracy in biomarker discovery. With the emphasis on
the importance of biomarkers in diagnosis, scBeacon is positioned to be a
pivotal asset in the evolution of personalized medicine and targeted
treatments.
</p>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02609" title="Abstract">arXiv:2311.02609</a> (cross-list from math.OC) [<a href="/pdf/2311.02609" title="Download PDF">pdf</a>, <a href="/format/2311.02609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dock Assignment and Truck Scheduling Problem; Consideration of Multiple  Scenarios with Resource Allocation Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Monemia%2C+R+N">Rahimeh Neamatian Monemia</a>, 
<a href="/search/math?searchtype=author&query=Gelareh%2C+S">Shahin Gelareh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">The notion of 'resource' plays an important role in the overall efficiency
and performance of most cross-docks. The processing time can often be described
in terms of the resources allocated to different trucks. Conversely, for a
given processing time, different combinations of resources can be prescribed.
We study the problem of truck scheduling and dock assignment in the presence of
resource constraints. In the absence of a closed-form (or well-defined) linear
formulation describing the processing times as a function of resources, expert'
knowledge has been mobilised to enable modelling of the problem as an integer
linear model. Two cases are taken into account: In the first one, the expert
believes in his/her estimation of the processing time for every truck and only
proposes a different combination of resources for his/her estimation, while in
the second one the expert proposes a limited number of resource deployment
scenarios for serving trucks, each of which has a different combination of
resources and different processing times. We propose a novel compact integer
programming formulation for the problem, which is particularly designed with an
embedded structure that can be exploited in dual decomposition techniques with
a remarkably computationally efficient column generation approach in this case.
The case in which a scenario with invariant processing time is considered and
modelled as a special case of the proposed model. Since a direct application of
commercial solvers such as CPLEX to solve instances of this problem is not
realistic, we propose a branch-and-price framework and, moreover, several
classes of valid inequalities. Our extensive computational experiments confirm
that the proposed exact solution framework is very efficient and viable in
solving real-size instances of the practice and in a reasonable amount of time.
</p>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02610" title="Abstract">arXiv:2311.02610</a> (cross-list from stat.AP) [<a href="/pdf/2311.02610" title="Download PDF">pdf</a>, <a href="/format/2311.02610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An adaptive standardisation model for Day-Ahead electricity price  forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sebasti%C3%A1n%2C+C">Carlos Sebasti&#xe1;n</a>, 
<a href="/search/stat?searchtype=author&query=Gonz%C3%A1lez-Guill%C3%A9n%2C+C+E">Carlos E. Gonz&#xe1;lez-Guill&#xe9;n</a>, 
<a href="/search/stat?searchtype=author&query=Juan%2C+J">Jes&#xfa;s Juan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">The study of Day-Ahead prices in the electricity market is one of the most
popular problems in time series forecasting. Previous research has focused on
employing increasingly complex learning algorithms to capture the sophisticated
dynamics of the market. However, there is a threshold where increased
complexity fails to yield substantial improvements. In this work, we propose an
alternative approach by introducing an adaptive standardisation to mitigate the
effects of dataset shifts that commonly occur in the market. By doing so,
learning algorithms can prioritize uncovering the true relationship between the
target variable and the explanatory variables. We investigate four distinct
markets, including two novel datasets, previously unexplored in the literature.
These datasets provide a more realistic representation of the current market
context, that conventional datasets do not show. The results demonstrate a
significant improvement across all four markets, using learning algorithms that
are less complex yet widely accepted in the literature. This significant
advancement unveils opens up new lines of research in this field, highlighting
the potential of adaptive transformations in enhancing the performance of
forecasting models.
</p>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02644" title="Abstract">arXiv:2311.02644</a> (cross-list from math.PR) [<a href="/pdf/2311.02644" title="Download PDF">pdf</a>, <a href="/format/2311.02644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Some Results on Random Mixed SAT Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Basse-O%27Connor%2C+A">Andreas Basse-O&#x27;Connor</a>, 
<a href="/search/math?searchtype=author&query=Overgaard%2C+T+L">Tobias Lindhardt Overgaard</a>, 
<a href="/search/math?searchtype=author&query=Skj%C3%B8tt%2C+M">Mette Skj&#xf8;tt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in proceedings of 23rd EYSM
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">In this short paper we present a survey of some results concerning the random
SAT problems. To elaborate, the Boolean Satisfiability (SAT) Problem refers to
the problem of determining whether a given set of $m$ Boolean constraints over
$n$ variables can be simultaneously satisfied, i.e. all evaluate to $1$ under
some interpretation of the variables in $\{ 0,1\}$. If we choose the $m$
constraints i.i.d. uniformly at random among the set of disjunctive clauses of
length $k$, then the problem is known as the random $k$-SAT problem. It is
conjectured that this problem undergoes a structural phase transition; taking
$m=\alpha n$ for $\alpha&gt;0$, it is believed that the probability of there
existing a satisfying assignment tends in the large $n$ limit to $1$ if
$\alpha&lt;\alpha_\mathrm{sat}(k)$, and to $0$ if $\alpha&gt;\alpha_\mathrm{sat}(k)$,
for some critical value $\alpha_\mathrm{sat}(k)$ depending on $k$. We review
some of the progress made towards proving this and consider similar conjectures
and results for the more general case where the clauses are chosen with varying
lengths, i.e. for the so-called random mixed SAT problems.
</p>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02685" title="Abstract">arXiv:2311.02685</a> (cross-list from math.CO) [<a href="/pdf/2311.02685" title="Download PDF">pdf</a>, <a href="/ps/2311.02685" title="Download PostScript">ps</a>, <a href="/format/2311.02685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing Remoteness Functions of Moore, Wythoff, and Euclid&#x27;s games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Boros%2C+E">Endre Boros</a>, 
<a href="/search/math?searchtype=author&query=Gurvich%2C+V">Vladimir Gurvich</a>, 
<a href="/search/math?searchtype=author&query=Makino%2C+K">Kazuhisa Makino</a>, 
<a href="/search/math?searchtype=author&query=Vyalyi%2C+M">Michael Vyalyi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">We study remoteness function $\mathcal R$ of impartial games introduced by
Smith in 1966. The player who moves from a position $x$ can win if and only if
$\mathcal R(x)$ is odd. The odd values of $\mathcal R(x)$ show how soon the
winner can win, while even values show how long the loser can resist, provided
both players play optimally. This function can be applied to the conjunctive
compounds of impartial games, in the same way as the Sprague-Grundy function is
applicable to their disjunctive compounds.
<br />We provide polynomial algorithms computing $\mathcal R(x)$ for games Euclid
and generalized Wythoff. For Moore's NIM we give a simple explicit formula for
$\mathcal R(x)$ if it is even and show that computing it becomes an NP-hard
problem for the odd values.
</p>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02686" title="Abstract">arXiv:2311.02686</a> (cross-list from physics.soc-ph) [<a href="/pdf/2311.02686" title="Download PDF">pdf</a>, <a href="/ps/2311.02686" title="Download PostScript">ps</a>, <a href="/format/2311.02686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deciphering Unilateral Communication Patterns in Directed Temporal  Networks: Network Role Distribution Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kawahata%2C+Y">Yasuko Kawahata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Discussion Paper of Asatani, Kimitaka, et al. "Communication based on unilateral preference on twitter: Internet luring in japan." Social Informatics: 10th International Conference, SocInfo 2018, St. Petersburg, Russia, September 25-28, 2018, Proceedings, Part I 10. Springer International Publishing, 2018
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">In the vast expanse of online communication, identifying unilateral
preference patterns can be pivotal in understanding and mitigating risks such
as predatory behavior. This paper presents a comprehensive approach to dissect
and visualize such patterns in social networks. Through the lens of a directed
network model, we simulate a scenario where a predominant cluster 'A' disperses
information unilaterally towards a much larger, but passive, cluster 'B', while
being overseen by a vigilant cluster 'C', restricted by an information blocking
cluster 'D', and countered by an alerting cluster 'E'. Incorporated into this
study is a simulation framework that models the flow of information across a
directed network comprising various clusters with distinct roles and
communication behaviors. The simulation employs a dynamic system where clusters
'A' through 'E' interact over a series of time steps, with each cluster's
activity shaped by both intrinsic message-generation rules and external media
influences. By tracking the accumulated media influence on each cluster, we
gain a nuanced understanding of the long-term effects of media on communication
patterns. The results provide a window into the cyclical nature of influence
and the propagation of information, with potential applications in detecting
and mitigating unilateral communication patterns that could signal harmful
activities such as online predation.
<br />This study, therefore, presents a comprehensive approach that combines
network theory, simulation modeling, and dynamic media influence analysis to
explore and understand the complexities of unilateral preference communication
within social networks.
</p>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02695" title="Abstract">arXiv:2311.02695</a> (cross-list from stat.ML) [<a href="/pdf/2311.02695" title="Download PDF">pdf</a>, <a href="/format/2311.02695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying Linearly-Mixed Causal Representations from Multi-Node  Interventions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bing%2C+S">Simon Bing</a>, 
<a href="/search/stat?searchtype=author&query=Ninad%2C+U">Urmi Ninad</a>, 
<a href="/search/stat?searchtype=author&query=Wahl%2C+J">Jonas Wahl</a>, 
<a href="/search/stat?searchtype=author&query=Runge%2C+J">Jakob Runge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Currently under review. Comments welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
<p class="mathjax">The task of inferring high-level causal variables from low-level
observations, commonly referred to as causal representation learning, is
fundamentally underconstrained. As such, recent works to address this problem
focus on various assumptions that lead to identifiability of the underlying
latent causal variables. A large corpus of these preceding approaches consider
multi-environment data collected under different interventions on the causal
model. What is common to virtually all of these works is the restrictive
assumption that in each environment, only a single variable is intervened on.
In this work, we relax this assumption and provide the first identifiability
result for causal representation learning that allows for multiple variables to
be targeted by an intervention within one environment. Our approach hinges on a
general assumption on the coverage and diversity of interventions across
environments, which also includes the shared assumption of single-node
interventions of previous works. The main idea behind our approach is to
exploit the trace that interventions leave on the variance of the ground truth
causal variables and regularizing for a specific notion of sparsity with
respect to this trace. In addition to and inspired by our theoretical
contributions, we present a practical algorithm to learn causal representations
from multi-node interventional data and provide empirical evidence that
validates our identifiability results.
</p>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02704" title="Abstract">arXiv:2311.02704</a> (cross-list from q-bio.NC) [<a href="/pdf/2311.02704" title="Download PDF">pdf</a>, <a href="/format/2311.02704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Goal-Driven Approach to Systems Neuroscience
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Nayebi%2C+A">Aran Nayebi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 230 pages, Stanford University PhD Thesis, March 2022: <a href="https://purl.stanford.edu/qk457cr2641">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Humans and animals exhibit a range of interesting behaviors in dynamic
environments, and it is unclear how our brains actively reformat this dense
sensory information to enable these behaviors. Experimental neuroscience is
undergoing a revolution in its ability to record and manipulate hundreds to
thousands of neurons while an animal is performing a complex behavior. As these
paradigms enable unprecedented access to the brain, a natural question that
arises is how to distill these data into interpretable insights about how
neural circuits give rise to intelligent behaviors. The classical approach in
systems neuroscience has been to ascribe well-defined operations to individual
neurons and provide a description of how these operations combine to produce a
circuit-level theory of neural computations. While this approach has had some
success for small-scale recordings with simple stimuli, designed to probe a
particular circuit computation, often times these ultimately lead to disparate
descriptions of the same system across stimuli. Perhaps more strikingly, many
response profiles of neurons are difficult to succinctly describe in words,
suggesting that new approaches are needed in light of these experimental
observations. In this thesis, we offer a different definition of
interpretability that we show has promise in yielding unified structural and
functional models of neural circuits, and describes the evolutionary
constraints that give rise to the response properties of the neural population,
including those that have previously been difficult to describe individually.
We demonstrate the utility of this framework across multiple brain areas and
species to study the roles of recurrent processing in the primate ventral
visual pathway; mouse visual processing; heterogeneity in rodent medial
entorhinal cortex; and facilitating biological learning.
</p>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02743" title="Abstract">arXiv:2311.02743</a> (cross-list from math.CO) [<a href="/pdf/2311.02743" title="Download PDF">pdf</a>, <a href="/ps/2311.02743" title="Download PostScript">ps</a>, <a href="/format/2311.02743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear extensions of finite posets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chan%2C+S+H">Swee Hong Chan</a>, 
<a href="/search/math?searchtype=author&query=Pak%2C+I">Igor Pak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 55 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We give a broad survey of inequalities for the number of linear extensions of
finite posets. We review many examples, discuss open problems, and present
recent results on the subject. We emphasize the bounds, the equality conditions
of the inequalities, and the computational complexity aspects of the results.
</p>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02763" title="Abstract">arXiv:2311.02763</a> (cross-list from math.ST) [<a href="/pdf/2311.02763" title="Download PDF">pdf</a>, <a href="/ps/2311.02763" title="Download PostScript">ps</a>, <a href="/format/2311.02763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Log-Concavity of Multinomial Likelihood Functions Under Interval  Censoring Constraints on Frequencies or Their Partial Sums
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Levin%2C+B">Bruce Levin</a>, 
<a href="/search/math?searchtype=author&query=Learned-Miller%2C+E">Erik Learned-Miller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">We show that the likelihood function for a multinomial vector observed under
arbitrary interval censoring constraints on the frequencies or their partial
sums is completely log-concave by proving that the constrained sample spaces
comprise M-convex subsets of the discrete simplex.
</p>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02769" title="Abstract">arXiv:2311.02769</a> (cross-list from quant-ph) [<a href="/pdf/2311.02769" title="Download PDF">pdf</a>, <a href="/format/2311.02769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shorter Pulses, Smaller Errors: Quantum Circuit Optimization via  Parameterized Pulses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Voichick%2C+F">Finn Voichick</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lampropoulos%2C+L">Leonidas Lampropoulos</a>, 
<a href="/search/quant-ph?searchtype=author&query=Rand%2C+R">Robert Rand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">We propose a technique for optimizing quantum programs by temporally
stretching pre-calibrated pulses. As an example, we modify a three-qubit
Toffoli gate implementation by using an off-the-shelf numerical optimization
algorithm to shorten the cross-resonance pulses in the sequence. Preliminary
quantum process tomography results suggest that our strategy sometimes halves a
Toffoli gate's error in practice, increasing process fidelity from around 60%
to around 80%. Unlike existing quantum control techniques, ours takes seconds
to converge, demonstrating its potential utility when incorporated into a
general-purpose compiler pass that improves both the time and the accuracy of
quantum programs.
</p>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02794" title="Abstract">arXiv:2311.02794</a> (cross-list from stat.ML) [<a href="/pdf/2311.02794" title="Download PDF">pdf</a>, <a href="/format/2311.02794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modelling Cellular Perturbations with the Sparse Additive Mechanism  Shift Variational Autoencoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bereket%2C+M">Michael Bereket</a>, 
<a href="/search/stat?searchtype=author&query=Karaletsos%2C+T">Theofanis Karaletsos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Generative models of observations under interventions have been a vibrant
topic of interest across machine learning and the sciences in recent years. For
example, in drug discovery, there is a need to model the effects of diverse
interventions on cells in order to characterize unknown biological mechanisms
of action. We propose the Sparse Additive Mechanism Shift Variational
Autoencoder, SAMS-VAE, to combine compositionality, disentanglement, and
interpretability for perturbation models. SAMS-VAE models the latent state of a
perturbed sample as the sum of a local latent variable capturing
sample-specific variation and sparse global variables of latent intervention
effects. Crucially, SAMS-VAE sparsifies these global latent variables for
individual perturbations to identify disentangled, perturbation-specific latent
subspaces that are flexibly composable. We evaluate SAMS-VAE both
quantitatively and qualitatively on a range of tasks using two popular single
cell sequencing datasets. In order to measure perturbation-specific
model-properties, we also introduce a framework for evaluation of perturbation
models based on average treatment effects with links to posterior predictive
checks. SAMS-VAE outperforms comparable models in terms of generalization
across in-distribution and out-of-distribution tasks, including a combinatorial
reasoning task under resource paucity, and yields interpretable latent
structures which correlate strongly to known biological mechanisms. Our results
suggest SAMS-VAE is an interesting addition to the modeling toolkit for machine
learning-driven scientific discovery.
</p>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02827" title="Abstract">arXiv:2311.02827</a> (cross-list from stat.ML) [<a href="/pdf/2311.02827" title="Download PDF">pdf</a>, <a href="/format/2311.02827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Subagging Boosted Probit Model Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Qin%2C+T">Tian Qin</a>, 
<a href="/search/stat?searchtype=author&query=Huang%2C+W">Wei-Min Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">With the insight of variance-bias decomposition, we design a new hybrid
bagging-boosting algorithm named SBPMT for classification problems. For the
boosting part of SBPMT, we propose a new tree model called Probit Model Tree
(PMT) as base classifiers in AdaBoost procedure. For the bagging part, instead
of subsampling from the dataset at each step of boosting, we perform boosted
PMTs on each subagged dataset and combine them into a powerful "committee",
which can be viewed an incomplete U-statistic. Our theoretical analysis shows
that (1) SBPMT is consistent under certain assumptions, (2) Increase the
subagging times can reduce the generalization error of SBPMT to some extent and
(3) Large number of ProbitBoost iterations in PMT can benefit the performance
of SBPMT with fewer steps in the AdaBoost part. Those three properties are
verified by a famous simulation designed by Mease and Wyner (2008). The last
two points also provide a useful guidance in model tuning. A comparison of
performance with other state-of-the-art classification methods illustrates that
the proposed SBPMT algorithm has competitive prediction power in general and
performs significantly better in some cases.
</p>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02838" title="Abstract">arXiv:2311.02838</a> (cross-list from stat.ML) [<a href="/pdf/2311.02838" title="Download PDF">pdf</a>, <a href="/format/2311.02838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Barron Space for Graph Convolution Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chung%2C+S">Seok-Young Chung</a>, 
<a href="/search/stat?searchtype=author&query=Sun%2C+Q">Qiyu Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Graph convolutional neural network (GCNN) operates on graph domain and it has
achieved a superior performance to accomplish a wide range of tasks. In this
paper, we introduce a Barron space of functions on a compact domain of graph
signals. We prove that the proposed Barron space is a reproducing kernel Banach
space, it can be decomposed into the union of a family of reproducing kernel
Hilbert spaces with neuron kernels, and it could be dense in the space of
continuous functions on the domain. Approximation property is one of the main
principles to design neural networks. In this paper, we show that outputs of
GCNNs are contained in the Barron space and functions in the Barron space can
be well approximated by outputs of some GCNNs in the integrated square and
uniform measurements. We also estimate the Rademacher complexity of functions
with bounded Barron norm and conclude that functions in the Barron space could
be learnt from their random samples efficiently.
</p>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02855" title="Abstract">arXiv:2311.02855</a> (cross-list from eess.IV) [<a href="/pdf/2311.02855" title="Download PDF">pdf</a>, <a href="/format/2311.02855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural-based Compression Scheme for Solar Image Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zafari%2C+A">Ali Zafari</a>, 
<a href="/search/eess?searchtype=author&query=Khoshkhahtinat%2C+A">Atefeh Khoshkhahtinat</a>, 
<a href="/search/eess?searchtype=author&query=Grajeda%2C+J+A">Jeremy A. Grajeda</a>, 
<a href="/search/eess?searchtype=author&query=Mehta%2C+P+M">Piyush M. Mehta</a>, 
<a href="/search/eess?searchtype=author&query=Nasrabadi%2C+N+M">Nasser M. Nasrabadi</a>, 
<a href="/search/eess?searchtype=author&query=Boucheron%2C+L+E">Laura E. Boucheron</a>, 
<a href="/search/eess?searchtype=author&query=Thompson%2C+B+J">Barbara J. Thompson</a>, 
<a href="/search/eess?searchtype=author&query=Kirk%2C+M+S+F">Michael S. F. Kirk</a>, 
<a href="/search/eess?searchtype=author&query=da+Silva%2C+D">Daniel da Silva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in IEEE Transactions on Aerospace and Electronic Systems (TAES). arXiv admin note: text overlap with <a href="/abs/2210.06478">arXiv:2210.06478</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Information Theory (cs.IT)

</div>
<p class="mathjax">Studying the solar system and especially the Sun relies on the data gathered
daily from space missions. These missions are data-intensive and compressing
this data to make them efficiently transferable to the ground station is a
twofold decision to make. Stronger compression methods, by distorting the data,
can increase data throughput at the cost of accuracy which could affect
scientific analysis of the data. On the other hand, preserving subtle details
in the compressed data requires a high amount of data to be transferred,
reducing the desired gains from compression. In this work, we propose a neural
network-based lossy compression method to be used in NASA's data-intensive
imagery missions. We chose NASA's SDO mission which transmits 1.4 terabytes of
data each day as a proof of concept for the proposed algorithm. In this work,
we propose an adversarially trained neural network, equipped with local and
non-local attention modules to capture both the local and global structure of
the image resulting in a better trade-off in rate-distortion (RD) compared to
conventional hand-engineered codecs. The RD variational autoencoder used in
this work is jointly trained with a channel-dependent entropy model as a shared
prior between the analysis and synthesis transforms to make the entropy coding
of the latent code more effective. Our neural image compression algorithm
outperforms currently-in-use and state-of-the-art codecs such as JPEG and
JPEG-2000 in terms of the RD performance when compressing extreme-ultraviolet
(EUV) data. As a proof of concept for use of this algorithm in SDO data
analysis, we have performed coronal hole (CH) detection using our compressed
images, and generated consistent segmentations, even at a compression rate of
$\sim0.1$ bits per pixel (compared to 8 bits per pixel on the original data)
using EUV data from SDO.
</p>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02874" title="Abstract">arXiv:2311.02874</a> (cross-list from eess.IV) [<a href="/pdf/2311.02874" title="Download PDF">pdf</a>, <a href="/format/2311.02874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Neural Fields for Learning Atlases of 4D Fetal MRI Time-series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chi%2C+Z">Zeen Chi</a>, 
<a href="/search/eess?searchtype=author&query=Cong%2C+Z">Zhongxiao Cong</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+C+J">Clinton J. Wang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yingcheng Liu</a>, 
<a href="/search/eess?searchtype=author&query=Turk%2C+E+A">Esra Abaci Turk</a>, 
<a href="/search/eess?searchtype=author&query=Grant%2C+P+E">P. Ellen Grant</a>, 
<a href="/search/eess?searchtype=author&query=Abulnaga%2C+S+M">S. Mazdak Abulnaga</a>, 
<a href="/search/eess?searchtype=author&query=Golland%2C+P">Polina Golland</a>, 
<a href="/search/eess?searchtype=author&query=Dey%2C+N">Neel Dey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures. Accepted by Medical Imaging Meets NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a method for fast biomedical image atlas construction using neural
fields. Atlases are key to biomedical image analysis tasks, yet conventional
and deep network estimation methods remain time-intensive. In this preliminary
work, we frame subject-specific atlas building as learning a neural field of
deformable spatiotemporal observations. We apply our method to learning
subject-specific atlases and motion stabilization of dynamic BOLD MRI
time-series of fetuses in utero. Our method yields high-quality atlases of
fetal BOLD time-series with $\sim$5-7$\times$ faster convergence compared to
existing work. While our method slightly underperforms well-tuned baselines in
terms of anatomical overlap, it estimates templates significantly faster, thus
enabling rapid processing and stabilization of large databases of 4D dynamic
MRI acquisitions. Code is available at
https://github.com/Kidrauh/neural-atlasing
</p>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02890" title="Abstract">arXiv:2311.02890</a> (cross-list from math.AP) [<a href="/pdf/2311.02890" title="Download PDF">pdf</a>, <a href="/ps/2311.02890" title="Download PostScript">ps</a>, <a href="/format/2311.02890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On action ground states of defocusing nonlinear Schr&#xf6;dinger equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+C">Chushan Wang</a>, 
<a href="/search/math?searchtype=author&query=Zhao%2C+X">Xiaofei Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this work, we study some mathematical features for the action ground
states of the defocusing nonlinear Schr\"odinger equation with possible
rotation. Main attention is paid to characterizing the relation between the
action ground states and the energy ground states. Theoretical equivalence and
non-equivalence results have been established. Asymptotic behaviours of the
physical quantities are derived in some limiting parameter regimes. Numerical
evidence of non-equivalence is observed and numerical explorations for vortices
phenomena in action ground states are done.
</p>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02898" title="Abstract">arXiv:2311.02898</a> (cross-list from eess.AS) [<a href="/pdf/2311.02898" title="Download PDF">pdf</a>, <a href="/format/2311.02898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transduce and Speak: Neural Transducer for Text-to-Speech with Semantic  Token Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kim%2C+M">Minchan Kim</a>, 
<a href="/search/eess?searchtype=author&query=Jeong%2C+M">Myeonghun Jeong</a>, 
<a href="/search/eess?searchtype=author&query=Choi%2C+B+J">Byoung Jin Choi</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+D">Dongjune Lee</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+N+S">Nam Soo Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ASRU2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce a text-to-speech(TTS) framework based on a neural transducer. We
use discretized semantic tokens acquired from wav2vec2.0 embeddings, which
makes it easy to adopt a neural transducer for the TTS framework enjoying its
monotonic alignment constraints. The proposed model first generates aligned
semantic tokens using the neural transducer, then synthesizes a speech sample
from the semantic tokens using a non-autoregressive(NAR) speech generator. This
decoupled framework alleviates the training complexity of TTS and allows each
stage to focus on 1) linguistic and alignment modeling and 2) fine-grained
acoustic modeling, respectively. Experimental results on the zero-shot adaptive
TTS show that the proposed model exceeds the baselines in speech quality and
speaker similarity via objective and subjective measures. We also investigate
the inference speed and prosody controllability of our proposed model, showing
the potential of the neural transducer for TTS frameworks.
</p>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02901" title="Abstract">arXiv:2311.02901</a> (cross-list from quant-ph) [<a href="/pdf/2311.02901" title="Download PDF">pdf</a>, <a href="/format/2311.02901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pseudorandom Isometries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Ananth%2C+P">Prabhanjan Ananth</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gulati%2C+A">Aditya Gulati</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kaleoglu%2C+F">Fatih Kaleoglu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lin%2C+Y">Yao-Ting Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">We introduce a new notion called ${\cal Q}$-secure pseudorandom isometries
(PRI). A pseudorandom isometry is an efficient quantum circuit that maps an
$n$-qubit state to an $(n+m)$-qubit state in an isometric manner. In terms of
security, we require that the output of a $q$-fold PRI on $\rho$, for $ \rho
\in {\cal Q}$, for any polynomial $q$, should be computationally
indistinguishable from the output of a $q$-fold Haar isometry on $\rho$. \par
By fine-tuning ${\cal Q}$, we recover many existing notions of
pseudorandomness. We present a construction of PRIs and assuming post-quantum
one-way functions, we prove the security of ${\cal Q}$-secure pseudorandom
isometries (PRI) for different interesting settings of ${\cal Q}$. \par We also
demonstrate many cryptographic applications of PRIs, including, length
extension theorems for quantum pseudorandomness notions, message authentication
schemes for quantum states, multi-copy secure public and private encryption
schemes, and succinct quantum commitments. }
</p>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02911" title="Abstract">arXiv:2311.02911</a> (cross-list from eess.SP) [<a href="/pdf/2311.02911" title="Download PDF">pdf</a>, <a href="/format/2311.02911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Goal-Oriented Wireless Communication Resource Allocation for  Cyber-Physical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Feng%2C+C">Cheng Feng</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+K">Kedi Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+K">Kaibin Huang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Q">Qixin Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE ComSoc journal for possible publications. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The proliferation of novel industrial applications at the wireless edge, such
as smart grids and vehicle networks, demands the advancement of cyber-physical
systems. The performance of CPSs is closely linked to the last-mile wireless
communication networks, which often become bottlenecks due to their inherent
limited resources. Current CPS operations often treat wireless communication
networks as unpredictable and uncontrollable variables, ignoring the potential
adaptability of wireless networks, which results in inefficient and overly
conservative CPS operations. Meanwhile, current wireless communications often
focus more on throughput and other transmission-related metrics instead of CPS
goals. In this study, we introduce the framework of goal-oriented wireless
communication resource allocations, accounting for the semantics and
significance of data for CPS operation goals. This guarantees optimal CPS
performance from a cybernetic standpoint. We formulate a bandwidth allocation
problem aimed at maximizing the information utility gain of transmitted data
brought to CPS operation goals. Since the goal-oriented bandwidth allocation
problem is a large-scale combinational problem, we propose a divide-and-conquer
and greedy solution algorithm. The information utility gain is first
approximately decomposed into marginal utility information gains and computed
in a parallel manner. Subsequently, the bandwidth allocation problem is
reformulated as a knapsack problem, which can be further solved greedily with a
guaranteed sub-optimality gap. We further demonstrate how our proposed
goal-oriented bandwidth allocation algorithm can be applied in four potential
CPS applications, including data-driven decision-making, edge learning,
federated learning, and distributed optimization.
</p>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02959" title="Abstract">arXiv:2311.02959</a> (cross-list from physics.soc-ph) [<a href="/pdf/2311.02959" title="Download PDF">pdf</a>, <a href="/format/2311.02959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Manageable to unmanageable transition in a fractal model of project  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Vazquez%2C+A">Alexei Vazquez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Statistical Mechanics (cond-mat.stat-mech); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">We have suggested that project activity networks have a fractal structure
[Vazquez et al, Sci. Rep. 13, 509 (2023)]. We introduced a duplication-split
model of network growth characterized by (i) identical power law distributions
of in-degrees and out-degrees $p_k\sim k^{-1/q}$ and (ii) a fractal scaling of
the longest path length $L$ with the network size $N$, $L\sim N^{1-\alpha}$
with $0&lt;\alpha&lt;q$. Here I provide convincing evidence that the
duplication-split model generates fractal networks. The average distance
between nodes scales as $\langle d\rangle \sim d^{\beta}$ with $0&lt;\beta&lt;1$. The
average number of nodes $M_d$ within a distance $d$ scales as $M_d\sim
d^{d_f}$, with a fractal dimension $d_f=1/\beta&gt;1$. Furthermore, the
duplication-split networks are fragile for duplication rates $q&lt;q_c=1/2$: The
size of the giant out-component decreases with increasing the network size for
any site occupancy probability less than 1. In contrast, they exhibit a non
trivial percolation threshold $0&lt;p_c&lt;1$ for $q&gt;q_c$, in spite the mean
out-degree diverges with increasing the network size. I conclude the project
networks generated by the duplication-split model are manageable for $q&lt;q_c$
and unmanageable otherwise.
</p>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02986" title="Abstract">arXiv:2311.02986</a> (cross-list from quant-ph) [<a href="/pdf/2311.02986" title="Download PDF">pdf</a>, <a href="/format/2311.02986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hacking Cryptographic Protocols with Advanced Variational Quantum  Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Aizpurua%2C+B">Borja Aizpurua</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bermejo%2C+P">Pablo Bermejo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Martinez%2C+J+E">Josu Etxezarreta Martinez</a>, 
<a href="/search/quant-ph?searchtype=author&query=Orus%2C+R">Roman Orus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Here we introduce an improved approach to Variational Quantum Attack
Algorithms (VQAA) on crytographic protocols. Our methods provide robust quantum
attacks to well-known cryptographic algorithms, more efficiently and with
remarkably fewer qubits than previous approaches. We implement simulations of
our attacks for symmetric-key protocols such as S-DES, S-AES and Blowfish. For
instance, we show how our attack allows a classical simulation of a small
8-qubit quantum computer to find the secret key of one 32-bit Blowfish instance
with 24 times fewer number of iterations than a brute-force attack. Our work
also shows improvements in attack success rates for lightweight ciphers such as
S-DES and S-AES. Further applications beyond symmetric-key cryptography are
also discussed, including asymmetric-key protocols and hash functions. In
addition, we also comment on potential future improvements of our methods. Our
results bring one step closer assessing the vulnerability of large-size
classical cryptographic protocols with Noisy Intermediate-Scale Quantum (NISQ)
devices, and set the stage for future research in quantum cybersecurity.
</p>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02992" title="Abstract">arXiv:2311.02992</a> (cross-list from eess.IV) [<a href="/pdf/2311.02992" title="Download PDF">pdf</a>, <a href="/format/2311.02992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NEURO HAND: A weakly supervised Hierarchical Attention Network for  neuroimaging abnormality Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wood%2C+D+A">David A. Wood</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Clinical neuroimaging data is naturally hierarchical. Different magnetic
resonance imaging (MRI) sequences within a series, different slices covering
the head, and different regions within each slice all confer different
information. In this work we present a hierarchical attention network for
abnormality detection using MRI scans obtained in a clinical hospital setting.
The proposed network is suitable for non-volumetric data (i.e. stacks of
high-resolution MRI slices), and can be trained from binary examination-level
labels. We show that this hierarchical approach leads to improved
classification, while providing interpretability through either coarse inter-
and intra-slice abnormality localisation, or giving importance scores for
different slices and sequences, making our model suitable for use as an
automated triaging system in radiology departments.
</p>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03019" title="Abstract">arXiv:2311.03019</a> (cross-list from math.OC) [<a href="/pdf/2311.03019" title="Download PDF">pdf</a>, <a href="/format/2311.03019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Control of Linear Cost Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ohlin%2C+D">David Ohlin</a>, 
<a href="/search/math?searchtype=author&query=Tegling%2C+E">Emma Tegling</a>, 
<a href="/search/math?searchtype=author&query=Rantzer%2C+A">Anders Rantzer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ECC2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We present a method for optimal control with respect to a linear cost
function for positive linear systems with coupled input constraints. We show
that the optimal cost function and resulting sparse state feedback for these
systems can be computed by linear programming. Our framework admits a range of
network routing problems with underlying linear dynamics. These dynamics can be
used to model traditional graph-theoretical problems like shortest path as a
special case, but can also capture more complex behaviors. We provide an
asynchronous and distributed value iteration algorithm for obtaining the
optimal cost function and control law.
</p>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03030" title="Abstract">arXiv:2311.03030</a> (cross-list from math.OC) [<a href="/pdf/2311.03030" title="Download PDF">pdf</a>, <a href="/format/2311.03030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resilient Mobile Multi-Target Surveillance Using Multi-Hop Autonomous  UAV Networks for Extended Lifetime
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Da%C4%9Fa%C5%9Fan%2C+A">Abdulsamet Da&#x11f;a&#x15f;an</a>, 
<a href="/search/math?searchtype=author&query=Kara%C5%9Fan%2C+E">Ezhan Kara&#x15f;an</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Multiagent Systems (cs.MA); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Cooperative utilization of Unmanned Aerial Vehicles (UAVs) in public and
military surveillance applications has attracted significant attention in
recent years. Most UAVs are equipped with sensors that have bounded coverage
and wireless communication equipment with limited range. Such limitations pose
challenging problems to monitor mobile targets. This paper examines fulfilling
surveillance objectives to achieve better coverage while building a resilient
network between UAVs with an extended lifetime. The multiple target tracking
problem is studied by including a relay UAV within the fleet whose trajectory
is autonomously calculated in order to achieve a reliable connected network
among all UAVs. Optimization problems are formulated for single-hop and
multi-hop communications among UAVs. Three heuristic algorithms are proposed
for multi-hop communications and their performances are evaluated. A hybrid
algorithm, which dynamically switches between single-hop and multi-hop
communications is also proposed. The effect of the time horizon considered in
the optimization problem is studied. Performance evaluation results show that
the trajectories generated for the relay UAV by the hybrid algorithm can
achieve network lifetimes that are within 5% of the maximum possible network
lifetime which can be obtained if the entire trajectories of all targets were
known a priori.
</p>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03049" title="Abstract">arXiv:2311.03049</a> (cross-list from math.CO) [<a href="/pdf/2311.03049" title="Download PDF">pdf</a>, <a href="/ps/2311.03049" title="Download PostScript">ps</a>, <a href="/format/2311.03049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Arboricity and Acyclic Chromatic Number
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Knill%2C+O">Oliver Knill</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">A theorem of Hakimi, Mitchem and Schmeichel from 1996 states that the edge
arboricity arb(G) of a graph is bounded above by the acyclic chromatic number
acy(G). We can improve this HMS inequality by 1, if acy(G) is even. We review
also results about acyclic chromatic numbers in the context of a Gr\"unbaum
conjecture from 1973.
</p>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03056" title="Abstract">arXiv:2311.03056</a> (cross-list from q-bio.GN) [<a href="/pdf/2311.03056" title="Download PDF">pdf</a>, <a href="/ps/2311.03056" title="Download PostScript">ps</a>, <a href="/format/2311.03056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LitSumm: Large language models for literature summarisation of  non-coding RNAs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Green%2C+A">Andrew Green</a>, 
<a href="/search/q-bio?searchtype=author&query=Ribas%2C+C">Carlos Ribas</a>, 
<a href="/search/q-bio?searchtype=author&query=Ontiveros-Palacios%2C+N">Nancy Ontiveros-Palacios</a>, 
<a href="/search/q-bio?searchtype=author&query=Petrov%2C+A+I">Anton I. Petrov</a>, 
<a href="/search/q-bio?searchtype=author&query=Bateman%2C+A">Alex Bateman</a>, 
<a href="/search/q-bio?searchtype=author&query=Sweeney%2C+B">Blake Sweeney</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Motivation: Curation of literature in life sciences is a growing challenge.
The continued increase in the rate of publication, coupled with the relatively
fixed number of curators worldwide presents a major challenge to developers of
biomedical knowledgebases. Very few knowledgebases have resources to scale to
the whole relevant literature and all have to prioritise their efforts.
<br />Results: In this work, we take a first step to alleviating the lack of
curator time in RNA science by generating summaries of literature for
non-coding RNAs using large language models (LLMs). We demonstrate that
high-quality, factually accurate summaries with accurate references can be
automatically generated from the literature using a commercial LLM and a chain
of prompts and checks. Manual assessment was carried out for a subset of
summaries, with the majority being rated extremely high quality. We also
applied the most commonly used automated evaluation approaches, finding that
they do not correlate with human assessment. Finally, we apply our tool to a
selection of over 4,600 ncRNAs and make the generated summaries available via
the RNAcentral resource. We conclude that automated literature summarization is
feasible with the current generation of LLMs, provided careful prompting and
automated checking are applied.
<br />Availability: Code used to produce these summaries can be found here:
https://github.com/RNAcentral/litscan-summarization and the dataset of contexts
and summaries can be found here:
https://huggingface.co/datasets/RNAcentral/litsumm-v1. Summaries are also
displayed on the RNA report pages in RNAcentral (https://rnacentral.org/)
</p>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03062" title="Abstract">arXiv:2311.03062</a> (cross-list from physics.optics) [<a href="/pdf/2311.03062" title="Download PDF">pdf</a>, <a href="/ps/2311.03062" title="Download PostScript">ps</a>, <a href="/format/2311.03062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imaging through multimode fibres with physical prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Zhang%2C+C">Chuncheng Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Shi%2C+Y">Yingjie Shi</a>, 
<a href="/search/physics?searchtype=author&query=Yao%2C+Z">Zheyi Yao</a>, 
<a href="/search/physics?searchtype=author&query=Sui%2C+X">Xiubao Sui</a>, 
<a href="/search/physics?searchtype=author&query=Cheng%2C+Q">Qian Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Imaging through perturbed multimode fibres based on deep learning has been
widely researched. However, existing methods mainly use target-speckle pairs in
different configurations. It is challenging to reconstruct targets without
trained networks. In this paper, we propose a physics-assisted, unsupervised,
learning-based fibre imaging scheme. The role of the physical prior is to
simplify the mapping relationship between the speckle pattern and the target
image, thereby reducing the computational complexity. The unsupervised network
learns target features according to the optimized direction provided by the
physical prior. Therefore, the reconstruction process of the online learning
only requires a few speckle patterns and unpaired targets. The proposed scheme
also increases the generalization ability of the learning-based method in
perturbed multimode fibres. Our scheme has the potential to extend the
application of multimode fibre imaging.
</p>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03074" title="Abstract">arXiv:2311.03074</a> (cross-list from eess.IV) [<a href="/pdf/2311.03074" title="Download PDF">pdf</a>, <a href="/format/2311.03074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Two-Stage Generative Model with CycleGAN and Joint Diffusion for  MRI-based Brain Tumor Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+W">Wenxin Wang</a>, 
<a href="/search/eess?searchtype=author&query=Cui%2C+Z">Zhuo-Xu Cui</a>, 
<a href="/search/eess?searchtype=author&query=Cheng%2C+G">Guanxun Cheng</a>, 
<a href="/search/eess?searchtype=author&query=Cao%2C+C">Chentao Cao</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+X">Xi Xu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Haifeng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Qi%2C+Y">Yulong Qi</a>, 
<a href="/search/eess?searchtype=author&query=Liang%2C+D">Dong Liang</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+Y">Yanjie Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages,9 figures,3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Accurate detection and segmentation of brain tumors is critical for medical
diagnosis. However, current supervised learning methods require extensively
annotated images and the state-of-the-art generative models used in
unsupervised methods often have limitations in covering the whole data
distribution. In this paper, we propose a novel framework Two-Stage Generative
Model (TSGM) that combines Cycle Generative Adversarial Network (CycleGAN) and
Variance Exploding stochastic differential equation using joint probability
(VE-JP) to improve brain tumor detection and segmentation. The CycleGAN is
trained on unpaired data to generate abnormal images from healthy images as
data prior. Then VE-JP is implemented to reconstruct healthy images using
synthetic paired abnormal images as a guide, which alters only pathological
regions but not regions of healthy. Notably, our method directly learned the
joint probability distribution for conditional generation. The residual between
input and reconstructed images suggests the abnormalities and a thresholding
method is subsequently applied to obtain segmentation results. Furthermore, the
multimodal results are weighted with different weights to improve the
segmentation accuracy further. We validated our method on three datasets, and
compared with other unsupervised methods for anomaly detection and
segmentation. The DSC score of 0.8590 in BraTs2020 dataset, 0.6226 in ITCS
dataset and 0.7403 in In-house dataset show that our method achieves better
segmentation performance and has better generalization.
</p>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03097" title="Abstract">arXiv:2311.03097</a> (cross-list from quant-ph) [<a href="/pdf/2311.03097" title="Download PDF">pdf</a>, <a href="/format/2311.03097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum-Error-Mitigated Detectable Byzantine Agreement with Dynamical  Decoupling for Distributed Quantum Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Prest%2C+M">Matthew Prest</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+K">Kuan-Cheng Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Hardware Architecture (cs.AR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In the burgeoning domain of distributed quantum computing, achieving
consensus amidst adversarial settings remains a pivotal challenge. We introduce
an enhancement to the Quantum Byzantine Agreement (QBA) protocol, uniquely
incorporating advanced error mitigation techniques: Twirled Readout Error
Extinction (T-REx) and dynamical decoupling (DD). Central to this refined
approach is the utilization of a Noisy Intermediate Scale Quantum (NISQ) source
device for heightened performance. Extensive tests on both simulated and
real-world quantum devices, notably IBM's quantum computer, provide compelling
evidence of the effectiveness of our T-REx and DD adaptations in mitigating
prevalent quantum channel errors.
<br />Subsequent to the entanglement distribution, our protocol adopts a
verification method reminiscent of Quantum Key Distribution (QKD) schemes. The
Commander then issues orders encoded in specific quantum states, like Retreat
or Attack. In situations where received orders diverge, lieutenants engage in
structured games to reconcile discrepancies. Notably, the frequency of these
games is contingent upon the Commander's strategies and the overall network
size. Our empirical findings underscore the enhanced resilience and
effectiveness of the protocol in diverse scenarios. Nonetheless, scalability
emerges as a concern with the growth of the network size. To sum up, our
research illuminates the considerable potential of fortified quantum consensus
systems in the NISQ era, highlighting the imperative for sustained research in
bolstering quantum ecosystems.
</p>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03118" title="Abstract">arXiv:2311.03118</a> (cross-list from math.CT) [<a href="/pdf/2311.03118" title="Download PDF">pdf</a>, <a href="/ps/2311.03118" title="Download PostScript">ps</a>, <a href="/format/2311.03118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algebraic Dynamical Systems in Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jones%2C+I">Iolo Jones</a>, 
<a href="/search/math?searchtype=author&query=Swan%2C+J">Jerry Swan</a>, 
<a href="/search/math?searchtype=author&query=Giansiracusa%2C+J">Jeffrey Giansiracusa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in 'Applied Categorical Structures'
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce an algebraic analogue of dynamical systems, based on term
rewriting. We show that a recursive function applied to the output of an
iterated rewriting system defines a formal class of models into which all the
main architectures for dynamic machine learning models (including recurrent
neural networks, graph neural networks, and diffusion models) can be embedded.
Considered in category theory, we also show that these algebraic models are a
natural language for describing the compositionality of dynamic models.
Furthermore, we propose that these models provide a template for the
generalisation of the above dynamic models to learning problems on structured
or non-numerical data, including 'hybrid symbolic-numeric' models.
</p>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03129" title="Abstract">arXiv:2311.03129</a> (cross-list from stat.ML) [<a href="/pdf/2311.03129" title="Download PDF">pdf</a>, <a href="/format/2311.03129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonparametric modeling of the composite effect of multiple nutrients on  blood glucose dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Odnoblyudova%2C+A">Arina Odnoblyudova</a>, 
<a href="/search/stat?searchtype=author&query=Hizli%2C+%C3%87">&#xc7;a&#x11f;lar Hizli</a>, 
<a href="/search/stat?searchtype=author&query=John%2C+S">ST John</a>, 
<a href="/search/stat?searchtype=author&query=Cognolato%2C+A">Andrea Cognolato</a>, 
<a href="/search/stat?searchtype=author&query=Juuti%2C+A">Anne Juuti</a>, 
<a href="/search/stat?searchtype=author&query=S%C3%A4rkk%C3%A4%2C+S">Simo S&#xe4;rkk&#xe4;</a>, 
<a href="/search/stat?searchtype=author&query=Pietil%C3%A4inen%2C+K">Kirsi Pietil&#xe4;inen</a>, 
<a href="/search/stat?searchtype=author&query=Marttinen%2C+P">Pekka Marttinen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In biomedical applications it is often necessary to estimate a physiological
response to a treatment consisting of multiple components, and learn the
separate effects of the components in addition to the joint effect. Here, we
extend existing probabilistic nonparametric approaches to explicitly address
this problem. We also develop a new convolution-based model for composite
treatment-response curves that is more biologically interpretable. We validate
our models by estimating the impact of carbohydrate and fat in meals on blood
glucose. By differentiating treatment components, incorporating their dosages,
and sharing statistical information across patients via a hierarchical
multi-output Gaussian process, our method improves prediction accuracy over
existing approaches, and allows us to interpret the different effects of
carbohydrates and fat on the overall glucose response.
</p>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03131" title="Abstract">arXiv:2311.03131</a> (cross-list from q-bio.QM) [<a href="/pdf/2311.03131" title="Download PDF">pdf</a>, <a href="/format/2311.03131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reservoir-Computing Model for Mapping and Forecasting Neuronal  Interactions from Electrophysiological Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Auslender%2C+I">Ilya Auslender</a>, 
<a href="/search/q-bio?searchtype=author&query=Letti%2C+G">Giorgio Letti</a>, 
<a href="/search/q-bio?searchtype=author&query=Heydari%2C+Y">Yasaman Heydari</a>, 
<a href="/search/q-bio?searchtype=author&query=Pavesi%2C+L">Lorenzo Pavesi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First upload. Draft. arXiv admin note: text overlap with <a href="/abs/2309.06297">arXiv:2309.06297</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG); Biological Physics (physics.bio-ph)

</div>
<p class="mathjax">Electrophysiological nature of neuronal networks allows to reveal various
interactions between different cell units at a very short time-scales. One of
the many challenges in analyzing these signals is to retrieve the morphology
and functionality of a given network. In this work we developed a computational
model, based on Reservoir Computing Network (RCN) architecture, which decodes
the spatio-temporal data from electro-physiological measurements of neuronal
cultures and reconstructs the network structure on a macroscopic domain,
representing the connectivity between neuronal units. We demonstrate that the
model can predict the connectivity map of the network with higher accuracy than
the common methods such as Cross-Correlation and Transfer-Entropy. In addition,
we experimentally demonstrate the ability of the model to predict a network
response to a specific input, such as localized stimulus.
</p>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03137" title="Abstract">arXiv:2311.03137</a> (cross-list from physics.soc-ph) [<a href="/pdf/2311.03137" title="Download PDF">pdf</a>, <a href="/ps/2311.03137" title="Download PostScript">ps</a>, <a href="/format/2311.03137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phase Field Modeling in Social Media Dynamics:Simulation of Opinion  Evolution with Feedback, Separation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kawahata%2C+Y">Yasuko Kawahata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Discussion Paper:Theory of opinion distribution in human relations where trust and distrust mixed(2020)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">This study introduces a new numerical model to simulate how information is
comprehended and processed on social networks, using continuous "Phase Field
Modeling" variables (phiA, phiB, phiC) to represent individual users' opinions.
It captures the immediate and two-way nature of social media interactions,
reproducing the spread and feedback of information. The model incorporates
psychological and social factors like confirmation bias and opinion rigidity to
analyze information processing and opinion development among users. It also
explores the dynamics of opinion segregation and interaction in and out of
filter bubbles, offering a quantitative view of opinion dynamics on platforms
like social networking services (SNS). This approach combines theoretical
models with real-world social network data to study the effects of information
concentration on opinion formation and the phenome Phase Field Modeling of
opinion polarization and echo chamber effects on SNS.
</p>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03139" title="Abstract">arXiv:2311.03139</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2311.03139" title="Download PDF">pdf</a>, <a href="/ps/2311.03139" title="Download PostScript">ps</a>, <a href="/format/2311.03139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-end Material Thermal Conductivity Prediction through Machine  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Srivastava%2C+Y">Yagyank Srivastava</a>, 
<a href="/search/cond-mat?searchtype=author&query=Jain%2C+A">Ankit Jain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We investigated the accelerated prediction of the thermal conductivity of
materials through end- to-end structure-based approaches employing machine
learning methods. Due to the non-availability of high-quality thermal
conductivity data, we first performed high-throughput calculations based on
first principles and the Boltzmann transport equation for 225 materials,
effectively more than doubling the size of the existing dataset. We assessed
the performance of state-of-the-art machine learning models for thermal
conductivity prediction on this expanded dataset and observed that all these
models suffered from overfitting. To address this issue, we introduced a novel
graph-based neural network model, which demonstrated more consistent and
regularized performance across all evaluated datasets. Nevertheless, the best
mean absolute percentage error achieved on the test dataset remained in the
range of 50-60%. This suggests that while these models are valuable for
expediting material screening, their current accuracy is still limited.
</p>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03148" title="Abstract">arXiv:2311.03148</a> (cross-list from math.OC) [<a href="/pdf/2311.03148" title="Download PDF">pdf</a>, <a href="/format/2311.03148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collision Avoidance using Iterative Dynamic and Nonlinear Programming  with Adaptive Grid Refinements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Richter%2C+R">Rebecca Richter</a>, 
<a href="/search/math?searchtype=author&query=De+Marchi%2C+A">Alberto De Marchi</a>, 
<a href="/search/math?searchtype=author&query=Gerdts%2C+M">Matthias Gerdts</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, 1 algorithm, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Nonlinear optimal control problems for trajectory planning with obstacle
avoidance present several challenges. While general-purpose optimizers and
dynamic programming methods struggle when adopted separately, their combination
enabled by a penalty approach was found capable of handling highly nonlinear
systems while overcoming the curse of dimensionality. Nevertheless, using
dynamic programming with a fixed state space discretization limits the set of
reachable solutions, hindering convergence or requiring enormous memory
resources for uniformly spaced grids. In this work we solve this issue by
incorporating an adaptive refinement of the state space grid, splitting cells
where needed to better capture the problem structure while requiring less
discretization points overall. Numerical results on a space manipulator
demonstrate the improved robustness and efficiency of the combined method with
respect to the single components.
</p>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03167" title="Abstract">arXiv:2311.03167</a> (cross-list from math.OC) [<a href="/pdf/2311.03167" title="Download PDF">pdf</a>, <a href="/format/2311.03167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concurrent Design Optimization of Shared Powertrain Modules in a Family  of Electric Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Clemente%2C+M">Maurizio Clemente</a>, 
<a href="/search/math?searchtype=author&query=Salazar%2C+M">Mauro Salazar</a>, 
<a href="/search/math?searchtype=author&query=Hofman%2C+T">Theo Hofman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We present a concurrent optimization framework to design shared modular
powertrain components for a family of battery electric vehicles, whereby the
modules' sizes are jointly-optimized to minimize the family Total Cost of
Ownership (TCO). As opposed to individually-tailoring the components, our
approach can significantly reduce production costs due to the higher volumes of
the same item. We instantiate a bi-level nested framework consisting of an
inner convex optimization routine, which jointly optimizes the modules' sizes
and the powertrain operation for given driving cycles and modules'
multiplicities, and an outer loop comparing each configuration to identify the
minimum-TCO family co-design solution with global optimality guarantees.
Finally, we showcase our framework on a case study for the Tesla family in a
benchmark design problem, considering the Model S, Model 3, Model X, and Model
Y. Our results show that, compared to an individually tailored design, the
application of our concurrent design optimization framework achieves a
significant reduction of acquisition price for a minimal increase in
operational costs, ultimately lowering the family TCO in the benchmark design
problem by 3.5%. Moreover, in a sensitivity study on the market conditions
considered, our concurrent design optimization methodology can reduce the TCO
by up to 17%.
</p>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03175" title="Abstract">arXiv:2311.03175</a> (cross-list from eess.IV) [<a href="/pdf/2311.03175" title="Download PDF">pdf</a>, <a href="/ps/2311.03175" title="Download PostScript">ps</a>, <a href="/format/2311.03175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frequency Domain Decomposition Translation for Enhanced Medical Image  Translation Using GANs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zhuhui Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zuo%2C+J">Jianwei Zuo</a>, 
<a href="/search/eess?searchtype=author&query=Deng%2C+X">Xuliang Deng</a>, 
<a href="/search/eess?searchtype=author&query=Luo%2C+J">Jiajia Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Medical Image-to-image translation is a key task in computer vision and
generative artificial intelligence, and it is highly applicable to medical
image analysis. GAN-based methods are the mainstream image translation methods,
but they often ignore the variation and distribution of images in the frequency
domain, or only take simple measures to align high-frequency information, which
can lead to distortion and low quality of the generated images. To solve these
problems, we propose a novel method called frequency domain decomposition
translation (FDDT). This method decomposes the original image into a
high-frequency component and a low-frequency component, with the high-frequency
component containing the details and identity information, and the
low-frequency component containing the style information. Next, the
high-frequency and low-frequency components of the transformed image are
aligned with the transformed results of the high-frequency and low-frequency
components of the original image in the same frequency band in the spatial
domain, thus preserving the identity information of the image while destroying
as little stylistic information of the image as possible. We conduct extensive
experiments on MRI images and natural images with FDDT and several mainstream
baseline models, and we use four evaluation metrics to assess the quality of
the generated images. Compared with the baseline models, optimally, FDDT can
reduce Fr\'echet inception distance by up to 24.4%, structural similarity by up
to 4.4%, peak signal-to-noise ratio by up to 5.8%, and mean squared error by up
to 31%. Compared with the previous method, optimally, FDDT can reduce Fr\'echet
inception distance by up to 23.7%, structural similarity by up to 1.8%, peak
signal-to-noise ratio by up to 6.8%, and mean squared error by up to 31.6%.
</p>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03195" title="Abstract">arXiv:2311.03195</a> (cross-list from econ.TH) [<a href="/pdf/2311.03195" title="Download PDF">pdf</a>, <a href="/format/2311.03195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Some coordination problems are harder than others
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Deligkas%2C+A">Argyrios Deligkas</a>, 
<a href="/search/econ?searchtype=author&query=Eiben%2C+E">Eduard Eiben</a>, 
<a href="/search/econ?searchtype=author&query=Gutin%2C+G">Gregory Gutin</a>, 
<a href="/search/econ?searchtype=author&query=Neary%2C+P+R">Philip R. Neary</a>, 
<a href="/search/econ?searchtype=author&query=Yeo%2C+A">Anders Yeo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2305.07124">arXiv:2305.07124</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">In order to coordinate successfully individuals must first identify a target
pattern of behaviour. In this paper we investigate the difficulty of
identifying prominent outcomes in two kinds of binary action coordination
problems in social networks: pure coordination games and anti-coordination
games. For both environments, we determine the computational complexity of
finding a strategy profile that (i) maximises welfare, (ii) maximises welfare
subject to being an equilibrium, and (iii) maximises potential. We show that
the complexity of these objectives can vary with the type of coordination
problem. Objectives (i) and (iii) are tractable problems in pure coordination
games, but for anti-coordination games are NP-hard. Objective (ii), finding the
best Nash equilibrium, is NP-hard for both. Our results support the idea that
environments in which actions are strategic complements facilitate successful
coordination more readily than those in which actions are strategic
substitutes.
</p>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03201" title="Abstract">arXiv:2311.03201</a> (cross-list from stat.ML) [<a href="/pdf/2311.03201" title="Download PDF">pdf</a>, <a href="/format/2311.03201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial Process Approximations: Assessing Their Necessity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">In spatial statistics and machine learning, the kernel matrix plays a pivotal
role in prediction, classification, and maximum likelihood estimation. A
thorough examination reveals that for large sample sizes, the kernel matrix
becomes ill-conditioned, provided the sampling locations are fairly evenly
distributed. This condition poses significant challenges to numerical
algorithms used in prediction and estimation computations and necessitates an
approximation to prediction and the Gaussian likelihood. A review of current
methodologies for managing large spatial data indicates that some fail to
address this ill-conditioning problem. Such ill-conditioning often results in
low-rank approximations of the stochastic processes. This paper introduces
various optimality criteria and provides solutions for each.
</p>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03215" title="Abstract">arXiv:2311.03215</a> (cross-list from quant-ph) [<a href="/pdf/2311.03215" title="Download PDF">pdf</a>, <a href="/ps/2311.03215" title="Download PostScript">ps</a>, <a href="/format/2311.03215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum speedups for linear programming via interior point methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Apers%2C+S">Simon Apers</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gribling%2C+S">Sander Gribling</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS); Optimization and Control (math.OC)

</div>
<p class="mathjax">We describe a quantum algorithm based on an interior point method for solving
a linear program with $n$ inequality constraints on $d$ variables. The
algorithm explicitly returns a feasible solution that is $\epsilon$-close to
optimal, and runs in time $\sqrt{n}\,
\mathrm{poly}(d,\log(n),\log(1/\varepsilon))$ which is sublinear for tall
linear programs (i.e., $n \gg d$). Our algorithm speeds up the Newton step in
the state-of-the-art interior point method of Lee and Sidford [FOCS '14]. This
requires us to efficiently approximate the Hessian and gradient of the barrier
function, and these are our main contributions.
<br />To approximate the Hessian, we describe a quantum algorithm for the spectral
approximation of $A^T A$ for a tall matrix $A \in \mathbb R^{n \times d}$. The
algorithm uses leverage score sampling in combination with Grover search, and
returns a $\delta$-approximation by making $O(\sqrt{nd}/\delta)$ row queries to
$A$. This generalizes an earlier quantum speedup for graph sparsification by
Apers and de Wolf [FOCS '20]. To approximate the gradient, we use a recent
quantum algorithm for multivariate mean estimation by Cornelissen, Hamoudi and
Jerbi [STOC '22]. While a naive implementation introduces a dependence on the
condition number of the Hessian, we avoid this by pre-conditioning our random
variable using our quantum algorithm for spectral approximation.
</p>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03217" title="Abstract">arXiv:2311.03217</a> (cross-list from eess.IV) [<a href="/pdf/2311.03217" title="Download PDF">pdf</a>, <a href="/format/2311.03217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Transformers to Improve Breast Cancer Classification and Risk  Assessment with Multi-modal and Longitudinal Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shen%2C+Y">Yiqiu Shen</a>, 
<a href="/search/eess?searchtype=author&query=Park%2C+J">Jungkyu Park</a>, 
<a href="/search/eess?searchtype=author&query=Yeung%2C+F">Frank Yeung</a>, 
<a href="/search/eess?searchtype=author&query=Goldberg%2C+E">Eliana Goldberg</a>, 
<a href="/search/eess?searchtype=author&query=Heacock%2C+L">Laura Heacock</a>, 
<a href="/search/eess?searchtype=author&query=Shamout%2C+F">Farah Shamout</a>, 
<a href="/search/eess?searchtype=author&query=Geras%2C+K+J">Krzysztof J. Geras</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ML4H 2023 Findings Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Breast cancer screening, primarily conducted through mammography, is often
supplemented with ultrasound for women with dense breast tissue. However,
existing deep learning models analyze each modality independently, missing
opportunities to integrate information across imaging modalities and time. In
this study, we present Multi-modal Transformer (MMT), a neural network that
utilizes mammography and ultrasound synergistically, to identify patients who
currently have cancer and estimate the risk of future cancer for patients who
are currently cancer-free. MMT aggregates multi-modal data through
self-attention and tracks temporal tissue changes by comparing current exams to
prior imaging. Trained on 1.3 million exams, MMT achieves an AUROC of 0.943 in
detecting existing cancers, surpassing strong uni-modal baselines. For 5-year
risk prediction, MMT attains an AUROC of 0.826, outperforming prior
mammography-based risk models. Our research highlights the value of multi-modal
and longitudinal imaging in cancer diagnosis and risk stratification.
</p>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03234" title="Abstract">arXiv:2311.03234</a> (cross-list from math.CO) [<a href="/pdf/2311.03234" title="Download PDF">pdf</a>, <a href="/format/2311.03234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combinatorics of nondeterministic walks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=de+Panafieu%2C+%C3%89">&#xc9;lie de Panafieu</a>, 
<a href="/search/math?searchtype=author&query=Wallner%2C+M">Michael Wallner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages plus 8 pages of appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Formal Languages and Automata Theory (cs.FL); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">This paper introduces nondeterministic walks, a new variant of
one-dimensional discrete walks. The main difference to classical walks is that
its nondeterministic steps consist of sets of steps from a predefined set such
that all possible extensions are explored in parallel. We discuss in detail the
most natural nondeterministic step sets (Dyck and Motzkin step sets), and show
that several nondeterministic classes of lattice paths, such as
nondeterministic bridges, excursions, and meanders are algebraic. The key
concept is the generalization of the ending point of a walk to its reachable
points, i.e., a set of ending points. We extend our results to general step
sets: We show that nondeterministic bridges and several subclasses of
nondeterministic meanders are always algebraic. We conjecture the same is true
for nondeterministic excursions, and we present python and Maple packages to
support our conjecture. This research is motivated by the study of networks
involving encapsulation and decapsulation of protocols. Our results are
obtained using generating functions, analytic combinatorics, and additive
combinatorics.
<br />Keywords. Random walks, analytic combinatorics, generating functions, limit
laws, networking, encapsulation.
</p>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03252" title="Abstract">arXiv:2311.03252</a> (cross-list from math.OC) [<a href="/pdf/2311.03252" title="Download PDF">pdf</a>, <a href="/format/2311.03252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameter-Agnostic Optimization under Relaxed Smoothness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=H%C3%BCbler%2C+F">Florian H&#xfc;bler</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+J">Junchi Yang</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/math?searchtype=author&query=He%2C+N">Niao He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Tuning hyperparameters, such as the stepsize, presents a major challenge of
training machine learning models. To address this challenge, numerous adaptive
optimization algorithms have been developed that achieve near-optimal
complexities, even when stepsizes are independent of problem-specific
parameters, provided that the loss function is $L$-smooth. However, as the
assumption is relaxed to the more realistic $(L_0, L_1)$-smoothness, all
existing convergence results still necessitate tuning of the stepsize. In this
study, we demonstrate that Normalized Stochastic Gradient Descent with Momentum
(NSGD-M) can achieve a (nearly) rate-optimal complexity without prior knowledge
of any problem parameter, though this comes at the cost of introducing an
exponential term dependent on $L_1$ in the complexity. We further establish
that this exponential term is inevitable to such schemes by introducing a
theoretical framework of lower bounds tailored explicitly for
parameter-agnostic algorithms. Interestingly, in deterministic settings, the
exponential factor can be neutralized by employing Gradient Descent with a
Backtracking Line Search. To the best of our knowledge, these findings
represent the first parameter-agnostic convergence results under the
generalized smoothness condition. Our empirical experiments further confirm our
theoretical insights.
</p>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03255" title="Abstract">arXiv:2311.03255</a> (cross-list from math.CO) [<a href="/pdf/2311.03255" title="Download PDF">pdf</a>, <a href="/format/2311.03255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimal Arrangements of Spherical Geodesics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Viglietta%2C+G">Giovanni Viglietta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">We study arrangements of geodesic arcs on a sphere, where all arcs are
internally disjoint and each arc has its endpoints located within the interior
of other arcs. We establish fundamental results concerning the minimum number
of arcs in such arrangements, depending on local geometric constraints such as
"one-sidedness" and "k-orientation".
<br />En route to these results, we generalize and settle an open problem from CCCG
2022. Namely, we prove that any such arrangement has at least two "clockwise
swirls" and at least two "counterclockwise swirls".
</p>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03283" title="Abstract">arXiv:2311.03283</a> (cross-list from q-fin.MF) [<a href="/pdf/2311.03283" title="Download PDF">pdf</a>, <a href="/format/2311.03283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Risk of Transfer Learning and its Applications in Finance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Cao%2C+H">Haoyang Cao</a>, 
<a href="/search/q-fin?searchtype=author&query=Gu%2C+H">Haotian Gu</a>, 
<a href="/search/q-fin?searchtype=author&query=Guo%2C+X">Xin Guo</a>, 
<a href="/search/q-fin?searchtype=author&query=Rosenbaum%2C+M">Mathieu Rosenbaum</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2307.13546">arXiv:2307.13546</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Finance (q-fin.MF)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Transfer learning is an emerging and popular paradigm for utilizing existing
knowledge from previous learning tasks to improve the performance of new ones.
In this paper, we propose a novel concept of transfer risk and and analyze its
properties to evaluate transferability of transfer learning. We apply transfer
learning techniques and this concept of transfer risk to stock return
prediction and portfolio optimization problems. Numerical results demonstrate a
strong correlation between transfer risk and overall transfer learning
performance, where transfer risk provides a computationally efficient way to
identify appropriate source tasks in transfer learning, including
cross-continent, cross-sector, and cross-frequency transfer for portfolio
optimization.
</p>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03294" title="Abstract">arXiv:2311.03294</a> (cross-list from quant-ph) [<a href="/pdf/2311.03294" title="Download PDF">pdf</a>, <a href="/ps/2311.03294" title="Download PostScript">ps</a>, <a href="/format/2311.03294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Indirect Quantum Approximate Optimization Algorithms: application to the  TSP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Bourreau%2C+E">Eric Bourreau</a>, 
<a href="/search/quant-ph?searchtype=author&query=Fleury%2C+G">Gerard Fleury</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lacomme%2C+P">Philippe Lacomme</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We propose an Indirect Quantum Approximate Optimization Algorithm (referred
to as IQAOA) where the Quantum Alternating Operator Ansatz takes into
consideration a general parameterized family of unitary operators to
efficiently model the Hamiltonian describing the set of string vectors. This
algorithm creates an efficient alternative to QAOA, where: 1) a Quantum
parametrized circuit executed on a quantum machine models the set of string
vectors; 2) a Classical meta-optimization loop executed on a classical machine;
3) an estimation of the average cost of each string vector computing, using a
well know algorithm coming from the OR community that is problem dependent. The
indirect encoding defined by dimensional string vector is mapped into a
solution by an efficient coding/decoding mechanism. The main advantage is to
obtain a quantum circuit with a strongly limited number of gates that could be
executed on the noisy current quantum machines. The numerical experiments
achieved with IQAOA permits to solve 8-customer instances TSP using the IBM
simulator which are to the best of our knowledge the largest TSP ever solved
using a QAOA based approach.
</p>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03313" title="Abstract">arXiv:2311.03313</a> (cross-list from stat.ML) [<a href="/pdf/2311.03313" title="Download PDF">pdf</a>, <a href="/format/2311.03313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Practical considerations for variable screening in the Super Learner
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Williamson%2C+B+D">Brian D. Williamson</a>, 
<a href="/search/stat?searchtype=author&query=King%2C+D">Drew King</a>, 
<a href="/search/stat?searchtype=author&query=Huang%2C+Y">Ying Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Estimating a prediction function is a fundamental component of many data
analyses. The Super Learner ensemble, a particular implementation of stacking,
has desirable theoretical properties and has been used successfully in many
applications. Dimension reduction can be accomplished by using variable
screening algorithms, including the lasso, within the ensemble prior to fitting
other prediction algorithms. However, the performance of a Super Learner using
the lasso for dimension reduction has not been fully explored in cases where
the lasso is known to perform poorly. We provide empirical results that suggest
that a diverse set of candidate screening algorithms should be used to protect
against poor performance of any one screen, similar to the guidance for
choosing a library of prediction algorithms for the Super Learner.
</p>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03314" title="Abstract">arXiv:2311.03314</a> (cross-list from eess.IV) [<a href="/pdf/2311.03314" title="Download PDF">pdf</a>, <a href="/format/2311.03314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FATE: Feature-Agnostic Transformer-based Encoder for learning  generalized embedding spaces in flow cytometry data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Weijler%2C+L">Lisa Weijler</a>, 
<a href="/search/eess?searchtype=author&query=Kowarsch%2C+F">Florian Kowarsch</a>, 
<a href="/search/eess?searchtype=author&query=Reiter%2C+M">Michael Reiter</a>, 
<a href="/search/eess?searchtype=author&query=Hermosilla%2C+P">Pedro Hermosilla</a>, 
<a href="/search/eess?searchtype=author&query=Maurer-Granofszky%2C+M">Margarita Maurer-Granofszky</a>, 
<a href="/search/eess?searchtype=author&query=Dworzak%2C+M">Michael Dworzak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">While model architectures and training strategies have become more generic
and flexible with respect to different data modalities over the past years, a
persistent limitation lies in the assumption of fixed quantities and
arrangements of input features. This limitation becomes particularly relevant
in scenarios where the attributes captured during data acquisition vary across
different samples. In this work, we aim at effectively leveraging data with
varying features, without the need to constrain the input space to the
intersection of potential feature sets or to expand it to their union. We
propose a novel architecture that can directly process data without the
necessity of aligned feature modalities by learning a general embedding space
that captures the relationship between features across data samples with
varying sets of features. This is achieved via a set-transformer architecture
augmented by feature-encoder layers, thereby enabling the learning of a shared
latent feature space from data originating from heterogeneous feature spaces.
The advantages of the model are demonstrated for automatic cancer cell
detection in acute myeloid leukemia in flow cytometry data, where the features
measured during acquisition often vary between samples. Our proposed
architecture's capacity to operate seamlessly across incongruent feature spaces
is particularly relevant in this context, where data scarcity arises from the
low prevalence of the disease. The code is available for research purposes at
https://github.com/lisaweijler/FATE.
</p>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03326" title="Abstract">arXiv:2311.03326</a> (cross-list from math.OC) [<a href="/pdf/2311.03326" title="Download PDF">pdf</a>, <a href="/format/2311.03326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-convex potential game approach to global solution in sensor network  localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Xu%2C+G">Gehui Xu</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+G">Guanpu Chen</a>, 
<a href="/search/math?searchtype=author&query=Hong%2C+Y">Yiguang Hong</a>, 
<a href="/search/math?searchtype=author&query=Parisini%2C+T">Thomas Parisini</a>, 
<a href="/search/math?searchtype=author&query=Fidan%2C+B">Baris Fidan</a>, 
<a href="/search/math?searchtype=author&query=Johansson%2C+K+H">Karl H. Johansson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Sensor network localization (SNL) problems require determining the physical
coordinates of all sensors in a network. This process relies on the global
coordinates of anchors and the available measurements between non-anchor and
anchor nodes. Attributed to the intrinsic non-convexity, obtaining a globally
optimal solution to SNL is challenging, as well as implementing corresponding
algorithms. In this paper, we formulate a non-convex multi-player potential
game for a generic SNL problem to investigate the identification condition of
the global Nash equilibrium (NE) therein, where the global NE represents the
global solution of SNL. We employ canonical duality theory to transform the
non-convex game into a complementary dual problem. Then we develop a
conjugation-based algorithm to compute the stationary points of the
complementary dual problem. On this basis, we show an identification condition
of the global NE: the stationary point of the proposed algorithm satisfies a
duality relation. Finally, simulation results are provided to validate the
effectiveness of the theoretical results.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Tue,  7 Nov 23</h3>
<dl>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1812.06051" title="Abstract">arXiv:1812.06051</a> (replaced) [<a href="/pdf/1812.06051" title="Download PDF">pdf</a>, <a href="/format/1812.06051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Value of Interaction in Data Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Min Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was first submitted to CHI2019 on 21 Sept. 2018. Version 2 was submitted to CHI2023 on 10 Sept. 2022. Although it was not accepted in either case, the author believes that it may still be a useful contribution to the field of HCI. Version 3 includes the correction of a typo (in Eq. 3) identified by a CHI2023 reviewer. Version 4 was submitted to TOCHI on 3 Sept 2023 and 6 Nov. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1905.06104" title="Abstract">arXiv:1905.06104</a> (replaced) [<a href="/pdf/1905.06104" title="Download PDF">pdf</a>, <a href="/ps/1905.06104" title="Download PostScript">ps</a>, <a href="/format/1905.06104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On a Certain NP-Complete Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Margaryan%2C+S">Stepan Margaryan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1910.10708" title="Abstract">arXiv:1910.10708</a> (replaced) [<a href="/pdf/1910.10708" title="Download PDF">pdf</a>, <a href="/ps/1910.10708" title="Download PostScript">ps</a>, <a href="/format/1910.10708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Necessary and sufficient conditions for Boolean satisfiability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Margaryan%2C+S+G">Stepan G. Margaryan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 59 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2006.12622" title="Abstract">arXiv:2006.12622</a> (replaced) [<a href="/pdf/2006.12622" title="Download PDF">pdf</a>, <a href="/format/2006.12622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WD3: Taming the Estimation Bias in Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qiang He</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+X">Xinwen Hou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICTAI'20. Code: <a href="https://sites.google.com/view/ictai20-wd3/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2007.01777" title="Abstract">arXiv:2007.01777</a> (replaced) [<a href="/pdf/2007.01777" title="Download PDF">pdf</a>, <a href="/format/2007.01777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProtoryNet - Interpretable Text Classification Via Prototype  Trajectories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+D">Dat Hong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Baek%2C+S+S">Stephen S. Baek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2008.08838" title="Abstract">arXiv:2008.08838</a> (replaced) [<a href="/pdf/2008.08838" title="Download PDF">pdf</a>, <a href="/ps/2008.08838" title="Download PostScript">ps</a>, <a href="/format/2008.08838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training Matters: Unlocking Potentials of Deeper Graph Convolutional  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luan%2C+S">Sitao Luan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Mingde Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiao-Wen Chang</a>, 
<a href="/search/cs?searchtype=author&query=Precup%2C+D">Doina Precup</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 12th International Conference on Complex Networks and Their Applications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2011.07989" title="Abstract">arXiv:2011.07989</a> (replaced) [<a href="/pdf/2011.07989" title="Download PDF">pdf</a>, <a href="/format/2011.07989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Bandit Setting Balancing Information from State Evolution and  Corrupted Context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Galozy%2C+A">Alexander Galozy</a>, 
<a href="/search/cs?searchtype=author&query=Nowaczyk%2C+S">Slawomir Nowaczyk</a>, 
<a href="/search/cs?searchtype=author&query=Ohlsson%2C+M">Mattias Ohlsson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.03980" title="Abstract">arXiv:2103.03980</a> (replaced) [<a href="/pdf/2103.03980" title="Download PDF">pdf</a>, <a href="/format/2103.03980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revenue Maximization for Buyers with Costly Participation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gonczarowski%2C+Y+A">Yannai A. Gonczarowski</a>, 
<a href="/search/cs?searchtype=author&query=Immorlica%2C+N">Nicole Immorlica</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingkai Li</a>, 
<a href="/search/cs?searchtype=author&query=Lucier%2C+B">Brendan Lucier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at SODA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)

</div>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.04487" title="Abstract">arXiv:2105.04487</a> (replaced) [<a href="/pdf/2105.04487" title="Download PDF">pdf</a>, <a href="/format/2105.04487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tamper Detection against Unitary Operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boddu%2C+N+G">Naresh Goud Boddu</a>, 
<a href="/search/cs?searchtype=author&query=Kapshikar%2C+U+S">Upendra S. Kapshikar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Quantum
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Information Theory (cs.IT); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.09232" title="Abstract">arXiv:2107.09232</a> (replaced) [<a href="/pdf/2107.09232" title="Download PDF">pdf</a>, <a href="/format/2107.09232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using reinforcement learning to autonomously identify sources of error  for agents in group missions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Utimula%2C+K">Keishu Utimula</a>, 
<a href="/search/cs?searchtype=author&query=Hayaschi%2C+K">Ken-taro Hayaschi</a>, 
<a href="/search/cs?searchtype=author&query=Bihl%2C+T+J">Trevor J. Bihl</a>, 
<a href="/search/cs?searchtype=author&query=Hongo%2C+K">Kenta Hongo</a>, 
<a href="/search/cs?searchtype=author&query=Maezono%2C+R">Ryo Maezono</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> It has been edited in English
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.02551" title="Abstract">arXiv:2110.02551</a> (replaced) [<a href="/pdf/2110.02551" title="Download PDF">pdf</a>, <a href="/ps/2110.02551" title="Download PostScript">ps</a>, <a href="/format/2110.02551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Fish Tracking Techniques Based on Computer Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weiran Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenbo Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fei Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+M">Meng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Cen%2C+C">Chaojun Cen</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yanyu Qi</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qiannan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">You Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Substantial revisions, deletions and supplements have been made in this version to enhance readability and sharpen the logical flow
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.04060" title="Abstract">arXiv:2110.04060</a> (replaced) [<a href="/pdf/2110.04060" title="Download PDF">pdf</a>, <a href="/format/2110.04060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Insights into Graph Convolutional Networks using Neural Tangent  Kernels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sabanayagam%2C+M">Mahalakshmi Sabanayagam</a>, 
<a href="/search/cs?searchtype=author&query=Esser%2C+P">Pascal Esser</a>, 
<a href="/search/cs?searchtype=author&query=Ghoshdastidar%2C+D">Debarghya Ghoshdastidar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.06124" title="Abstract">arXiv:2110.06124</a> (replaced) [<a href="/pdf/2110.06124" title="Download PDF">pdf</a>, <a href="/ps/2110.06124" title="Download PostScript">ps</a>, <a href="/format/2110.06124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Taxonomy and Archetypes of Business Analytics in Smart Manufacturing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wanner%2C+J">Jonas Wanner</a>, 
<a href="/search/cs?searchtype=author&query=Wissuchek%2C+C">Christopher Wissuchek</a>, 
<a href="/search/cs?searchtype=author&query=Welsch%2C+G">Giacomo Welsch</a>, 
<a href="/search/cs?searchtype=author&query=Janiesch%2C+C">Christian Janiesch</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM SIGMIS Database: the DATABASE for Advances in Information
  Systems, Volume 54, Issue 1, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.08665" title="Abstract">arXiv:2111.08665</a> (replaced) [<a href="/pdf/2111.08665" title="Download PDF">pdf</a>, <a href="/ps/2111.08665" title="Download PostScript">ps</a>, <a href="/format/2111.08665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Post-Quantum Simulatable Extraction with Minimal Assumptions: Black-Box  and Constant-Round
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chia%2C+N">Nai-Hui Chia</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+K">Kai-Min Chung</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiao Liang</a>, 
<a href="/search/cs?searchtype=author&query=Yamakawa%2C+T">Takashi Yamakawa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.01587" title="Abstract">arXiv:2112.01587</a> (replaced) [<a href="/pdf/2112.01587" title="Download PDF">pdf</a>, <a href="/ps/2112.01587" title="Download PostScript">ps</a>, <a href="/format/2112.01587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving accuracy and uncertainty quantification of deep learning based  quantitative MRI using Monte Carlo dropout
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Avci%2C+M+Y">Mehmet Yigit Avci</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Ziyu Li</a>, 
<a href="/search/eess?searchtype=author&query=Fan%2C+Q">Qiuyun Fan</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+S">Susie Huang</a>, 
<a href="/search/eess?searchtype=author&query=Bilgic%2C+B">Berkin Bilgic</a>, 
<a href="/search/eess?searchtype=author&query=Tian%2C+Q">Qiyuan Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)

</div>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.12965" title="Abstract">arXiv:2112.12965</a> (replaced) [<a href="/pdf/2112.12965" title="Download PDF">pdf</a>, <a href="/format/2112.12965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error-bounded Approximate Time Series Joins Using Compact Dictionary  Representations of Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeh%2C+C+M">Chin-Chia Michael Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huiyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Z">Zhongfang Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Keogh%2C+E">Eamonn Keogh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.12305" title="Abstract">arXiv:2201.12305</a> (replaced) [<a href="/pdf/2201.12305" title="Download PDF">pdf</a>, <a href="/format/2201.12305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Post-Quantum Associative Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Lami%2C+L">Ludovico Lami</a>, 
<a href="/search/quant-ph?searchtype=author&query=Goldwater%2C+D">Daniel Goldwater</a>, 
<a href="/search/quant-ph?searchtype=author&query=Adesso%2C+G">Gerardo Adesso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 5 figures. v2: Extended with new analytical and numerical results for N&amp;gt;2, showing that an exponential advantage persists for large post-quantum memories. v3 is close to the published version
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J. Phys. A: Math. Theor. 56 455304 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT); Mathematical Physics (math-ph); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.02905" title="Abstract">arXiv:2202.02905</a> (replaced) [<a href="/pdf/2202.02905" title="Download PDF">pdf</a>, <a href="/format/2202.02905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Channel Capacity for Adversaries with Computationally Bounded  Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruzomberka%2C+E">Eric Ruzomberka</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chih-Chun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Love%2C+D+J">David J. Love</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.05069" title="Abstract">arXiv:2202.05069</a> (replaced) [<a href="/pdf/2202.05069" title="Download PDF">pdf</a>, <a href="/format/2202.05069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transfer-Learning Across Datasets with Different Input Dimensions: An  Algorithm and Analysis for the Linear Regression Case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Silvestrin%2C+L+P">Luis Pedro Silvestrin</a>, 
<a href="/search/stat?searchtype=author&query=van+Zanten%2C+H">Harry van Zanten</a>, 
<a href="/search/stat?searchtype=author&query=Hoogendoorn%2C+M">Mark Hoogendoorn</a>, 
<a href="/search/stat?searchtype=author&query=Koole%2C+G">Ger Koole</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Manuscript accepted for publication at the Journal of Computational Mathematics and Data Science. Code available at <a href="https://github.com/lpsilvestrin/incremental_input_tl">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.05246" title="Abstract">arXiv:2202.05246</a> (replaced) [<a href="/pdf/2202.05246" title="Download PDF">pdf</a>, <a href="/format/2202.05246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monotone Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bousquet%2C+O">Olivier Bousquet</a>, 
<a href="/search/cs?searchtype=author&query=Daniely%2C+A">Amit Daniely</a>, 
<a href="/search/cs?searchtype=author&query=Kaplan%2C+H">Haim Kaplan</a>, 
<a href="/search/cs?searchtype=author&query=Mansour%2C+Y">Yishay Mansour</a>, 
<a href="/search/cs?searchtype=author&query=Moran%2C+S">Shay Moran</a>, 
<a href="/search/cs?searchtype=author&query=Stemmer%2C+U">Uri Stemmer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fixed a calculation error in Lemma 2.5
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.05423" title="Abstract">arXiv:2202.05423</a> (replaced) [<a href="/pdf/2202.05423" title="Download PDF">pdf</a>, <a href="/ps/2202.05423" title="Download PostScript">ps</a>, <a href="/format/2202.05423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Curriculum Learning in Policy Optimization for Online  Combinatorial Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+R">Runlong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zelin He</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuandong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S+S">Simon S. Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 10 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.04262" title="Abstract">arXiv:2203.04262</a> (replaced) [<a href="/pdf/2203.04262" title="Download PDF">pdf</a>, <a href="/format/2203.04262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Hardness of the Minimum Distance Problem of Quantum Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Kapshikar%2C+U">Upendra Kapshikar</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kundu%2C+S">Srijita Kundu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Contains results previously included in <a href="/abs/2107.11286">arXiv:2107.11286</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Information Theory (Volume: 69, Issue: 10,
  October 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.05674" title="Abstract">arXiv:2203.05674</a> (replaced) [<a href="/pdf/2203.05674" title="Download PDF">pdf</a>, <a href="/ps/2203.05674" title="Download PostScript">ps</a>, <a href="/format/2203.05674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Particle Swarm Optimization based on Novelty Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Misra%2C+M+R">Mr.Rajesh Misra</a>, 
<a href="/search/cs?searchtype=author&query=Ray%2C+D+K+S">Dr. Kumar S Ray</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.07593" title="Abstract">arXiv:2203.07593</a> (replaced) [<a href="/pdf/2203.07593" title="Download PDF">pdf</a>, <a href="/format/2203.07593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distraction is All You Need for Fairness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yazdani-Jahromi%2C+M">Mehdi Yazdani-Jahromi</a>, 
<a href="/search/cs?searchtype=author&query=Rajabi%2C+A">AmirArsalan Rajabi</a>, 
<a href="/search/cs?searchtype=author&query=Yalabadi%2C+A+K">Ali Khodabandeh Yalabadi</a>, 
<a href="/search/cs?searchtype=author&query=Tayebi%2C+A">Aida Tayebi</a>, 
<a href="/search/cs?searchtype=author&query=Garibay%2C+O+O">Ozlem Ozmen Garibay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.13987" title="Abstract">arXiv:2203.13987</a> (replaced) [<a href="/pdf/2203.13987" title="Download PDF">pdf</a>, <a href="/format/2203.13987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Viability of Monocular Depth Pre-training for Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lao%2C+D">Dong Lao</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+A">Alex Wong</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Samuel Lu</a>, 
<a href="/search/cs?searchtype=author&query=Soatto%2C+S">Stefano Soatto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.14379" title="Abstract">arXiv:2203.14379</a> (replaced) [<a href="/pdf/2203.14379" title="Download PDF">pdf</a>, <a href="/ps/2203.14379" title="Download PostScript">ps</a>, <a href="/format/2203.14379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constructive Separations and Their Consequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lijie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Ce Jin</a>, 
<a href="/search/cs?searchtype=author&query=Santhanam%2C+R">Rahul Santhanam</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+R">Ryan Williams</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A preliminary version of this paper appeared in FOCS 2021. Abstract shortened to fit arXiv requirements
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.04415" title="Abstract">arXiv:2204.04415</a> (replaced) [<a href="/pdf/2204.04415" title="Download PDF">pdf</a>, <a href="/ps/2204.04415" title="Download PostScript">ps</a>, <a href="/format/2204.04415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Dynamic Average Consensus for a Network of Agents with  Time-varying Reference Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gudeta%2C+S">Solomon Gudeta</a>, 
<a href="/search/eess?searchtype=author&query=Karimoddini%2C+A">Ali Karimoddini</a>, 
<a href="/search/eess?searchtype=author&query=Davoodi%2C+M">Mohammadreza Davoodi</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 10.1109/SMC42975.2020.9282935
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.04785" title="Abstract">arXiv:2204.04785</a> (replaced) [<a href="/pdf/2204.04785" title="Download PDF">pdf</a>, <a href="/format/2204.04785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-free optimization of power/efficiency tradeoffs in quantum thermal  machines using reinforcement learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Erdman%2C+P+A">Paolo Andrea Erdman</a>, 
<a href="/search/quant-ph?searchtype=author&query=No%C3%A9%2C+F">Frank No&#xe9;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7+13 pages, 9 figures. arXiv admin note: text overlap with <a href="/abs/2108.13525">arXiv:2108.13525</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> PNAS Nexus 2, pgad248 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Mesoscale and Nanoscale Physics (cond-mat.mes-hall); Machine Learning (cs.LG); Chemical Physics (physics.chem-ph)

</div>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.08610" title="Abstract">arXiv:2204.08610</a> (replaced) [<a href="/pdf/2204.08610" title="Download PDF">pdf</a>, <a href="/format/2204.08610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Data Augmentation for Deep Learning: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Suorong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+W">Weikang Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengchen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Suhan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+F">Furao Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.10806" title="Abstract">arXiv:2204.10806</a> (replaced) [<a href="/pdf/2204.10806" title="Download PDF">pdf</a>, <a href="/format/2204.10806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Taxonomy of Human and ML Strengths in Decision-Making to Investigate  Human-ML Complementarity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rastogi%2C+C">Charvi Rastogi</a>, 
<a href="/search/cs?searchtype=author&query=Leqi%2C+L">Liu Leqi</a>, 
<a href="/search/cs?searchtype=author&query=Holstein%2C+K">Kenneth Holstein</a>, 
<a href="/search/cs?searchtype=author&query=Heidari%2C+H">Hoda Heidari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 5 figures, Proceedings of HCOMP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.06562" title="Abstract">arXiv:2205.06562</a> (replaced) [<a href="/pdf/2205.06562" title="Download PDF">pdf</a>, <a href="/format/2205.06562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A graph-based probabilistic geometric deep learning framework with  online enforcement of physical constraints to predict the criticality of  defects in porous materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krokos%2C+V">Vasilis Krokos</a>, 
<a href="/search/cs?searchtype=author&query=Bordas%2C+S+P+A">St&#xe9;phane P. A. Bordas</a>, 
<a href="/search/cs?searchtype=author&query=Kerfriden%2C+P">Pierre Kerfriden</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 68 pages; 52 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.12239" title="Abstract">arXiv:2205.12239</a> (replaced) [<a href="/pdf/2205.12239" title="Download PDF">pdf</a>, <a href="/format/2205.12239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gacs-Korner Common Information Variational Autoencoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kleinman%2C+M">Michael Kleinman</a>, 
<a href="/search/cs?searchtype=author&query=Achille%2C+A">Alessandro Achille</a>, 
<a href="/search/cs?searchtype=author&query=Soatto%2C+S">Stefano Soatto</a>, 
<a href="/search/cs?searchtype=author&query=Kao%2C+J">Jonathan Kao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item671">[671]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.13935" title="Abstract">arXiv:2205.13935</a> (replaced) [<a href="/pdf/2205.13935" title="Download PDF">pdf</a>, <a href="/format/2205.13935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting hidden confounding in observational data using multiple  environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Karlsson%2C+R+K+A">Rickard K.A. Karlsson</a>, 
<a href="/search/stat?searchtype=author&query=Krijthe%2C+J+H">Jesse H. Krijthe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 camera-ready version; 30 pages including references and appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item672">[672]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.16004" title="Abstract">arXiv:2205.16004</a> (replaced) [<a href="/pdf/2205.16004" title="Download PDF">pdf</a>, <a href="/format/2205.16004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Knowledge Gets Distilled in Knowledge Distillation?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ojha%2C+U">Utkarsh Ojha</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Rajan%2C+A+S">Anirudh Sundara Rajan</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yingyu Liang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y+J">Yong Jae Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 camera ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item673">[673]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.01820" title="Abstract">arXiv:2206.01820</a> (replaced) [<a href="/pdf/2206.01820" title="Download PDF">pdf</a>, <a href="/format/2206.01820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Robust Backpropagation-Free Framework for Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zee%2C+T">Timothy Zee</a>, 
<a href="/search/cs?searchtype=author&query=Ororbia%2C+A+G">Alexander G. Ororbia</a>, 
<a href="/search/cs?searchtype=author&query=Mali%2C+A">Ankur Mali</a>, 
<a href="/search/cs?searchtype=author&query=Nwogu%2C+I">Ifeoma Nwogu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item674">[674]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.01906" title="Abstract">arXiv:2206.01906</a> (replaced) [<a href="/pdf/2206.01906" title="Download PDF">pdf</a>, <a href="/format/2206.01906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Machine Learning in D2D-Enabled Heterogeneous Networks:  Architectures, Performance, and Open Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhipeng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xuwei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liwang%2C+M">Minghui Liwang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Ning Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xiaoyu Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xianbin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages,3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item675">[675]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.07245" title="Abstract">arXiv:2206.07245</a> (replaced) [<a href="/pdf/2206.07245" title="Download PDF">pdf</a>, <a href="/format/2206.07245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Extractive-and-Abstractive Framework for Source Code Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weisong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chunrong Fang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuchen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Quanjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+G">Guanhong Tao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+T">Tingxu Han</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yifei Ge</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yudu You</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bin Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ACM Transactions on Software Engineering and Methodology (TOSEM)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item676">[676]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.09375" title="Abstract">arXiv:2206.09375</a> (replaced) [<a href="/pdf/2206.09375" title="Download PDF">pdf</a>, <a href="/format/2206.09375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gray Learning from Non-IID Data with Out-of-distribution Samples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhilin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Longbing Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chang-Dong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item677">[677]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.10143" title="Abstract">arXiv:2206.10143</a> (replaced) [<a href="/pdf/2206.10143" title="Download PDF">pdf</a>, <a href="/format/2206.10143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Contrastive Approach to Online Change Point Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Goldman%2C+A">Artur Goldman</a>, 
<a href="/search/stat?searchtype=author&query=Puchkin%2C+N">Nikita Puchkin</a>, 
<a href="/search/stat?searchtype=author&query=Shcherbakova%2C+V">Valeriia Shcherbakova</a>, 
<a href="/search/stat?searchtype=author&query=Vinogradova%2C+U">Uliana Vinogradova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at AISTATS 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of The 26th International Conference on Artificial
  Intelligence and Statistics, PMLR 206:5686-5713, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item678">[678]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.04197" title="Abstract">arXiv:2207.04197</a> (replaced) [<a href="/pdf/2207.04197" title="Download PDF">pdf</a>, <a href="/format/2207.04197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-label Classification with High-rank and High-order Label  Correlations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Si%2C+C">Chongjie Si</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yuheng Jia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min-Ling Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yanghe Feng</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+C">Chongxiao Qu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023, TKDE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item679">[679]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.04277" title="Abstract">arXiv:2207.04277</a> (replaced) [<a href="/pdf/2207.04277" title="Download PDF">pdf</a>, <a href="/format/2207.04277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal policies for Bayesian olfactory search in turbulent flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Heinonen%2C+R+A">Robin A. Heinonen</a>, 
<a href="/search/physics?searchtype=author&query=Biferale%2C+L">Luca Biferale</a>, 
<a href="/search/physics?searchtype=author&query=Celani%2C+A">Antonio Celani</a>, 
<a href="/search/physics?searchtype=author&query=Vergassola%2C+M">Massimo Vergassola</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Computational Engineering, Finance, and Science (cs.CE); Chaotic Dynamics (nlin.CD); Biological Physics (physics.bio-ph)

</div>
</div>
</dd>
<dt><a name="item680">[680]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.05861" title="Abstract">arXiv:2207.05861</a> (replaced) [<a href="/pdf/2207.05861" title="Download PDF">pdf</a>, <a href="/format/2207.05861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Approach to Post-Quantum Non-Malleability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Liang%2C+X">Xiao Liang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pandey%2C+O">Omkant Pandey</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yamakawa%2C+T">Takashi Yamakawa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item681">[681]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.00638" title="Abstract">arXiv:2208.00638</a> (replaced) [<a href="/pdf/2208.00638" title="Download PDF">pdf</a>, <a href="/format/2208.00638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Composable Text Controls in Latent Space with ODEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guangyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zeyu Feng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zichao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaodan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+J">Junwei Bao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaodong He</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shuguang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhen Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhiting Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Camera Ready. Code available at: <a href="https://github.com/guangyliu/LatentOps">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item682">[682]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.09045" title="Abstract">arXiv:2208.09045</a> (replaced) [<a href="/pdf/2208.09045" title="Download PDF">pdf</a>, <a href="/format/2208.09045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monte Carlo is a good sampling strategy for polynomial approximation in  high dimensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Adcock%2C+B">Ben Adcock</a>, 
<a href="/search/math?searchtype=author&query=Brugiapaglia%2C+S">Simone Brugiapaglia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Functional Analysis (math.FA)

</div>
</div>
</dd>
<dt><a name="item683">[683]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.09495" title="Abstract">arXiv:2208.09495</a> (replaced) [<a href="/pdf/2208.09495" title="Download PDF">pdf</a>, <a href="/format/2208.09495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topical: Learning Repository Embeddings from Source Code using Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lherondelle%2C+A">Agathe Lherondelle</a>, 
<a href="/search/cs?searchtype=author&query=Babbar%2C+V">Varun Babbar</a>, 
<a href="/search/cs?searchtype=author&query=Satsangi%2C+Y">Yash Satsangi</a>, 
<a href="/search/cs?searchtype=author&query=Silavong%2C+F">Fran Silavong</a>, 
<a href="/search/cs?searchtype=author&query=Eloul%2C+S">Shaltiel Eloul</a>, 
<a href="/search/cs?searchtype=author&query=Moran%2C+S">Sean Moran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-print, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item684">[684]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.14228" title="Abstract">arXiv:2208.14228</a> (replaced) [<a href="/pdf/2208.14228" title="Download PDF">pdf</a>, <a href="/format/2208.14228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EasyScale: Accuracy-consistent Elastic Training for Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingzhen Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+W">Wencong Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Biao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hanyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hailong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Shiru Ren</a>, 
<a href="/search/cs?searchtype=author&query=Luan%2C+Z">Zhongzhi Luan</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xianyan Jia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Wei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+D">Depei Qian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be appeared at SC'23. Link: <a href="https://sc23.supercomputing.org/presentation/?id=pap262">this https URL</a>&amp;sess=sess168
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item685">[685]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.02528" title="Abstract">arXiv:2209.02528</a> (replaced) [<a href="/pdf/2209.02528" title="Download PDF">pdf</a>, <a href="/format/2209.02528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Symmetric Matrix Factorization: A More General and Better  Clustering Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kai Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICDM2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item686">[686]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.07863" title="Abstract">arXiv:2209.07863</a> (replaced) [<a href="/pdf/2209.07863" title="Download PDF">pdf</a>, <a href="/format/2209.07863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expanding continual few-shot learning benchmarks to include recognition  of specific instances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kowadlo%2C+G">Gideon Kowadlo</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+A">Abdelrahman Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Mayan%2C+A">Amir Mayan</a>, 
<a href="/search/cs?searchtype=author&query=Rawlinson%2C+D">David Rawlinson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 9 figures, 10 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item687">[687]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.10137" title="Abstract">arXiv:2209.10137</a> (replaced) [<a href="/pdf/2209.10137" title="Download PDF">pdf</a>, <a href="/format/2209.10137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rank-Preserving Multidimensional Mechanisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Bikhchandani%2C+S">Sushil Bikhchandani</a>, 
<a href="/search/econ?searchtype=author&query=Mishra%2C+D">Debasis Mishra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item688">[688]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.03713" title="Abstract">arXiv:2210.03713</a> (replaced) [<a href="/pdf/2210.03713" title="Download PDF">pdf</a>, <a href="/format/2210.03713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integration of Riemannian Motion Policy with Whole-Body Control for  Collision-Free Legged Locomotion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marew%2C+D">Daniel Marew</a>, 
<a href="/search/cs?searchtype=author&query=Lvovsky%2C+M">Misha Lvovsky</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shangqun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sessions%2C+S">Shotaro Sessions</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Donghyun Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, 2023 IEEE-RAS International Conference on Humanoid Robots
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item689">[689]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.07484" title="Abstract">arXiv:2210.07484</a> (replaced) [<a href="/pdf/2210.07484" title="Download PDF">pdf</a>, <a href="/format/2210.07484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mutual Information Regularized Offline Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+B">Bingyi Kang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhongwen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Min Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shuicheng Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item690">[690]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.07893" title="Abstract">arXiv:2210.07893</a> (replaced) [<a href="/pdf/2210.07893" title="Download PDF">pdf</a>, <a href="/format/2210.07893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerically Stable Sparse Gaussian Processes via Minimum Separation  using Cover Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Terenin%2C+A">Alexander Terenin</a>, 
<a href="/search/stat?searchtype=author&query=Burt%2C+D+R">David R. Burt</a>, 
<a href="/search/stat?searchtype=author&query=Artemev%2C+A">Artem Artemev</a>, 
<a href="/search/stat?searchtype=author&query=Flaxman%2C+S">Seth Flaxman</a>, 
<a href="/search/stat?searchtype=author&query=van+der+Wilk%2C+M">Mark van der Wilk</a>, 
<a href="/search/stat?searchtype=author&query=Rasmussen%2C+C+E">Carl Edward Rasmussen</a>, 
<a href="/search/stat?searchtype=author&query=Ge%2C+H">Hong Ge</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Machine Learning Research, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item691">[691]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.11921" title="Abstract">arXiv:2210.11921</a> (replaced) [<a href="/pdf/2210.11921" title="Download PDF">pdf</a>, <a href="/format/2210.11921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-scale data reconstruction of turbulent rotating flows with Gappy  POD, Extended POD and Generative Adversarial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Li%2C+T">Tianyi Li</a>, 
<a href="/search/physics?searchtype=author&query=Buzzicotti%2C+M">Michele Buzzicotti</a>, 
<a href="/search/physics?searchtype=author&query=Biferale%2C+L">Luca Biferale</a>, 
<a href="/search/physics?searchtype=author&query=Bonaccorso%2C+F">Fabio Bonaccorso</a>, 
<a href="/search/physics?searchtype=author&query=Chen%2C+S">Shiyi Chen</a>, 
<a href="/search/physics?searchtype=author&query=Wan%2C+M">Minping Wan</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J. Fluid Mech. 971, A3 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Chaotic Dynamics (nlin.CD); Geophysics (physics.geo-ph)

</div>
</div>
</dd>
<dt><a name="item692">[692]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.13111" title="Abstract">arXiv:2210.13111</a> (replaced) [<a href="/pdf/2210.13111" title="Download PDF">pdf</a>, <a href="/format/2210.13111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning and Meta Learning: Approaches, Applications, and  Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaonan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yansha Deng</a>, 
<a href="/search/cs?searchtype=author&query=Nallanathan%2C+A">Arumugam Nallanathan</a>, 
<a href="/search/cs?searchtype=author&query=Bennis%2C+M">Mehdi Bennis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item693">[693]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.13708" title="Abstract">arXiv:2210.13708</a> (replaced) [<a href="/pdf/2210.13708" title="Download PDF">pdf</a>, <a href="/format/2210.13708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MARLlib: A Scalable and Efficient Multi-agent Reinforcement Learning  Library
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Siyi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yifan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Minquan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weixun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaodan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhihui Li</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiaojun Chang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yaodong Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item694">[694]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.16979" title="Abstract">arXiv:2210.16979</a> (replaced) [<a href="/pdf/2210.16979" title="Download PDF">pdf</a>, <a href="/ps/2210.16979" title="Download PostScript">ps</a>, <a href="/format/2210.16979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Do We Need Graph Neural Networks for Node Classification?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luan%2C+S">Sitao Luan</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+C">Chenqing Hua</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Qincheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiaqi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiao-Wen Chang</a>, 
<a href="/search/cs?searchtype=author&query=Precup%2C+D">Doina Precup</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 12th International Conference on Complex Networks and Their Applications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item695">[695]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.05223" title="Abstract">arXiv:2211.05223</a> (replaced) [<a href="/pdf/2211.05223" title="Download PDF">pdf</a>, <a href="/format/2211.05223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed State Estimation for Linear Time-invariant Systems with  Aperiodic Sampled Measurement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+S">Shimin Wang</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+Y">Ya-Jun Pan</a>, 
<a href="/search/eess?searchtype=author&query=Guay%2C+M">Martin Guay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Dynamical Systems (math.DS); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item696">[696]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08405" title="Abstract">arXiv:2211.08405</a> (replaced) [<a href="/pdf/2211.08405" title="Download PDF">pdf</a>, <a href="/format/2211.08405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using multimodal learning and deep generative models for corporate  bankruptcy prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Mancisidor%2C+R+A">Rogelio A. Mancisidor</a>, 
<a href="/search/q-fin?searchtype=author&query=Aas%2C+K">Kjersti Aas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Risk Management (q-fin.RM)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item697">[697]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.11081" title="Abstract">arXiv:2211.11081</a> (replaced) [<a href="/pdf/2211.11081" title="Download PDF">pdf</a>, <a href="/format/2211.11081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Theory of Unsupervised Translation Motivated by Understanding Animal  Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goldwasser%2C+S">Shafi Goldwasser</a>, 
<a href="/search/cs?searchtype=author&query=Gruber%2C+D+F">David F. Gruber</a>, 
<a href="/search/cs?searchtype=author&query=Kalai%2C+A+T">Adam Tauman Kalai</a>, 
<a href="/search/cs?searchtype=author&query=Paradise%2C+O">Orr Paradise</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item698">[698]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13979" title="Abstract">arXiv:2211.13979</a> (replaced) [<a href="/pdf/2211.13979" title="Download PDF">pdf</a>, <a href="/format/2211.13979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BatmanNet: Bi-branch Masked Graph Transformer Autoencoder for Molecular  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zheng Feng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanjun Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bowen Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongrui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sha%2C+C">Chulin Sha</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+M">Min He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaolin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 6 figures, Accepted by Briefings in Bioinformatics in 17-Oct-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item699">[699]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14578" title="Abstract">arXiv:2211.14578</a> (replaced) [<a href="/pdf/2211.14578" title="Download PDF">pdf</a>, <a href="/format/2211.14578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimation and inference for transfer learning with high-dimensional  quantile regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Huang%2C+J">Jiayu Huang</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+M">Mingqiu Wang</a>, 
<a href="/search/stat?searchtype=author&query=Wu%2C+Y">Yuanshan Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 124 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item700">[700]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14785" title="Abstract">arXiv:2211.14785</a> (replaced) [<a href="/pdf/2211.14785" title="Download PDF">pdf</a>, <a href="/ps/2211.14785" title="Download PostScript">ps</a>, <a href="/format/2211.14785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning for Efficient CSI Feedback in Massive MIMO: Adapting to  New Environments and Small Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Li Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lianming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zhi Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 11 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item701">[701]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14851" title="Abstract">arXiv:2211.14851</a> (replaced) [<a href="/pdf/2211.14851" title="Download PDF">pdf</a>, <a href="/format/2211.14851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance evaluation of deep segmentation models for Contrails  detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhandari%2C+A">Akshat Bhandari</a>, 
<a href="/search/cs?searchtype=author&query=Rallabandi%2C+S">Sriya Rallabandi</a>, 
<a href="/search/cs?searchtype=author&query=Singhal%2C+S">Sanchit Singhal</a>, 
<a href="/search/cs?searchtype=author&query=Kasliwal%2C+A">Aditya Kasliwal</a>, 
<a href="/search/cs?searchtype=author&query=Seth%2C+P">Pratinav Seth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Tackling Climate Change with Machine Learning: workshop at NeurIPS 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item702">[702]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.00219" title="Abstract">arXiv:2212.00219</a> (replaced) [<a href="/pdf/2212.00219" title="Download PDF">pdf</a>, <a href="/format/2212.00219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are you using test log-likelihood correctly?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Deshpande%2C+S+K">Sameer K. Deshpande</a>, 
<a href="/search/stat?searchtype=author&query=Ghosh%2C+S">Soumya Ghosh</a>, 
<a href="/search/stat?searchtype=author&query=Nguyen%2C+T+D">Tin D. Nguyen</a>, 
<a href="/search/stat?searchtype=author&query=Broderick%2C+T">Tamara Broderick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the ICBINB Workshop at NeurIPS 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Other Statistics (stat.OT)

</div>
</div>
</dd>
<dt><a name="item703">[703]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.06132" title="Abstract">arXiv:2212.06132</a> (replaced) [<a href="/pdf/2212.06132" title="Download PDF">pdf</a>, <a href="/ps/2212.06132" title="Download PostScript">ps</a>, <a href="/format/2212.06132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nearly Minimax Optimal Reinforcement Learning for Linear Markov Decision  Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiafan He</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Heyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Dongruo Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Quanquan Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 1 table. In ICML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item704">[704]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.06272" title="Abstract">arXiv:2212.06272</a> (replaced) [<a href="/pdf/2212.06272" title="Download PDF">pdf</a>, <a href="/format/2212.06272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightweight Blockchain Solutions: Taxonomy, Research Progress, and  Comprehensive Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mershad%2C+K">Khaleel Mershad</a>, 
<a href="/search/cs?searchtype=author&query=Cheikhrouhou%2C+O">Omar Cheikhrouhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 77 pages, 10 figures, final version accepted by Internet of Things Journal, Elsevier
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 24(2023)100984
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item705">[705]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.06776" title="Abstract">arXiv:2212.06776</a> (replaced) [<a href="/pdf/2212.06776" title="Download PDF">pdf</a>, <a href="/format/2212.06776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unfolding Local Growth Rate Estimates for (Almost) Perfect Adversarial  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lorenz%2C+P">Peter Lorenz</a>, 
<a href="/search/cs?searchtype=author&query=Keuper%2C+M">Margret Keuper</a>, 
<a href="/search/cs?searchtype=author&query=Keuper%2C+J">Janis Keuper</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at VISAPP23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item706">[706]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07372" title="Abstract">arXiv:2212.07372</a> (replaced) [<a href="/pdf/2212.07372" title="Download PDF">pdf</a>, <a href="/format/2212.07372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Compression with Product Quantized Masked Image Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=El-Nouby%2C+A">Alaaeldin El-Nouby</a>, 
<a href="/search/cs?searchtype=author&query=Muckley%2C+M+J">Matthew J. Muckley</a>, 
<a href="/search/cs?searchtype=author&query=Ullrich%2C+K">Karen Ullrich</a>, 
<a href="/search/cs?searchtype=author&query=Laptev%2C+I">Ivan Laptev</a>, 
<a href="/search/cs?searchtype=author&query=Verbeek%2C+J">Jakob Verbeek</a>, 
<a href="/search/cs?searchtype=author&query=J%C3%A9gou%2C+H">Herv&#xe9; J&#xe9;gou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item707">[707]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07907" title="Abstract">arXiv:2212.07907</a> (replaced) [<a href="/pdf/2212.07907" title="Download PDF">pdf</a>, <a href="/format/2212.07907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic vehicle trajectory data reconstruction at scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanbing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gloudemans%2C+D">Derek Gloudemans</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Junyi Ji</a>, 
<a href="/search/cs?searchtype=author&query=Teoh%2C+Z+N">Zi Nean Teoh</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lisa Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zach%C3%A1r%2C+G">Gergely Zach&#xe1;r</a>, 
<a href="/search/cs?searchtype=author&query=Barbour%2C+W">William Barbour</a>, 
<a href="/search/cs?searchtype=author&query=Work%2C+D">Daniel Work</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item708">[708]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09577" title="Abstract">arXiv:2212.09577</a> (replaced) [<a href="/pdf/2212.09577" title="Download PDF">pdf</a>, <a href="/format/2212.09577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CiteBench: A benchmark for Scientific Citation Text Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Funkquist%2C+M">Martin Funkquist</a>, 
<a href="/search/cs?searchtype=author&query=Kuznetsov%2C+I">Ilia Kuznetsov</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yufang Hou</a>, 
<a href="/search/cs?searchtype=author&query=Gurevych%2C+I">Iryna Gurevych</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in EMNLP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item709">[709]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.11143" title="Abstract">arXiv:2212.11143</a> (replaced) [<a href="/pdf/2212.11143" title="Download PDF">pdf</a>, <a href="/format/2212.11143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient First-order Methods for Convex Optimization with Strongly  Convex Function Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lin%2C+Z">Zhenwei Lin</a>, 
<a href="/search/math?searchtype=author&query=Deng%2C+Q">Qi Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> new experiments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item710">[710]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.11702" title="Abstract">arXiv:2212.11702</a> (replaced) [<a href="/pdf/2212.11702" title="Download PDF">pdf</a>, <a href="/format/2212.11702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Meta-Representation Learning via Global Label Inference and  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruohan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Falk%2C+I">Isak Falk</a>, 
<a href="/search/cs?searchtype=author&query=Pontil%2C+M">Massimiliano Pontil</a>, 
<a href="/search/cs?searchtype=author&query=Ciliberto%2C+C">Carlo Ciliberto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item711">[711]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.14246" title="Abstract">arXiv:2212.14246</a> (replaced) [<a href="/pdf/2212.14246" title="Download PDF">pdf</a>, <a href="/format/2212.14246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust representations of oil wells&#x27; intervals via sparse attention  mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ermilova%2C+A">Alina Ermilova</a>, 
<a href="/search/cs?searchtype=author&query=Baramiia%2C+N">Nikita Baramiia</a>, 
<a href="/search/cs?searchtype=author&query=Kornilov%2C+V">Valerii Kornilov</a>, 
<a href="/search/cs?searchtype=author&query=Petrakov%2C+S">Sergey Petrakov</a>, 
<a href="/search/cs?searchtype=author&query=Zaytsev%2C+A">Alexey Zaytsev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item712">[712]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02364" title="Abstract">arXiv:2301.02364</a> (replaced) [<a href="/pdf/2301.02364" title="Download PDF">pdf</a>, <a href="/format/2301.02364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object as Query: Lifting any 2D Object Detector to 3D Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zitian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zehao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jiahui Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Naiyan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Si Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item713">[713]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03505" title="Abstract">arXiv:2301.03505</a> (replaced) [<a href="/pdf/2301.03505" title="Download PDF">pdf</a>, <a href="/format/2301.03505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advances in Medical Image Analysis with Vision Transformers: A  Comprehensive Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azad%2C+R">Reza Azad</a>, 
<a href="/search/cs?searchtype=author&query=Kazerouni%2C+A">Amirhossein Kazerouni</a>, 
<a href="/search/cs?searchtype=author&query=Heidari%2C+M">Moein Heidari</a>, 
<a href="/search/cs?searchtype=author&query=Aghdam%2C+E+K">Ehsan Khodapanah Aghdam</a>, 
<a href="/search/cs?searchtype=author&query=Molaei%2C+A">Amirali Molaei</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yiwei Jia</a>, 
<a href="/search/cs?searchtype=author&query=Jose%2C+A">Abin Jose</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+R">Rijo Roy</a>, 
<a href="/search/cs?searchtype=author&query=Merhof%2C+D">Dorit Merhof</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841523002608">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item714">[714]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03764" title="Abstract">arXiv:2301.03764</a> (replaced) [<a href="/pdf/2301.03764" title="Download PDF">pdf</a>, <a href="/format/2301.03764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exponential Runge-Kutta Parareal for Non-Diffusive Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Buvoli%2C+T">Tommaso Buvoli</a>, 
<a href="/search/math?searchtype=author&query=Minion%2C+M+L">Michael L. Minion</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item715">[715]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.05313" title="Abstract">arXiv:2301.05313</a> (replaced) [<a href="/pdf/2301.05313" title="Download PDF">pdf</a>, <a href="/ps/2301.05313" title="Download PostScript">ps</a>, <a href="/format/2301.05313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algebraic Invariants of Codes on Weighted Projective Planes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%87ak%C4%B1ro%C4%9Flu%2C+Y">Ya&#x11f;mur &#xc7;ak&#x131;ro&#x11f;lu</a>, 
<a href="/search/cs?searchtype=author&query=%C5%9Eahin%2C+M">Mesut &#x15e;ahin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Commutative Algebra (math.AC); Algebraic Geometry (math.AG)

</div>
</div>
</dd>
<dt><a name="item716">[716]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.05661" title="Abstract">arXiv:2301.05661</a> (replaced) [<a href="/pdf/2301.05661" title="Download PDF">pdf</a>, <a href="/ps/2301.05661" title="Download PostScript">ps</a>, <a href="/format/2301.05661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Choice-free Dualities for Lattice Expansions: Application to Logics with  a Negation Operator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hartonas%2C+C">Chrysafis Hartonas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2110.06924">arXiv:2110.06924</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item717">[717]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.06627" title="Abstract">arXiv:2301.06627</a> (replaced) [<a href="/pdf/2301.06627" title="Download PDF">pdf</a>, <a href="/format/2301.06627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dissociating language and thought in large language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahowald%2C+K">Kyle Mahowald</a>, 
<a href="/search/cs?searchtype=author&query=Ivanova%2C+A+A">Anna A. Ivanova</a>, 
<a href="/search/cs?searchtype=author&query=Blank%2C+I+A">Idan A. Blank</a>, 
<a href="/search/cs?searchtype=author&query=Kanwisher%2C+N">Nancy Kanwisher</a>, 
<a href="/search/cs?searchtype=author&query=Tenenbaum%2C+J+B">Joshua B. Tenenbaum</a>, 
<a href="/search/cs?searchtype=author&query=Fedorenko%2C+E">Evelina Fedorenko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The two lead authors contributed equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item718">[718]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07541" title="Abstract">arXiv:2301.07541</a> (replaced) [<a href="/pdf/2301.07541" title="Download PDF">pdf</a>, <a href="/format/2301.07541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Adversarial Networks to infer velocity components in rotating  turbulent flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Li%2C+T">Tianyi Li</a>, 
<a href="/search/physics?searchtype=author&query=Buzzicotti%2C+M">Michele Buzzicotti</a>, 
<a href="/search/physics?searchtype=author&query=Biferale%2C+L">Luca Biferale</a>, 
<a href="/search/physics?searchtype=author&query=Bonaccorso%2C+F">Fabio Bonaccorso</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Eur. Phys. J. E 46, 31 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Chaotic Dynamics (nlin.CD); Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item719">[719]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.08110" title="Abstract">arXiv:2301.08110</a> (replaced) [<a href="/pdf/2301.08110" title="Download PDF">pdf</a>, <a href="/format/2301.08110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AtMan: Understanding Transformer Predictions Through Memory Efficient  Attention Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deiseroth%2C+B">Bj&#xf6;rn Deiseroth</a>, 
<a href="/search/cs?searchtype=author&query=Deb%2C+M">Mayukh Deb</a>, 
<a href="/search/cs?searchtype=author&query=Weinbach%2C+S">Samuel Weinbach</a>, 
<a href="/search/cs?searchtype=author&query=Brack%2C+M">Manuel Brack</a>, 
<a href="/search/cs?searchtype=author&query=Schramowski%2C+P">Patrick Schramowski</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+K">Kristian Kersting</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item720">[720]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09493" title="Abstract">arXiv:2301.09493</a> (replaced) [<a href="/pdf/2301.09493" title="Download PDF">pdf</a>, <a href="/ps/2301.09493" title="Download PostScript">ps</a>, <a href="/format/2301.09493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Functionality of box intersection graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dallard%2C+C">Cl&#xe9;ment Dallard</a>, 
<a href="/search/math?searchtype=author&query=Lozin%2C+V">Vadim Lozin</a>, 
<a href="/search/math?searchtype=author&query=Milani%C4%8D%2C+M">Martin Milani&#x10d;</a>, 
<a href="/search/math?searchtype=author&query=%C5%A0torgel%2C+K">Kenny &#x160;torgel</a>, 
<a href="/search/math?searchtype=author&query=Zamaraev%2C+V">Viktor Zamaraev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item721">[721]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10134" title="Abstract">arXiv:2301.10134</a> (replaced) [<a href="/pdf/2301.10134" title="Download PDF">pdf</a>, <a href="/format/2301.10134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bipartite Graph Diffusion Model for Human Interaction Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chopin%2C+B">Baptiste Chopin</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Daoudi%2C+M">Mohamed Daoudi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted in WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item722">[722]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11841" title="Abstract">arXiv:2301.11841</a> (replaced) [<a href="/pdf/2301.11841" title="Download PDF">pdf</a>, <a href="/format/2301.11841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PhysGraph: Physics-Based Integration Using Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Halimi%2C+O">Oshri Halimi</a>, 
<a href="/search/cs?searchtype=author&query=Larionov%2C+E">Egor Larionov</a>, 
<a href="/search/cs?searchtype=author&query=Barzelay%2C+Z">Zohar Barzelay</a>, 
<a href="/search/cs?searchtype=author&query=Herholz%2C+P">Philipp Herholz</a>, 
<a href="/search/cs?searchtype=author&query=Stuyck%2C+T">Tuur Stuyck</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item723">[723]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12608" title="Abstract">arXiv:2301.12608</a> (replaced) [<a href="/pdf/2301.12608" title="Download PDF">pdf</a>, <a href="/format/2301.12608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Neuron Interpretation Methods of NLP Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yimin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Dalvi%2C+F">Fahim Dalvi</a>, 
<a href="/search/cs?searchtype=author&query=Durrani%2C+N">Nadir Durrani</a>, 
<a href="/search/cs?searchtype=author&query=Sajjad%2C+H">Hassan Sajjad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item724">[724]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13139" title="Abstract">arXiv:2301.13139</a> (replaced) [<a href="/pdf/2301.13139" title="Download PDF">pdf</a>, <a href="/format/2301.13139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Framework for Policy Mirror Descent with General  Parameterization and Linear Convergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Alfano%2C+C">Carlo Alfano</a>, 
<a href="/search/stat?searchtype=author&query=Yuan%2C+R">Rui Yuan</a>, 
<a href="/search/stat?searchtype=author&query=Rebeschini%2C+P">Patrick Rebeschini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Uploaded NeurIPS accepted paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item725">[725]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00151" title="Abstract">arXiv:2302.00151</a> (replaced) [<a href="/pdf/2302.00151" title="Download PDF">pdf</a>, <a href="/ps/2302.00151" title="Download PostScript">ps</a>, <a href="/format/2302.00151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formalizing $&#x3c0;_4(\mathbb{S}^3) \cong \mathbb{Z}/2\mathbb{Z}$ and  Computing a Brunerie Number in Cubical Agda
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ljungstr%C3%B6m%2C+A">Axel Ljungstr&#xf6;m</a>, 
<a href="/search/math?searchtype=author&query=M%C3%B6rtberg%2C+A">Anders M&#xf6;rtberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Topology (math.AT)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item726">[726]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00217" title="Abstract">arXiv:2302.00217</a> (replaced) [<a href="/pdf/2302.00217" title="Download PDF">pdf</a>, <a href="/format/2302.00217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reliable A Posteriori Error Estimator for a Multi-scale Cancer Invasion  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=B.%2C+G+P">Gopika P. B.</a>, 
<a href="/search/math?searchtype=author&query=Ranwan%2C+N">Nishant Ranwan</a>, 
<a href="/search/math?searchtype=author&query=Chamakuri%2C+N">Nagaiah Chamakuri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item727">[727]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01186" title="Abstract">arXiv:2302.01186</a> (replaced) [<a href="/pdf/2302.01186" title="Download PDF">pdf</a>, <a href="/format/2302.01186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Power of Preconditioning in Overparameterized Low-Rank Matrix  Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xingyu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yandi Shen</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+Y">Yuejie Chi</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Cong Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> New analysis in the noisy and the approximately low-rank settings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item728">[728]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02713" title="Abstract">arXiv:2302.02713</a> (replaced) [<a href="/pdf/2302.02713" title="Download PDF">pdf</a>, <a href="/format/2302.02713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flat Seeking Bayesian Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V">Van-Anh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Vuong%2C+T">Tung-Long Vuong</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+H">Hoang Phan</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+T">Thanh-Toan Do</a>, 
<a href="/search/cs?searchtype=author&query=Phung%2C+D">Dinh Phung</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Trung Le</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Advances in Neural Information Processing Systems, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item729">[729]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02995" title="Abstract">arXiv:2302.02995</a> (replaced) [<a href="/pdf/2302.02995" title="Download PDF">pdf</a>, <a href="/format/2302.02995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tight bound on treedepth in terms of pathwidth and longest path
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hatzel%2C+M">Meike Hatzel</a>, 
<a href="/search/math?searchtype=author&query=Joret%2C+G">Gwena&#xeb;l Joret</a>, 
<a href="/search/math?searchtype=author&query=Micek%2C+P">Piotr Micek</a>, 
<a href="/search/math?searchtype=author&query=Pilipczuk%2C+M">Marcin Pilipczuk</a>, 
<a href="/search/math?searchtype=author&query=Ueckerdt%2C+T">Torsten Ueckerdt</a>, 
<a href="/search/math?searchtype=author&query=Walczak%2C+B">Bartosz Walczak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v3: corrected some typos. v2: revised following referees' comments, corrects an error in v1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item730">[730]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03014" title="Abstract">arXiv:2302.03014</a> (replaced) [<a href="/pdf/2302.03014" title="Download PDF">pdf</a>, <a href="/format/2302.03014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detection and Localization of Melanoma Skin Cancer in Histopathological  Whole Slide Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kanwal%2C+N">Neel Kanwal</a>, 
<a href="/search/eess?searchtype=author&query=Amundsen%2C+R">Roger Amundsen</a>, 
<a href="/search/eess?searchtype=author&query=Hardardottir%2C+H">Helga Hardardottir</a>, 
<a href="/search/eess?searchtype=author&query=Tomasetti%2C+L">Luca Tomasetti</a>, 
<a href="/search/eess?searchtype=author&query=Undersrud%2C+E+S">Erling Sandoy Undersrud</a>, 
<a href="/search/eess?searchtype=author&query=Janssen%2C+E+A+M">Emiel A.M. Janssen</a>, 
<a href="/search/eess?searchtype=author&query=Engan%2C+K">Kjersti Engan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EUSIPCO 23
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 10.23919/EUSIPCO58844.2023.10290087
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item731">[731]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03421" title="Abstract">arXiv:2302.03421</a> (replaced) [<a href="/pdf/2302.03421" title="Download PDF">pdf</a>, <a href="/format/2302.03421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A unified recipe for deriving (time-uniform) PAC-Bayes bounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chugg%2C+B">Ben Chugg</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+H">Hongjian Wang</a>, 
<a href="/search/stat?searchtype=author&query=Ramdas%2C+A">Aaditya Ramdas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 57 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item732">[732]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05979" title="Abstract">arXiv:2302.05979</a> (replaced) [<a href="/pdf/2302.05979" title="Download PDF">pdf</a>, <a href="/format/2302.05979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Integrators and Graph-Based Solvers for Multibody Dynamics  in Maximal Coordinates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Br%C3%BCdigam%2C+J">Jan Br&#xfc;digam</a>, 
<a href="/search/cs?searchtype=author&query=Sosnowski%2C+S">Stefan Sosnowski</a>, 
<a href="/search/cs?searchtype=author&query=Manchester%2C+Z">Zachary Manchester</a>, 
<a href="/search/cs?searchtype=author&query=Hirche%2C+S">Sandra Hirche</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item733">[733]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06960" title="Abstract">arXiv:2302.06960</a> (replaced) [<a href="/pdf/2302.06960" title="Download PDF">pdf</a>, <a href="/format/2302.06960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data pruning and neural scaling laws: fundamental limitations of  score-based algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ayed%2C+F">Fadhel Ayed</a>, 
<a href="/search/stat?searchtype=author&query=Hayou%2C+S">Soufiane Hayou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item734">[734]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07425" title="Abstract">arXiv:2302.07425</a> (replaced) [<a href="/pdf/2302.07425" title="Download PDF">pdf</a>, <a href="/format/2302.07425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bandit Social Learning: Exploration under Myopic Behavior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banihashem%2C+K">Kiarash Banihashem</a>, 
<a href="/search/cs?searchtype=author&query=Hajiaghayi%2C+M">MohammadTaghi Hajiaghayi</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+S">Suho Shin</a>, 
<a href="/search/cs?searchtype=author&query=Slivkins%2C+A">Aleksandrs Slivkins</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of NeurIPS 2023 paper titled "Bandit Social Learning under Myopic Behavior"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item735">[735]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08284" title="Abstract">arXiv:2302.08284</a> (replaced) [<a href="/pdf/2302.08284" title="Download PDF">pdf</a>, <a href="/format/2302.08284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClaPIM: Scalable Sequence CLAssification using Processing-In-Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khalifa%2C+M">Marcel Khalifa</a>, 
<a href="/search/cs?searchtype=author&query=Hoffer%2C+B">Barak Hoffer</a>, 
<a href="/search/cs?searchtype=author&query=Leitersdorf%2C+O">Orian Leitersdorf</a>, 
<a href="/search/cs?searchtype=author&query=Hanhan%2C+R">Robert Hanhan</a>, 
<a href="/search/cs?searchtype=author&query=Perach%2C+B">Ben Perach</a>, 
<a href="/search/cs?searchtype=author&query=Yavits%2C+L">Leonid Yavits</a>, 
<a href="/search/cs?searchtype=author&query=Kvatinsky%2C+S">Shahar Kvatinsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item736">[736]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08956" title="Abstract">arXiv:2302.08956</a> (replaced) [<a href="/pdf/2302.08956" title="Download PDF">pdf</a>, <a href="/format/2302.08956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AfriSenti: A Twitter Sentiment Analysis Benchmark for African Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muhammad%2C+S+H">Shamsuddeen Hassan Muhammad</a>, 
<a href="/search/cs?searchtype=author&query=Abdulmumin%2C+I">Idris Abdulmumin</a>, 
<a href="/search/cs?searchtype=author&query=Ayele%2C+A+A">Abinew Ali Ayele</a>, 
<a href="/search/cs?searchtype=author&query=Ousidhoum%2C+N">Nedjma Ousidhoum</a>, 
<a href="/search/cs?searchtype=author&query=Adelani%2C+D+I">David Ifeoluwa Adelani</a>, 
<a href="/search/cs?searchtype=author&query=Yimam%2C+S+M">Seid Muhie Yimam</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+I+S">Ibrahim Sa&#x27;id Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Beloucif%2C+M">Meriem Beloucif</a>, 
<a href="/search/cs?searchtype=author&query=Mohammad%2C+S+M">Saif M. Mohammad</a>, 
<a href="/search/cs?searchtype=author&query=Ruder%2C+S">Sebastian Ruder</a>, 
<a href="/search/cs?searchtype=author&query=Hourrane%2C+O">Oumaima Hourrane</a>, 
<a href="/search/cs?searchtype=author&query=Brazdil%2C+P">Pavel Brazdil</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+F+D+M+A">Felermino D&#xe1;rio M&#xe1;rio Ant&#xf3;nio Ali</a>, 
<a href="/search/cs?searchtype=author&query=David%2C+D">Davis David</a>, 
<a href="/search/cs?searchtype=author&query=Osei%2C+S">Salomey Osei</a>, 
<a href="/search/cs?searchtype=author&query=Bello%2C+B+S">Bello Shehu Bello</a>, 
<a href="/search/cs?searchtype=author&query=Ibrahim%2C+F">Falalu Ibrahim</a>, 
<a href="/search/cs?searchtype=author&query=Gwadabe%2C+T">Tajuddeen Gwadabe</a>, 
<a href="/search/cs?searchtype=author&query=Rutunda%2C+S">Samuel Rutunda</a>, 
<a href="/search/cs?searchtype=author&query=Belay%2C+T">Tadesse Belay</a>, 
<a href="/search/cs?searchtype=author&query=Messelle%2C+W+B">Wendimu Baye Messelle</a>, 
<a href="/search/cs?searchtype=author&query=Balcha%2C+H+B">Hailu Beshada Balcha</a>, 
<a href="/search/cs?searchtype=author&query=Chala%2C+S+A">Sisay Adugna Chala</a>, 
<a href="/search/cs?searchtype=author&query=Gebremichael%2C+H+T">Hagos Tesfahun Gebremichael</a>, 
<a href="/search/cs?searchtype=author&query=Opoku%2C+B">Bernard Opoku</a>, 
<a href="/search/cs?searchtype=author&query=Arthur%2C+S">Steven Arthur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 3 Figures, 10 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item737">[737]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10798" title="Abstract">arXiv:2302.10798</a> (replaced) [<a href="/pdf/2302.10798" title="Download PDF">pdf</a>, <a href="/format/2302.10798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning a Consensus Sub-Network with Polarization Regularization and  One Pass Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhi%2C+X">Xiaoying Zhi</a>, 
<a href="/search/cs?searchtype=author&query=Babbar%2C+V">Varun Babbar</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+P">Pheobe Sun</a>, 
<a href="/search/cs?searchtype=author&query=Silavong%2C+F">Fran Silavong</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+R">Ruibo Shi</a>, 
<a href="/search/cs?searchtype=author&query=Moran%2C+S">Sean Moran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item738">[738]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11522" title="Abstract">arXiv:2302.11522</a> (replaced) [<a href="/pdf/2302.11522" title="Download PDF">pdf</a>, <a href="/ps/2302.11522" title="Download PostScript">ps</a>, <a href="/format/2302.11522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of Extra Pixel Interpolation with Mask Processing for Medical  Image Segmentation with Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rukundo%2C+O">Olivier Rukundo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 10 figure, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item739">[739]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12990" title="Abstract">arXiv:2302.12990</a> (replaced) [<a href="/pdf/2302.12990" title="Download PDF">pdf</a>, <a href="/ps/2302.12990" title="Download PostScript">ps</a>, <a href="/format/2302.12990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fully Composable and Adequate Verified Compilation with Direct  Refinements between Open Modules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Ling Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuting Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jinhua Wu</a>, 
<a href="/search/cs?searchtype=author&query=Koenig%2C+J">J&#xe9;r&#xe9;mie Koenig</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Zhong Shao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item740">[740]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14201" title="Abstract">arXiv:2302.14201</a> (replaced) [<a href="/pdf/2302.14201" title="Download PDF">pdf</a>, <a href="/format/2302.14201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nautilus: A Framework for Cross-Layer Cartography of Submarine Cables  and IP Links
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramanathan%2C+A">Alagappan Ramanathan</a>, 
<a href="/search/cs?searchtype=author&query=Jyothi%2C+S+A">Sangeetha Abdu Jyothi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item741">[741]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01679" title="Abstract">arXiv:2303.01679</a> (replaced) [<a href="/pdf/2303.01679" title="Download PDF">pdf</a>, <a href="/format/2303.01679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Machine Learning for Deep Learning based Malware Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brown%2C+A">Austin Brown</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+M">Maanak Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Abdelsalam%2C+M">Mahmoud Abdelsalam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item742">[742]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03004" title="Abstract">arXiv:2303.03004</a> (replaced) [<a href="/pdf/2303.03004" title="Download PDF">pdf</a>, <a href="/format/2303.03004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> xCodeEval: A Large Scale Multilingual Multitask Benchmark for Code  Understanding, Generation, Translation and Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+A+M">Mohammad Abdullah Matin Khan</a>, 
<a href="/search/cs?searchtype=author&query=Bari%2C+M+S">M Saiful Bari</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+X+L">Xuan Long Do</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weishi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Parvez%2C+M+R">Md Rizwan Parvez</a>, 
<a href="/search/cs?searchtype=author&query=Joty%2C+S">Shafiq Joty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code &amp; Data available at <a href="https://github.com/ntunlp/xCodeEval">this https URL</a>, <a href="https://huggingface.co/datasets/NTU-NLP-sg/xCodeEval.">this https URL</a> Evaluation framework available at <a href="https://github.com/ntunlp/execeval">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item743">[743]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03480" title="Abstract">arXiv:2303.03480</a> (replaced) [<a href="/pdf/2303.03480" title="Download PDF">pdf</a>, <a href="/format/2303.03480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can an Embodied Agent Find Your &quot;Cat-shaped Mug&quot;? LLM-Guided Exploration  for Zero-Shot Object Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dorbala%2C+V+S">Vishnu Sashank Dorbala</a>, 
<a href="/search/cs?searchtype=author&query=Mullen%2C+J+F">James F. Mullen Jr.</a>, 
<a href="/search/cs?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item744">[744]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04145" title="Abstract">arXiv:2303.04145</a> (replaced) [<a href="/pdf/2303.04145" title="Download PDF">pdf</a>, <a href="/format/2303.04145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benign Overfitting for Two-layer ReLU Convolutional Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kou%2C+Y">Yiwen Kou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zixiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuanzhou Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Quanquan Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages, 3 figures, 2 tables. In ICML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item745">[745]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04772" title="Abstract">arXiv:2303.04772</a> (replaced) [<a href="/pdf/2303.04772" title="Download PDF">pdf</a>, <a href="/format/2303.04772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilevel Diffusion: Infinite Dimensional Score-Based Diffusion Models  for Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hagemann%2C+P">Paul Hagemann</a>, 
<a href="/search/cs?searchtype=author&query=Mildenberger%2C+S">Sophie Mildenberger</a>, 
<a href="/search/cs?searchtype=author&query=Ruthotto%2C+L">Lars Ruthotto</a>, 
<a href="/search/cs?searchtype=author&query=Steidl%2C+G">Gabriele Steidl</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+N+T">Nicole Tianjiao Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Probability (math.PR); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item746">[746]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05445" title="Abstract">arXiv:2303.05445</a> (replaced) [<a href="/pdf/2303.05445" title="Download PDF">pdf</a>, <a href="/format/2303.05445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flooding with Absorption: An Efficient Protocol for Heterogeneous  Bandits over Complex Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Junghyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+L">Laura Schmid</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+S">Se-Young Yun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 6 figures. Accepted to the 27th International Conference on Principles of Distributed Systems (OPODIS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Networking and Internet Architecture (cs.NI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item747">[747]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07104" title="Abstract">arXiv:2303.07104</a> (replaced) [<a href="/pdf/2303.07104" title="Download PDF">pdf</a>, <a href="/format/2303.07104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> xASTNN: Improved Code Representations for Industrial Practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Min Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xibin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongyu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ESEC/FSE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item748">[748]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08797" title="Abstract">arXiv:2303.08797</a> (replaced) [<a href="/pdf/2303.08797" title="Download PDF">pdf</a>, <a href="/format/2303.08797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Interpolants: A Unifying Framework for Flows and Diffusions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Albergo%2C+M+S">Michael S. Albergo</a>, 
<a href="/search/cs?searchtype=author&query=Boffi%2C+N+M">Nicholas M. Boffi</a>, 
<a href="/search/cs?searchtype=author&query=Vanden-Eijnden%2C+E">Eric Vanden-Eijnden</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item749">[749]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09270" title="Abstract">arXiv:2303.09270</a> (replaced) [<a href="/pdf/2303.09270" title="Download PDF">pdf</a>, <a href="/format/2303.09270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpectralCLIP: Preventing Artifacts in Text-Guided Style Transfer from a  Spectral Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zipeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+S">Songlong Xing</a>, 
<a href="/search/cs?searchtype=author&query=Sangineto%2C+E">Enver Sangineto</a>, 
<a href="/search/cs?searchtype=author&query=Sebe%2C+N">Nicu Sebe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item750">[750]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09935" title="Abstract">arXiv:2303.09935</a> (replaced) [<a href="/pdf/2303.09935" title="Download PDF">pdf</a>, <a href="/format/2303.09935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alternate Loss Functions for Classification and Robust Regression Can  Improve the Accuracy of Artificial Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Noel%2C+M+M">Mathew Mithra Noel</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+A">Arindam Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=D%2C+G+B+A">Geraldine Bessie Amali D</a>, 
<a href="/search/cs?searchtype=author&query=Muthiah-Nakarajan%2C+V">Venkataraman Muthiah-Nakarajan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item751">[751]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10500" title="Abstract">arXiv:2303.10500</a> (replaced) [<a href="/pdf/2303.10500" title="Download PDF">pdf</a>, <a href="/format/2303.10500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blockchain-Based, Confidentiality-Preserving Orchestration of  Collaborative Workflows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Toldi%2C+B+%C3%81">Bal&#xe1;zs &#xc1;d&#xe1;m Toldi</a>, 
<a href="/search/cs?searchtype=author&query=Kocsis%2C+I">Imre Kocsis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item752">[752]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12059" title="Abstract">arXiv:2303.12059</a> (replaced) [<a href="/pdf/2303.12059" title="Download PDF">pdf</a>, <a href="/format/2303.12059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion Matters: Neural Motion Transfer for Better Camera Physiological  Measurement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paruchuri%2C+A">Akshay Paruchuri</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yulu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+S">Shwetak Patel</a>, 
<a href="/search/cs?searchtype=author&query=McDuff%2C+D">Daniel McDuff</a>, 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+S">Soumyadip Sengupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV 2024, 17 pages, 6 figures, 15 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item753">[753]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12513" title="Abstract">arXiv:2303.12513</a> (replaced) [<a href="/pdf/2303.12513" title="Download PDF">pdf</a>, <a href="/format/2303.12513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is BERT Blind? Exploring the Effect of Vision-and-Language Pretraining  on Visual Language Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alper%2C+M">Morris Alper</a>, 
<a href="/search/cs?searchtype=author&query=Fiman%2C+M">Michael Fiman</a>, 
<a href="/search/cs?searchtype=author&query=Averbuch-Elor%2C+H">Hadar Averbuch-Elor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2023. Project webpage: <a href="https://isbertblind.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item754">[754]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13129" title="Abstract">arXiv:2303.13129</a> (replaced) [<a href="/pdf/2303.13129" title="Download PDF">pdf</a>, <a href="/format/2303.13129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task-Oriented Human-Object Interactions Generation with Implicit Neural  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Quanzhou Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingbo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Loy%2C+C+C">Chen Change Loy</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bo Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item755">[755]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13460" title="Abstract">arXiv:2303.13460</a> (replaced) [<a href="/pdf/2303.13460" title="Download PDF">pdf</a>, <a href="/ps/2303.13460" title="Download PostScript">ps</a>, <a href="/format/2303.13460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complexity reduction of large-scale stochastic systems using linear  quadratic Gaussian balancing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Damm%2C+T">Tobias Damm</a>, 
<a href="/search/math?searchtype=author&query=Redmann%2C+M">Martin Redmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item756">[756]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13764" title="Abstract">arXiv:2303.13764</a> (replaced) [<a href="/pdf/2303.13764" title="Download PDF">pdf</a>, <a href="/format/2303.13764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GQE-Net: A Graph-based Quality Enhancement Network for Point Cloud Color  Attribute
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xing%2C+J">Jinrui Xing</a>, 
<a href="/search/eess?searchtype=author&query=Yuan%2C+H">Hui Yuan</a>, 
<a href="/search/eess?searchtype=author&query=Hamzaoui%2C+R">Raouf Hamzaoui</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/eess?searchtype=author&query=Hou%2C+J">Junhui Hou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 11 figures, submitted to IEEE TIP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item757">[757]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.14193" title="Abstract">arXiv:2303.14193</a> (replaced) [<a href="/pdf/2303.14193" title="Download PDF">pdf</a>, <a href="/format/2303.14193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quadratic Graph Attention Network (Q-GAT) for Robust Construction of  Gene Regulatory Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+H">Hui Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=An%2C+X">Xuexin An</a>, 
<a href="/search/q-bio?searchtype=author&query=He%2C+Q">Qiang He</a>, 
<a href="/search/q-bio?searchtype=author&query=Yao%2C+Y">Yudong Yao</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+Y">Yudong Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Fan%2C+F">Feng-Lei Fan</a>, 
<a href="/search/q-bio?searchtype=author&query=Teng%2C+Y">Yueyang Teng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Molecular Networks (q-bio.MN)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item758">[758]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.14269" title="Abstract">arXiv:2303.14269</a> (replaced) [<a href="/pdf/2303.14269" title="Download PDF">pdf</a>, <a href="/ps/2303.14269" title="Download PostScript">ps</a>, <a href="/format/2303.14269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Exact Sample Complexity Gain from Invariances for Kernel Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tahmasebi%2C+B">Behrooz Tahmasebi</a>, 
<a href="/search/cs?searchtype=author&query=Jegelka%2C+S">Stefanie Jegelka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item759">[759]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.14620" title="Abstract">arXiv:2303.14620</a> (replaced) [<a href="/pdf/2303.14620" title="Download PDF">pdf</a>, <a href="/format/2303.14620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PBScaler: A Bottleneck-aware Autoscaling Framework for  Microservice-based Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shuaiyu Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bing Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zekun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Duantengchuan Li</a>, 
<a href="/search/cs?searchtype=author&query=H%2C+P+C+K">Patrick C. K. H</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item760">[760]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15987" title="Abstract">arXiv:2303.15987</a> (replaced) [<a href="/pdf/2303.15987" title="Download PDF">pdf</a>, <a href="/ps/2303.15987" title="Download PostScript">ps</a>, <a href="/format/2303.15987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sentiment Analysis Dataset in Moroccan Dialect: Bridging the Gap Between  Arabic and Latin Scripted dialect
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jbel%2C+M">Mouad Jbel</a>, 
<a href="/search/cs?searchtype=author&query=Hafidi%2C+I">Imad Hafidi</a>, 
<a href="/search/cs?searchtype=author&query=Metrane%2C+A">Abdulmutallib Metrane</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 8 tables, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item761">[761]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16604" title="Abstract">arXiv:2303.16604</a> (replaced) [<a href="/pdf/2303.16604" title="Download PDF">pdf</a>, <a href="/format/2303.16604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bi-directional Training for Composed Image Retrieval via Text Prompt  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zheyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weixuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yicong Hong</a>, 
<a href="/search/cs?searchtype=author&query=Teney%2C+D">Damien Teney</a>, 
<a href="/search/cs?searchtype=author&query=Gould%2C+S">Stephen Gould</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024 accepted. 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item762">[762]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01246" title="Abstract">arXiv:2304.01246</a> (replaced) [<a href="/pdf/2304.01246" title="Download PDF">pdf</a>, <a href="/format/2304.01246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safety Analysis in the Era of Large Language Models: A Case Study of  STPA using ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yi Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xingyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Khastgir%2C+S">Siddartha Khastgir</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaowei Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item763">[763]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01754" title="Abstract">arXiv:2304.01754</a> (replaced) [<a href="/pdf/2304.01754" title="Download PDF">pdf</a>, <a href="/ps/2304.01754" title="Download PostScript">ps</a>, <a href="/format/2304.01754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Infinite-dimensional integration and $L^2$-approximation on Hermite  spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gnewuch%2C+M">Michael Gnewuch</a>, 
<a href="/search/math?searchtype=author&query=Hinrichs%2C+A">Aicke Hinrichs</a>, 
<a href="/search/math?searchtype=author&query=Ritter%2C+K">Klaus Ritter</a>, 
<a href="/search/math?searchtype=author&query=R%C3%BC%C3%9Fmann%2C+R">Robin R&#xfc;&#xdf;mann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item764">[764]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01790" title="Abstract">arXiv:2304.01790</a> (replaced) [<a href="/pdf/2304.01790" title="Download PDF">pdf</a>, <a href="/format/2304.01790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VC Set Systems in Minor-free (Di)Graphs and Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+H">Hung Le</a>, 
<a href="/search/cs?searchtype=author&query=Wulff-Nilsen%2C+C">Christian Wulff-Nilsen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fix typos and several minor issues; abstract shorten due to Arxiv limits. Extended abstract appeared in SODA24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item765">[765]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03164" title="Abstract">arXiv:2304.03164</a> (replaced) [<a href="/pdf/2304.03164" title="Download PDF">pdf</a>, <a href="/format/2304.03164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthesizing Anyone, Anywhere, in Any Pose
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hukkel%C3%A5s%2C+H">H&#xe5;kon Hukkel&#xe5;s</a>, 
<a href="/search/cs?searchtype=author&query=Lindseth%2C+F">Frank Lindseth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item766">[766]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06286" title="Abstract">arXiv:2304.06286</a> (replaced) [<a href="/pdf/2304.06286" title="Download PDF">pdf</a>, <a href="/format/2304.06286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Cardiovascular Record Retrieval by Multimodal Learning between  Electrocardiogram and Clinical Report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Qiu%2C+J">Jielin Qiu</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+J">Jiacheng Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+S">Shiqi Liu</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+W">William Han</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jingqi Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Duan%2C+C">Chaojing Duan</a>, 
<a href="/search/eess?searchtype=author&query=Rosenberg%2C+M">Michael Rosenberg</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+E">Emerson Liu</a>, 
<a href="/search/eess?searchtype=author&query=Weber%2C+D">Douglas Weber</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+D">Ding Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the ML4H 2023 Proceedings track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item767">[767]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06813" title="Abstract">arXiv:2304.06813</a> (replaced) [<a href="/pdf/2304.06813" title="Download PDF">pdf</a>, <a href="/format/2304.06813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified Out-Of-Distribution Detection: A Model-Specific Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Averly%2C+R">Reza Averly</a>, 
<a href="/search/cs?searchtype=author&query=Chao%2C+W">Wei-Lun Chao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in International Conference on Computer Vision (ICCV 2023): <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Averly_Unified_Out-Of-Distribution_Detection_A_Model-Specific_Perspective_ICCV_2023_paper.pdf.">this https URL</a> Extra references added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item768">[768]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08897" title="Abstract">arXiv:2304.08897</a> (replaced) [<a href="/pdf/2304.08897" title="Download PDF">pdf</a>, <a href="/format/2304.08897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An adaptive safety layer with hard constraints for safe reinforcement  learning in multi-energy management systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ceusters%2C+G">Glenn Ceusters</a>, 
<a href="/search/eess?searchtype=author&query=Putratama%2C+M+A">Muhammad Andy Putratama</a>, 
<a href="/search/eess?searchtype=author&query=Franke%2C+R">R&#xfc;diger Franke</a>, 
<a href="/search/eess?searchtype=author&query=Now%C3%A9%2C+A">Ann Now&#xe9;</a>, 
<a href="/search/eess?searchtype=author&query=Messagie%2C+M">Maarten Messagie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> post-print
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item769">[769]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09823" title="Abstract">arXiv:2304.09823</a> (replaced) [<a href="/pdf/2304.09823" title="Download PDF">pdf</a>, <a href="/format/2304.09823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Future of ChatGPT-enabled Labor Market: A Preliminary Study in China
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shiyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yaqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+M">Meng Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hengshu Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item770">[770]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09853" title="Abstract">arXiv:2304.09853</a> (replaced) [<a href="/pdf/2304.09853" title="Download PDF">pdf</a>, <a href="/format/2304.09853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging RL Theory and Practice with the Effective Horizon
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laidlaw%2C+C">Cassidy Laidlaw</a>, 
<a href="/search/cs?searchtype=author&query=Russell%2C+S">Stuart Russell</a>, 
<a href="/search/cs?searchtype=author&query=Dragan%2C+A">Anca Dragan</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item771">[771]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11300" title="Abstract">arXiv:2304.11300</a> (replaced) [<a href="/pdf/2304.11300" title="Download PDF">pdf</a>, <a href="/format/2304.11300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAWSEO: Adversarial Wiki Search Poisoning for Illicit Online Promotion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zilong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhengyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+X">Xiaojing Liao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">XiaoFeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaozhong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item772">[772]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12958" title="Abstract">arXiv:2304.12958</a> (replaced) [<a href="/pdf/2304.12958" title="Download PDF">pdf</a>, <a href="/format/2304.12958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Closer Look at Reward Decomposition for High-Level Robotic  Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wenhao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xufeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Magg%2C+S">Sven Magg</a>, 
<a href="/search/cs?searchtype=author&query=Gromniak%2C+M">Martin Gromniak</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengdi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wermter%2C+S">Stefan Wermter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://lukaswill.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item773">[773]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13219" title="Abstract">arXiv:2304.13219</a> (replaced) [<a href="/pdf/2304.13219" title="Download PDF">pdf</a>, <a href="/format/2304.13219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZRG: A Dataset for Multimodal 3D Residential Rooftop Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Corley%2C+I">Isaac Corley</a>, 
<a href="/search/cs?searchtype=author&query=Lwowski%2C+J">Jonathan Lwowski</a>, 
<a href="/search/cs?searchtype=author&query=Najafirad%2C+P">Peyman Najafirad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, Preprint accepted to WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item774">[774]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00702" title="Abstract">arXiv:2305.00702</a> (replaced) [<a href="/pdf/2305.00702" title="Download PDF">pdf</a>, <a href="/ps/2305.00702" title="Download PostScript">ps</a>, <a href="/format/2305.00702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Arithmetic of D-Algebraic Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tabuguia%2C+B+T">Bertrand Teguia Tabuguia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages. 46 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Commutative Algebra (math.AC)

</div>
</div>
</dd>
<dt><a name="item775">[775]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02305" title="Abstract">arXiv:2305.02305</a> (replaced) [<a href="/pdf/2305.02305" title="Download PDF">pdf</a>, <a href="/format/2305.02305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calibrated Explanations: with Uncertainty Information and  Counterfactuals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lofstrom%2C+H">Helena Lofstrom</a>, 
<a href="/search/cs?searchtype=author&query=Lofstrom%2C+T">Tuwe Lofstrom</a>, 
<a href="/search/cs?searchtype=author&query=Johansson%2C+U">Ulf Johansson</a>, 
<a href="/search/cs?searchtype=author&query=Sonstrod%2C+C">Cecilia Sonstrod</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 6 figures, 3 tables, submitted to journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item776">[776]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02386" title="Abstract">arXiv:2305.02386</a> (replaced) [<a href="/pdf/2305.02386" title="Download PDF">pdf</a>, <a href="/format/2305.02386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximating CKY with Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khalighinejad%2C+G">Ghazal Khalighinejad</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+O">Ollie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wiseman%2C+S">Sam Wiseman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item777">[777]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02541" title="Abstract">arXiv:2305.02541</a> (replaced) [<a href="/pdf/2305.02541" title="Download PDF">pdf</a>, <a href="/format/2305.02541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Catch Missing Details: Image Reconstruction with Frequency Augmented  Variational Autoencoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xinmiao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yikang Li</a>, 
<a href="/search/cs?searchtype=author&query=Hsiao%2C+J">Jenhao Hsiao</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+C">Chiuman Ho</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Y">Yu Kong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2023, code available at <a href="https://github.com/oppo-us-research/FA-VAE">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item778">[778]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02646" title="Abstract">arXiv:2305.02646</a> (replaced) [<a href="/pdf/2305.02646" title="Download PDF">pdf</a>, <a href="/format/2305.02646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and Detection of Unitary Constellations in Non-Coherent SIMO  Systems for Short Packet Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duong%2C+S+T">Son T. Duong</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H+H">Ha H. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Bedeer%2C+E">Ebrahim Bedeer</a>, 
<a href="/search/cs?searchtype=author&query=Barton%2C+R">Robert Barton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 11 figures, in preparation to submit to IEEE Transactions on Wireless Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item779">[779]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02820" title="Abstract">arXiv:2305.02820</a> (replaced) [<a href="/pdf/2305.02820" title="Download PDF">pdf</a>, <a href="/format/2305.02820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Space Grounded Weighted Decoding for Multi-Attribute  Controllable Dialogue Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiling Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Mengyue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K+Q">Kenny Q. Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item780">[780]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03017" title="Abstract">arXiv:2305.03017</a> (replaced) [<a href="/pdf/2305.03017" title="Download PDF">pdf</a>, <a href="/format/2305.03017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Code Example Recommendations on Informal Documentation Using  BERT and Query-Aware LSH: A Comparative Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahmani%2C+S">Sajjad Rahmani</a>, 
<a href="/search/cs?searchtype=author&query=Naghshzan%2C+A">AmirHossein Naghshzan</a>, 
<a href="/search/cs?searchtype=author&query=Guerrouj%2C+L">Latifa Guerrouj</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item781">[781]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03942" title="Abstract">arXiv:2305.03942</a> (replaced) [<a href="/pdf/2305.03942" title="Download PDF">pdf</a>, <a href="/format/2305.03942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HACMan: Learning Hybrid Actor-Critic Maps for 6D Non-Prehensile  Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wenxuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bowen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Paxton%2C+C">Chris Paxton</a>, 
<a href="/search/cs?searchtype=author&query=Held%2C+D">David Held</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7th Conference on Robot Learning (CoRL 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item782">[782]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05065" title="Abstract">arXiv:2305.05065</a> (replaced) [<a href="/pdf/2305.05065" title="Download PDF">pdf</a>, <a href="/format/2305.05065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recommender Systems with Generative Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajput%2C+S">Shashank Rajput</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+N">Nikhil Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Anima Singh</a>, 
<a href="/search/cs?searchtype=author&query=Keshavan%2C+R+H">Raghunandan H. Keshavan</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+T">Trung Vu</a>, 
<a href="/search/cs?searchtype=author&query=Heldt%2C+L">Lukasz Heldt</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Lichan Hong</a>, 
<a href="/search/cs?searchtype=author&query=Tay%2C+Y">Yi Tay</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+V+Q">Vinh Q. Tran</a>, 
<a href="/search/cs?searchtype=author&query=Samost%2C+J">Jonah Samost</a>, 
<a href="/search/cs?searchtype=author&query=Kula%2C+M">Maciej Kula</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+E+H">Ed H. Chi</a>, 
<a href="/search/cs?searchtype=author&query=Sathiamoorthy%2C+M">Maheswaran Sathiamoorthy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in The 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item783">[783]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05803" title="Abstract">arXiv:2305.05803</a> (replaced) [<a href="/pdf/2305.05803" title="Download PDF">pdf</a>, <a href="/format/2305.05803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment Anything Model (SAM) Enhanced Pseudo Labels for Weakly  Supervised Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianle Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+Z">Zheda Mai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruiwen Li</a>, 
<a href="/search/cs?searchtype=author&query=Chao%2C+W">Wei-lun Chao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tianle Chen and Zheda Mai contributed equally to this work. Accepted to NeurIPS2023 ICBINB Workshop Our code is available at \url{<a href="https://github.com/cskyl/SAM_WSSS">this https URL</a>}
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item784">[784]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06349" title="Abstract">arXiv:2305.06349</a> (replaced) [<a href="/pdf/2305.06349" title="Download PDF">pdf</a>, <a href="/format/2305.06349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RECKONING: Reasoning through Dynamic Knowledge Encoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zeming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Weiss%2C+G">Gail Weiss</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+E">Eric Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Celikyilmaz%2C+A">Asli Celikyilmaz</a>, 
<a href="/search/cs?searchtype=author&query=Bosselut%2C+A">Antoine Bosselut</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 8 figures, 10 tables, Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item785">[785]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07015" title="Abstract">arXiv:2305.07015</a> (replaced) [<a href="/pdf/2305.07015" title="Download PDF">pdf</a>, <a href="/format/2305.07015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Diffusion Prior for Real-World Image Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Z">Zongsheng Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shangchen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+K+C+K">Kelvin C.K. Chan</a>, 
<a href="/search/cs?searchtype=author&query=Loy%2C+C+C">Chen Change Loy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://iceclear.github.io/projects/stablesr/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item786">[786]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07812" title="Abstract">arXiv:2305.07812</a> (replaced) [<a href="/pdf/2305.07812" title="Download PDF">pdf</a>, <a href="/format/2305.07812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightweight Delivery Detection on Doorbell Cameras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khorramshahi%2C+P">Pirazh Khorramshahi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhe Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianchen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Deluccia%2C+L">Luke Deluccia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongcheng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 2024 WACV conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item787">[787]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08322" title="Abstract">arXiv:2305.08322</a> (replaced) [<a href="/pdf/2305.08322" title="Download PDF">pdf</a>, <a href="/format/2305.08322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for  Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuzhen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yuzhuo Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhihao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junlei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinghan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+T">Tangjun Su</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junteng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+C">Chuancheng Lv</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yikai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+J">Jiayi Lei</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yao Fu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Maosong Sun</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junxian He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. Website: <a href="https://cevalbenchmark.com">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item788">[788]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08675" title="Abstract">arXiv:2305.08675</a> (replaced) [<a href="/pdf/2305.08675" title="Download PDF">pdf</a>, <a href="/ps/2305.08675" title="Download PostScript">ps</a>, <a href="/format/2305.08675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved baselines for vision-language pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fini%2C+E">Enrico Fini</a>, 
<a href="/search/cs?searchtype=author&query=Astolfi%2C+P">Pietro Astolfi</a>, 
<a href="/search/cs?searchtype=author&query=Romero-Soriano%2C+A">Adriana Romero-Soriano</a>, 
<a href="/search/cs?searchtype=author&query=Verbeek%2C+J">Jakob Verbeek</a>, 
<a href="/search/cs?searchtype=author&query=Drozdzal%2C+M">Michal Drozdzal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TMLR, featured certification; changelog at <a href="https://openreview.net/forum?id=a7nvXxNmdV">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transactions on Machine Learning Research, 10/2023, issn 2835-8856
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item789">[789]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08946" title="Abstract">arXiv:2305.08946</a> (replaced) [<a href="/pdf/2305.08946" title="Download PDF">pdf</a>, <a href="/format/2305.08946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Matching by Bare Homography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bellavia%2C+F">Fabio Bellavia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> major revision update - fixed minor typos and higher pdf compression
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item790">[790]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09538" title="Abstract">arXiv:2305.09538</a> (replaced) [<a href="/pdf/2305.09538" title="Download PDF">pdf</a>, <a href="/format/2305.09538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A LOCAL View of the Polynomial Hierarchy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reiter%2C+F">Fabian Reiter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 70 pages, 15 figures (4 repeated); v3: New section "Informal overview" and minor presentation improvements
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computational Complexity (cs.CC); Formal Languages and Automata Theory (cs.FL); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item791">[791]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09545" title="Abstract">arXiv:2305.09545</a> (replaced) [<a href="/pdf/2305.09545" title="Download PDF">pdf</a>, <a href="/ps/2305.09545" title="Download PostScript">ps</a>, <a href="/format/2305.09545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure compilation of rich smart contracts on poor UTXO blockchains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bartoletti%2C+M">Massimo Bartoletti</a>, 
<a href="/search/cs?searchtype=author&query=Marchesin%2C+R">Riccardo Marchesin</a>, 
<a href="/search/cs?searchtype=author&query=Zunino%2C+R">Roberto Zunino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item792">[792]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10927" title="Abstract">arXiv:2305.10927</a> (replaced) [<a href="/pdf/2305.10927" title="Download PDF">pdf</a>, <a href="/format/2305.10927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Document-Grounded Dialogue Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yingxiu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bowen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haiyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bowen Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N+L">Nevin L. Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 main
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item793">[793]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11049" title="Abstract">arXiv:2305.11049</a> (replaced) [<a href="/pdf/2305.11049" title="Download PDF">pdf</a>, <a href="/format/2305.11049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NODE-ImgNet: a PDE-informed effective and robust model for image  denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xie%2C+X">Xinheng Xie</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Y">Yue Wu</a>, 
<a href="/search/eess?searchtype=author&query=Ni%2C+H">Hao Ni</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+C">Cuiyu He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item794">[794]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11650" title="Abstract">arXiv:2305.11650</a> (replaced) [<a href="/pdf/2305.11650" title="Download PDF">pdf</a>, <a href="/format/2305.11650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Moment Matching Denoising Gibbs Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhang%2C+M">Mingtian Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Hawkins-Hooker%2C+A">Alex Hawkins-Hooker</a>, 
<a href="/search/stat?searchtype=author&query=Paige%2C+B">Brooks Paige</a>, 
<a href="/search/stat?searchtype=author&query=Barber%2C+D">David Barber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item795">[795]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12322" title="Abstract">arXiv:2305.12322</a> (replaced) [<a href="/pdf/2305.12322" title="Download PDF">pdf</a>, <a href="/format/2305.12322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Large Graph Property Prediction via Graph Segment Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+K">Kaidi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Phothilimthana%2C+P+M">Phitchaya Mangpo Phothilimthana</a>, 
<a href="/search/cs?searchtype=author&query=Abu-El-Haija%2C+S">Sami Abu-El-Haija</a>, 
<a href="/search/cs?searchtype=author&query=Zelle%2C+D">Dustin Zelle</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yanqi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Mendis%2C+C">Charith Mendis</a>, 
<a href="/search/cs?searchtype=author&query=Leskovec%2C+J">Jure Leskovec</a>, 
<a href="/search/cs?searchtype=author&query=Perozzi%2C+B">Bryan Perozzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item796">[796]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12473" title="Abstract">arXiv:2305.12473</a> (replaced) [<a href="/pdf/2305.12473" title="Download PDF">pdf</a>, <a href="/format/2305.12473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continually Improving Extractive QA via Human Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+G">Ge Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hung-Ting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Artzi%2C+Y">Yoav Artzi</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+E">Eunsol Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item797">[797]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12529" title="Abstract">arXiv:2305.12529</a> (replaced) [<a href="/pdf/2305.12529" title="Download PDF">pdf</a>, <a href="/format/2305.12529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreamWaltz: Make a Scene with Complex 3D Animatable Avatars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yukun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+A">Ailing Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">He Cao</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xianbiao Qi</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yukai Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+Z">Zheng-Jun Zha</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in NeurIPS 2023; Project page: <a href="https://dreamwaltz3d.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item798">[798]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13141" title="Abstract">arXiv:2305.13141</a> (replaced) [<a href="/pdf/2305.13141" title="Download PDF">pdf</a>, <a href="/ps/2305.13141" title="Download PostScript">ps</a>, <a href="/format/2305.13141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tight conditions for when the NTK approximation is valid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boix-Adsera%2C+E">Enric Boix-Adsera</a>, 
<a href="/search/cs?searchtype=author&query=Littwin%2C+E">Etai Littwin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to TMLR. Added proof flowchart
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item799">[799]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13241" title="Abstract">arXiv:2305.13241</a> (replaced) [<a href="/pdf/2305.13241" title="Download PDF">pdf</a>, <a href="/format/2305.13241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Whose baseline compiler is it anyway?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Titzer%2C+B+L">Ben L. Titzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item800">[800]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13588" title="Abstract">arXiv:2305.13588</a> (replaced) [<a href="/pdf/2305.13588" title="Download PDF">pdf</a>, <a href="/format/2305.13588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning with Kernels through RKHM and the Perron-Frobenius  Operator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hashimoto%2C+Y">Yuka Hashimoto</a>, 
<a href="/search/stat?searchtype=author&query=Ikeda%2C+M">Masahiro Ikeda</a>, 
<a href="/search/stat?searchtype=author&query=Kadri%2C+H">Hachem Kadri</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item801">[801]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13903" title="Abstract">arXiv:2305.13903</a> (replaced) [<a href="/pdf/2305.13903" title="Download PDF">pdf</a>, <a href="/format/2305.13903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Let&#x27;s Think Frame by Frame with VIP: A Video Infilling and Prediction  Dataset for Evaluating Video Chain-of-Thought
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Himakunthala%2C+V">Vaishnavi Himakunthala</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+A">Andy Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Rose%2C+D">Daniel Rose</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ryan He</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+A">Alex Mei</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yujie Lu</a>, 
<a href="/search/cs?searchtype=author&query=Sonar%2C+C">Chinmay Sonar</a>, 
<a href="/search/cs?searchtype=author&query=Saxon%2C+M">Michael Saxon</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W+Y">William Yang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item802">[802]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13946" title="Abstract">arXiv:2305.13946</a> (replaced) [<a href="/pdf/2305.13946" title="Download PDF">pdf</a>, <a href="/ps/2305.13946" title="Download PostScript">ps</a>, <a href="/format/2305.13946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Dependent Bounds for Online Portfolio Selection Without  Lipschitzness and Smoothness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsai%2C+C">Chung-En Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Ying-Ting Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yen-Huan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, typos fixed, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item803">[803]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14202" title="Abstract">arXiv:2305.14202</a> (replaced) [<a href="/pdf/2305.14202" title="Download PDF">pdf</a>, <a href="/format/2305.14202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-tuned LLMs Know More, Hallucinate Less with Few-Shot  Sequence-to-Sequence Semantic Parsing over Wikidata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Silei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shicheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Culhane%2C+T">Theo Culhane</a>, 
<a href="/search/cs?searchtype=author&query=Pertseva%2C+E">Elizaveta Pertseva</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Meng-Hsi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Semnani%2C+S+J">Sina J. Semnani</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+M+S">Monica S. Lam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Main
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item804">[804]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14263" title="Abstract">arXiv:2305.14263</a> (replaced) [<a href="/pdf/2305.14263" title="Download PDF">pdf</a>, <a href="/format/2305.14263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LIMIT: Language Identification, Misidentification, and Translation using  Hierarchical Models in 350+ Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+M">Milind Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+M+M+I">Md Mahfuz Ibn Alam</a>, 
<a href="/search/cs?searchtype=author&query=Anastasopoulos%2C+A">Antonios Anastasopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at EMNLP 2023. 24 pages, 2 figures, 12 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item805">[805]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14323" title="Abstract">arXiv:2305.14323</a> (replaced) [<a href="/pdf/2305.14323" title="Download PDF">pdf</a>, <a href="/format/2305.14323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhipeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Beichen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Z">Zheng Gong</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W+X">Wayne Xin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, working in progress, Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item806">[806]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14481" title="Abstract">arXiv:2305.14481</a> (replaced) [<a href="/pdf/2305.14481" title="Download PDF">pdf</a>, <a href="/format/2305.14481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FOCUS: Effective Embedding Initialization for Monolingual Specialization  of Multilingual Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dobler%2C+K">Konstantin Dobler</a>, 
<a href="/search/cs?searchtype=author&query=de+Melo%2C+G">Gerard de Melo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 Main Conference (Long Paper). Code: <a href="https://github.com/konstantinjdobler/focus">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item807">[807]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14599" title="Abstract">arXiv:2305.14599</a> (replaced) [<a href="/pdf/2305.14599" title="Download PDF">pdf</a>, <a href="/format/2305.14599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Continuous and Discrete Spaces: Interpretable Sentence  Representation Learning via Compositional Operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J+Y">James Y. Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Wenlin Yao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kaiqiang Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Muhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item808">[808]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14788" title="Abstract">arXiv:2305.14788</a> (replaced) [<a href="/pdf/2305.14788" title="Download PDF">pdf</a>, <a href="/format/2305.14788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapting Language Models to Compress Contexts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chevalier%2C+A">Alexis Chevalier</a>, 
<a href="/search/cs?searchtype=author&query=Wettig%2C+A">Alexander Wettig</a>, 
<a href="/search/cs?searchtype=author&query=Ajith%2C+A">Anirudh Ajith</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Danqi Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023; added results for Llama-2-7B model
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item809">[809]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14871" title="Abstract">arXiv:2305.14871</a> (replaced) [<a href="/pdf/2305.14871" title="Download PDF">pdf</a>, <a href="/format/2305.14871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClusterLLM: Large Language Models as a Guide for Text Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+J">Jingbo Shang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP2023(main)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item810">[810]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14919" title="Abstract">arXiv:2305.14919</a> (replaced) [<a href="/pdf/2305.14919" title="Download PDF">pdf</a>, <a href="/format/2305.14919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frugal Prompting for Dialog Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santra%2C+B">Bishal Santra</a>, 
<a href="/search/cs?searchtype=author&query=Basak%2C+S">Sakya Basak</a>, 
<a href="/search/cs?searchtype=author&query=De%2C+A">Abhinandan De</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+M">Manish Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+P">Pawan Goyal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint, To appear in EMNLP 2023 (Findings); First two authors have equal contribution
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item811">[811]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15092" title="Abstract">arXiv:2305.15092</a> (replaced) [<a href="/pdf/2305.15092" title="Download PDF">pdf</a>, <a href="/format/2305.15092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedZero: Leveraging Renewable Excess Energy in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wiesner%2C+P">Philipp Wiesner</a>, 
<a href="/search/cs?searchtype=author&query=Khalili%2C+R">Ramin Khalili</a>, 
<a href="/search/cs?searchtype=author&query=Grinwald%2C+D">Dennis Grinwald</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+P">Pratik Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Thamsen%2C+L">Lauritz Thamsen</a>, 
<a href="/search/cs?searchtype=author&query=Kao%2C+O">Odej Kao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at ACM e-Energy '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item812">[812]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15093" title="Abstract">arXiv:2305.15093</a> (replaced) [<a href="/pdf/2305.15093" title="Download PDF">pdf</a>, <a href="/format/2305.15093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> C-STS: Conditional Semantic Textual Similarity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+A">Ameet Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Jimenez%2C+C+E">Carlos E. Jimenez</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Howard Chen</a>, 
<a href="/search/cs?searchtype=author&query=Murahari%2C+V">Vishvak Murahari</a>, 
<a href="/search/cs?searchtype=author&query=Graf%2C+V">Victoria Graf</a>, 
<a href="/search/cs?searchtype=author&query=Rajpurohit%2C+T">Tanmay Rajpurohit</a>, 
<a href="/search/cs?searchtype=author&query=Kalyan%2C+A">Ashwin Kalyan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Danqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Narasimhan%2C+K">Karthik Narasimhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item813">[813]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15269" title="Abstract">arXiv:2305.15269</a> (replaced) [<a href="/pdf/2305.15269" title="Download PDF">pdf</a>, <a href="/format/2305.15269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing the General Deductive Reasoning Capacity of Large Language  Models Using OOD Examples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saparov%2C+A">Abulhair Saparov</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+R+Y">Richard Yuanzhe Pang</a>, 
<a href="/search/cs?searchtype=author&query=Padmakumar%2C+V">Vishakh Padmakumar</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+N">Nitish Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Kazemi%2C+S+M">Seyed Mehran Kazemi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+N">Najoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">He He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item814">[814]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15408" title="Abstract">arXiv:2305.15408</a> (replaced) [<a href="/pdf/2305.15408" title="Download PDF">pdf</a>, <a href="/format/2305.15408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Revealing the Mystery behind Chain of Thought: A Theoretical  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+G">Guhao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bohang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuntian Gu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Haotian Ye</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+D">Di He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liwei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages; Camera-ready version for NeurIPS 2023 (Oral Presentation)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Complexity (cs.CC); Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item815">[815]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15452" title="Abstract">arXiv:2305.15452</a> (replaced) [<a href="/pdf/2305.15452" title="Download PDF">pdf</a>, <a href="/ps/2305.15452" title="Download PostScript">ps</a>, <a href="/format/2305.15452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Data Analysis in a Balanced Adversarial Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nissim%2C+K">Kobbi Nissim</a>, 
<a href="/search/cs?searchtype=author&query=Stemmer%2C+U">Uri Stemmer</a>, 
<a href="/search/cs?searchtype=author&query=Tsfadia%2C+E">Eliad Tsfadia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023 (Spotlight)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item816">[816]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15771" title="Abstract">arXiv:2305.15771</a> (replaced) [<a href="/pdf/2305.15771" title="Download PDF">pdf</a>, <a href="/format/2305.15771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Planning Abilities of Large Language Models : A Critical  Investigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valmeekam%2C+K">Karthik Valmeekam</a>, 
<a href="/search/cs?searchtype=author&query=Marquez%2C+M">Matthew Marquez</a>, 
<a href="/search/cs?searchtype=author&query=Sreedharan%2C+S">Sarath Sreedharan</a>, 
<a href="/search/cs?searchtype=author&query=Kambhampati%2C+S">Subbarao Kambhampati</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Spotlight
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item817">[817]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16041" title="Abstract">arXiv:2305.16041</a> (replaced) [<a href="/pdf/2305.16041" title="Download PDF">pdf</a>, <a href="/format/2305.16041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An $\varepsilon$-Best-Arm Identification Algorithm for Fixed-Confidence  and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Jourdan%2C+M">Marc Jourdan</a>, 
<a href="/search/stat?searchtype=author&query=Degenne%2C+R">R&#xe9;my Degenne</a>, 
<a href="/search/stat?searchtype=author&query=Kaufmann%2C+E">Emilie Kaufmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 68 pages, 14 figures, 4 tables. To be published in the Thirty-seventh Conference on Neural Information Processing Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item818">[818]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16358" title="Abstract">arXiv:2305.16358</a> (replaced) [<a href="/pdf/2305.16358" title="Download PDF">pdf</a>, <a href="/format/2305.16358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Clustering with Perturbed Spanning Forests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stewart%2C+L">Lawrence Stewart</a> (DI-ENS), 
<a href="/search/cs?searchtype=author&query=Bach%2C+F+S">Francis S Bach</a> (DI-ENS), 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+F+L">Felipe Llinares L&#xf3;pez</a>, 
<a href="/search/cs?searchtype=author&query=Berthet%2C+Q">Quentin Berthet</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 37th Conference on Neural Information Processing Systems, Dec
  2023, New Orleans, United States
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item819">[819]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16914" title="Abstract">arXiv:2305.16914</a> (replaced) [<a href="/pdf/2305.16914" title="Download PDF">pdf</a>, <a href="/format/2305.16914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PlaNeRF: SVD Unsupervised 3D Plane Regularization for NeRF Large-Scale  Scene Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fusang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Louys%2C+A">Arnaud Louys</a>, 
<a href="/search/cs?searchtype=author&query=Piasco%2C+N">Nathan Piasco</a>, 
<a href="/search/cs?searchtype=author&query=Bennehar%2C+M">Moussab Bennehar</a>, 
<a href="/search/cs?searchtype=author&query=Rold%C3%A3o%2C+L">Luis Rold&#xe3;o</a>, 
<a href="/search/cs?searchtype=author&query=Tsishkou%2C+D">Dzmitry Tsishkou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to 3DV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item820">[820]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17076" title="Abstract">arXiv:2305.17076</a> (replaced) [<a href="/pdf/2305.17076" title="Download PDF">pdf</a>, <a href="/format/2305.17076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact Generalization Guarantees for (Regularized) Wasserstein  Distributionally Robust Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azizian%2C+W">Wa&#xef;ss Azizian</a> (DAO), 
<a href="/search/cs?searchtype=author&query=Iutzeler%2C+F">Franck Iutzeler</a> (DAO), 
<a href="/search/cs?searchtype=author&query=Malick%2C+J">J&#xe9;r&#xf4;me Malick</a> (DAO)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 49 pages, 2 figures; to be presented at the 37th Annual Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 37th Annual Conference on Neural Information Processing Systems
  (NeurIPS 2023), Dec 2023, New Orleans, United States
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item821">[821]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17600" title="Abstract">arXiv:2305.17600</a> (replaced) [<a href="/pdf/2305.17600" title="Download PDF">pdf</a>, <a href="/format/2305.17600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NashFormer: Leveraging Local Nash Equilibria for Semantically Diverse  Trajectory Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lidard%2C+J">Justin Lidard</a>, 
<a href="/search/cs?searchtype=author&query=So%2C+O">Oswin So</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanxia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=DeCastro%2C+J">Jonathan DeCastro</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+X">Xiongyi Cui</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Kuo%2C+Y">Yen-Ling Kuo</a>, 
<a href="/search/cs?searchtype=author&query=Leonard%2C+J">John Leonard</a>, 
<a href="/search/cs?searchtype=author&query=Balachandran%2C+A">Avinash Balachandran</a>, 
<a href="/search/cs?searchtype=author&query=Leonard%2C+N">Naomi Leonard</a>, 
<a href="/search/cs?searchtype=author&query=Rosman%2C+G">Guy Rosman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Computer Science and Game Theory (cs.GT); Robotics (cs.RO); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item822">[822]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18097" title="Abstract">arXiv:2305.18097</a> (replaced) [<a href="/pdf/2305.18097" title="Download PDF">pdf</a>, <a href="/ps/2305.18097" title="Download PostScript">ps</a>, <a href="/format/2305.18097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance Analysis of Discrete-Phase-Shifter IRS-aided  Amplify-and-Forward Relay Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+R">Rongen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhongyi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+F">Feng Shu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Mengxing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiangzhou Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item823">[823]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18213" title="Abstract">arXiv:2305.18213</a> (replaced) [<a href="/pdf/2305.18213" title="Download PDF">pdf</a>, <a href="/ps/2305.18213" title="Download PostScript">ps</a>, <a href="/format/2305.18213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Process Probes (GPP) for Uncertainty-Aware Probing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ku%2C+A">Alexander Ku</a>, 
<a href="/search/cs?searchtype=author&query=Baldridge%2C+J">Jason Baldridge</a>, 
<a href="/search/cs?searchtype=author&query=Griffiths%2C+T+L">Thomas L. Griffiths</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Been Kim</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 37th Conference on Neural Information Processing Systems (NeurIPS
  2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item824">[824]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18273" title="Abstract">arXiv:2305.18273</a> (replaced) [<a href="/pdf/2305.18273" title="Download PDF">pdf</a>, <a href="/format/2305.18273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pix2Repair: Implicit Shape Restoration from Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xinchao Song</a>, 
<a href="/search/cs?searchtype=author&query=Lamb%2C+N">Nikolas Lamb</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Sean Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+N+K">Natasha Kholgade Banerjee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item825">[825]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18288" title="Abstract">arXiv:2305.18288</a> (replaced) [<a href="/pdf/2305.18288" title="Download PDF">pdf</a>, <a href="/format/2305.18288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linearizability of flows by embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kvalheim%2C+M+D">Matthew D. Kvalheim</a>, 
<a href="/search/math?searchtype=author&query=Arathoon%2C+P">Philip Arathoon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 1 figure; v4 contains minor updates
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item826">[826]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00975" title="Abstract">arXiv:2306.00975</a> (replaced) [<a href="/pdf/2306.00975" title="Download PDF">pdf</a>, <a href="/format/2306.00975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Vision Reinforcement Learning under Limited Visual Observability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shang%2C+J">Jinghuan Shang</a>, 
<a href="/search/cs?searchtype=author&query=Ryoo%2C+M+S">Michael S. Ryoo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. Project page at <a href="https://elicassion.github.io/sugarl/sugarl.html">this https URL</a> Code at <a href="https://github.com/elicassion/sugarl">this https URL</a> Environment library at <a href="https://github.com/elicassion/active-gym">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item827">[827]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01001" title="Abstract">arXiv:2306.01001</a> (replaced) [<a href="/pdf/2306.01001" title="Download PDF">pdf</a>, <a href="/format/2306.01001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffLoad: Uncertainty Quantification in Load Forecasting with Diffusion  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhixian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Q">Qingsong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaoli Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Liang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item828">[828]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01589" title="Abstract">arXiv:2306.01589</a> (replaced) [<a href="/pdf/2306.01589" title="Download PDF">pdf</a>, <a href="/format/2306.01589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transfer learning for atomistic simulations using GNNs and kernel mean  embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Falk%2C+J">John Falk</a>, 
<a href="/search/cs?searchtype=author&query=Bonati%2C+L">Luigi Bonati</a>, 
<a href="/search/cs?searchtype=author&query=Novelli%2C+P">Pietro Novelli</a>, 
<a href="/search/cs?searchtype=author&query=Parrinello%2C+M">Michele Parrinello</a>, 
<a href="/search/cs?searchtype=author&query=Pontil%2C+M">Massimiliano Pontil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 4 figures, 7 tables, to be published in NeurIPS 2023. Replaced due to updates due to review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Chemical Physics (physics.chem-ph)

</div>
</div>
</dd>
<dt><a name="item829">[829]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01694" title="Abstract">arXiv:2306.01694</a> (replaced) [<a href="/pdf/2306.01694" title="Download PDF">pdf</a>, <a href="/format/2306.01694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Language Models for Mathematics through Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Collins%2C+K+M">Katherine M. Collins</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+A+Q">Albert Q. Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Frieder%2C+S">Simon Frieder</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+L">Lionel Wong</a>, 
<a href="/search/cs?searchtype=author&query=Zilka%2C+M">Miri Zilka</a>, 
<a href="/search/cs?searchtype=author&query=Bhatt%2C+U">Umang Bhatt</a>, 
<a href="/search/cs?searchtype=author&query=Lukasiewicz%2C+T">Thomas Lukasiewicz</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuhuai Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tenenbaum%2C+J+B">Joshua B. Tenenbaum</a>, 
<a href="/search/cs?searchtype=author&query=Hart%2C+W">William Hart</a>, 
<a href="/search/cs?searchtype=author&query=Gowers%2C+T">Timothy Gowers</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenda Li</a>, 
<a href="/search/cs?searchtype=author&query=Weller%2C+A">Adrian Weller</a>, 
<a href="/search/cs?searchtype=author&query=Jamnik%2C+M">Mateja Jamnik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item830">[830]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01951" title="Abstract">arXiv:2306.01951</a> (replaced) [<a href="/pdf/2306.01951" title="Download PDF">pdf</a>, <a href="/format/2306.01951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GAD-NR: Graph Anomaly Detection via Neighborhood Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+A">Amit Roy</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+J">Juan Shu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Carl Yang</a>, 
<a href="/search/cs?searchtype=author&query=Elshocht%2C+O">Olivier Elshocht</a>, 
<a href="/search/cs?searchtype=author&query=Smeets%2C+J">Jeroen Smeets</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 17th ACM International Conference on Web Search and Data Mining (WSDM-2024)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The 17th ACM International Conference on Web Search and Data
  Mining (WSDM-2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item831">[831]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02213" title="Abstract">arXiv:2306.02213</a> (replaced) [<a href="/pdf/2306.02213" title="Download PDF">pdf</a>, <a href="/format/2306.02213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Emotion Arcs Across Languages: Bridging the Global Divide in  Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teodorescu%2C+D">Daniela Teodorescu</a>, 
<a href="/search/cs?searchtype=author&query=Mohammad%2C+S+M">Saif M. Mohammad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures. arXiv admin note: substantial text overlap with <a href="/abs/2210.07381">arXiv:2210.07381</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item832">[832]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02451" title="Abstract">arXiv:2306.02451</a> (replaced) [<a href="/pdf/2306.02451" title="Download PDF">pdf</a>, <a href="/format/2306.02451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> For SALE: State-Action Representation Learning for Deep Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fujimoto%2C+S">Scott Fujimoto</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+W">Wei-Di Chang</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+E+J">Edward J. Smith</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+S+S">Shixiang Shane Gu</a>, 
<a href="/search/cs?searchtype=author&query=Precup%2C+D">Doina Precup</a>, 
<a href="/search/cs?searchtype=author&query=Meger%2C+D">David Meger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item833">[833]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03302" title="Abstract">arXiv:2306.03302</a> (replaced) [<a href="/pdf/2306.03302" title="Download PDF">pdf</a>, <a href="/format/2306.03302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical Inference Under Constrained Selection Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Cortes-Gomez%2C+S">Santiago Cortes-Gomez</a>, 
<a href="/search/stat?searchtype=author&query=Dulce%2C+M">Mateo Dulce</a>, 
<a href="/search/stat?searchtype=author&query=Patino%2C+C">Carlos Patino</a>, 
<a href="/search/stat?searchtype=author&query=Wilder%2C+B">Bryan Wilder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item834">[834]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03535" title="Abstract">arXiv:2306.03535</a> (replaced) [<a href="/pdf/2306.03535" title="Download PDF">pdf</a>, <a href="/format/2306.03535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SciLit: A Platform for Joint Scientific Literature Discovery,  Summarization and Citation Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+N">Nianlong Gu</a>, 
<a href="/search/cs?searchtype=author&query=Hahnloser%2C+R+H+R">Richard H.R. Hahnloser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ACL 2023 System Demonstration
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item835">[835]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03774" title="Abstract">arXiv:2306.03774</a> (replaced) [<a href="/pdf/2306.03774" title="Download PDF">pdf</a>, <a href="/format/2306.03774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Hybrid Linguistic Features for Turkish Text Readability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uluslu%2C+A+Y">Ahmet Yavuz Uluslu</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+G">Gerold Schneider</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item836">[836]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03929" title="Abstract">arXiv:2306.03929</a> (replaced) [<a href="/pdf/2306.03929" title="Download PDF">pdf</a>, <a href="/format/2306.03929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Counterfactually Optimal Action Sequences in Continuous State  Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsirtsis%2C+S">Stratis Tsirtsis</a>, 
<a href="/search/cs?searchtype=author&query=Gomez-Rodriguez%2C+M">Manuel Gomez-Rodriguez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item837">[837]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03937" title="Abstract">arXiv:2306.03937</a> (replaced) [<a href="/pdf/2306.03937" title="Download PDF">pdf</a>, <a href="/format/2306.03937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guiding The Last Layer in Federated Learning with Pre-Trained Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Legate%2C+G">Gwen Legate</a>, 
<a href="/search/cs?searchtype=author&query=Bernier%2C+N">Nicolas Bernier</a>, 
<a href="/search/cs?searchtype=author&query=Caccia%2C+L">Lucas Caccia</a>, 
<a href="/search/cs?searchtype=author&query=Oyallon%2C+E">Edouard Oyallon</a>, 
<a href="/search/cs?searchtype=author&query=Belilovsky%2C+E">Eugene Belilovsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item838">[838]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04181" title="Abstract">arXiv:2306.04181</a> (replaced) [<a href="/pdf/2306.04181" title="Download PDF">pdf</a>, <a href="/format/2306.04181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Foundation Models with Language-Model-as-an-Examiner
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yushi Bai</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+J">Jiahao Ying</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yixin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+X">Xin Lv</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuze He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaozhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jifan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+K">Kaisheng Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yijia Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+H">Haozhe Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiayin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juanzi Li</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Lei Hou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Datasets and Benchmarks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item839">[839]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04492" title="Abstract">arXiv:2306.04492</a> (replaced) [<a href="/pdf/2306.04492" title="Download PDF">pdf</a>, <a href="/ps/2306.04492" title="Download PostScript">ps</a>, <a href="/format/2306.04492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Bregman Proximal Perspective on Classical and Quantum Blahut-Arimoto  Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+K">Kerry He</a>, 
<a href="/search/cs?searchtype=author&query=Saunderson%2C+J">James Saunderson</a>, 
<a href="/search/cs?searchtype=author&query=Fawzi%2C+H">Hamza Fawzi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages. v2: Revised introduction and numerical experiments; strengthened proof for Theorem 4.7; other minor edits throughout
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Optimization and Control (math.OC); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item840">[840]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05401" title="Abstract">arXiv:2306.05401</a> (replaced) [<a href="/pdf/2306.05401" title="Download PDF">pdf</a>, <a href="/format/2306.05401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RDumb: A simple approach that questions our progress in continual  test-time adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Press%2C+O">Ori Press</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+S">Steffen Schneider</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BCmmerer%2C+M">Matthias K&#xfc;mmerer</a>, 
<a href="/search/cs?searchtype=author&query=Bethge%2C+M">Matthias Bethge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item841">[841]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05694" title="Abstract">arXiv:2306.05694</a> (replaced) [<a href="/pdf/2306.05694" title="Download PDF">pdf</a>, <a href="/format/2306.05694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Representation Learning of Small Quantum States
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Frohnert%2C+F">Felix Frohnert</a>, 
<a href="/search/quant-ph?searchtype=author&query=van+Nieuwenburg%2C+E">Evert van Nieuwenburg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item842">[842]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05720" title="Abstract">arXiv:2306.05720</a> (replaced) [<a href="/pdf/2306.05720" title="Download PDF">pdf</a>, <a href="/format/2306.05720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Surface Statistics: Scene Representations in a Latent Diffusion  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yida Chen</a>, 
<a href="/search/cs?searchtype=author&query=Vi%C3%A9gas%2C+F">Fernanda Vi&#xe9;gas</a>, 
<a href="/search/cs?searchtype=author&query=Wattenberg%2C+M">Martin Wattenberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A short version of this paper is accepted in the NeurIPS 2023 Workshop on Diffusion Models: <a href="https://nips.cc/virtual/2023/74894">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item843">[843]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06203" title="Abstract">arXiv:2306.06203</a> (replaced) [<a href="/pdf/2306.06203" title="Download PDF">pdf</a>, <a href="/format/2306.06203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FLSL: Feature-level Self-supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+Q">Qing Su</a>, 
<a href="/search/cs?searchtype=author&query=Netchaev%2C+A">Anton Netchaev</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hai Li</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shihao Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a main conference paper at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item844">[844]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06215" title="Abstract">arXiv:2306.06215</a> (replaced) [<a href="/pdf/2306.06215" title="Download PDF">pdf</a>, <a href="/format/2306.06215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Covering Planar Metrics (and Beyond): O(1) Trees Suffice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">Hsien-Chih Chang</a>, 
<a href="/search/cs?searchtype=author&query=Conroy%2C+J">Jonathan Conroy</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+H">Hung Le</a>, 
<a href="/search/cs?searchtype=author&query=Milenkovic%2C+L">Lazar Milenkovic</a>, 
<a href="/search/cs?searchtype=author&query=Solomon%2C+S">Shay Solomon</a>, 
<a href="/search/cs?searchtype=author&query=Than%2C+C">Cuong Than</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Abstract truncated to fit arXiv limits
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Geometry (cs.CG)

</div>
</div>
</dd>
<dt><a name="item845">[845]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06543" title="Abstract">arXiv:2306.06543</a> (replaced) [<a href="/pdf/2306.06543" title="Download PDF">pdf</a>, <a href="/format/2306.06543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MANER: Multi-Agent Neural Rearrangement Planning of Objects in Cluttered  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+V">Vivek Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Dhir%2C+P">Praphpreet Dhir</a>, 
<a href="/search/cs?searchtype=author&query=Dani%2C+J">Jeegn Dani</a>, 
<a href="/search/cs?searchtype=author&query=Qureshi%2C+A+H">Ahmed H. Qureshi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The videos and supplementary material are available at <a href="https://sites.google.com/view/maner-supplementary">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Published in IEEE Robotics and Automation Letters, vol. 8, no. 12,
  pp. 8295-8302, Dec. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item846">[846]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06687" title="Abstract">arXiv:2306.06687</a> (replaced) [<a href="/pdf/2306.06687" title="Download PDF">pdf</a>, <a href="/format/2306.06687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LAMM: Language-Assisted Multi-Modal Instruction-Tuning Dataset,  Framework, and Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhenfei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jianjian Cao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhelun Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dingning Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mukai Li</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+L">Lu Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+L">Lei Bai</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaoshui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiyong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jing Shao</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS2023 camera ready ; 37 pages, 33 figures. Code available at <a href="https://github.com/OpenLAMM/LAMM">this https URL</a> ; Project page: <a href="https://openlamm.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item847">[847]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06874" title="Abstract">arXiv:2306.06874</a> (replaced) [<a href="/pdf/2306.06874" title="Download PDF">pdf</a>, <a href="/format/2306.06874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VillanDiffusion: A Unified Backdoor Attack Framework for Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chou%2C+S">Sheng-Yen Chou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pin-Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+T">Tsung-Yi Ho</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023, NeurIPS BUGS Workshop Oral
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item848">[848]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08687" title="Abstract">arXiv:2306.08687</a> (replaced) [<a href="/pdf/2306.08687" title="Download PDF">pdf</a>, <a href="/format/2306.08687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Norm-guided latent space exploration for text-to-image generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Samuel%2C+D">Dvir Samuel</a>, 
<a href="/search/cs?searchtype=author&query=Ben-Ari%2C+R">Rami Ben-Ari</a>, 
<a href="/search/cs?searchtype=author&query=Darshan%2C+N">Nir Darshan</a>, 
<a href="/search/cs?searchtype=author&query=Maron%2C+H">Haggai Maron</a>, 
<a href="/search/cs?searchtype=author&query=Chechik%2C+G">Gal Chechik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item849">[849]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08776" title="Abstract">arXiv:2306.08776</a> (replaced) [<a href="/pdf/2306.08776" title="Download PDF">pdf</a>, <a href="/format/2306.08776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Learning for Obstacle Avoidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Snyder%2C+D">David Snyder</a>, 
<a href="/search/cs?searchtype=author&query=Booker%2C+M">Meghan Booker</a>, 
<a href="/search/cs?searchtype=author&query=Simon%2C+N">Nathaniel Simon</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+W">Wenhan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Suo%2C+D">Daniel Suo</a>, 
<a href="/search/cs?searchtype=author&query=Hazan%2C+E">Elad Hazan</a>, 
<a href="/search/cs?searchtype=author&query=Majumdar%2C+A">Anirudha Majumdar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 + 21 pages, 2 + 11 figures, Accepted to CoRL 2023 [Poster]
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item850">[850]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09774" title="Abstract">arXiv:2306.09774</a> (replaced) [<a href="/pdf/2306.09774" title="Download PDF">pdf</a>, <a href="/format/2306.09774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Testbed for Carbon-Aware Applications and Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wiesner%2C+P">Philipp Wiesner</a>, 
<a href="/search/cs?searchtype=author&query=Behnke%2C+I">Ilja Behnke</a>, 
<a href="/search/cs?searchtype=author&query=Kao%2C+O">Odej Kao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item851">[851]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09869" title="Abstract">arXiv:2306.09869</a> (replaced) [<a href="/pdf/2306.09869" title="Download PDF">pdf</a>, <a href="/format/2306.09869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-Based Cross Attention for Bayesian Context Update in  Text-to-Image Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+G+Y">Geon Yeong Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jeongsol Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Beomsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S+W">Sang Wan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J+C">Jong Chul Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item852">[852]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10915" title="Abstract">arXiv:2306.10915</a> (replaced) [<a href="/pdf/2306.10915" title="Download PDF">pdf</a>, <a href="/format/2306.10915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Practical Equivariances via Relational Conditional Neural Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Huang%2C+D">Daolang Huang</a>, 
<a href="/search/stat?searchtype=author&query=Haussmann%2C+M">Manuel Haussmann</a>, 
<a href="/search/stat?searchtype=author&query=Remes%2C+U">Ulpu Remes</a>, 
<a href="/search/stat?searchtype=author&query=John%2C+S">ST John</a>, 
<a href="/search/stat?searchtype=author&query=Clart%C3%A9%2C+G">Gr&#xe9;goire Clart&#xe9;</a>, 
<a href="/search/stat?searchtype=author&query=Luck%2C+K+S">Kevin Sebastian Luck</a>, 
<a href="/search/stat?searchtype=author&query=Kaski%2C+S">Samuel Kaski</a>, 
<a href="/search/stat?searchtype=author&query=Acerbi%2C+L">Luigi Acerbi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 8 figures. Accepted at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item853">[853]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11147" title="Abstract">arXiv:2306.11147</a> (replaced) [<a href="/pdf/2306.11147" title="Download PDF">pdf</a>, <a href="/format/2306.11147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAT-Walk: Inductive Hypergraph Learning via Set Walks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Behrouz%2C+A">Ali Behrouz</a>, 
<a href="/search/cs?searchtype=author&query=Hashemi%2C+F">Farnoosh Hashemi</a>, 
<a href="/search/cs?searchtype=author&query=Sadeghian%2C+S">Sadaf Sadeghian</a>, 
<a href="/search/cs?searchtype=author&query=Seltzer%2C+M">Margo Seltzer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item854">[854]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11197" title="Abstract">arXiv:2306.11197</a> (replaced) [<a href="/pdf/2306.11197" title="Download PDF">pdf</a>, <a href="/format/2306.11197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Modular Activation for Efficient Sequence Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+L">Liliang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuohang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yichong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chenguang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+C">ChengXiang Zhai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023. Camera-ready Version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item855">[855]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11368" title="Abstract">arXiv:2306.11368</a> (replaced) [<a href="/pdf/2306.11368" title="Download PDF">pdf</a>, <a href="/format/2306.11368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoMe: Towards Large Scale Road Surface Reconstruction via Mesh  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mei%2C+R">Ruohong Mei</a>, 
<a href="/search/cs?searchtype=author&query=Sui%2C+W">Wei Sui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+X">Xue Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+T">Tao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cong Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item856">[856]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11464" title="Abstract">arXiv:2306.11464</a> (replaced) [<a href="/pdf/2306.11464" title="Download PDF">pdf</a>, <a href="/format/2306.11464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-to-Many Spectral Upsampling of Reflectances and Transmittances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belcour%2C+L">Laurent Belcour</a>, 
<a href="/search/cs?searchtype=author&query=Barla%2C+P">Pacal Barla</a>, 
<a href="/search/cs?searchtype=author&query=Guennebaud%2C+G">Gael Guennebaud</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Graphics Forum (proceedings of EGSR 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
</div>
</dd>
<dt><a name="item857">[857]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11515" title="Abstract">arXiv:2306.11515</a> (replaced) [<a href="/pdf/2306.11515" title="Download PDF">pdf</a>, <a href="/format/2306.11515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An implicit-explicit solver for a two-fluid single-temperature model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Luk%C3%A1%C4%8Dov%C3%A1-Medvid%27ov%C3%A1%2C+M">M&#xe1;ria Luk&#xe1;&#x10d;ov&#xe1;-Medvid&#x27;ov&#xe1;</a>, 
<a href="/search/math?searchtype=author&query=Peshkov%2C+I">Ilya Peshkov</a>, 
<a href="/search/math?searchtype=author&query=Thomann%2C+A">Andrea Thomann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item858">[858]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11582" title="Abstract">arXiv:2306.11582</a> (replaced) [<a href="/pdf/2306.11582" title="Download PDF">pdf</a>, <a href="/format/2306.11582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing a human-like reaction time metric from stable recurrent vision  models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goetschalckx%2C+L">Lore Goetschalckx</a>, 
<a href="/search/cs?searchtype=author&query=Govindarajan%2C+L+N">Lakshmi Narasimhan Govindarajan</a>, 
<a href="/search/cs?searchtype=author&query=Ashok%2C+A+K">Alekh Karkada Ashok</a>, 
<a href="/search/cs?searchtype=author&query=Ahuja%2C+A">Aarit Ahuja</a>, 
<a href="/search/cs?searchtype=author&query=Sheinberg%2C+D+L">David L. Sheinberg</a>, 
<a href="/search/cs?searchtype=author&query=Serre%2C+T">Thomas Serre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item859">[859]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11739" title="Abstract">arXiv:2306.11739</a> (replaced) [<a href="/pdf/2306.11739" title="Download PDF">pdf</a>, <a href="/format/2306.11739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-view 3D Object Reconstruction and Uncertainty Modelling with  Neural Shape Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+Z">Ziwei Liao</a>, 
<a href="/search/cs?searchtype=author&query=Waslander%2C+S+L">Steven L. Waslander</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Manuscript accepted by WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item860">[860]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12392" title="Abstract">arXiv:2306.12392</a> (replaced) [<a href="/pdf/2306.12392" title="Download PDF">pdf</a>, <a href="/format/2306.12392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-shot Imitation Learning via Interaction Warping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biza%2C+O">Ondrej Biza</a>, 
<a href="/search/cs?searchtype=author&query=Thompson%2C+S">Skye Thompson</a>, 
<a href="/search/cs?searchtype=author&query=Pagidi%2C+K+R">Kishore Reddy Pagidi</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Abhinav Kumar</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Pol%2C+E">Elise van der Pol</a>, 
<a href="/search/cs?searchtype=author&query=Walters%2C+R">Robin Walters</a>, 
<a href="/search/cs?searchtype=author&query=Kipf%2C+T">Thomas Kipf</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Meent%2C+J">Jan-Willem van de Meent</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+L+L+S">Lawson L.S. Wong</a>, 
<a href="/search/cs?searchtype=author&query=Platt%2C+R">Robert Platt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CoRL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item861">[861]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13153" title="Abstract">arXiv:2306.13153</a> (replaced) [<a href="/pdf/2306.13153" title="Download PDF">pdf</a>, <a href="/format/2306.13153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyperboloidal discontinuous time-symmetric numerical algorithm with  higher order jumps for gravitational self-force computations in the time  domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/gr-qc?searchtype=author&query=Da+Silva%2C+L+J+G">Lidia J. Gomes Da Silva</a>, 
<a href="/search/gr-qc?searchtype=author&query=Macedo%2C+R+P">Rodrigo Panosso Macedo</a>, 
<a href="/search/gr-qc?searchtype=author&query=Thompson%2C+J+E">Jonathan E. Thompson</a>, 
<a href="/search/gr-qc?searchtype=author&query=Kroon%2C+J+A+V">Juan A. Valiente Kroon</a>, 
<a href="/search/gr-qc?searchtype=author&query=Durkan%2C+L">Leanne Durkan</a>, 
<a href="/search/gr-qc?searchtype=author&query=Long%2C+O">Oliver Long</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages; Corrected to accommodate for valuable feedback from the referee; Minor typos corrected in Appendix B
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Relativity and Quantum Cosmology (gr-qc)</span>; Numerical Analysis (math.NA); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item862">[862]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14111" title="Abstract">arXiv:2306.14111</a> (replaced) [<a href="/pdf/2306.14111" title="Download PDF">pdf</a>, <a href="/format/2306.14111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is RLHF More Difficult than Standard RL?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuanhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qinghua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Chi Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at NeurIPS 2023; 29 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item863">[863]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14597" title="Abstract">arXiv:2306.14597</a> (replaced) [<a href="/pdf/2306.14597" title="Download PDF">pdf</a>, <a href="/format/2306.14597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Providing Curative Distribution Grid Flexibility Using Online Feedback  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Klein-Helmkamp%2C+F">Florian Klein-Helmkamp</a>, 
<a href="/search/eess?searchtype=author&query=B%C3%B6hm%2C+F">Fabian B&#xf6;hm</a>, 
<a href="/search/eess?searchtype=author&query=Ortmann%2C+L">Lukas Ortmann</a>, 
<a href="/search/eess?searchtype=author&query=Winkens%2C+A">Alexander Winkens</a>, 
<a href="/search/eess?searchtype=author&query=Schmidtke%2C+F">Florian Schmidtke</a>, 
<a href="/search/eess?searchtype=author&query=Bolognani%2C+S">Saverio Bolognani</a>, 
<a href="/search/eess?searchtype=author&query=D%C3%B6rfler%2C+F">Florian D&#xf6;rfler</a>, 
<a href="/search/eess?searchtype=author&query=Ulbig%2C+A">Andreas Ulbig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item864">[864]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15136" title="Abstract">arXiv:2306.15136</a> (replaced) [<a href="/pdf/2306.15136" title="Download PDF">pdf</a>, <a href="/format/2306.15136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Truly Matters in Trajectory Prediction for Autonomous Driving?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+P">Phong Tran</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoran Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Cunjun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+P">Panpan Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Sifa Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+D">David Hsu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item865">[865]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15951" title="Abstract">arXiv:2306.15951</a> (replaced) [<a href="/pdf/2306.15951" title="Download PDF">pdf</a>, <a href="/ps/2306.15951" title="Download PostScript">ps</a>, <a href="/format/2306.15951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reduce Computational Complexity for Convolutional Layers by Skipping  Zeros
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pengfei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhuopin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item866">[866]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17237" title="Abstract">arXiv:2306.17237</a> (replaced) [<a href="/pdf/2306.17237" title="Download PDF">pdf</a>, <a href="/format/2306.17237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HYDRA: Hybrid Robot Actions for Imitation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belkhale%2C+S">Suneel Belkhale</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yuchen Cui</a>, 
<a href="/search/cs?searchtype=author&query=Sadigh%2C+D">Dorsa Sadigh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item867">[867]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01050" title="Abstract">arXiv:2307.01050</a> (replaced) [<a href="/pdf/2307.01050" title="Download PDF">pdf</a>, <a href="/format/2307.01050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transport, Variational Inference and Diffusions: with Applications to  Annealed Flows and Schr&#xf6;dinger Bridges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Vargas%2C+F">Francisco Vargas</a>, 
<a href="/search/stat?searchtype=author&query=Padhy%2C+S">Shreyas Padhy</a>, 
<a href="/search/stat?searchtype=author&query=Blessing%2C+D">Denis Blessing</a>, 
<a href="/search/stat?searchtype=author&query=N%C3%BCsken%2C+N">Nikolas N&#xfc;sken</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Workshop on New Frontiers in Learning, Control, and Dynamical Systems at the International Conference on Machine Learning (ICML), Honolulu, Hawaii, USA, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item868">[868]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01205" title="Abstract">arXiv:2307.01205</a> (replaced) [<a href="/pdf/2307.01205" title="Download PDF">pdf</a>, <a href="/ps/2307.01205" title="Download PostScript">ps</a>, <a href="/format/2307.01205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heuristic Algorithms for RIS-assisted Wireless Networks: Exploring  Heuristic-aided Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Erol-Kantarci%2C+M">Melike Erol-Kantarci</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Poor%2C+H+V">H. Vincent Poor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item869">[869]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01396" title="Abstract">arXiv:2307.01396</a> (replaced) [<a href="/pdf/2307.01396" title="Download PDF">pdf</a>, <a href="/format/2307.01396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Precheck Sequence Based False Base Station Detection During Handover: A  Physical Layer Security Scheme
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiangyu Li</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+K">Kaiwen Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+S">Sidong Guo</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+X">Xiaoli Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item870">[870]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02707" title="Abstract">arXiv:2307.02707</a> (replaced) [<a href="/pdf/2307.02707" title="Download PDF">pdf</a>, <a href="/format/2307.02707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Symmetry-Aware Generation of Periodic Materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Youzhi Luo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chengkai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shuiwang Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023 as a spotlight paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Materials Science (cond-mat.mtrl-sci)

</div>
</div>
</dd>
<dt><a name="item871">[871]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02954" title="Abstract">arXiv:2307.02954</a> (replaced) [<a href="/pdf/2307.02954" title="Download PDF">pdf</a>, <a href="/format/2307.02954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eating sandwiches: Modular and lightweight elimination of transaction  reordering attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alpos%2C+O">Orestis Alpos</a>, 
<a href="/search/cs?searchtype=author&query=Amores-Sesar%2C+I">Ignacio Amores-Sesar</a>, 
<a href="/search/cs?searchtype=author&query=Cachin%2C+C">Christian Cachin</a>, 
<a href="/search/cs?searchtype=author&query=Yeo%2C+M">Michelle Yeo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item872">[872]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04075" title="Abstract">arXiv:2307.04075</a> (replaced) [<a href="/pdf/2307.04075" title="Download PDF">pdf</a>, <a href="/ps/2307.04075" title="Download PostScript">ps</a>, <a href="/format/2307.04075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DEDUCE: Multi-head attention decoupled contrastive learning to discover  cancer subtypes based on multi-omics data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Liangrui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dazhen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Y">Yutao Dou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhichao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+P">Pengfei Rong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Liwen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Shaoliang Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item873">[873]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04596" title="Abstract">arXiv:2307.04596</a> (replaced) [<a href="/pdf/2307.04596" title="Download PDF">pdf</a>, <a href="/format/2307.04596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distill-SODA: Distilling Self-Supervised Vision Transformer for  Source-Free Open-Set Domain Adaptation in Computational Pathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vray%2C+G">Guillaume Vray</a>, 
<a href="/search/cs?searchtype=author&query=Tomar%2C+D">Devavrat Tomar</a>, 
<a href="/search/cs?searchtype=author&query=Bozorgtabar%2C+B">Behzad Bozorgtabar</a>, 
<a href="/search/cs?searchtype=author&query=Thiran%2C+J">Jean-Philippe Thiran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item874">[874]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05884" title="Abstract">arXiv:2307.05884</a> (replaced) [<a href="/pdf/2307.05884" title="Download PDF">pdf</a>, <a href="/format/2307.05884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Koopman Operators with Control Using Bi-level Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Huang%2C+D">Daning Huang</a>, 
<a href="/search/eess?searchtype=author&query=Prasetyo%2C+M+B">Muhammad Bayu Prasetyo</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+Y">Yin Yu</a>, 
<a href="/search/eess?searchtype=author&query=Geng%2C+J">Junyi Geng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 2023 IEEE 62nd Conference on Decision and Control (CDC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item875">[875]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06775" title="Abstract">arXiv:2307.06775</a> (replaced) [<a href="/pdf/2307.06775" title="Download PDF">pdf</a>, <a href="/ps/2307.06775" title="Download PostScript">ps</a>, <a href="/format/2307.06775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Site-Agnostic Multimodal Deep Learning Model to Identify  Pro-Eating Disorder Content on Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feldman%2C+J">Jonathan Feldman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item876">[876]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06870" title="Abstract">arXiv:2307.06870</a> (replaced) [<a href="/pdf/2307.06870" title="Download PDF">pdf</a>, <a href="/format/2307.06870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embodied Lifelong Learning for Task and Motion Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mendez-Mendez%2C+J">Jorge Mendez-Mendez</a>, 
<a href="/search/cs?searchtype=author&query=Kaelbling%2C+L+P">Leslie Pack Kaelbling</a>, 
<a href="/search/cs?searchtype=author&query=Lozano-P%C3%A9rez%2C+T">Tom&#xe1;s Lozano-P&#xe9;rez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at CoRL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item877">[877]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07320" title="Abstract">arXiv:2307.07320</a> (replaced) [<a href="/pdf/2307.07320" title="Download PDF">pdf</a>, <a href="/format/2307.07320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Linear Estimating Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ying%2C+M">Mufang Ying</a>, 
<a href="/search/math?searchtype=author&query=Khamaru%2C+K">Koulik Khamaru</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+C">Cun-Hui Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper is accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item878">[878]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07643" title="Abstract">arXiv:2307.07643</a> (replaced) [<a href="/pdf/2307.07643" title="Download PDF">pdf</a>, <a href="/format/2307.07643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AECIF-Net: An Attention-Enhanced Co-Interactive Fusion Network for  Automated Structural Condition Assessment in Visual Inspection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhaozheng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+R">Ruwen Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Automation in Construction
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item879">[879]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07970" title="Abstract">arXiv:2307.07970</a> (replaced) [<a href="/pdf/2307.07970" title="Download PDF">pdf</a>, <a href="/ps/2307.07970" title="Download PostScript">ps</a>, <a href="/format/2307.07970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Bounds for Matrix Multiplication: from Alpha to Omega
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Williams%2C+V+V">Virginia Vassilevska Williams</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yinzhan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zixuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+R">Renfei Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 55 pages; in SODA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item880">[880]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08168" title="Abstract">arXiv:2307.08168</a> (replaced) [<a href="/pdf/2307.08168" title="Download PDF">pdf</a>, <a href="/format/2307.08168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling Efficient, Reliable Real-World Reinforcement Learning with  Approximate Physics-Based Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Westenbroek%2C+T">Tyler Westenbroek</a>, 
<a href="/search/cs?searchtype=author&query=Levy%2C+J">Jacob Levy</a>, 
<a href="/search/cs?searchtype=author&query=Fridovich-Keil%2C+D">David Fridovich-Keil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item881">[881]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08701" title="Abstract">arXiv:2307.08701</a> (replaced) [<a href="/pdf/2307.08701" title="Download PDF">pdf</a>, <a href="/format/2307.08701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AlpaGasus: Training A Better Alpaca with Fewer Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lichang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shiyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jun Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gunaratna%2C+K">Kalpa Gunaratna</a>, 
<a href="/search/cs?searchtype=author&query=Yadav%2C+V">Vikas Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zheng Tang</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+V">Vijay Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Heng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Hongxia Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 Pages; 29 Figures; 15 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item882">[882]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08779" title="Abstract">arXiv:2307.08779</a> (replaced) [<a href="/pdf/2307.08779" title="Download PDF">pdf</a>, <a href="/format/2307.08779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Similarity Min-Max: Zero-Shot Day-Night Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+R">Rundong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenhan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaying Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item883">[883]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10894" title="Abstract">arXiv:2307.10894</a> (replaced) [<a href="/pdf/2307.10894" title="Download PDF">pdf</a>, <a href="/format/2307.10894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Motion Generation: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wentao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaoxuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ro%2C+D">Dongwoo Ro</a>, 
<a href="/search/cs?searchtype=author&query=Ci%2C+H">Hai Ci</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinlu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jiaxin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+F">Feng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qi Tian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yizhou Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to TPAMI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item884">[884]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12522" title="Abstract">arXiv:2307.12522</a> (replaced) [<a href="/pdf/2307.12522" title="Download PDF">pdf</a>, <a href="/format/2307.12522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Mapping of Adaptive App GUIs from Phones to TVs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Han Hu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+R">Ruiqi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Grundy%2C+J">John Grundy</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+M">Thai Minh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huaxiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chunyang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item885">[885]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13225" title="Abstract">arXiv:2307.13225</a> (replaced) [<a href="/pdf/2307.13225" title="Download PDF">pdf</a>, <a href="/format/2307.13225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Pairwise Dataset for GUI Conversion and Retrieval between Android  Phones and Tablets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Han Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+H">Haolan Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yujin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Di Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item886">[886]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14302" title="Abstract">arXiv:2307.14302</a> (replaced) [<a href="/pdf/2307.14302" title="Download PDF">pdf</a>, <a href="/format/2307.14302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Discontinuous Galerkin Finite Element Model for Compound Flood  Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wichitrnithed%2C+C">Chayanon Wichitrnithed</a>, 
<a href="/search/cs?searchtype=author&query=Valseth%2C+E">Eirik Valseth</a>, 
<a href="/search/cs?searchtype=author&query=Kubatko%2C+E+J">Ethan J. Kubatko</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Younghun Kang</a>, 
<a href="/search/cs?searchtype=author&query=Hudson%2C+M">Mackenzie Hudson</a>, 
<a href="/search/cs?searchtype=author&query=Dawson%2C+C">Clint Dawson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item887">[887]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14850" title="Abstract">arXiv:2307.14850</a> (replaced) [<a href="/pdf/2307.14850" title="Download PDF">pdf</a>, <a href="/format/2307.14850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Turkish Native Language Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uluslu%2C+A+Y">Ahmet Yavuz Uluslu</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+G">Gerold Schneider</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item888">[888]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15873" title="Abstract">arXiv:2307.15873</a> (replaced) [<a href="/pdf/2307.15873" title="Download PDF">pdf</a>, <a href="/format/2307.15873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extended tensor decomposition model reduction methods: training,  prediction, and design under uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lu%2C+Y">Ye Lu</a>, 
<a href="/search/math?searchtype=author&query=Mojumder%2C+S">Satyajit Mojumder</a>, 
<a href="/search/math?searchtype=author&query=Guo%2C+J">Jiachen Guo</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+Y">Yangfan Li</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+W+K">Wing Kam Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item889">[889]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15936" title="Abstract">arXiv:2307.15936</a> (replaced) [<a href="/pdf/2307.15936" title="Download PDF">pdf</a>, <a href="/format/2307.15936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Theory for Emergence of Complex Skills in Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arora%2C+S">Sanjeev Arora</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+A">Anirudh Goyal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item890">[890]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16104" title="Abstract">arXiv:2307.16104</a> (replaced) [<a href="/pdf/2307.16104" title="Download PDF">pdf</a>, <a href="/format/2307.16104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Increases Global Access to Reliable Flood Forecasts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nearing%2C+G">Grey Nearing</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+D">Deborah Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Dube%2C+V">Vusumuzi Dube</a>, 
<a href="/search/cs?searchtype=author&query=Gauch%2C+M">Martin Gauch</a>, 
<a href="/search/cs?searchtype=author&query=Gilon%2C+O">Oren Gilon</a>, 
<a href="/search/cs?searchtype=author&query=Harrigan%2C+S">Shaun Harrigan</a>, 
<a href="/search/cs?searchtype=author&query=Hassidim%2C+A">Avinatan Hassidim</a>, 
<a href="/search/cs?searchtype=author&query=Klotz%2C+D">Daniel Klotz</a>, 
<a href="/search/cs?searchtype=author&query=Kratzert%2C+F">Frederik Kratzert</a>, 
<a href="/search/cs?searchtype=author&query=Metzger%2C+A">Asher Metzger</a>, 
<a href="/search/cs?searchtype=author&query=Nevo%2C+S">Sella Nevo</a>, 
<a href="/search/cs?searchtype=author&query=Pappenberger%2C+F">Florian Pappenberger</a>, 
<a href="/search/cs?searchtype=author&query=Prudhomme%2C+C">Christel Prudhomme</a>, 
<a href="/search/cs?searchtype=author&query=Shalev%2C+G">Guy Shalev</a>, 
<a href="/search/cs?searchtype=author&query=Shenzis%2C+S">Shlomo Shenzis</a>, 
<a href="/search/cs?searchtype=author&query=Tekalign%2C+T">Tadele Tekalign</a>, 
<a href="/search/cs?searchtype=author&query=Weitzner%2C+D">Dana Weitzner</a>, 
<a href="/search/cs?searchtype=author&query=Matias%2C+Y">Yoss Matias</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item891">[891]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00158" title="Abstract">arXiv:2308.00158</a> (replaced) [<a href="/pdf/2308.00158" title="Download PDF">pdf</a>, <a href="/format/2308.00158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predictive Data Analytics with AI: assessing the need for post-editing  of MT output by fine-tuning OpenAI LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gladkoff%2C+S">Serge Gladkoff</a>, 
<a href="/search/cs?searchtype=author&query=Erofeev%2C+G">Gleb Erofeev</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Lifeng Han</a>, 
<a href="/search/cs?searchtype=author&query=Nenadic%2C+G">Goran Nenadic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> working paper - 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item892">[892]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00352" title="Abstract">arXiv:2308.00352</a> (replaced) [<a href="/pdf/2308.00352" title="Download PDF">pdf</a>, <a href="/format/2308.00352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Sirui Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zhuge%2C+M">Mingchen Zhuge</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jonathan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiawu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yuheng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Ceyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinlin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zili Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yau%2C+S+K+S">Steven Ka Shing Yau</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zijuan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Liyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ran%2C+C">Chenyu Ran</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Lingfeng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenglin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Schmidhuber%2C+J">J&#xfc;rgen Schmidhuber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item893">[893]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00677" title="Abstract">arXiv:2308.00677</a> (replaced) [<a href="/pdf/2308.00677" title="Download PDF">pdf</a>, <a href="/format/2308.00677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discrete neural nets and polymorphic learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aten%2C+C">Charlotte Aten</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Version 2 includes the figures which were missing in the first version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG); Combinatorics (math.CO); Rings and Algebras (math.RA)

</div>
</div>
</dd>
<dt><a name="item894">[894]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01481" title="Abstract">arXiv:2308.01481</a> (replaced) [<a href="/pdf/2308.01481" title="Download PDF">pdf</a>, <a href="/format/2308.01481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online covariance estimation for stochastic gradient descent under  Markovian sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Roy%2C+A">Abhishek Roy</a>, 
<a href="/search/math?searchtype=author&query=Balasubramanian%2C+K">Krishnakumar Balasubramanian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item895">[895]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02698" title="Abstract">arXiv:2308.02698</a> (replaced) [<a href="/pdf/2308.02698" title="Download PDF">pdf</a>, <a href="/format/2308.02698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Decision-Theoretic Approaches for Robotic Environmental  Monitoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sung%2C+Y">Yoonchang Sung</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+J">Jnaneshwar Das</a>, 
<a href="/search/cs?searchtype=author&query=Tokekar%2C+P">Pratap Tokekar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 95 pages, 8 figures, Published in Foundations and Trends in Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item896">[896]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04345" title="Abstract">arXiv:2308.04345</a> (replaced) [<a href="/pdf/2308.04345" title="Download PDF">pdf</a>, <a href="/format/2308.04345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair and Inclusive Participatory Budgeting: Voter Experience with  Cumulative and Quadratic Voting Interfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wellings%2C+T">Thomas Wellings</a>, 
<a href="/search/cs?searchtype=author&query=Heravan%2C+F+B">Fatemeh Banaie Heravan</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Abhinav Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Gelauff%2C+L">Lodewijk Gelauff</a>, 
<a href="/search/cs?searchtype=author&query=Fricker%2C+R+H">Regula H&#xe4;nggli Fricker</a>, 
<a href="/search/cs?searchtype=author&query=Pournaras%2C+E">Evangelos Pournaras</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item897">[897]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04451" title="Abstract">arXiv:2308.04451</a> (replaced) [<a href="/pdf/2308.04451" title="Download PDF">pdf</a>, <a href="/format/2308.04451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vulnerabilities in AI Code Generators: Exploring Targeted Data Poisoning  Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cotroneo%2C+D">Domenico Cotroneo</a>, 
<a href="/search/cs?searchtype=author&query=Improta%2C+C">Cristina Improta</a>, 
<a href="/search/cs?searchtype=author&query=Liguori%2C+P">Pietro Liguori</a>, 
<a href="/search/cs?searchtype=author&query=Natella%2C+R">Roberto Natella</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item898">[898]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05061" title="Abstract">arXiv:2308.05061</a> (replaced) [<a href="/pdf/2308.05061" title="Download PDF">pdf</a>, <a href="/format/2308.05061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Tune Language Models as Differential Equation Solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Siting Liu</a>, 
<a href="/search/cs?searchtype=author&query=Osher%2C+S+J">Stanley J. Osher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item899">[899]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06032" title="Abstract">arXiv:2308.06032</a> (replaced) [<a href="/pdf/2308.06032" title="Download PDF">pdf</a>, <a href="/format/2308.06032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models in Cryptocurrency Securities Cases: Can ChatGPT  Replace Lawyers?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Trozze%2C+A">Arianna Trozze</a>, 
<a href="/search/cs?searchtype=author&query=Davies%2C+T">Toby Davies</a>, 
<a href="/search/cs?searchtype=author&query=Kleinberg%2C+B">Bennett Kleinberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item900">[900]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06197" title="Abstract">arXiv:2308.06197</a> (replaced) [<a href="/pdf/2308.06197" title="Download PDF">pdf</a>, <a href="/format/2308.06197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complex Facial Expression Recognition Using Deep Knowledge Distillation  of Basic Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maiden%2C+A">Angus Maiden</a> (1), 
<a href="/search/cs?searchtype=author&query=Nakisa%2C+B">Bahareh Nakisa</a> (1) ((1) Deakin University)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 9 figures, 6 tables, 3 algorithms. Code available at <a href="https://github.com/AngusMaiden/complex-FER">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item901">[901]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08670" title="Abstract">arXiv:2308.08670</a> (replaced) [<a href="/pdf/2308.08670" title="Download PDF">pdf</a>, <a href="/ps/2308.08670" title="Download PostScript">ps</a>, <a href="/format/2308.08670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Approximation Bounds for Minimum Weight Cycle in the CONGEST  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manoharan%2C+V">Vignesh Manoharan</a>, 
<a href="/search/cs?searchtype=author&query=Ramachandran%2C+V">Vijaya Ramachandran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> More details have been provided for all algorithms. The algorithm for directed approximate MWC has been updated and the round bound now is $\tilde{O}(n^{4/5}+D)$
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item902">[902]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09544" title="Abstract">arXiv:2308.09544</a> (replaced) [<a href="/pdf/2308.09544" title="Download PDF">pdf</a>, <a href="/format/2308.09544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapt Your Teacher: Improving Knowledge Distillation for Exemplar-free  Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Szatkowski%2C+F">Filip Szatkowski</a>, 
<a href="/search/cs?searchtype=author&query=Pyla%2C+M">Mateusz Pyla</a>, 
<a href="/search/cs?searchtype=author&query=Przewi%C4%99%C5%BAlikowski%2C+M">Marcin Przewi&#x119;&#x17a;likowski</a>, 
<a href="/search/cs?searchtype=author&query=Cygert%2C+S">Sebastian Cygert</a>, 
<a href="/search/cs?searchtype=author&query=Twardowski%2C+B">Bart&#x142;omiej Twardowski</a>, 
<a href="/search/cs?searchtype=author&query=Trzci%C5%84ski%2C+T">Tomasz Trzci&#x144;ski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item903">[903]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09883" title="Abstract">arXiv:2308.09883</a> (replaced) [<a href="/pdf/2308.09883" title="Download PDF">pdf</a>, <a href="/format/2308.09883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flamingo: Multi-Round Single-Server Secure Aggregation with Applications  to Private Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yiping Ma</a>, 
<a href="/search/cs?searchtype=author&query=Woods%2C+J">Jess Woods</a>, 
<a href="/search/cs?searchtype=author&query=Angel%2C+S">Sebastian Angel</a>, 
<a href="/search/cs?searchtype=author&query=Polychroniadou%2C+A">Antigoni Polychroniadou</a>, 
<a href="/search/cs?searchtype=author&query=Rabin%2C+T">Tal Rabin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item904">[904]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10101" title="Abstract">arXiv:2308.10101</a> (replaced) [<a href="/pdf/2308.10101" title="Download PDF">pdf</a>, <a href="/format/2308.10101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Online Multiple Kernel Parallelizable Learning Scheme
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruiz-Moreno%2C+E">Emilio Ruiz-Moreno</a>, 
<a href="/search/cs?searchtype=author&query=Beferull-Lozano%2C+B">Baltasar Beferull-Lozano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item905">[905]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10275" title="Abstract">arXiv:2308.10275</a> (replaced) [<a href="/pdf/2308.10275" title="Download PDF">pdf</a>, <a href="/format/2308.10275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SBSM-Pro: Support Bio-sequence Machine for Proteins
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+Y">Yizheng Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhai%2C+Y">Yixiao Zhai</a>, 
<a href="/search/q-bio?searchtype=author&query=Ding%2C+Y">Yijie Ding</a>, 
<a href="/search/q-bio?searchtype=author&query=Zou%2C+Q">Quan Zou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item906">[906]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11567" title="Abstract">arXiv:2308.11567</a> (replaced) [<a href="/pdf/2308.11567" title="Download PDF">pdf</a>, <a href="/format/2308.11567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low Tensor Rank Learning of Neural Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Pellegrino%2C+A">Arthur Pellegrino</a>, 
<a href="/search/q-bio?searchtype=author&query=Cayco-Gajic%2C+N+A">N Alex Cayco-Gajic</a>, 
<a href="/search/q-bio?searchtype=author&query=Chadwick%2C+A">Angus Chadwick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The last two authors contributed equally - Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Dynamical Systems (math.DS); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item907">[907]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12486" title="Abstract">arXiv:2308.12486</a> (replaced) [<a href="/pdf/2308.12486" title="Download PDF">pdf</a>, <a href="/format/2308.12486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Brain-Inspired Sequence Learning Model based on a Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bowen Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item908">[908]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12522" title="Abstract">arXiv:2308.12522</a> (replaced) [<a href="/pdf/2308.12522" title="Download PDF">pdf</a>, <a href="/format/2308.12522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uniformly Distributed Category Prototype-Guided Vision-Language  Framework for Long-Tail Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+S">Siming Fu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaoxuan He</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+X">Xinpeng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yuchen Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hualiang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11pages, 5figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM MM2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item909">[909]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12636" title="Abstract">arXiv:2308.12636</a> (replaced) [<a href="/pdf/2308.12636" title="Download PDF">pdf</a>, <a href="/format/2308.12636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Transferability of Multimodal Adversarial Samples for  Vision-Language Pre-training Models with Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Youze Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wenbo Hu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yinpeng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanwang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+R">Richang Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
</div>
</dd>
<dt><a name="item910">[910]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12670" title="Abstract">arXiv:2308.12670</a> (replaced) [<a href="/pdf/2308.12670" title="Download PDF">pdf</a>, <a href="/format/2308.12670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal data pooling for shared learning in maintenance operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Drent%2C+C">Collin Drent</a>, 
<a href="/search/cs?searchtype=author&query=Drent%2C+M">Melvin Drent</a>, 
<a href="/search/cs?searchtype=author&query=van+Houtum%2C+G">Geert-Jan van Houtum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item911">[911]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12739" title="Abstract">arXiv:2308.12739</a> (replaced) [<a href="/pdf/2308.12739" title="Download PDF">pdf</a>, <a href="/format/2308.12739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Practical limitations on robustness and scalability of quantum Internet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Sadhu%2C+A">Abhishek Sadhu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Somayajula%2C+M+A">Meghana Ayyala Somayajula</a>, 
<a href="/search/quant-ph?searchtype=author&query=Horodecki%2C+K">Karol Horodecki</a>, 
<a href="/search/quant-ph?searchtype=author&query=Das%2C+S">Siddhartha Das</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Happy about the successful soft landing of Chandrayaan-3 on the moon by ISRO. 37 pages, 34 figures. Revised version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item912">[912]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12805" title="Abstract">arXiv:2308.12805</a> (replaced) [<a href="/pdf/2308.12805" title="Download PDF">pdf</a>, <a href="/format/2308.12805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Test Generation for Medical Rules Web Services: A Case Study  at the Cancer Registry of Norway
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laaber%2C+C">Christoph Laaber</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+T">Tao Yue</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+S">Shaukat Ali</a>, 
<a href="/search/cs?searchtype=author&query=Schwitalla%2C+T">Thomas Schwitalla</a>, 
<a href="/search/cs?searchtype=author&query=Nyg%C3%A5rd%2C+J+F">Jan F. Nyg&#xe5;rd</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 2 figures, 5 tables; accepted to the industry track of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE '23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item913">[913]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12877" title="Abstract">arXiv:2308.12877</a> (replaced) [<a href="/pdf/2308.12877" title="Download PDF">pdf</a>, <a href="/ps/2308.12877" title="Download PostScript">ps</a>, <a href="/format/2308.12877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DS4DH at #SMM4H 2023: Zero-Shot Adverse Drug Events Normalization using  Sentence Transformers and Reciprocal-Rank Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yazdani%2C+A">Anthony Yazdani</a>, 
<a href="/search/cs?searchtype=author&query=Rouhizadeh%2C+H">Hossein Rouhizadeh</a>, 
<a href="/search/cs?searchtype=author&query=Alvarez%2C+D+V">David Vicente Alvarez</a>, 
<a href="/search/cs?searchtype=author&query=Teodoro%2C+D">Douglas Teodoro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Peer-reviewed and accepted for presentation at the #SMM4H 2023 Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item914">[914]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13670" title="Abstract">arXiv:2308.13670</a> (replaced) [<a href="/e-print/2308.13670" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear Oscillation: A Novel Activation Function for Vision Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yun%2C+J">Juyoung Yun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This was an experimental paper, and i need to test more and rewrite a lot of things
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item915">[915]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14132" title="Abstract">arXiv:2308.14132</a> (replaced) [<a href="/pdf/2308.14132" title="Download PDF">pdf</a>, <a href="/format/2308.14132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Language Model Attacks with Perplexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alon%2C+G">Gabriel Alon</a>, 
<a href="/search/cs?searchtype=author&query=Kamfonas%2C+M">Michael Kamfonas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item916">[916]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15727" title="Abstract">arXiv:2308.15727</a> (replaced) [<a href="/pdf/2308.15727" title="Download PDF">pdf</a>, <a href="/format/2308.15727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying and Analyzing Entity-level Memorization in Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhenhong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+J">Jiuyang Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaomeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+S">Sen Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item917">[917]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16466" title="Abstract">arXiv:2308.16466</a> (replaced) [<a href="/pdf/2308.16466" title="Download PDF">pdf</a>, <a href="/format/2308.16466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Sampling Meta SAM: Enhancing Few-shot Medical Image Segmentation  with Meta-Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Leng%2C+T">Tianang Leng</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kun Han</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaohui Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item918">[918]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00287" title="Abstract">arXiv:2309.00287</a> (replaced) [<a href="/pdf/2309.00287" title="Download PDF">pdf</a>, <a href="/format/2309.00287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Diffusion EM: a diffusion model for blind inverse problems with  application to deconvolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laroche%2C+C">Charles Laroche</a>, 
<a href="/search/cs?searchtype=author&query=Almansa%2C+A">Andr&#xe9;s Almansa</a>, 
<a href="/search/cs?searchtype=author&query=Coupete%2C+E">Eva Coupete</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item919">[919]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00312" title="Abstract">arXiv:2309.00312</a> (replaced) [<a href="/pdf/2309.00312" title="Download PDF">pdf</a>, <a href="/ps/2309.00312" title="Download PostScript">ps</a>, <a href="/format/2309.00312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Topic Modeling for Determinants of Divergent Report Results  Applied to Macular Degeneration Studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jacaruso%2C+L+C">Lucas Cassiel Jacaruso</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item920">[920]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00738" title="Abstract">arXiv:2309.00738</a> (replaced) [<a href="/pdf/2309.00738" title="Download PDF">pdf</a>, <a href="/format/2309.00738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking the Power of Graph Canonization in Graph Representation  Learning with Stability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zehao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Muhan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Payne%2C+P+R+O">Philip R.O. Payne</a>, 
<a href="/search/cs?searchtype=author&query=Province%2C+M+A">Michael A Province</a>, 
<a href="/search/cs?searchtype=author&query=Cruchaga%2C+C">Carlos Cruchaga</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tianyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fuhai Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yixin Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item921">[921]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01539" title="Abstract">arXiv:2309.01539</a> (replaced) [<a href="/pdf/2309.01539" title="Download PDF">pdf</a>, <a href="/format/2309.01539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TSTTC: A Large-Scale Dataset for Time-to-Contact Estimation in Driving  Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yuheng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zehao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Naiyan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiaojie Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item922">[922]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01950" title="Abstract">arXiv:2309.01950</a> (replaced) [<a href="/pdf/2309.01950" title="Download PDF">pdf</a>, <a href="/format/2309.01950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RADIO: Reference-Agnostic Dubbing Video Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongyeun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Chaewon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Sangjoon Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+J">Jaejun Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+G">Gyeong-Moon Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item923">[923]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02334" title="Abstract">arXiv:2309.02334</a> (replaced) [<a href="/pdf/2309.02334" title="Download PDF">pdf</a>, <a href="/format/2309.02334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PolyLUT: Learning Piecewise Polynomials for Ultra-Low Latency FPGA  LUT-based Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Andronic%2C+M">Marta Andronic</a>, 
<a href="/search/cs?searchtype=author&query=Constantinides%2C+G+A">George A. Constantinides</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item924">[924]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03329" title="Abstract">arXiv:2309.03329</a> (replaced) [<a href="/pdf/2309.03329" title="Download PDF">pdf</a>, <a href="/format/2309.03329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MEGANet: Multi-Scale Edge-Guided Attention Network for Weak Boundary  Polyp Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bui%2C+N">Nhat-Tan Bui</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+D">Dinh-Hieu Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q">Quang-Thuc Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+M">Minh-Triet Tran</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+N">Ngan Le</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item925">[925]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03374" title="Abstract">arXiv:2309.03374</a> (replaced) [<a href="/pdf/2309.03374" title="Download PDF">pdf</a>, <a href="/format/2309.03374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics Informed Neural Networks for Modeling of 3D Flow-Thermal  Problems with Sparse Domain Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhatnagar%2C+S">Saakaar Bhatnagar</a>, 
<a href="/search/cs?searchtype=author&query=Comerford%2C+A">Andrew Comerford</a>, 
<a href="/search/cs?searchtype=author&query=Banaeizadeh%2C+A">Araz Banaeizadeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item926">[926]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03412" title="Abstract">arXiv:2309.03412</a> (replaced) [<a href="/pdf/2309.03412" title="Download PDF">pdf</a>, <a href="/format/2309.03412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Base to Conversational: Japanese Instruction Dataset and Tuning  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+M">Masahiro Suzuki</a>, 
<a href="/search/cs?searchtype=author&query=Hirano%2C+M">Masanori Hirano</a>, 
<a href="/search/cs?searchtype=author&query=Sakaji%2C+H">Hiroki Sakaji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 1 figure, 2 tables. The paper is a camera-ready version of IEEE BigData 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item927">[927]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03734" title="Abstract">arXiv:2309.03734</a> (replaced) [<a href="/pdf/2309.03734" title="Download PDF">pdf</a>, <a href="/format/2309.03734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClusterFusion: Leveraging Radar Spatial Features for Radar-Camera 3D  Object Detection in Autonomous Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kurniawan%2C+I+T">Irfan Tito Kurniawan</a>, 
<a href="/search/cs?searchtype=author&query=Trilaksono%2C+B+R">Bambang Riyanto Trilaksono</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in IEEE Access
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item928">[928]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05259" title="Abstract">arXiv:2309.05259</a> (replaced) [<a href="/pdf/2309.05259" title="Download PDF">pdf</a>, <a href="/format/2309.05259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A physics-informed and attention-based graph learning approach for  regional electric vehicle charging demand prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+H">Haohao Qu</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+H">Haoxuan Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+L">Linlin You</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. This work has been submitted to the IEEE Transactions on ITS for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item929">[929]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05378" title="Abstract">arXiv:2309.05378</a> (replaced) [<a href="/pdf/2309.05378" title="Download PDF">pdf</a>, <a href="/format/2309.05378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Steps Towards Satisficing Distributed Dynamic Team Trust
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hunt%2C+E+R">Edmund R. Hunt</a>, 
<a href="/search/cs?searchtype=author&query=Baber%2C+C">Chris Baber</a>, 
<a href="/search/cs?searchtype=author&query=Sobhani%2C+M">Mehdi Sobhani</a>, 
<a href="/search/cs?searchtype=author&query=Milivojevic%2C+S">Sanja Milivojevic</a>, 
<a href="/search/cs?searchtype=author&query=Yusuf%2C+S">Sagir Yusuf</a>, 
<a href="/search/cs?searchtype=author&query=Musolesi%2C+M">Mirco Musolesi</a>, 
<a href="/search/cs?searchtype=author&query=Waterson%2C+P">Patrick Waterson</a>, 
<a href="/search/cs?searchtype=author&query=Maynard%2C+S">Sally Maynard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item930">[930]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05454" title="Abstract">arXiv:2309.05454</a> (replaced) [<a href="/pdf/2309.05454" title="Download PDF">pdf</a>, <a href="/format/2309.05454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flesch or Fumble? Evaluating Readability Standard Alignment of  Instruction-Tuned Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Imperial%2C+J+M">Joseph Marvin Imperial</a>, 
<a href="/search/cs?searchtype=author&query=Madabushi%2C+H+T">Harish Tayyar Madabushi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Final camera-ready for EMNLP GEM Workshop 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item931">[931]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06038" title="Abstract">arXiv:2309.06038</a> (replaced) [<a href="/pdf/2309.06038" title="Download PDF">pdf</a>, <a href="/format/2309.06038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Score-based Grasping Primitive for Human-assisting Dexterous  Grasping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianhao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Mingdong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Y">Yunchong Gan</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item932">[932]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06067" title="Abstract">arXiv:2309.06067</a> (replaced) [<a href="/pdf/2309.06067" title="Download PDF">pdf</a>, <a href="/ps/2309.06067" title="Download PostScript">ps</a>, <a href="/format/2309.06067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Neural Representation for MRI Parallel Imaging Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Yusheng Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jianan Liu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+X">Xiling Liu</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+T">Tao Huang</a>, 
<a href="/search/eess?searchtype=author&query=Lv%2C+Z">Zhihan Lv</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)

</div>
</div>
</dd>
<dt><a name="item933">[933]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07760" title="Abstract">arXiv:2309.07760</a> (replaced) [<a href="/pdf/2309.07760" title="Download PDF">pdf</a>, <a href="/ps/2309.07760" title="Download PostScript">ps</a>, <a href="/format/2309.07760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PRE: Vision-Language Prompt Learning with Reparameterization Encoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Minh%2C+A+P+T">Anh Pham Thi Minh</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+A+D">An Duc Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Tzimiropoulos%2C+G">Georgios Tzimiropoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages excluding References and Appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item934">[934]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07906" title="Abstract">arXiv:2309.07906</a> (replaced) [<a href="/pdf/2309.07906" title="Download PDF">pdf</a>, <a href="/format/2309.07906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Image Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhengqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Tucker%2C+R">Richard Tucker</a>, 
<a href="/search/cs?searchtype=author&query=Snavely%2C+N">Noah Snavely</a>, 
<a href="/search/cs?searchtype=author&query=Holynski%2C+A">Aleksander Holynski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="http://generative-dynamics.github.io">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item935">[935]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08138" title="Abstract">arXiv:2309.08138</a> (replaced) [<a href="/pdf/2309.08138" title="Download PDF">pdf</a>, <a href="/format/2309.08138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Find What You Want: Learning Demand-conditioned Object Attribute Space  for Demand-driven Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongcheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+A+G+H">Andy Guan Hong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Mingdong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023; Project page:<a href="https://sites.google.com/view/demand-driven-navigation">this https URL</a>; Code: <a href="https://github.com/whcpumpkin/Demand-driven-navigation">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item936">[936]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08549" title="Abstract">arXiv:2309.08549</a> (replaced) [<a href="/pdf/2309.08549" title="Download PDF">pdf</a>, <a href="/format/2309.08549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HINT: Healthy Influential-Noise based Training to Defend against Data  Poisoning Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van%2C+M">Minh-Hao Van</a>, 
<a href="/search/cs?searchtype=author&query=Carey%2C+A+N">Alycia N. Carey</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xintao Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item937">[937]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09319" title="Abstract">arXiv:2309.09319</a> (replaced) [<a href="/pdf/2309.09319" title="Download PDF">pdf</a>, <a href="/format/2309.09319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Learning for Semantic Segmentation with Multi-class Label Query
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hwang%2C+S">Sehyun Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sohyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hoyoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+M">Minhyeon Oh</a>, 
<a href="/search/cs?searchtype=author&query=Ok%2C+J">Jungseul Ok</a>, 
<a href="/search/cs?searchtype=author&query=Kwak%2C+S">Suha Kwak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item938">[938]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09812" title="Abstract">arXiv:2309.09812</a> (replaced) [<a href="/pdf/2309.09812" title="Download PDF">pdf</a>, <a href="/format/2309.09812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> R2GenGPT: Radiology Report Generation with Frozen LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhanyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingqiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Luping Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by meta-radiology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item939">[939]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10160" title="Abstract">arXiv:2309.10160</a> (replaced) [<a href="/pdf/2309.10160" title="Download PDF">pdf</a>, <a href="/format/2309.10160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RadOnc-GPT: A Large Language Model for Radiation Oncology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Liu%2C+Z">Zhengliang Liu</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+P">Peilong Wang</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+Y">Yiwei Li</a>, 
<a href="/search/physics?searchtype=author&query=Holmes%2C+J">Jason Holmes</a>, 
<a href="/search/physics?searchtype=author&query=Shu%2C+P">Peng Shu</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+L">Lian Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+C">Chenbin Liu</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+N">Ninghao Liu</a>, 
<a href="/search/physics?searchtype=author&query=Zhu%2C+D">Dajiang Zhu</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+Q">Quanzheng Li</a>, 
<a href="/search/physics?searchtype=author&query=Patel%2C+S+H">Samir H. Patel</a>, 
<a href="/search/physics?searchtype=author&query=Sio%2C+T+T">Terence T. Sio</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+T">Tianming Liu</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+W">Wei Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item940">[940]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13190" title="Abstract">arXiv:2309.13190</a> (replaced) [<a href="/pdf/2309.13190" title="Download PDF">pdf</a>, <a href="/format/2309.13190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial-frequency channels, shape bias, and adversarial robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Subramanian%2C+A">Ajay Subramanian</a>, 
<a href="/search/cs?searchtype=author&query=Sizikova%2C+E">Elena Sizikova</a>, 
<a href="/search/cs?searchtype=author&query=Majaj%2C+N+J">Najib J. Majaj</a>, 
<a href="/search/cs?searchtype=author&query=Pelli%2C+D+G">Denis G. Pelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Neural Information Processing Systems (NeurIPS) 2023 (Oral Presentation). Camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item941">[941]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13836" title="Abstract">arXiv:2309.13836</a> (replaced) [<a href="/e-print/2309.13836" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Energy Efficiency of THz-NOMA enhanced UAV Cooperative Network  with SWIPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jalali%2C+J">Jalal Jalali</a>, 
<a href="/search/cs?searchtype=author&query=Khalili%2C+A">Ata Khalili</a>, 
<a href="/search/cs?searchtype=author&query=Tabassum%2C+H">Hina Tabassum</a>, 
<a href="/search/cs?searchtype=author&query=Berkvens%2C+R">Rafael Berkvens</a>, 
<a href="/search/cs?searchtype=author&query=Famaey%2C+J">Jeroen Famaey</a>, 
<a href="/search/cs?searchtype=author&query=Saad%2C+W">Walid Saad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We are improving the work to address reviewers comments at the moment
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item942">[942]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14008" title="Abstract">arXiv:2309.14008</a> (replaced) [<a href="/pdf/2309.14008" title="Download PDF">pdf</a>, <a href="/format/2309.14008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Carrier Aggregation Enabled Integrated Sensing and Communication Signal  Design and Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wei%2C+Z">Zhiqing Wei</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+H">Haotian Liu</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+X">Xinyi Yang</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+W">Wangjun Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+H">Huici Wu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xingwang Li</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+Z">Zhiyong Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item943">[943]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14032" title="Abstract">arXiv:2309.14032</a> (replaced) [<a href="/pdf/2309.14032" title="Download PDF">pdf</a>, <a href="/format/2309.14032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepACO: Neural-enhanced Ant Systems for Combinatorial Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Haoran Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiarui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhiguang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+H">Helan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item944">[944]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14118" title="Abstract">arXiv:2309.14118</a> (replaced) [<a href="/pdf/2309.14118" title="Download PDF">pdf</a>, <a href="/format/2309.14118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultiModN- Multimodal, Multi-Task, Interpretable Modular Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Swamy%2C+V">Vinitra Swamy</a>, 
<a href="/search/cs?searchtype=author&query=Satayeva%2C+M">Malika Satayeva</a>, 
<a href="/search/cs?searchtype=author&query=Frej%2C+J">Jibril Frej</a>, 
<a href="/search/cs?searchtype=author&query=Bossy%2C+T">Thierry Bossy</a>, 
<a href="/search/cs?searchtype=author&query=Vogels%2C+T">Thijs Vogels</a>, 
<a href="/search/cs?searchtype=author&query=Jaggi%2C+M">Martin Jaggi</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%A4ser%2C+T">Tanja K&#xe4;ser</a>, 
<a href="/search/cs?searchtype=author&query=Hartley%2C+M">Mary-Anne Hartley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a full paper at NeurIPS 2023 in New Orleans, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item945">[945]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14500" title="Abstract">arXiv:2309.14500</a> (replaced) [<a href="/pdf/2309.14500" title="Download PDF">pdf</a>, <a href="/format/2309.14500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessment of a new GeoAI foundation model for flood inundation mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenwen Li</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hyunho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sizhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+C">Chia-Yu Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Arundel%2C+S+T">Samantha T. Arundel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, Accepted for the 6th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item946">[946]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15533" title="Abstract">arXiv:2309.15533</a> (replaced) [<a href="/pdf/2309.15533" title="Download PDF">pdf</a>, <a href="/format/2309.15533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Quantification via Neural Posterior Principal Components
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nehme%2C+E">Elias Nehme</a>, 
<a href="/search/cs?searchtype=author&query=Yair%2C+O">Omer Yair</a>, 
<a href="/search/cs?searchtype=author&query=Michaeli%2C+T">Tomer Michaeli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Camera Ready, interactive examples at <a href="https://eliasnehme.github.io/NPPC/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item947">[947]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15669" title="Abstract">arXiv:2309.15669</a> (replaced) [<a href="/pdf/2309.15669" title="Download PDF">pdf</a>, <a href="/format/2309.15669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Computational Entanglement of Distant Features in Adversarial  Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">YenLung Lai</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xingbo Dong</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhe Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item948">[948]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15702" title="Abstract">arXiv:2309.15702</a> (replaced) [<a href="/pdf/2309.15702" title="Download PDF">pdf</a>, <a href="/format/2309.15702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SGRec3D: Self-Supervised 3D Scene Graph Learning via Object-Level Scene  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koch%2C+S">Sebastian Koch</a>, 
<a href="/search/cs?searchtype=author&query=Hermosilla%2C+P">Pedro Hermosilla</a>, 
<a href="/search/cs?searchtype=author&query=Vaskevicius%2C+N">Narunas Vaskevicius</a>, 
<a href="/search/cs?searchtype=author&query=Colosi%2C+M">Mirco Colosi</a>, 
<a href="/search/cs?searchtype=author&query=Ropinski%2C+T">Timo Ropinski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024, Project page: <a href="https://kochsebastian.com/sgrec3d">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item949">[949]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15751" title="Abstract">arXiv:2309.15751</a> (replaced) [<a href="/pdf/2309.15751" title="Download PDF">pdf</a>, <a href="/format/2309.15751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InfraParis: A multi-modal and multi-task autonomous driving dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Franchi%2C+G">Gianni Franchi</a>, 
<a href="/search/cs?searchtype=author&query=Hariat%2C+M">Marwane Hariat</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xuanlong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Belkhir%2C+N">Nacim Belkhir</a>, 
<a href="/search/cs?searchtype=author&query=Manzanera%2C+A">Antoine Manzanera</a>, 
<a href="/search/cs?searchtype=author&query=Filliat%2C+D">David Filliat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures. Accepted at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item950">[950]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16223" title="Abstract">arXiv:2309.16223</a> (replaced) [<a href="/pdf/2309.16223" title="Download PDF">pdf</a>, <a href="/format/2309.16223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GInX-Eval: Towards In-Distribution Evaluation of Graph Neural Network  Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amara%2C+K">Kenza Amara</a>, 
<a href="/search/cs?searchtype=author&query=El-Assady%2C+M">Mennatallah El-Assady</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+R">Rex Ying</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint, Submitted to ICLR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item951">[951]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16873" title="Abstract">arXiv:2309.16873</a> (replaced) [<a href="/pdf/2309.16873" title="Download PDF">pdf</a>, <a href="/format/2309.16873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Object Interactions with Behavior Primitives: An Application  in Stowing Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haonan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yilong Niu</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+K">Kaiwen Hong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuijing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yixuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunzhu Li</a>, 
<a href="/search/cs?searchtype=author&query=Driggs-Campbell%2C+K">Katherine Driggs-Campbell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://haonan16.github.io/stow_page/">this https URL</a> 16 pages, 9 figures, Accepted for an oral presentation at CoRL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item952">[952]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17076" title="Abstract">arXiv:2309.17076</a> (replaced) [<a href="/pdf/2309.17076" title="Download PDF">pdf</a>, <a href="/format/2309.17076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benefits of mirror weight symmetry for 3D mesh segmentation in  biomedical applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dordiuk%2C+V">Vladislav Dordiuk</a>, 
<a href="/search/eess?searchtype=author&query=Dzhigil%2C+M">Maksim Dzhigil</a>, 
<a href="/search/eess?searchtype=author&query=Ushenin%2C+K">Konstantin Ushenin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> was sent to IEEE conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item953">[953]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17425" title="Abstract">arXiv:2309.17425</a> (replaced) [<a href="/pdf/2309.17425" title="Download PDF">pdf</a>, <a href="/format/2309.17425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Filtering Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+A">Alex Fang</a>, 
<a href="/search/cs?searchtype=author&query=Jose%2C+A+M">Albin Madappally Jose</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Amit Jain</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+L">Ludwig Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Toshev%2C+A">Alexander Toshev</a>, 
<a href="/search/cs?searchtype=author&query=Shankar%2C+V">Vaishaal Shankar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item954">[954]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00723" title="Abstract">arXiv:2310.00723</a> (replaced) [<a href="/pdf/2310.00723" title="Download PDF">pdf</a>, <a href="/format/2310.00723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HOH: Markerless Multimodal Human-Object-Human Handover Dataset with  Large Object Count
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wiederhold%2C+N">Noah Wiederhold</a>, 
<a href="/search/cs?searchtype=author&query=Megyeri%2C+A">Ava Megyeri</a>, 
<a href="/search/cs?searchtype=author&query=Paris%2C+D">DiMaggio Paris</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Sean Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+N+K">Natasha Kholgade Banerjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Datasets and Benchmarks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item955">[955]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00836" title="Abstract">arXiv:2310.00836</a> (replaced) [<a href="/pdf/2310.00836" title="Download PDF">pdf</a>, <a href="/format/2310.00836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards LogiGLUE: A Brief Survey and A Benchmark for Analyzing Logical  Reasoning Capabilities of Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+M">Man Luo</a>, 
<a href="/search/cs?searchtype=author&query=Kumbhar%2C+S">Shrinidhi Kumbhar</a>, 
<a href="/search/cs?searchtype=author&query=shen%2C+M">Ming shen</a>, 
<a href="/search/cs?searchtype=author&query=Parmar%2C+M">Mihir Parmar</a>, 
<a href="/search/cs?searchtype=author&query=Varshney%2C+N">Neeraj Varshney</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+P">Pratyay Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Aditya%2C+S">Somak Aditya</a>, 
<a href="/search/cs?searchtype=author&query=Baral%2C+C">Chitta Baral</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item956">[956]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01210" title="Abstract">arXiv:2310.01210</a> (replaced) [<a href="/pdf/2310.01210" title="Download PDF">pdf</a>, <a href="/format/2310.01210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Robust Cardiac Segmentation using Graph Convolutional Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Van+De+Vyver%2C+G">Gilles Van De Vyver</a>, 
<a href="/search/eess?searchtype=author&query=Thomas%2C+S">Sarina Thomas</a>, 
<a href="/search/eess?searchtype=author&query=Ben-Yosef%2C+G">Guy Ben-Yosef</a>, 
<a href="/search/eess?searchtype=author&query=Olaisen%2C+S+H">Sindre Hellum Olaisen</a>, 
<a href="/search/eess?searchtype=author&query=Dalen%2C+H">H&#xe5;vard Dalen</a>, 
<a href="/search/eess?searchtype=author&query=L%C3%B8vstakken%2C+L">Lasse L&#xf8;vstakken</a>, 
<a href="/search/eess?searchtype=author&query=Smistad%2C+E">Erik Smistad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item957">[957]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01352" title="Abstract">arXiv:2310.01352</a> (replaced) [<a href="/pdf/2310.01352" title="Download PDF">pdf</a>, <a href="/format/2310.01352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RA-DIT: Retrieval-Augmented Dual Instruction Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+X+V">Xi Victoria Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xilun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingda Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Weijia Shi</a>, 
<a href="/search/cs?searchtype=author&query=Lomeli%2C+M">Maria Lomeli</a>, 
<a href="/search/cs?searchtype=author&query=James%2C+R">Rich James</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+P">Pedro Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Kahn%2C+J">Jacob Kahn</a>, 
<a href="/search/cs?searchtype=author&query=Szilvasy%2C+G">Gergely Szilvasy</a>, 
<a href="/search/cs?searchtype=author&query=Lewis%2C+M">Mike Lewis</a>, 
<a href="/search/cs?searchtype=author&query=Zettlemoyer%2C+L">Luke Zettlemoyer</a>, 
<a href="/search/cs?searchtype=author&query=Yih%2C+S">Scott Yih</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v3: Add the performance of full RA-DIT model on commonsense reasoning tasks 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item958">[958]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01381" title="Abstract">arXiv:2310.01381</a> (replaced) [<a href="/pdf/2310.01381" title="Download PDF">pdf</a>, <a href="/format/2310.01381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffAR: Denoising Diffusion Autoregressive Model for Raw Speech Waveform  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Benita%2C+R">Roi Benita</a>, 
<a href="/search/cs?searchtype=author&query=Elad%2C+M">Michael Elad</a>, 
<a href="/search/cs?searchtype=author&query=Keshet%2C+J">Joseph Keshet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item959">[959]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01775" title="Abstract">arXiv:2310.01775</a> (replaced) [<a href="/pdf/2310.01775" title="Download PDF">pdf</a>, <a href="/format/2310.01775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STAMP: Differentiable Task and Motion Planning via Stein Variational  Gradient Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yewon Lee</a> (1), 
<a href="/search/cs?searchtype=author&query=Huang%2C+P">Philip Huang</a> (2), 
<a href="/search/cs?searchtype=author&query=Jatavallabhula%2C+K+M">Krishna Murthy Jatavallabhula</a> (3), 
<a href="/search/cs?searchtype=author&query=Li%2C+A+Z">Andrew Z. Li</a> (1), 
<a href="/search/cs?searchtype=author&query=Damken%2C+F">Fabian Damken</a> (1 and 4), 
<a href="/search/cs?searchtype=author&query=Heiden%2C+E">Eric Heiden</a> (5), 
<a href="/search/cs?searchtype=author&query=Smith%2C+K">Kevin Smith</a> (3), 
<a href="/search/cs?searchtype=author&query=Nowrouzezahrai%2C+D">Derek Nowrouzezahrai</a> (6), 
<a href="/search/cs?searchtype=author&query=Ramos%2C+F">Fabio Ramos</a> (5 and 7), 
<a href="/search/cs?searchtype=author&query=Shkurti%2C+F">Florian Shkurti</a> (1) ((1) University of Toronto, (2) Carnegie Mellon University, (3) Massachusetts Institute of Technology, (4) Technische Universitat Darmstadt, (5) NVIDIA, (6) McGill University, (7) University of Sydney)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures, Learning Effective Abstractions for Planning (LEAP) Workshop at CoRL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item960">[960]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01852" title="Abstract">arXiv:2310.01852</a> (replaced) [<a href="/pdf/2310.01852" title="Download PDF">pdf</a>, <a href="/format/2310.01852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LanguageBind: Extending Video-Language Pretraining to N-modality by  Language-based Semantic Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Bin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Bin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+M">Munan Ning</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jiaxi Cui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">HongFa Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+Y">Yatian Pang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wenhao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junwu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wancai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhifeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Li Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review as a conference paper at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item961">[961]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01992" title="Abstract">arXiv:2310.01992</a> (replaced) [<a href="/pdf/2310.01992" title="Download PDF">pdf</a>, <a href="/format/2310.01992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Acyclic Petri and Workflow Nets with Resets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chistikov%2C+D">Dmitry Chistikov</a>, 
<a href="/search/cs?searchtype=author&query=Czerwi%C5%84ski%2C+W">Wojciech Czerwi&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Hofman%2C+P">Piotr Hofman</a>, 
<a href="/search/cs?searchtype=author&query=Mazowiecki%2C+F">Filip Mazowiecki</a>, 
<a href="/search/cs?searchtype=author&query=Sinclair-Banks%2C+H">Henry Sinclair-Banks</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint for FSTTCS'23 containing 28 pages and 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item962">[962]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02025" title="Abstract">arXiv:2310.02025</a> (replaced) [<a href="/pdf/2310.02025" title="Download PDF">pdf</a>, <a href="/format/2310.02025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepZero: Scaling up Zeroth-Order Optimization for Deep Model Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Aochuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yimeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jinghan Jia</a>, 
<a href="/search/cs?searchtype=author&query=Diffenderfer%2C+J">James Diffenderfer</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiancheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Parasyris%2C+K">Konstantinos Parasyris</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yihua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kailkhura%2C+B">Bhavya Kailkhura</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sijia Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item963">[963]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02066" title="Abstract">arXiv:2310.02066</a> (replaced) [<a href="/pdf/2310.02066" title="Download PDF">pdf</a>, <a href="/format/2310.02066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> De Novo Drug Design with Joint Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Izdebski%2C+A">Adam Izdebski</a>, 
<a href="/search/cs?searchtype=author&query=Weglarz-Tomczak%2C+E">Ewelina Weglarz-Tomczak</a>, 
<a href="/search/cs?searchtype=author&query=Szczurek%2C+E">Ewa Szczurek</a>, 
<a href="/search/cs?searchtype=author&query=Tomczak%2C+J+M">Jakub M. Tomczak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added acknowledgments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item964">[964]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02911" title="Abstract">arXiv:2310.02911</a> (replaced) [<a href="/pdf/2310.02911" title="Download PDF">pdf</a>, <a href="/format/2310.02911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deciphering the Crypto-shopper: Knowledge and Preferences of Consumers  Using Cryptocurrencies for Purchases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Silenzi%2C+M">Massimiliano Silenzi</a>, 
<a href="/search/cs?searchtype=author&query=Cabuk%2C+U+C">Umut Can Cabuk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Cryptorefills Labs Research Paper. 13 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computational Engineering, Finance, and Science (cs.CE); Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item965">[965]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03355" title="Abstract">arXiv:2310.03355</a> (replaced) [<a href="/pdf/2310.03355" title="Download PDF">pdf</a>, <a href="/ps/2310.03355" title="Download PostScript">ps</a>, <a href="/format/2310.03355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Note on the LogRank Conjecture in Communication Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grolmusz%2C+V">Vince Grolmusz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Some typos were corrected in this version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item966">[966]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03378" title="Abstract">arXiv:2310.03378</a> (replaced) [<a href="/pdf/2310.03378" title="Download PDF">pdf</a>, <a href="/format/2310.03378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine learning the interaction network in coupled dynamical systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bhure%2C+P+R">Pawan R. Bhure</a>, 
<a href="/search/math?searchtype=author&query=Santhanam%2C+M+S">M. S. Santhanam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item967">[967]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03525" title="Abstract">arXiv:2310.03525</a> (replaced) [<a href="/pdf/2310.03525" title="Download PDF">pdf</a>, <a href="/format/2310.03525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> V2X Cooperative Perception for Autonomous Driving: Recent Advances and  Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+C">Dinh C. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Azghadi%2C+M+R">Mostafa Rahimi Azghadi</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yuxuan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Q">Qing-Long Han</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Sumei Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 6 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item968">[968]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03597" title="Abstract">arXiv:2310.03597</a> (replaced) [<a href="/pdf/2310.03597" title="Download PDF">pdf</a>, <a href="/format/2310.03597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sampling via Gradient Flows in the Space of Probability Measures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chen%2C+Y">Yifan Chen</a>, 
<a href="/search/stat?searchtype=author&query=Huang%2C+D+Z">Daniel Zhengyu Huang</a>, 
<a href="/search/stat?searchtype=author&query=Huang%2C+J">Jiaoyang Huang</a>, 
<a href="/search/stat?searchtype=author&query=Reich%2C+S">Sebastian Reich</a>, 
<a href="/search/stat?searchtype=author&query=Stuart%2C+A+M">Andrew M Stuart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Related to <a href="/abs/2302.11024">arXiv:2302.11024</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Dynamical Systems (math.DS); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item969">[969]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03906" title="Abstract">arXiv:2310.03906</a> (replaced) [<a href="/pdf/2310.03906" title="Download PDF">pdf</a>, <a href="/ps/2310.03906" title="Download PostScript">ps</a>, <a href="/format/2310.03906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PyDCM: Custom Data Center Models with Reinforcement Learning for  Sustainability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naug%2C+A">Avisek Naug</a>, 
<a href="/search/cs?searchtype=author&query=Guillen%2C+A">Antonio Guillen</a>, 
<a href="/search/cs?searchtype=author&query=Guti%C3%A9rrez%2C+R+L">Ricardo Luna Guti&#xe9;rrez</a>, 
<a href="/search/cs?searchtype=author&query=Gundecha%2C+V">Vineet Gundecha</a>, 
<a href="/search/cs?searchtype=author&query=Markovikj%2C+D">Dejan Markovikj</a>, 
<a href="/search/cs?searchtype=author&query=Kashyap%2C+L+D">Lekhapriya Dheeraj Kashyap</a>, 
<a href="/search/cs?searchtype=author&query=Krause%2C+L">Lorenz Krause</a>, 
<a href="/search/cs?searchtype=author&query=Ghorbanpour%2C+S">Sahand Ghorbanpour</a>, 
<a href="/search/cs?searchtype=author&query=Mousavi%2C+S">Sajad Mousavi</a>, 
<a href="/search/cs?searchtype=author&query=Babu%2C+A+R">Ashwin Ramesh Babu</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S">Soumyendu Sarkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 10th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation (BuildSys '23), November 15-16, 2023, Istanbul, Turkey
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item970">[970]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03912" title="Abstract">arXiv:2310.03912</a> (replaced) [<a href="/pdf/2310.03912" title="Download PDF">pdf</a>, <a href="/ps/2310.03912" title="Download PostScript">ps</a>, <a href="/format/2310.03912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RTDK-BO: High Dimensional Bayesian Optimization with Reinforced  Transformer Deep kernels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shmakov%2C+A">Alexander Shmakov</a>, 
<a href="/search/cs?searchtype=author&query=Naug%2C+A">Avisek Naug</a>, 
<a href="/search/cs?searchtype=author&query=Gundecha%2C+V">Vineet Gundecha</a>, 
<a href="/search/cs?searchtype=author&query=Ghorbanpour%2C+S">Sahand Ghorbanpour</a>, 
<a href="/search/cs?searchtype=author&query=Gutierrez%2C+R+L">Ricardo Luna Gutierrez</a>, 
<a href="/search/cs?searchtype=author&query=Babu%2C+A+R">Ashwin Ramesh Babu</a>, 
<a href="/search/cs?searchtype=author&query=Guillen%2C+A">Antonio Guillen</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S">Soumyendu Sarkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE 19th International Conference on Automation Science and Engineering (CASE)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item971">[971]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04017" title="Abstract">arXiv:2310.04017</a> (replaced) [<a href="/pdf/2310.04017" title="Download PDF">pdf</a>, <a href="/format/2310.04017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PGraphDTA: Improving Drug Target Interaction Prediction using Protein  Language Models and Contact Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bal%2C+R">Rakesh Bal</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yijia Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AI for Science Workshop, NeurIPS 2023. 11 pages, 5 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item972">[972]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04027" title="Abstract">arXiv:2310.04027</a> (replaced) [<a href="/pdf/2310.04027" title="Download PDF">pdf</a>, <a href="/format/2310.04027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Financial Sentiment Analysis via Retrieval Augmented Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Boyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongyang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Babar%2C+A">Ali Babar</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao-Yang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM International Conference on AI in Finance (ICAIF) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Statistical Finance (q-fin.ST); Trading and Market Microstructure (q-fin.TR)

</div>
</div>
</dd>
<dt><a name="item973">[973]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04755" title="Abstract">arXiv:2310.04755</a> (replaced) [<a href="/pdf/2310.04755" title="Download PDF">pdf</a>, <a href="/format/2310.04755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pairwise GUI Dataset Construction Between Android Phones and Tablets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Han Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+H">Haolan Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yujin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Di Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures. arXiv admin note: substantial text overlap with <a href="/abs/2307.13225">arXiv:2307.13225</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item974">[974]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04963" title="Abstract">arXiv:2310.04963</a> (replaced) [<a href="/pdf/2310.04963" title="Download PDF">pdf</a>, <a href="/format/2310.04963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM4VV: Developing LLM-Driven Testsuite for Compiler Validation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Munley%2C+C">Christian Munley</a>, 
<a href="/search/cs?searchtype=author&query=Jarmusch%2C+A">Aaron Jarmusch</a>, 
<a href="/search/cs?searchtype=author&query=Chandrasekaran%2C+S">Sunita Chandrasekaran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item975">[975]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05199" title="Abstract">arXiv:2310.05199</a> (replaced) [<a href="/pdf/2310.05199" title="Download PDF">pdf</a>, <a href="/format/2310.05199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Loose lips sink ships: Mitigating Length Bias in Reinforcement Learning  from Human Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Wei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Rui Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+W">Wenyu Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+S">Shihan Dou</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+T">Tao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 findings, Length Bias in RLHF, Mitigate bias in reward modeling
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item976">[976]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05654" title="Abstract">arXiv:2310.05654</a> (replaced) [<a href="/pdf/2310.05654" title="Download PDF">pdf</a>, <a href="/format/2310.05654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> No Token Left Behind: Efficient Vision Transformer via Dynamic Token  Idling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xuwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changlin Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yudong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiaojun Chang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiajun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sen Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AJCAI2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item977">[977]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05764" title="Abstract">arXiv:2310.05764</a> (replaced) [<a href="/pdf/2310.05764" title="Download PDF">pdf</a>, <a href="/format/2310.05764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harmonic Self-Conditioned Flow Matching for Multi-Ligand Docking and  Binding Site Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=St%C3%A4rk%2C+H">Hannes St&#xe4;rk</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+B">Bowen Jing</a>, 
<a href="/search/cs?searchtype=author&query=Barzilay%2C+R">Regina Barzilay</a>, 
<a href="/search/cs?searchtype=author&query=Jaakkola%2C+T">Tommi Jaakkola</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review. 25 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item978">[978]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06298" title="Abstract">arXiv:2310.06298</a> (replaced) [<a href="/pdf/2310.06298" title="Download PDF">pdf</a>, <a href="/format/2310.06298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Just-in-Time Flaky Test Detection via Abstracted Failure Symptom  Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+G">Gabin An</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+J">Juyeon Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Bach%2C+T">Thomas Bach</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Jingun Hong</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+S">Shin Yoo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item979">[979]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06338" title="Abstract">arXiv:2310.06338</a> (replaced) [<a href="/pdf/2310.06338" title="Download PDF">pdf</a>, <a href="/format/2310.06338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Better Safe than Sorry: Recovering after Adversarial Majority
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sridhar%2C+S">Srivatsan Sridhar</a>, 
<a href="/search/cs?searchtype=author&query=Zindros%2C+D">Dionysis Zindros</a>, 
<a href="/search/cs?searchtype=author&query=Tse%2C+D">David Tse</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item980">[980]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07749" title="Abstract">arXiv:2310.07749</a> (replaced) [<a href="/pdf/2310.07749" title="Download PDF">pdf</a>, <a href="/format/2310.07749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenLEAF: Open-Domain Interleaved Image-Text Generation and Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+J">Jie An</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhengyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kevin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zicheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lijuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiebo Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item981">[981]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07915" title="Abstract">arXiv:2310.07915</a> (replaced) [<a href="/pdf/2310.07915" title="Download PDF">pdf</a>, <a href="/format/2310.07915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tag Your Fish in the Broken Net: A Responsible Web Framework for  Protecting Online Privacy and Copyright
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dawen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+B">Boming Xia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+T">Thong Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhenchang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Staples%2C+M">Mark Staples</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Qinghua Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Liming Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> added some information on how to deal with CDN in the design section; minor fixes on writing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Computers and Society (cs.CY); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item982">[982]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08338" title="Abstract">arXiv:2310.08338</a> (replaced) [<a href="/pdf/2310.08338" title="Download PDF">pdf</a>, <a href="/ps/2310.08338" title="Download PostScript">ps</a>, <a href="/format/2310.08338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A cry for help: Early detection of brain injury in newborns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Onu%2C+C+C">Charles C. Onu</a>, 
<a href="/search/eess?searchtype=author&query=Latremouille%2C+S">Samantha Latremouille</a>, 
<a href="/search/eess?searchtype=author&query=Gorin%2C+A">Arsenii Gorin</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Junhao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Udeogu%2C+I">Innocent Udeogu</a>, 
<a href="/search/eess?searchtype=author&query=Ekwochi%2C+U">Uchenna Ekwochi</a>, 
<a href="/search/eess?searchtype=author&query=Ubuane%2C+P+O">Peter O. Ubuane</a>, 
<a href="/search/eess?searchtype=author&query=Kehinde%2C+O+A">Omolara A. Kehinde</a>, 
<a href="/search/eess?searchtype=author&query=Salisu%2C+M+A">Muhammad A. Salisu</a>, 
<a href="/search/eess?searchtype=author&query=Briggs%2C+D">Datonye Briggs</a>, 
<a href="/search/eess?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>, 
<a href="/search/eess?searchtype=author&query=Precup%2C+D">Doina Precup</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item983">[983]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08442" title="Abstract">arXiv:2310.08442</a> (replaced) [<a href="/pdf/2310.08442" title="Download PDF">pdf</a>, <a href="/format/2310.08442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Debias the Training of Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li Shen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Man Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Feng Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> University of Science and Technology of China, Alibaba Group, The Chinese University of Hong Kong
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item984">[984]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08553" title="Abstract">arXiv:2310.08553</a> (replaced) [<a href="/pdf/2310.08553" title="Download PDF">pdf</a>, <a href="/format/2310.08553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transmission line dynamics on inverter-dominated grids: analysis and  simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Colon-Reyes%2C+G+E">Gabriel E. Colon-Reyes</a>, 
<a href="/search/eess?searchtype=author&query=Kravis%2C+R">Ruth Kravis</a>, 
<a href="/search/eess?searchtype=author&query=Sharma%2C+S">Sunash Sharma</a>, 
<a href="/search/eess?searchtype=author&query=Callaway%2C+D">Duncan Callaway</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item985">[985]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08669" title="Abstract">arXiv:2310.08669</a> (replaced) [<a href="/pdf/2310.08669" title="Download PDF">pdf</a>, <a href="/format/2310.08669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Large Language Model for Visual Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsai%2C+Y+H">Yao-Hung Hubert Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Dhar%2C+V">Vansh Dhar</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jialu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bowen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item986">[986]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08812" title="Abstract">arXiv:2310.08812</a> (replaced) [<a href="/pdf/2310.08812" title="Download PDF">pdf</a>, <a href="/format/2310.08812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Nonlinear Method for time series forecasting using VMD-GARCH-LSTM  model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Gui%2C+Z">Zhengtao Gui</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+H">Haoyuan Li</a>, 
<a href="/search/stat?searchtype=author&query=Xu%2C+S">Sijie Xu</a>, 
<a href="/search/stat?searchtype=author&query=Chen%2C+Y">Yu Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item987">[987]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09586" title="Abstract">arXiv:2310.09586</a> (replaced) [<a href="/pdf/2310.09586" title="Download PDF">pdf</a>, <a href="/format/2310.09586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causality and Independence Enhancement for Biased Node Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guoxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+F">Fangda Guo</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qinglang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jiangli Shao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Huawei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, accepted by CIKM2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item988">[988]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09903" title="Abstract">arXiv:2310.09903</a> (replaced) [<a href="/pdf/2310.09903" title="Download PDF">pdf</a>, <a href="/ps/2310.09903" title="Download PostScript">ps</a>, <a href="/format/2310.09903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature selection and regression methods for stock price prediction  using technical indicators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Moodi%2C+F">Fatemeh Moodi</a>, 
<a href="/search/q-fin?searchtype=author&query=Jahangard-Rafsanjani%2C+A">Amir Jahangard-Rafsanjani</a>, 
<a href="/search/q-fin?searchtype=author&query=Zarifzadeh%2C+S">Sajad Zarifzadeh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 9 figures,5 tables,45 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item989">[989]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09971" title="Abstract">arXiv:2310.09971</a> (replaced) [<a href="/pdf/2310.09971" title="Download PDF">pdf</a>, <a href="/format/2310.09971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AMAGO: Scalable In-Context Reinforcement Learning for Adaptive Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grigsby%2C+J">Jake Grigsby</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Linxi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuke Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item990">[990]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10073" title="Abstract">arXiv:2310.10073</a> (replaced) [<a href="/pdf/2310.10073" title="Download PDF">pdf</a>, <a href="/format/2310.10073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expression Domain Translation Network for Cross-domain Head Reenactment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+T">Taewoong Kang</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+J">Jeongsik Oh</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaeseong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sunghyun Park</a>, 
<a href="/search/cs?searchtype=author&query=Choo%2C+J">Jaegul Choo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page with videos: <a href="https://keh0t0.github.io/research/EDTN/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item991">[991]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10118" title="Abstract">arXiv:2310.10118</a> (replaced) [<a href="/pdf/2310.10118" title="Download PDF">pdf</a>, <a href="/format/2310.10118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Rank Context for Named Entity Recognition Using a Synthetic  Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amalvy%2C+A">Arthur Amalvy</a> (LIA), 
<a href="/search/cs?searchtype=author&query=Labatut%2C+V">Vincent Labatut</a> (LIA), 
<a href="/search/cs?searchtype=author&query=Dufour%2C+R">Richard Dufour</a> (LS2N - &#xe9;quipe TALN )
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The 2023 Conference on Empirical Methods in Natural Language
  Processing, Dec 2023, Singapore, Singapore
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item992">[992]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10191" title="Abstract">arXiv:2310.10191</a> (replaced) [<a href="/pdf/2310.10191" title="Download PDF">pdf</a>, <a href="/format/2310.10191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VIBE: Topic-Driven Temporal Adaptation for Twitter Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jing Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenjie Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by EMNLP 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The 2023 Conference on Empirical Methods in Natural Language
  Processing (EMNLP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item993">[993]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10544" title="Abstract">arXiv:2310.10544</a> (replaced) [<a href="/pdf/2310.10544" title="Download PDF">pdf</a>, <a href="/ps/2310.10544" title="Download PostScript">ps</a>, <a href="/format/2310.10544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Use of probabilistic phrases in a coordination game: human versus GPT-4
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Maloney%2C+L+T">Laurence T Maloney</a>, 
<a href="/search/q-bio?searchtype=author&query=Martello%2C+M+F+D">Maria F Dal Martello</a>, 
<a href="/search/q-bio?searchtype=author&query=Fei%2C+V">Vivian Fei</a>, 
<a href="/search/q-bio?searchtype=author&query=Ma%2C+V">Valerie Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Corrected typos, extended discussion, added references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item994">[994]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11132" title="Abstract">arXiv:2310.11132</a> (replaced) [<a href="/pdf/2310.11132" title="Download PDF">pdf</a>, <a href="/format/2310.11132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-parametric Conditional Independence Testing for Mixed  Continuous-Categorical Variables: A Novel Method and Numerical Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Popescu%2C+O">Oana-Iuliana Popescu</a>, 
<a href="/search/cs?searchtype=author&query=Gerhardus%2C+A">Andreas Gerhardus</a>, 
<a href="/search/cs?searchtype=author&query=Runge%2C+J">Jakob Runge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item995">[995]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11441" title="Abstract">arXiv:2310.11441</a> (replaced) [<a href="/pdf/2310.11441" title="Download PDF">pdf</a>, <a href="/format/2310.11441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Set-of-Mark Prompting Unleashes Extraordinary Visual Grounding in GPT-4V
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Feng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xueyan Zou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianfeng Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item996">[996]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11516" title="Abstract">arXiv:2310.11516</a> (replaced) [<a href="/pdf/2310.11516" title="Download PDF">pdf</a>, <a href="/format/2310.11516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Field Robot for High-throughput and High-resolution 3D Plant Phenotyping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esser%2C+F">Felix Esser</a>, 
<a href="/search/cs?searchtype=author&query=Rosu%2C+R+A">Radu Alexandru Rosu</a>, 
<a href="/search/cs?searchtype=author&query=Corneli%C3%9Fen%2C+A">Andr&#xe9; Corneli&#xdf;en</a>, 
<a href="/search/cs?searchtype=author&query=Klingbeil%2C+L">Lasse Klingbeil</a>, 
<a href="/search/cs?searchtype=author&query=Kuhlmann%2C+H">Heiner Kuhlmann</a>, 
<a href="/search/cs?searchtype=author&query=Behnke%2C+S">Sven Behnke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for IEEE Robotics and Automation Magazine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item997">[997]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11864" title="Abstract">arXiv:2310.11864</a> (replaced) [<a href="/pdf/2310.11864" title="Download PDF">pdf</a>, <a href="/format/2310.11864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VQ-NeRF: Neural Reflectance Decomposition and Editing with Vector  Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+H">Hongliang Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingbo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+J">Jing Liao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TVCG. Project Page: <a href="https://jtbzhl.github.io/VQ-NeRF.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item998">[998]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12508" title="Abstract">arXiv:2310.12508</a> (replaced) [<a href="/pdf/2310.12508" title="Download PDF">pdf</a>, <a href="/format/2310.12508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency  in Both Image Classification and Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chongyu Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiancheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yihua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+D">Dennis Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+E">Eric Wong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sijia Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item999">[999]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13505" title="Abstract">arXiv:2310.13505</a> (replaced) [<a href="/pdf/2310.13505" title="Download PDF">pdf</a>, <a href="/format/2310.13505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Training for Conversational Question Answering Models with  Reinforced Reformulation Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaiser%2C+M">Magdalena Kaiser</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+R+S">Rishiraj Saha Roy</a>, 
<a href="/search/cs?searchtype=author&query=Weikum%2C+G">Gerhard Weikum</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WSDM 2024 Research Paper, 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item1000">[1000]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13540" title="Abstract">arXiv:2310.13540</a> (replaced) [<a href="/pdf/2310.13540" title="Download PDF">pdf</a>, <a href="/format/2310.13540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Thoroughly Modeling Multi-domain Pre-trained Recommendation as Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+Z">Zekai Qu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+R">Ruobing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chaojun Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+F">Fengzong Lian</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Z">Zhanhui Kang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item1001">[1001]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13682" title="Abstract">arXiv:2310.13682</a> (replaced) [<a href="/pdf/2310.13682" title="Download PDF">pdf</a>, <a href="/format/2310.13682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Retrieval-augmented Reader Models via Token Elimination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berchansky%2C+M">Moshe Berchansky</a>, 
<a href="/search/cs?searchtype=author&query=Izsak%2C+P">Peter Izsak</a>, 
<a href="/search/cs?searchtype=author&query=Caciularu%2C+A">Avi Caciularu</a>, 
<a href="/search/cs?searchtype=author&query=Dagan%2C+I">Ido Dagan</a>, 
<a href="/search/cs?searchtype=author&query=Wasserblat%2C+M">Moshe Wasserblat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Main Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1002">[1002]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14017" title="Abstract">arXiv:2310.14017</a> (replaced) [<a href="/pdf/2310.14017" title="Download PDF">pdf</a>, <a href="/format/2310.14017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrast Everything: A Hierarchical Contrastive Framework for Medical  Time-Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yihe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yu Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haishuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023; 24pages (13 pages main paper + 11 pages supplementary materials)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1003">[1003]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14265" title="Abstract">arXiv:2310.14265</a> (replaced) [<a href="/pdf/2310.14265" title="Download PDF">pdf</a>, <a href="/format/2310.14265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CT-GAT: Cross-Task Generative Adversarial Attack based on  Transferability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lv%2C+M">Minxuan Lv</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+C">Chengwei Dai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kun Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Songlin Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 main conference Corrected the header error in Figure 3
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1004">[1004]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14421" title="Abstract">arXiv:2310.14421</a> (replaced) [<a href="/pdf/2310.14421" title="Download PDF">pdf</a>, <a href="/format/2310.14421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On existence, uniqueness and scalability of adversarial robustness  measures for AI classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Horenko%2C+I">Illia Horenko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1005">[1005]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14455" title="Abstract">arXiv:2310.14455</a> (replaced) [<a href="/pdf/2310.14455" title="Download PDF">pdf</a>, <a href="/ps/2310.14455" title="Download PostScript">ps</a>, <a href="/format/2310.14455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An International Consortium for Evaluations of Societal-Scale Risks from  Advanced AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gruetzemacher%2C+R">Ross Gruetzemacher</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+A">Alan Chan</a>, 
<a href="/search/cs?searchtype=author&query=Frazier%2C+K">Kevin Frazier</a>, 
<a href="/search/cs?searchtype=author&query=Manning%2C+C">Christy Manning</a>, 
<a href="/search/cs?searchtype=author&query=Los%2C+%C5%A0">&#x160;t&#x11b;p&#xe1;n Los</a>, 
<a href="/search/cs?searchtype=author&query=Fox%2C+J">James Fox</a>, 
<a href="/search/cs?searchtype=author&query=Hern%C3%A1ndez-Orallo%2C+J">Jos&#xe9; Hern&#xe1;ndez-Orallo</a>, 
<a href="/search/cs?searchtype=author&query=Burden%2C+J">John Burden</a>, 
<a href="/search/cs?searchtype=author&query=Franklin%2C+M">Matija Franklin</a>, 
<a href="/search/cs?searchtype=author&query=Ghuidhir%2C+C+N">Cl&#xed;odhna N&#xed; Ghuidhir</a>, 
<a href="/search/cs?searchtype=author&query=Bailey%2C+M">Mark Bailey</a>, 
<a href="/search/cs?searchtype=author&query=Eth%2C+D">Daniel Eth</a>, 
<a href="/search/cs?searchtype=author&query=Pilditch%2C+T">Toby Pilditch</a>, 
<a href="/search/cs?searchtype=author&query=Kilian%2C+K">Kyle Kilian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 50 pages, 2 figures; updated w/ a few minor revisions based on feedback from SoLaR Workshop reviewers (on 5 page version)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1006">[1006]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14926" title="Abstract">arXiv:2310.14926</a> (replaced) [<a href="/pdf/2310.14926" title="Download PDF">pdf</a>, <a href="/format/2310.14926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reference-based Restoration of Digitized Analog Videotapes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agnolucci%2C+L">Lorenzo Agnolucci</a>, 
<a href="/search/cs?searchtype=author&query=Galteri%2C+L">Leonardo Galteri</a>, 
<a href="/search/cs?searchtype=author&query=Bertini%2C+M">Marco Bertini</a>, 
<a href="/search/cs?searchtype=author&query=Del+Bimbo%2C+A">Alberto Del Bimbo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item1007">[1007]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14942" title="Abstract">arXiv:2310.14942</a> (replaced) [<a href="/pdf/2310.14942" title="Download PDF">pdf</a>, <a href="/format/2310.14942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Watermark: Effective and Harmless Dataset Copyright Protection is  Closed at Hand
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Junfeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiming Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lixu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shu-Tao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Heng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by NeurIPS 2023. The first two authors contributed equally to this work. 30 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1008">[1008]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15177" title="Abstract">arXiv:2310.15177</a> (replaced) [<a href="/pdf/2310.15177" title="Download PDF">pdf</a>, <a href="/format/2310.15177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Neuro-mimetic Realization of the Common Model of Cognition via Hebbian  Learning and Free Energy Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Ororbia%2C+A">Alexander Ororbia</a>, 
<a href="/search/q-bio?searchtype=author&query=Kelly%2C+M+A">Mary Alexandria Kelly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Additional section on hopfield functionals and CogNGen's full free energy, basal ganglia sub-circuit diagram integrated
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1009">[1009]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15494" title="Abstract">arXiv:2310.15494</a> (replaced) [<a href="/pdf/2310.15494" title="Download PDF">pdf</a>, <a href="/format/2310.15494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TRAMS: Training-free Memory Selection for Long-range Language Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haofei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cunxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+W">Wei Bi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1010">[1010]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15747" title="Abstract">arXiv:2310.15747</a> (replaced) [<a href="/pdf/2310.15747" title="Download PDF">pdf</a>, <a href="/format/2310.15747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models are Temporal and Causal Reasoners for Video  Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ko%2C+D">Dohwan Ko</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+S">Ji Soo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+W">Wooyoung Kang</a>, 
<a href="/search/cs?searchtype=author&query=Roh%2C+B">Byungseok Roh</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H+J">Hyunwoo J. Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted paper at EMNLP 2023 Main
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1011">[1011]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16169" title="Abstract">arXiv:2310.16169</a> (replaced) [<a href="/pdf/2310.16169" title="Download PDF">pdf</a>, <a href="/format/2310.16169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Bayesian model calibration framework for stochastic compartmental  models with both time-varying and time-invariant parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Robinson%2C+B">Brandon Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Bisaillon%2C+P">Philippe Bisaillon</a>, 
<a href="/search/cs?searchtype=author&query=Edwards%2C+J+D">Jodi D. Edwards</a>, 
<a href="/search/cs?searchtype=author&query=Kendzerska%2C+T">Tetyana Kendzerska</a>, 
<a href="/search/cs?searchtype=author&query=Khalil%2C+M">Mohammad Khalil</a>, 
<a href="/search/cs?searchtype=author&query=Poirel%2C+D">Dominique Poirel</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+A">Abhijit Sarkar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item1012">[1012]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16248" title="Abstract">arXiv:2310.16248</a> (replaced) [<a href="/pdf/2310.16248" title="Download PDF">pdf</a>, <a href="/format/2310.16248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GlotLID: Language Identification for Low-Resource Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kargaran%2C+A+H">Amir Hossein Kargaran</a>, 
<a href="/search/cs?searchtype=author&query=Imani%2C+A">Ayyoob Imani</a>, 
<a href="/search/cs?searchtype=author&query=Yvon%2C+F">Fran&#xe7;ois Yvon</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%BCtze%2C+H">Hinrich Sch&#xfc;tze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1013">[1013]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16333" title="Abstract">arXiv:2310.16333</a> (replaced) [<a href="/pdf/2310.16333" title="Download PDF">pdf</a>, <a href="/format/2310.16333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Optimal Power Management for Large-Scale Battery Energy Storage  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Farakhor%2C+A">Amir Farakhor</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+D">Di Wu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yebin Wang</a>, 
<a href="/search/eess?searchtype=author&query=Fang%2C+H">Huazhen Fang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Transactions on Transportation Electrification
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item1014">[1014]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16787" title="Abstract">arXiv:2310.16787</a> (replaced) [<a href="/pdf/2310.16787" title="Download PDF">pdf</a>, <a href="/format/2310.16787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Data Provenance Initiative: A Large Scale Audit of Dataset Licensing  &amp; Attribution in AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Longpre%2C+S">Shayne Longpre</a>, 
<a href="/search/cs?searchtype=author&query=Mahari%2C+R">Robert Mahari</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Anthony Chen</a>, 
<a href="/search/cs?searchtype=author&query=Obeng-Marnu%2C+N">Naana Obeng-Marnu</a>, 
<a href="/search/cs?searchtype=author&query=Sileo%2C+D">Damien Sileo</a>, 
<a href="/search/cs?searchtype=author&query=Brannon%2C+W">William Brannon</a>, 
<a href="/search/cs?searchtype=author&query=Muennighoff%2C+N">Niklas Muennighoff</a>, 
<a href="/search/cs?searchtype=author&query=Khazam%2C+N">Nathan Khazam</a>, 
<a href="/search/cs?searchtype=author&query=Kabbara%2C+J">Jad Kabbara</a>, 
<a href="/search/cs?searchtype=author&query=Perisetla%2C+K">Kartik Perisetla</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xinyi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Shippole%2C+E">Enrico Shippole</a>, 
<a href="/search/cs?searchtype=author&query=Bollacker%2C+K">Kurt Bollacker</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tongshuang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Villa%2C+L">Luis Villa</a>, 
<a href="/search/cs?searchtype=author&query=Pentland%2C+S">Sandy Pentland</a>, 
<a href="/search/cs?searchtype=author&query=Hooker%2C+S">Sara Hooker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages (18 main), 6 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1015">[1015]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17179" title="Abstract">arXiv:2310.17179</a> (replaced) [<a href="/pdf/2310.17179" title="Download PDF">pdf</a>, <a href="/format/2310.17179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linking intra- and extra-cellular metabolic domains via neural-network  surrogates for dynamic metabolic control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Espinel-R%C3%ADos%2C+S">Sebasti&#xe1;n Espinel-R&#xed;os</a>, 
<a href="/search/eess?searchtype=author&query=Avalos%2C+J+L">Jos&#xe9; L. Avalos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures, conference paper submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item1016">[1016]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17316" title="Abstract">arXiv:2310.17316</a> (replaced) [<a href="/pdf/2310.17316" title="Download PDF">pdf</a>, <a href="/format/2310.17316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defect Spectrum: A Granular Look of Large-Scale Defect Datasets with  Rich Semantics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhifei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pengguang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+X">Xi Fang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingcong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1017">[1017]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17369" title="Abstract">arXiv:2310.17369</a> (replaced) [<a href="/pdf/2310.17369" title="Download PDF">pdf</a>, <a href="/format/2310.17369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language and Mental Health: Measures of Emotion Dynamics from Text as  Linguistic Biosocial Markers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teodorescu%2C+D">Daniela Teodorescu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+T">Tiffany Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Fyshe%2C+A">Alona Fyshe</a>, 
<a href="/search/cs?searchtype=author&query=Mohammad%2C+S+M">Saif M. Mohammad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1018">[1018]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17482" title="Abstract">arXiv:2310.17482</a> (replaced) [<a href="/pdf/2310.17482" title="Download PDF">pdf</a>, <a href="/ps/2310.17482" title="Download PostScript">ps</a>, <a href="/format/2310.17482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orthonormal representations, vector chromatic number, and extension  complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Balla%2C+I">Igor Balla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages; Fixed minor typographical and logical errors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item1019">[1019]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17814" title="Abstract">arXiv:2310.17814</a> (replaced) [<a href="/pdf/2310.17814" title="Download PDF">pdf</a>, <a href="/format/2310.17814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DIVI: Dynamically Interactive Visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Snyder%2C+L+S">Luke S. Snyder</a>, 
<a href="/search/cs?searchtype=author&query=Heer%2C+J">Jeffrey Heer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 pages supplementary material, 10 figures, IEEE TVCG 2024 (Proc. VIS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item1020">[1020]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18146" title="Abstract">arXiv:2310.18146</a> (replaced) [<a href="/pdf/2310.18146" title="Download PDF">pdf</a>, <a href="/format/2310.18146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Out-Orientations with Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chekuri%2C+C">Chandra Chekuri</a>, 
<a href="/search/cs?searchtype=author&query=Christiansen%2C+A+B">Aleksander Bj&#xf8;rn Christiansen</a>, 
<a href="/search/cs?searchtype=author&query=Holm%2C+J">Jacob Holm</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Hoog%2C+I">Ivor van der Hoog</a>, 
<a href="/search/cs?searchtype=author&query=Quanrud%2C+K">Kent Quanrud</a>, 
<a href="/search/cs?searchtype=author&query=Rotenberg%2C+E">Eva Rotenberg</a>, 
<a href="/search/cs?searchtype=author&query=Schwiegelshohn%2C+C">Chris Schwiegelshohn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at SODA24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item1021">[1021]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18152" title="Abstract">arXiv:2310.18152</a> (replaced) [<a href="/pdf/2310.18152" title="Download PDF">pdf</a>, <a href="/format/2310.18152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangled Representation Learning with Large Language Models for  Text-Attributed Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yijian Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenwu Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1022">[1022]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18208" title="Abstract">arXiv:2310.18208</a> (replaced) [<a href="/pdf/2310.18208" title="Download PDF">pdf</a>, <a href="/format/2310.18208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ArcheType: A Novel Framework for Open-Source Column Type Annotation  using Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feuer%2C+B">Benjamin Feuer</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yurong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hegde%2C+C">Chinmay Hegde</a>, 
<a href="/search/cs?searchtype=author&query=Freire%2C+J">Juliana Freire</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1023">[1023]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18238" title="Abstract">arXiv:2310.18238</a> (replaced) [<a href="/pdf/2310.18238" title="Download PDF">pdf</a>, <a href="/format/2310.18238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Order-2 Delaunay Triangulations Optimize Angles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Edelsbrunner%2C+H">Herbert Edelsbrunner</a>, 
<a href="/search/math?searchtype=author&query=Garber%2C+A">Alexey Garber</a>, 
<a href="/search/math?searchtype=author&query=Saghafian%2C+M">Morteza Saghafian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Geometry (cs.CG); Metric Geometry (math.MG)

</div>
</div>
</dd>
<dt><a name="item1024">[1024]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18343" title="Abstract">arXiv:2310.18343</a> (replaced) [<a href="/pdf/2310.18343" title="Download PDF">pdf</a>, <a href="/format/2310.18343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PHD: Pixel-Based Language Modeling of Historical Documents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borenstein%2C+N">Nadav Borenstein</a>, 
<a href="/search/cs?searchtype=author&query=Rust%2C+P">Phillip Rust</a>, 
<a href="/search/cs?searchtype=author&query=Elliott%2C+D">Desmond Elliott</a>, 
<a href="/search/cs?searchtype=author&query=Augenstein%2C+I">Isabelle Augenstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the main conference of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1025">[1025]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18651" title="Abstract">arXiv:2310.18651</a> (replaced) [<a href="/pdf/2310.18651" title="Download PDF">pdf</a>, <a href="/ps/2310.18651" title="Download PostScript">ps</a>, <a href="/format/2310.18651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local-Global Self-Supervised Visual Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Javidani%2C+A">Ali Javidani</a>, 
<a href="/search/cs?searchtype=author&query=Sadeghi%2C+M+A">Mohammad Amin Sadeghi</a>, 
<a href="/search/cs?searchtype=author&query=Araabi%2C+B+N">Babak Nadjar Araabi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1026">[1026]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18917" title="Abstract">arXiv:2310.18917</a> (replaced) [<a href="/pdf/2310.18917" title="Download PDF">pdf</a>, <a href="/format/2310.18917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TiV-NeRF: Tracking and Mapping via Time-Varying Representation with  Dynamic Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+C">Chengyao Duan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhiliu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1027">[1027]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18919" title="Abstract">arXiv:2310.18919</a> (replaced) [<a href="/pdf/2310.18919" title="Download PDF">pdf</a>, <a href="/format/2310.18919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Posterior Sampling with Delayed Feedback for Reinforcement Learning with  Linear Function Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuang%2C+N+L">Nikki Lijing Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+M">Ming Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengdi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yi-An Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1028">[1028]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18986" title="Abstract">arXiv:2310.18986</a> (replaced) [<a href="/pdf/2310.18986" title="Download PDF">pdf</a>, <a href="/format/2310.18986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controllable Group Choreography using Contrastive Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+N">Nhat Le</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+T">Tuong Do</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+K">Khoa Do</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Hien Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Tjiputra%2C+E">Erman Tjiputra</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+Q+D">Quang D. Tran</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+A">Anh Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1029">[1029]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18987" title="Abstract">arXiv:2310.18987</a> (replaced) [<a href="/pdf/2310.18987" title="Download PDF">pdf</a>, <a href="/ps/2310.18987" title="Download PostScript">ps</a>, <a href="/format/2310.18987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Path Analysis for Effective Fault Localization in Deep Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hashemifar%2C+S">Soroush Hashemifar</a>, 
<a href="/search/cs?searchtype=author&query=Parsa%2C+S">Saeed Parsa</a>, 
<a href="/search/cs?searchtype=author&query=Kalaee%2C+A">Akram Kalaee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Neural and Evolutionary Computing (cs.NE); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item1030">[1030]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19080" title="Abstract">arXiv:2310.19080</a> (replaced) [<a href="/pdf/2310.19080" title="Download PDF">pdf</a>, <a href="/format/2310.19080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reward Finetuning for Faster and More Accurate Unsupervised Object  Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+K+Z">Katie Z Luo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenzhen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiangyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yurong You</a>, 
<a href="/search/cs?searchtype=author&query=Benaim%2C+S">Sagie Benaim</a>, 
<a href="/search/cs?searchtype=author&query=Phoo%2C+C+P">Cheng Perng Phoo</a>, 
<a href="/search/cs?searchtype=author&query=Campbell%2C+M">Mark Campbell</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hariharan%2C+B">Bharath Hariharan</a>, 
<a href="/search/cs?searchtype=author&query=Weinberger%2C+K+Q">Kilian Q. Weinberger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1031">[1031]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19233" title="Abstract">arXiv:2310.19233</a> (replaced) [<a href="/pdf/2310.19233" title="Download PDF">pdf</a>, <a href="/format/2310.19233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building Real-World Meeting Summarization Systems using Large Language  Models: A Practical Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laskar%2C+M+T+R">Md Tahmid Rahman Laskar</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xue-Yong Fu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=TN%2C+S+B">Shashi Bhushan TN</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Industry Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1032">[1032]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19630" title="Abstract">arXiv:2310.19630</a> (replaced) [<a href="/pdf/2310.19630" title="Download PDF">pdf</a>, <a href="/ps/2310.19630" title="Download PostScript">ps</a>, <a href="/format/2310.19630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convolutional Neural Networks for Automatic Detection of Intact  Adenovirus from TEM Imaging with Debris, Broken and Artefacts Particles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rukundo%2C+O">Olivier Rukundo</a>, 
<a href="/search/cs?searchtype=author&query=Behanova%2C+A">Andrea Behanova</a>, 
<a href="/search/cs?searchtype=author&query=De+Feo%2C+R">Riccardo De Feo</a>, 
<a href="/search/cs?searchtype=author&query=Ronkko%2C+S">Seppo Ronkko</a>, 
<a href="/search/cs?searchtype=author&query=Oja%2C+J">Joni Oja</a>, 
<a href="/search/cs?searchtype=author&query=Tohka%2C+J">Jussi Tohka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item1033">[1033]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19776" title="Abstract">arXiv:2310.19776</a> (replaced) [<a href="/pdf/2310.19776" title="Download PDF">pdf</a>, <a href="/format/2310.19776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learn to Categorize or Categorize to Learn? Self-Coding for Generalized  Category Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rastegar%2C+S">Sarah Rastegar</a>, 
<a href="/search/cs?searchtype=author&query=Doughty%2C+H">Hazel Doughty</a>, 
<a href="/search/cs?searchtype=author&query=Snoek%2C+C+G+M">Cees G. M. Snoek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1034">[1034]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19967" title="Abstract">arXiv:2310.19967</a> (replaced) [<a href="/pdf/2310.19967" title="Download PDF">pdf</a>, <a href="/ps/2310.19967" title="Download PostScript">ps</a>, <a href="/format/2310.19967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Early detection of inflammatory arthritis to improve referrals using  multimodal machine learning from blood testing, semi-structured and  unstructured patient records
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weizi Li</a>, 
<a href="/search/cs?searchtype=author&query=Bradlow%2C+A">Anthony Bradlow</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+A+T+Y">Antoni T.Y. Chan</a>, 
<a href="/search/cs?searchtype=author&query=Bazuaye%2C+E">Eghosa Bazuaye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in The 57th Hawaii International Conference on System Sciences, 3-6 Jan 2024, Hawaii
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1035">[1035]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19975" title="Abstract">arXiv:2310.19975</a> (replaced) [<a href="/pdf/2310.19975" title="Download PDF">pdf</a>, <a href="/format/2310.19975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BioInstruct: Instruction Tuning of Large Language Models for Biomedical  Natural Language Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+H">Hieu Tran</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhichao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zonghai Yao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1036">[1036]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20145" title="Abstract">arXiv:2310.20145</a> (replaced) [<a href="/pdf/2310.20145" title="Download PDF">pdf</a>, <a href="/format/2310.20145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Robust Bayesian Optimization for Arbitrary Uncertain Inputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+J">Junlong Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+W">Wenlong Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhitang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1037">[1037]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20195" title="Abstract">arXiv:2310.20195</a> (replaced) [<a href="/pdf/2310.20195" title="Download PDF">pdf</a>, <a href="/format/2310.20195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Continuations in Multilingual Idiomatic Contexts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pokharel%2C+R">Rhitabrat Pokharel</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+A">Ameeta Agrawal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at MRL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1038">[1038]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20256" title="Abstract">arXiv:2310.20256</a> (replaced) [<a href="/pdf/2310.20256" title="Download PDF">pdf</a>, <a href="/format/2310.20256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PsyCoT: Psychological Questionnaire as Powerful Chain-of-Thought for  Personality Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+T">Tianyuan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+F">Fanqi Wan</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+X">Xiaojun Quan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bingzhe Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiaxiang Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1039">[1039]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20290" title="Abstract">arXiv:2310.20290</a> (replaced) [<a href="/pdf/2310.20290" title="Download PDF">pdf</a>, <a href="/format/2310.20290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Rayleigh Quotient Iteration for Dual Quaternion Hermitian Eigenvalue  Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Duan%2C+S">Shan-Qi Duan</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+Q">Qing-Wen Wang</a>, 
<a href="/search/math?searchtype=author&query=Duan%2C+X">Xue-Feng Duan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2111.12211">arXiv:2111.12211</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item1040">[1040]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20327" title="Abstract">arXiv:2310.20327</a> (replaced) [<a href="/pdf/2310.20327" title="Download PDF">pdf</a>, <a href="/format/2310.20327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Entropy-Based Test-Time Adaptation from a Clustering View
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guoliang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+H">Hanjiang Lai</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jian Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1041">[1041]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20381" title="Abstract">arXiv:2310.20381</a> (replaced) [<a href="/pdf/2310.20381" title="Download PDF">pdf</a>, <a href="/format/2310.20381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Study of GPT-4V&#x27;s Multimodal Capabilities in Medical  Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingshu Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhanyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xinyu Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingqiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+L">Leyang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhaopeng Tu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Longyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Luping Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1042">[1042]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20499" title="Abstract">arXiv:2310.20499</a> (replaced) [<a href="/pdf/2310.20499" title="Download PDF">pdf</a>, <a href="/format/2310.20499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Word Guessing Games to Assess the Intelligence of Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+T">Tian Liang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhiwei He</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jen-tse Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+W">Wenxiang Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujiu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhaopeng Tu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xing Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1043">[1043]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20554" title="Abstract">arXiv:2310.20554</a> (replaced) [<a href="/pdf/2310.20554" title="Download PDF">pdf</a>, <a href="/format/2310.20554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast and Delay-Robust Multimodal Journey Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bez%2C+D">Dominik Bez</a>, 
<a href="/search/cs?searchtype=author&query=Sauer%2C+J">Jonas Sauer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item1044">[1044]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20587" title="Abstract">arXiv:2310.20587</a> (replaced) [<a href="/pdf/2310.20587" title="Download PDF">pdf</a>, <a href="/format/2310.20587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unleashing the Power of Pre-trained Language Models for Offline  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+R">Ruizhe Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuyao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ze%2C+Y">Yanjie Ze</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S+S">Simon S. Du</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huazhe Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1045">[1045]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20700" title="Abstract">arXiv:2310.20700</a> (replaced) [<a href="/pdf/2310.20700" title="Download PDF">pdf</a>, <a href="/format/2310.20700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEINE: Short-to-Long Video Diffusion Model for Generative Transition and  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaohui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lingjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+S">Shaobin Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiashuo Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yali Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://vchitect.github.io/SEINE-project/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1046">[1046]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00369" title="Abstract">arXiv:2311.00369</a> (replaced) [<a href="/pdf/2311.00369" title="Download PDF">pdf</a>, <a href="/format/2311.00369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Direct System Identification of Dynamical Networks with Partial  Measurements: a Maximum Likelihood Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=da+Mata%2C+J+V+G">Jo&#xe3;o Victor Galv&#xe3;o da Mata</a>, 
<a href="/search/eess?searchtype=author&query=Hansson%2C+A">Anders Hansson</a>, 
<a href="/search/eess?searchtype=author&query=Andersen%2C+M+S">Martin S. Andersen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ECC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item1047">[1047]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00422" title="Abstract">arXiv:2311.00422</a> (replaced) [<a href="/pdf/2311.00422" title="Download PDF">pdf</a>, <a href="/format/2311.00422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Universal Atomic Composability: A Formal Model for Multi-Rollup  Environments on Ethereum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+D">Dipankar Sarkar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1048">[1048]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00423" title="Abstract">arXiv:2311.00423</a> (replaced) [<a href="/pdf/2311.00423" title="Download PDF">pdf</a>, <a href="/format/2311.00423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMRec: Large Language Models with Graph Augmentation for Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xubin Ren</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiabin Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qinyong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+L">Lixin Su</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Suqi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Dawei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WSDM 2024 Oral Presentation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item1049">[1049]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00429" title="Abstract">arXiv:2311.00429</a> (replaced) [<a href="/pdf/2311.00429" title="Download PDF">pdf</a>, <a href="/format/2311.00429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Crop Disease Classification using Support Vector Machines with Green  Chromatic Coordinate (GCC) and Attention based feature extraction for IoT  based Smart Agricultural Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jha%2C+S">Shashwat Jha</a>, 
<a href="/search/eess?searchtype=author&query=Luhach%2C+V">Vishvaditya Luhach</a>, 
<a href="/search/eess?searchtype=author&query=Gupta%2C+G+S">Gauri Shanker Gupta</a>, 
<a href="/search/eess?searchtype=author&query=Singh%2C+B">Beependra Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1050">[1050]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00447" title="Abstract">arXiv:2311.00447</a> (replaced) [<a href="/pdf/2311.00447" title="Download PDF">pdf</a>, <a href="/format/2311.00447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Opportunities of Green Computing: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">You Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiujing Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Maolin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+G">Gangwei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Huakang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yupeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhe Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kehang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sui%2C+Y">Yongduo Sui</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+F">Fengwei Jia</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zuoli Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tiannuo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weibo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yunong Mao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yi Li</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+D">De Bao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yu Li</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+H">Hongrui Liao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingwen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jinchi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=WEI%2C+Y">Ying WEI</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+H">Hong Qian</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kin%2C+W">Wai Kin</a> (Victor)
<a href="/search/cs?searchtype=author&query=Chan">Chan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yusen Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shiyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jining Yan</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+C">Chao Mou</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shuai Han</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+W">Wuxia Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guannan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xiaodong Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 113 pages, 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1051">[1051]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00548" title="Abstract">arXiv:2311.00548</a> (replaced) [<a href="/pdf/2311.00548" title="Download PDF">pdf</a>, <a href="/format/2311.00548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual atlas-based segmentation of prostate MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ranem%2C+A">Amin Ranem</a>, 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A1lez%2C+C">Camila Gonz&#xe1;lez</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+D+P+d">Daniel Pinto dos Santos</a>, 
<a href="/search/cs?searchtype=author&query=Bucher%2C+A+M">Andreas M. Bucher</a>, 
<a href="/search/cs?searchtype=author&query=Othman%2C+A+E">Ahmed E. Othman</a>, 
<a href="/search/cs?searchtype=author&query=Mukhopadhyay%2C+A">Anirban Mukhopadhyay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1052">[1052]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00634" title="Abstract">arXiv:2311.00634</a> (replaced) [<a href="/pdf/2311.00634" title="Download PDF">pdf</a>, <a href="/ps/2311.00634" title="Download PostScript">ps</a>, <a href="/format/2311.00634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Bi-level Framework for Traffic Accident Duration Prediction:  Leveraging Weather and Road Condition Data within a Practical Optimum  Pipeline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sukonna%2C+R+T">Rafat Tabassum Sukonna</a>, 
<a href="/search/cs?searchtype=author&query=Swapnil%2C+S+I">Soham Irtiza Swapnil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1053">[1053]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00734" title="Abstract">arXiv:2311.00734</a> (replaced) [<a href="/pdf/2311.00734" title="Download PDF">pdf</a>, <a href="/format/2311.00734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Manipulating Scene Text in the Wild with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santoso%2C+J">Joshua Santoso</a>, 
<a href="/search/cs?searchtype=author&query=Simon%2C+C">Christian Simon</a>, 
<a href="/search/cs?searchtype=author&query=Pao%2C+W">Williem Pao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1054">[1054]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00779" title="Abstract">arXiv:2311.00779</a> (replaced) [<a href="/pdf/2311.00779" title="Download PDF">pdf</a>, <a href="/format/2311.00779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shortest paths on polymatroids and hypergraphic polytopes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cardinal%2C+J">Jean Cardinal</a>, 
<a href="/search/cs?searchtype=author&query=Steiner%2C+R">Raphael Steiner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 5 figures, full version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item1055">[1055]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01066" title="Abstract">arXiv:2311.01066</a> (replaced) [<a href="/pdf/2311.01066" title="Download PDF">pdf</a>, <a href="/format/2311.01066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Multimodal Information Bottleneck for Multimodality  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fang%2C+Y">Yingying Fang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+S">Shuang Wu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+S">Sheng Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+C">Chaoyan Huang</a>, 
<a href="/search/eess?searchtype=author&query=Zeng%2C+T">Tieyong Zeng</a>, 
<a href="/search/eess?searchtype=author&query=Xing%2C+X">Xiaodan Xing</a>, 
<a href="/search/eess?searchtype=author&query=Walsh%2C+S">Simon Walsh</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+G">Guang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1056">[1056]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01194" title="Abstract">arXiv:2311.01194</a> (replaced) [<a href="/pdf/2311.01194" title="Download PDF">pdf</a>, <a href="/format/2311.01194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Statistical Approach for Improving HVOF Coating: Predictive Modelling  of Critical Variables using Generalized Linear Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Rannetbauer%2C+W">Wolfgang Rannetbauer</a>, 
<a href="/search/stat?searchtype=author&query=Hubmer%2C+S">Simon Hubmer</a>, 
<a href="/search/stat?searchtype=author&query=Hambrock%2C+C">Carina Hambrock</a>, 
<a href="/search/stat?searchtype=author&query=Ramlau%2C+R">Ronny Ramlau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Numerical Analysis (math.NA); Applied Physics (physics.app-ph)

</div>
</div>
</dd>
<dt><a name="item1057">[1057]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01301" title="Abstract">arXiv:2311.01301</a> (replaced) [<a href="/pdf/2311.01301" title="Download PDF">pdf</a>, <a href="/format/2311.01301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TRIALSCOPE: A Unifying Causal Framework for Scaling Real-World Evidence  Generation with Biomedical Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A1lez%2C+J">Javier Gonz&#xe1;lez</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+C">Cliff Wong</a>, 
<a href="/search/cs?searchtype=author&query=Gero%2C+Z">Zelalem Gero</a>, 
<a href="/search/cs?searchtype=author&query=Bagga%2C+J">Jass Bagga</a>, 
<a href="/search/cs?searchtype=author&query=Ueno%2C+R">Risa Ueno</a>, 
<a href="/search/cs?searchtype=author&query=Chien%2C+I">Isabel Chien</a>, 
<a href="/search/cs?searchtype=author&query=Oravkin%2C+E">Eduard Oravkin</a>, 
<a href="/search/cs?searchtype=author&query=Kiciman%2C+E">Emre Kiciman</a>, 
<a href="/search/cs?searchtype=author&query=Nori%2C+A">Aditya Nori</a>, 
<a href="/search/cs?searchtype=author&query=Weerasinghe%2C+R">Roshanthi Weerasinghe</a>, 
<a href="/search/cs?searchtype=author&query=Leidner%2C+R+S">Rom S. Leidner</a>, 
<a href="/search/cs?searchtype=author&query=Piening%2C+B">Brian Piening</a>, 
<a href="/search/cs?searchtype=author&query=Naumann%2C+T">Tristan Naumann</a>, 
<a href="/search/cs?searchtype=author&query=Bifulco%2C+C">Carlo Bifulco</a>, 
<a href="/search/cs?searchtype=author&query=Poon%2C+H">Hoifung Poon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 Figures, 22 Pages, 3 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item1058">[1058]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01343" title="Abstract">arXiv:2311.01343</a> (replaced) [<a href="/pdf/2311.01343" title="Download PDF">pdf</a>, <a href="/format/2311.01343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Large Language Model for Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yaochen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Liang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Liangjie Hong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jundong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item1059">[1059]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01378" title="Abstract">arXiv:2311.01378</a> (replaced) [<a href="/pdf/2311.01378" title="Download PDF">pdf</a>, <a href="/format/2311.01378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision-Language Foundation Models as Effective Robot Imitators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinghang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Minghuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanbo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Cunjun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hongtao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cheang%2C+C">Chilam Cheang</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+Y">Ya Jing</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huaping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hang Li</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+T">Tao Kong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fix typos. Project page: <a href="https://roboflamingo.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1060">[1060]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01414" title="Abstract">arXiv:2311.01414</a> (replaced) [<a href="/pdf/2311.01414" title="Download PDF">pdf</a>, <a href="/ps/2311.01414" title="Download PostScript">ps</a>, <a href="/format/2311.01414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Dynamic Temporal Logic for Quality of Service in Choreographic Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pombo%2C+C+G+L">Carlos G. Lopez Pombo</a>, 
<a href="/search/cs?searchtype=author&query=Su%C3%B1%C3%A9%2C+A+E+M">Agust&#xed;n E. Martinez Su&#xf1;&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Tuosto%2C+E">Emilio Tuosto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, Accepted for publication at International Conference on Theoretical Aspects of Computing 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item1061">[1061]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01423" title="Abstract">arXiv:2311.01423</a> (replaced) [<a href="/pdf/2311.01423" title="Download PDF">pdf</a>, <a href="/format/2311.01423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CenterRadarNet: Joint 3D Object Detection and Tracking Framework using  4D FMCW Radar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jen-Hao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Kuan%2C+S">Sheng-Yao Kuan</a>, 
<a href="/search/cs?searchtype=author&query=Latapie%2C+H">Hugo Latapie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Gaowen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jenq-Neng Hwang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1062">[1062]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01584" title="Abstract">arXiv:2311.01584</a> (replaced) [<a href="/pdf/2311.01584" title="Download PDF">pdf</a>, <a href="/format/2311.01584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secured Fiscal Credit Model: Multi-Agent Systems And Decentralized  Autonomous Organisations For Tax Credit&#x27;s Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Gasperis%2C+G">Giovanni De Gasperis</a>, 
<a href="/search/cs?searchtype=author&query=Facchini%2C+S+D">Sante Dino Facchini</a>, 
<a href="/search/cs?searchtype=author&query=Letteri%2C+I">Ivan Letteri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
</div>
</dd>
<dt><a name="item1063">[1063]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01723" title="Abstract">arXiv:2311.01723</a> (replaced) [<a href="/pdf/2311.01723" title="Download PDF">pdf</a>, <a href="/format/2311.01723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Calibrated Robust Fine-Tuning of Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oh%2C+C">Changdae Oh</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Mijoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+H">Hyesu Lim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Junhyeok Park</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+E">Euiseog Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhi-Qi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kyungwoo Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Workshop on Distribution Shifts (DistShift)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1064">[1064]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01729" title="Abstract">arXiv:2311.01729</a> (replaced) [<a href="/pdf/2311.01729" title="Download PDF">pdf</a>, <a href="/format/2311.01729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CDGraph: Dual Conditional Social Graph Synthesizing via Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsai%2C+J">Jui-Yi Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+Y">Ya-Wen Teng</a>, 
<a href="/search/cs?searchtype=author&query=Yew%2C+H+C">Ho Chiok Yew</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">De-Nian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L+Y">Lydia Y. Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1065">[1065]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01766" title="Abstract">arXiv:2311.01766</a> (replaced) [<a href="/pdf/2311.01766" title="Download PDF">pdf</a>, <a href="/format/2311.01766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Support or Refute: Analyzing the Stance of Evidence to Detect  Out-of-Context Mis- and Disinformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jie Guo</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+W">Weidong Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shujun Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1066">[1066]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01825" title="Abstract">arXiv:2311.01825</a> (replaced) [<a href="/pdf/2311.01825" title="Download PDF">pdf</a>, <a href="/format/2311.01825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models to the Rescue: Reducing the Complexity in  Scientific Workflow Development Using ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%C3%A4nger%2C+M">Mario S&#xe4;nger</a>, 
<a href="/search/cs?searchtype=author&query=De+Mecquenem%2C+N">Ninon De Mecquenem</a>, 
<a href="/search/cs?searchtype=author&query=Lewi%C5%84ska%2C+K+E">Katarzyna Ewa Lewi&#x144;ska</a>, 
<a href="/search/cs?searchtype=author&query=Bountris%2C+V">Vasilis Bountris</a>, 
<a href="/search/cs?searchtype=author&query=Lehmann%2C+F">Fabian Lehmann</a>, 
<a href="/search/cs?searchtype=author&query=Leser%2C+U">Ulf Leser</a>, 
<a href="/search/cs?searchtype=author&query=Kosch%2C+T">Thomas Kosch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item1067">[1067]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01977" title="Abstract">arXiv:2311.01977</a> (replaced) [<a href="/pdf/2311.01977" title="Download PDF">pdf</a>, <a href="/format/2311.01977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory  Sketches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiayuan Gu</a>, 
<a href="/search/cs?searchtype=author&query=Kirmani%2C+S">Sean Kirmani</a>, 
<a href="/search/cs?searchtype=author&query=Wohlhart%2C+P">Paul Wohlhart</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Arenas%2C+M+G">Montserrat Gonzalez Arenas</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+K">Kanishka Rao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenhao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Chuyuan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Gopalakrishnan%2C+K">Keerthana Gopalakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhuo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sundaresan%2C+P">Priya Sundaresan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Peng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hao Su</a>, 
<a href="/search/cs?searchtype=author&query=Hausman%2C+K">Karol Hausman</a>, 
<a href="/search/cs?searchtype=author&query=Finn%2C+C">Chelsea Finn</a>, 
<a href="/search/cs?searchtype=author&query=Vuong%2C+Q">Quan Vuong</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Ted Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Evaluation videos can be found at <a href="https://rt-trajectory.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1068">[1068]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01989" title="Abstract">arXiv:2311.01989</a> (replaced) [<a href="/pdf/2311.01989" title="Download PDF">pdf</a>, <a href="/format/2311.01989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Large-Scale Pretrained Vision Foundation Models for  Label-Efficient 3D Point Cloud Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+S">Shichao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fayao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guosheng Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item559">Cross-lists</a></li>
<li><a href="#item639">Replacements</a></li>
</ul>
<small>[ total of 1068 entries:  <b>1-1068</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2311">2311</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
