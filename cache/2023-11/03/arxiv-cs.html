<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Wed  1 Nov 23  to  Thu  2 Nov 23, announced Fri,  3 Nov 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item347">Cross-lists</a></li>
<li><a href="#item384">Replacements</a></li>
</ul>
<small>[ total of 605 entries:  <b>1-605</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Fri,  3 Nov 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00706" title="Abstract">arXiv:2311.00706</a> [<a href="/pdf/2311.00706" title="Download PDF">pdf</a>, <a href="/format/2311.00706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can AI Mitigate Human Perceptual Biases? A Pilot Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geuy%2C+R">Ross Geuy</a>, 
<a href="/search/cs?searchtype=author&query=Rising%2C+N">Nate Rising</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+T">Tiancheng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+M">Meng Ling</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jian Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was accepted IEEE VIS 2023 VISxVISION Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present results from a pilot experiment to measure if machine
recommendations can debias human perceptual biases in visualization tasks. We
specifically studied the ``pull-down'' effect, i.e., people underestimate the
average position of lines, for the task of estimating the ensemble average of
data points in line charts. These line charts can show for example temperature
or precipitation in 12 months. Six participants estimated ensemble averages
with or without an AI assistant. The assistant, when available, responded at
three different speeds to assemble the conditions of a human collaborator who
may delay his or her responses. Our pilot study showed that participants were
faster with AI assistance in ensemble tasks, compared to the baseline without
AI assistance. Although ``pull-down'' biases were reduced, the effect of AI
assistance was not statistically significant. Also, delaying AI responses had
no significant impact on human decision accuracy. We discuss the implications
of these preliminary results for subsequent studies.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00709" title="Abstract">arXiv:2311.00709</a> [<a href="/pdf/2311.00709" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Chemistry Learning with ChatGPT, Bing Chat, Bard, and Claude  as Agents-to-Think-With: A Comparative Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santos%2C+R+P+d">Renato P. dos Santos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This research delves into the comparative advantages of Generative AI
chatbots (GenAIbots) -- ChatGPT, Bing Chat, Bard, and Claude -- in the context
of Chemistry education, framed within a constructivist perspective. Our primary
objective was to identify which of these four AI tools is more effective for
enhancing Chemistry learning. Employing a single-case study approach, we
scrutinised interaction logs between the AI systems and a simulated student
persona during Chemistry learning simulations, incorporating Content Analysis
methodology to delve deeper into the discourse. Our findings underscore these
tools' potential as "agents-to-think-with", enhancing critical thinking,
problem-solving, comprehension, creativity, and tailored learning. Especially
noteworthy is their ability to stimulate learners through Socratic-like
questioning, aligning with constructionist principles. The research emphasises
the pivotal role of prompt crafting to coax desired responses from GenAIbots,
engendering iterative reflections. It also highlights the need for robust
educator training to infuse these technologies into educational settings.
Conclusively, while ChatGPT, Bing Chat, Bard, and Claude are poised to enrich
Chemistry education by fostering dynamic, inclusive learning experiences,
ChatGPT stood out, decisively surpassing Bing Chat in its performance. Bard and
Claude trailed closely, with all three showcasing a more in-depth, precise, and
nuanced understanding, underscoring ChatGPT's adeptness at contextual
comprehension.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00710" title="Abstract">arXiv:2311.00710</a> [<a href="/pdf/2311.00710" title="Download PDF">pdf</a>, <a href="/format/2311.00710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Alignment in the Design of Interactive AI: Specification Alignment,  Process Alignment, and Evaluation Support
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Terry%2C+M">Michael Terry</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+C">Chinmay Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Wattenberg%2C+M">Martin Wattenberg</a>, 
<a href="/search/cs?searchtype=author&query=Dixon%2C+L">Lucas Dixon</a>, 
<a href="/search/cs?searchtype=author&query=Morris%2C+M+R">Meredith Ringel Morris</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">AI alignment considers the overall problem of ensuring an AI produces desired
outcomes, without undesirable side effects. While often considered from the
perspectives of safety and human values, AI alignment can also be considered in
the context of designing and evaluating interfaces for interactive AI systems.
This paper maps concepts from AI alignment onto a basic, three step interaction
cycle, yielding a corresponding set of alignment objectives: 1) specification
alignment: ensuring the user can efficiently and reliably communicate
objectives to the AI, 2) process alignment: providing the ability to verify and
optionally control the AI's execution process, and 3) evaluation support:
ensuring the user can verify and understand the AI's output. We also introduce
the concepts of a surrogate process, defined as a simplified, separately
derived, but controllable representation of the AI's actual process; and the
notion of a Process Gulf, which highlights how differences between human and AI
processes can lead to challenges in AI control. To illustrate the value of this
framework, we describe commercial and research systems along each of the three
alignment dimensions, and show how interfaces that provide interactive
alignment mechanisms can lead to qualitatively different and improved user
experiences.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00718" title="Abstract">arXiv:2311.00718</a> [<a href="/pdf/2311.00718" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chat GPT Integrated with Voice Assistant as Learning Oral Chat-based  Constructive Communication to Improve Communicative Competence for EFL  earners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wei Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 page
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Chat GPT belongs to the category of Generative Pre-trained Transformer (GPT)
language models, which have received specialized training to produce text based
on natural language inputs. Its purpose is to imitate human-like conversation
and can be implemented in multiple applications, such as chatbots, virtual
assistants, and language translation systems, starting with an introduction to
the new trends and differences between artificial intelligence, machine
learning, and artificial neural networks, and highlighting the rigorous
language logic and powerful text generation capabilities of Chat GPT. This
paper delves into how advances in artificial intelligence will shape e-learning
in the coming decades, particularly in terms of Chat- GPT's ability to improve
learners' Communicative Competence when English is a second language. The
combination of new trends in artificial intelligence, mainly in the particular
case of English as a second language, and, at the academic level, chatbot
technology, will be the next step in the replacement of the human academic
community by virtual assistants, apparently until a certain point. Despite the
controversy, this very innovative solution will be able to bridge the gap
between technology and education. Moreover, such innovative practices
facilitate communication by enabling its inclusion in various applications,
including virtual assistants, chatbots, and language education. Keyword: Chat
GPT, artificial intelligence, Communicative Competence, Communicative Language
Teaching (CLT)
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00719" title="Abstract">arXiv:2311.00719</a> [<a href="/pdf/2311.00719" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is Human Culture Locked by Evolution?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Human culture has evolved for thousands of years and thrived in the era of
Internet. Due to the availability of big data, we could do research on human
culture by analyzing its representation such as user item rating values on
websites like MovieLens and Douban. Industrial workers have applied recommender
systems in big data to predict user behavior and promote web traffic. In this
paper, we analyze the social impact of an algorithm named ZeroMat to show that
human culture is locked into a state where individual's cultural taste is
predictable at high precision without historic data. We also provide solutions
to this problem and interpretation of current Chinese government's regulations
and policies.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00720" title="Abstract">arXiv:2311.00720</a> [<a href="/pdf/2311.00720" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harmonic content analysis of a soft starting variable frequency motor  drive based on FPGA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sapkota%2C+Y">Yogesh Sapkota</a>, 
<a href="/search/eess?searchtype=author&query=Devkota%2C+S">Suman Devkota</a>, 
<a href="/search/eess?searchtype=author&query=Borra%2C+V">Vamsi Borra</a>, 
<a href="/search/eess?searchtype=author&query=Cortes%2C+P">Pedro Cortes</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+F">Frank Li</a>, 
<a href="/search/eess?searchtype=author&query=Itapu%2C+S">Srikanth Itapu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sapkota, Yogesh, et al. "Harmonic content analysis of a soft
  starting variable frequency motor drive based on FPGA." 2023 IEEE 3rd
  International Conference on Sustainable Energy and Future Electric
  Transportation (SEFET). IEEE, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">As the demands for electric vehicles, electric aircrafts, unmanned aircraft
systems, and other motor-driven systems increase, high-performance motor drives
employing variable frequency control with higher efficiency and reliability are
becoming increasingly important parts of the ever-changing technological
landscape. This study proposes a Field Programmable Gate Array (FPGA)-based
variable frequency soft-starting motor drive for a three-phase induction motor.
The inverter output voltage and the load currents are analyzed for the harmonic
contents using MATLAB. In the experimental realization, a four-pole squirrel
cage delta-connected induction motor is utilized with a switching frequency of
4 kHz. The current and voltage characteristics of the induction motor are
studied under different operating conditions to study harmonic contents and the
effect of changing soft-start duration. The findings demonstrate a low-cost,
flexible control of the induction motor with improved harmonic performance.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00721" title="Abstract">arXiv:2311.00721</a> [<a href="/pdf/2311.00721" title="Download PDF">pdf</a>, <a href="/format/2311.00721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empathy Detection Using Machine Learning on Text, Audiovisual, Audio or  Physiological Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hasan%2C+M+R">Md Rakibul Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Hossain%2C+M+Z">Md Zakir Hossain</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Shreya Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Soon%2C+S">Susannah Soon</a>, 
<a href="/search/cs?searchtype=author&query=Gedeon%2C+T">Tom Gedeon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Empathy is a social skill that indicates an individual's ability to
understand others. Over the past few years, empathy has drawn attention from
various disciplines, including but not limited to Affective Computing,
Cognitive Science and Psychology. Empathy is a context-dependent term; thus,
detecting or recognising empathy has potential applications in society,
healthcare and education. Despite being a broad and overlapping topic, the
avenue of empathy detection studies leveraging Machine Learning remains
underexplored from a holistic literature perspective. To this end, we
systematically collect and screen 801 papers from 10 well-known databases and
analyse the selected 54 papers. We group the papers based on input modalities
of empathy detection systems, i.e., text, audiovisual, audio and physiological
signals. We examine modality-specific pre-processing and network architecture
design protocols, popular dataset descriptions and availability details, and
evaluation protocols. We further discuss the potential applications, deployment
challenges and research gaps in the Affective Computing-based empathy domain,
which can facilitate new avenues of exploration. We believe that our work is a
stepping stone to developing a privacy-preserving and unbiased empathic system
inclusive of culture, diversity and multilingualism that can be deployed in
practice to enhance the overall well-being of human life.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00724" title="Abstract">arXiv:2311.00724</a> [<a href="/pdf/2311.00724" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fraud Analytics Using Machine-learning &amp; Engineering on Big Data (FAME)  for Telecom
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pratihar%2C+S+R">Sudarson Roy Pratihar</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+S">Subhadip Paul</a>, 
<a href="/search/cs?searchtype=author&query=Dash%2C+P+K">Pranab Kumar Dash</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A+K">Amartya Kumar Das</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented in International Conference in Indian Institute of Management, Bangalore, India
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Telecom industries lose globally 46.3 Billion USD due to fraud. Data mining
and machine learning techniques (apart from rules oriented approach) have been
used in past, but efficiency has been low as fraud pattern changes very
rapidly. This paper presents an industrialized solution approach with self
adaptive data mining technique and application of big data technologies to
detect fraud and discover novel fraud patterns in accurate, efficient and cost
effective manner. Solution has been successfully demonstrated to detect
International Revenue Share Fraud with &lt;5% false positive. More than 1 Terra
Bytes of Call Detail Record from a reputed wholesale carrier and overseas
telecom transit carrier has been used to conduct this study.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00727" title="Abstract">arXiv:2311.00727</a> [<a href="/pdf/2311.00727" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Relative Performance of Transfer and Meta Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alwis%2C+B">Benji Alwis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Over the past decade, the field of machine learning has experienced
remarkable advancements. While image recognition systems have achieved
impressive levels of accuracy, they continue to rely on extensive training
datasets. Additionally, a significant challenge has emerged in the form of poor
out-of-distribution performance, which necessitates retraining neural networks
when they encounter conditions that deviate from their training data. This
limitation has notably contributed to the slow progress in self-driving car
technology. These pressing issues have sparked considerable interest in methods
that enable neural networks to learn effectively from limited data. This paper
presents the outcomes of an extensive investigation designed to compare two
distinct approaches, transfer learning and meta learning, as potential
solutions to this problem. The overarching objective was to establish a robust
criterion for selecting the most suitable method in diverse machine learning
scenarios. Building upon prior research, I expanded the comparative analysis by
introducing a new meta learning method into the investigation. Subsequently, I
assessed whether the findings remained consistent under varying conditions.
Finally, I delved into the impact of altering the size of the training dataset
on the relative performance of these methods. This comprehensive exploration
has yielded insights into the conditions favoring each approach, thereby
facilitating the development of a criterion for selecting the most appropriate
method in any given situation
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00728" title="Abstract">arXiv:2311.00728</a> [<a href="/pdf/2311.00728" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Collective Superintelligence, a Pilot Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rosenberg%2C+L">Louis Rosenberg</a>, 
<a href="/search/cs?searchtype=author&query=Willcox%2C+G">Gregg Willcox</a>, 
<a href="/search/cs?searchtype=author&query=Schumann%2C+H">Hans Schumann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Conversational Swarm Intelligence (CSI) is a new technology that enables
human groups of potentially any size to hold real-time deliberative
conversations online. Modeled on the dynamics of biological swarms, CSI aims to
optimize group insights and amplify group intelligence. It uses Large Language
Models (LLMs) in a novel framework to structure large-scale conversations,
combining the benefits of small-group deliberative reasoning and large-group
collective intelligence. In this study, a group of 241 real-time participants
were asked to estimate the number of gumballs in a jar by looking at a photo.
In one test case, individual participants entered their estimation in a
standard survey. In another test case, participants converged on groupwise
estimates collaboratively using a prototype CSI text-chat platform called
Thinkscape. The results show that when using CSI, the group of 241 participants
estimated within 12% of the correct answer, which was significantly more
accurate (p&lt;0.001) than the average individual (mean error of 55%) and the
survey-based Wisdom of Crowd (error of 25%). The group using CSI was also more
accurate than an estimate generated by GPT 4 (error of 42%). This suggests that
CSI is a viable method for enabling large, networked groups to hold coherent
real-time deliberative conversations that amplify collective intelligence.
Because this technology is scalable, it could provide a possible pathway
towards building a general-purpose Collective Superintelligence (CSi).
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00729" title="Abstract">arXiv:2311.00729</a> [<a href="/pdf/2311.00729" title="Download PDF">pdf</a>, <a href="/format/2311.00729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZEETAD: Adapting Pretrained Vision-Language Model for Zero-Shot  End-to-End Temporal Action Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phan%2C+T">Thinh Phan</a>, 
<a href="/search/cs?searchtype=author&query=Vo%2C+K">Khoa Vo</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+D">Duy Le</a>, 
<a href="/search/cs?searchtype=author&query=Doretto%2C+G">Gianfranco Doretto</a>, 
<a href="/search/cs?searchtype=author&query=Adjeroh%2C+D">Donald Adjeroh</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+N">Ngan Le</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Temporal action detection (TAD) involves the localization and classification
of action instances within untrimmed videos. While standard TAD follows fully
supervised learning with closed-set setting on large training data, recent
zero-shot TAD methods showcase the promising of open-set setting by leveraging
large-scale contrastive visual-language (ViL) pretrained models. However,
existing zero-shot TAD methods have limitations on how to properly construct
the strong relationships between two interdependent tasks of localization and
classification and adapt ViL model to video understanding. In this work, we
present ZEETAD, featuring two modules: dual-localization and zero-shot proposal
classification. The former is a Transformer-based module that detects action
events while selectively collecting crucial semantic embeddings for later
recognition. The latter one, CLIP-based module, generates semantic embeddings
from text and frame inputs for each temporal unit. Additionally, we enhance
discriminative capability on unseen classes by minimally updating the frozen
CLIP encoder with lightweight adapters. Extensive experiments on THUMOS14 and
ActivityNet-1.3 datasets demonstrate our approach's superior performance in
zero-shot TAD and effective knowledge transfer from ViL models to unseen action
categories.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00731" title="Abstract">arXiv:2311.00731</a> [<a href="/pdf/2311.00731" title="Download PDF">pdf</a>, <a href="/format/2311.00731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Clustering Representations with Positive Proximity and Cluster  Dispersion Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Abhishek Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dong-Gyu Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Contemporary deep clustering approaches often rely on either contrastive or
non-contrastive techniques to acquire effective representations for clustering
tasks. Contrastive methods leverage negative pairs to achieve homogenous
representations but can introduce class collision issues, potentially
compromising clustering performance. On the contrary, non-contrastive
techniques prevent class collisions but may produce non-uniform representations
that lead to clustering collapse. In this work, we propose a novel end-to-end
deep clustering approach named PIPCDR, designed to harness the strengths of
both approaches while mitigating their limitations. PIPCDR incorporates a
positive instance proximity loss and a cluster dispersion regularizer. The
positive instance proximity loss ensures alignment between augmented views of
instances and their sampled neighbors, enhancing within-cluster compactness by
selecting genuinely positive pairs within the embedding space. Meanwhile, the
cluster dispersion regularizer maximizes inter-cluster distances while
minimizing within-cluster compactness, promoting uniformity in the learned
representations. PIPCDR excels in producing well-separated clusters, generating
uniform representations, avoiding class collision issues, and enhancing
within-cluster compactness. We extensively validate the effectiveness of PIPCDR
within an end-to-end Majorize-Minimization framework, demonstrating its
competitive performance on moderate-scale clustering benchmark datasets and
establishing new state-of-the-art results on large-scale datasets.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00732" title="Abstract">arXiv:2311.00732</a> [<a href="/pdf/2311.00732" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> tmn at #SMM4H 2023: Comparing Text Preprocessing Techniques for  Detecting Tweets Self-reporting a COVID-19 Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Glazkova%2C+A">Anna Glazkova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been peer-reviewed and accepted for presentation at the #SMM4H 2023 Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">The paper describes a system developed for Task 1 at SMM4H 2023. The goal of
the task is to automatically distinguish tweets that self-report a COVID-19
diagnosis (for example, a positive test, clinical diagnosis, or
hospitalization) from those that do not. We investigate the use of different
techniques for preprocessing tweets using four transformer-based models. The
ensemble of fine-tuned language models obtained an F1-score of 84.5%, which is
4.1% higher than the average value.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00733" title="Abstract">arXiv:2311.00733</a> [<a href="/pdf/2311.00733" title="Download PDF">pdf</a>, <a href="/format/2311.00733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAT Solving Using XOR-OR-AND Normal Forms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Andraschko%2C+B">Bernhard Andraschko</a>, 
<a href="/search/cs?searchtype=author&query=Danner%2C+J">Julian Danner</a>, 
<a href="/search/cs?searchtype=author&query=Kreuzer%2C+M">Martin Kreuzer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Commutative Algebra (math.AC); Logic (math.LO)

</div>
<p class="mathjax">This paper introduces the XOR-OR-AND normal form (XNF) for logical formulas.
It is a generalization of the well-known Conjunctive Normal Form (CNF) where
literals are replaced by XORs of literals. As a first theoretic result, we show
that every formula is equisatisfiable to a formula in 2-XNF, i.e., a formula in
XNF where each disjunction involves at most two XORs of literals. Subsequently,
we present an algorithm which converts Boolean polynomials efficiently from
their Algebraic Normal Form (ANF) to formulas in 2-XNF. Experiments with the
cipher ASCON-128 show that cryptographic problems, which by design are based
strongly on XOR-operations, can be represented using far fewer variables and
clauses in 2-XNF than in CNF. In order to take advantage of this compact
representation, new SAT solvers based on input formulas in 2-XNF need to be
designed. By taking inspiration from graph-based 2-CNF SAT solving, we devise a
new DPLL-based SAT solver for formulas in 2-XNF. Among others, we present
advanced pre- and in-processing techniques. Finally, we give timings for random
2-XNF instances and instances related to key recovery attacks on round reduced
ASCON-128, where our solver outperforms state-of-the-art alternative solving
approaches.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00734" title="Abstract">arXiv:2311.00734</a> [<a href="/pdf/2311.00734" title="Download PDF">pdf</a>, <a href="/format/2311.00734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Manipulating Scene Text in the Wild with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santoso%2C+J">Joshua Santoso</a>, 
<a href="/search/cs?searchtype=author&query=Simon%2C+C">Christian Simon</a>, 
<a href="/search/cs?searchtype=author&query=Pao%2C+W">Williem Pao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion models have gained attention for image editing yielding impressive
results in text-to-image tasks. On the downside, one might notice that
generated images of stable diffusion models suffer from deteriorated details.
This pitfall impacts image editing tasks that require information preservation
e.g., scene text editing. As a desired result, the model must show the
capability to replace the text on the source image to the target text while
preserving the details e.g., color, font size, and background. To leverage the
potential of diffusion models, in this work, we introduce Diffusion-BasEd Scene
Text manipulation Network so-called DBEST. Specifically, we design two
adaptation strategies, namely one-shot style adaptation and text-recognition
guidance. In experiments, we thoroughly assess and compare our proposed method
against state-of-the-arts on various scene text datasets, then provide
extensive ablation studies for each granularity to analyze our performance
gain. Also, we demonstrate the effectiveness of our proposed method to
synthesize scene text indicated by competitive Optical Character Recognition
(OCR) accuracy. Our method achieves 94.15% and 98.12% on COCO-text and
ICDAR2013 datasets for character-level evaluation.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00735" title="Abstract">arXiv:2311.00735</a> [<a href="/pdf/2311.00735" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PET Tracer Conversion among Brain PET via Variable Augmented Invertible  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+B">Bohui Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xubiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P">Pengfei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shirui Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xinchong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangsong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaoyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weirui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bingxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qiegen Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Positron emission tomography (PET), as an imaging technique with high
biochemical sensitivity, has been widely used in diagnosis of encephalopathy
and brain science research used in brain disease diagnosis and brain science
research. Since different tracers present different effects on the same focal
area, the choice of tracers is getting more significant for PET imaging.
Nowadays, with the wide application of PET imaging in neuropsychiatric
treatment, 6-18F-fluoro-3, 4-dihydroxy-L-phenylalanine (DOPA) has been found to
be more effective than 18F-labeled fluorine-2-deoxyglucose (FDG) in this field.
However, due to the complexity of its preparation and other limitations, DOPA
is far less widely used than FDG. To address this issue, a tracer conversion
invertible neural network (TC-INN) for image projection is developed to map FDG
images to DOPA images through deep learning. More diagnostic information is
obtained by generating PET images from FDG to DOPA. Specifically, the proposed
TC-INN consists of two separate phases, one for training the traceable data,
the other for re-building the new data. The reference DOPA PET image is used as
the learning target for the corresponding network during the training process
of tracer conversion. Mean-while, the invertible network iteratively estimates
the resultant DOPA PET data and compares it to the reference DOPA PET data.
Notably, the reversible model employed variable enhancement techniques to
achieve better power generation. Moreover, image registration needs to be
performed before training due to the angular deviation of the acquired FDG and
DOPA data information. Experimental results show generative ability in mapping
be-tween FDG images and DOPA images. It demonstrates great potential for PET
image conversion in the case of limited tracer applications.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00737" title="Abstract">arXiv:2311.00737</a> [<a href="/pdf/2311.00737" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Magnetic Tracking and Diagnosis of COVID-19 via Machine  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D">Dang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Huynh%2C+P+K">Phat K. Huynh</a>, 
<a href="/search/cs?searchtype=author&query=Bui%2C+V+D+A">Vinh Duc An Bui</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+K+Y">Kee Young Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+N">Nityanand Jain</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+C">Chau Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Minh%2C+L+H+N">Le Huu Nhat Minh</a>, 
<a href="/search/cs?searchtype=author&query=Van+Truong%2C+L">Le Van Truong</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+X+T">Xuan Thanh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+H">Dinh Hoang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Dung%2C+L+T">Le Tien Dung</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T+Q">Trung Q. Le</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+M">Manh-Huong Phan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Instrumentation and Detectors (physics.ins-det); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">The COVID-19 pandemic underscored the importance of reliable, noninvasive
diagnostic tools for robust public health interventions. In this work, we fused
magnetic respiratory sensing technology (MRST) with machine learning (ML) to
create a diagnostic platform for real-time tracking and diagnosis of COVID-19
and other respiratory diseases. The MRST precisely captures breathing patterns
through three specific breath testing protocols: normal breath, holding breath,
and deep breath. We collected breath data from both COVID-19 patients and
healthy subjects in Vietnam using this platform, which then served to train and
validate ML models. Our evaluation encompassed multiple ML algorithms,
including support vector machines and deep learning models, assessing their
ability to diagnose COVID-19. Our multi-model validation methodology ensures a
thorough comparison and grants the adaptability to select the most optimal
model, striking a balance between diagnostic precision with model
interpretability. The findings highlight the exceptional potential of our
diagnostic tool in pinpointing respiratory anomalies, achieving over 90%
accuracy. This innovative sensor technology can be seamlessly integrated into
healthcare settings for patient monitoring, marking a significant enhancement
for the healthcare infrastructure.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00738" title="Abstract">arXiv:2311.00738</a> [<a href="/pdf/2311.00738" title="Download PDF">pdf</a>, <a href="/format/2311.00738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Foundation Models Watch, Talk and Guide You Step by Step to Make a  Cake?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+Y">Yuwei Bao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K+P">Keunwoo Peter Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yichi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Storks%2C+S">Shane Storks</a>, 
<a href="/search/cs?searchtype=author&query=Bar-Yossef%2C+I">Itamar Bar-Yossef</a>, 
<a href="/search/cs?searchtype=author&query=De+La+Iglesia%2C+A">Alexander De La Iglesia</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+M">Megan Su</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X+L">Xiao Lin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+J">Joyce Chai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Despite tremendous advances in AI, it remains a significant challenge to
develop interactive task guidance systems that can offer situated, personalized
guidance and assist humans in various tasks. These systems need to have a
sophisticated understanding of the user as well as the environment, and make
timely accurate decisions on when and what to say. To address this issue, we
created a new multimodal benchmark dataset, Watch, Talk and Guide (WTaG) based
on natural interaction between a human user and a human instructor. We further
proposed two tasks: User and Environment Understanding, and Instructor Decision
Making. We leveraged several foundation models to study to what extent these
models can be quickly adapted to perceptually enabled task guidance. Our
quantitative, qualitative, and human evaluation results show that these models
can demonstrate fair performances in some cases with no task-specific training,
but a fast and reliable adaptation remains a significant challenge. Our
benchmark and baselines will provide a stepping stone for future work on
situated task guidance.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00739" title="Abstract">arXiv:2311.00739</a> [<a href="/pdf/2311.00739" title="Download PDF">pdf</a>, <a href="/format/2311.00739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Large Language Models Design Accurate Label Functions?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+N">Naiqing Guan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kaiwen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Koudas%2C+N">Nick Koudas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, submitted to VLDB 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Databases (cs.DB); Machine Learning (cs.LG)

</div>
<p class="mathjax">Programmatic weak supervision methodologies facilitate the expedited labeling
of extensive datasets through the use of label functions (LFs) that encapsulate
heuristic data sources. Nonetheless, the creation of precise LFs necessitates
domain expertise and substantial endeavors. Recent advances in pre-trained
language models (PLMs) have exhibited substantial potential across diverse
tasks. However, the capacity of PLMs to autonomously formulate accurate LFs
remains an underexplored domain. In this research, we address this gap by
introducing DataSculpt, an interactive framework that harnesses PLMs for the
automated generation of LFs. Within DataSculpt, we incorporate an array of
prompting techniques, instance selection strategies, and LF filtration methods
to explore the expansive design landscape. Ultimately, we conduct a thorough
assessment of DataSculpt's performance on 12 real-world datasets, encompassing
a range of tasks. This evaluation unveils both the strengths and limitations of
contemporary PLMs in LF design.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00749" title="Abstract">arXiv:2311.00749</a> [<a href="/pdf/2311.00749" title="Download PDF">pdf</a>, <a href="/format/2311.00749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sorting with Predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xingjian Bai</a>, 
<a href="/search/cs?searchtype=author&query=Coester%2C+C">Christian Coester</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We explore the fundamental problem of sorting through the lens of
learning-augmented algorithms, where algorithms can leverage possibly erroneous
predictions to improve their efficiency. We consider two different settings: In
the first setting, each item is provided a prediction of its position in the
sorted list. In the second setting, we assume there is a "quick-and-dirty" way
of comparing items, in addition to slow-and-exact comparisons. For both
settings, we design new and simple algorithms using only $O(\sum_i \log
\eta_i)$ exact comparisons, where $\eta_i$ is a suitably defined prediction
error for the $i$th element. In particular, as the quality of predictions
deteriorates, the number of comparisons degrades smoothly from $O(n)$ to
$O(n\log n)$. We prove that the comparison complexity is theoretically optimal
with respect to the examined error measures. An experimental evaluation against
existing adaptive and non-adaptive sorting algorithms demonstrates the
potential of applying learning-augmented algorithms in sorting tasks.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00750" title="Abstract">arXiv:2311.00750</a> [<a href="/pdf/2311.00750" title="Download PDF">pdf</a>, <a href="/format/2311.00750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are These the Same Apple? Comparing Images Based on Object Intrinsics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kotar%2C+K">Klemen Kotar</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+S">Stephen Tian</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hong-Xing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yamins%2C+D+L+K">Daniel L.K. Yamins</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First two authors contributed equally. Accepted at NeurIPS Datasets and Benchmarks Track 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The human visual system can effortlessly recognize an object under different
extrinsic factors such as lighting, object poses, and background, yet current
computer vision systems often struggle with these variations. An important step
to understanding and improving artificial vision systems is to measure image
similarity purely based on intrinsic object properties that define object
identity. This problem has been studied in the computer vision literature as
re-identification, though mostly restricted to specific object categories such
as people and cars. We propose to extend it to general object categories,
exploring an image similarity metric based on object intrinsics. To benchmark
such measurements, we collect the Common paired objects Under differenT
Extrinsics (CUTE) dataset of $18,000$ images of $180$ objects under different
extrinsic factors such as lighting, poses, and imaging conditions. While
existing methods such as LPIPS and CLIP scores do not measure object intrinsics
well, we find that combining deep features learned from contrastive
self-supervised learning with foreground filtering is a simple yet effective
approach to approximating the similarity. We conduct an extensive survey of
pre-trained features and foreground extraction methods to arrive at a strong
baseline that best measures intrinsic object-centric image similarity among
current methods. Finally, we demonstrate that our approach can aid in
downstream applications such as acting as an analog for human subjects and
improving generalizable re-identification. Please see our project website at
https://s-tian.github.io/projects/cute/ for visualizations of the data and
demos of our metric.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00754" title="Abstract">arXiv:2311.00754</a> [<a href="/pdf/2311.00754" title="Download PDF">pdf</a>, <a href="/format/2311.00754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Design and Use Tools for Robotic Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+S">Stephen Tian</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Michelle Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C+K">C. Karen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First two authors contributed equally. Accepted at CoRL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">When limited by their own morphologies, humans and some species of animals
have the remarkable ability to use objects from the environment toward
accomplishing otherwise impossible tasks. Robots might similarly unlock a range
of additional capabilities through tool use. Recent techniques for jointly
optimizing morphology and control via deep learning are effective at designing
locomotion agents. But while outputting a single morphology makes sense for
locomotion, manipulation involves a variety of strategies depending on the task
goals at hand. A manipulation agent must be capable of rapidly prototyping
specialized tools for different goals. Therefore, we propose learning a
designer policy, rather than a single design. A designer policy is conditioned
on task information and outputs a tool design that helps solve the task. A
design-conditioned controller policy can then perform manipulation using these
tools. In this work, we take a step towards this goal by introducing a
reinforcement learning framework for jointly learning these policies. Through
simulated manipulation tasks, we show that this framework is more sample
efficient than prior methods in multi-goal or multi-variant settings, can
perform zero-shot interpolation or fine-tuning to tackle previously unseen
goals, and allows tradeoffs between the complexity of design and control
policies under practical constraints. Finally, we deploy our learned policies
onto a real robot. Please see our supplementary video and website at
https://robotic-tool-design.github.io/ for visualizations.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00762" title="Abstract">arXiv:2311.00762</a> [<a href="/pdf/2311.00762" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges for Linguistically-Driven Computer-Based Sign Recognition  from Continuous Signing for American Sign Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neidle%2C+C">Carol Neidle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 24 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">There have been recent advances in computer-based recognition of isolated,
citation-form signs from video. There are many challenges for such a task, not
least the naturally occurring inter- and intra- signer synchronic variation in
sign production, including sociolinguistic variation in the realization of
certain signs. However, there are several significant factors that make
recognition of signs from continuous signing an even more difficult problem.
This article presents an overview of such challenges, based in part on findings
from a large corpus of linguistically annotated video data for American Sign
Language (ASL). Some linguistic regularities in the structure of signs that can
boost handshape and sign recognition are also discussed.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00767" title="Abstract">arXiv:2311.00767</a> [<a href="/pdf/2311.00767" title="Download PDF">pdf</a>, <a href="/format/2311.00767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hand Gesture Classification on Praxis Dataset: Trading Accuracy for  Expense
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+R">Rahat Islam</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+K">Kenneth Lai</a>, 
<a href="/search/cs?searchtype=author&query=Yanushkevich%2C+S">Svetlana Yanushkevich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2022 International Joint Conference on Neural Networks (IJCNN),
  Padua, pp. 1-8
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In this paper, we investigate hand gesture classifiers that rely upon the
abstracted 'skeletal' data recorded using the RGB-Depth sensor. We focus on
'skeletal' data represented by the body joint coordinates, from the Praxis
dataset. The PRAXIS dataset contains recordings of patients with cortical
pathologies such as Alzheimer's disease, performing a Praxis test under the
direction of a clinician. In this paper, we propose hand gesture classifiers
that are more effective with the PRAXIS dataset than previously proposed
models. Body joint data offers a compressed form of data that can be analyzed
specifically for hand gesture recognition. Using a combination of windowing
techniques with deep learning architecture such as a Recurrent Neural Network
(RNN), we achieved an overall accuracy of 70.8% using only body joint data. In
addition, we investigated a long-short-term-memory (LSTM) to extract and
analyze the movement of the joints through time to recognize the hand gestures
being performed and achieved a gesture recognition rate of 74.3% and 67.3% for
static and dynamic gestures, respectively. The proposed approach contributed to
the task of developing an automated, accurate, and inexpensive approach to
diagnosing cortical pathologies for multiple healthcare applications.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00768" title="Abstract">arXiv:2311.00768</a> [<a href="/pdf/2311.00768" title="Download PDF">pdf</a>, <a href="/format/2311.00768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Model Training Paradigms for Clinical Feature Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yurong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Burger%2C+M">Manuel Burger</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%A4tsch%2C+G">Gunnar R&#xe4;tsch</a>, 
<a href="/search/cs?searchtype=author&query=Kuznetsova%2C+R">Rita Kuznetsova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Poster at "NeurIPS 2023 Workshop: Self-Supervised Learning - Theory and Practice"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">In research areas with scarce data, representation learning plays a
significant role. This work aims to enhance representation learning for
clinical time series by deriving universal embeddings for clinical features,
such as heart rate and blood pressure. We use self-supervised training
paradigms for language models to learn high-quality clinical feature
embeddings, achieving a finer granularity than existing time-step and
patient-level representation learning. We visualize the learnt embeddings via
unsupervised dimension reduction techniques and observe a high degree of
consistency with prior clinical knowledge. We also evaluate the model
performance on the MIMIC-III benchmark and demonstrate the effectiveness of
using clinical feature embeddings. We publish our code online for replication.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00769" title="Abstract">arXiv:2311.00769</a> [<a href="/pdf/2311.00769" title="Download PDF">pdf</a>, <a href="/format/2311.00769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Integrated Approach to Aerial Grasping: Combining a Bistable Gripper  with Adaptive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yadav%2C+R+D">Rishabh Dev Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+B">Brycen Jones</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Saksham Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Amitabh Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiefeng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jianguo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+S">Spandan Roy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Grasping using an aerial robot can have many applications ranging from
infrastructure inspection and maintenance to precise agriculture. However,
aerial grasping is a challenging problem since the robot has to maintain an
accurate position and orientation relative to the grasping object, while
negotiating various forms of uncertainties (e.g., contact force from the
object). To address such challenges, in this paper, we integrate a novel
passive gripper design and advanced adaptive control methods to enable robust
aerial grasping. The gripper is enabled by a pre-stressed band with two stable
states (a flat shape and a curled shape). In this case, it can automatically
initiate the grasping process upon contact with an object. The gripper also
features a cable-driven system by a single DC motor to open the gripper without
using cumbersome pneumatics. Since the gripper is passively triggered and
initially has a straight shape, it can function without precisely aligning the
gripper with the object (within an $80$ mm tolerance). Our adaptive control
scheme eliminates the need for any a priori knowledge (nominal or upper bounds)
of uncertainties. The closed-loop stability of the system is analyzed via
Lyapunov-based method. Combining the gripper and the adaptive control, we
conduct comparative real-time experimental results to demonstrate the
effectiveness of the proposed integrated system for grasping. Our integrated
approach can pave the way to enhance aerial grasping for different
applications.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00772" title="Abstract">arXiv:2311.00772</a> [<a href="/pdf/2311.00772" title="Download PDF">pdf</a>, <a href="/format/2311.00772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAGE: Smart home Agent with Grounded Execution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rivkin%2C+D">Dmitriy Rivkin</a>, 
<a href="/search/cs?searchtype=author&query=Hogan%2C+F">Francois Hogan</a>, 
<a href="/search/cs?searchtype=author&query=Feriani%2C+A">Amal Feriani</a>, 
<a href="/search/cs?searchtype=author&query=Konar%2C+A">Abhisek Konar</a>, 
<a href="/search/cs?searchtype=author&query=Sigal%2C+A">Adam Sigal</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Steve Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dudek%2C+G">Greg Dudek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC); Robotics (cs.RO)

</div>
<p class="mathjax">This article introduces SAGE (Smart home Agent with Grounded Execution), a
framework designed to maximize the flexibility of smart home assistants by
replacing manually-defined inference logic with an LLM-powered autonomous agent
system. SAGE integrates information about user preferences, device states, and
external factors (such as weather and TV schedules) through the orchestration
of a collection of tools. SAGE's capabilities include learning user preferences
from natural-language utterances, interacting with devices by reading their API
documentation, writing code to continuously monitor devices, and understanding
natural device references. To evaluate SAGE, we develop a benchmark of 43
highly challenging smart home tasks, where SAGE successfully achieves 23 tasks,
significantly outperforming existing LLM-enabled baselines (5/43).
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00774" title="Abstract">arXiv:2311.00774</a> [<a href="/pdf/2311.00774" title="Download PDF">pdf</a>, <a href="/format/2311.00774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conformalized Deep Splines for Optimal and Efficient Prediction Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diamant%2C+N">Nathaniel Diamant</a>, 
<a href="/search/cs?searchtype=author&query=Hajiramezanali%2C+E">Ehsan Hajiramezanali</a>, 
<a href="/search/cs?searchtype=author&query=Biancalani%2C+T">Tommaso Biancalani</a>, 
<a href="/search/cs?searchtype=author&query=Scalia%2C+G">Gabriele Scalia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Uncertainty estimation is critical in high-stakes machine learning
applications. One effective way to estimate uncertainty is conformal
prediction, which can provide predictive inference with statistical coverage
guarantees. We present a new conformal regression method, Spline Prediction
Intervals via Conformal Estimation (SPICE), that estimates the conditional
density using neural-network-parameterized splines. We prove universal
approximation and optimality results for SPICE, which are empirically validated
by our experiments. SPICE is compatible with two different efficient-to-compute
conformal scores, one oracle-optimal for marginal coverage (SPICE-ND) and the
other asymptotically optimal for conditional coverage (SPICE-HPD). Results on
benchmark datasets demonstrate SPICE-ND models achieve the smallest average
prediction set sizes, including average size reductions of nearly 50% for some
datasets compared to the next best baseline. SPICE-HPD models achieve the best
conditional coverage compared to baselines. The SPICE implementation is made
available.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00778" title="Abstract">arXiv:2311.00778</a> [<a href="/pdf/2311.00778" title="Download PDF">pdf</a>, <a href="/format/2311.00778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence of Heterogeneous Learning Dynamics in Zero-sum Stochastic  Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arslantas%2C+Y">Yuksel Arslantas</a>, 
<a href="/search/cs?searchtype=author&query=Yuceel%2C+E">Ege Yuceel</a>, 
<a href="/search/cs?searchtype=author&query=Yalin%2C+Y">Yigit Yalin</a>, 
<a href="/search/cs?searchtype=author&query=Sayin%2C+M+O">Muhammed O. Sayin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">This paper presents new families of algorithms for the repeated play of
two-agent (near) zero-sum games and two-agent zero-sum stochastic games. For
example, the family includes fictitious play and its variants as members.
Commonly, the algorithms in this family are all uncoupled, rational, and
convergent even in heterogeneous cases, e.g., where the dynamics may differ in
terms of learning rates, full, none or temporal access to opponent actions, and
model-based vs model-free learning. The convergence of heterogeneous dynamics
is of practical interest especially in competitive environments since agents
may have no means or interests in following the same dynamic with the same
parameters. We prove that any mixture of such asymmetries does not impact the
algorithms' convergence to equilibrium (or near equilibrium if there is
experimentation) in zero-sum games with repeated play and in zero-sum
(irreducible) stochastic games with sufficiently small discount factors.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00779" title="Abstract">arXiv:2311.00779</a> [<a href="/pdf/2311.00779" title="Download PDF">pdf</a>, <a href="/format/2311.00779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shortest paths on polymatroids and hypergraphic polytopes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cardinal%2C+J">Jean Cardinal</a>, 
<a href="/search/cs?searchtype=author&query=Steiner%2C+R">Raphael Steiner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 5 figures, full version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO); Optimization and Control (math.OC)

</div>
<p class="mathjax">Base polytopes of polymatroids, also known as generalized permutohedra, are
polytopes whose edges are parallel to a vector of the form $\mathbf{e}_i -
\mathbf{e}_j$. We consider the following computational problem: Given two
vertices of a generalized permutohedron $P$, find a shortest path between them
on the skeleton of $P$. This captures many known flip distance problems, such
as computing the minimum number of exchanges between two spanning trees of a
graph, the rotation distance between binary search trees, the flip distance
between acyclic orientations of a graph, or rectangulations of a square. We
prove that this problem is $NP$-hard, even when restricted to very simple
polymatroids in $\mathbb{R}^n$ defined by $O(n)$ inequalities. Assuming $P\not=
NP$, this rules out the existence of an efficient simplex pivoting rule that
performs a minimum number of nondegenerate pivoting steps to an optimal
solution of a linear program, even when the latter defines a polymatroid. We
also prove that the shortest path problem is inapproximable when the
polymatroid is specified via an evaluation oracle for a corresponding
submodular function, strengthening a recent result by Ito et al. (ICALP'23).
More precisely, we prove the $APX$-hardness of the shortest path problem when
the polymatroid is a hypergraphic polytope, whose vertices are in bijection
with acyclic orientations of a given hypergraph. The shortest path problem then
amounts to computing the flip distance between two acyclic orientations of a
hypergraph. On the positive side, we provide a polynomial-time approximation
algorithm for the problem of computing the flip distance between two acyclic
orientations of a hypergraph, where the approximation factor is the maximum
codegree of the hypergraph. Our result implies an exact polynomial-time
algorithm for the flip distance between two acyclic orientations of any linear
hypergraph.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00785" title="Abstract">arXiv:2311.00785</a> [<a href="/pdf/2311.00785" title="Download PDF">pdf</a>, <a href="/format/2311.00785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Cost of Interruptions in Human-Robot Teaming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mannem%2C+S">Swathi Mannem</a>, 
<a href="/search/cs?searchtype=author&query=Macke%2C+W">William Macke</a>, 
<a href="/search/cs?searchtype=author&query=Stone%2C+P">Peter Stone</a>, 
<a href="/search/cs?searchtype=author&query=Mirsky%2C+R">Reuth Mirsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint of a paper accepted for publication in Humanoids 2023 (<a href="https://2023.ieee-humanoids.org/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Productive and efficient human-robot teaming is a highly desirable ability in
service robots, yet there is a fundamental trade-off that a robot needs to
consider in such tasks. On the one hand, gaining information from communication
with teammates can help individual planning. On the other hand, such
communication comes at the cost of distracting teammates from efficiently
completing their goals, which can also harm the overall team performance. In
this study, we quantify the cost of interruptions in terms of degradation of
human task performance, as a robot interrupts its teammate to gain information
about their task. Interruptions are varied in timing, content, and proximity.
The results show that people find the interrupting robot significantly less
helpful. However, the human teammate's performance in a secondary task
deteriorates only slightly when interrupted. These results imply that while
interruptions can objectively have a low cost, an uninformed implementation can
cause these interruptions to be perceived as distracting. These research
outcomes can be leveraged in numerous applications where collaborative robots
must be aware of the costs and gains of interruptive communication, including
logistics and service robots.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00788" title="Abstract">arXiv:2311.00788</a> [<a href="/pdf/2311.00788" title="Download PDF">pdf</a>, <a href="/format/2311.00788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Code Sparsification and its Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khanna%2C+S">Sanjeev Khanna</a>, 
<a href="/search/cs?searchtype=author&query=Putterman%2C+A+L">Aaron L Putterman</a>, 
<a href="/search/cs?searchtype=author&query=Sudan%2C+M">Madhu Sudan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We introduce a notion of code sparsification that generalizes the notion of
cut sparsification in graphs. For a (linear) code $\mathcal{C} \subseteq
\mathbb{F}_q^n$ of dimension $k$ a $(1 \pm \epsilon)$-sparsification of size
$s$ is given by a weighted set $S \subseteq [n]$ with $|S| \leq s$ such that
for every codeword $c \in \mathcal{C}$ the projection $c|_S$ of $c$ to the set
$S$ has (weighted) hamming weight which is a $(1 \pm \epsilon)$ approximation
of the hamming weight of $c$. We show that for every code there exists a $(1
\pm \epsilon)$-sparsification of size $s = \widetilde{O}(k \log (q) /
\epsilon^2)$. This immediately implies known results on graph and hypergraph
cut sparsification up to polylogarithmic factors (with a simple unified proof).
<br />One application of our result is near-linear size sparsifiers for constraint
satisfaction problems (CSPs) over $\mathbb{F}_p$-valued variables whose
unsatisfying assignments can be expressed as the zeros of a linear equation
modulo a prime $p$. Building on this, we obtain a complete characterization of
ternary Boolean CSPs that admit near-linear size sparsification. Finally, by
connections between the eigenvalues of the Laplacians of Cayley graphs over
$\mathbb{F}_2^k$ to the weights of codewords, we also give the first proof of
the existence of spectral Cayley graph sparsifiers over $\mathbb{F}_2^k$ by
Cayley graphs, i.e., where we sparsify the set of generators to nearly-optimal
size.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00790" title="Abstract">arXiv:2311.00790</a> [<a href="/pdf/2311.00790" title="Download PDF">pdf</a>, <a href="/format/2311.00790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Construction Artifacts in Metaphor Identification Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boisson%2C+J">Joanne Boisson</a>, 
<a href="/search/cs?searchtype=author&query=Espinosa-Anke%2C+L">Luis Espinosa-Anke</a>, 
<a href="/search/cs?searchtype=author&query=Camacho-Collados%2C+J">Jose Camacho-Collados</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Short paper accepted to EMNLP 2023 main conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Metaphor identification aims at understanding whether a given expression is
used figuratively in context. However, in this paper we show how existing
metaphor identification datasets can be gamed by fully ignoring the potential
metaphorical expression or the context in which it occurs. We test this
hypothesis in a variety of datasets and settings, and show that metaphor
identification systems based on language models without complete information
can be competitive with those using the full context. This is due to the
construction procedures to build such datasets, which introduce unwanted biases
for positive and negative classes. Finally, we test the same hypothesis on
datasets that are carefully sampled from natural corpora and where this bias is
not present, making these datasets more challenging and reliable.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00791" title="Abstract">arXiv:2311.00791</a> [<a href="/pdf/2311.00791" title="Download PDF">pdf</a>, <a href="/ps/2311.00791" title="Download PostScript">ps</a>, <a href="/format/2311.00791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Where to Deploy an Airborne Relay in Unknown Environments: Feasible  Locations for Throughput and LoS Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pabon%2C+J+D">Juan David Pabon</a>, 
<a href="/search/cs?searchtype=author&query=Valenti%2C+M+C">Matthew C. Valenti</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xi Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Military Communications Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">The deployment of heterogeneous teams of both air and ground mobile assets
combines the advantages of mobility, sensing capability, and operational
duration when performing complex tasks. Air assets in such teams act to relay
information between ground assets but must maintain unblocked paths to enable
high-capacity communication modes. Obstacles in the operational environment may
block the line of sight (LoS) between air assets and ground assets depending on
their locations and heights. In this paper, we analyze the probability of
spanning a two-hop communication between a pair of ground assets deployed in an
environment with obstacles at random locations and with random heights (i.e. a
Poisson Forest) using an air asset at any location near the ground assets. We
provide a closed-form expression of the LoS probability based on the
3-dimensional locations of the air asset. We then compute a 3-D manifold of the
air asset locations that satisfy a given LoS probability constraint. We further
consider throughput as a measure of communication quality, and use it as an
optimization objective.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00792" title="Abstract">arXiv:2311.00792</a> [<a href="/pdf/2311.00792" title="Download PDF">pdf</a>, <a href="/format/2311.00792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring the Impact of Distractors on Student Learning Gains while  Using Proof Blocks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poulsen%2C+S">Seth Poulsen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongxuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gertner%2C+Y">Yael Gertner</a>, 
<a href="/search/cs?searchtype=author&query=Cosman%2C+B">Benjamin Cosman</a>, 
<a href="/search/cs?searchtype=author&query=West%2C+M">Matthew West</a>, 
<a href="/search/cs?searchtype=author&query=Herman%2C+G+L">Geoffrey L Herman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2211.09609">arXiv:2211.09609</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Background: Proof Blocks is a software tool that enables students to
construct proofs by assembling prewritten lines and gives them automated
feedback. Prior work on learning gains from Proof Blocks has focused on
comparing learning gains from Proof Blocks against other learning activities
such as writing proofs or reading.
<br />Purpose: The study described in this paper aims to compare learning gains
from different variations of Proof Blocks. Specifically, we attempt to quantify
the difference in learning gains for students who complete Proof Blocks
problems with and without distractors.
<br />Methods: We conducted a randomized controlled trial with three experimental
groups: a control group that completed an off-topic Proof Blocks activity, one
that completed a \tool{} activity without distractors, and one that completed a
Proof Blocks activity with distractors. All three groups read a book chapter on
proof by induction before completing their activity.
<br />Findings: The group that completed the Proof Blocks activity with distractors
performed better on the posttest than the group that completed the Proof Blocks
without distractors, who in turn performed better than the group that completed
the off-topic Proof Blocks activity. However, none of these differences were
statistically significant. While the results of this study are inconclusive, we
hope that it can serve as a foundation for future work.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00796" title="Abstract">arXiv:2311.00796</a> [<a href="/pdf/2311.00796" title="Download PDF">pdf</a>, <a href="/format/2311.00796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic counting of planting microsites via local visual detection and  global count estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zgaren%2C+A">Ahmed Zgaren</a>, 
<a href="/search/cs?searchtype=author&query=Bouachir%2C+W">Wassim Bouachir</a>, 
<a href="/search/cs?searchtype=author&query=Bouguila%2C+N">Nizar Bouguila</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Emerging Topics in Computational
  Intelligence, 2023, 1-15
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In forest industry, mechanical site preparation by mounding is widely used
prior to planting operations. One of the main problems when planning planting
operations is the difficulty in estimating the number of mounds present on a
planting block, as their number may greatly vary depending on site
characteristics. This estimation is often carried out through field surveys by
several forestry workers. However, this procedure is prone to error and
slowness. Motivated by recent advances in UAV imagery and artificial
intelligence, we propose a fully automated framework to estimate the number of
mounds on a planting block. Using computer vision and machine learning, we
formulate the counting task as a supervised learning problem using two
prediction models. A local detection model is firstly used to detect visible
mounds based on deep features, while a global prediction function is
subsequently applied to provide a final estimation based on block-level
features. To evaluate the proposed method, we constructed a challenging UAV
dataset representing several plantation blocks with different characteristics.
The performed experiments demonstrated the robustness of the proposed method,
which outperforms manual methods in precision, while significantly reducing
time and cost.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00797" title="Abstract">arXiv:2311.00797</a> [<a href="/pdf/2311.00797" title="Download PDF">pdf</a>, <a href="/format/2311.00797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tipping Points of Evolving Epidemiological Networks: Machine  Learning-Assisted, Data-Driven Effective Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Evangelou%2C+N">Nikolaos Evangelou</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+T">Tianqi Cui</a>, 
<a href="/search/cs?searchtype=author&query=Bello-Rivas%2C+J+M">Juan M. Bello-Rivas</a>, 
<a href="/search/cs?searchtype=author&query=Makeev%2C+A">Alexei Makeev</a>, 
<a href="/search/cs?searchtype=author&query=Kevrekidis%2C+I+G">Ioannis G. Kevrekidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Dynamical Systems (math.DS); Populations and Evolution (q-bio.PE)

</div>
<p class="mathjax">We study the tipping point collective dynamics of an adaptive
susceptible-infected-susceptible (SIS) epidemiological network in a
data-driven, machine learning-assisted manner. We identify a
parameter-dependent effective stochastic differential equation (eSDE) in terms
of physically meaningful coarse mean-field variables through a deep-learning
ResNet architecture inspired by numerical stochastic integrators. We construct
an approximate effective bifurcation diagram based on the identified drift term
of the eSDE and contrast it with the mean-field SIS model bifurcation diagram.
We observe a subcritical Hopf bifurcation in the evolving network's effective
SIS dynamics, that causes the tipping point behavior; this takes the form of
large amplitude collective oscillations that spontaneously -- yet rarely --
arise from the neighborhood of a (noisy) stationary state. We study the
statistics of these rare events both through repeated brute force simulations
and by using established mathematical/computational tools exploiting the
right-hand-side of the identified SDE. We demonstrate that such a collective
SDE can also be identified (and the rare events computations also performed) in
terms of data-driven coarse observables, obtained here via manifold learning
techniques, in particular Diffusion Maps. The workflow of our study is
straightforwardly applicable to other complex dynamics problems exhibiting
tipping point dynamics.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00798" title="Abstract">arXiv:2311.00798</a> [<a href="/pdf/2311.00798" title="Download PDF">pdf</a>, <a href="/ps/2311.00798" title="Download PostScript">ps</a>, <a href="/format/2311.00798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finer-grained Reductions in Fine-grained Hardness of Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abboud%2C+E">Elie Abboud</a>, 
<a href="/search/cs?searchtype=author&query=Ron-Zewi%2C+N">Noga Ron-Zewi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC); Computational Geometry (cs.CG)

</div>
<p class="mathjax">We investigate the relation between $\delta$ and $\epsilon$ required for
obtaining a $(1+\delta)$-approximation in time $N^{2-\epsilon}$ for closest
pair problems under various distance metrics, and for other related problems in
fine-grained complexity.
<br />Specifically, our main result shows that if it is impossible to (exactly)
solve the (bichromatic) inner product (IP) problem for vectors of dimension $c
\log N$ in time $N^{2-\epsilon}$, then there is no $(1+\delta)$-approximation
algorithm for (bichromatic) Euclidean Closest Pair running in time
$N^{2-2\epsilon}$, where $\delta \approx (\epsilon/c)^2$ (where $\approx$ hides
$\polylog$ factors). This improves on the prior result due to Chen and Williams
(SODA 2019) which gave a smaller polynomial dependence of $\delta$ on
$\epsilon$, on the order of $\delta \approx (\epsilon/c)^6$. Our result implies
in turn that no $(1+\delta)$-approximation algorithm exists for Euclidean
closest pair for $\delta \approx \epsilon^4$, unless an algorithmic improvement
for IP is obtained. This in turn is very close to the approximation guarantee
of $\delta \approx \epsilon^3$ for Euclidean closest pair, given by the best
known algorithm of Almam, Chan, and Williams (FOCS 2016). By known reductions,
a similar result follows for a host of other related problems in fine-grained
hardness of approximation.
<br />Our reduction combines the hardness of approximation framework of Chen and
Williams, together with an MA communication protocol for IP over a small
alphabet, that is inspired by the MA protocol of Chen (Theory of Computing,
2020).
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00800" title="Abstract">arXiv:2311.00800</a> [<a href="/pdf/2311.00800" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Still Images: Robust Multi-Stream Spatiotemporal Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fadaei%2C+A">AmirHosein Fadaei</a>, 
<a href="/search/cs?searchtype=author&query=Dehaqani%2C+M+A">Mohammad-Reza A. Dehaqani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">A defining characteristic of natural vision is its ability to withstand a
variety of input alterations, resulting in the creation of an invariant
representation of the surroundings. While convolutional neural networks exhibit
resilience to certain forms of spatial input variation, modifications in the
spatial and temporal aspects can significantly affect the representations of
video content in deep neural networks. Inspired by the resilience of natural
vision to input variations, we employ a simple multi-stream model to explore
its potential to address spatiotemporal changes by including temporal features.
Our primary goal is to introduce a video-trained model and evaluate its
robustness to diverse image and video inputs, with a particular focus on
exploring the role of temporal features in invariant recognition. Results show
that including videos and the temporal stream during training mitigates the
decline in accuracy and mAP in image and video understanding tasks by 1.36% and
3.14%, respectively.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00801" title="Abstract">arXiv:2311.00801</a> [<a href="/pdf/2311.00801" title="Download PDF">pdf</a>, <a href="/format/2311.00801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GIST: Generated Inputs Sets Transferability in Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tambon%2C+F">Florian Tambon</a>, 
<a href="/search/cs?searchtype=author&query=Khomh%2C+F">Foutse Khomh</a>, 
<a href="/search/cs?searchtype=author&query=Antoniol%2C+G">Giuliano Antoniol</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to the "ACM Transactions on Software Engineering and Methodology" journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">As the demand for verifiability and testability of neural networks continues
to rise, an increasing number of methods for generating test sets are being
developed. However, each of these techniques tends to emphasize specific
testing aspects and can be quite time-consuming. A straightforward solution to
mitigate this issue is to transfer test sets between some benchmarked models
and a new model under test, based on a desirable property one wishes to
transfer. This paper introduces GIST (Generated Inputs Sets Transferability), a
novel approach for the efficient transfer of test sets among Deep Learning
models. Given a property of interest that a user wishes to transfer (e.g.,
coverage criterion), GIST enables the selection of good test sets from the
point of view of this property among available ones from a benchmark. We
empirically evaluate GIST on fault types coverage property with two modalities
and different test set generation procedures to demonstrate the approach's
feasibility. Experimental results show that GIST can select an effective test
set for the given property to transfer it to the model under test. Our results
suggest that GIST could be applied to transfer other properties and could
generalize to different test sets' generation procedures and modalities
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00802" title="Abstract">arXiv:2311.00802</a> [<a href="/pdf/2311.00802" title="Download PDF">pdf</a>, <a href="/format/2311.00802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Field Dynamics Model for Granular Object Piles Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+S">Shangjie Xue</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Shuo Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Kachana%2C+P">Pujith Kachana</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Danfei Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a learning-based dynamics model for granular material
manipulation. Inspired by the Eulerian approach commonly used in fluid
dynamics, our method adopts a fully convolutional neural network that operates
on a density field-based representation of object piles and pushers, allowing
it to exploit the spatial locality of inter-object interactions as well as the
translation equivariance through convolution operations. Furthermore, our
differentiable action rendering module makes the model fully differentiable and
can be directly integrated with a gradient-based trajectory optimization
algorithm. We evaluate our model with a wide array of piles manipulation tasks
both in simulation and real-world experiments and demonstrate that it
significantly exceeds existing latent or particle-based methods in both
accuracy and computation efficiency, and exhibits zero-shot generalization
capabilities across various environments and tasks.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00807" title="Abstract">arXiv:2311.00807</a> [<a href="/pdf/2311.00807" title="Download PDF">pdf</a>, <a href="/format/2311.00807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VQA-GEN: A Visual Question Answering Benchmark for Domain Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Unni%2C+S+J">Suraj Jyothi Unni</a>, 
<a href="/search/cs?searchtype=author&query=Moraffah%2C+R">Raha Moraffah</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Visual question answering (VQA) models are designed to demonstrate
visual-textual reasoning capabilities. However, their real-world applicability
is hindered by a lack of comprehensive benchmark datasets. Existing domain
generalization datasets for VQA exhibit a unilateral focus on textual shifts
while VQA being a multi-modal task contains shifts across both visual and
textual domains. We propose VQA-GEN, the first ever multi-modal benchmark
dataset for distribution shift generated through a shift induced pipeline.
Experiments demonstrate VQA-GEN dataset exposes the vulnerability of existing
methods to joint multi-modal distribution shifts. validating that comprehensive
multi-modal shifts are critical for robust VQA generalization. Models trained
on VQA-GEN exhibit improved cross-domain and in-domain performance, confirming
the value of VQA-GEN. Further, we analyze the importance of each shift
technique of our pipeline contributing to the generalization of the model.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00808" title="Abstract">arXiv:2311.00808</a> [<a href="/pdf/2311.00808" title="Download PDF">pdf</a>, <a href="/format/2311.00808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mahalanobis-Aware Training for Out-of-Distribution Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mclaughlin%2C+C">Connor Mclaughlin</a>, 
<a href="/search/cs?searchtype=author&query=Matterer%2C+J">Jason Matterer</a>, 
<a href="/search/cs?searchtype=author&query=Yee%2C+M">Michael Yee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages, 2 figures. Presented at AAAI Fall Symposium Series `23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">While deep learning models have seen widespread success in controlled
environments, there are still barriers to their adoption in open-world
settings. One critical task for safe deployment is the detection of anomalous
or out-of-distribution samples that may require human intervention. In this
work, we present a novel loss function and recipe for training networks with
improved density-based out-of-distribution sensitivity. We demonstrate the
effectiveness of our method on CIFAR-10, notably reducing the false-positive
rate of the relative Mahalanobis distance method on far-OOD tasks by over 50%.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00810" title="Abstract">arXiv:2311.00810</a> [<a href="/pdf/2311.00810" title="Download PDF">pdf</a>, <a href="/format/2311.00810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Call to Arms: AI Should be Critical for Social Media Analysis of  Conflict Zones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abedin%2C+A">Afia Abedin</a>, 
<a href="/search/cs?searchtype=author&query=Bais%2C+A">Abdul Bais</a>, 
<a href="/search/cs?searchtype=author&query=Buntain%2C+C">Cody Buntain</a>, 
<a href="/search/cs?searchtype=author&query=Courchesne%2C+L">Laura Courchesne</a>, 
<a href="/search/cs?searchtype=author&query=McQuinn%2C+B">Brian McQuinn</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+M+E">Matthew E. Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Ullah%2C+M">Muhib Ullah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">The massive proliferation of social media data represents a transformative
moment in conflict studies. This data can provide unique insights into the
spread and use of weaponry, but the scale and types of data are problematic for
traditional open-source intelligence. This paper presents preliminary,
transdisciplinary work using computer vision to identify specific weapon
systems and the insignias of the armed groups using them. There is potential to
not only track how weapons are distributed through networks of armed units but
also to track which types of weapons are being used by the different types of
state and non-state military actors in Ukraine. Such a system could ultimately
be used to understand conflicts in real-time, including where humanitarian and
medical aid is most needed. We believe that using AI to help automate such
processes should be a high-priority goal for our community, with near-term
real-world payoffs.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00812" title="Abstract">arXiv:2311.00812</a> [<a href="/pdf/2311.00812" title="Download PDF">pdf</a>, <a href="/format/2311.00812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InfoGuard: A Design and Usability Study of User-Controlled  Application-Independent Encryption for Privacy-Conscious Users
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yadav%2C+T">Tarun Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Cook%2C+A">Austin Cook</a>, 
<a href="/search/cs?searchtype=author&query=Hales%2C+J">Justin Hales</a>, 
<a href="/search/cs?searchtype=author&query=Seamons%2C+K">Kent Seamons</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Billions of secure messaging users have adopted end-to-end encryption (E2EE).
Nevertheless, challenges remain. Most communication applications do not provide
E2EE, and application silos prevent interoperability. Our qualitative analysis
of privacy-conscious users' discussions of E2EE on Reddit reveals concerns
about trusting client applications with plaintext, lack of clear indicators
about how encryption works, high cost to switch apps, and concerns that most
apps are not open source. We propose InfoGuard, a system enabling E2EE for
user-to-user communication in any application. InfoGuard allows users to
trigger encryption on any textbox, even if the application does not support
E2EE. InfoGuard encrypts text before it reaches the application, eliminating
the client app's access to plaintext. InfoGuard also incorporates visible
encryption to make it easier for users to understand that their data is being
encrypted and give them greater confidence in the system's security. The design
enables fine-grained encryption, allowing specific sensitive data items to be
encrypted while the rest remains visible to the server. Participants in our
user study found InfoGuard usable and trustworthy, expressing a willingness to
adopt it.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00814" title="Abstract">arXiv:2311.00814</a> [<a href="/pdf/2311.00814" title="Download PDF">pdf</a>, <a href="/format/2311.00814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Self-Supervised Deep Representations for EEG-based  Auditory Attention Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thakkar%2C+K">Karan Thakkar</a>, 
<a href="/search/cs?searchtype=author&query=Hai%2C+J">Jiarui Hai</a>, 
<a href="/search/cs?searchtype=author&query=Elhilali%2C+M">Mounya Elhilali</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Auditory Attention Decoding (AAD) algorithms play a crucial role in isolating
desired sound sources within challenging acoustic environments directly from
brain activity. Although recent research has shown promise in AAD using shallow
representations such as auditory envelope and spectrogram, there has been
limited exploration of deep Self-Supervised (SS) representations on a larger
scale. In this study, we undertake a comprehensive investigation into the
performance of linear decoders across 12 deep and 2 shallow representations,
applied to EEG data from multiple studies spanning 57 subjects and multiple
languages. Our experimental results consistently reveal the superiority of deep
features for AAD at decoding background speakers, regardless of the datasets
and analysis windows. This result indicates possible nonlinear encoding of
unattended signals in the brain that are revealed using deep nonlinear
features. Additionally, we analyze the impact of different layers of SS
representations and window sizes on AAD performance. These findings underscore
the potential for enhancing EEG-based AAD systems through the integration of
deep feature representations.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00815" title="Abstract">arXiv:2311.00815</a> [<a href="/pdf/2311.00815" title="Download PDF">pdf</a>, <a href="/format/2311.00815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PIAug -- Physics Informed Augmentation for Learning Vehicle Dynamics for  Off-Road Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maheshwari%2C+P">Parv Maheshwari</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenshan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Triest%2C+S">Samuel Triest</a>, 
<a href="/search/cs?searchtype=author&query=Sivaprakasam%2C+M">Matthew Sivaprakasam</a>, 
<a href="/search/cs?searchtype=author&query=Aich%2C+S">Shubhra Aich</a>, 
<a href="/search/cs?searchtype=author&query=Rogers%2C+J+G">John G. Rogers III</a>, 
<a href="/search/cs?searchtype=author&query=Gregory%2C+J+M">Jason M. Gregory</a>, 
<a href="/search/cs?searchtype=author&query=Scherer%2C+S">Sebastian Scherer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review at ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Modeling the precise dynamics of off-road vehicles is a complex yet essential
task due to the challenging terrain they encounter and the need for optimal
performance and safety. Recently, there has been a focus on integrating nominal
physics-based models alongside data-driven neural networks using Physics
Informed Neural Networks. These approaches often assume the availability of a
well-distributed dataset; however, this assumption may not hold due to regions
in the physical distribution that are hard to collect, such as high-speed
motions and rare terrains. Therefore, we introduce a physics-informed data
augmentation methodology called PIAug. We show an example use case of the same
by modeling high-speed and aggressive motion predictions, given a dataset with
only low-speed data. During the training phase, we leverage the nominal model
for generating target domain (medium and high velocity) data using the
available source data (low velocity). Subsequently, we employ a
physics-inspired loss function with this augmented dataset to incorporate prior
knowledge of physics into the neural network. Our methodology results in up to
67% less mean error in trajectory prediction in comparison to a standalone
nominal model, especially during aggressive maneuvers at speeds outside the
training domain. In real-life navigation experiments, our model succeeds in 4x
tighter waypoint tracking constraints than the Kinematic Bicycle Model (KBM) at
out-of-domain velocities.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00816" title="Abstract">arXiv:2311.00816</a> [<a href="/pdf/2311.00816" title="Download PDF">pdf</a>, <a href="/ps/2311.00816" title="Download PostScript">ps</a>, <a href="/format/2311.00816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Peace via Inclusivity: An Efficient Paradigm to Understand  Populations in Conflict Zones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bilich%2C+J">Jordan Bilich</a>, 
<a href="/search/cs?searchtype=author&query=Varga%2C+M">Michael Varga</a>, 
<a href="/search/cs?searchtype=author&query=Masood%2C+D">Daanish Masood</a>, 
<a href="/search/cs?searchtype=author&query=Konya%2C+A">Andrew Konya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AI for Social Good workshop at NeurIPS (2019), Vancouver, Canada
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">United Nations practice shows that inclusivity is vital for mediation to be
successful in helping end violent conflict and establish lasting peace.
However, current methods for understanding the views and needs of populations
during dynamic situations create tension between inclusivity and efficiency.
This work introduces a novel paradigm to mitigate such tension. In partnership
with collaborators at the United Nations we develop a realtime large-scale
synchronous dialogue process (RLSDP) to understand stakeholder populations on
an hour timescale. We demonstrate a machine learning model which enables each
dialogue cycle to take place on a minute-timescale. We manage a key risk
related to machine learning result trustworthiness by computing result
confidence from a fast and reliable estimation of posterior variance. Lastly,
we highlight a constellation of risks stemming from this new paradigm and
suggest policies to mitigate them.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00822" title="Abstract">arXiv:2311.00822</a> [<a href="/pdf/2311.00822" title="Download PDF">pdf</a>, <a href="/format/2311.00822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthesis and verification of robust-adaptive safe controllers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+S">Simin Liu</a>, 
<a href="/search/eess?searchtype=author&query=Yun%2C+K+S">Kai S. Yun</a>, 
<a href="/search/eess?searchtype=author&query=Dolan%2C+J+M">John M. Dolan</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+C">Changliu Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First 2 authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Safe control with guarantees generally requires the system model to be known.
It is far more challenging to handle systems with uncertain parameters. In this
paper, we propose a generic algorithm that can synthesize and verify safe
controllers for systems with constant, unknown parameters. In particular, we
use robust-adaptive control barrier functions (raCBFs) to achieve safety. We
develop new theories and techniques using sum-of-squares that enable us to pose
synthesis and verification as a series of convex optimization problems. In our
experiments, we show that our algorithms are general and scalable, applying
them to three different polynomial systems of up to moderate size (7D). Our
raCBFs are currently the most effective way to guarantee safety for uncertain
systems, achieving 100% safety and up to 55% performance improvement over a
robust baseline.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00830" title="Abstract">arXiv:2311.00830</a> [<a href="/pdf/2311.00830" title="Download PDF">pdf</a>, <a href="/format/2311.00830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User Experiences with Third-Party SIM Cards and ID Registration in Kenya  and Tanzania
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luhanga%2C+E">Edith Luhanga</a> (1), 
<a href="/search/cs?searchtype=author&query=Sowon%2C+K">Karen Sowon</a> (2), 
<a href="/search/cs?searchtype=author&query=Cranor%2C+L+F">Lorrie Faith Cranor</a> (2), 
<a href="/search/cs?searchtype=author&query=Fanti%2C+G">Giulia Fanti</a> (2), 
<a href="/search/cs?searchtype=author&query=Tucker%2C+C">Conrad Tucker</a> (2), 
<a href="/search/cs?searchtype=author&query=Gueye%2C+A">Assane Gueye</a> (1) ((1) Carnegie Mellon University - Africa, (2) Carnegie Mellon University)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Mobile money services in Sub-Saharan Africa (SSA) have increased access to
financial services. To ensure proper identification of users, countries have
put in place Know-Your-Customer (KYC) measures such as SIM registration using
an official identification. However, half of the 850 million people without IDs
globally live in SSA, and the use of SIM cards registered in another person's
name (third-party SIM) is prevalent. In this study, we explore challenges that
contribute to and arise from the use of third-party SIM cards. We interviewed
36 participants in Kenya and Tanzania. Our results highlight great strides in
ID accessibility, but also highlight numerous institutional and social factors
that contribute to the use of third-party SIM cards. While privacy concerns
contribute to the use of third-party SIM cards, third-party SIM card users are
exposed to significant security and privacy risks, including scams, financial
loss, and wrongful arrest.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00835" title="Abstract">arXiv:2311.00835</a> [<a href="/pdf/2311.00835" title="Download PDF">pdf</a>, <a href="/format/2311.00835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calibrated Seq2seq Models for Efficient and Generalizable Ultra-fine  Entity Typing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yanlin Feng</a>, 
<a href="/search/cs?searchtype=author&query=Pratapa%2C+A">Adithya Pratapa</a>, 
<a href="/search/cs?searchtype=author&query=Mortensen%2C+D+R">David R Mortensen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Ultra-fine entity typing plays a crucial role in information extraction by
predicting fine-grained semantic types for entity mentions in text. However,
this task poses significant challenges due to the massive number of entity
types in the output space. The current state-of-the-art approaches, based on
standard multi-label classifiers or cross-encoder models, suffer from poor
generalization performance or inefficient inference. In this paper, we present
CASENT, a seq2seq model designed for ultra-fine entity typing that predicts
ultra-fine types with calibrated confidence scores. Our model takes an entity
mention as input and employs constrained beam search to generate multiple types
autoregressively. The raw sequence probabilities associated with the predicted
types are then transformed into confidence scores using a novel calibration
method. We conduct extensive experiments on the UFET dataset which contains
over 10k types. Our method outperforms the previous state-of-the-art in terms
of F1 score and calibration error, while achieving an inference speedup of over
50 times. Additionally, we demonstrate the generalization capabilities of our
model by evaluating it in zero-shot and few-shot settings on five specialized
domain entity typing datasets that are unseen during training. Remarkably, our
model outperforms large language models with 10 times more parameters in the
zero-shot setting, and when fine-tuned on 50 examples, it significantly
outperforms ChatGPT on all datasets. Our code, models and demo are available at
https://github.com/yanlinf/CASENT.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00837" title="Abstract">arXiv:2311.00837</a> [<a href="/pdf/2311.00837" title="Download PDF">pdf</a>, <a href="/format/2311.00837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constant-time Motion Planning with Anytime Refinement for Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishani%2C+I">Itamar Mishani</a>, 
<a href="/search/cs?searchtype=author&query=Feddock%2C+H">Hayden Feddock</a>, 
<a href="/search/cs?searchtype=author&query=Likhachev%2C+M">Maxim Likhachev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review for publication at the 2024 IEEE International Conference on Robotics and Automation (ICRA 2024). Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Robotic manipulators are essential for future autonomous systems, yet limited
trust in their autonomy has confined them to rigid, task-specific systems. The
intricate configuration space of manipulators, coupled with the challenges of
obstacle avoidance and constraint satisfaction, often makes motion planning the
bottleneck for achieving reliable and adaptable autonomy. Recently, a class of
constant-time motion planners (CTMP) was introduced. These planners employ a
preprocessing phase to compute data structures that enable online planning
provably guarantee the ability to generate motion plans, potentially
sub-optimal, within a user defined time bound. This framework has been
demonstrated to be effective in a number of time-critical tasks. However,
robotic systems often have more time allotted for planning than the online
portion of CTMP requires, time that can be used to improve the solution. To
this end, we propose an anytime refinement approach that works in combination
with CTMP algorithms. Our proposed framework, as it operates as a constant time
algorithm, rapidly generates an initial solution within a user-defined time
threshold. Furthermore, functioning as an anytime algorithm, it iteratively
refines the solution's quality within the allocated time budget. This enables
our approach to strike a balance between guaranteed fast plan generation and
the pursuit of optimization over time. We support our approach by elucidating
its analytical properties, showing the convergence of the anytime component
towards optimal solutions. Additionally, we provide empirical validation
through simulation and real-world demonstrations on a 6 degree-of-freedom robot
manipulator, applied to an assembly domain.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00840" title="Abstract">arXiv:2311.00840</a> [<a href="/pdf/2311.00840" title="Download PDF">pdf</a>, <a href="/format/2311.00840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sharp Noisy Binary Search with Monotonic Probabilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gretta%2C+L">Lucas Gretta</a>, 
<a href="/search/cs?searchtype=author&query=Price%2C+E">Eric Price</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We revisit the noisy binary search model of Karp and Kleinberg, in which we
have $n$ coins with unknown probabilities $p_i$ that we can flip. The coins are
sorted by increasing $p_i$, and we would like to find where the probability
crosses (to within $\varepsilon$) of a target value $\tau$. This generalized
the fixed-noise model of Burnashev and Zigangirov , in which $p_i = \frac{1}{2}
\pm \varepsilon$, to a setting where coins near the target may be
indistinguishable from it. Karp and Kleinberg showed that
$\Theta(\frac{1}{\varepsilon^2} \log n)$ samples are necessary and sufficient
for this task.
<br />We produce a practical algorithm by solving two theoretical challenges:
high-probability behavior and sharp constants. We give an algorithm that
succeeds with probability $1-\delta$ from
<br />\[
<br />\frac{1}{C_{\tau, \varepsilon}} \cdot \left(\lg n + O(\log^{2/3} n \log^{1/3}
\frac{1}{\delta} + \log \frac{1}{\delta})\right)
<br />\]
<br />samples, where $C_{\tau, \varepsilon}$ is the optimal such constant
achievable. For $\delta &gt; n^{-o(1)}$ this is within $1 + o(1)$ of optimal, and
for $\delta \ll 1$ it is the first bound within constant factors of optimal.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00842" title="Abstract">arXiv:2311.00842</a> [<a href="/pdf/2311.00842" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> healthAIChain: Improving security and safety using Blockchain Technology  applications in AI-based healthcare systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kshetri%2C+N">Naresh Kshetri</a>, 
<a href="/search/cs?searchtype=author&query=Hutson%2C+J">James Hutson</a>, 
<a href="/search/cs?searchtype=author&query=G%2C+R">Revathy G</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Blockchain as a digital ledger for keeping records of digital transactions
and other information, it is secure and decentralized technology. The globally
growing number of digital population every day possesses a significant threat
to online data including the medical and patients data. After bitcoin,
blockchain technology has emerged into a general-purpose technology with
applications in medical industries and healthcare. Blockchain can promote
highly configurable openness while retaining the highest security standards for
critical data of medical patients. Referred to as distributed record keeping
for healthcare systems which makes digital assets unalterable and transparent
via a cryptographic hash and decentralized network. The study delves into the
security and safety improvement associated with implementing blockchain in
AI-based healthcare systems. Blockchain-enabled AI tackles the existing issues
related to security, performance efficiencies, and safety in healthcare
systems. We have also examined the Artificial Intelligence in healthcare and
medical industry, potential areas, open questions concerning the blockchain in
healthcare systems. Finally, the article proposed an AI-based healthcare
blockchain model (healthAIChain) to improve patients data and security.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00847" title="Abstract">arXiv:2311.00847</a> [<a href="/pdf/2311.00847" title="Download PDF">pdf</a>, <a href="/ps/2311.00847" title="Download PostScript">ps</a>, <a href="/format/2311.00847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pseudo-Deterministic One-Way Functions from Pseudorandom States
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barhoush%2C+M">Mohammed Barhoush</a>, 
<a href="/search/cs?searchtype=author&query=Salvail%2C+L">Louis Salvail</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Quantum cryptography has shed light on the potential redundancy of one-way
functions (OWFs) in certain applications, where it would otherwise be required
classically. It has been revealed that many such cryptographic primitives can
be constructed using the concept of pseudorandom quantum states (PRSs), which
represent a potentially weaker foundational assumption.
<br />In this work, we aim to investigate and provide a more comprehensive
understanding of the relationship between PRSs and OWFs. To begin, we introduce
the novel notion of pseudo-deterministic one-way functions (QPD-OWFs). These
are similar to conventional OWFs with the exception that the output is
deterministic only with high probability.
<br />Our study demonstrates that QPD-OWFs can indeed be derived from PRSs,
utilizing recent developments in the construction of pseudo-deterministic
pseudorandom functions from PRSs. As a direct outcome of this revelation, we
present a (many-time) digital signature scheme for classical messages with
classical signatures, thereby addressing a previously unresolved question posed
in Morimae and Yamakawa's work (Crypto, 2022).
<br />Furthermore, we devise a quantum public-key encryption scheme featuring
reusable public-keys, constructed from pseudorandom function-like states. This
contribution supersedes previous constructions, which relied on stronger
assumptions or failed to ensure reusability.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00848" title="Abstract">arXiv:2311.00848</a> [<a href="/pdf/2311.00848" title="Download PDF">pdf</a>, <a href="/format/2311.00848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ABCD: Algorithm for Balanced Component Discovery in Signed Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shebaro%2C+M">Muhieddine Shebaro</a>, 
<a href="/search/cs?searchtype=author&query=Te%C5%A1i%C4%87%2C+J">Jelena Te&#x161;i&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">The most significant balanced element in signed graphs plays a vital role in
helping researchers understand the fundamental structure of the graph, as it
reveals valuable information about the complex relationships between vertices
in the network. The challenge is an NP-hard problem; there is no current
baseline to evaluate state-of-the-art signed graphs derived from real networks.
In this paper, we propose a scalable state-of-the-art approach for the maximum
balanced sub-graph detection in the network of \emph{any} size. However, it is
still bounded by computational capability. The proposed approach builds on the
graph characteristics and a scalable fundamental cycle discovery method to
minimize the number of vertices discarded. We evaluate the proposed approach
against state-of-the-art and demonstrate over two times higher graph size
regarding the number of vertices selected of the discovered subset on an
extensive signed network with millions of vertices and edges over the
state-of-art in the same time frame.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00853" title="Abstract">arXiv:2311.00853</a> [<a href="/pdf/2311.00853" title="Download PDF">pdf</a>, <a href="/format/2311.00853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An efficient tangent based topologically distinctive path finding for  grid maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zhuo Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Conventional local planners frequently become trapped in a locally optimal
trajectory, primarily due to their inability to traverse obstacles. Having a
larger number of topologically distinctive paths increases the likelihood of
finding the optimal trajectory. It is crucial to generate a substantial number
of topologically distinctive paths in real-time. Accordingly, we propose an
efficient path planning approach based on tangent graphs to yield multiple
topologically distinctive paths. Diverging from existing algorithms, our method
eliminates the necessity of distinguishing whether two paths belong to the same
topology; instead, it generates multiple topologically distinctive paths based
on the locally shortest property of tangents. Additionally, we introduce a
priority constraint for the queue during graph search, thereby averting the
exponential expansion of queue size. To illustrate the advantages of our
method, we conducted a comparative analysis with various typical algorithms
using a widely recognized public
dataset\footnote{https://movingai.com/benchmarks/grids.html}. The results
indicate that, on average, our method generates 320 topologically distinctive
paths within a mere 100 milliseconds. This outcome underscores a significant
enhancement in efficiency when compared to existing methods. To foster further
research within the community, we have made the source code of our proposed
algorithm publicly
accessible\footnote{https://joeyao-bit.github.io/posts/2023/09/07/}. We
anticipate that this framework will significantly contribute to the development
of more efficient topologically distinctive path planning, along with related
trajectory optimization and motion planning endeavors.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00854" title="Abstract">arXiv:2311.00854</a> [<a href="/pdf/2311.00854" title="Download PDF">pdf</a>, <a href="/format/2311.00854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $2$-Fault-Tolerant Strong Connectivity Oracles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Georgiadis%2C+L">Loukas Georgiadis</a>, 
<a href="/search/cs?searchtype=author&query=Kosinas%2C+E">Evangelos Kosinas</a>, 
<a href="/search/cs?searchtype=author&query=Tsokaktsis%2C+D">Daniel Tsokaktsis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference version to appear in the proceedings of ALENEX 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study the problem of efficiently answering strong connectivity queries
under two vertex failures. Given a directed graph $G$ with $n$ vertices, we
provide a data structure with $O(nh)$ space and $O(h)$ query time, where $h$ is
the height of a decomposition tree of $G$ into strongly connected subgraphs.
This immediately implies data structures with $O(n \log{n})$ space and
$O(\log{n})$ query time for graphs of constant treewidth, and $O(n^{3/2})$
space and $O(\sqrt{n})$ query time for planar graphs. For general directed
graphs, we give a refined version of our data structure that achieves
$O(n\sqrt{m})$ space and $O(\sqrt{m})$ query time, where $m$ is the number of
edges of the graph. We also provide some simple BFS-based heuristics that seem
to work remarkably well in practice. In the experimental part, we first
evaluate various methods to construct a decomposition tree with small height
$h$ in practice. Then we provide efficient implementations of our data
structures, and evaluate their empirical performance by conducting an extensive
experimental study on graphs taken from real-world applications.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00855" title="Abstract">arXiv:2311.00855</a> [<a href="/pdf/2311.00855" title="Download PDF">pdf</a>, <a href="/format/2311.00855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-Agent Reinforcement Learning Framework for Evaluating the U.S.  Ending the HIV Epidemic Plan
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+D">Dinesh Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Ankit Shah</a>, 
<a href="/search/cs?searchtype=author&query=Gopalappa%2C+C">Chaitra Gopalappa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Human immunodeficiency virus (HIV) is a major public health concern in the
United States, with about 1.2 million people living with HIV and 35,000 newly
infected each year. There are considerable geographical disparities in HIV
burden and care access across the U.S. The 2019 Ending the HIV Epidemic (EHE)
initiative aims to reduce new infections by 90% by 2030, by improving coverage
of diagnoses, treatment, and prevention interventions and prioritizing
jurisdictions with high HIV prevalence. Identifying optimal scale-up of
intervention combinations will help inform resource allocation. Existing HIV
decision analytic models either evaluate specific cities or the overall
national population, thus overlooking jurisdictional interactions or
differences. In this paper, we propose a multi-agent reinforcement learning
(MARL) model, that enables jurisdiction-specific decision analyses but in an
environment with cross-jurisdictional epidemiological interactions. In
experimental analyses, conducted on jurisdictions within California and
Florida, optimal policies from MARL were significantly different than those
generated from single-agent RL, highlighting the influence of jurisdictional
variations and interactions. By using comprehensive modeling of HIV and
formulations of state space, action space, and reward functions, this work
helps demonstrate the strengths and applicability of MARL for informing public
health policies, and provides a framework for expanding to the national-level
to inform the EHE.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00858" title="Abstract">arXiv:2311.00858</a> [<a href="/pdf/2311.00858" title="Download PDF">pdf</a>, <a href="/format/2311.00858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SmoothHess: ReLU Network Feature Interactions via Stein&#x27;s Lemma
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Torop%2C+M">Max Torop</a>, 
<a href="/search/cs?searchtype=author&query=Masoomi%2C+A">Aria Masoomi</a>, 
<a href="/search/cs?searchtype=author&query=Hill%2C+D">Davin Hill</a>, 
<a href="/search/cs?searchtype=author&query=Kose%2C+K">Kivanc Kose</a>, 
<a href="/search/cs?searchtype=author&query=Ioannidis%2C+S">Stratis Ioannidis</a>, 
<a href="/search/cs?searchtype=author&query=Dy%2C+J">Jennifer Dy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023 as a conference paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Several recent methods for interpretability model feature interactions by
looking at the Hessian of a neural network. This poses a challenge for ReLU
networks, which are piecewise-linear and thus have a zero Hessian almost
everywhere. We propose SmoothHess, a method of estimating second-order
interactions through Stein's Lemma. In particular, we estimate the Hessian of
the network convolved with a Gaussian through an efficient sampling algorithm,
requiring only network gradient calls. SmoothHess is applied post-hoc, requires
no modifications to the ReLU network architecture, and the extent of smoothing
can be controlled explicitly. We provide a non-asymptotic bound on the sample
complexity of our estimation procedure. We validate the superior ability of
SmoothHess to capture interactions on benchmark datasets and a real-world
medical spirometry dataset.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00859" title="Abstract">arXiv:2311.00859</a> [<a href="/pdf/2311.00859" title="Download PDF">pdf</a>, <a href="/format/2311.00859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Cost Constrained Adversarial Attacks For Multiple Agent Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Ziqing Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guanlin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+L">Lifeng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weiyu Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICCASP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Finding optimal adversarial attack strategies is an important topic in
reinforcement learning and the Markov decision process. Previous studies
usually assume one all-knowing coordinator (attacker) for whom attacking
different recipient (victim) agents incurs uniform costs. However, in reality,
instead of using one limitless central attacker, the attacks often need to be
performed by distributed attack agents. We formulate the problem of performing
optimal adversarial agent-to-agent attacks using distributed attack agents, in
which we impose distinct cost constraints on each different attacker-victim
pair. We propose an optimal method integrating within-step static constrained
attack-resource allocation optimization and between-step dynamic programming to
achieve the optimal adversarial attack in a multi-agent system. Our numerical
results show that the proposed attacks can significantly reduce the rewards
received by the attacked agents.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00860" title="Abstract">arXiv:2311.00860</a> [<a href="/pdf/2311.00860" title="Download PDF">pdf</a>, <a href="/format/2311.00860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero Coordinate Shift: Whetted Automatic Differentiation for  Physics-informed Operator Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leng%2C+K">Kuangdai Leng</a>, 
<a href="/search/cs?searchtype=author&query=Shankar%2C+M">Mallikarjun Shankar</a>, 
<a href="/search/cs?searchtype=author&query=Thiyagalingam%2C+J">Jeyan Thiyagalingam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Numerical Analysis (math.NA); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Automatic differentiation (AD) is a critical step in physics-informed machine
learning, required for computing the high-order derivatives of network output
w.r.t. coordinates. In this paper, we present a novel and lightweight algorithm
to conduct such AD for physics-informed operator learning, as we call the trick
of Zero Coordinate Shift (ZCS). Instead of making all sampled coordinates leaf
variables, ZCS introduces only one scalar-valued leaf variable for each spatial
or temporal dimension, leading to a game-changing performance leap by
simplifying the wanted derivatives from "many-roots-many-leaves" to
"one-root-many-leaves". ZCS is easy to implement with current deep learning
libraries; our own implementation is by extending the DeepXDE package. We carry
out a comprehensive benchmark analysis and several case studies, training
physics-informed DeepONets to solve partial differential equations (PDEs)
without data. The results show that ZCS has persistently brought down GPU
memory consumption and wall time for training by an order of magnitude, with
the savings increasing with problem scale (i.e., number of functions, number of
points and order of PDE). As a low-level optimisation, ZCS entails no
restrictions on data, physics (PDEs) or network architecture and does not
compromise training results from any aspect.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00863" title="Abstract">arXiv:2311.00863</a> [<a href="/pdf/2311.00863" title="Download PDF">pdf</a>, <a href="/format/2311.00863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training Dynamics of Contextual N-Grams in Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Quirke%2C+L">Lucia Quirke</a>, 
<a href="/search/cs?searchtype=author&query=Heindrich%2C+L">Lovis Heindrich</a>, 
<a href="/search/cs?searchtype=author&query=Gurnee%2C+W">Wes Gurnee</a>, 
<a href="/search/cs?searchtype=author&query=Nanda%2C+N">Neel Nanda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted workshop paper at ATTRIB 2023 (@ NeurIPS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Prior work has shown the existence of contextual neurons in language models,
including a neuron that activates on German text. We show that this neuron
exists within a broader contextual n-gram circuit: we find late layer neurons
which recognize and continue n-grams common in German text, but which only
activate if the German neuron is active. We investigate the formation of this
circuit throughout training and find that it is an example of what we call a
second-order circuit. In particular, both the constituent n-gram circuits and
the German detection circuit which culminates in the German neuron form with
independent functions early in training - the German detection circuit
partially through modeling German unigram statistics, and the n-grams by
boosting appropriate completions. Only after both circuits have already formed
do they fit together into a second-order circuit. Contrary to the hypotheses
presented in prior work, we find that the contextual n-gram circuit forms
gradually rather than in a sudden phase transition. We further present a range
of anomalous observations such as a simultaneous phase transition in many tasks
coinciding with the learning rate warm-up, and evidence that many context
neurons form simultaneously early in training but are later unlearned.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00865" title="Abstract">arXiv:2311.00865</a> [<a href="/pdf/2311.00865" title="Download PDF">pdf</a>, <a href="/format/2311.00865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Selectively Sharing Experiences Improves Multi-Agent Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gerstgrasser%2C+M">Matthias Gerstgrasser</a>, 
<a href="/search/cs?searchtype=author&query=Danino%2C+T">Tom Danino</a>, 
<a href="/search/cs?searchtype=author&query=Keren%2C+S">Sarah Keren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to be published at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Robotics (cs.RO)

</div>
<p class="mathjax">We present a novel multi-agent RL approach, Selective Multi-Agent Prioritized
Experience Relay, in which agents share with other agents a limited number of
transitions they observe during training. The intuition behind this is that
even a small number of relevant experiences from other agents could help each
agent learn. Unlike many other multi-agent RL algorithms, this approach allows
for largely decentralized training, requiring only a limited communication
channel between agents. We show that our approach outperforms baseline
no-sharing decentralized training and state-of-the art multi-agent RL
algorithms. Further, sharing only a small number of highly relevant experiences
outperforms sharing all experiences between agents, and the performance uplift
from selective experience sharing is robust across a range of hyperparameters
and DQN variants. A reference implementation of our algorithm is available at
https://github.com/mgerstgrasser/super.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00866" title="Abstract">arXiv:2311.00866</a> [<a href="/pdf/2311.00866" title="Download PDF">pdf</a>, <a href="/format/2311.00866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizing Nonlinear ICA Beyond Structural Sparsity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yujia Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Machine Learning (stat.ML)

</div>
<p class="mathjax">Nonlinear independent component analysis (ICA) aims to uncover the true
latent sources from their observable nonlinear mixtures. Despite its
significance, the identifiability of nonlinear ICA is known to be impossible
without additional assumptions. Recent advances have proposed conditions on the
connective structure from sources to observed variables, known as Structural
Sparsity, to achieve identifiability in an unsupervised manner. However, the
sparsity constraint may not hold universally for all sources in practice.
Furthermore, the assumptions of bijectivity of the mixing process and
independence among all sources, which arise from the setting of ICA, may also
be violated in many real-world scenarios. To address these limitations and
generalize nonlinear ICA, we propose a set of new identifiability results in
the general settings of undercompleteness, partial sparsity and source
dependence, and flexible grouping structures. Specifically, we prove
identifiability when there are more observed variables than sources
(undercomplete), and when certain sparsity and/or source independence
assumptions are not met for some changing sources. Moreover, we show that even
in cases with flexible grouping structures (e.g., part of the sources can be
divided into irreducible independent groups with various sizes), appropriate
identifiability results can also be established. Theoretical claims are
supported empirically on both synthetic and real-world datasets.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00869" title="Abstract">arXiv:2311.00869</a> [<a href="/pdf/2311.00869" title="Download PDF">pdf</a>, <a href="/format/2311.00869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Frustration Index and Corresponding Balanced State Discovery for  Real Signed Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shebaro%2C+M">Muhieddine Shebaro</a>, 
<a href="/search/cs?searchtype=author&query=Te%C5%A1i%C4%87%2C+J">Jelena Te&#x161;i&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">Structural balance modeling for signed graph networks presents how to model
the sources of conflicts. The state-of-the-art has focused on computing the
frustration index of a signed graph as a critical step toward solving problems
in social and sensor networks and for scientific modeling. However, the
proposed approaches do not scale to modern large, sparse signed networks. Also,
they do not address that there is more than one way in some networks to reach a
consensus with the minimum number of edge-sign switches needed. We propose an
efficient balanced state discovery algorithm and a network frustration
computation that will discover the nearest balanced state for the \emph{any}
size of the graph network and compute the frustration of the network. The
speedup of the proposed method is around 300 times faster than the
state-of-the-art for signed graphs with hundreds of thousands of edges. The
technique successfully scales to find the balanced states and frustration of
the networks with millions of nodes and edges in real time where
state-of-the-art fails.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00871" title="Abstract">arXiv:2311.00871</a> [<a href="/pdf/2311.00871" title="Download PDF">pdf</a>, <a href="/format/2311.00871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in  Transformer Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yadlowsky%2C+S">Steve Yadlowsky</a>, 
<a href="/search/cs?searchtype=author&query=Doshi%2C+L">Lyric Doshi</a>, 
<a href="/search/cs?searchtype=author&query=Tripuraneni%2C+N">Nilesh Tripuraneni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
<p class="mathjax">Transformer models, notably large language models (LLMs), have the remarkable
ability to perform in-context learning (ICL) -- to perform new tasks when
prompted with unseen input-output examples without any explicit model training.
In this work, we study how effectively transformers can bridge between their
pretraining data mixture, comprised of multiple distinct task families, to
identify and learn new tasks in-context which are both inside and outside the
pretraining distribution. Building on previous work, we investigate this
question in a controlled setting, where we study transformer models trained on
sequences of $(x, f(x))$ pairs rather than natural language. Our empirical
results show transformers demonstrate near-optimal unsupervised model selection
capabilities, in their ability to first in-context identify different task
families and in-context learn within them when the task families are
well-represented in their pretraining data. However when presented with tasks
or functions which are out-of-domain of their pretraining data, we demonstrate
various failure modes of transformers and degradation of their generalization
for even simple extrapolation tasks. Together our results highlight that the
impressive ICL abilities of high-capacity sequence models may be more closely
tied to the coverage of their pretraining data mixtures than inductive biases
that create fundamental generalization capabilities.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00873" title="Abstract">arXiv:2311.00873</a> [<a href="/pdf/2311.00873" title="Download PDF">pdf</a>, <a href="/format/2311.00873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-latency Real-time Voice Conversion on CPU
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sadov%2C+K">Konstantine Sadov</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+M">Matthew Hutter</a>, 
<a href="/search/cs?searchtype=author&query=Near%2C+A">Asara Near</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We adapt the architectures of previous audio manipulation and generation
neural networks to the task of real-time any-to-one voice conversion. Our
resulting model, LLVC ($\textbf{L}$ow-latency $\textbf{L}$ow-resource
$\textbf{V}$oice $\textbf{C}$onversion), has a latency of under 20ms at a
bitrate of 16kHz and runs nearly 2.8x faster than real-time on a consumer CPU.
LLVC uses both a generative adversarial architecture as well as knowledge
distillation in order to attain this performance. To our knowledge LLVC
achieves both the lowest resource usage as well as the lowest latency of any
open-source voice conversion model. We provide open-source samples, code, and
pretrained model weights at https://github.com/KoeAI/LLVC.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00875" title="Abstract">arXiv:2311.00875</a> [<a href="/pdf/2311.00875" title="Download PDF">pdf</a>, <a href="/format/2311.00875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Collective Behaviors from Observation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jinchao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+M">Ming Zhong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA); Dynamical Systems (math.DS)

</div>
<p class="mathjax">We present a review of a series of learning methods used to identify the
structure of dynamical systems, aiming to understand emergent behaviors in
complex systems of interacting agents. These methods not only offer theoretical
guarantees of convergence but also demonstrate computational efficiency in
handling high-dimensional observational data. They can manage observation data
from both first- and second-order dynamical systems, accounting for
observation/stochastic noise, complex interaction rules, missing interaction
features, and real-world observations of interacting agent systems. The essence
of developing such a series of learning methods lies in designing appropriate
loss functions using the variational inverse problem approach, which inherently
provides dimension reduction capabilities to our learning methods.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00880" title="Abstract">arXiv:2311.00880</a> [<a href="/pdf/2311.00880" title="Download PDF">pdf</a>, <a href="/format/2311.00880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCPO: Safe Reinforcement Learning with Safety Critic Policy Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mhamed%2C+J">Jaafar Mhamed</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+S">Shangding Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Incorporating safety is an essential prerequisite for broadening the
practical applications of reinforcement learning in real-world scenarios. To
tackle this challenge, Constrained Markov Decision Processes (CMDPs) are
leveraged, which introduce a distinct cost function representing safety
violations. In CMDPs' settings, Lagrangian relaxation technique has been
employed in previous algorithms to convert constrained optimization problems
into unconstrained dual problems. However, these algorithms may inaccurately
predict unsafe behavior, resulting in instability while learning the Lagrange
multiplier. This study introduces a novel safe reinforcement learning
algorithm, Safety Critic Policy Optimization (SCPO). In this study, we define
the safety critic, a mechanism that nullifies rewards obtained through
violating safety constraints. Furthermore, our theoretical analysis indicates
that the proposed algorithm can automatically balance the trade-off between
adhering to safety constraints and maximizing rewards. The effectiveness of the
SCPO algorithm is empirically validated by benchmarking it against strong
baselines.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00882" title="Abstract">arXiv:2311.00882</a> [<a href="/pdf/2311.00882" title="Download PDF">pdf</a>, <a href="/format/2311.00882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semidefinite programming and linear equations vs. homomorphism problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ciardo%2C+L">Lorenzo Ciardo</a>, 
<a href="/search/cs?searchtype=author&query=%C5%BDivn%C3%BD%2C+S">Stanislav &#x17d;ivn&#xfd;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS); Optimization and Control (math.OC)

</div>
<p class="mathjax">We introduce a relaxation for homomorphism problems that combines
semidefinite programming with linear Diophantine equations, and propose a
framework for the analysis of its power based on the spectral theory of
association schemes. We use this framework to establish an unconditional lower
bound against the semidefinite programming + linear equations model, by showing
that the relaxation does not solve the approximate graph homomorphism problem
and thus, in particular, the approximate graph colouring problem.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00883" title="Abstract">arXiv:2311.00883</a> [<a href="/pdf/2311.00883" title="Download PDF">pdf</a>, <a href="/format/2311.00883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the accuracy and scalability of large-scale physics-based  data-driven reduced modeling via domain decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Farcas%2C+I">Ionut-Gabriel Farcas</a>, 
<a href="/search/math?searchtype=author&query=Gundevia%2C+R+P">Rayomand P. Gundevia</a>, 
<a href="/search/math?searchtype=author&query=Munipalli%2C+R">Ramakanth Munipalli</a>, 
<a href="/search/math?searchtype=author&query=Willcox%2C+K+E">Karen E. Willcox</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">This paper focuses on the construction of accurate and predictive data-driven
reduced models of large-scale numerical simulations with complex dynamics and
sparse training data sets. In these settings, standard, single-domain
approaches may be too inaccurate or may overfit and hence generalize poorly.
Moreover, processing large-scale data sets typically requires significant
memory and computing resources which can render single-domain approaches
computationally prohibitive. To address these challenges, we introduce a domain
decomposition formulation into the construction of a data-driven reduced model.
In doing so, the basis functions used in the reduced model approximation become
localized in space, which can increase the accuracy of the domain-decomposed
approximation of the complex dynamics. The decomposition furthermore reduces
the memory and computing requirements to process the underlying large-scale
training data set. We demonstrate the effectiveness and scalability of our
approach in a large-scale three-dimensional unsteady rotating detonation rocket
engine simulation scenario with over $75$ million degrees of freedom and a
sparse training data set. Our results show that compared to the single-domain
approach, the domain-decomposed version reduces both the training and
prediction errors for pressure by up to $13 \%$ and up to $5\%$ for other key
quantities, such as temperature, and fuel and oxidizer mass fractions. Lastly,
our approach decreases the memory requirements for processing by almost a
factor of four, which in turn reduces the computing requirements as well.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00886" title="Abstract">arXiv:2311.00886</a> [<a href="/pdf/2311.00886" title="Download PDF">pdf</a>, <a href="/format/2311.00886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COSTAR: Improved Temporal Counterfactual Estimation with Self-Supervised  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+C">Chuizheng Meng</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yihe Dong</a>, 
<a href="/search/cs?searchtype=author&query=Ar%C4%B1k%2C+S+%C3%96">Sercan &#xd6;. Ar&#x131;k</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pfister%2C+T">Tomas Pfister</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Estimation of temporal counterfactual outcomes from observed history is
crucial for decision-making in many domains such as healthcare and e-commerce,
particularly when randomized controlled trials (RCTs) suffer from high cost or
impracticality. For real-world datasets, modeling time-dependent confounders is
challenging due to complex dynamics, long-range dependencies and both past
treatments and covariates affecting the future outcomes. In this paper, we
introduce COunterfactual Self-supervised TrAnsformeR (COSTAR), a novel approach
that integrates self-supervised learning for improved historical
representations. The proposed framework combines temporal and feature-wise
attention with a component-wise contrastive loss tailored for temporal
treatment outcome observations, yielding superior performance in estimation
accuracy and generalization to out-of-distribution data compared to existing
models, as validated by empirical results on both synthetic and real-world
datasets.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00887" title="Abstract">arXiv:2311.00887</a> [<a href="/pdf/2311.00887" title="Download PDF">pdf</a>, <a href="/format/2311.00887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Centralized Management of a Wifi Mesh for Autonomous Farms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tahir%2C+A">Ammar Tahir</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yueshen Li</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jianli Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Changxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+D">Daniel Moon</a>, 
<a href="/search/cs?searchtype=author&query=Mihigo%2C+A">Aganze Mihigo</a>, 
<a href="/search/cs?searchtype=author&query=Tariq%2C+M+T">Muhammad Taimoor Tariq</a>, 
<a href="/search/cs?searchtype=author&query=Vasisht%2C+D">Deepak Vasisht</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+R">Radhika Mittal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Emerging autonomous farming techniques rely on smart devices such as
multi-spectral cameras, collecting fine-grained data, and robots performing
tasks such as de-weeding, berry-picking, etc. These techniques require a high
throughput network, supporting 10s of Mbps per device at the scale of tens to
hundreds of devices in a large farm. We conduct a survey across 12 agronomists
to understand these networking requirements of farm workloads and perform
extensive measurements of WiFi 6 performance in a farm to identify the
challenges in meeting them. Our measurements reveal how network capacity is
fundamentally limited in such a setting, with severe degradation in network
performance due to crop canopy, and spotlight farm networks as an emerging new
problem domain that can benefit from smarter network resource management
decisions. To that end, we design Cornet, a network for supporting on-farm
applications that comprises: (i) a multi-hop mesh of WiFi routers that uses a
strategic combination of 2.4GHz and 5GHz bands as informed by our measurements,
and (ii) a centralized traffic engineering (TE) system that uses a novel
abstraction of resource units to reason about wireless network capacity and
make TE decisions (schedule flows, assign flow rates, and select routes and
channels). Our evaluation, using testbeds in a farm and trace-driven
simulations, shows how Cornet achieves 1.4 $\times$ higher network utilization
and better meets application demands, compared to standard wireless mesh
strategies.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00888" title="Abstract">arXiv:2311.00888</a> [<a href="/pdf/2311.00888" title="Download PDF">pdf</a>, <a href="/format/2311.00888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust inter-patient comparison and analysis of blood vessels through  the univocal definition of point coordinates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Romero%2C+P">Pau Romero</a>, 
<a href="/search/cs?searchtype=author&query=Pedr%C3%B3s%2C+A">Abel Pedr&#xf3;s</a>, 
<a href="/search/cs?searchtype=author&query=Sebastian%2C+R">Rafael Sebastian</a>, 
<a href="/search/cs?searchtype=author&query=Lozano%2C+M">Miguel Lozano</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa-Fern%C3%A1ndez%2C+I">Ignacio Garc&#xed;a-Fern&#xe1;ndez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">The availability of digital twins for the cardiovascular system will enable
insightful computational tools both for research and clinical practice. This,
however, demands robust and well defined methods for the different steps
involved in the process. We present a vessel coordinate system (VCS) that
enables the unanbiguous definition of locations in a vessel section, by
adapting the idea of cylindrical coordinates to the vessel geometry. Using the
VCS, point correspondence can be defined among different samples of a cohort,
allowing data transfer, quantitative comparison, shape coregistration or
population analysis. We provide the technical details for coordinates
computation and discuss the assumptions taken to guarantee that they are well
defined. The VCS is tested in a series of applications. We present a robust,
low dimensional, patient specific vascular model and use it to study phenotype
variability analysis of the thoracic aorta within a cohort of patients. Point
correspondence is exploited to build an haemodynamics atlas of the aorta for
the same cohort. Across the paper, we also show how VCS can be used for
visualization of different types of data on the anatomy.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00889" title="Abstract">arXiv:2311.00889</a> [<a href="/pdf/2311.00889" title="Download PDF">pdf</a>, <a href="/format/2311.00889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generate and Pray: Using SALLMS to Evaluate the Security of LLM  Generated Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Siddiq%2C+M+L">Mohammed Latif Siddiq</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+J+C+S">Joanna C. S. Santos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the growing popularity of Large Language Models (e.g. GitHub Copilot,
ChatGPT, etc.) in software engineers' daily practices, it is important to
ensure that the code generated by these tools is not only functionally correct
but also free of vulnerabilities. Although LLMs can help developers to be more
productive, prior empirical studies have shown that LLMs can generate insecure
code. There are two contributing factors to the insecure code generation.
First, existing datasets used to evaluate Large Language Models (LLMs) do not
adequately represent genuine software engineering tasks sensitive to security.
Instead, they are often based on competitive programming challenges or
classroom-type coding tasks. In real-world applications, the code produced is
integrated into larger codebases, introducing potential security risks. There's
a clear absence of benchmarks that focus on evaluating the security of the
generated code. Second, existing evaluation metrics primarily focus on the
functional correctness of the generated code while ignoring security
considerations. Metrics such as pass@k gauge the probability of obtaining the
correct code in the top k suggestions. Other popular metrics like BLEU,
CodeBLEU, ROUGE, and METEOR similarly emphasize functional accuracy, neglecting
security implications. In light of these research gaps, in this paper, we
described SALLM, a framework to benchmark LLMs' abilities to generate secure
code systematically. This framework has three major components: a novel dataset
of security-centric Python prompts, an evaluation environment to test the
generated code, and novel metrics to evaluate the models' performance from the
perspective of secure code generation.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00890" title="Abstract">arXiv:2311.00890</a> [<a href="/pdf/2311.00890" title="Download PDF">pdf</a>, <a href="/format/2311.00890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Combinatorial Assignment in Independence Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marinkovic%2C+J">Javier Marinkovic</a>, 
<a href="/search/cs?searchtype=author&query=Soto%2C+J+A">Jos&#xe9; A. Soto</a>, 
<a href="/search/cs?searchtype=author&query=Verdugo%2C+V">Victor Verdugo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We consider an online multi-weighted generalization of several classic online
optimization problems, called the online combinatorial assignment problem. We
are given an independence system over a ground set of elements and agents that
arrive online one by one. Upon arrival, each agent reveals a weight function
over the elements of the ground set. If the independence system is given by the
matchings of a hypergraph we recover the combinatorial auction problem, where
every node represents an item to be sold, and every edge represents a bundle of
items. For combinatorial auctions, Kesselheim et al. showed upper bounds of
O(loglog(k)/log(k)) and $O(\log \log(n)/\log(n))$ on the competitiveness of any
online algorithm, even in the random order model, where $k$ is the maximum
bundle size and $n$ is the number of items. We provide an exponential
improvement on these upper bounds to show that the competitiveness of any
online algorithm in the prophet IID setting is upper bounded by $O(\log(k)/k)$,
and $O(\log(n)/\sqrt{n})$. Furthermore, using linear programming, we provide
new and improved guarantees for the $k$-bounded online combinatorial auction
problem (i.e., bundles of size at most $k$). We show a
$(1-e^{-k})/k$-competitive algorithm in the prophet IID model, a
$1/(k+1)$-competitive algorithm in the prophet-secretary model using a single
sample per agent, and a $k^{-k/(k-1)}$-competitive algorithm in the secretary
model. Our algorithms run in polynomial time and work in more general
independence systems where the offline combinatorial assignment problem admits
the existence of a polynomial-time randomized algorithm that we call
certificate sampler. We show that certificate samplers have a nice interplay
with random order models, and we also provide new polynomial-time competitive
algorithms for some classes of matroids, matroid intersections, and matchoids.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00892" title="Abstract">arXiv:2311.00892</a> [<a href="/pdf/2311.00892" title="Download PDF">pdf</a>, <a href="/format/2311.00892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A PTAS for $\ell_0$-Low Rank Approximation: Solving Dense CSPs over  Reals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cohen-Addad%2C+V">Vincent Cohen-Addad</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chenglin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Ghoshal%2C+S">Suprovat Ghoshal</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+E">Euiwoong Lee</a>, 
<a href="/search/cs?searchtype=author&query=de+Mesmay%2C+A">Arnaud de Mesmay</a>, 
<a href="/search/cs?searchtype=author&query=Newman%2C+A">Alantha Newman</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T+C">Tony Chang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in SODA 24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We consider the Low Rank Approximation problem, where the input consists of a
matrix $A \in \mathbb{R}^{n_R \times n_C}$ and an integer $k$, and the goal is
to find a matrix $B$ of rank at most $k$ that minimizes $\| A - B \|_0$, which
is the number of entries where $A$ and $B$ differ. For any constant $k$ and
$\varepsilon &gt; 0$, we present a polynomial time $(1 +
\varepsilon)$-approximation time for this problem, which significantly improves
the previous best $poly(k)$-approximation.
<br />Our algorithm is obtained by viewing the problem as a Constraint Satisfaction
Problem (CSP) where each row and column becomes a variable that can have a
value from $\mathbb{R}^k$. In this view, we have a constraint between each row
and column, which results in a {\em dense} CSP, a well-studied topic in
approximation algorithms. While most of previous algorithms focus on
finite-size (or constant-size) domains and involve an exhaustive enumeration
over the entire domain, we present a new framework that bypasses such an
enumeration in $\mathbb{R}^k$. We also use tools from the rich literature of
Low Rank Approximation in different objectives (e.g., $\ell_p$ with $p \in (0,
\infty)$) or domains (e.g., finite fields/generalized Boolean). We believe that
our techniques might be useful to study other real-valued CSPs and matrix
optimization problems.
<br />On the hardness side, when $k$ is part of the input, we prove that Low Rank
Approximation is NP-hard to approximate within a factor of $\Omega(\log n)$.
This is the first superconstant NP-hardness of approximation for any $p \in [0,
\infty]$ that does not rely on stronger conjectures (e.g., the Small Set
Expansion Hypothesis).
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00895" title="Abstract">arXiv:2311.00895</a> [<a href="/pdf/2311.00895" title="Download PDF">pdf</a>, <a href="/format/2311.00895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Context Prompt Editing For Conditional Audio Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+E">Ernie Chang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+P">Pin-Jie Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+S">Sidd Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+G+L">Gael Le Lan</a>, 
<a href="/search/cs?searchtype=author&query=Kant%2C+D">David Kant</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yangyang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Iandola%2C+F">Forrest Iandola</a>, 
<a href="/search/cs?searchtype=author&query=Chandra%2C+V">Vikas Chandra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Distributional shift is a central challenge in the deployment of machine
learning models as they can be ill-equipped for real-world data. This is
particularly evident in text-to-audio generation where the encoded
representations are easily undermined by unseen prompts, which leads to the
degradation of generated audio -- the limited set of the text-audio pairs
remains inadequate for conditional audio generation in the wild as user prompts
are under-specified. In particular, we observe a consistent audio quality
degradation in generated audio samples with user prompts, as opposed to
training set prompts. To this end, we present a retrieval-based in-context
prompt editing framework that leverages the training captions as demonstrative
exemplars to revisit the user prompts. We show that the framework enhanced the
audio quality across the set of collected user prompts, which were edited with
reference to the training captions as exemplars.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00897" title="Abstract">arXiv:2311.00897</a> [<a href="/pdf/2311.00897" title="Download PDF">pdf</a>, <a href="/format/2311.00897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On The Open Prompt Challenge In Conditional Audio Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+E">Ernie Chang</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+S">Sidd Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Luthra%2C+M">Mahi Luthra</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+P">Pin-Jie Lin</a>, 
<a href="/search/cs?searchtype=author&query=Nagaraja%2C+V">Varun Nagaraja</a>, 
<a href="/search/cs?searchtype=author&query=Iandola%2C+F">Forrest Iandola</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zechun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+Z">Zhaoheng Ni</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Changsheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yangyang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chandra%2C+V">Vikas Chandra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Text-to-audio generation (TTA) produces audio from a text description,
learning from pairs of audio samples and hand-annotated text. However,
commercializing audio generation is challenging as user-input prompts are often
under-specified when compared to text descriptions used to train TTA models. In
this work, we treat TTA models as a ``blackbox'' and address the user prompt
challenge with two key insights: (1) User prompts are generally
under-specified, leading to a large alignment gap between user prompts and
training prompts. (2) There is a distribution of audio descriptions for which
TTA models are better at generating higher quality audio, which we refer to as
``audionese''. To this end, we rewrite prompts with instruction-tuned models
and propose utilizing text-audio alignment as feedback signals via margin
ranking learning for audio improvements. On both objective and subjective human
evaluations, we observed marked improvements in both text-audio alignment and
music audio quality.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00899" title="Abstract">arXiv:2311.00899</a> [<a href="/pdf/2311.00899" title="Download PDF">pdf</a>, <a href="/format/2311.00899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoboVQA: Multimodal Long-Horizon Reasoning for Robotics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sermanet%2C+P">Pierre Sermanet</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+T">Tianli Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jeffrey Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+F">Fei Xia</a>, 
<a href="/search/cs?searchtype=author&query=Dwibedi%2C+D">Debidatta Dwibedi</a>, 
<a href="/search/cs?searchtype=author&query=Gopalakrishnan%2C+K">Keerthana Gopalakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+C">Christine Chan</a>, 
<a href="/search/cs?searchtype=author&query=Dulac-Arnold%2C+G">Gabriel Dulac-Arnold</a>, 
<a href="/search/cs?searchtype=author&query=Maddineni%2C+S">Sharath Maddineni</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+N+J">Nikhil J Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Florence%2C+P">Pete Florence</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+W">Wei Han</a>, 
<a href="/search/cs?searchtype=author&query=Baruch%2C+R">Robert Baruch</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Mirchandani%2C+S">Suvir Mirchandani</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Peng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sanketi%2C+P">Pannag Sanketi</a>, 
<a href="/search/cs?searchtype=author&query=Hausman%2C+K">Karol Hausman</a>, 
<a href="/search/cs?searchtype=author&query=Shafran%2C+I">Izhak Shafran</a>, 
<a href="/search/cs?searchtype=author&query=Ichter%2C+B">Brian Ichter</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yuan Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present a scalable, bottom-up and intrinsically diverse data collection
scheme that can be used for high-level reasoning with long and medium horizons
and that has 2.2x higher throughput compared to traditional narrow top-down
step-by-step collection. We collect realistic data by performing any user
requests within the entirety of 3 office buildings and using multiple robot and
human embodiments. With this data, we show that models trained on all
embodiments perform better than ones trained on the robot data only, even when
evaluated solely on robot episodes. We find that for a fixed collection budget
it is beneficial to take advantage of cheaper human collection along with robot
collection. We release a large and highly diverse (29,520 unique instructions)
dataset dubbed RoboVQA containing 829,502 (video, text) pairs for
robotics-focused visual question answering. We also demonstrate how evaluating
real robot experiments with an intervention mechanism enables performing tasks
to completion, making it deployable with human oversight even if imperfect
while also providing a single performance metric. We demonstrate a single
video-conditioned model named RoboVQA-VideoCoCa trained on our dataset that is
capable of performing a variety of grounded high-level reasoning tasks in broad
realistic settings with a cognitive intervention rate 46% lower than the
zero-shot state of the art visual language model (VLM) baseline and is able to
guide real robots through long-horizon tasks. The performance gap with
zero-shot state-of-the-art models indicates that a lot of grounded data remains
to be collected for real-world deployment, emphasizing the critical need for
scalable data collection approaches. Finally, we show that video VLMs
significantly outperform single-image VLMs with an average error rate reduction
of 19% across all VQA tasks. Data and videos available at
https://robovqa.github.io
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00903" title="Abstract">arXiv:2311.00903</a> [<a href="/pdf/2311.00903" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Artificial Intelligence Ethics Education in Cybersecurity: Challenges  and Opportunities: a focus group report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jackson%2C+D">Diane Jackson</a>, 
<a href="/search/cs?searchtype=author&query=Matei%2C+S+A">Sorin Adam Matei</a>, 
<a href="/search/cs?searchtype=author&query=Bertino%2C+E">Elisa Bertino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">The emergence of AI tools in cybersecurity creates many opportunities and
uncertainties. A focus group with advanced graduate students in cybersecurity
revealed the potential depth and breadth of the challenges and opportunities.
The salient issues are access to open source or free tools, documentation,
curricular diversity, and clear articulation of ethical principles for AI
cybersecurity education. Confronting the "black box" mentality in AI
cybersecurity work is also of the greatest importance, doubled by deeper and
prior education in foundational AI work. Systems thinking and effective
communication were considered relevant areas of educational improvement. Future
AI educators and practitioners need to address these issues by implementing
rigorous technical training curricula, clear documentation, and frameworks for
ethically monitoring AI combined with critical and system's thinking and
communication skills.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00906" title="Abstract">arXiv:2311.00906</a> [<a href="/pdf/2311.00906" title="Download PDF">pdf</a>, <a href="/format/2311.00906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Re-weighting Tokens: A Simple and Effective Active Learning Strategy for  Named Entity Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haocheng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+W">Wei Tan</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+N+D">Ngoc Dang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Lan Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Active learning, a widely adopted technique for enhancing machine learning
models in text and image classification tasks with limited annotation
resources, has received relatively little attention in the domain of Named
Entity Recognition (NER). The challenge of data imbalance in NER has hindered
the effectiveness of active learning, as sequence labellers lack sufficient
learning signals. To address these challenges, this paper presents a novel
reweighting-based active learning strategy that assigns dynamic smoothed
weights to individual tokens. This adaptable strategy is compatible with
various token-level acquisition functions and contributes to the development of
robust active learners. Experimental results on multiple corpora demonstrate
the substantial performance improvement achieved by incorporating our
re-weighting strategy into existing acquisition functions, validating its
practical efficacy.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00911" title="Abstract">arXiv:2311.00911</a> [<a href="/pdf/2311.00911" title="Download PDF">pdf</a>, <a href="/format/2311.00911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Lightweight Routing Layer Using a Reliable Link-Layer Protocol
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+Q">Qianfeng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Chow%2C+P">Paul Chow</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">In today's data centers, the performance of interconnects plays a pivotal
role. However, many of the underlying technologies for these interconnects have
a history of several decades and existed long before data centers came into
being.To better cater to the requirements of data center networks, particularly
in the context of intra-rack communication, we have developed a new
interconnect. This interconnect is based on a lossless link layer protocol,
named RIFL. In this work, we designed and implemented RIFL Layer 2, a scalable
network that supports up to multi-hundred Gbps communication. RIFL Layer 2
includes the RIFL switch and RIFL NIC. By utilizing a simple Batcher Banyan and
iSLIP RIFL switch, we effectively keep the typical intra-rack latency under 400
nanoseconds. Moreover, for a 32-port 100Gbps network, under both Bernoulli
arrival and bursty arrival traffic patterns, we ensure that the 99\% tail
latency does not exceed 12microseconds.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00913" title="Abstract">arXiv:2311.00913</a> [<a href="/pdf/2311.00913" title="Download PDF">pdf</a>, <a href="/format/2311.00913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Influence Guided Data Reweighting for Language Model Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thakkar%2C+M">Megh Thakkar</a>, 
<a href="/search/cs?searchtype=author&query=Bolukbasi%2C+T">Tolga Bolukbasi</a>, 
<a href="/search/cs?searchtype=author&query=Ganapathy%2C+S">Sriram Ganapathy</a>, 
<a href="/search/cs?searchtype=author&query=Vashishth%2C+S">Shikhar Vashishth</a>, 
<a href="/search/cs?searchtype=author&query=Chandar%2C+S">Sarath Chandar</a>, 
<a href="/search/cs?searchtype=author&query=Talukdar%2C+P">Partha Talukdar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Language Models (LMs) pre-trained with self-supervision on large text corpora
have become the default starting point for developing models for various NLP
tasks. Once the pre-training corpus has been assembled, all data samples in the
corpus are treated with equal importance during LM pre-training. However, due
to varying levels of relevance and quality of data, equal importance to all the
data samples may not be the optimal choice. While data reweighting has been
explored in the context of task-specific supervised learning and LM
fine-tuning, model-driven reweighting for pre-training data has not been
explored. We fill this important gap and propose PRESENCE, a method for jointly
reweighting samples by leveraging self-influence (SI) scores as an indicator of
sample importance and pre-training. PRESENCE promotes novelty and stability for
model pre-training. Through extensive analysis spanning multiple model sizes,
datasets, and tasks, we present PRESENCE as an important first step in the
research direction of sample reweighting for pre-training language models.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00915" title="Abstract">arXiv:2311.00915</a> [<a href="/pdf/2311.00915" title="Download PDF">pdf</a>, <a href="/format/2311.00915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task-Agnostic Low-Rank Adapters for Unseen English Dialects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zedian Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Held%2C+W">William Held</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yanchen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Diyi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) are trained on corpora disproportionally
weighted in favor of Standard American English. As a result, speakers of other
dialects experience significantly more failures when interacting with these
technologies. In practice, these speakers often accommodate their speech to be
better understood. Our work shares the belief that language technologies should
be designed to accommodate the diversity in English dialects and not the other
way around. However, prior works on dialect struggle with generalizing to
evolving and emerging dialects in a scalable manner. To fill this gap, our
method, HyperLoRA, leverages expert linguistic knowledge to enable
resource-efficient adaptation via hypernetworks. By disentangling
dialect-specific and cross-dialectal information, HyperLoRA improves
generalization to unseen dialects in a task-agnostic fashion. Not only is
HyperLoRA more scalable in the number of parameters, but it also achieves the
best or most competitive performance across 5 dialects in a zero-shot setting.
In this way, our approach facilitates access to language technology for
billions of English dialect speakers who are traditionally underrepresented.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00917" title="Abstract">arXiv:2311.00917</a> [<a href="/pdf/2311.00917" title="Download PDF">pdf</a>, <a href="/format/2311.00917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RPCANet: Deep Unfolding RPCA Based Infrared Small Target Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fengyi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianfang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zhenming Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep learning (DL) networks have achieved remarkable performance in infrared
small target detection (ISTD). However, these structures exhibit a deficiency
in interpretability and are widely regarded as black boxes, as they disregard
domain knowledge in ISTD. To alleviate this issue, this work proposes an
interpretable deep network for detecting infrared dim targets, dubbed RPCANet.
Specifically, our approach formulates the ISTD task as sparse target
extraction, low-rank background estimation, and image reconstruction in a
relaxed Robust Principle Component Analysis (RPCA) model. By unfolding the
iterative optimization updating steps into a deep-learning framework,
time-consuming and complex matrix calculations are replaced by theory-guided
neural networks. RPCANet detects targets with clear interpretability and
preserves the intrinsic image feature, instead of directly transforming the
detection task into a matrix decomposition problem. Extensive experiments
substantiate the effectiveness of our deep unfolding framework and demonstrate
its trustworthy results, surpassing baseline methods in both qualitative and
quantitative evaluations.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00919" title="Abstract">arXiv:2311.00919</a> [<a href="/pdf/2311.00919" title="Download PDF">pdf</a>, <a href="/format/2311.00919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MIST: Defending Against Membership Inference Attacks Through  Membership-Invariant Subspace Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiacheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Ninghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+B">Bruno Ribeiro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In Member Inference (MI) attacks, the adversary try to determine whether an
instance is used to train a machine learning (ML) model. MI attacks are a major
privacy concern when using private data to train ML models. Most MI attacks in
the literature take advantage of the fact that ML models are trained to fit the
training data well, and thus have very low loss on training instances. Most
defenses against MI attacks therefore try to make the model fit the training
data less well. Doing so, however, generally results in lower accuracy. We
observe that training instances have different degrees of vulnerability to MI
attacks. Most instances will have low loss even when not included in training.
For these instances, the model can fit them well without concerns of MI
attacks. An effective defense only needs to (possibly implicitly) identify
instances that are vulnerable to MI attacks and avoids overfitting them. A
major challenge is how to achieve such an effect in an efficient training
process. Leveraging two distinct recent advancements in representation
learning: counterfactually-invariant representations and subspace learning
methods, we introduce a novel Membership-Invariant Subspace Training (MIST)
method to defend against MI attacks. MIST avoids overfitting the vulnerable
instances without significant impact on other instances. We have conducted
extensive experimental studies, comparing MIST with various other
state-of-the-art (SOTA) MI defenses against several SOTA MI attacks. We find
that MIST outperforms other defenses while resulting in minimal reduction in
testing accuracy.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00921" title="Abstract">arXiv:2311.00921</a> [<a href="/pdf/2311.00921" title="Download PDF">pdf</a>, <a href="/format/2311.00921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $O(N)$ distributed direct factorization of structured dense matrices  using runtime systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Deshmukh%2C+S">Sameer Deshmukh</a>, 
<a href="/search/math?searchtype=author&query=Ma%2C+Q">Qinxiang Ma</a>, 
<a href="/search/math?searchtype=author&query=Yokota%2C+R">Rio Yokota</a>, 
<a href="/search/math?searchtype=author&query=Bosilca%2C+G">George Bosilca</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Software (cs.MS)

</div>
<p class="mathjax">Structured dense matrices result from boundary integral problems in
electrostatics and geostatistics, and also Schur complements in sparse
preconditioners such as multi-frontal methods. Exploiting the structure of such
matrices can reduce the time for dense direct factorization from $O(N^3)$ to
$O(N)$. The Hierarchically Semi-Separable (HSS) matrix is one such low rank
matrix format that can be factorized using a Cholesky-like algorithm called ULV
factorization. The HSS-ULV algorithm is highly parallel because it removes the
dependency on trailing sub-matrices at each HSS level. However, a key merge
step that links two successive HSS levels remains a challenge for efficient
parallelization. In this paper, we use an asynchronous runtime system PaRSEC
with the HSS-ULV algorithm. We compare our work with STRUMPACK and LORAPO, both
state-of-the-art implementations of dense direct low rank factorization, and
achieve up to 2x better factorization time for matrices arising from a diverse
set of applications on up to 128 nodes of Fugaku for similar or better accuracy
for all the problems that we survey.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00922" title="Abstract">arXiv:2311.00922</a> [<a href="/pdf/2311.00922" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Research Team Identification Based on Representation Learning of  Academic Heterogeneous Information Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junfu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yawen Li</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Z">Zhe Xue</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Ang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Academic networks in the real world can usually be described by heterogeneous
information networks composed of multi-type nodes and relationships. Some
existing research on representation learning for homogeneous information
networks lacks the ability to explore heterogeneous information networks in
heterogeneous information networks. It cannot be applied to heterogeneous
information networks. Aiming at the practical needs of effectively identifying
and discovering scientific research teams from the academic heterogeneous
information network composed of massive and complex scientific and
technological big data, this paper proposes a scientific research team
identification method based on representation learning of academic
heterogeneous information networks. The attention mechanism at node level and
meta-path level learns low-dimensional, dense and real-valued vector
representations on the basis of retaining the rich topological information of
nodes in the network and the semantic information based on meta-paths, and
realizes effective identification and discovery of scientific research teams
and important team members in academic heterogeneous information networks based
on maximizing node influence. Experimental results show that our proposed
method outperforms the comparative methods.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00923" title="Abstract">arXiv:2311.00923</a> [<a href="/pdf/2311.00923" title="Download PDF">pdf</a>, <a href="/format/2311.00923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Review and Roadmap of Deep Causal Model from Different Causal  Structures and Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+K">Keqing Du</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenguang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinyu Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">The fusion of causal models with deep learning introducing increasingly
intricate data sets, such as the causal associations within images or between
textual components, has surfaced as a focal research area. Nonetheless, the
broadening of original causal concepts and theories to such complex,
non-statistical data has been met with serious challenges. In response, our
study proposes redefinitions of causal data into three distinct categories from
the standpoint of causal structure and representation: definite data,
semi-definite data, and indefinite data. Definite data chiefly pertains to
statistical data used in conventional causal scenarios, while semi-definite
data refers to a spectrum of data formats germane to deep learning, including
time-series, images, text, and others. Indefinite data is an emergent research
sphere inferred from the progression of data forms by us. To comprehensively
present these three data paradigms, we elaborate on their formal definitions,
differences manifested in datasets, resolution pathways, and development of
research. We summarize key tasks and achievements pertaining to definite and
semi-definite data from myriad research undertakings, present a roadmap for
indefinite data, beginning with its current research conundrums. Lastly, we
classify and scrutinize the key datasets presently utilized within these three
paradigms.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00924" title="Abstract">arXiv:2311.00924</a> [<a href="/pdf/2311.00924" title="Download PDF">pdf</a>, <a href="/format/2311.00924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Power of the Senses: Generalizable Manipulation from Vision and  Touch through Masked Multimodal Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sferrazza%2C+C">Carmelo Sferrazza</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+Y">Younggyo Seo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Youngwoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Abbeel%2C+P">Pieter Abbeel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Humans rely on the synergy of their senses for most essential tasks. For
tasks requiring object manipulation, we seamlessly and effectively exploit the
complementarity of our senses of vision and touch. This paper draws inspiration
from such capabilities and aims to find a systematic approach to fuse visual
and tactile information in a reinforcement learning setting. We propose Masked
Multimodal Learning (M3L), which jointly learns a policy and visual-tactile
representations based on masked autoencoding. The representations jointly
learned from vision and touch improve sample efficiency, and unlock
generalization capabilities beyond those achievable through each of the senses
separately. Remarkably, representations learned in a multimodal setting also
benefit vision-only policies at test time. We evaluate M3L on three simulated
environments with both visual and tactile observations: robotic insertion, door
opening, and dexterous in-hand manipulation, demonstrating the benefits of
learning a multimodal policy. Code and videos of the experiments are available
at https://sferrazza.cc/m3l_site.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00926" title="Abstract">arXiv:2311.00926</a> [<a href="/pdf/2311.00926" title="Download PDF">pdf</a>, <a href="/format/2311.00926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M2T2: Multi-Task Masked Transformer for Object-centric Pick and Place
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Wentao Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Murali%2C+A">Adithyavairavan Murali</a>, 
<a href="/search/cs?searchtype=author&query=Mousavian%2C+A">Arsalan Mousavian</a>, 
<a href="/search/cs?searchtype=author&query=Fox%2C+D">Dieter Fox</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures, accepted by CoRL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">With the advent of large language models and large-scale robotic datasets,
there has been tremendous progress in high-level decision-making for object
manipulation. These generic models are able to interpret complex tasks using
language commands, but they often have difficulties generalizing to
out-of-distribution objects due to the inability of low-level action
primitives. In contrast, existing task-specific models excel in low-level
manipulation of unknown objects, but only work for a single type of action. To
bridge this gap, we present M2T2, a single model that supplies different types
of low-level actions that work robustly on arbitrary objects in cluttered
scenes. M2T2 is a transformer model which reasons about contact points and
predicts valid gripper poses for different action modes given a raw point cloud
of the scene. Trained on a large-scale synthetic dataset with 128K scenes, M2T2
achieves zero-shot sim2real transfer on the real robot, outperforming the
baseline system with state-of-the-art task-specific models by about 19% in
overall performance and 37.5% in challenging scenes where the object needs to
be re-oriented for collision-free placement. M2T2 also achieves
state-of-the-art results on a subset of language conditioned tasks in RLBench.
Videos of robot experiments on unseen objects in both real world and simulation
are available on our project website https://m2-t2.github.io.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00928" title="Abstract">arXiv:2311.00928</a> [<a href="/pdf/2311.00928" title="Download PDF">pdf</a>, <a href="/format/2311.00928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quatro++: Robust Global Registration Exploiting Ground Segmentation for  Loop Closing in LiDAR SLAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lim%2C+H">Hyungtae Lim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Beomsoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Daebeom Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+E+M">Eungchang Mason Lee</a>, 
<a href="/search/cs?searchtype=author&query=Myung%2C+H">Hyun Myung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 23 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Global registration is a fundamental task that estimates the relative pose
between two viewpoints of 3D point clouds. However, there are two issues that
degrade the performance of global registration in LiDAR SLAM: one is the
sparsity issue and the other is degeneracy. The sparsity issue is caused by the
sparse characteristics of the 3D point cloud measurements in a mechanically
spinning LiDAR sensor. The degeneracy issue sometimes occurs because the
outlier-rejection methods reject too many correspondences, leaving less than
three inliers. These two issues have become more severe as the pose discrepancy
between the two viewpoints of 3D point clouds becomes greater. To tackle these
problems, we propose a robust global registration framework, called
\textit{Quatro++}. Extending our previous work that solely focused on the
global registration itself, we address the robust global registration in terms
of the loop closing in LiDAR SLAM. To this end, ground segmentation is
exploited to achieve robust global registration. Through the experiments, we
demonstrate that our proposed method shows a higher success rate than the
state-of-the-art global registration methods, overcoming the sparsity and
degeneracy issues. In addition, we show that ground segmentation significantly
helps to increase the success rate for the ground vehicles. Finally, we apply
our proposed method to the loop closing module in LiDAR SLAM and confirm that
the quality of the loop constraints is improved, showing more precise mapping
results. Therefore, the experimental evidence corroborated the suitability of
our method as an initial alignment in the loop closing. Our code is available
at https://quatro-plusplus.github.io.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00931" title="Abstract">arXiv:2311.00931</a> [<a href="/pdf/2311.00931" title="Download PDF">pdf</a>, <a href="/format/2311.00931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Defect Prediction from Unrealistic Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alrashedy%2C+K">Kamel Alrashedy</a>, 
<a href="/search/cs?searchtype=author&query=Hellendoorn%2C+V+J">Vincent J. Hellendoorn</a>, 
<a href="/search/cs?searchtype=author&query=Orso%2C+A">Alessandro Orso</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Pretrained models of code, such as CodeBERT and CodeT5, have become popular
choices for code understanding and generation tasks. Such models tend to be
large and require commensurate volumes of training data, which are rarely
available for downstream tasks. Instead, it has become popular to train models
with far larger but less realistic datasets, such as functions with
artificially injected bugs. Models trained on such data, however, tend to only
perform well on similar data, while underperforming on real world programs. In
this paper, we conjecture that this discrepancy stems from the presence of
distracting samples that steer the model away from the real-world task
distribution. To investigate this conjecture, we propose an approach for
identifying the subsets of these large yet unrealistic datasets that are most
similar to examples in real-world datasets based on their learned
representations. Our approach extracts high-dimensional embeddings of both
real-world and artificial programs using a neural model and scores artificial
samples based on their distance to the nearest real-world sample. We show that
training on only the nearest, representationally most similar samples while
discarding samples that are not at all similar in representations yields
consistent improvements across two popular pretrained models of code on two
code understanding tasks. Our results are promising, in that they show that
training models on a representative subset of an unrealistic dataset can help
us harness the power of large-scale synthetic data generation while preserving
downstream task performance. Finally, we highlight the limitations of applying
AI models for predicting vulnerabilities and bugs in real-world applications
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00932" title="Abstract">arXiv:2311.00932</a> [<a href="/pdf/2311.00932" title="Download PDF">pdf</a>, <a href="/format/2311.00932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards High-quality HDR Deghosting with Conditional Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Q">Qingsen Yan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+T">Tao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+W">Wei Dong</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanning Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by IEEE TCSVT
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">High Dynamic Range (HDR) images can be recovered from several Low Dynamic
Range (LDR) images by existing Deep Neural Networks (DNNs) techniques. Despite
the remarkable progress, DNN-based methods still generate ghosting artifacts
when LDR images have saturation and large motion, which hinders potential
applications in real-world scenarios. To address this challenge, we formulate
the HDR deghosting problem as an image generation that leverages LDR features
as the diffusion model's condition, consisting of the feature condition
generator and the noise predictor. Feature condition generator employs
attention and Domain Feature Alignment (DFA) layer to transform the
intermediate features to avoid ghosting artifacts. With the learned features as
conditions, the noise predictor leverages a stochastic iterative denoising
process for diffusion models to generate an HDR image by steering the sampling
process. Furthermore, to mitigate semantic confusion caused by the saturation
problem of LDR images, we design a sliding window noise estimator to sample
smooth noise in a patch-based manner. In addition, an image space loss is
proposed to avoid the color distortion of the estimated HDR results. We
empirically evaluate our model on benchmark datasets for HDR imaging. The
results demonstrate that our approach achieves state-of-the-art performances
and well generalization to real-world images.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00936" title="Abstract">arXiv:2311.00936</a> [<a href="/pdf/2311.00936" title="Download PDF">pdf</a>, <a href="/format/2311.00936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SatBird: Bird Species Distribution Modeling with Remote Sensing and  Citizen Science Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teng%2C+M">M&#xe9;lisande Teng</a>, 
<a href="/search/cs?searchtype=author&query=Elmustafa%2C+A">Amna Elmustafa</a>, 
<a href="/search/cs?searchtype=author&query=Akera%2C+B">Benjamin Akera</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>, 
<a href="/search/cs?searchtype=author&query=Abdelwahed%2C+H+R">Hager Radi Abdelwahed</a>, 
<a href="/search/cs?searchtype=author&query=Larochelle%2C+H">Hugo Larochelle</a>, 
<a href="/search/cs?searchtype=author&query=Rolnick%2C+D">David Rolnick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37th Conference on Neural Information Processing Systems (NeurIPS 2023) Track on Datasets and Benchmarks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Populations and Evolution (q-bio.PE)

</div>
<p class="mathjax">Biodiversity is declining at an unprecedented rate, impacting ecosystem
services necessary to ensure food, water, and human health and well-being.
Understanding the distribution of species and their habitats is crucial for
conservation policy planning. However, traditional methods in ecology for
species distribution models (SDMs) generally focus either on narrow sets of
species or narrow geographical areas and there remain significant knowledge
gaps about the distribution of species. A major reason for this is the limited
availability of data traditionally used, due to the prohibitive amount of
effort and expertise required for traditional field monitoring. The wide
availability of remote sensing data and the growing adoption of citizen science
tools to collect species observations data at low cost offer an opportunity for
improving biodiversity monitoring and enabling the modelling of complex
ecosystems. We introduce a novel task for mapping bird species to their
habitats by predicting species encounter rates from satellite images, and
present SatBird, a satellite dataset of locations in the USA with labels
derived from presence-absence observation data from the citizen science
database eBird, considering summer (breeding) and winter seasons. We also
provide a dataset in Kenya representing low-data regimes. We additionally
provide environmental data and species range maps for each location. We
benchmark a set of baselines on our dataset, including SOTA models for remote
sensing tasks. SatBird opens up possibilities for scalably modelling properties
of ecosystems worldwide.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00938" title="Abstract">arXiv:2311.00938</a> [<a href="/pdf/2311.00938" title="Download PDF">pdf</a>, <a href="/format/2311.00938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging the Gap: Addressing Discrepancies in Diffusion Model Training  for Classifier-Free Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patel%2C+N">Niket Patel</a>, 
<a href="/search/cs?searchtype=author&query=Salamanca%2C+L">Luis Salamanca</a>, 
<a href="/search/cs?searchtype=author&query=Barba%2C+L">Luis Barba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS Diffusion Workshop 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Diffusion models have emerged as a pivotal advancement in generative models,
setting new standards to the quality of the generated instances. In the current
paper we aim to underscore a discrepancy between conventional training methods
and the desired conditional sampling behavior of these models. While the
prevalent classifier-free guidance technique works well, it's not without
flaws. At higher values for the guidance scale parameter $w$, we often get out
of distribution samples and mode collapse, whereas at lower values for $w$ we
may not get the desired specificity. To address these challenges, we introduce
an updated loss function that better aligns training objectives with sampling
behaviors. Experimental validation with FID scores on CIFAR-10 elucidates our
method's ability to produce higher quality samples with fewer sampling
timesteps, and be more robust to the choice of guidance scale $w$. We also
experiment with fine-tuning Stable Diffusion on the proposed loss, to provide
early evidence that large diffusion models may also benefit from this refined
loss function.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00940" title="Abstract">arXiv:2311.00940</a> [<a href="/pdf/2311.00940" title="Download PDF">pdf</a>, <a href="/format/2311.00940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Uploading Scheduling in mmWave-Based Sensor Networks via Mobile  Blocker Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sun%2C+Y">Yifei Sun</a>, 
<a href="/search/eess?searchtype=author&query=Lv%2C+B">Bojie Lv</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/eess?searchtype=author&query=Tan%2C+H">Haisheng Tan</a>, 
<a href="/search/eess?searchtype=author&query=Lau%2C+F+C+M">Francis C. M. Lau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, accepted for publication on ICPADS23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The freshness of information, measured as Age of Information (AoI), is
critical for many applications in next-generation wireless sensor networks
(WSNs). Due to its high bandwidth, millimeter wave (mmWave) communication is
seen to be frequently exploited in WSNs to facilitate the deployment of
bandwidth-demanding applications. However, the vulnerability of mmWave to user
mobility typically results in link blockage and thus postponed real-time
communications. In this paper, joint sampling and uploading scheduling in an
AoI-oriented WSN working in mmWave band is considered, where a single human
blocker is moving randomly and signal propagation paths may be blocked. The
locations of signal reflectors and the real-time position of the blocker can be
detected via wireless sensing technologies. With the knowledge of blocker
motion pattern, the statistics of future wireless channels can be predicted. As
a result, the AoI degradation arising from link blockage can be forecast and
mitigated. Specifically, we formulate the long-term sampling, uplink
transmission time and power allocation as an infinite-horizon Markov decision
process (MDP) with discounted cost. Due to the curse of dimensionality, the
optimal solution is infeasible. A novel low-complexity solution framework with
guaranteed performance in the worst case is proposed where the forecast of link
blockage is exploited in a value function approximation. Simulations show that
compared with several heuristic benchmarks, our proposed policy, benefiting
from the awareness of link blockage, can reduce average cost up to 49.6%.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00941" title="Abstract">arXiv:2311.00941</a> [<a href="/pdf/2311.00941" title="Download PDF">pdf</a>, <a href="/format/2311.00941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Mixture Solvers for Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hanzhong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+F">Fan Bao</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+T">Tianyu Pang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shuicheng Yan</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+C">Chao Du</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chongxuan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recently, diffusion models have achieved great success in generative tasks.
Sampling from diffusion models is equivalent to solving the reverse diffusion
stochastic differential equations (SDEs) or the corresponding probability flow
ordinary differential equations (ODEs). In comparison, SDE-based solvers can
generate samples of higher quality and are suited for image translation tasks
like stroke-based synthesis. During inference, however, existing SDE-based
solvers are severely constrained by the efficiency-effectiveness dilemma. Our
investigation suggests that this is because the Gaussian assumption in the
reverse transition kernel is frequently violated (even in the case of simple
mixture data) given a limited number of discretization steps. To overcome this
limitation, we introduce a novel class of SDE-based solvers called
\emph{Gaussian Mixture Solvers (GMS)} for diffusion models. Our solver
estimates the first three-order moments and optimizes the parameters of a
Gaussian mixture transition kernel using generalized methods of moments in each
step during sampling. Empirically, our solver outperforms numerous SDE-based
solvers in terms of sample quality in image generation and stroke-based
synthesis in various diffusion models, which validates the motivation and
effectiveness of GMS. Our code is available at
https://github.com/Guohanzhong/GMS.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00943" title="Abstract">arXiv:2311.00943</a> [<a href="/pdf/2311.00943" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sound Call Graph Construction for Java Object Deserialization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santos%2C+J+C+S">Joanna C. S. Santos</a>, 
<a href="/search/cs?searchtype=author&query=Mirakhorli%2C+M">Mehdi Mirakhorli</a>, 
<a href="/search/cs?searchtype=author&query=Shokri%2C+A">Ali Shokri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Object serialization and deserialization is widely used for storing and
preserving objects in files, memory, or database as well as for transporting
them across machines, enabling remote interaction among processes and many
more. This mechanism relies on reflection, a dynamic language that introduces
serious challenges for static analyses. Current state-of-the-art call graph
construction algorithms does not fully support object
serialization/deserialization, i.e., they are unable to uncover the callback
methods that are invoked when objects are serialized and deserialized. Since
call graphs are a core data structure for multiple type of analysis (e.g.,
vulnerability detection), an appropriate analysis cannot be performed since the
call graph does not capture hidden (vulnerable) paths that occur via callback
methods. In this paper, we present Seneca, an approach for handling
serialization with improved soundness in the context of call graph
construction. Our approach relies on taint analysis and API modeling to
construct sound call graphs. We evaluated our approach with respect to
soundness, precision, performance, and usefulness in detecting untrusted object
deserialization vulnerabilities. Our results show that Seneca can create sound
call graphs with respect to serialization features. The resulting call graphs
do not incur significant overhead and were shown to be useful for performing
identification of vulnerable paths caused by untrusted object deserialization.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00945" title="Abstract">arXiv:2311.00945</a> [<a href="/pdf/2311.00945" title="Download PDF">pdf</a>, <a href="/format/2311.00945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E3 TTS: Easy End-to-End Diffusion-based Text to Speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Morioka%2C+N">Nobuyuki Morioka</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Nanxin Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ASRU 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We propose Easy End-to-End Diffusion-based Text to Speech, a simple and
efficient end-to-end text-to-speech model based on diffusion. E3 TTS directly
takes plain text as input and generates an audio waveform through an iterative
refinement process. Unlike many prior work, E3 TTS does not rely on any
intermediate representations like spectrogram features or alignment
information. Instead, E3 TTS models the temporal structure of the waveform
through the diffusion process. Without relying on additional conditioning
information, E3 TTS could support flexible latent structure within the given
audio. This enables E3 TTS to be easily adapted for zero-shot tasks such as
editing without any additional training. Experiments show that E3 TTS can
generate high-fidelity audio, approaching the performance of a state-of-the-art
neural TTS system. Audio samples are available at https://e3tts.github.io.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00947" title="Abstract">arXiv:2311.00947</a> [<a href="/pdf/2311.00947" title="Download PDF">pdf</a>, <a href="/format/2311.00947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Age of Generative AI and AI-Generated Everything
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Hongyang Du</a>, 
<a href="/search/cs?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiawen Kang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zehui Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Ping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shuguang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xuemin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+S">Shiwen Mao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhu Han</a>, 
<a href="/search/cs?searchtype=author&query=Jamalipour%2C+A">Abbas Jamalipour</a>, 
<a href="/search/cs?searchtype=author&query=Poor%2C+H+V">H. Vincent Poor</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D+I">Dong In Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Generative AI (GAI) has emerged as a significant advancement in artificial
intelligence, renowned for its language and image generation capabilities. This
paper presents ``AI-Generated Everything'' (AIGX), a concept that extends GAI
beyond mere content creation to real-time adaptation and control across diverse
technological domains. In networking, AIGX collaborates closely with physical,
data link, network, and application layers to enhance real-time network
management that responds to various system and service settings as well as
application and user requirements. Networks, in return, serve as crucial
components in further AIGX capability optimization through the AIGX lifecycle,
i.e., data collection, distributed pre-training, and rapid decision-making,
thereby establishing a mutually enhancing interplay. Moreover, we offer an
in-depth case study focused on power allocation to illustrate the
interdependence between AIGX and networking systems. Through this exploration,
the article analyzes the significant role of GAI for networking, clarifies the
ways networks augment AIGX functionalities, and underscores the virtuous
interactive cycle they form. This article paves the way for subsequent future
research aimed at fully unlocking the potential of GAI and networks.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00949" title="Abstract">arXiv:2311.00949</a> [<a href="/pdf/2311.00949" title="Download PDF">pdf</a>, <a href="/format/2311.00949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Noise pursuit for Augmenting Text-to-Video Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shijie Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huayi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengjian Li</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+W">Weidong Geng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Meng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaxiong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite the remarkable progress in text-to-video generation, existing
diffusion-based models often exhibit instability in terms of noise during
inference. Specifically, when different noises are fed for the given text,
these models produce videos that differ significantly in terms of both frame
quality and temporal consistency. With this observation, we posit that there
exists an optimal noise matched to each textual input; however, the widely
adopted strategies of random noise sampling often fail to capture it. In this
paper, we argue that the optimal noise can be approached through inverting the
groundtruth video using the established noise-video mapping derived from the
diffusion model. Nevertheless, the groundtruth video for the text prompt is not
available during inference. To address this challenge, we propose to
approximate the optimal noise via a search and inversion pipeline. Given a text
prompt, we initially search for a video from a predefined candidate pool that
closely relates to the text prompt. Subsequently, we invert the searched video
into the noise space, which serves as an improved noise prompt for the textual
input. In addition to addressing noise, we also observe that the text prompt
with richer details often leads to higher-quality videos. Motivated by this, we
further design a semantic-preserving rewriter to enrich the text prompt, where
a reference-guided rewriting is devised for reasonable details compensation,
and a denoising with a hybrid semantics strategy is proposed to preserve the
semantic consistency. Extensive experiments on the WebVid-10M benchmark show
that our proposed method can improve the text-to-video models with a clear
margin, while introducing no optimization burden.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00952" title="Abstract">arXiv:2311.00952</a> [<a href="/pdf/2311.00952" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Workspace optimization of 1T2R parallel manipulators with a  dimensionally homogeneous constraint-embedded Jacobian
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nigatu%2C+H">Hassen Nigatu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Doik Kim</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> \cite{Nigatu2023}
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents the workspace optimization of one-translational
two-rotational (1T2R) parallel manipulators using a dimensionally homogeneous
constraint-embedded Jacobian. The mixed degrees of freedom of 1T2R parallel
manipulators, which cause dimensional inconsistency, make it difficult to
optimize their architectural parameters. To solve this problem, a point-based
approach with a shifting property, selection matrix, and constraint-embedded
inverse Jacobian is proposed. A simplified formulation is provided, eliminating
the complex partial differentiation required in previous approaches. The
dimensional homogeneity of the proposed method was analytically proven, and its
validity was confirmed by comparing it with the conventional point-based method
using a 3-PRS manipulator. Furthermore, the approach was applied to an
asymmetric 2-RRS/RRRU manipulator with no parasitic motion. This mechanism has
a T-shape combination of limbs with different kinematic parameters, making it
challenging to derive a dimensionally homogeneous Jacobian using the
conventional method. Finally, optimization was performed, and the results show
that the proposed method is more efficient than the conventional approach. The
efficiency and simplicity of the proposed method were verified using two
distinct parallel manipulators.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00953" title="Abstract">arXiv:2311.00953</a> [<a href="/pdf/2311.00953" title="Download PDF">pdf</a>, <a href="/ps/2311.00953" title="Download PostScript">ps</a>, <a href="/format/2311.00953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blending Reward Functions via Few Expert Demonstrations for Faithful and  Accurate Knowledge-Grounded Dialogue Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Wanyu Du</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Y">Yangfeng Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The development of trustworthy conversational information-seeking systems
relies on dialogue models that can generate faithful and accurate responses
based on relevant knowledge texts. However, two main challenges hinder this
task. Firstly, language models may generate hallucinations due to data biases
present in their pretraining corpus. Secondly, knowledge texts often contain
redundant and irrelevant information that distracts the model's attention from
the relevant text span. Previous works use additional data annotations on the
knowledge texts to learn a knowledge identification module in order to bypass
irrelevant information, but collecting such high-quality span annotations can
be costly. In this work, we leverage reinforcement learning algorithms to
overcome the above challenges by introducing a novel reward function. Our
reward function combines an accuracy metric and a faithfulness metric to
provide a balanced quality judgment of generated responses, which can be used
as a cost-effective approximation to a human preference reward model when only
a few preference annotations are available. Empirical experiments on two
conversational information-seeking datasets demonstrate that our method can
compete with other strong supervised learning baselines.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00958" title="Abstract">arXiv:2311.00958</a> [<a href="/pdf/2311.00958" title="Download PDF">pdf</a>, <a href="/format/2311.00958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IndoToD: A Multi-Domain Indonesian Benchmark For End-to-End  Task-Oriented Dialogue Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kautsar%2C+M+D+A">Muhammad Dehan Al Kautsar</a>, 
<a href="/search/cs?searchtype=author&query=Nurdini%2C+R+K">Rahmah Khoirussyifa&#x27; Nurdini</a>, 
<a href="/search/cs?searchtype=author&query=Cahyawijaya%2C+S">Samuel Cahyawijaya</a>, 
<a href="/search/cs?searchtype=author&query=Winata%2C+G+I">Genta Indra Winata</a>, 
<a href="/search/cs?searchtype=author&query=Purwarianti%2C+A">Ayu Purwarianti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 1st Workshop in South East Asian Language Processing (SEALP), Co-located with AACL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Task-oriented dialogue (ToD) systems have been mostly created for
high-resource languages, such as English and Chinese. However, there is a need
to develop ToD systems for other regional or local languages to broaden their
ability to comprehend the dialogue contexts in various languages. This paper
introduces IndoToD, an end-to-end multi domain ToD benchmark in Indonesian. We
extend two English ToD datasets to Indonesian, comprising four different
domains by delexicalization to efficiently reduce the size of annotations. To
ensure a high-quality data collection, we hire native speakers to manually
translate the dialogues. Along with the original English datasets, these new
Indonesian datasets serve as an effective benchmark for evaluating Indonesian
and English ToD systems as well as exploring the potential benefits of
cross-lingual and bilingual transfer learning approaches.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00959" title="Abstract">arXiv:2311.00959</a> [<a href="/pdf/2311.00959" title="Download PDF">pdf</a>, <a href="/format/2311.00959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Fair Federated Learning Based on Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weikang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+J">Junping Du</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Yingxia Shao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yangxi Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Information Theory (cs.IT)

</div>
<p class="mathjax">Federated learning enables a collaborative training and optimization of
global models among a group of devices without sharing local data samples.
However, the heterogeneity of data in federated learning can lead to unfair
representation of the global model across different devices. To address the
fairness issue in federated learning, we propose a dynamic q fairness federated
learning algorithm with reinforcement learning, called DQFFL. DQFFL aims to
mitigate the discrepancies in device aggregation and enhance the fairness of
treatment for all groups involved in federated learning. To quantify fairness,
DQFFL leverages the performance of the global federated model on each device
and incorporates {\alpha}-fairness to transform the preservation of fairness
during federated aggregation into the distribution of client weights in the
aggregation process. Considering the sensitivity of parameters in measuring
fairness, we propose to utilize reinforcement learning for dynamic parameters
during aggregation. Experimental results demonstrate that our DQFFL outperforms
the state-of-the-art methods in terms of overall performance, fairness and
convergence speed.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00960" title="Abstract">arXiv:2311.00960</a> [<a href="/pdf/2311.00960" title="Download PDF">pdf</a>, <a href="/format/2311.00960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trajectory Similarity Measurement: An Efficiency Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yanchuan Chang</a>, 
<a href="/search/cs?searchtype=author&query=Tanin%2C+E">Egemen Tanin</a>, 
<a href="/search/cs?searchtype=author&query=Cong%2C+G">Gao Cong</a>, 
<a href="/search/cs?searchtype=author&query=Jensen%2C+C+S">Christian S. Jensen</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Jianzhong Qi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Trajectories that capture object movement have numerous applications, in
which similarity computation between trajectories often plays a key role.
Traditionally, the similarity between two trajectories is quantified by means
of heuristic measures, e.g., Hausdorff or ERP, that operate directly on the
trajectories. In contrast, recent studies exploit deep learning to map
trajectories to d-dimensional vectors, called embeddings. Then, some distance
measure, e.g., Manhattan or Euclidean, is applied to the embeddings to quantify
trajectory similarity. The resulting similarities are inaccurate: they only
approximate the similarities obtained using the heuristic measures. As distance
computation on embeddings is efficient, focus has been on achieving embeddings
yielding high accuracy.
<br />Adopting an efficiency perspective, we analyze the time complexities of both
the heuristic and the learning-based approaches, finding that the time
complexities of the former approaches are not necessarily higher. Through
extensive experiments on open datasets, we find that, on both CPUs and GPUs,
only a few learning-based approaches can deliver the promised higher
efficiency, when the embeddings can be pre-computed, while heuristic approaches
are more efficient for one-off computations. Among the learning-based
approaches, the self-attention-based ones are the fastest to learn embeddings
that also yield the highest accuracy for similarity queries. These results have
implications for the use of trajectory similarity approaches given different
application requirements.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00961" title="Abstract">arXiv:2311.00961</a> [<a href="/pdf/2311.00961" title="Download PDF">pdf</a>, <a href="/format/2311.00961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concatenated Masked Autoencoders as Spatial-Temporal Learner
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhouqiang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bowen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+T">Tong Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Z">Zhaofeng Niu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hong Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guangshun Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liangzhi Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://github.com/minhoooo1/CatMAE">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learning representations from videos requires understanding continuous motion
and visual correspondences between frames. In this paper, we introduce the
Concatenated Masked Autoencoders (CatMAE) as a spatial-temporal learner for
self-supervised video representation learning. For the input sequence of video
frames, CatMAE keeps the initial frame unchanged while applying substantial
masking (95%) to subsequent frames. The encoder in CatMAE is responsible for
encoding visible patches for each frame individually; subsequently, for each
masked frame, the decoder leverages visible patches from both previous and
current frames to reconstruct the original image. Our proposed method enables
the model to estimate the motion information between visible patches, match the
correspondences between preceding and succeeding frames, and ultimately learn
the evolution of scenes. Furthermore, we propose a new data augmentation
strategy, Video-Reverse (ViRe), which uses reversed video frames as the model's
reconstruction targets. This further encourages the model to utilize continuous
motion details and correspondences to complete the reconstruction, thereby
enhancing the model's capabilities. Compared to the most advanced pre-training
methods, CatMAE achieves a leading level in video segmentation tasks and action
recognition tasks.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00962" title="Abstract">arXiv:2311.00962</a> [<a href="/pdf/2311.00962" title="Download PDF">pdf</a>, <a href="/format/2311.00962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Generated Images by Real Images Only
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bi%2C+X">Xiuli Bi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+B">Bin Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weisheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cosman%2C+P+C">Pamela C. Cosman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">As deep learning technology continues to evolve, the images yielded by
generative models are becoming more and more realistic, triggering people to
question the authenticity of images. Existing generated image detection methods
detect visual artifacts in generated images or learn discriminative features
from both real and generated images by massive training. This learning paradigm
will result in efficiency and generalization issues, making detection methods
always lag behind generation methods. This paper approaches the generated image
detection problem from a new perspective: Start from real images. By finding
the commonality of real images and mapping them to a dense subspace in feature
space, the goal is that generated images, regardless of their generative model,
are then projected outside the subspace. As a result, images from different
generative models can be detected, solving some long-existing problems in the
field. Experimental results show that although our method was trained only by
real images and uses 99.9\% less training data than other deep learning-based
methods, it can compete with state-of-the-art methods and shows excellent
performance in detecting emerging generative models with high inference
efficiency. Moreover, the proposed method shows robustness against various
post-processing. These advantages allow the method to be used in real-world
scenarios.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00964" title="Abstract">arXiv:2311.00964</a> [<a href="/pdf/2311.00964" title="Download PDF">pdf</a>, <a href="/format/2311.00964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Finding Bi-objective Pareto-optimal Fraud Prevention Rule Sets for  Fintech Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+C">Chengyao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+Y">Yin Lou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistical Finance (q-fin.ST)

</div>
<p class="mathjax">Rules are widely used in Fintech institutions to make fraud prevention
decisions, since rules are highly interpretable thanks to their intuitive
if-then structure. In practice, a two-stage framework of fraud prevention
decision rule set mining is usually employed in large Fintech institutions.
This paper is concerned with finding high-quality rule subsets in a
bi-objective space (such as precision and recall) from an initial pool of
rules. To this end, we adopt the concept of Pareto optimality and aim to find a
set of non-dominated rule subsets, which constitutes a Pareto front. We propose
a heuristic-based framework called PORS and we identify that the core of PORS
is the problem of solution selection on the front (SSF). We provide a
systematic categorization of the SSF problem and a thorough empirical
evaluation of various SSF methods on both public and proprietary datasets. We
also introduce a novel variant of sequential covering algorithm called
SpectralRules to encourage the diversity of the initial rule set and we
empirically find that SpectralRules further improves the quality of the found
Pareto front. On two real application scenarios within Alipay, we demonstrate
the advantages of our proposed methodology compared to existing work.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00966" title="Abstract">arXiv:2311.00966</a> [<a href="/pdf/2311.00966" title="Download PDF">pdf</a>, <a href="/format/2311.00966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invariant-Feature Subspace Recovery: A New Class of Provable Domain  Generalization Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Balasubramaniam%2C+G">Gargi Balasubramaniam</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+H">Haozhe Si</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Han Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to JMLR. This journal version significantly extends our ICML 2022 paper, <a href="/abs/2201.12919">arXiv:2201.12919</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Domain generalization asks for models trained over a set of training
environments to generalize well in unseen test environments. Recently, a series
of algorithms such as Invariant Risk Minimization (IRM) have been proposed for
domain generalization. However, Rosenfeld et al. (2021) shows that in a simple
linear data model, even if non-convexity issues are ignored, IRM and its
extensions cannot generalize to unseen environments with less than $d_s+1$
training environments, where $d_s$ is the dimension of the spurious-feature
subspace. In this work, we propose Invariant-feature Subspace Recovery (ISR): a
new class of algorithms to achieve provable domain generalization across the
settings of classification and regression problems. First, in the binary
classification setup of Rosenfeld et al. (2021), we show that our first
algorithm, ISR-Mean, can identify the subspace spanned by invariant features
from the first-order moments of the class-conditional distributions, and
achieve provable domain generalization with $d_s+1$ training environments. Our
second algorithm, ISR-Cov, further reduces the required number of training
environments to $O(1)$ using the information of second-order moments. Notably,
unlike IRM, our algorithms bypass non-convexity issues and enjoy global
convergence guarantees. Next, we extend ISR-Mean to the more general setting of
multi-class classification and propose ISR-Multiclass, which leverages class
information and provably recovers the invariant-feature subspace with $\lceil
d_s/k\rceil+1$ training environments for $k$-class classification. Finally, for
regression problems, we propose ISR-Regression that can identify the
invariant-feature subspace with $d_s+1$ training environments. Empirically, we
demonstrate the superior performance of our ISRs on synthetic benchmarks.
Further, ISR can be used as post-processing methods for feature extractors such
as neural nets.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00967" title="Abstract">arXiv:2311.00967</a> [<a href="/pdf/2311.00967" title="Download PDF">pdf</a>, <a href="/format/2311.00967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision-Language Interpreter for Robot Task Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shirai%2C+K">Keisuke Shirai</a>, 
<a href="/search/cs?searchtype=author&query=Beltran-Hernandez%2C+C+C">Cristian C. Beltran-Hernandez</a>, 
<a href="/search/cs?searchtype=author&query=Hamaya%2C+M">Masashi Hamaya</a>, 
<a href="/search/cs?searchtype=author&query=Hashimoto%2C+A">Atsushi Hashimoto</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+S">Shohei Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Kawaharazuka%2C+K">Kento Kawaharazuka</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+K">Kazutoshi Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Ushiku%2C+Y">Yoshitaka Ushiku</a>, 
<a href="/search/cs?searchtype=author&query=Mori%2C+S">Shinsuke Mori</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models (LLMs) are accelerating the development of
language-guided robot planners. Meanwhile, symbolic planners offer the
advantage of interpretability. This paper proposes a new task that bridges
these two trends, namely, multimodal planning problem specification. The aim is
to generate a problem description (PD), a machine-readable file used by the
planners to find a plan. By generating PDs from language instruction and scene
observation, we can drive symbolic planners in a language-guided framework. We
propose a Vision-Language Interpreter (ViLaIn), a new framework that generates
PDs using state-of-the-art LLM and vision-language models. ViLaIn can refine
generated PDs via error message feedback from the symbolic planner. Our aim is
to answer the question: How accurately can ViLaIn and the symbolic planner
generate valid robot plans? To evaluate ViLaIn, we introduce a novel dataset
called the problem description generation (ProDG) dataset. The framework is
evaluated with four new evaluation metrics. Experimental results show that
ViLaIn can generate syntactically correct problems with more than 99% accuracy
and valid plans with more than 58% accuracy.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00968" title="Abstract">arXiv:2311.00968</a> [<a href="/pdf/2311.00968" title="Download PDF">pdf</a>, <a href="/format/2311.00968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video2Music: Suitable Music Generation from Videos using an Affective  Multimodal Transformer model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jaeyong Kang</a>, 
<a href="/search/cs?searchtype=author&query=Poria%2C+S">Soujanya Poria</a>, 
<a href="/search/cs?searchtype=author&query=Herremans%2C+D">Dorien Herremans</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Numerous studies in the field of music generation have demonstrated
impressive performance, yet virtually no models are able to directly generate
music to match accompanying videos. In this work, we develop a generative music
AI framework, Video2Music, that can match a provided video. We first curated a
unique collection of music videos. Then, we analysed the music videos to obtain
semantic, scene offset, motion, and emotion features. These distinct features
are then employed as guiding input to our music generation model. We transcribe
the audio files into MIDI and chords, and extract features such as note density
and loudness. This results in a rich multimodal dataset, called MuVi-Sync, on
which we train a novel Affective Multimodal Transformer (AMT) model to generate
music given a video. This model includes a novel mechanism to enforce affective
similarity between video and music. Finally, post-processing is performed based
on a biGRU-based regression model to estimate note density and loudness based
on the video features. This ensures a dynamic rendering of the generated chords
with varying rhythm and volume. In a thorough experiment, we show that our
proposed framework can generate music that matches the video content in terms
of emotion. The musical quality, along with the quality of music-video matching
is confirmed in a user study. The proposed AMT model, along with the new
MuVi-Sync dataset, presents a promising step for the new task of music
generation for videos.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00971" title="Abstract">arXiv:2311.00971</a> [<a href="/pdf/2311.00971" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Integrated Framework Integrating Monte Carlo Tree Search and  Supervised Learning for Train Timetabling Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Feiyu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">The single-track railway train timetabling problem (TTP) is an important and
complex problem. This article proposes an integrated Monte Carlo Tree Search
(MCTS) computing framework that combines heuristic methods, unsupervised
learning methods, and supervised learning methods for solving TTP in discrete
action spaces. This article first describes the mathematical model and
simulation system dynamics of TTP, analyzes the characteristics of the solution
from the perspective of MCTS, and proposes some heuristic methods to improve
MCTS. This article considers these methods as planners in the proposed
framework. Secondly, this article utilizes deep convolutional neural networks
to approximate the value of nodes and further applies them to the MCTS search
process, referred to as learners. The experiment shows that the proposed
heuristic MCTS method is beneficial for solving TTP; The algorithm framework
that integrates planners and learners can improve the data efficiency of
solving TTP; The proposed method provides a new paradigm for solving TTP.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00973" title="Abstract">arXiv:2311.00973</a> [<a href="/pdf/2311.00973" title="Download PDF">pdf</a>, <a href="/format/2311.00973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Linear Bandits with Finite Adversarial Actions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Li Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+R">Ruida Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+C">Chao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Cong Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023, camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study a federated linear bandits model, where $M$ clients communicate with
a central server to solve a linear contextual bandits problem with finite
adversarial action sets that may be different across clients. To address the
unique challenges of adversarial finite action sets, we propose the
FedSupLinUCB algorithm, which extends the principles of SupLinUCB and OFUL
algorithms in linear contextual bandits. We prove that FedSupLinUCB achieves a
total regret of $\tilde{O}(\sqrt{d T})$, where $T$ is the total number of arm
pulls from all clients, and $d$ is the ambient dimension of the linear model.
This matches the minimax lower bound and thus is order-optimal (up to polylog
terms). We study both asynchronous and synchronous cases and show that the
communication cost can be controlled as $O(d M^2 \log(d)\log(T))$ and
$O(\sqrt{d^3 M^3} \log(d))$, respectively. The FedSupLinUCB design is further
extended to two scenarios: (1) variance-adaptive, where a total regret of
$\tilde{O} (\sqrt{d \sum \nolimits_{t=1}^{T} \sigma_t^2})$ can be achieved with
$\sigma_t^2$ being the noise variance of round $t$; and (2) adversarial
corruption, where a total regret of $\tilde{O}(\sqrt{dT} + d C_p)$ can be
achieved with $C_p$ being the total corruption budget. Experiment results
corroborate the theoretical analysis and demonstrate the effectiveness of
FedSupLinUCB on both synthetic and real-world datasets.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00974" title="Abstract">arXiv:2311.00974</a> [<a href="/pdf/2311.00974" title="Download PDF">pdf</a>, <a href="/format/2311.00974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CloudSim Express: A Novel Framework for Rapid Low Code Simulation of  Cloud Computing Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hewage%2C+T+B">Tharindu B. Hewage</a>, 
<a href="/search/cs?searchtype=author&query=Ilager%2C+S">Shashikant Ilager</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+M+A">Maria A. Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Buyya%2C+R">Rajkumar Buyya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Journal of Software: Practice and Experience
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Cloud computing environment simulators enable cost-effective experimentation
of novel infrastructure designs and management approaches by avoiding
significant costs incurred from repetitive deployments in real Cloud platforms.
However, widely used Cloud environment simulators compromise on usability due
to complexities in design and configuration, along with the added overhead of
programming language expertise. Existing approaches attempting to reduce this
overhead, such as script-based simulators and Graphical User Interface (GUI)
based simulators, often compromise on the extensibility of the simulator.
Simulator extensibility allows for customization at a fine-grained level, thus
reducing it significantly affects flexibility in creating simulations. To
address these challenges, we propose an architectural framework to enable
human-readable script-based simulations in existing Cloud environment
simulators while minimizing the impact on simulator extensibility. We implement
the proposed framework for the widely used Cloud environment simulator, the
CloudSim toolkit, and compare it against state-of-the-art baselines using a
practical use case. The resulting framework, called CloudSim Express, achieves
extensible simulations while surpassing baselines with over a 71.43% reduction
in code complexity and an 89.42% reduction in lines of code.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00976" title="Abstract">arXiv:2311.00976</a> [<a href="/pdf/2311.00976" title="Download PDF">pdf</a>, <a href="/format/2311.00976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spontaneous-Ordering Platoon Control for Multirobot Path Navigation  Using Guiding Vector Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Bin-Bin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hai-Tao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Weijia Yao</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jianing Ding</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+M">Ming Cao</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transaction on Robotics, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this paper, we propose a distributed guiding-vector-field (DGVF) algorithm
for a team of robots to form a spontaneous-ordering platoon moving along a
predefined desired path in the n-dimensional Euclidean space. Particularly, by
adding a path parameter as an additional virtual coordinate to each robot, the
DGVF algorithm can eliminate the singular points where the vector fields
vanish, and govern robots to approach a closed and even self-intersecting
desired path. Then, the interactions among neighboring robots and a virtual
target robot through their virtual coordinates enable the realization of the
desired platoon; in particular, relative parametric displacements can be
achieved with arbitrary ordering sequences. Rigorous analysis is provided to
guarantee the global convergence to the spontaneous-ordering platoon on the
common desired path from any initial positions. 2D experiments using three
HUSTER-0.3 unmanned surface vessels (USVs) are conducted to validate the
practical effectiveness of the proposed DGVF algorithm, and 3D numerical
simulations are presented to demonstrate its effectiveness and robustness when
tackling higher-dimensional multi-robot path-navigation missions and some
robots breakdown.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00978" title="Abstract">arXiv:2311.00978</a> [<a href="/pdf/2311.00978" title="Download PDF">pdf</a>, <a href="/format/2311.00978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cooperative Label-Free Moving Target Fencing for Second-Order  Multi-Agent Systems with Rigid Formation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Bin-Bin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hai-Tao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yang Shi</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Automatica, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">This paper proposes a label-free controller for a second-order multi-agent
system to cooperatively fence a moving target of variational velocity into a
convex hull formed by the agents whereas maintaining a rigid formation.
Therein, no label is predetermined for a specified agent. To attain a rigid
formation with guaranteed collision avoidance, each controller consists of two
terms: a dynamic regulator with an internal model to drive agents towards the
moving target merely by position information feedback, and a repulsive force
between each pair of adjacent agents. Significantly, sufficient conditions are
derived to guarantee the asymptotic stability of the closed-loop systems
governed by the proposed fencing controller. Rigorous analysis is provided to
eliminate the strong nonlinear couplings induced by the label-free property.
Finally, the effectiveness of the controller is substantiated by numerical
simulations.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00979" title="Abstract">arXiv:2311.00979</a> [<a href="/pdf/2311.00979" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overhead Line Defect Recognition Based on Unsupervised Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weixi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+X">Xichen Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sizhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xun Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Overhead line inspection greatly benefits from defect recognition using
visible light imagery. Addressing the limitations of existing feature
extraction techniques and the heavy data dependency of deep learning
approaches, this paper introduces a novel defect recognition framework. This is
built on the Faster RCNN network and complemented by unsupervised semantic
segmentation. The approach involves identifying the type and location of the
target equipment, utilizing semantic segmentation to differentiate between the
device and its backdrop, and finally employing similarity measures and logical
rules to categorize the type of defect. Experimental results indicate that this
methodology focuses more on the equipment rather than the defects when
identifying issues in overhead lines. This leads to a notable enhancement in
accuracy and exhibits impressive adaptability. Thus, offering a fresh
perspective for automating the inspection of distribution network equipment.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00980" title="Abstract">arXiv:2311.00980</a> [<a href="/pdf/2311.00980" title="Download PDF">pdf</a>, <a href="/format/2311.00980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAAIG: Motion Analysis And Instruction Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeh%2C+W">Wei-Hsin Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+P+H">Pei Hsin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yu-An Su</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+W+H">Wen Hsiang Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Ku%2C+L">Lun-Wei Ku</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the ACM Multimedia Asia 2023 Workshop on Intelligent Sports Technologies (WIST)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Many people engage in self-directed sports training at home but lack the
real-time guidance of professional coaches, making them susceptible to injuries
or the development of incorrect habits. In this paper, we propose a novel
application framework called MAAIG(Motion Analysis And Instruction Generation).
It can generate embedding vectors for each frame based on user-provided sports
action videos. These embedding vectors are associated with the 3D skeleton of
each frame and are further input into a pretrained T5 model. Ultimately, our
model utilizes this information to generate specific sports instructions. It
has the capability to identify potential issues and provide real-time guidance
in a manner akin to professional coaches, helping users improve their sports
skills and avoid injuries.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00982" title="Abstract">arXiv:2311.00982</a> [<a href="/pdf/2311.00982" title="Download PDF">pdf</a>, <a href="/ps/2311.00982" title="Download PostScript">ps</a>, <a href="/format/2311.00982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The c-differential properties of a class of power functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Huan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xiaoni Du</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Wenping Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+X">Xingbin Qiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Power functions with low $c$-differential uniformity have been widely studied
not only because of their strong resistance to multiplicative differential
attacks, but also low implementation cost in hardware. Furthermore, the
$c$-differential spectrum of a function gives a more precise characterization
of its $c$-differential properties. Let $f(x)=x^{\frac{p^n+3}{2}}$ be a power
function over the finite field $\mathbb{F}_{p^{n}}$, where $p\neq3$ is an odd
prime and $n$ is a positive integer. In this paper, for all primes $p\neq3$, by
investigating certain character sums with regard to elliptic curves and
computing the number of solutions of a system of equations over
$\mathbb{F}_{p^{n}}$, we determine explicitly the $(-1)$-differential spectrum
of $f$ with a unified approach. We show that if $p^n \equiv 3 \pmod 4$, then
$f$ is a differentially $(-1,3)$-uniform function except for
$p^n\in\{7,19,23\}$ where $f$ is an APcN function, and if $p^n \equiv 1 \pmod
4$, the $(-1)$-differential uniformity of $f$ is equal to $4$. In addition, an
upper bound of the $c$-differential uniformity of $f$ is also given.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00983" title="Abstract">arXiv:2311.00983</a> [<a href="/pdf/2311.00983" title="Download PDF">pdf</a>, <a href="/format/2311.00983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Inventory Routing: A Decision-Focused Learning Approach using  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+S">MD Shafikul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Wasi%2C+A+T">Azmine Toushik Wasi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 Pages, 2 figures, New in ML Workshop at NeurIPS 2023. Openreview forum: <a href="https://openreview.net/forum?id=r0fzjB8f7f">this https URL</a>&amp;
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
<p class="mathjax">Inventory Routing Problem (IRP) is a crucial challenge in supply chain
management as it involves optimizing efficient route selection while
considering the uncertainty of inventory demand planning. To solve IRPs,
usually a two-stage approach is employed, where demand is predicted using
machine learning techniques first, and then an optimization algorithm is used
to minimize routing costs. Our experiment shows machine learning models fall
short of achieving perfect accuracy because inventory levels are influenced by
the dynamic business environment, which, in turn, affects the optimization
problem in the next stage, resulting in sub-optimal decisions. In this paper,
we formulate and propose a decision-focused learning-based approach to solving
real-world IRPs. This approach directly integrates inventory prediction and
routing optimization within an end-to-end system potentially ensuring a robust
supply chain strategy.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00984" title="Abstract">arXiv:2311.00984</a> [<a href="/pdf/2311.00984" title="Download PDF">pdf</a>, <a href="/format/2311.00984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inclusiveness Matters: A Large-Scale Analysis of User Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arony%2C+N+N">Nowshin Nawar Arony</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z+S">Ze Shi Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bowen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Damian%2C+D">Daniela Damian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">In an era of rapidly expanding software usage, catering to the diverse needs
of users from various backgrounds has become a critical challenge.
Inclusiveness, representing a core human value, is frequently overlooked during
software development, leading to user dissatisfaction. Users often engage in
discourse on online platforms where they indicate their concerns. In this
study, we leverage user feedback from three popular online sources, Reddit,
Google Play Store, and Twitter, for 50 of the most popular apps in the world to
reveal the inclusiveness-related concerns from end users. Using a
Socio-Technical Grounded Theory approach, we analyzed 23,107 posts across the
three sources and identified 1,211 inclusiveness related posts. We organize our
empirical results in a taxonomy for inclusiveness comprising 6 major
categories: Fairness, Technology, Privacy, Demography, Usability, and Other
Human Values. To explore automated support to identifying inclusiveness-related
posts, we experimented with five state-of-the-art pre-trained large language
models (LLMs) and found that these models' effectiveness is high and yet varied
depending on the data source. GPT-2 performed best on Reddit, BERT on the
Google Play Store, and BART on Twitter. Our study provides an in-depth view of
inclusiveness-related user feedback from most popular apps and online sources.
We provide implications and recommendations that can be used to bridge the gap
between user expectations and software so that software developers can resonate
with the varied and evolving needs of the wide spectrum of users.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00986" title="Abstract">arXiv:2311.00986</a> [<a href="/pdf/2311.00986" title="Download PDF">pdf</a>, <a href="/format/2311.00986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M&amp;M3D: Multi-Dataset Training and Efficient Network for Multi-view 3D  Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this research, I proposed a network structure for multi-view 3D object
detection using camera-only data and a Bird's-Eye-View map. My work is based on
a current key challenge domain adaptation and visual data transfer. Although
many excellent camera-only 3D object detection has been continuously proposed,
many research work risk dramatic performance drop when the networks are trained
on the source domain but tested on a different target domain. Then I found it
is very surprising that predictions on bounding boxes and classes are still
replied to on 2D networks. Based on the domain gap assumption on various 3D
datasets, I found they still shared a similar data extraction on the same BEV
map size and camera data transfer. Therefore, to analyze the domain gap
influence on the current method and to make good use of 3D space information
among the dataset and the real world, I proposed a transfer learning method and
Transformer construction to study the 3D object detection on NuScenes-mini and
Lyft. Through multi-dataset training and a detection head from the Transformer,
the network demonstrated good data migration performance and efficient
detection performance by using 3D anchor query and 3D positional information.
Relying on only a small amount of source data and the existing large model
pre-training weights, the efficient network manages to achieve competitive
results on the new target domain. Moreover, my study utilizes 3D information as
available semantic information and 2D multi-view image features blending into
the visual-language transfer design. In the final 3D anchor box prediction and
object classification, my network achieved good results on standard metrics of
3D object detection, which differs from dataset-specific models on each
training domain without any fine-tuning.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00987" title="Abstract">arXiv:2311.00987</a> [<a href="/pdf/2311.00987" title="Download PDF">pdf</a>, <a href="/format/2311.00987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CML-MOTS: Collaborative Multi-task Learning for Multi-Object Tracking  and Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yiming Cui</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+C">Cheng Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dongfang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The advancement of computer vision has pushed visual analysis tasks from
still images to the video domain. In recent years, video instance segmentation,
which aims to track and segment multiple objects in video frames, has drawn
much attention for its potential applications in various emerging areas such as
autonomous driving, intelligent transportation, and smart retail. In this
paper, we propose an effective framework for instance-level visual analysis on
video frames, which can simultaneously conduct object detection, instance
segmentation, and multi-object tracking. The core idea of our method is
collaborative multi-task learning which is achieved by a novel structure, named
associative connections among detection, segmentation, and tracking task heads
in an end-to-end learnable CNN. These additional connections allow information
propagation across multiple related tasks, so as to benefit these tasks
simultaneously. We evaluate the proposed method extensively on KITTI MOTS and
MOTS Challenge datasets and obtain quite encouraging results.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00988" title="Abstract">arXiv:2311.00988</a> [<a href="/pdf/2311.00988" title="Download PDF">pdf</a>, <a href="/format/2311.00988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Augmented Reality to Assess and Modify Mobile Manipulator Surface  Repair Plans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Regal%2C+F">Frank Regal</a>, 
<a href="/search/cs?searchtype=author&query=Swanbeck%2C+S">Steven Swanbeck</a>, 
<a href="/search/cs?searchtype=author&query=Parra%2C+F">Fabian Parra</a>, 
<a href="/search/cs?searchtype=author&query=Rosenbaum%2C+J">Jared Rosenbaum</a>, 
<a href="/search/cs?searchtype=author&query=Pryor%2C+M">Mitch Pryor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Winning Paper (2nd Prize) at The Second International Horizons of an Extended Robotics Reality (XR-ROB) Workshop - IEEE IROS 2023 | Workshop Website: <a href="https://sites.google.com/view/xr-robotics-iros2023/home?authuser=0">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Industrial robotics are redefining inspection and maintenance routines across
multiple sectors, enhancing safety, efficiency, and environmental
sustainability. In outdoor industrial facilities, it is crucial to inspect and
repair complex surfaces affected by corrosion. To address this challenge,
mobile manipulators have been developed to navigate these facilities, identify
corroded areas, and apply protective coatings. However, given that this
technology is still in its infancy and the consequences of improperly coating
essential equipment can be significant, human oversight is necessary to review
the robot's corrosion identification and repair plan. We present a practical
and scalable Augmented Reality (AR)-based system designed to empower
non-experts to visualize, modify, and approve robot-generated surface corrosion
repair plans in real-time. Built upon an AR-based human-robot interaction
framework, Augmented Robot Environment (AugRE), we developed a comprehensive AR
application module called Situational Task Accept and Repair (STAR). STAR
allows users to examine identified corrosion images, point cloud data, and
robot navigation objectives overlaid on the physical environment within these
industrial environments. Users are able to additionally make adjustments to the
robot repair plan in real-time using interactive holographic volumes, excluding
critical nearby equipment that might be at risk of coating overspray. We
demonstrate the entire system using a Microsoft HoloLens 2 and a dual-arm
mobile manipulator. Our future research will focus on evaluating user
experience, system robustness, and real-world validation.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00990" title="Abstract">arXiv:2311.00990</a> [<a href="/pdf/2311.00990" title="Download PDF">pdf</a>, <a href="/format/2311.00990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VideoDreamer: Customized Multi-Subject Text-to-Video Generation with  Disen-Mix Finetuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+G">Guanning Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yipeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuwei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+F">Feilin Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenwu Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Customized text-to-video generation aims to generate text-guided videos with
customized user-given subjects, which has gained increasing attention recently.
However, existing works are primarily limited to generating videos for a single
subject, leaving the more challenging problem of customized multi-subject
text-to-video generation largely unexplored. In this paper, we fill this gap
and propose a novel VideoDreamer framework. VideoDreamer can generate
temporally consistent text-guided videos that faithfully preserve the visual
features of the given multiple subjects. Specifically, VideoDreamer leverages
the pretrained Stable Diffusion with latent-code motion dynamics and temporal
cross-frame attention as the base video generator. The video generator is
further customized for the given multiple subjects by the proposed Disen-Mix
Finetuning and Human-in-the-Loop Re-finetuning strategy, which can tackle the
attribute binding problem of multi-subject generation. We also introduce
MultiStudioBench, a benchmark for evaluating customized multi-subject
text-to-video generation models. Extensive experiments demonstrate the
remarkable ability of VideoDreamer to generate videos with new content such as
new events and backgrounds, tailored to the customized multiple subjects. Our
project page is available at https://videodreamer23.github.io/.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00991" title="Abstract">arXiv:2311.00991</a> [<a href="/pdf/2311.00991" title="Download PDF">pdf</a>, <a href="/format/2311.00991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IR-UWB Radar-based Situational Awareness System for  Smartphone-Distracted Pedestrians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ppallan%2C+J+M">Jamsheed Manja Ppallan</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+R">Ruchi Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Damam%2C+Y">Yellappa Damam</a>, 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+V+N">Vijay Narayan Tiwari</a>, 
<a href="/search/cs?searchtype=author&query=Arunachalam%2C+K">Karthikeyan Arunachalam</a>, 
<a href="/search/cs?searchtype=author&query=Ray%2C+A">Antariksha Ray</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the widespread adoption of smartphones, ensuring pedestrian safety on
roads has become a critical concern due to smartphone distraction. This paper
proposes a novel and real-time assistance system called UWB-assisted Safe Walk
(UASW) for obstacle detection and warns users about real-time situations. The
proposed method leverages Impulse Radio Ultra-Wideband (IR-UWB) radar embedded
in the smartphone, which provides excellent range resolution and high noise
resilience using short pulses. We implemented UASW specifically for Android
smartphones with IR-UWB connectivity. The framework uses complex Channel
Impulse Response (CIR) data to integrate rule-based obstacle detection with
artificial neural network (ANN) based obstacle classification. The performance
of the proposed UASW system is analyzed using real-time collected data. The
results show that the proposed system achieves an obstacle detection accuracy
of up to 97% and obstacle classification accuracy of up to 95% with an
inference delay of 26.8 ms. The results highlight the effectiveness of UASW in
assisting smartphone-distracted pedestrians and improving their situational
awareness.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00992" title="Abstract">arXiv:2311.00992</a> [<a href="/pdf/2311.00992" title="Download PDF">pdf</a>, <a href="/ps/2311.00992" title="Download PostScript">ps</a>, <a href="/format/2311.00992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing random $r$-orthogonal Latin squares
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bereg%2C+S">Sergey Bereg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">Two Latin squares of order $n$ are $r$-orthogonal if, when superimposed,
there are exactly $r$ distinct ordered pairs. The spectrum of all values of $r$
for Latin squares of order $n$ is known. A Latin square $A$ of order $n$ is
$r$-self-orthogonal if $A$ and its transpose are $r$-orthogonal. The spectrum
of all values of $r$ is known for all orders $n\ne 14$. We develop randomized
algorithms for computing pairs of $r$-orthogonal Latin squares of order $n$ and
algorithms for computing $r$-self-orthogonal Latin squares of order $n$.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00993" title="Abstract">arXiv:2311.00993</a> [<a href="/pdf/2311.00993" title="Download PDF">pdf</a>, <a href="/format/2311.00993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Probabilistic Forecasting in Retail with Gradient Boosted  Trees: A Practitioner&#x27;s Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+X">Xueying Long</a>, 
<a href="/search/cs?searchtype=author&query=Bui%2C+Q">Quang Bui</a>, 
<a href="/search/cs?searchtype=author&query=Oktavian%2C+G">Grady Oktavian</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+D+F">Daniel F. Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Bergmeir%2C+C">Christoph Bergmeir</a>, 
<a href="/search/cs?searchtype=author&query=Godahewa%2C+R">Rakshitha Godahewa</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S+P">Seong Per Lee</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kaifeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Condylis%2C+P">Paul Condylis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The recent M5 competition has advanced the state-of-the-art in retail
forecasting. However, we notice important differences between the competition
challenge and the challenges we face in a large e-commerce company. The
datasets in our scenario are larger (hundreds of thousands of time series), and
e-commerce can afford to have a larger assortment than brick-and-mortar
retailers, leading to more intermittent data. To scale to larger dataset sizes
with feasible computational effort, firstly, we investigate a two-layer
hierarchy and propose a top-down approach to forecasting at an aggregated level
with less amount of series and intermittency, and then disaggregating to obtain
the decision-level forecasts. Probabilistic forecasts are generated under
distributional assumptions. Secondly, direct training at the lower level with
subsamples can also be an alternative way of scaling. Performance of modelling
with subsets is evaluated with the main dataset. Apart from a proprietary
dataset, the proposed scalable methods are evaluated using the Favorita dataset
and the M5 dataset. We are able to show the differences in characteristics of
the e-commerce and brick-and-mortar retail datasets. Notably, our top-down
forecasting framework enters the top 50 of the original M5 competition, even
with models trained at a higher level under a much simpler setting.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00994" title="Abstract">arXiv:2311.00994</a> [<a href="/pdf/2311.00994" title="Download PDF">pdf</a>, <a href="/format/2311.00994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LaughTalk: Expressive 3D Talking Head Generation with Laughter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sung-Bin%2C+K">Kim Sung-Bin</a>, 
<a href="/search/cs?searchtype=author&query=Hyun%2C+L">Lee Hyun</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+D+H">Da Hye Hong</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+S">Suekyeong Nam</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+J">Janghoon Ju</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+T">Tae-Hyun Oh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Laughter is a unique expression, essential to affirmative social interactions
of humans. Although current 3D talking head generation methods produce
convincing verbal articulations, they often fail to capture the vitality and
subtleties of laughter and smiles despite their importance in social context.
In this paper, we introduce a novel task to generate 3D talking heads capable
of both articulate speech and authentic laughter. Our newly curated dataset
comprises 2D laughing videos paired with pseudo-annotated and human-validated
3D FLAME parameters and vertices. Given our proposed dataset, we present a
strong baseline with a two-stage training scheme: the model first learns to
talk and then acquires the ability to express laughter. Extensive experiments
demonstrate that our method performs favorably compared to existing approaches
in both talking head generation and expressing laughter signals. We further
explore potential applications on top of our proposed method for rigging
realistic avatars.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00995" title="Abstract">arXiv:2311.00995</a> [<a href="/pdf/2311.00995" title="Download PDF">pdf</a>, <a href="/ps/2311.00995" title="Download PostScript">ps</a>, <a href="/format/2311.00995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Chronological Survey of Theoretical Advancements in Generative  Adversarial Networks for Computer Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+H">Hrishikesh Sharma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Generative Adversarial Networks (GANs) have been workhorse generative models
for last many years, especially in the research field of computer vision.
Accordingly, there have been many significant advancements in the theory and
application of GAN models, which are notoriously hard to train, but produce
good results if trained well. There have been many a surveys on GANs,
organizing the vast GAN literature from various focus and perspectives.
However, none of the surveys brings out the important chronological aspect: how
the multiple challenges of employing GAN models were solved one-by-one over
time, across multiple landmark research works. This survey intends to bridge
that gap and present some of the landmark research works on the theory and
application of GANs, in chronological order.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00998" title="Abstract">arXiv:2311.00998</a> [<a href="/pdf/2311.00998" title="Download PDF">pdf</a>, <a href="/format/2311.00998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Replicable Benchmarking of Neural Machine Translation (NMT) on  Low-Resource Local Languages in Indonesia
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Susanto%2C+L">Lucky Susanto</a>, 
<a href="/search/cs?searchtype=author&query=Diandaru%2C+R">Ryandito Diandaru</a>, 
<a href="/search/cs?searchtype=author&query=Krisnadhi%2C+A">Adila Krisnadhi</a>, 
<a href="/search/cs?searchtype=author&query=Purwarianti%2C+A">Ayu Purwarianti</a>, 
<a href="/search/cs?searchtype=author&query=Wijaya%2C+D">Derry Wijaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted on SEALP 2023, Workshop in IJCNLP-AACL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Neural machine translation (NMT) for low-resource local languages in
Indonesia faces significant challenges, including the need for a representative
benchmark and limited data availability. This work addresses these challenges
by comprehensively analyzing training NMT systems for four low-resource local
languages in Indonesia: Javanese, Sundanese, Minangkabau, and Balinese. Our
study encompasses various training approaches, paradigms, data sizes, and a
preliminary study into using large language models for synthetic low-resource
languages parallel data generation. We reveal specific trends and insights into
practical strategies for low-resource language translation. Our research
demonstrates that despite limited computational resources and textual data,
several of our NMT systems achieve competitive performances, rivaling the
translation quality of zero-shot gpt-3.5-turbo. These findings significantly
advance NMT for low-resource languages, offering valuable guidance for
researchers in similar contexts.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01001" title="Abstract">arXiv:2311.01001</a> [<a href="/pdf/2311.01001" title="Download PDF">pdf</a>, <a href="/format/2311.01001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fully Quantized Always-on Face Detector Considering Mobile Image Sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Haechang Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+W">Wongi Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Ryu%2C+D">Dongil Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Je%2C+H">Hyunwoo Je</a>, 
<a href="/search/cs?searchtype=author&query=No%2C+A">Albert No</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kijeong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Chun%2C+S+Y">Se Young Chun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023 Workshop on Low-Bit Quantized Neural Networks (LBQNN), Oral
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite significant research on lightweight deep neural networks (DNNs)
designed for edge devices, the current face detectors do not fully meet the
requirements for "intelligent" CMOS image sensors (iCISs) integrated with
embedded DNNs. These sensors are essential in various practical applications,
such as energy-efficient mobile phones and surveillance systems with always-on
capabilities. One noteworthy limitation is the absence of suitable face
detectors for the always-on scenario, a crucial aspect of image sensor-level
applications. These detectors must operate directly with sensor RAW data before
the image signal processor (ISP) takes over. This gap poses a significant
challenge in achieving optimal performance in such scenarios. Further research
and development are necessary to bridge this gap and fully leverage the
potential of iCIS applications. In this study, we aim to bridge the gap by
exploring extremely low-bit lightweight face detectors, focusing on the
always-on face detection scenario for mobile image sensor applications. To
achieve this, our proposed model utilizes sensor-aware synthetic RAW inputs,
simulating always-on face detection processed "before" the ISP chain. Our
approach employs ternary (-1, 0, 1) weights for potential implementations in
image sensors, resulting in a relatively simple network architecture with
shallow layers and extremely low-bitwidth. Our method demonstrates reasonable
face detection performance and excellent efficiency in simulation studies,
offering promising possibilities for practical always-on face detectors in
real-world applications.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01002" title="Abstract">arXiv:2311.01002</a> [<a href="/pdf/2311.01002" title="Download PDF">pdf</a>, <a href="/format/2311.01002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Data Pruning under Label Noise via Maximizing Re-labeling  Accuracy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+D">Dongmin Park</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Seola Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Doyoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hwanjun Song</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jae-Gil Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Data pruning, which aims to downsize a large training set into a small
informative subset, is crucial for reducing the enormous computational costs of
modern deep learning. Though large-scale data collections invariably contain
annotation noise and numerous robust learning methods have been developed, data
pruning for the noise-robust learning scenario has received little attention.
With state-of-the-art Re-labeling methods that self-correct erroneous labels
while training, it is challenging to identify which subset induces the most
accurate re-labeling of erroneous labels in the entire training set. In this
paper, we formalize the problem of data pruning with re-labeling. We first show
that the likelihood of a training example being correctly re-labeled is
proportional to the prediction confidence of its neighborhood in the subset.
Therefore, we propose a novel data pruning algorithm, Prune4Rel, that finds a
subset maximizing the total neighborhood confidence of all training examples,
thereby maximizing the re-labeling accuracy and generalization performance.
Extensive experiments on four real and one synthetic noisy datasets show that
\algname{} outperforms the baselines with Re-labeling models by up to 9.1% as
well as those with a standard model by up to 21.6%.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01003" title="Abstract">arXiv:2311.01003</a> [<a href="/pdf/2311.01003" title="Download PDF">pdf</a>, <a href="/format/2311.01003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimum Snap Trajectory Generation and Control for an Under-actuated  Flapping Wing Aerial Vehicle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Qian%2C+C">Chen Qian</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+R">Rui Chen</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+P">Peiyao Shen</a>, 
<a href="/search/eess?searchtype=author&query=Fang%2C+Y">Yongchun Fang</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+J">Jifu Yan</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+T">Tiefeng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Minimum Snap Trajectory Generation and Control for an Under-actuated Flapping
Wing Aerial VehicleThis paper presents both the trajectory generation and
tracking control strategies for an underactuated flapping wing aerial vehicle
(FWAV). First, the FWAV dynamics is analyzed in a practical perspective. Then,
based on these analyses, we demonstrate the differential flatness of the FWAV
system, and develop a general-purpose trajectory generation strategy.
Subsequently, the trajectory tracking controller is developed with the help of
robust control and switch control techniques. After that, the overall system
asymptotic stability is guaranteed by Lyapunov stability analysis. To make the
controller applicable in real flight, we also provide several instructions.
Finally, a series of experiment results manifest the successful implementation
of the proposed trajectory generation strategy and tracking control strategy.
This work firstly achieves the closed-loop integration of trajectory generation
and control for real 3-dimensional flight of an underactuated FWAV to a
practical level.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01004" title="Abstract">arXiv:2311.01004</a> [<a href="/pdf/2311.01004" title="Download PDF">pdf</a>, <a href="/format/2311.01004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sam-Guided Enhanced Fine-Grained Encoding with Mixed Semantic Learning  for Medical Image Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gaoang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Benlu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+W">Weijie Liang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yizhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xuechen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guanhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shiyan Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the development of multimodality and large language models, the deep
learning-based technique for medical image captioning holds the potential to
offer valuable diagnostic recommendations. However, current generic text and
image pre-trained models do not yield satisfactory results when it comes to
describing intricate details within medical images. In this paper, we present a
novel medical image captioning method guided by the segment anything model
(SAM) to enable enhanced encoding with both general and detailed feature
extraction. In addition, our approach employs a distinctive pre-training
strategy with mixed semantic learning to simultaneously capture both the
overall information and finer details within medical images. We demonstrate the
effectiveness of this approach, as it outperforms the pre-trained BLIP2 model
on various evaluation metrics for generating descriptions of medical images.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01007" title="Abstract">arXiv:2311.01007</a> [<a href="/pdf/2311.01007" title="Download PDF">pdf</a>, <a href="/format/2311.01007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effective Human-AI Teams via Learned Natural Language Rules and  Onboarding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mozannar%2C+H">Hussein Mozannar</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+J">Jimin J Lee</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+D">Dennis Wei</a>, 
<a href="/search/cs?searchtype=author&query=Sattigeri%2C+P">Prasanna Sattigeri</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Subhro Das</a>, 
<a href="/search/cs?searchtype=author&query=Sontag%2C+D">David Sontag</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Spotlight
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">People are relying on AI agents to assist them with various tasks. The human
must know when to rely on the agent, collaborate with the agent, or ignore its
suggestions. In this work, we propose to learn rules grounded in data regions
and described in natural language that illustrate how the human should
collaborate with the AI. Our novel region discovery algorithm finds local
regions in the data as neighborhoods in an embedding space that corrects the
human prior. Each region is then described using an iterative and contrastive
procedure where a large language model describes the region. We then teach
these rules to the human via an onboarding stage. Through user studies on
object detection and question-answering tasks, we show that our method can lead
to more accurate human-AI teams. We also evaluate our region discovery and
description algorithms separately.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01008" title="Abstract">arXiv:2311.01008</a> [<a href="/pdf/2311.01008" title="Download PDF">pdf</a>, <a href="/ps/2311.01008" title="Download PostScript">ps</a>, <a href="/format/2311.01008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Linear Complementary Pairs of Algebraic Geometry Codes over Finite  Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhowmick%2C+S">Sanjit Bhowmick</a>, 
<a href="/search/cs?searchtype=author&query=Dalai%2C+D+K">Deepak Kumar Dalai</a>, 
<a href="/search/cs?searchtype=author&query=Mesnager%2C+S">Sihem Mesnager</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Linear complementary dual (LCD) codes and linear complementary pairs (LCP) of
codes have been proposed for new applications as countermeasures against
side-channel attacks (SCA) and fault injection attacks (FIA) in the context of
direct sum masking (DSM). The countermeasure against FIA may lead to a
vulnerability for SCA when the whole algorithm needs to be masked (in
environments like smart cards). This led to a variant of the LCD and LCP
problems, where several results have been obtained intensively for LCD codes,
but only partial results have been derived for LCP codes. Given the gap between
the thin results and their particular importance, this paper aims to reduce
this by further studying the LCP of codes in special code families and,
precisely, the characterisation and construction mechanism of LCP codes of
algebraic geometry codes over finite fields. Notably, we propose constructing
explicit LCP of codes from elliptic curves. Besides, we also study the security
parameters of the derived LCP of codes $(\mathcal{C}, \mathcal{D})$ (notably
for cyclic codes), which are given by the minimum distances $d(\mathcal{C})$
and $d(\mathcal{D}^\perp)$. Further, we show that for LCP algebraic geometry
codes $(\mathcal{C},\mathcal{D})$, the dual code $\mathcal{C}^\perp$ is
equivalent to $\mathcal{D}$ under some specific conditions we exhibit. Finally,
we investigate whether MDS LCP of algebraic geometry codes exist (MDS codes are
among the most important in coding theory due to their theoretical significance
and practical interests). Construction schemes for obtaining LCD codes from any
algebraic curve were given in 2018 by Mesnager, Tang and Qi in [``Complementary
dual algebraic geometry codes", IEEE Trans. Inform Theory, vol. 64(4),
2390--3297, 2018]. To our knowledge, it is the first time LCP of algebraic
geometry codes has been studied.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01009" title="Abstract">arXiv:2311.01009</a> [<a href="/pdf/2311.01009" title="Download PDF">pdf</a>, <a href="/format/2311.01009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revamping AI Models in Dermatology: Overcoming Critical Challenges for  Enhanced Skin Lesion Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehta%2C+D">Deval Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Betz-Stablein%2C+B">Brigid Betz-Stablein</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+D">Toan D Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Gal%2C+Y">Yaniv Gal</a>, 
<a href="/search/cs?searchtype=author&query=Bowling%2C+A">Adrian Bowling</a>, 
<a href="/search/cs?searchtype=author&query=Haskett%2C+M">Martin Haskett</a>, 
<a href="/search/cs?searchtype=author&query=Sashindranath%2C+M">Maithili Sashindranath</a>, 
<a href="/search/cs?searchtype=author&query=Bonnington%2C+P">Paul Bonnington</a>, 
<a href="/search/cs?searchtype=author&query=Mar%2C+V">Victoria Mar</a>, 
<a href="/search/cs?searchtype=author&query=Soyer%2C+H+P">H Peter Soyer</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Z">Zongyuan Ge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The surge in developing deep learning models for diagnosing skin lesions
through image analysis is notable, yet their clinical black faces challenges.
Current dermatology AI models have limitations: limited number of possible
diagnostic outputs, lack of real-world testing on uncommon skin lesions,
inability to detect out-of-distribution images, and over-reliance on
dermoscopic images. To address these, we present an All-In-One
\textbf{H}ierarchical-\textbf{O}ut of Distribution-\textbf{C}linical Triage
(HOT) model. For a clinical image, our model generates three outputs: a
hierarchical prediction, an alert for out-of-distribution images, and a
recommendation for dermoscopy if clinical image alone is insufficient for
diagnosis. When the recommendation is pursued, it integrates both clinical and
dermoscopic images to deliver final diagnosis. Extensive experiments on a
representative cutaneous lesion dataset demonstrate the effectiveness and
synergy of each component within our framework. Our versatile model provides
valuable decision support for lesion diagnosis and sets a promising precedent
for medical AI applications.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01010" title="Abstract">arXiv:2311.01010</a> [<a href="/pdf/2311.01010" title="Download PDF">pdf</a>, <a href="/format/2311.01010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Unified Perspective For Fast Shapley Value Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Borui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+B">Baotong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Wenzhao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiwen Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Shapley values have emerged as a widely accepted and trustworthy tool,
grounded in theoretical axioms, for addressing challenges posed by black-box
models like deep neural networks. However, computing Shapley values encounters
exponential complexity in the number of features. Various approaches, including
ApproSemivalue, KernelSHAP, and FastSHAP, have been explored to expedite the
computation. We analyze the consistency of existing works and conclude that
stochastic estimators can be unified as the linear transformation of importance
sampling of feature subsets. Based on this, we investigate the possibility of
designing simple amortized estimators and propose a straightforward and
efficient one, SimSHAP, by eliminating redundant techniques. Extensive
experiments conducted on tabular and image datasets validate the effectiveness
of our SimSHAP, which significantly accelerates the computation of accurate
Shapley values.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01011" title="Abstract">arXiv:2311.01011</a> [<a href="/pdf/2311.01011" title="Download PDF">pdf</a>, <a href="/format/2311.01011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Toyer%2C+S">Sam Toyer</a>, 
<a href="/search/cs?searchtype=author&query=Watkins%2C+O">Olivia Watkins</a>, 
<a href="/search/cs?searchtype=author&query=Mendes%2C+E+A">Ethan Adrian Mendes</a>, 
<a href="/search/cs?searchtype=author&query=Svegliato%2C+J">Justin Svegliato</a>, 
<a href="/search/cs?searchtype=author&query=Bailey%2C+L">Luke Bailey</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tiffany Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ong%2C+I">Isaac Ong</a>, 
<a href="/search/cs?searchtype=author&query=Elmaaroufi%2C+K">Karim Elmaaroufi</a>, 
<a href="/search/cs?searchtype=author&query=Abbeel%2C+P">Pieter Abbeel</a>, 
<a href="/search/cs?searchtype=author&query=Darrell%2C+T">Trevor Darrell</a>, 
<a href="/search/cs?searchtype=author&query=Ritter%2C+A">Alan Ritter</a>, 
<a href="/search/cs?searchtype=author&query=Russell%2C+S">Stuart Russell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">While Large Language Models (LLMs) are increasingly being used in real-world
applications, they remain vulnerable to prompt injection attacks: malicious
third party prompts that subvert the intent of the system designer. To help
researchers study this problem, we present a dataset of over 126,000 prompt
injection attacks and 46,000 prompt-based "defenses" against prompt injection,
all created by players of an online game called Tensor Trust. To the best of
our knowledge, this is currently the largest dataset of human-generated
adversarial examples for instruction-following LLMs. The attacks in our dataset
have a lot of easily interpretable stucture, and shed light on the weaknesses
of LLMs. We also use the dataset to create a benchmark for resistance to two
types of prompt injection, which we refer to as prompt extraction and prompt
hijacking. Our benchmark results show that many models are vulnerable to the
attack strategies in the Tensor Trust dataset. Furthermore, we show that some
attack strategies from the dataset generalize to deployed LLM-based
applications, even though they have a very different set of constraints to the
game. We release all data and source code at https://tensortrust.ai/paper
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01012" title="Abstract">arXiv:2311.01012</a> [<a href="/pdf/2311.01012" title="Download PDF">pdf</a>, <a href="/format/2311.01012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COPAL-ID: Indonesian Language Reasoning with Local Culture and Nuances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wibowo%2C+H+A">Haryo Akbarianto Wibowo</a>, 
<a href="/search/cs?searchtype=author&query=Fuadi%2C+E+H">Erland Hilman Fuadi</a>, 
<a href="/search/cs?searchtype=author&query=Nityasya%2C+M+N">Made Nindyatama Nityasya</a>, 
<a href="/search/cs?searchtype=author&query=Prasojo%2C+R+E">Radityo Eko Prasojo</a>, 
<a href="/search/cs?searchtype=author&query=Aji%2C+A+F">Alham Fikri Aji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present publicly available COPAL-ID, a novel Indonesian language common
sense reasoning dataset. Unlike the previous Indonesian COPA dataset
(XCOPA-ID), COPAL-ID incorporates Indonesian local and cultural nuances, and
therefore, provides a more natural portrayal of day-to-day causal reasoning
within the Indonesian cultural sphere. Professionally written by natives from
scratch, COPAL-ID is more fluent and free from awkward phrases, unlike the
translated XCOPA-ID. In addition, we present COPAL-ID in both standard
Indonesian and in Jakartan Indonesian--a dialect commonly used in daily
conversation. COPAL-ID poses a greater challenge for existing open-sourced and
closed state-of-the-art multilingual language models, yet is trivially easy for
humans. Our findings suggest that even the current best open-source,
multilingual model struggles to perform well, achieving 65.47% accuracy on
COPAL-ID, significantly lower than on the culturally-devoid XCOPA-ID (79.40%).
Despite GPT-4's impressive score, it suffers the same performance degradation
compared to its XCOPA-ID score, and it still falls short of human performance.
This shows that these language models are still way behind in comprehending the
local nuances of Indonesian.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01013" title="Abstract">arXiv:2311.01013</a> [<a href="/pdf/2311.01013" title="Download PDF">pdf</a>, <a href="/format/2311.01013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation Measures of Individual Item Fairness for Recommender Systems:  A Critical Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rampisela%2C+T+V">Theresia Veronika Rampisela</a>, 
<a href="/search/cs?searchtype=author&query=Maistro%2C+M">Maria Maistro</a>, 
<a href="/search/cs?searchtype=author&query=Ruotsalo%2C+T">Tuukka Ruotsalo</a>, 
<a href="/search/cs?searchtype=author&query=Lioma%2C+C">Christina Lioma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ACM Transactions on Recommender Systems (TORS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Fairness is an emerging and challenging topic in recommender systems. In
recent years, various ways of evaluating and therefore improving fairness have
emerged. In this study, we examine existing evaluation measures of fairness in
recommender systems. Specifically, we focus solely on exposure-based fairness
measures of individual items that aim to quantify the disparity in how
individual items are recommended to users, separate from item relevance to
users. We gather all such measures and we critically analyse their theoretical
properties. We identify a series of limitations in each of them, which
collectively may render the affected measures hard or impossible to interpret,
to compute, or to use for comparing recommendations. We resolve these
limitations by redefining or correcting the affected measures, or we argue why
certain limitations cannot be resolved. We further perform a comprehensive
empirical analysis of both the original and our corrected versions of these
fairness measures, using real-world and synthetic datasets. Our analysis
provides novel insights into the relationship between measures based on
different fairness concepts, and different levels of measure sensitivity and
strictness. We conclude with practical suggestions of which fairness measures
should be used and when. Our code is publicly available. To our knowledge, this
is the first critical comparison of individual item fairness measures in
recommender systems.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01015" title="Abstract">arXiv:2311.01015</a> [<a href="/pdf/2311.01015" title="Download PDF">pdf</a>, <a href="/format/2311.01015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Act As You Wish: Fine-Grained Control of Motion Diffusion Model with  Hierarchical Semantic Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+P">Peng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yanbo Fan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhongqian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Li Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Most text-driven human motion generation methods employ sequential modeling
approaches, e.g., transformer, to extract sentence-level text representations
automatically and implicitly for human motion synthesis. However, these compact
text representations may overemphasize the action names at the expense of other
important properties and lack fine-grained details to guide the synthesis of
subtly distinct motion. In this paper, we propose hierarchical semantic graphs
for fine-grained control over motion generation. Specifically, we disentangle
motion descriptions into hierarchical semantic graphs including three levels of
motions, actions, and specifics. Such global-to-local structures facilitate a
comprehensive understanding of motion description and fine-grained control of
motion generation. Correspondingly, to leverage the coarse-to-fine topology of
hierarchical semantic graphs, we decompose the text-to-motion diffusion process
into three semantic levels, which correspond to capturing the overall motion,
local actions, and action specifics. Extensive experiments on two benchmark
human motion datasets, including HumanML3D and KIT, with superior performances,
justify the efficacy of our method. More encouragingly, by modifying the edge
weights of hierarchical semantic graphs, our method can continuously refine the
generated motion, which may have a far-reaching impact on the community. Code
and pre-training weights are available at
https://github.com/jpthu17/GraphMotion.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01016" title="Abstract">arXiv:2311.01016</a> [<a href="/pdf/2311.01016" title="Download PDF">pdf</a>, <a href="/format/2311.01016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Analytics for Efficient Image Exploration and User-Guided Image  Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiran Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Aboagye%2C+P">Prince Aboagye</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+M">Michael Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+K">Kwan-Liu Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advancements in pre-trained large-scale language-image models have
ushered in a new era of visual comprehension, offering a significant leap
forward. These breakthroughs have proven particularly instrumental in
addressing long-standing challenges that were previously daunting. Leveraging
these innovative techniques, this paper tackles two well-known issues within
the realm of visual analytics: (1) the efficient exploration of large-scale
image datasets and identification of potential data biases within them; (2) the
evaluation of image captions and steering of their generation process. On the
one hand, by visually examining the captions automatically generated from
language-image models for an image dataset, we gain deeper insights into the
semantic underpinnings of the visual contents, unearthing data biases that may
be entrenched within the dataset. On the other hand, by depicting the
association between visual contents and textual captions, we expose the
weaknesses of pre-trained language-image models in their captioning capability
and propose an interactive interface to steer caption generation. The two parts
have been coalesced into a coordinated visual analytics system, fostering
mutual enrichment of visual and textual elements. We validate the effectiveness
of the system with domain practitioners through concrete case studies with
large-scale image datasets.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01017" title="Abstract">arXiv:2311.01017</a> [<a href="/pdf/2311.01017" title="Download PDF">pdf</a>, <a href="/format/2311.01017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Unsupervised World Models for Autonomous Driving via Discrete  Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lunjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yuwen Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ze Yang</a>, 
<a href="/search/cs?searchtype=author&query=Casas%2C+S">Sergio Casas</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Rui Hu</a>, 
<a href="/search/cs?searchtype=author&query=Urtasun%2C+R">Raquel Urtasun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Learning world models can teach an agent how the world works in an
unsupervised manner. Even though it can be viewed as a special case of sequence
modeling, progress for scaling world models on robotic applications such as
autonomous driving has been somewhat less rapid than scaling language models
with Generative Pre-trained Transformers (GPT). We identify two reasons as
major bottlenecks: dealing with complex and unstructured observation space, and
having a scalable generative model. Consequently, we propose a novel world
modeling approach that first tokenizes sensor observations with VQVAE, then
predicts the future via discrete diffusion. To efficiently decode and denoise
tokens in parallel, we recast Masked Generative Image Transformer into the
discrete diffusion framework with a few simple changes, resulting in notable
improvement. When applied to learning world models on point cloud observations,
our model reduces prior SOTA Chamfer distance by more than 65% for 1s
prediction, and more than 50% for 3s prediction, across NuScenes, KITTI
Odometry, and Argoverse2 datasets. Our results demonstrate that discrete
diffusion on tokenized agent experience can unlock the power of GPT-like
unsupervised learning for robotic agents.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01018" title="Abstract">arXiv:2311.01018</a> [<a href="/pdf/2311.01018" title="Download PDF">pdf</a>, <a href="/format/2311.01018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expanding Expressiveness of Diffusion Models with Limited Data via  Self-Distillation based Fine-Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hur%2C+J">Jiwan Hur</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jaehyun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+G">Gyojin Han</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dong-Jae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Junmo Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Training diffusion models on limited datasets poses challenges in terms of
limited generation capacity and expressiveness, leading to unsatisfactory
results in various downstream tasks utilizing pretrained diffusion models, such
as domain translation and text-guided image manipulation. In this paper, we
propose Self-Distillation for Fine-Tuning diffusion models (SDFT), a
methodology to address these challenges by leveraging diverse features from
diffusion models pretrained on large source datasets. SDFT distills more
general features (shape, colors, etc.) and less domain-specific features
(texture, fine details, etc) from the source model, allowing successful
knowledge transfer without disturbing the training process on target datasets.
The proposed method is not constrained by the specific architecture of the
model and thus can be generally adopted to existing frameworks. Experimental
results demonstrate that SDFT enhances the expressiveness of the diffusion
model with limited datasets, resulting in improved generation capabilities
across various downstream tasks.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01020" title="Abstract">arXiv:2311.01020</a> [<a href="/pdf/2311.01020" title="Download PDF">pdf</a>, <a href="/format/2311.01020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Concerns of Developers When Using GitHub Copilot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Peng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Beiqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zengyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+A">Aakash Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Shahin%2C+M">Mojtaba Shahin</a>, 
<a href="/search/cs?searchtype=author&query=Waseem%2C+M">Muhammad Waseem</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">With the recent advancement of Artificial Intelligence (AI) and the emergence
of Large Language Models (LLMs), AI-based code generation tools have achieved
significant progress and become a practical solution for software development.
GitHub Copilot, referred to as AI pair programmer, utilizes machine learning
models that are trained on a large corpus of code snippets to generate code
suggestions or auto-complete code using natural language processing. Despite
its popularity, there is little empirical evidence on the actual experiences of
software developers who work with Copilot. To this end, we conducted an
empirical study to understand the issues and challenges that developers face
when using Copilot in practice, as well as their underlying causes and
potential solutions. We collected data from 476 GitHub issues, 706 GitHub
discussions, and 184 Stack Overflow posts, and identified the issues, causes
that trigger the issues, and solutions that resolve the issues when using
Copilot. Our results reveal that (1) Usage Issue and Compatibility Issue are
the most common problems faced by Copilot users, (2) Copilot Internal Issue,
Network Connection Issue, and Editor/IDE Compatibility Issue are identified as
the most frequent causes, and (3) Bug Fixed by Copilot, Modify
Configuration/Setting, and Use Suitable Version are the predominant solutions.
Based on the results, we delve into the main challenges users encounter when
implementing Copilot in practical development, the possible impact of Copilot
on the coding process, aspects in which Copilot can be further enhanced, and
potential new features desired by Copilot users.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01022" title="Abstract">arXiv:2311.01022</a> [<a href="/pdf/2311.01022" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuroWrite: Predictive Handwritten Digit Classification using Deep  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Asish%2C+K">Kottakota Asish</a>, 
<a href="/search/cs?searchtype=author&query=Teja%2C+P+S">P. Sarath Teja</a>, 
<a href="/search/cs?searchtype=author&query=Chander%2C+R+K">R. Kishan Chander</a>, 
<a href="/search/cs?searchtype=author&query=Hema%2C+D+D+D">Dr. D. Deva Hema</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The rapid evolution of deep neural networks has revolutionized the field of
machine learning, enabling remarkable advancements in various domains. In this
article, we introduce NeuroWrite, a unique method for predicting the
categorization of handwritten digits using deep neural networks. Our model
exhibits outstanding accuracy in identifying and categorising handwritten
digits by utilising the strength of convolutional neural networks (CNNs) and
recurrent neural networks (RNNs).In this article, we give a thorough
examination of the data preparation methods, network design, and training
methods used in NeuroWrite. By implementing state-of-the-art techniques, we
showcase how NeuroWrite can achieve high classification accuracy and robust
generalization on handwritten digit datasets, such as MNIST. Furthermore, we
explore the model's potential for real-world applications, including digit
recognition in digitized documents, signature verification, and automated
postal code recognition. NeuroWrite is a useful tool for computer vision and
pattern recognition because of its performance and adaptability.The
architecture, training procedure, and evaluation metrics of NeuroWrite are
covered in detail in this study, illustrating how it can improve a number of
applications that call for handwritten digit classification. The outcomes show
that NeuroWrite is a promising method for raising the bar for deep neural
network-based handwritten digit recognition.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01023" title="Abstract">arXiv:2311.01023</a> [<a href="/pdf/2311.01023" title="Download PDF">pdf</a>, <a href="/format/2311.01023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmentation is AUtO-Net: Augmentation-Driven Contrastive Multiview  Learning for Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yanming Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The utilisation of deep learning segmentation algorithms that learn complex
organs and tissue patterns and extract essential regions of interest from the
noisy background to improve the visual ability for medical image diagnosis has
achieved impressive results in Medical Image Computing (MIC). This thesis
focuses on retinal blood vessel segmentation tasks, providing an extensive
literature review of deep learning-based medical image segmentation approaches
while comparing the methodologies and empirical performances. The work also
examines the limitations of current state-of-the-art methods by pointing out
the two significant existing limitations: data size constraints and the
dependency on high computational resources. To address such problems, this work
proposes a novel efficient, simple multiview learning framework that
contrastively learns invariant vessel feature representation by comparing with
multiple augmented views by various transformations to overcome data shortage
and improve generalisation ability. Moreover, the hybrid network architecture
integrates the attention mechanism into a Convolutional Neural Network to
further capture complex continuous curvilinear vessel structures. The result
demonstrates the proposed method validated on the CHASE-DB1 dataset, attaining
the highest F1 score of 83.46% and the highest Intersection over Union (IOU)
score of 71.62% with UNet structure, surpassing existing benchmark UNet-based
methods by 1.95% and 2.8%, respectively. The combination of the metrics
indicates the model detects the vessel object accurately with a highly
coincidental location with the ground truth. Moreover, the proposed approach
could be trained within 30 minutes by consuming less than 3 GB GPU RAM, and
such characteristics support the efficient implementation for real-world
applications and deployments.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01024" title="Abstract">arXiv:2311.01024</a> [<a href="/pdf/2311.01024" title="Download PDF">pdf</a>, <a href="/format/2311.01024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distance-Based Propagation for Efficient Knowledge Graph Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shomer%2C+H">Harry Shomer</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juanhui Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+C+C">Charu C. Aggarwal</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiliang Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Knowledge graph completion (KGC) aims to predict unseen edges in knowledge
graphs (KGs), resulting in the discovery of new facts. A new class of methods
have been proposed to tackle this problem by aggregating path information.
These methods have shown tremendous ability in the task of KGC. However they
are plagued by efficiency issues. Though there are a few recent attempts to
address this through learnable path pruning, they often sacrifice the
performance to gain efficiency. In this work, we identify two intrinsic
limitations of these methods that affect the efficiency and representation
quality. To address the limitations, we introduce a new method, TAGNet, which
is able to efficiently propagate information. This is achieved by only
aggregating paths in a fixed window for each source-target pair. We demonstrate
that the complexity of TAGNet is independent of the number of layers. Extensive
experiments demonstrate that TAGNet can cut down on the number of propagated
messages by as much as 90% while achieving competitive performance on multiple
KG datasets. The code is available at https://github.com/HarryShomer/TAGNet.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01025" title="Abstract">arXiv:2311.01025</a> [<a href="/pdf/2311.01025" title="Download PDF">pdf</a>, <a href="/format/2311.01025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incorporating Language-Driven Appearance Knowledge Units with Visual  Cues in Pedestrian Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sungjune Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyunjun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ro%2C+Y+M">Yong Man Ro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large language models (LLMs) have shown their capability in understanding
contextual and semantic information regarding appearance knowledge of
instances. In this paper, we introduce a novel approach to utilize the strength
of an LLM in understanding contextual appearance variations and to leverage its
knowledge into a vision model (here, pedestrian detection). While pedestrian
detection is considered one of crucial tasks directly related with our safety
(e.g., intelligent driving system), it is challenging because of varying
appearances and poses in diverse scenes. Therefore, we propose to formulate
language-driven appearance knowledge units and incorporate them with visual
cues in pedestrian detection. To this end, we establish description corpus
which includes numerous narratives describing various appearances of
pedestrians and others. By feeding them through an LLM, we extract appearance
knowledge sets that contain the representations of appearance variations. After
that, we perform a task-prompting process to obtain appearance knowledge units
which are representative appearance knowledge guided to be relevant to a
downstream pedestrian detection task. Finally, we provide plentiful appearance
information by integrating the language-driven knowledge units with visual
cues. Through comprehensive experiments with various pedestrian detectors, we
verify the effectiveness of our method showing noticeable performance gains and
achieving state-of-the-art detection performance.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01026" title="Abstract">arXiv:2311.01026</a> [<a href="/pdf/2311.01026" title="Download PDF">pdf</a>, <a href="/ps/2311.01026" title="Download PostScript">ps</a>, <a href="/format/2311.01026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Constant Factor Approximation for Directed Feedback Vertex Set in  Graphs of Bounded Genus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hao Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">The minimum directed feedback vertex set problem consists in finding the
minimum set of vertices that should be removed in order to make a directed
graph acyclic. This is a well-known NP-hard optimization problem with
applications in various fields, such as VLSI chip design, bioinformatics and
transaction processing deadlock prevention and node-weighted network design. We
show a constant factor approximation for the directed feedback vertex set
problem in graphs of bounded genus.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01030" title="Abstract">arXiv:2311.01030</a> [<a href="/pdf/2311.01030" title="Download PDF">pdf</a>, <a href="/format/2311.01030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Learning of Local and Global Features for Aspect-based Sentiment  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+H">Hao Niu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yun Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaosu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Aspect-based sentiment classification (ASC) aims to judge the sentiment
polarity conveyed by the given aspect term in a sentence. The sentiment
polarity is not only determined by the local context but also related to the
words far away from the given aspect term. Most recent efforts related to the
attention-based models can not sufficiently distinguish which words they should
pay more attention to in some cases. Meanwhile, graph-based models are coming
into ASC to encode syntactic dependency tree information. But these models do
not fully leverage syntactic dependency trees as they neglect to incorporate
dependency relation tag information into representation learning effectively.
In this paper, we address these problems by effectively modeling the local and
global features. Firstly, we design a local encoder containing: a Gaussian mask
layer and a covariance self-attention layer. The Gaussian mask layer tends to
adjust the receptive field around aspect terms adaptively to deemphasize the
effects of unrelated words and pay more attention to local information. The
covariance self-attention layer can distinguish the attention weights of
different words more obviously. Furthermore, we propose a dual-level graph
attention network as a global encoder by fully employing dependency tag
information to capture long-distance information effectively. Our model
achieves state-of-the-art performance on both SemEval 2014 and Twitter
datasets.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01032" title="Abstract">arXiv:2311.01032</a> [<a href="/pdf/2311.01032" title="Download PDF">pdf</a>, <a href="/ps/2311.01032" title="Download PostScript">ps</a>, <a href="/format/2311.01032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized Generalized Approximate Message-Passing for  Tree-Structured Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Takeuchi%2C+K">Keigo Takeuchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE Trans. Inf. Theory
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Decentralized generalized approximate message-passing (GAMP) is proposed for
compressed sensing from distributed generalized linear measurements in a
tree-structured network. Consensus propagation is used to realize average
consensus required in GAMP via local communications between adjacent nodes.
Decentralized GAMP is applicable to all tree-structured networks that do not
necessarily have central nodes connected to all other nodes. State evolution is
used to analyze the asymptotic dynamics of decentralized GAMP for zero-mean
independent and identically distributed Gaussian sensing matrices. The state
evolution recursion for decentralized GAMP is proved to have the same fixed
points as that for centralized GAMP when homogeneous measurements with an
identical dimension in all nodes are considered. Furthermore, existing
long-memory proof strategy is used to prove that the state evolution recursion
for decentralized GAMP with the Bayes-optimal denoisers converges to a fixed
point. These results imply that the state evolution recursion for decentralized
GAMP with the Bayes-optimal denoisers converges to the Bayes-optimal fixed
point for the homogeneous measurements when the fixed point is unique.
Numerical results for decentralized GAMP are presented in the cases of linear
measurements and clipping. As examples of tree-structured networks, a
one-dimensional chain and a tree with no central nodes are considered.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01033" title="Abstract">arXiv:2311.01033</a> [<a href="/pdf/2311.01033" title="Download PDF">pdf</a>, <a href="/format/2311.01033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Autoregressive Diffusion-based Temporal Point Processes for  Continuous-Time Long-Term Event Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wang-Tao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Z">Zhao Kang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+L">Ling Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Continuous-time long-term event prediction plays an important role in many
application scenarios. Most existing works rely on autoregressive frameworks to
predict event sequences, which suffer from error accumulation, thus
compromising prediction quality. Inspired by the success of denoising diffusion
probabilistic models, we propose a diffusion-based non-autoregressive temporal
point process model for long-term event prediction in continuous time. Instead
of generating events one at a time in an autoregressive way, our model predicts
the future event sequence entirely as a whole. In order to perform diffusion
processes on event sequences, we develop a bidirectional map between target
event sequences and the Euclidean vector space. Furthermore, we design a novel
denoising network to capture both sequential and contextual features for better
sample quality. Extensive experiments are conducted to prove the superiority of
our proposed model over state-of-the-art methods on long-term event prediction
in continuous time. To the best of our knowledge, this is the first work to
apply diffusion methods to long-term event prediction problems.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01034" title="Abstract">arXiv:2311.01034</a> [<a href="/pdf/2311.01034" title="Download PDF">pdf</a>, <a href="/format/2311.01034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Adapt CLIP for Few-Shot Monocular Depth Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xueting Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Ce Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hai%2C+B">Bowen Hai</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Ke Yu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhihai He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Pre-trained Vision-Language Models (VLMs), such as CLIP, have shown enhanced
performance across a range of tasks that involve the integration of visual and
linguistic modalities. When CLIP is used for depth estimation tasks, the
patches, divided from the input images, can be combined with a series of
semantic descriptions of the depth information to obtain similarity results.
The coarse estimation of depth is then achieved by weighting and summing the
depth values, called depth bins, corresponding to the predefined semantic
descriptions. The zero-shot approach circumvents the computational and
time-intensive nature of traditional fully-supervised depth estimation methods.
However, this method, utilizing fixed depth bins, may not effectively
generalize as images from different scenes may exhibit distinct depth
distributions. To address this challenge, we propose a few-shot-based method
which learns to adapt the VLMs for monocular depth estimation to balance
training costs and generalization capabilities. Specifically, it assigns
different depth bins for different scenes, which can be selected by the model
during inference. Additionally, we incorporate learnable prompts to preprocess
the input text to convert the easily human-understood text into easily
model-understood vectors and further enhance the performance. With only one
image per scene for training, our extensive experiment results on the NYU V2
and KITTI dataset demonstrate that our method outperforms the previous
state-of-the-art method by up to 10.6\% in terms of MARE.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01036" title="Abstract">arXiv:2311.01036</a> [<a href="/pdf/2311.01036" title="Download PDF">pdf</a>, <a href="/format/2311.01036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ATHENA: Mathematical Reasoning with Thought Expansion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">JB. Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hazel Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hahn%2C+J">Joonghyuk Hahn</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yo-Sub Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 (main); 13 pages, 5 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Solving math word problems depends on how to articulate the problems, the
lens through which models view human linguistic expressions. Real-world
settings count on such a method even more due to the diverse practices of the
same mathematical operations. Earlier works constrain available thinking
processes by limited prediction strategies without considering their
significance in acquiring mathematical knowledge. We introduce Attention-based
THought Expansion Network Architecture (ATHENA) to tackle the challenges of
real-world practices by mimicking human thought expansion mechanisms in the
form of neural network propagation. A thought expansion recurrently generates
the candidates carrying the thoughts of possible math expressions driven from
the previous step and yields reasonable thoughts by selecting the valid
pathways to the goal. Our experiments show that ATHENA achieves a new
state-of-the-art stage toward the ideal model that is compelling in variant
questions even when the informativeness in training examples is restricted.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01038" title="Abstract">arXiv:2311.01038</a> [<a href="/pdf/2311.01038" title="Download PDF">pdf</a>, <a href="/format/2311.01038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Better with Less: A Data-Active Perspective on Pre-Training Graph Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiarong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Renhong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xin Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yuxuan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Carl Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chunping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Pre-training on graph neural networks (GNNs) aims to learn transferable
knowledge for downstream tasks with unlabeled data, and it has recently become
an active research area. The success of graph pre-training models is often
attributed to the massive amount of input data. In this paper, however, we
identify the curse of big data phenomenon in graph pre-training: more training
data do not necessarily lead to better downstream performance. Motivated by
this observation, we propose a better-with-less framework for graph
pre-training: fewer, but carefully chosen data are fed into a GNN model to
enhance pre-training. The proposed pre-training pipeline is called the
data-active graph pre-training (APT) framework, and is composed of a graph
selector and a pre-training model. The graph selector chooses the most
representative and instructive data points based on the inherent properties of
graphs as well as predictive uncertainty. The proposed predictive uncertainty,
as feedback from the pre-training model, measures the confidence level of the
model in the data. When fed with the chosen data, on the other hand, the
pre-training model grasps an initial understanding of the new, unseen data, and
at the same time attempts to remember the knowledge learned from previous data.
Therefore, the integration and interaction between these two components form a
unified framework (APT), in which graph pre-training is performed in a
progressive and iterative way. Experiment results show that the proposed APT is
able to obtain an efficient pre-training model with fewer training data and
better downstream performance.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01039" title="Abstract">arXiv:2311.01039</a> [<a href="/pdf/2311.01039" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-cultural electronic word-of-mouth: a systematic literature review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kusawat%2C+P">Poompak Kusawat</a>, 
<a href="/search/cs?searchtype=author&query=Teerakapibal%2C+S">Surat Teerakapibal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 2 tables, 2 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Spanish Journal of Marketing - ESIC, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Purpose: Global adoption of the internet and mobile usage results in a huge
variation in the cultural backgrounds of consumers who generate and consume
electronic word-of-mouth (eWOM). Unsurprisingly, a research trend on
cross-cultural eWOM has emerged. However, there has not been an attempt to
synthesize this research topic. This paper aims to bridge this gap.
<br />Methodology: This research paper conducts a systematic literature review of
the current research findings on cross-cultural eWOM. Journal articles
published from 2006 to 2021 are included. This study then presents the key
issues in the extant literature and suggests potential future research.
<br />Findings: The findings show that there has been an upward trend in the number
of publications on cross-cultural eWOM since the early 2010s, with a relatively
steeper increase toward 2020. The findings also synthesize cross-cultural eWOM
research into four elements and suggest potential future research avenues.
<br />Value: To the best of the authors' knowledge, there is currently no
exhaustive/integrated review of cross-cultural eWOM research. This research
fills the need to summarize the current state of cross-cultural eWOM literature
and identifies research questions to be addressed in the future.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01040" title="Abstract">arXiv:2311.01040</a> [<a href="/pdf/2311.01040" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Roles of Culture in Online User Reviews: An Empirical Investigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kusawat%2C+P">Poompak Kusawat</a>, 
<a href="/search/cs?searchtype=author&query=Teerakapibal%2C+S">Surat Teerakapibal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 4 tables, 2 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Global Marketing, 34(3), 2021, 189-204
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Electronic word-of-mouth (eWOM) is a prominent source of information that
significantly influences consumer purchase decisions. Recent literature has
extensively explored the impact of eWOM on consumers-generated reviews and
purchase decisions. However, few studies have analyzed the role of culture on
eWOM. We use a novel dataset of Airbnb eWOM messages in order to empirically
extend the findings by Banerjee and Chai (2019). We find that the sentiment of
individualistic customers is worse than that of their collectivistic
counterparts when both groups experience the same level of negative
disconfirmations. Furthermore, guests from a relatively more distant culture
rely less on heuristics. In particular, quality signals, such as the
"superhost" status, are more influential to consumers from a less distant
cultural background.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01041" title="Abstract">arXiv:2311.01041</a> [<a href="/pdf/2311.01041" title="Download PDF">pdf</a>, <a href="/format/2311.01041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learn to Refuse: Making Large Language Models More Controllable and  Reliable through Knowledge Scope Limitation and Refusal Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Lang Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated impressive language
understanding and generation capabilities, enabling them to answer a wide range
of questions across various domains. However, these models are not flawless and
often produce responses that contain errors or misinformation. These
inaccuracies, commonly referred to as hallucinations, render LLMs unreliable
and even unusable in many scenarios. In this paper, our focus is on mitigating
the issue of hallucination in LLMs, particularly in the context of
question-answering. Instead of attempting to answer all questions, we explore a
refusal mechanism that instructs LLMs to refuse to answer challenging questions
in order to avoid errors. We then propose a simple yet effective solution
called Learn to Refuse (L2R), which incorporates the refusal mechanism to
enable LLMs to recognize and refuse to answer questions that they find
difficult to address. To achieve this, we utilize a structured knowledge base
to represent all the LLM's understanding of the world, enabling it to provide
traceable gold knowledge. This knowledge base is separate from the LLM and
initially empty, and it is progressively expanded with validated knowledge.
When an LLM encounters questions outside its domain, the system recognizes its
knowledge scope and determines whether it can answer the question
independently. Additionally, we introduce a method for automatically and
efficiently expanding the knowledge base of LLMs. Through qualitative and
quantitative analysis, we demonstrate that our approach enhances the
controllability and reliability of LLMs.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01043" title="Abstract">arXiv:2311.01043</a> [<a href="/pdf/2311.01043" title="Download PDF">pdf</a>, <a href="/format/2311.01043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Large Language Models for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhenjie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiaosong Jia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> GitHub Repo: <a href="https://github.com/Thinklab-SJTU/Awesome-LLM4AD">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Autonomous driving technology, a catalyst for revolutionizing transportation
and urban mobility, has the tend to transition from rule-based systems to
data-driven strategies. Traditional module-based systems are constrained by
cumulative errors among cascaded modules and inflexible pre-set rules. In
contrast, end-to-end autonomous driving systems have the potential to avoid
error accumulation due to their fully data-driven training process, although
they often lack transparency due to their ``black box" nature, complicating the
validation and traceability of decisions. Recently, large language models
(LLMs) have demonstrated abilities including understanding context, logical
reasoning, and generating answers. A natural thought is to utilize these
abilities to empower autonomous driving. By combining LLM with foundation
vision models, it could open the door to open-world understanding, reasoning,
and few-shot learning, which current autonomous driving systems are lacking. In
this paper, we systematically review a research line about \textit{Large
Language Models for Autonomous Driving (LLM4AD)}. This study evaluates the
current state of technological advancements, distinctly outlining the principal
challenges and prospective directions for the field. For the convenience of
researchers in academia and industry, we provide real-time updates on the
latest advances in the field as well as relevant open-source resources via the
designated link: https://github.com/Thinklab-SJTU/Awesome-LLM4AD.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01046" title="Abstract">arXiv:2311.01046</a> [<a href="/pdf/2311.01046" title="Download PDF">pdf</a>, <a href="/ps/2311.01046" title="Download PostScript">ps</a>, <a href="/format/2311.01046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Independent Information-Theoretic Generalization Bounds for SGLD
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Futami%2C+F">Futoshi Futami</a>, 
<a href="/search/cs?searchtype=author&query=Fujisawa%2C+M">Masahiro Fujisawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS2023), 29 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We provide novel information-theoretic generalization bounds for stochastic
gradient Langevin dynamics (SGLD) under the assumptions of smoothness and
dissipativity, which are widely used in sampling and non-convex optimization
studies. Our bounds are time-independent and decay to zero as the sample size
increases, regardless of the number of iterations and whether the step size is
fixed. Unlike previous studies, we derive the generalization error bounds by
focusing on the time evolution of the Kullback--Leibler divergence, which is
related to the stability of datasets and is the upper bound of the mutual
information between output parameters and an input dataset. Additionally, we
establish the first information-theoretic generalization bound when the
training and test loss are the same by showing that a loss function of SGLD is
sub-exponential. This bound is also time-independent and removes the
problematic step size dependence in existing work, leading to an improved
excess risk bound by combining our analysis with the existing non-convex
optimization error bounds.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01047" title="Abstract">arXiv:2311.01047</a> [<a href="/pdf/2311.01047" title="Download PDF">pdf</a>, <a href="/format/2311.01047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Robustness via Tilted Exponential Layer: A  Communication-Theoretic Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Puranik%2C+B">Bhagyashree Puranik</a>, 
<a href="/search/cs?searchtype=author&query=Beirami%2C+A">Ahmad Beirami</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yao Qin</a>, 
<a href="/search/cs?searchtype=author&query=Madhow%2C+U">Upamanyu Madhow</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Signal Processing (eess.SP)

</div>
<p class="mathjax">State-of-the-art techniques for enhancing robustness of deep networks mostly
rely on empirical risk minimization with suitable data augmentation. In this
paper, we propose a complementary approach motivated by communication theory,
aimed at enhancing the signal-to-noise ratio at the output of a neural network
layer via neural competition during learning and inference. In addition to
minimization of a standard end-to-end cost, neurons compete to sparsely
represent layer inputs by maximization of a tilted exponential (TEXP) objective
function for the layer. TEXP learning can be interpreted as maximum likelihood
estimation of matched filters under a Gaussian model for data noise. Inference
in a TEXP layer is accomplished by replacing batch norm by a tilted softmax,
which can be interpreted as computation of posterior probabilities for the
competing signaling hypotheses represented by each neuron. After providing
insights via simplified models, we show, by experimentation on standard image
datasets, that TEXP learning and inference enhances robustness against noise
and other common corruptions, without requiring data augmentation. Further
cumulative gains in robustness against this array of distortions can be
obtained by appropriately combining TEXP with data augmentation techniques.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01048" title="Abstract">arXiv:2311.01048</a> [<a href="/pdf/2311.01048" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-assisted Learning for Electronic Engineering Courses in High  Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ngoc%2C+T+N">Thanh Nguyen Ngoc</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+Q+N">Quang Nhat Tran</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+A">Arthur Tang</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+B">Bao Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thuy Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+T">Thanh Pham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study evaluates the efficacy of ChatGPT as an AI teaching and learning
support tool in an integrated circuit systems course at a higher education
institution in an Asian country. Various question types were completed, and
ChatGPT responses were assessed to gain valuable insights for further
investigation. The objective is to assess ChatGPT's ability to provide
insights, personalized support, and interactive learning experiences in
engineering education. The study includes the evaluation and reflection of
different stakeholders: students, lecturers, and engineers. The findings of
this study shed light on the benefits and limitations of ChatGPT as an AI tool,
paving the way for innovative learning approaches in technical disciplines.
Furthermore, the study contributes to our understanding of how digital
transformation is likely to unfold in the education sector.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01049" title="Abstract">arXiv:2311.01049</a> [<a href="/pdf/2311.01049" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-dimensional data refining strategy for effective fine-tuning LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ngoc%2C+T+N">Thanh Nguyen Ngoc</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+Q+N">Quang Nhat Tran</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+A">Arthur Tang</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+B">Bao Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thuy Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+T">Thanh Pham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Data is a cornerstone for fine-tuning large language models, yet acquiring
suitable data remains challenging. Challenges encompassed data scarcity,
linguistic diversity, and domain-specific content. This paper presents lessons
learned while crawling and refining data tailored for fine-tuning Vietnamese
language models. Crafting such a dataset, while accounting for linguistic
intricacies and striking a balance between inclusivity and accuracy, demands
meticulous planning. Our paper presents a multidimensional strategy including
leveraging existing datasets in the English language and developing customized
data-crawling scripts with the assistance of generative AI tools. A fine-tuned
LLM model for the Vietnamese language, which was produced using resultant
datasets, demonstrated good performance while generating Vietnamese news
articles from prompts. The study offers practical solutions and guidance for
future fine-tuning models in languages like Vietnamese.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01050" title="Abstract">arXiv:2311.01050</a> [<a href="/pdf/2311.01050" title="Download PDF">pdf</a>, <a href="/format/2311.01050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Application and Energy-Aware Data Aggregation using Vector  Synchronization in Distributed Battery-less IoT Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singhal%2C+C">Chetna Singhal</a>, 
<a href="/search/cs?searchtype=author&query=Barick%2C+S">Subhrajit Barick</a>, 
<a href="/search/cs?searchtype=author&query=Sonkar%2C+R">Rishabh Sonkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The battery-less Internet of Things (IoT) devices are a key element in the
sustainable green initiative for the next-generation wireless networks. These
battery-free devices use the ambient energy, harvested from the environment.
The energy harvesting environment is dynamic and causes intermittent task
execution. The harvested energy is stored in small capacitors and it is
challenging to assure the application task execution. The main goal is to
provide a mechanism to aggregate the sensor data and provide a sustainable
application support in the distributed battery-less IoT network. We model the
distributed IoT network system consisting of many battery-free IoT sensor
hardware modules and heterogeneous IoT applications that are being supported in
the device-edge-cloud continuum. The applications require sensor data from a
distributed set of battery-less hardware modules and there is provision of
joint control over the module actuators. We propose an application-aware task
and energy manager (ATEM) for the IoT devices and a vector-synchronization
based data aggregator (VSDA). The ATEM is supported by device-level federated
energy harvesting and system-level energy-aware heterogeneous application
management. In our proposed framework the data aggregator forecasts the
available power from the ambient energy harvester using long-short-term-memory
(LSTM) model and sets the device profile as well as the application task rates
accordingly. Our proposed scheme meets the heterogeneous application
requirements with negligible overhead; reduces the data loss and packet delay;
increases the hardware component availability; and makes the components
available sooner as compared to the state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01051" title="Abstract">arXiv:2311.01051</a> [<a href="/pdf/2311.01051" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sponsorship Disclosure in Native Advertising: A Theoretical Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kusawat%2C+P">Poompak Kusawat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 1 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Community Development Research (Humanities and Social
  Sciences), 14(2), 2021, 29-38
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Native advertising is one of the fastest growing areas of online promotion.
After reviewing extant literature via EBSCOhost database, this study draws on
Persuasion Knowledge Model and develops a theoretical framework which
facilitates a clearer understanding of the relationship between sponsorship
disclosure in native advertising and consumer outcome. The framework suggests
that sponsorship disclosure has a negative effect on electronic word of mouth
(eWOM), and further proposes the interplay between the main effect with brand
prominence and the type of device. This is highly relevant to marketer as
regulators have been pressuring for the disclosure of native advertising. As
this is likely to have detrimental effect to the eWOM, marketer may employ the
boundary conditions proposed by this framework to attenuate that negative
effect.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01054" title="Abstract">arXiv:2311.01054</a> [<a href="/pdf/2311.01054" title="Download PDF">pdf</a>, <a href="/ps/2311.01054" title="Download PostScript">ps</a>, <a href="/format/2311.01054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A feasible and unitary programming language with quantum control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz-Caro%2C+A">Alejandro D&#xed;az-Caro</a> (CONICET, UBA, UNQ), 
<a href="/search/cs?searchtype=author&query=Hainry%2C+E">Emmanuel Hainry</a> (MOCQUA, UL, LORIA), 
<a href="/search/cs?searchtype=author&query=P%C3%A9choux%2C+R">Romain P&#xe9;choux</a> (MOCQUA, UL, LORIA), 
<a href="/search/cs?searchtype=author&query=Silva%2C+M">M&#xe1;rio Silva</a> (MOCQUA, UL, LORIA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">We introduce PUNQ, a novel quantum programming language with quantum control,
which features higher-order programs that can be superposed, enabling quantum
control via quantum conditionals. Our language boasts a type system
guaranteeing both unitarity and polynomial-time normalization. Unitarity is
achieved by using a special modality for superpositions while requiring
orthogonality among superposed terms. Polynomial-time normalization is achieved
using a linear-logic-based type discipline employing Barber and Plotkin duality
along with a specific modality to account for potential duplications. This type
discipline also guarantees that derived values have polynomial size. PUNQ
seamlessly combines the two modalities: quantum circuit programs uphold
unitarity, and all programs are evaluated in polynomial time, ensuring their
feasibility.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01055" title="Abstract">arXiv:2311.01055</a> [<a href="/pdf/2311.01055" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From 5G to 6G: Revolutionizing Satellite Networks through TRANTOR  Foundation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Henarejos%2C+P">Pol Henarejos</a>, 
<a href="/search/cs?searchtype=author&query=Artiga%2C+X">Xavier Artiga</a>, 
<a href="/search/cs?searchtype=author&query=V%C3%A1zquez%2C+M+A">Miguel A. V&#xe1;zquez</a>, 
<a href="/search/cs?searchtype=author&query=Caus%2C+M">M&#xe0;rius Caus</a>, 
<a href="/search/cs?searchtype=author&query=Shaat%2C+M">Musbah Shaat</a>, 
<a href="/search/cs?searchtype=author&query=Bas%2C+J">Joan Bas</a>, 
<a href="/search/cs?searchtype=author&query=Blanco%2C+L">Llu&#xed;s Blanco</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez-Neira%2C+A+I">Ana I. P&#xe9;rez-Neira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">5G technology will drastically change the way satellite internet providers
deliver services by offering higher data speeds, massive network capacity,
reduced latency, improved reliability and increased availability. A
standardised 5G ecosystem will enable adapting 5G to satellite needs. The
EU-funded TRANTOR project will seek to develop novel and secure satellite
network management solutions that allow scaling up heterogeneous satellite
traffic demands and capacities in a cost-effective and highly dynamic way.
Researchers also target the development of flexible 6G non-terrestrial access
architectures. The focus will be on the design of a multi-orbit and multi-band
antenna for satellite user equipment (UE), as well as the development of gNodeB
(gNB) and UE 5G non-terrestrial network equipment to support
multi-connectivity.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01056" title="Abstract">arXiv:2311.01056</a> [<a href="/pdf/2311.01056" title="Download PDF">pdf</a>, <a href="/format/2311.01056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaboration and Transition: Distilling Item Transitions into  Multi-Query Self-Attention for Sequential Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Tianyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yansong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yihong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Mo%2C+F">Fengran Mo</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+J">Jian-Yun Nie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WSDM 2024 Oral Presentation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Modern recommender systems employ various sequential modules such as
self-attention to learn dynamic user interests. However, these methods are less
effective in capturing collaborative and transitional signals within user
interaction sequences. First, the self-attention architecture uses the
embedding of a single item as the attention query, which is inherently
challenging to capture collaborative signals. Second, these methods typically
follow an auto-regressive framework, which is unable to learn global item
transition patterns. To overcome these limitations, we propose a new method
called Multi-Query Self-Attention with Transition-Aware Embedding Distillation
(MQSA-TED). First, we propose an $L$-query self-attention module that employs
flexible window sizes for attention queries to capture collaborative signals.
In addition, we introduce a multi-query self-attention method that balances the
bias-variance trade-off in modeling user preferences by combining long and
short-query self-attentions. Second, we develop a transition-aware embedding
distillation module that distills global item-to-item transition patterns into
item embeddings, which enables the model to memorize and leverage transitional
signals and serves as a calibrator for collaborative signals. Experimental
results on four real-world datasets show the superiority of our proposed method
over state-of-the-art sequential recommendation methods.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01057" title="Abstract">arXiv:2311.01057</a> [<a href="/pdf/2311.01057" title="Download PDF">pdf</a>, <a href="/format/2311.01057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultra-Efficient On-Device Object Detection on AI-Integrated Smart  Glasses with TinyissimoYOLO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moosmann%2C+J">Julian Moosmann</a>, 
<a href="/search/cs?searchtype=author&query=Bonazzi%2C+P">Pietro Bonazzi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yawei Li</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+S">Sizhen Bian</a>, 
<a href="/search/cs?searchtype=author&query=Mayer%2C+P">Philipp Mayer</a>, 
<a href="/search/cs?searchtype=author&query=Benini%2C+L">Luca Benini</a>, 
<a href="/search/cs?searchtype=author&query=Magno%2C+M">Michele Magno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Smart glasses are rapidly gaining advanced functionality thanks to
cutting-edge computing technologies, accelerated hardware architectures, and
tiny AI algorithms. Integrating AI into smart glasses featuring a small form
factor and limited battery capacity is still challenging when targeting
full-day usage for a satisfactory user experience. This paper illustrates the
design and implementation of tiny machine-learning algorithms exploiting novel
low-power processors to enable prolonged continuous operation in smart glasses.
We explore the energy- and latency-efficient of smart glasses in the case of
real-time object detection. To this goal, we designed a smart glasses prototype
as a research platform featuring two microcontrollers, including a novel
milliwatt-power RISC-V parallel processor with a hardware accelerator for
visual AI, and a Bluetooth low-power module for communication. The smart
glasses integrate power cycling mechanisms, including image and audio sensing
interfaces. Furthermore, we developed a family of novel tiny deep-learning
models based on YOLO with sub-million parameters customized for
microcontroller-based inference dubbed TinyissimoYOLO v1.3, v5, and v8, aiming
at benchmarking object detection with smart glasses for energy and latency.
Evaluations on the prototype of the smart glasses demonstrate TinyissimoYOLO's
17ms inference latency and 1.59mJ energy consumption per inference while
ensuring acceptable detection accuracy. Further evaluation reveals an
end-to-end latency from image capturing to the algorithm's prediction of 56ms
or equivalently 18 fps, with a total power consumption of 62.9mW, equivalent to
a 9.3 hours of continuous run time on a 154mAh battery. These results
outperform MCUNet (TinyNAS+TinyEngine), which runs a simpler task (image
classification) at just 7.3 fps per second.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01059" title="Abstract">arXiv:2311.01059</a> [<a href="/pdf/2311.01059" title="Download PDF">pdf</a>, <a href="/format/2311.01059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapt On-the-Go: Behavior Modulation for Single-Life Robot Deployment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+A+S">Annie S. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chada%2C+G">Govind Chada</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+L">Laura Smith</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Archit Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Z">Zipeng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>, 
<a href="/search/cs?searchtype=author&query=Finn%2C+C">Chelsea Finn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">To succeed in the real world, robots must cope with situations that differ
from those seen during training. We study the problem of adapting on-the-fly to
such novel scenarios during deployment, by drawing upon a diverse repertoire of
previously learned behaviors. Our approach, RObust Autonomous Modulation
(ROAM), introduces a mechanism based on the perceived value of pre-trained
behaviors to select and adapt pre-trained behaviors to the situation at hand.
Crucially, this adaptation process all happens within a single episode at test
time, without any human supervision. We provide theoretical analysis of our
selection mechanism and demonstrate that ROAM enables a robot to adapt rapidly
to changes in dynamics both in simulation and on a real Go1 quadruped, even
successfully moving forward with roller skates on its feet. Our approach adapts
over 2x as efficiently compared to existing methods when facing a variety of
out-of-distribution situations during deployment by effectively choosing and
adapting relevant behaviors on-the-fly.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01060" title="Abstract">arXiv:2311.01060</a> [<a href="/pdf/2311.01060" title="Download PDF">pdf</a>, <a href="/format/2311.01060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reputation Systems for Supply Chains: The Challenge of Achieving Privacy  Preservation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bader%2C+L">Lennart Bader</a>, 
<a href="/search/cs?searchtype=author&query=Pennekamp%2C+J">Jan Pennekamp</a>, 
<a href="/search/cs?searchtype=author&query=Thevaraj%2C+E">Emildeon Thevaraj</a>, 
<a href="/search/cs?searchtype=author&query=Spi%C3%9F%2C+M">Maria Spi&#xdf;</a>, 
<a href="/search/cs?searchtype=author&query=Kanhere%2C+S+S">Salil S. Kanhere</a>, 
<a href="/search/cs?searchtype=author&query=Wehrle%2C+K">Klaus Wehrle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Consumers frequently interact with reputation systems to rate products,
services, and deliveries. While past research extensively studied different
conceptual approaches to realize such systems securely and
privacy-preservingly, these concepts are not yet in use in business-to-business
environments. In this paper, (1) we thus outline which specific challenges
privacy-cautious stakeholders in volatile supply chain networks introduce, (2)
give an overview of the diverse landscape of privacy-preserving reputation
systems and their properties, and (3) based on well-established concepts from
supply chain information systems and cryptography, we further propose an
initial concept that accounts for the aforementioned challenges by utilizing
fully homomorphic encryption. For future work, we identify the need of
evaluating whether novel systems address the supply chain-specific privacy and
confidentiality needs.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01061" title="Abstract">arXiv:2311.01061</a> [<a href="/pdf/2311.01061" title="Download PDF">pdf</a>, <a href="/format/2311.01061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning for real-time neural decoding of grasp
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Viviani%2C+P">Paolo Viviani</a>, 
<a href="/search/cs?searchtype=author&query=Gesmundo%2C+I">Ilaria Gesmundo</a>, 
<a href="/search/cs?searchtype=author&query=Ghinato%2C+E">Elios Ghinato</a>, 
<a href="/search/cs?searchtype=author&query=Agudelo-Toro%2C+A">Andres Agudelo-Toro</a>, 
<a href="/search/cs?searchtype=author&query=Vercellino%2C+C">Chiara Vercellino</a>, 
<a href="/search/cs?searchtype=author&query=Vitali%2C+G">Giacomo Vitali</a>, 
<a href="/search/cs?searchtype=author&query=Bergamasco%2C+L">Letizia Bergamasco</a>, 
<a href="/search/cs?searchtype=author&query=Scionti%2C+A">Alberto Scionti</a>, 
<a href="/search/cs?searchtype=author&query=Ghislieri%2C+M">Marco Ghislieri</a>, 
<a href="/search/cs?searchtype=author&query=Agostini%2C+V">Valentina Agostini</a>, 
<a href="/search/cs?searchtype=author&query=Terzo%2C+O">Olivier Terzo</a>, 
<a href="/search/cs?searchtype=author&query=Scherberger%2C+H">Hansj&#xf6;rg Scherberger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Neural decoding involves correlating signals acquired from the brain to
variables in the physical world like limb movement or robot control in Brain
Machine Interfaces. In this context, this work starts from a specific
pre-existing dataset of neural recordings from monkey motor cortex and presents
a Deep Learning-based approach to the decoding of neural signals for grasp type
classification. Specifically, we propose here an approach that exploits LSTM
networks to classify time series containing neural data (i.e., spike trains)
into classes representing the object being grasped. The main goal of the
presented approach is to improve over state-of-the-art decoding accuracy
without relying on any prior neuroscience knowledge, and leveraging only the
capability of deep learning models to extract correlations from data. The paper
presents the results achieved for the considered dataset and compares them with
previous works on the same dataset, showing a significant improvement in
classification accuracy, even if considering simulated real-time decoding.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01064" title="Abstract">arXiv:2311.01064</a> [<a href="/pdf/2311.01064" title="Download PDF">pdf</a>, <a href="/format/2311.01064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Foundation Models for Zero-shot Animal Species Recognition in  Camera Trap Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fabian%2C+Z">Zalan Fabian</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+Z">Zhongqi Miao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuanhan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hern%C3%A1ndez%2C+A">Andr&#xe9;s Hern&#xe1;ndez</a>, 
<a href="/search/cs?searchtype=author&query=Montes-Rojas%2C+A">Andr&#xe9;s Montes-Rojas</a>, 
<a href="/search/cs?searchtype=author&query=Escucha%2C+R">Rafael Escucha</a>, 
<a href="/search/cs?searchtype=author&query=Siabatto%2C+L">Laura Siabatto</a>, 
<a href="/search/cs?searchtype=author&query=Link%2C+A">Andr&#xe9;s Link</a>, 
<a href="/search/cs?searchtype=author&query=Arbel%C3%A1ez%2C+P">Pablo Arbel&#xe1;ez</a>, 
<a href="/search/cs?searchtype=author&query=Dodhia%2C+R">Rahul Dodhia</a>, 
<a href="/search/cs?searchtype=author&query=Ferres%2C+J+L">Juan Lavista Ferres</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Due to deteriorating environmental conditions and increasing human activity,
conservation efforts directed towards wildlife is crucial. Motion-activated
camera traps constitute an efficient tool for tracking and monitoring wildlife
populations across the globe. Supervised learning techniques have been
successfully deployed to analyze such imagery, however training such techniques
requires annotations from experts. Reducing the reliance on costly labelled
data therefore has immense potential in developing large-scale wildlife
tracking solutions with markedly less human labor. In this work we propose
WildMatch, a novel zero-shot species classification framework that leverages
multimodal foundation models. In particular, we instruction tune
vision-language models to generate detailed visual descriptions of camera trap
images using similar terminology to experts. Then, we match the generated
caption to an external knowledge base of descriptions in order to determine the
species in a zero-shot manner. We investigate techniques to build instruction
tuning datasets for detailed animal description generation and propose a novel
knowledge augmentation technique to enhance caption quality. We demonstrate the
performance of WildMatch on a new camera trap dataset collected in the
Magdalena Medio region of Colombia.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01065" title="Abstract">arXiv:2311.01065</a> [<a href="/pdf/2311.01065" title="Download PDF">pdf</a>, <a href="/format/2311.01065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Novel View Synthesis from a Single RGBD Image for Indoor Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hetang%2C+C">Congrui Hetang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuping Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2nd International Conference on Image Processing, Computer Vision and Machine Learning, November 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we propose an approach for synthesizing novel view images from
a single RGBD (Red Green Blue-Depth) input. Novel view synthesis (NVS) is an
interesting computer vision task with extensive applications. Methods using
multiple images has been well-studied, exemplary ones include training
scene-specific Neural Radiance Fields (NeRF), or leveraging multi-view stereo
(MVS) and 3D rendering pipelines. However, both are either computationally
intensive or non-generalizable across different scenes, limiting their
practical value. Conversely, the depth information embedded in RGBD images
unlocks 3D potential from a singular view, simplifying NVS. The widespread
availability of compact, affordable stereo cameras, and even LiDARs in
contemporary devices like smartphones, makes capturing RGBD images more
accessible than ever. In our method, we convert an RGBD image into a point
cloud and render it from a different viewpoint, then formulate the NVS task
into an image translation problem. We leveraged generative adversarial networks
to style-transfer the rendered image, achieving a result similar to a
photograph taken from the new perspective. We explore both unsupervised
learning using CycleGAN and supervised learning with Pix2Pix, and demonstrate
the qualitative results. Our method circumvents the limitations of traditional
multi-image techniques, holding significant promise for practical, real-time
applications in NVS.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01070" title="Abstract">arXiv:2311.01070</a> [<a href="/pdf/2311.01070" title="Download PDF">pdf</a>, <a href="/format/2311.01070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DistilWhisper: Efficient Distillation of Multi-task Speech Models via  Language-Specific Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferraz%2C+T+P">Thomas Palmeira Ferraz</a>, 
<a href="/search/cs?searchtype=author&query=Boito%2C+M+Z">Marcely Zanon Boito</a>, 
<a href="/search/cs?searchtype=author&query=Brun%2C+C">Caroline Brun</a>, 
<a href="/search/cs?searchtype=author&query=Nikoulina%2C+V">Vassilina Nikoulina</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE ICASSP 2024 in September 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Whisper is a multitask and multilingual speech model covering 99 languages.
It yields commendable automatic speech recognition (ASR) results in a subset of
its covered languages, but the model still under-performs on a non-negligible
number of under-represented languages, a problem exacerbated in smaller model
versions. In this work, we propose DistilWhisper, an approach able to bridge
the performance gap in ASR for these languages while retaining the advantages
of multitask and multilingual capabilities. Our approach involves two key
strategies: lightweight modular ASR fine-tuning of whisper-small using
language-specific experts, and knowledge distillation from whisper-large-v2.
This dual approach allows us to effectively boost ASR performance while keeping
the robustness inherited from the multitask and multilingual pre-training.
Results demonstrate that our approach is more effective than standard
fine-tuning or LoRA adapters, boosting performance in the targeted languages
for both in- and out-of-domain test sets, while introducing only a negligible
parameter overhead at inference.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01073" title="Abstract">arXiv:2311.01073</a> [<a href="/pdf/2311.01073" title="Download PDF">pdf</a>, <a href="/format/2311.01073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fourier Analysis of Signals on Directed Acyclic Graphs (DAG) Using Graph  Zero-Padding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stankovic%2C+L">Ljubisa Stankovic</a>, 
<a href="/search/cs?searchtype=author&query=Dakovic%2C+M">Milos Dakovic</a>, 
<a href="/search/cs?searchtype=author&query=Bardi%2C+A+B">Ali Bagheri Bardi</a>, 
<a href="/search/cs?searchtype=author&query=Brajovic%2C+M">Milos Brajovic</a>, 
<a href="/search/cs?searchtype=author&query=Stankovic%2C+I">Isidora Stankovic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Directed acyclic graphs (DAGs) are used for modeling causal relationships,
dependencies, and flows in various systems. However, spectral analysis becomes
impractical in this setting because the eigendecomposition of the adjacency
matrix yields all eigenvalues equal to zero. This inherent property of DAGs
results in an inability to differentiate between frequency components of
signals on such graphs. This problem can be addressed by adding edges in DAG.
However, this approach changes the physics of the considered problem. To
address this limitation, we propose a graph zero-padding approach. This
approach involves augmenting the original DAG with additional vertices that are
connected to the existing structure. The added vertices are characterized by
signal values set to zero. The proposed technique enables the spectral
evaluation of system outputs on DAGs, that is the computation of vertex-domain
convolution without the adverse effects of aliasing due to changes in graph
structure.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01075" title="Abstract">arXiv:2311.01075</a> [<a href="/pdf/2311.01075" title="Download PDF">pdf</a>, <a href="/format/2311.01075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Modules with Temporal Attention for Multi-Task Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lan%2C+S">Siming Lan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+Q">Qi Yi</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiaming Guo</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Shaohui Peng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yunkai Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruizhi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zidong Du</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xishan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Ling Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yunji Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted at NeurIPS 2023 as a poster
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In the field of multi-task reinforcement learning, the modular principle,
which involves specializing functionalities into different modules and
combining them appropriately, has been widely adopted as a promising approach
to prevent the negative transfer problem that performance degradation due to
conflicts between tasks. However, most of the existing multi-task RL methods
only combine shared modules at the task level, ignoring that there may be
conflicts within the task. In addition, these methods do not take into account
that without constraints, some modules may learn similar functions, resulting
in restricting the model's expressiveness and generalization capability of
modular methods. In this paper, we propose the Contrastive Modules with
Temporal Attention(CMTA) method to address these limitations. CMTA constrains
the modules to be different from each other by contrastive learning and
combining shared modules at a finer granularity than the task level with
temporal attention, alleviating the negative transfer within the task and
improving the generalization ability and the performance for multi-task RL. We
conducted the experiment on Meta-World, a multi-task RL benchmark containing
various robotics manipulation tasks. Experimental results show that CMTA
outperforms learning each task individually for the first time and achieves
substantial performance improvements over the baselines.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01077" title="Abstract">arXiv:2311.01077</a> [<a href="/pdf/2311.01077" title="Download PDF">pdf</a>, <a href="/ps/2311.01077" title="Download PostScript">ps</a>, <a href="/format/2311.01077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Conflict-Free Cuts: Algorithms and Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rauch%2C+J">Johannes Rauch</a>, 
<a href="/search/cs?searchtype=author&query=Rautenbach%2C+D">Dieter Rautenbach</a>, 
<a href="/search/cs?searchtype=author&query=Souza%2C+U+S">U&#xe9;verton S. Souza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">One way to define the Matching Cut problem is: Given a graph $G$, is there an
edge-cut $M$ of $G$ such that $M$ is an independent set in the line graph of
$G$? We propose the more general Conflict-Free Cut problem: Together with the
graph $G$, we are given a so-called conflict graph $\hat{G}$ on the edges of
$G$, and we ask for an edge-cutset $M$ of $G$ that is independent in $\hat{G}$.
Since conflict-free settings are popular generalizations of classical
optimization problems and Conflict-Free Cut was not considered in the
literature so far, we start the study of the problem. We show that the problem
is $\textsf{NP}$-complete even when the maximum degree of $G$ is 5 and
$\hat{G}$ is 1-regular. The same reduction implies an exponential lower bound
on the solvability based on the Exponential Time Hypothesis. We also give
parameterized complexity results: We show that the problem is fixed-parameter
tractable with the vertex cover number of $G$ as a parameter, and we show
$\textsf{W[1]}$-hardness even when $G$ has a feedback vertex set of size one,
and the clique cover number of $\hat{G}$ is the parameter. Since the clique
cover number of $\hat{G}$ is an upper bound on the independence number of
$\hat{G}$ and thus the solution size, this implies $\textsf{W[1]}$-hardness
when parameterized by the cut size. We list polynomial-time solvable cases and
interesting open problems. At last, we draw a connection to a symmetric variant
of SAT.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01078" title="Abstract">arXiv:2311.01078</a> [<a href="/pdf/2311.01078" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-agent robotic systems and exploration algorithms: Applications for  data collection in construction sites
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prieto%2C+S+A">Samuel A. Prieto</a>, 
<a href="/search/cs?searchtype=author&query=Giakoumidis%2C+N">Nikolaos Giakoumidis</a>, 
<a href="/search/cs?searchtype=author&query=de+Soto%2C+B+G">Borja Garcia de Soto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">The construction industry has been notoriously slow to adopt new technology
and embrace automation. This has resulted in lower efficiency and productivity
compared to other industries where automation has been widely adopted. However,
recent advancements in robotics and artificial intelligence offer a potential
solution to this problem. In this study, a methodology is proposed to integrate
multi-robotic systems in construction projects with the aim of increasing
efficiency and productivity. The proposed approach involves the use of multiple
robot and human agents working collaboratively to complete a construction task.
The methodology was tested through a case study that involved 3D digitization
of a small, occluded space using two robots and one human agent. The results
show that integrating multi-agent robotic systems in construction can
effectively overcome challenges and complete tasks efficiently. The
implications of this study suggest that multi-agent robotic systems could
revolutionize the industry.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01079" title="Abstract">arXiv:2311.01079</a> [<a href="/pdf/2311.01079" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experiencing Urban Air Mobility: How Passengers evaluate a simulated  flight with an Air Taxi
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Papenfuss%2C+A">Anne Papenfuss</a>, 
<a href="/search/eess?searchtype=author&query=Stolz%2C+M">Maria Stolz</a>, 
<a href="/search/eess?searchtype=author&query=Riedesel%2C+N">Nele Riedesel</a>, 
<a href="/search/eess?searchtype=author&query=Dunkel%2C+F">Franziska Dunkel</a>, 
<a href="/search/eess?searchtype=author&query=Ernst%2C+J+M">Johannes Maria Ernst</a>, 
<a href="/search/eess?searchtype=author&query=Laudien%2C+T">Tim Laudien</a>, 
<a href="/search/eess?searchtype=author&query=Lenz%2C+H">Helge Lenz</a>, 
<a href="/search/eess?searchtype=author&query=Korkmaz%2C+A">Aytek Korkmaz</a>, 
<a href="/search/eess?searchtype=author&query=End%2C+A">Albert End</a>, 
<a href="/search/eess?searchtype=author&query=Schuchardt%2C+B+I">Bianca Isabella Schuchardt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 12 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">For the successful development and implementation of novel concepts and
technology, the acceptance of potential users is crucial. Therefore, within the
project HorizonUAM, we investigated passengers' acceptance of air taxis. One
challenge is that not many people have real experiences with urban air mobility
(UAM) at the moment and thus requirements formulated by potential users refer
to rather abstract concepts. To allow participants to gain realistic
impressions of UAM concepts, a Mixed Reality Air Taxi Simulator was set up. It
allows participants to experience an inner-city business shuttle flight. A
study with 30 participants assessed the information needs and the influence of
another person on board on wellbeing in nominal situations (experiment 1) as
well as one non-nominal situation (experiment 2). For the latter, participants
experienced a re-routing of the flight due to an unavailability of landing
sites at the vertidrome. During and after the flights, participants answered
questionnaires and extensive interviews were conducted. The study produced
first empirical data on relevant factors regarding interaction, information
needs and comfort within an air taxi. The findings show that passengers want to
be informed about intentions of the vehicle. The presence of a steward on board
is not necessary but can increase wellbeing especially during non-nominal
situations.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01090" title="Abstract">arXiv:2311.01090</a> [<a href="/pdf/2311.01090" title="Download PDF">pdf</a>, <a href="/format/2311.01090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Infusion: Internal Diffusion for Video Inpainting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cherel%2C+N">Nicolas Cherel</a>, 
<a href="/search/cs?searchtype=author&query=Almansa%2C+A">Andr&#xe9;s Almansa</a>, 
<a href="/search/cs?searchtype=author&query=Gousseau%2C+Y">Yann Gousseau</a>, 
<a href="/search/cs?searchtype=author&query=Newson%2C+A">Alasdair Newson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video inpainting is the task of filling a desired region in a video in a
visually convincing manner. It is a very challenging task due to the high
dimensionality of the signal and the temporal consistency required for
obtaining convincing results. Recently, diffusion models have shown impressive
results in modeling complex data distributions, including images and videos.
Diffusion models remain nonetheless very expensive to train and perform
inference with, which strongly restrict their application to video. We show
that in the case of video inpainting, thanks to the highly auto-similar nature
of videos, the training of a diffusion model can be restricted to the video to
inpaint and still produce very satisfying results. This leads us to adopt an
internal learning approch, which also allows for a greatly reduced network
size. We call our approach "Infusion": an internal learning algorithm for video
inpainting through diffusion. Due to our frugal network, we are able to propose
the first video inpainting approach based purely on diffusion. Other methods
require supporting elements such as optical flow estimation, which limits their
performance in the case of dynamic textures for example. We introduce a new
method for efficient training and inference of diffusion models in the context
of internal learning. We split the diffusion process into different learning
intervals which greatly simplifies the learning steps. We show qualititative
and quantitative results, demonstrating that our method reaches
state-of-the-art performance, in particular in the case of dynamic backgrounds
and textures.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01091" title="Abstract">arXiv:2311.01091</a> [<a href="/pdf/2311.01091" title="Download PDF">pdf</a>, <a href="/format/2311.01091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enriching Phrases with Coupled Pixel and Object Contexts for Panoptic  Narrative Grounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hui%2C+T">Tianrui Hui</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zihan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Junshi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xiaoming Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xiaolin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jiao Dai</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jizhong Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Si Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IJCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Panoptic narrative grounding (PNG) aims to segment things and stuff objects
in an image described by noun phrases of a narrative caption. As a multimodal
task, an essential aspect of PNG is the visual-linguistic interaction between
image and caption. The previous two-stage method aggregates visual contexts
from offline-generated mask proposals to phrase features, which tend to be
noisy and fragmentary. The recent one-stage method aggregates only pixel
contexts from image features to phrase features, which may incur semantic
misalignment due to lacking object priors. To realize more comprehensive
visual-linguistic interaction, we propose to enrich phrases with coupled pixel
and object contexts by designing a Phrase-Pixel-Object Transformer Decoder
(PPO-TD), where both fine-grained part details and coarse-grained entity clues
are aggregated to phrase features. In addition, we also propose a PhraseObject
Contrastive Loss (POCL) to pull closer the matched phrase-object pairs and push
away unmatched ones for aggregating more precise object contexts from more
phrase-relevant object tokens. Extensive experiments on the PNG benchmark show
our method achieves new state-of-the-art performance with large margins.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01092" title="Abstract">arXiv:2311.01092</a> [<a href="/pdf/2311.01092" title="Download PDF">pdf</a>, <a href="/format/2311.01092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning A Multi-Task Transformer Via Unified And Customized Instruction  Tuning For Chest Radiograph Interpretation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lijian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+Z">Ziyu Ni</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinglong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaosong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaoting Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The emergence of multi-modal deep learning models has made significant
impacts on clinical applications in the last decade. However, the majority of
models are limited to single-tasking, without considering disease diagnosis is
indeed a multi-task procedure. Here, we demonstrate a unified transformer model
specifically designed for multi-modal clinical tasks by incorporating
customized instruction tuning. We first compose a multi-task training dataset
comprising 13.4 million instruction and ground-truth pairs (with approximately
one million radiographs) for the customized tuning, involving both image- and
pixel-level tasks. Thus, we can unify the various vision-intensive tasks in a
single training framework with homogeneous model inputs and outputs to increase
clinical interpretability in one reading. Finally, we demonstrate the overall
superior performance of our model compared to prior arts on various chest X-ray
benchmarks across multi-tasks in both direct inference and finetuning settings.
Three radiologists further evaluate the generated reports against the recorded
ones, which also exhibit the enhanced explainability of our multi-task model.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01094" title="Abstract">arXiv:2311.01094</a> [<a href="/pdf/2311.01094" title="Download PDF">pdf</a>, <a href="/format/2311.01094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Max $s,t$-Flow Oracles and Negative Cycle Detection in Planar Digraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karczmarz%2C+A">Adam Karczmarz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended abstract to appear in SODA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study the maximum $s,t$-flow oracle problem on planar directed graphs
where the goal is to design a data structure answering max $s,t$-flow value (or
equivalently, min $s,t$-cut value) queries for arbitrary source-target pairs
$(s,t)$. For the case of polynomially bounded integer edge capacities, we
describe an exact max $s,t$-flow oracle with truly subquadratic space and
preprocessing, and sublinear query time. Moreover, if
$(1-\epsilon)$-approximate answers are acceptable, we obtain a static oracle
with near-linear preprocessing and $\tilde{O}(n^{3/4})$ query time and a
dynamic oracle supporting edge capacity updates and queries in
$\tilde{O}(n^{6/7})$ worst-case time.
<br />To the best of our knowledge, for directed planar graphs, no (approximate)
max $s,t$-flow oracles have been described even in the unweighted case, and
only trivial tradeoffs involving either no preprocessing or precomputing all
the $n^2$ possible answers have been known.
<br />One key technical tool we develop on the way is a sublinear (in the number of
edges) algorithm for finding a negative cycle in so-called dense distance
graphs. By plugging it in earlier frameworks, we obtain improved bounds for
other fundamental problems on planar digraphs. In particular, we show: (1) a
deterministic $O(n\log(nC))$ time algorithm for negatively-weighted SSSP in
planar digraphs with integer edge weights at least $-C$. This improves upon the
previously known bounds in the important case of weights polynomial in $n$, and
(2) an improved $O(n\log{n})$ bound on finding a perfect matching in a
bipartite planar graph.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01106" title="Abstract">arXiv:2311.01106</a> [<a href="/pdf/2311.01106" title="Download PDF">pdf</a>, <a href="/format/2311.01106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In Defense of Softmax Parametrization for Calibrated and Consistent  Learning to Defer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yuzhou Cao</a>, 
<a href="/search/cs?searchtype=author&query=Mozannar%2C+H">Hussein Mozannar</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+L">Lei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Hongxin Wei</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+B">Bo An</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Enabling machine learning classifiers to defer their decision to a downstream
expert when the expert is more accurate will ensure improved safety and
performance. This objective can be achieved with the learning-to-defer
framework which aims to jointly learn how to classify and how to defer to the
expert. In recent studies, it has been theoretically shown that popular
estimators for learning to defer parameterized with softmax provide unbounded
estimates for the likelihood of deferring which makes them uncalibrated.
However, it remains unknown whether this is due to the widely used softmax
parameterization and if we can find a softmax-based estimator that is both
statistically consistent and possesses a valid probability estimator. In this
work, we first show that the cause of the miscalibrated and unbounded estimator
in prior literature is due to the symmetric nature of the surrogate losses used
and not due to softmax. We then propose a novel statistically consistent
asymmetric softmax-based surrogate loss that can produce valid estimates
without the issue of unboundedness. We further analyze the non-asymptotic
properties of our method and empirically validate its performance and
calibration on benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01107" title="Abstract">arXiv:2311.01107</a> [<a href="/pdf/2311.01107" title="Download PDF">pdf</a>, <a href="/format/2311.01107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GREEMA: Proposal and Experimental Verification of Growing Robot by  Eating Environmental MAterial for Landslide Disaster
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsunoda%2C+Y">Yusuke Tsunoda</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+Y">Yuya Sato</a>, 
<a href="/search/cs?searchtype=author&query=Osuka%2C+K">Koichi Osuka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In areas that are inaccessible to humans, such as the lunar surface and
landslide sites, there is a need for multiple autonomous mobile robot systems
that can replace human workers. In particular, at landslide sites such as river
channel blockages, robots are required to remove water and sediment from the
site as soon as possible. Conventionally, several construction machines have
been deployed to the site for civil engineering work. However, because of the
large size and weight of conventional construction equipment, it is difficult
to move multiple units of construction equipment to the site, resulting in
significant transportation costs and time. To solve such problems, this study
proposes a novel growing robot by eating environmental material called GREEMA,
which is lightweight and compact during transportation, but can function by
eating on environmental materials once it arrives at the site. GREEMA actively
takes in environmental materials such as water and sediment, uses them as its
structure, and removes them by moving itself. In this paper, we developed and
experimentally verified two types of GREEMAs. First, we developed a fin-type
swimming robot that passively takes water into its body using a water-absorbing
polymer and forms a body to express its swimming function. Second, we
constructed an arm-type robot that eats soil to increase the rigidity of its
body. We discuss the results of these two experiments from the viewpoint of
Explicit-Implicit control and describe the design theory of GREEMA.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01108" title="Abstract">arXiv:2311.01108</a> [<a href="/pdf/2311.01108" title="Download PDF">pdf</a>, <a href="/format/2311.01108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noise-Robust Fine-Tuning of Pretrained Language Models via External  Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Song Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhen Tan</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Ruocheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jundong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP Findings 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Adopting a two-stage paradigm of pretraining followed by fine-tuning,
Pretrained Language Models (PLMs) have achieved substantial advancements in the
field of natural language processing. However, in real-world scenarios, data
labels are often noisy due to the complex annotation process, making it
essential to develop strategies for fine-tuning PLMs with such noisy labels. To
this end, we introduce an innovative approach for fine-tuning PLMs using noisy
labels, which incorporates the guidance of Large Language Models (LLMs) like
ChatGPT. This guidance assists in accurately distinguishing between clean and
noisy samples and provides supplementary information beyond the noisy labels,
thereby boosting the learning process during fine-tuning PLMs. Extensive
experiments on synthetic and real-world noisy datasets further demonstrate the
superior advantages of our framework over the state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01111" title="Abstract">arXiv:2311.01111</a> [<a href="/pdf/2311.01111" title="Download PDF">pdf</a>, <a href="/format/2311.01111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> H-NeXt: The next step towards roto-translation invariant networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karella%2C+T">Tomas Karella</a>, 
<a href="/search/cs?searchtype=author&query=Sroubek%2C+F">Filip Sroubek</a>, 
<a href="/search/cs?searchtype=author&query=Flusser%2C+J">Jan Flusser</a>, 
<a href="/search/cs?searchtype=author&query=Blazek%2C+J">Jan Blazek</a>, 
<a href="/search/cs?searchtype=author&query=Kosik%2C+V">Vasek Kosik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in British Machine Vision Conference 2023 (BMVC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The widespread popularity of equivariant networks underscores the
significance of parameter efficient models and effective use of training data.
At a time when robustness to unseen deformations is becoming increasingly
important, we present H-NeXt, which bridges the gap between equivariance and
invariance. H-NeXt is a parameter-efficient roto-translation invariant network
that is trained without a single augmented image in the training set. Our
network comprises three components: an equivariant backbone for learning
roto-translation independent features, an invariant pooling layer for
discarding roto-translation information, and a classification layer. H-NeXt
outperforms the state of the art in classification on unaugmented training sets
and augmented test sets of MNIST and CIFAR-10.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01113" title="Abstract">arXiv:2311.01113</a> [<a href="/pdf/2311.01113" title="Download PDF">pdf</a>, <a href="/format/2311.01113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Coin Selection Algorithms in UTXO-based Blockchains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramezan%2C+G">Gholamreza Ramezan</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+M">Manvir Schneider</a>, 
<a href="/search/cs?searchtype=author&query=McCann%2C+M">Mel McCann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Coin selection algorithms are a fundamental component of blockchain
technology. In this paper, we present a comprehensive review of the existing
coin selection algorithms utilized in unspent transaction output (UTXO)-based
blockchains. We provide a list of the desired objectives and categorize
existing algorithms into three types: primitive, basic, and advanced
algorithms. This allows for a structured understanding of their functionalities
and limitations. We also evaluate the performance of existing coin selection
algorithms. The aim of this paper is to provide system researchers and
developers with a concrete view of the current design landscape.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01115" title="Abstract">arXiv:2311.01115</a> [<a href="/pdf/2311.01115" title="Download PDF">pdf</a>, <a href="/format/2311.01115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamically Maintaining the Persistent Homology of Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=di+Montesano%2C+S+C">Sebastiano Cultrera di Montesano</a>, 
<a href="/search/cs?searchtype=author&query=Edelsbrunner%2C+H">Herbert Edelsbrunner</a>, 
<a href="/search/cs?searchtype=author&query=Henzinger%2C+M">Monika Henzinger</a>, 
<a href="/search/cs?searchtype=author&query=Ost%2C+L">Lara Ost</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at SODA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">We present a dynamic data structure for maintaining the persistent homology
of a time series of real numbers. The data structure supports local operations,
including the insertion and deletion of an item and the cutting and
concatenating of lists, each in time $O(\log n + k)$, in which $n$ counts the
critical items and $k$ the changes in the augmented persistence diagram. To
achieve this, we design a tailor-made tree structure with an unconventional
representation, referred to as banana tree, which may be useful in its own
right.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01117" title="Abstract">arXiv:2311.01117</a> [<a href="/pdf/2311.01117" title="Download PDF">pdf</a>, <a href="/format/2311.01117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cheating Depth: Enhancing 3D Surface Anomaly Detection via Depth  Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zavrtanik%2C+V">Vitjan Zavrtanik</a>, 
<a href="/search/cs?searchtype=author&query=Kristan%2C+M">Matej Kristan</a>, 
<a href="/search/cs?searchtype=author&query=Sko%C4%8Daj%2C+D">Danijel Sko&#x10d;aj</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">RGB-based surface anomaly detection methods have advanced significantly.
However, certain surface anomalies remain practically invisible in RGB alone,
necessitating the incorporation of 3D information. Existing approaches that
employ point-cloud backbones suffer from suboptimal representations and reduced
applicability due to slow processing. Re-training RGB backbones, designed for
faster dense input processing, on industrial depth datasets is hindered by the
limited availability of sufficiently large datasets. We make several
contributions to address these challenges. (i) We propose a novel Depth-Aware
Discrete Autoencoder (DADA) architecture, that enables learning a general
discrete latent space that jointly models RGB and 3D data for 3D surface
anomaly detection. (ii) We tackle the lack of diverse industrial depth datasets
by introducing a simulation process for learning informative depth features in
the depth encoder. (iii) We propose a new surface anomaly detection method
3DSR, which outperforms all existing state-of-the-art on the challenging
MVTec3D anomaly detection benchmark, both in terms of accuracy and processing
speed. The experimental results validate the effectiveness and efficiency of
our approach, highlighting the potential of utilizing depth information for
improved surface anomaly detection.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01118" title="Abstract">arXiv:2311.01118</a> [<a href="/pdf/2311.01118" title="Download PDF">pdf</a>, <a href="/format/2311.01118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI for Interpretable Chemistry: Predicting Radical Mechanistic Pathways  via Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tavakoli%2C+M">Mohammadamin Tavakoli</a>, 
<a href="/search/cs?searchtype=author&query=Chiu%2C+Y+T+T">Yin Ting T.Chiu</a>, 
<a href="/search/cs?searchtype=author&query=Shmakov%2C+A">Alexander Shmakov</a>, 
<a href="/search/cs?searchtype=author&query=Carlton%2C+A+M">Ann Marie Carlton</a>, 
<a href="/search/cs?searchtype=author&query=Van+Vranken%2C+D">David Van Vranken</a>, 
<a href="/search/cs?searchtype=author&query=Baldi%2C+P">Pierre Baldi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Chemical Physics (physics.chem-ph)

</div>
<p class="mathjax">Deep learning-based reaction predictors have undergone significant
architectural evolution. However, their reliance on reactions from the US
Patent Office results in a lack of interpretable predictions and limited
generalization capability to other chemistry domains, such as radical and
atmospheric chemistry. To address these challenges, we introduce a new reaction
predictor system, RMechRP, that leverages contrastive learning in conjunction
with mechanistic pathways, the most interpretable representation of chemical
reactions. Specifically designed for radical reactions, RMechRP provides
different levels of interpretation of chemical reactions. We develop and train
multiple deep-learning models using RMechDB, a public database of radical
reactions, to establish the first benchmark for predicting radical reactions.
Our results demonstrate the effectiveness of RMechRP in providing accurate and
interpretable predictions of radical reactions, and its potential for various
applications in atmospheric chemistry.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01122" title="Abstract">arXiv:2311.01122</a> [<a href="/pdf/2311.01122" title="Download PDF">pdf</a>, <a href="/format/2311.01122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Joint Source-Channel Coding for DNA Image Storage: A Novel Approach  with Enhanced Error Resilience and Biological Constraint Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenfeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+L">Luping Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kun Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
<p class="mathjax">In the current era, DeoxyriboNucleic Acid (DNA) based data storage emerges as
an intriguing approach, garnering substantial academic interest and
investigation. This paper introduces a novel deep joint source-channel coding
(DJSCC) scheme for DNA image storage, designated as DJSCC-DNA. This paradigm
distinguishes itself from conventional DNA storage techniques through three key
modifications: 1) it employs advanced deep learning methodologies, employing
convolutional neural networks for DNA encoding and decoding processes; 2) it
seamlessly integrates DNA polymerase chain reaction (PCR) amplification into
the network architecture, thereby augmenting data recovery precision; and 3) it
restructures the loss function by targeting biological constraints for
optimization. The performance of the proposed model is demonstrated via
numerical results from specific channel testing, suggesting that it surpasses
conventional deep learning methodologies in terms of peak signal-to-noise ratio
(PSNR) and structural similarity index (SSIM). Additionally, the model
effectively ensures positive constraints on both homopolymer run-length and GC
content.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01125" title="Abstract">arXiv:2311.01125</a> [<a href="/pdf/2311.01125" title="Download PDF">pdf</a>, <a href="/format/2311.01125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bi-Preference Learning Heterogeneous Hypergraph Networks for  Session-based Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaokun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+F">Fenglong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hongfei Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by ACM TOIS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Session-based recommendation intends to predict next purchased items based on
anonymous behavior sequences. Numerous economic studies have revealed that item
price is a key factor influencing user purchase decisions. Unfortunately,
existing methods for session-based recommendation only aim at capturing user
interest preference, while ignoring user price preference. Actually, there are
primarily two challenges preventing us from accessing price preference.
Firstly, the price preference is highly associated to various item features
(i.e., category and brand), which asks us to mine price preference from
heterogeneous information. Secondly, price preference and interest preference
are interdependent and collectively determine user choice, necessitating that
we jointly consider both price and interest preference for intent modeling. To
handle above challenges, we propose a novel approach Bi-Preference Learning
Heterogeneous Hypergraph Networks (BiPNet) for session-based recommendation.
Specifically, the customized heterogeneous hypergraph networks with a
triple-level convolution are devised to capture user price and interest
preference from heterogeneous features of items. Besides, we develop a
Bi-Preference Learning schema to explore mutual relations between price and
interest preference and collectively learn these two preferences under the
multi-task learning architecture. Extensive experiments on multiple public
datasets confirm the superiority of BiPNet over competitive baselines.
Additional research also supports the notion that the price is crucial for the
task.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01129" title="Abstract">arXiv:2311.01129</a> [<a href="/pdf/2311.01129" title="Download PDF">pdf</a>, <a href="/ps/2311.01129" title="Download PostScript">ps</a>, <a href="/format/2311.01129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained Submodular Maximization via New Bounds for DR-Submodular  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Buchbinder%2C+N">Niv Buchbinder</a>, 
<a href="/search/cs?searchtype=author&query=Feldman%2C+M">Moran Feldman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Submodular maximization under various constraints is a fundamental problem
studied continuously, in both computer science and operations research, since
the late $1970$'s. A central technique in this field is to approximately
optimize the multilinear extension of the submodular objective, and then round
the solution. The use of this technique requires a solver able to approximately
maximize multilinear extensions. Following a long line of work, Buchbinder and
Feldman (2019) described such a solver guaranteeing $0.385$-approximation for
down-closed constraints, while Oveis Gharan and Vondr\'ak (2011) showed that no
solver can guarantee better than $0.478$-approximation. In this paper, we
present a solver guaranteeing $0.401$-approximation, which significantly
reduces the gap between the best known solver and the inapproximability result.
The design and analysis of our solver are based on a novel bound that we prove
for DR-submodular functions. This bound improves over a previous bound due to
Feldman et al. (2011) that is used by essentially all state-of-the-art results
for constrained maximization of general submodular/DR-submodular functions.
Hence, we believe that our new bound is likely to find many additional
applications in related problems, and to be a key component for further
improvement.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01130" title="Abstract">arXiv:2311.01130</a> [<a href="/pdf/2311.01130" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A deep learning experiment for semantic segmentation of overlapping  characters in palimpsests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perino%2C+M">Michela Perino</a>, 
<a href="/search/cs?searchtype=author&query=Ginolfi%2C+M">Michele Ginolfi</a>, 
<a href="/search/cs?searchtype=author&query=Felici%2C+A+C">Anna Candida Felici</a>, 
<a href="/search/cs?searchtype=author&query=Rosellini%2C+M">Michela Rosellini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Palimpsests refer to historical manuscripts where erased writings have been
partially covered by the superimposition of a second writing. By employing
imaging techniques, e.g., multispectral imaging, it becomes possible to
identify features that are imperceptible to the naked eye, including faded and
erased inks. When dealing with overlapping inks, Artificial Intelligence
techniques can be utilized to disentangle complex nodes of overlapping letters.
In this work, we propose deep learning-based semantic segmentation as a method
for identifying and segmenting individual letters in overlapping characters.
The experiment was conceived as a proof of concept, focusing on the palimpsests
of the Ars Grammatica by Prisciano as a case study. Furthermore, caveats and
prospects of our approach combined with multispectral imaging are also
discussed.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01133" title="Abstract">arXiv:2311.01133</a> [<a href="/pdf/2311.01133" title="Download PDF">pdf</a>, <a href="/format/2311.01133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Bayesian optimization framework for the automatic tuning of MPC-based  shared controllers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+der+Horst%2C+A">Anne van der Horst</a>, 
<a href="/search/cs?searchtype=author&query=Meere%2C+B">Bas Meere</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamoorthy%2C+D">Dinesh Krishnamoorthy</a>, 
<a href="/search/cs?searchtype=author&query=Bakker%2C+S">Saray Bakker</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Vrande%2C+B">Bram van de Vrande</a>, 
<a href="/search/cs?searchtype=author&query=Stoutjesdijk%2C+H">Henry Stoutjesdijk</a>, 
<a href="/search/cs?searchtype=author&query=Alonso%2C+M">Marco Alonso</a>, 
<a href="/search/cs?searchtype=author&query=Torta%2C+E">Elena Torta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a Bayesian optimization framework for the automatic
tuning of shared controllers which are defined as a Model Predictive Control
(MPC) problem. The proposed framework includes the design of performance
metrics as well as the representation of user inputs for simulation-based
optimization. The framework is applied to the optimization of a shared
controller for an Image Guided Therapy robot. VR-based user experiments confirm
the increase in performance of the automatically tuned MPC shared controller
with respect to a hand-tuned baseline version as well as its generalization
ability.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01135" title="Abstract">arXiv:2311.01135</a> [<a href="/pdf/2311.01135" title="Download PDF">pdf</a>, <a href="/format/2311.01135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating QM1B with PySCF$_{\text{IPU}}$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mathiasen%2C+A">Alexander Mathiasen</a>, 
<a href="/search/cs?searchtype=author&query=Helal%2C+H">Hatem Helal</a>, 
<a href="/search/cs?searchtype=author&query=Klaser%2C+K">Kerstin Klaser</a>, 
<a href="/search/cs?searchtype=author&query=Balanca%2C+P">Paul Balanca</a>, 
<a href="/search/cs?searchtype=author&query=Dean%2C+J">Josef Dean</a>, 
<a href="/search/cs?searchtype=author&query=Luschi%2C+C">Carlo Luschi</a>, 
<a href="/search/cs?searchtype=author&query=Beaini%2C+D">Dominique Beaini</a>, 
<a href="/search/cs?searchtype=author&query=Fitzgibbon%2C+A">Andrew Fitzgibbon</a>, 
<a href="/search/cs?searchtype=author&query=Masters%2C+D">Dominic Masters</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures. NeurIPS 2023 Track Datasets and Benchmarks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Chemical Physics (physics.chem-ph)

</div>
<p class="mathjax">The emergence of foundation models in Computer Vision and Natural Language
Processing have resulted in immense progress on downstream tasks. This progress
was enabled by datasets with billions of training examples. Similar benefits
are yet to be unlocked for quantum chemistry, where the potential of deep
learning is constrained by comparatively small datasets with 100k to 20M
training examples. These datasets are limited in size because the labels are
computed using the accurate (but computationally demanding) predictions of
Density Functional Theory (DFT). Notably, prior DFT datasets were created using
CPU supercomputers without leveraging hardware acceleration. In this paper, we
take a first step towards utilising hardware accelerators by introducing the
data generator PySCF$_{\text{IPU}}$ using Intelligence Processing Units (IPUs).
This allowed us to create the dataset QM1B with one billion training examples
containing 9-11 heavy atoms. We demonstrate that a simple baseline neural
network (SchNet 9M) improves its performance by simply increasing the amount of
training data without additional inductive biases. To encourage future
researchers to use QM1B responsibly, we highlight several limitations of QM1B
and emphasise the low-resolution of our DFT options, which also serves as
motivation for even larger, more accurate datasets. Code and dataset are
available on Github: <a href="http://github.com/graphcore-research/pyscf-ipu">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01138" title="Abstract">arXiv:2311.01138</a> [<a href="/pdf/2311.01138" title="Download PDF">pdf</a>, <a href="/format/2311.01138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AeroPath: An airway segmentation benchmark dataset with challenging  pathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=St%C3%B8verud%2C+K">Karen-Helene St&#xf8;verud</a>, 
<a href="/search/cs?searchtype=author&query=Bouget%2C+D">David Bouget</a>, 
<a href="/search/cs?searchtype=author&query=Pedersen%2C+A">Andre Pedersen</a>, 
<a href="/search/cs?searchtype=author&query=Leira%2C+H+O">H&#xe5;kon Olav Leira</a>, 
<a href="/search/cs?searchtype=author&query=Lang%C3%B8%2C+T">Thomas Lang&#xf8;</a>, 
<a href="/search/cs?searchtype=author&query=Hofstad%2C+E+F">Erlend Fagertun Hofstad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures, submitted to Scientific Reports
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">To improve the prognosis of patients suffering from pulmonary diseases, such
as lung cancer, early diagnosis and treatment are crucial. The analysis of CT
images is invaluable for diagnosis, whereas high quality segmentation of the
airway tree are required for intervention planning and live guidance during
bronchoscopy. Recently, the Multi-domain Airway Tree Modeling (ATM'22)
challenge released a large dataset, both enabling training of deep-learning
based models and bringing substantial improvement of the state-of-the-art for
the airway segmentation task. However, the ATM'22 dataset includes few patients
with severe pathologies affecting the airway tree anatomy. In this study, we
introduce a new public benchmark dataset (AeroPath), consisting of 27 CT images
from patients with pathologies ranging from emphysema to large tumors, with
corresponding trachea and bronchi annotations. Second, we present a multiscale
fusion design for automatic airway segmentation. Models were trained on the
ATM'22 dataset, tested on the AeroPath dataset, and further evaluated against
competitive open-source methods. The same performance metrics as used in the
ATM'22 challenge were used to benchmark the different considered approaches.
Lastly, an open web application is developed, to easily test the proposed model
on new data. The results demonstrated that our proposed architecture predicted
topologically correct segmentations for all the patients included in the
AeroPath dataset. The proposed method is robust and able to handle various
anomalies, down to at least the fifth airway generation. In addition, the
AeroPath dataset, featuring patients with challenging pathologies, will
contribute to development of new state-of-the-art methods. The AeroPath dataset
and the web application are made openly available.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01139" title="Abstract">arXiv:2311.01139</a> [<a href="/pdf/2311.01139" title="Download PDF">pdf</a>, <a href="/format/2311.01139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Add and Thin: Diffusion for Temporal Point Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%BCdke%2C+D">David L&#xfc;dke</a>, 
<a href="/search/cs?searchtype=author&query=Bilo%C5%A1%2C+M">Marin Bilo&#x161;</a>, 
<a href="/search/cs?searchtype=author&query=Shchur%2C+O">Oleksandr Shchur</a>, 
<a href="/search/cs?searchtype=author&query=Lienen%2C+M">Marten Lienen</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCnnemann%2C+S">Stephan G&#xfc;nnemann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Autoregressive neural networks within the temporal point process (TPP)
framework have become the standard for modeling continuous-time event data.
Even though these models can expressively capture event sequences in a
one-step-ahead fashion, they are inherently limited for long-term forecasting
applications due to the accumulation of errors caused by their sequential
nature. To overcome these limitations, we derive ADD-THIN, a principled
probabilistic denoising diffusion model for TPPs that operates on entire event
sequences. Unlike existing diffusion approaches, ADD-THIN naturally handles
data with discrete and continuous components. In experiments on synthetic and
real-world datasets, our model matches the state-of-the-art TPP models in
density estimation and strongly outperforms them in forecasting.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01145" title="Abstract">arXiv:2311.01145</a> [<a href="/pdf/2311.01145" title="Download PDF">pdf</a>, <a href="/ps/2311.01145" title="Download PostScript">ps</a>, <a href="/format/2311.01145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simpler Distribution Testing with Little Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Canonne%2C+C+L">Cl&#xe9;ment L. Canonne</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J+Q">Joy Qiping Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the 2024 SIAM Symposium on Simplicity in Algorithms (SOSA'24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We consider the question of distribution testing (specifically, uniformity
and closeness testing) in the streaming setting, \ie under stringent memory
constraints. We improve on the results of Diakonikolas, Gouleakis, Kane, and
Rao (2019) by providing considerably simpler algorithms, which remove some
restrictions on the range of parameters and match their lower bounds.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01146" title="Abstract">arXiv:2311.01146</a> [<a href="/pdf/2311.01146" title="Download PDF">pdf</a>, <a href="/format/2311.01146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building for Speech: Designing the Next Generation of Social Robots for  Audio Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Addlesee%2C+A">Angus Addlesee</a>, 
<a href="/search/cs?searchtype=author&query=Papaioannou%2C+I">Ioannis Papaioannou</a>, 
<a href="/search/cs?searchtype=author&query=Lemon%2C+O">Oliver Lemon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Part of WTF 23 workshop proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">There have been incredible advancements in robotics and spoken dialogue
systems (SDSs) over the past few years, yet we still don't find social robots
in public spaces like train stations, shopping malls, or hospital waiting
rooms. In this paper, we argue that early-stage collaboration between robot
designers and SDS researchers is crucial to create social robots that can
legitimately be used in real-world environments. We draw from our experiences
running experiments with social robots, and the surrounding literature, to
highlight recurring issues. Robots need more speakers, more microphones,
quieter motors, and quieter fans to enable human-robot spoken interaction in
the wild and improve accessibility. More robust robot joints are also needed to
limit potential harm to older adults and other more vulnerable groups.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01149" title="Abstract">arXiv:2311.01149</a> [<a href="/pdf/2311.01149" title="Download PDF">pdf</a>, <a href="/format/2311.01149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chinesewebtext: Large-scale high-quality Chinese web text extracted with  effective evaluation model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianghao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jian%2C+P">Pu Jian</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+T">Tengxiao Xi</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+Y">Yidong Yi</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Chenglin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Q">Qianlong Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+G">Guibo Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+C">Chengqing Zong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinqiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiajun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">During the development of large language models (LLMs), the scale and quality
of the pre-training data play a crucial role in shaping LLMs' capabilities. To
accelerate the research of LLMs, several large-scale datasets, such as C4 [1],
Pile [2], RefinedWeb [3] and WanJuan [4], have been released to the public.
However, most of the released corpus focus mainly on English, and there is
still lack of complete tool-chain for extracting clean texts from web data.
Furthermore, fine-grained information of the corpus, e.g. the quality of each
text, is missing. To address these challenges, we propose in this paper a new
complete tool-chain EvalWeb to extract Chinese clean texts from noisy web data.
First, similar to previous work, manually crafted rules are employed to discard
explicit noisy texts from the raw crawled web contents. Second, a well-designed
evaluation model is leveraged to assess the remaining relatively clean data,
and each text is assigned a specific quality score. Finally, we can easily
utilize an appropriate threshold to select the high-quality pre-training data
for Chinese. Using our proposed approach, we release the largest and latest
large-scale high-quality Chinese web text ChineseWebText, which consists of
1.42 TB and each text is associated with a quality score, facilitating the LLM
researchers to choose the data according to the desired quality thresholds. We
also release a much cleaner subset of 600 GB Chinese data with the quality
exceeding 90%.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01150" title="Abstract">arXiv:2311.01150</a> [<a href="/pdf/2311.01150" title="Download PDF">pdf</a>, <a href="/format/2311.01150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting the Knowledge Injection Frameworks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+P">Peng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haobo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+W">Weikang Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Junbo Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures, accepted by EMNLP 2023 Main
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In recent years, large language models (LLMs), such as GPTs, have attained
great impact worldwide. However, how to adapt these LLMs to better suit the
vertical domain-specific tasks by utilizing external knowledge remains not
completely solved. Indeed, there have emerged a few works on this line where
most of them rely on an alignment heuristic that is built to inject the
corresponding knowledge tuple into the associated text sample.
<br />However, despite the promise, we identify a pivotal problem in this work
ubiquitously. Simply put, we find that injecting unaligned (i.e., random)
knowledge tuple into the LLMs achieves comparable (and sometimes better)
results than the aligned knowledge being injected. We therefore take a thorough
investigation of this frustrating finding on a variety of related prior work
and further provide a chain of potential interpretations for the phenomenon.
Based on all that, we offer a simple remediated technique. Briefly, the core of
this technique is rooted in an ideological emphasis on the pruning and
purification of the external knowledge base to be injected into LLMs. At last,
we show that by integrating this technique into most (if not all) knowledge
injection frameworks and recent LLMs, it manages to overcome the aforementioned
sanity problem and further pushes the boundary of the performance of the
domain-adaptive LLMs.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01152" title="Abstract">arXiv:2311.01152</a> [<a href="/pdf/2311.01152" title="Download PDF">pdf</a>, <a href="/format/2311.01152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Question-Answering Performance of Large Language Models  through Semantic Consistency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rabinovich%2C+E">Ella Rabinovich</a>, 
<a href="/search/cs?searchtype=author&query=Ackerman%2C+S">Samuel Ackerman</a>, 
<a href="/search/cs?searchtype=author&query=Raz%2C+O">Orna Raz</a>, 
<a href="/search/cs?searchtype=author&query=Farchi%2C+E">Eitan Farchi</a>, 
<a href="/search/cs?searchtype=author&query=Anaby-Tavor%2C+A">Ateret Anaby-Tavor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP2023 GEM workshop, 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Semantic consistency of a language model is broadly defined as the model's
ability to produce semantically-equivalent outputs, given
semantically-equivalent inputs. We address the task of assessing
question-answering (QA) semantic consistency of contemporary large language
models (LLMs) by manually creating a benchmark dataset with high-quality
paraphrases for factual questions, and release the dataset to the community.
<br />We further combine the semantic consistency metric with additional
measurements suggested in prior work as correlating with LLM QA accuracy, for
building and evaluating a framework for factual QA reference-less performance
prediction -- predicting the likelihood of a language model to accurately
answer a question. Evaluating the framework on five contemporary LLMs, we
demonstrate encouraging, significantly outperforming baselines, results.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01153" title="Abstract">arXiv:2311.01153</a> [<a href="/pdf/2311.01153" title="Download PDF">pdf</a>, <a href="/format/2311.01153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ACES: Translation Accuracy Challenge Sets at WMT 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amrhein%2C+C">Chantal Amrhein</a>, 
<a href="/search/cs?searchtype=author&query=Moghe%2C+N">Nikita Moghe</a>, 
<a href="/search/cs?searchtype=author&query=Guillou%2C+L">Liane Guillou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera Ready WMT 2023. arXiv admin note: text overlap with <a href="/abs/2210.15615">arXiv:2210.15615</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We benchmark the performance of segmentlevel metrics submitted to WMT 2023
using the ACES Challenge Set (Amrhein et al., 2022). The challenge set consists
of 36K examples representing challenges from 68 phenomena and covering 146
language pairs. The phenomena range from simple perturbations at the
word/character level to more complex errors based on discourse and real-world
knowledge. For each metric, we provide a detailed profile of performance over a
range of error categories as well as an overall ACES-Score for quick
comparison. We also measure the incremental performance of the metrics
submitted to both WMT 2023 and 2022. We find that 1) there is no clear winner
among the metrics submitted to WMT 2023, and 2) performance change between the
2023 and 2022 versions of the metrics is highly variable. Our recommendations
are similar to those from WMT 2022. Metric developers should focus on: building
ensembles of metrics from different design families, developing metrics that
pay more attention to the source and rely less on surface-level overlap, and
carefully determining the influence of multilingual embeddings on MT
evaluation.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01154" title="Abstract">arXiv:2311.01154</a> [<a href="/pdf/2311.01154" title="Download PDF">pdf</a>, <a href="/format/2311.01154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Review of Digital Twins and their Application in Cybersecurity based  on Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Homaei%2C+M">MohammadHossein Homaei</a>, 
<a href="/search/cs?searchtype=author&query=Gutierrez%2C+O+M">Oscar Mogollon Gutierrez</a>, 
<a href="/search/cs?searchtype=author&query=Nunez%2C+J+C+S">Jose Carlos Sancho Nunez</a>, 
<a href="/search/cs?searchtype=author&query=Vegas%2C+M+A">Mar Avila Vegas</a>, 
<a href="/search/cs?searchtype=author&query=Lindo%2C+A+C">Andres Caro Lindo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 60 pages, 8 Figures, 15 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The potential of digital twin technology is yet to be fully realized due to
its diversity and untapped potential. Digital twins enable systems' analysis,
design, optimization, and evolution to be performed digitally or in conjunction
with a cyber-physical approach to improve speed, accuracy, and efficiency over
traditional engineering methods. Industry 4.0, factories of the future, and
digital twins continue to benefit from the technology and provide enhanced
efficiency within existing systems. Due to the lack of information and security
standards associated with the transition to cyber digitization, cybercriminals
have been able to take advantage of the situation. Access to a digital twin of
a product or service is equivalent to threatening the entire collection. There
is a robust interaction between digital twins and artificial intelligence
tools, which leads to strong interaction between these technologies, so it can
be used to improve the cybersecurity of these digital platforms based on their
integration with these technologies. This study aims to investigate the role of
artificial intelligence in providing cybersecurity for digital twin versions of
various industries, as well as the risks associated with these versions. In
addition, this research serves as a road map for researchers and others
interested in cybersecurity and digital security.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01155" title="Abstract">arXiv:2311.01155</a> [<a href="/pdf/2311.01155" title="Download PDF">pdf</a>, <a href="/format/2311.01155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Intra and Inter-Camera Invariance for Isolated Camera  Supervised Person Re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Menglin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+X">Xiaojin Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM MultiMedia 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Supervised person re-identification assumes that a person has images captured
under multiple cameras. However when cameras are placed in distance, a person
rarely appears in more than one camera. This paper thus studies person re-ID
under such isolated camera supervised (ISCS) setting. Instead of trying to
generate fake cross-camera features like previous methods, we explore a novel
perspective by making efficient use of the variation in training data. Under
ISCS setting, a person only has limited images from a single camera, so the
camera bias becomes a critical issue confounding ID discrimination.
Cross-camera images are prone to being recognized as different IDs simply by
camera style. To eliminate the confounding effect of camera bias, we propose to
learn both intra- and inter-camera invariance under a unified framework. First,
we construct style-consistent environments via clustering, and perform
prototypical contrastive learning within each environment. Meanwhile, strongly
augmented images are contrasted with original prototypes to enforce
intra-camera augmentation invariance. For inter-camera invariance, we further
design a much improved variant of multi-camera negative loss that optimizes the
distance of multi-level negatives. The resulting model learns to be invariant
to both subtle and severe style variation within and cross-camera. On multiple
benchmarks, we conduct extensive experiments and validate the effectiveness and
superiority of the proposed method. Code will be available at
https://github.com/Terminator8758/IICI.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01156" title="Abstract">arXiv:2311.01156</a> [<a href="/pdf/2311.01156" title="Download PDF">pdf</a>, <a href="/ps/2311.01156" title="Download PostScript">ps</a>, <a href="/format/2311.01156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Several Consequences of Optimality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+D">Dibakar Das</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Rationality is frequently associated with making the best possible decisions.
It's widely acknowledged that humans, as rational beings, have limitations in
their decision-making capabilities. Nevertheless, recent advancements in
fields, such as, computing, science and technology, combined with the
availability of vast amounts of data, have sparked optimism that these
developments could potentially expand the boundaries of human bounded
rationality through the augmentation of machine intelligence. In this paper,
findings from a computational model demonstrated that when an increasing number
of agents independently strive to achieve global optimality, facilitated by
improved computing power, etc., they indirectly accelerated the occurrence of
the "tragedy of the commons" by depleting shared resources at a faster rate.
Further, as agents achieve optimality, there is a drop in information entropy
among the solutions of the agents. Also, clear economic divide emerges among
agents. Considering, two groups, one as producer and the other (the group
agents searching for optimality) as consumer of the highest consumed resource,
the consumers seem to gain more than the producers. Thus, bounded rationality
could be seen as boon to sustainability.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01161" title="Abstract">arXiv:2311.01161</a> [<a href="/pdf/2311.01161" title="Download PDF">pdf</a>, <a href="/format/2311.01161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly Supervised Semantic Parsing with Execution-based Spurious Program  Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kang-il Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Segwang Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+K">Kyomin Jung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The problem of spurious programs is a longstanding challenge when training a
semantic parser from weak supervision. To eliminate such programs that have
wrong semantics but correct denotation, existing methods focus on exploiting
similarities between examples based on domain-specific knowledge. In this
paper, we propose a domain-agnostic filtering mechanism based on program
execution results. Specifically, for each program obtained through the search
process, we first construct a representation that captures the program's
semantics as execution results under various inputs. Then, we run a majority
vote on these representations to identify and filter out programs with
significantly different semantics from the other programs. In particular, our
method is orthogonal to the program search process so that it can easily
augment any of the existing weakly supervised semantic parsing frameworks.
Empirical evaluations on the Natural Language Visual Reasoning and
WikiTableQuestions demonstrate that applying our method to the existing
semantic parsers induces significantly improved performances.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01164" title="Abstract">arXiv:2311.01164</a> [<a href="/pdf/2311.01164" title="Download PDF">pdf</a>, <a href="/format/2311.01164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Insight Into SEER
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lekan%2C+K">Kasra Lekan</a>, 
<a href="/search/cs?searchtype=author&query=Choquette%2C+N">Nicki Choquette</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Developing test oracles can be inefficient: developer generative oracles are
time-intensive and thus costly while automatic oracle generation in the form of
regression or exception oracles assumes that the underlying code is correct. To
mitigate the high cost of testing oracles, the SEER tool was developed to
predict test outcomes without needing assertion statements. The creators of
SEER introduced the tool with an overall accuracy of 93%, precision of 86%,
recall of 94%, and an F1 score of 90%. If these results are replicable on new
data with perturbations, i.e. SEER is generalizable and robust, the model would
represent a significant advancement in the field of automated testing.
Consequently, we conducted a comprehensive reproduction of SEER and attempted
to verify the model's results on a new dataset.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01166" title="Abstract">arXiv:2311.01166</a> [<a href="/pdf/2311.01166" title="Download PDF">pdf</a>, <a href="/format/2311.01166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Input: Towards Next-Generation Input Methods Paradigm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+K">Keyu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongcan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zihang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Z">Zhenzhen Jia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shijin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Enhong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Since the release of ChatGPT, generative models have achieved tremendous
success and become the de facto approach for various NLP tasks. However, its
application in the field of input methods remains under-explored. Many neural
network approaches have been applied to the construction of Chinese input
method engines(IMEs).Previous research often assumed that the input pinyin was
correct and focused on Pinyin-to-character(P2C) task, which significantly falls
short of meeting users' demands. Moreover, previous research could not leverage
user feedback to optimize the model and provide personalized results. In this
study, we propose a novel Generative Input paradigm named GeneInput. It uses
prompts to handle all input scenarios and other intelligent auxiliary input
functions, optimizing the model with user feedback to deliver personalized
results. The results demonstrate that we have achieved state-of-the-art
performance for the first time in the Full-mode Key-sequence to
Characters(FK2C) task. We propose a novel reward model training method that
eliminates the need for additional manual annotations and the performance
surpasses GPT-4 in tasks involving intelligent association and conversational
assistance. Compared to traditional paradigms, GeneInput not only demonstrates
superior performance but also exhibits enhanced robustness, scalability, and
online learning capabilities.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01167" title="Abstract">arXiv:2311.01167</a> [<a href="/pdf/2311.01167" title="Download PDF">pdf</a>, <a href="/format/2311.01167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modulation Design and Optimization for RIS-Assisted Symbiotic Radios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+B">Bowen Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qianqian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+R">Ruizhe Long</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+Y">Yiyang Pei</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Ying-Chang Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages,15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In reconfigurable intelligent surface (RIS)-assisted symbiotic radio (SR),
the RIS acts as a secondary transmitter by modulating its information bits over
the incident primary signal and simultaneously assists the primary
transmission, then a cooperative receiver is used to jointly decode the primary
and secondary signals. Most existing works of SR focus on using RIS to enhance
the reflecting link while ignoring the ambiguity problem for the joint
detection caused by the multiplication relationship of the primary and
secondary signals. Particularly, in case of a blocked direct link, joint
detection will suffer from severe performance loss due to the ambiguity, when
using the conventional on-off keying and binary phase shift keying modulation
schemes for RIS. To address this issue, we propose a novel modulation scheme
for RIS-assisted SR that divides the phase-shift matrix into two components:
the symbol-invariant and symbol-varying components, which are used to assist
the primary transmission and carry the secondary signal, respectively. To
design these two components, we focus on the detection of the composite signal
formed by the primary and secondary signals, through which a problem of
minimizing the bit error rate (BER) of the composite signal is formulated to
improve both the BER performance of the primary and secondary ones. By solving
the problem, we derive the closed-form solution of the optimal symbol-invariant
and symbol-varying components, which is related to the channel strength ratio
of the direct link to the reflecting link. Moreover, theoretical BER
performance is analyzed. Finally, simulation results show the superiority of
the proposed modulation scheme over its conventional counterpart.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01171" title="Abstract">arXiv:2311.01171</a> [<a href="/pdf/2311.01171" title="Download PDF">pdf</a>, <a href="/format/2311.01171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memristor-based hardware and algorithms for higher-order Hopfield  optimization solver outperforming quadratic Ising machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hizzani%2C+M">Mohammad Hizzani</a>, 
<a href="/search/cs?searchtype=author&query=Heittmann%2C+A">Arne Heittmann</a>, 
<a href="/search/cs?searchtype=author&query=Hutchinson%2C+G">George Hutchinson</a>, 
<a href="/search/cs?searchtype=author&query=Dobrynin%2C+D">Dmitrii Dobrynin</a>, 
<a href="/search/cs?searchtype=author&query=Van+Vaerenbergh%2C+T">Thomas Van Vaerenbergh</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+T">Tinish Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Renaudineau%2C+A">Adrien Renaudineau</a>, 
<a href="/search/cs?searchtype=author&query=Strukov%2C+D">Dmitri Strukov</a>, 
<a href="/search/cs?searchtype=author&query=Strachan%2C+J+P">John Paul Strachan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Ising solvers offer a promising physics-based approach to tackle the
challenging class of combinatorial optimization problems. However, typical
solvers operate in a quadratic energy space, having only pair-wise coupling
elements which already dominate area and energy. We show that such
quadratization can cause severe problems: increased dimensionality, a rugged
search landscape, and misalignment with the original objective function. Here,
we design and quantify a higher-order Hopfield optimization solver, with 28nm
CMOS technology and memristive couplings for lower area and energy
computations. We combine algorithmic and circuit analysis to show quantitative
advantages over quadratic Ising Machines (IM)s, yielding 48x and 72x reduction
in time-to-solution (TTS) and energy-to-solution (ETS) respectively for Boolean
satisfiability problems of 150 variables, with favorable scaling.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01173" title="Abstract">arXiv:2311.01173</a> [<a href="/pdf/2311.01173" title="Download PDF">pdf</a>, <a href="/format/2311.01173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CRUSH4SQL: Collective Retrieval Using Schema Hallucination For Text2SQL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kothyari%2C+M">Mayank Kothyari</a>, 
<a href="/search/cs?searchtype=author&query=Dhingra%2C+D">Dhruva Dhingra</a>, 
<a href="/search/cs?searchtype=author&query=Sarawagi%2C+S">Sunita Sarawagi</a>, 
<a href="/search/cs?searchtype=author&query=Chakrabarti%2C+S">Soumen Chakrabarti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at EMNLP 2023 (Main)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Existing Text-to-SQL generators require the entire schema to be encoded with
the user text. This is expensive or impractical for large databases with tens
of thousands of columns. Standard dense retrieval techniques are inadequate for
schema subsetting of a large structured database, where the correct semantics
of retrieval demands that we rank sets of schema elements rather than
individual elements. In response, we propose a two-stage process for effective
coverage during retrieval. First, we instruct an LLM to hallucinate a minimal
DB schema deemed adequate to answer the query. We use the hallucinated schema
to retrieve a subset of the actual schema, by composing the results from
multiple dense retrievals. Remarkably, hallucination $\unicode{x2013}$
generally considered a nuisance $\unicode{x2013}$ turns out to be actually
useful as a bridging mechanism. Since no existing benchmarks exist for schema
subsetting on large databases, we introduce three benchmarks. Two
semi-synthetic datasets are derived from the union of schemas in two well-known
datasets, SPIDER and BIRD, resulting in 4502 and 798 schema elements
respectively. A real-life benchmark called SocialDB is sourced from an actual
large data warehouse comprising 17844 schema elements. We show that our method1
leads to significantly higher recall than SOTA retrieval-based augmentation
methods.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01180" title="Abstract">arXiv:2311.01180</a> [<a href="/pdf/2311.01180" title="Download PDF">pdf</a>, <a href="/ps/2311.01180" title="Download PostScript">ps</a>, <a href="/format/2311.01180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Configuration of Multi-Agent Model Predictive Controllers  based on Semantic Graph World Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Vos%2C+K">K. de Vos</a>, 
<a href="/search/cs?searchtype=author&query=Torta%2C+E">E. Torta</a>, 
<a href="/search/cs?searchtype=author&query=Bruyninckx%2C+H">H. Bruyninckx</a>, 
<a href="/search/cs?searchtype=author&query=Martinez%2C+C+A+L">C.A. Lopez Martinez</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Molengraft%2C+M+J+G">M.J.G. van de Molengraft</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We propose a shared semantic map architecture to construct and configure
Model Predictive Controllers (MPC) dynamically, that solve navigation problems
for multiple robotic agents sharing parts of the same environment. The
navigation task is represented as a sequence of semantically labeled areas in
the map, that must be traversed sequentially, i.e. a route. Each semantic label
represents one or more constraints on the robots' motion behaviour in that
area. The advantages of this approach are: (i) an MPC-based motion controller
in each individual robot can be (re-)configured, at runtime, with the locally
and temporally relevant parameters; (ii) the application can influence, also at
runtime, the navigation behaviour of the robots, just by adapting the semantic
labels; and (iii) the robots can reason about their need for coordination,
through analyzing over which horizon in time and space their routes overlap.
The paper provides simulations of various representative situations, showing
that the approach of runtime configuration of the MPC drastically decreases
computation time, while retaining task execution performance similar to an
approach in which each robot always includes all other robots in its MPC
computations.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01181" title="Abstract">arXiv:2311.01181</a> [<a href="/pdf/2311.01181" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced Traffic Congestion Management with Fog Computing: A  Simulation-based Investigation using iFog-Simulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elsayed%2C+A">Alzahraa Elsayed</a>, 
<a href="/search/cs?searchtype=author&query=Mohamed%2C+K">Khalil Mohamed</a>, 
<a href="/search/cs?searchtype=author&query=Harb%2C+H">Hany Harb</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Accurate latency computation is essential for the Internet of Things (IoT)
since the connected devices generate a vast amount of data that is processed on
cloud infrastructure. However, the cloud is not an optimal solution. To
overcome this issue, fog computing is used to enable processing at the edge
while still allowing communication with the cloud. Many applications rely on
fog computing, including traffic management. In this paper, an Intelligent
Traffic Congestion Mitigation System (ITCMS) is proposed to address traffic
congestion in heavily populated smart cities. The proposed system is
implemented using fog computing and tested in a crowded city. Its performance
is evaluated based on multiple metrics, such as traffic efficiency, energy
savings, reduced latency, average traffic flow rate, and waiting time. The
obtained results are compared with similar techniques that tackle the same
issue. The results obtained indicate that the execution time of the simulation
is 4,538 seconds, and the delay in the application loop is 49.67 seconds. The
paper addresses various issues, including CPU usage, heap memory usage,
throughput, and the total average delay, which are essential for evaluating the
performance of the ITCMS. Our system model is also compared with other models
to assess its performance. A comparison is made using two parameters, namely
throughput and the total average delay, between the ITCMS, IOV (Internet of
Vehicle), and STL (Seasonal-Trend Decomposition Procedure based on LOESS).
Consequently, the results confirm that the proposed system outperforms the
others in terms of higher accuracy, lower latency, and improved traffic
efficiency.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01184" title="Abstract">arXiv:2311.01184</a> [<a href="/pdf/2311.01184" title="Download PDF">pdf</a>, <a href="/ps/2311.01184" title="Download PostScript">ps</a>, <a href="/format/2311.01184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A correspondence between the time and space complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Latkin%2C+I+V">Ivan V. Latkin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 26 references bibliography; text overlap with <a href="/abs/1907.04521">arXiv:1907.04521</a> because the paper is created in the same method
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Logic in Computer Science (cs.LO); Logic (math.LO)

</div>
<p class="mathjax">We investigate the correspondence between the time and space recognition
complexity of languages; for this purpose, we will code the long-continued
computations of deterministic two-tape Turing machines by the relatively
short-length quantified Boolean formulae. The modified Stockmeyer and Meyer
method will appreciably be used for this simulation. It will be proved using
this modeling that the complexity classes $\mathbf{EXP}$ and $\mathbf{PSPACE}$
coincide; and more generally, the class $(k\!+\!1)$-fold Deterministic
Exponential Time equals to the class $k$-fold Deterministic Exponential Space
for each $k\geqslant1$; the space complexity of the languages of the class
$\mathbf{P}$ will also be studied. Furthermore, this allows us to slightly
improve the early founded lower complexity bound of decidable theories that are
nontrivial relative to some equivalence relation (this relation may be
equality) -- each of these theories is consistent with the formula, which
asserts that there are two non-equivalent elements.
<br />Keywords: computational complexity, the coding of computations through
formulae, exponential time, polynomial space, lower complexity bound of the
language recognition
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01185" title="Abstract">arXiv:2311.01185</a> [<a href="/pdf/2311.01185" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revolutionizing Healthcare Image Analysis in Pandemic-Based Fog-Cloud  Computing Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elsayed%2C+A+Z">Al Zahraa Elsayed</a>, 
<a href="/search/cs?searchtype=author&query=Mohamed%2C+K">Khalil Mohamed</a>, 
<a href="/search/cs?searchtype=author&query=Harb%2C+H">Hany Harb</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The emergence of pandemics has significantly emphasized the need for
effective solutions in healthcare data analysis. One particular challenge in
this domain is the manual examination of medical images, such as X-rays and CT
scans. This process is time-consuming and involves the logistical complexities
of transferring these images to centralized cloud computing servers.
Additionally, the speed and accuracy of image analysis are vital for efficient
healthcare image management. This research paper introduces an innovative
healthcare architecture that tackles the challenges of analysis efficiency and
accuracy by harnessing the capabilities of Artificial Intelligence (AI).
Specifically, the proposed architecture utilizes fog computing and presents a
modified Convolutional Neural Network (CNN) designed specifically for image
analysis. Different architectures of CNN layers are thoroughly explored and
evaluated to optimize overall performance. To demonstrate the effectiveness of
the proposed approach, a dataset of X-ray images is utilized for analysis and
evaluation. Comparative assessments are conducted against recent models such as
VGG16, VGG19, MobileNet, and related research papers. Notably, the proposed
approach achieves an exceptional accuracy rate of 99.88% in classifying normal
cases, accompanied by a validation rate of 96.5%, precision and recall rates of
100%, and an F1 score of 100%. These results highlight the immense potential of
fog computing and modified CNNs in revolutionizing healthcare image analysis
and diagnosis, not only during pandemics but also in the future. By leveraging
these technologies, healthcare professionals can enhance the efficiency and
accuracy of medical image analysis, leading to improved patient care and
outcomes.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01188" title="Abstract">arXiv:2311.01188</a> [<a href="/pdf/2311.01188" title="Download PDF">pdf</a>, <a href="/format/2311.01188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Terrain-Informed Self-Supervised Learning: Enhancing Building Footprint  Extraction from LiDAR Data with Limited Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vats%2C+A">Anuja Vats</a>, 
<a href="/search/cs?searchtype=author&query=V%C3%B6lgyes%2C+D">David V&#xf6;lgyes</a>, 
<a href="/search/cs?searchtype=author&query=Vermeer%2C+M">Martijn Vermeer</a>, 
<a href="/search/cs?searchtype=author&query=Pedersen%2C+M">Marius Pedersen</a>, 
<a href="/search/cs?searchtype=author&query=Raja%2C+K">Kiran Raja</a>, 
<a href="/search/cs?searchtype=author&query=Fantin%2C+D+S+M">Daniele S.M.Fantin</a>, 
<a href="/search/cs?searchtype=author&query=Hay%2C+J+A">Jacob Alexander Hay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Estimating building footprint maps from geospatial data is of paramount
importance in urban planning, development, disaster management, and various
other applications. Deep learning methodologies have gained prominence in
building segmentation maps, offering the promise of precise footprint
extraction without extensive post-processing. However, these methods face
challenges in generalization and label efficiency, particularly in remote
sensing, where obtaining accurate labels can be both expensive and
time-consuming. To address these challenges, we propose terrain-aware
self-supervised learning, tailored to remote sensing, using digital elevation
models from LiDAR data. We propose to learn a model to differentiate between
bare Earth and superimposed structures enabling the network to implicitly learn
domain-relevant features without the need for extensive pixel-level
annotations. We test the effectiveness of our approach by evaluating building
segmentation performance on test datasets with varying label fractions.
Remarkably, with only 1% of the labels (equivalent to 25 labeled examples), our
method improves over ImageNet pre-training, showing the advantage of leveraging
unlabeled data for feature extraction in the domain of remote sensing. The
performance improvement is more pronounced in few-shot scenarios and gradually
closes the gap with ImageNet pre-training as the label fraction increases. We
test on a dataset characterized by substantial distribution shifts and labeling
errors to demonstrate the generalizability of our approach. When compared to
other baselines, including ImageNet pretraining and more complex architectures,
our approach consistently performs better, demonstrating the efficiency and
effectiveness of self-supervised terrain-aware feature learning.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01191" title="Abstract">arXiv:2311.01191</a> [<a href="/pdf/2311.01191" title="Download PDF">pdf</a>, <a href="/format/2311.01191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VIGraph: Self-supervised Learning for Class-Imbalanced Node  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yulan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+S">Sheng Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhirui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Class imbalance in graph data poses significant challenges for node
classification. Existing methods, represented by SMOTE-based approaches,
partially alleviate this issue but still exhibit limitations during imbalanced
scenario construction. Self-supervised learning (SSL) offers a promising
solution by synthesizing minority nodes from the data itself, yet its potential
remains unexplored. In this paper, we analyze the limitations of SMOTE-based
approaches and introduce VIGraph, a novel SSL model based on the
self-supervised Variational Graph Auto-Encoder (VGAE) that leverages
Variational Inference (VI) to generate minority nodes. Specifically, VIGraph
strictly adheres to the concept of imbalance when constructing imbalanced
graphs and utilizes the generative VGAE to generate minority nodes. Moreover,
VIGraph introduces a novel Siamese contrastive strategy at the decoding phase
to improve the overall quality of generated nodes. VIGraph can generate
high-quality nodes without reintegrating them into the original graph,
eliminating the "Generating, Reintegrating, and Retraining" process found in
SMOTE-based methods. Experiments on multiple real-world datasets demonstrate
that VIGraph achieves promising results for class-imbalanced node
classification tasks.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01192" title="Abstract">arXiv:2311.01192</a> [<a href="/pdf/2311.01192" title="Download PDF">pdf</a>, <a href="/format/2311.01192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Scene Graph Generation Based on an Edge Dual Scene Graph and  Message Passing Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyeongjin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sangwon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+T">Jong Taek Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+B+C">Byoung Chul Ko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Along with generative AI, interest in scene graph generation (SGG), which
comprehensively captures the relationships and interactions between objects in
an image and creates a structured graph-based representation, has significantly
increased in recent years. However, relying on object-centric and dichotomous
relationships, existing SGG methods have a limited ability to accurately
predict detailed relationships. To solve these problems, a new approach to the
modeling multiobject relationships, called edge dual scene graph generation
(EdgeSGG), is proposed herein. EdgeSGG is based on a edge dual scene graph and
Dual Message Passing Neural Network (DualMPNN), which can capture rich
contextual interactions between unconstrained objects. To facilitate the
learning of edge dual scene graphs with a symmetric graph structure, the
proposed DualMPNN learns both object- and relation-centric features for more
accurately predicting relation-aware contexts and allows fine-grained
relational updates between objects. A comparative experiment with
state-of-the-art (SoTA) methods was conducted using two public datasets for SGG
operations and six metrics for three subtasks. Compared with SoTA approaches,
the proposed model exhibited substantial performance improvements across all
SGG subtasks. Furthermore, experiment on long-tail distributions revealed that
incorporating the relationships between objects effectively mitigates existing
long-tail problems.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01193" title="Abstract">arXiv:2311.01193</a> [<a href="/pdf/2311.01193" title="Download PDF">pdf</a>, <a href="/format/2311.01193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextual Confidence and Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Shrey Jain</a>, 
<a href="/search/cs?searchtype=author&query=Hitzig%2C+Z">Zo&#xeb; Hitzig</a>, 
<a href="/search/cs?searchtype=author&query=Mishkin%2C+P">Pamela Mishkin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Generative AI models perturb the foundations of effective human
communication. They present new challenges to contextual confidence, disrupting
participants' ability to identify the authentic context of communication and
their ability to protect communication from reuse and recombination outside its
intended context. In this paper, we describe strategies--tools, technologies
and policies--that aim to stabilize communication in the face of these
challenges. The strategies we discuss fall into two broad categories.
Containment strategies aim to reassert context in environments where it is
currently threatened--a reaction to the context-free expectations and norms
established by the internet. Mobilization strategies, by contrast, view the
rise of generative AI as an opportunity to proactively set new and higher
expectations around privacy and authenticity in mediated communication.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01195" title="Abstract">arXiv:2311.01195</a> [<a href="/pdf/2311.01195" title="Download PDF">pdf</a>, <a href="/format/2311.01195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Batch Bayesian Optimization for Replicable Experimental Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+Z">Zhongxiang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q+P">Quoc Phong Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Tay%2C+S+S">Sebastian Shenghong Tay</a>, 
<a href="/search/cs?searchtype=author&query=Urano%2C+D">Daisuke Urano</a>, 
<a href="/search/cs?searchtype=author&query=Leong%2C+R">Richalynn Leong</a>, 
<a href="/search/cs?searchtype=author&query=Low%2C+B+K+H">Bryan Kian Hsiang Low</a>, 
<a href="/search/cs?searchtype=author&query=Jaillet%2C+P">Patrick Jaillet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Many real-world experimental design problems (a) evaluate multiple
experimental conditions in parallel and (b) replicate each condition multiple
times due to large and heteroscedastic observation noise. Given a fixed total
budget, this naturally induces a trade-off between evaluating more unique
conditions while replicating each of them fewer times vs. evaluating fewer
unique conditions and replicating each more times. Moreover, in these problems,
practitioners may be risk-averse and hence prefer an input with both good
average performance and small variability. To tackle both challenges, we
propose the Batch Thompson Sampling for Replicable Experimental Design
(BTS-RED) framework, which encompasses three algorithms. Our BTS-RED-Known and
BTS-RED-Unknown algorithms, for, respectively, known and unknown noise
variance, choose the number of replications adaptively rather than
deterministically such that an input with a larger noise variance is replicated
more times. As a result, despite the noise heteroscedasticity, both algorithms
enjoy a theoretical guarantee and are asymptotically no-regret. Our
Mean-Var-BTS-RED algorithm aims at risk-averse optimization and is also
asymptotically no-regret. We also show the effectiveness of our algorithms in
two practical real-world applications: precision agriculture and AutoML.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01196" title="Abstract">arXiv:2311.01196</a> [<a href="/pdf/2311.01196" title="Download PDF">pdf</a>, <a href="/format/2311.01196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combating Bilateral Edge Noise for Robust Link Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhanke Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiangchao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaxu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiawei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Q">Quanming Yao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Li He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Bo Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bo Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Although link prediction on graphs has achieved great success with the
development of graph neural networks (GNNs), the potential robustness under the
edge noise is still less investigated. To close this gap, we first conduct an
empirical study to disclose that the edge noise bilaterally perturbs both input
topology and target label, yielding severe performance degradation and
representation collapse. To address this dilemma, we propose an
information-theory-guided principle, Robust Graph Information Bottleneck
(RGIB), to extract reliable supervision signals and avoid representation
collapse. Different from the basic information bottleneck, RGIB further
decouples and balances the mutual dependence among graph topology, target
labels, and representation, building new learning objectives for robust
representation against the bilateral noise. Two instantiations, RGIB-SSL and
RGIB-REP, are explored to leverage the merits of different methodologies, i.e.,
self-supervised learning and data reparameterization, for implicit and explicit
data denoising, respectively. Extensive experiments on six datasets and three
GNNs with diverse noisy scenarios verify the effectiveness of our RGIB
instantiations. The code is publicly available at:
https://github.com/tmlr-group/RGIB.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01197" title="Abstract">arXiv:2311.01197</a> [<a href="/pdf/2311.01197" title="Download PDF">pdf</a>, <a href="/format/2311.01197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AiluRus: A Scalable ViT Framework for Dense Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jin Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaoming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaopeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Bowen Shi</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Dongsheng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenglin Li</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+W">Wenrui Dai</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hongkai Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qi Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Vision transformers (ViTs) have emerged as a prevalent architecture for
vision tasks owing to their impressive performance. However, when it comes to
handling long token sequences, especially in dense prediction tasks that
require high-resolution input, the complexity of ViTs increases significantly.
Notably, dense prediction tasks, such as semantic segmentation or object
detection, emphasize more on the contours or shapes of objects, while the
texture inside objects is less informative. Motivated by this observation, we
propose to apply adaptive resolution for different regions in the image
according to their importance. Specifically, at the intermediate layer of the
ViT, we utilize a spatial-aware density-based clustering algorithm to select
representative tokens from the token sequence. Once the representative tokens
are determined, we proceed to merge other tokens into their closest
representative token. Consequently, semantic similar tokens are merged together
to form low-resolution regions, while semantic irrelevant tokens are preserved
independently as high-resolution regions. This strategy effectively reduces the
number of tokens, allowing subsequent layers to handle a reduced token sequence
and achieve acceleration. We evaluate our proposed method on three different
datasets and observe promising performance. For example, the "Segmenter ViT-L"
model can be accelerated by 48% FPS without fine-tuning, while maintaining the
performance. Additionally, our method can be applied to accelerate fine-tuning
as well. Experimental results demonstrate that we can save 52% training time
while accelerating 2.46 times FPS with only a 0.09% performance drop. The code
is available at https://github.com/caddyless/ailurus/tree/main.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01198" title="Abstract">arXiv:2311.01198</a> [<a href="/pdf/2311.01198" title="Download PDF">pdf</a>, <a href="/format/2311.01198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Processes on Cellular Complexes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alain%2C+M">Mathieu Alain</a>, 
<a href="/search/cs?searchtype=author&query=Takao%2C+S">So Takao</a>, 
<a href="/search/cs?searchtype=author&query=Paige%2C+B">Brooks Paige</a>, 
<a href="/search/cs?searchtype=author&query=Deisenroth%2C+M+P">Marc Peter Deisenroth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">In recent years, there has been considerable interest in developing machine
learning models on graphs in order to account for topological inductive biases.
In particular, recent attention was given to Gaussian processes on such
structures since they can additionally account for uncertainty. However, graphs
are limited to modelling relations between two vertices. In this paper, we go
beyond this dyadic setting and consider polyadic relations that include
interactions between vertices, edges and one of their generalisations, known as
cells. Specifically, we propose Gaussian processes on cellular complexes, a
generalisation of graphs that captures interactions between these higher-order
cells. One of our key contributions is the derivation of two novel kernels, one
that generalises the graph Mat\'ern kernel and one that additionally mixes
information of different cell types.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01200" title="Abstract">arXiv:2311.01200</a> [<a href="/pdf/2311.01200" title="Download PDF">pdf</a>, <a href="/format/2311.01200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study of Continual Learning Under Language Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gogoulou%2C+E">Evangelia Gogoulou</a>, 
<a href="/search/cs?searchtype=author&query=Lesort%2C+T">Timoth&#xe9;e Lesort</a>, 
<a href="/search/cs?searchtype=author&query=Boman%2C+M">Magnus Boman</a>, 
<a href="/search/cs?searchtype=author&query=Nivre%2C+J">Joakim Nivre</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The recent increase in data and model scale for language model pre-training
has led to huge training costs. In scenarios where new data become available
over time, updating a model instead of fully retraining it would therefore
provide significant gains. In this paper, we study the benefits and downsides
of updating a language model when new data comes from new languages - the case
of continual learning under language shift. Starting from a monolingual English
language model, we incrementally add data from Norwegian and Icelandic to
investigate how forward and backward transfer effects depend on the
pre-training order and characteristics of languages, for different model sizes
and learning rate schedulers. Our results show that, while forward transfer is
largely positive and independent of language order, backward transfer can be
either positive or negative depending on the order and characteristics of new
languages. To explain these patterns we explore several language similarity
metrics and find that syntactic similarity appears to have the best correlation
with our results.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01201" title="Abstract">arXiv:2311.01201</a> [<a href="/pdf/2311.01201" title="Download PDF">pdf</a>, <a href="/format/2311.01201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning on Edge Sensing Devices: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saylam%2C+B">Berrenur Saylam</a>, 
<a href="/search/cs?searchtype=author&query=%C4%B0ncel%2C+%C3%96+D">&#xd6;zlem Durmaz &#x130;ncel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">The ability to monitor ambient characteristics, interact with them, and
derive information about the surroundings has been made possible by the rapid
proliferation of edge sensing devices like IoT, mobile, and wearable devices
and their measuring capabilities with integrated sensors. Even though these
devices are small and have less capacity for data storage and processing, they
produce vast amounts of data. Some example application areas where sensor data
is collected and processed include healthcare, environmental (including air
quality and pollution levels), automotive, industrial, aerospace, and
agricultural applications. These enormous volumes of sensing data collected
from the edge devices are analyzed using a variety of Machine Learning (ML) and
Deep Learning (DL) approaches. However, analyzing them on the cloud or a server
presents challenges related to privacy, hardware, and connectivity limitations.
Federated Learning (FL) is emerging as a solution to these problems while
preserving privacy by jointly training a model without sharing raw data. In
this paper, we review the FL strategies from the perspective of edge sensing
devices to get over the limitations of conventional machine learning
techniques. We focus on the key FL principles, software frameworks, and
testbeds. We also explore the current sensor technologies, properties of the
sensing devices and sensing applications where FL is utilized. We conclude with
a discussion on open issues and future research directions on FL for further
studies
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01202" title="Abstract">arXiv:2311.01202</a> [<a href="/pdf/2311.01202" title="Download PDF">pdf</a>, <a href="/format/2311.01202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Modal Information-Guided Network using Contrastive Learning for  Point Cloud Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yifan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jihua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shiqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+P">Pengcheng Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, accepted by RAL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The majority of point cloud registration methods currently rely on extracting
features from points. However, these methods are limited by their dependence on
information obtained from a single modality of points, which can result in
deficiencies such as inadequate perception of global features and a lack of
texture information. Actually, humans can employ visual information learned
from 2D images to comprehend the 3D world. Based on this fact, we present a
novel Cross-Modal Information-Guided Network (CMIGNet), which obtains global
shape perception through cross-modal information to achieve precise and robust
point cloud registration. Specifically, we first incorporate the projected
images from the point clouds and fuse the cross-modal features using the
attention mechanism. Furthermore, we employ two contrastive learning
strategies, namely overlapping contrastive learning and cross-modal contrastive
learning. The former focuses on features in overlapping regions, while the
latter emphasizes the correspondences between 2D and 3D features. Finally, we
propose a mask prediction module to identify keypoints in the point clouds.
Extensive experiments on several benchmark datasets demonstrate that our
network achieves superior registration performance.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01205" title="Abstract">arXiv:2311.01205</a> [<a href="/pdf/2311.01205" title="Download PDF">pdf</a>, <a href="/format/2311.01205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attacking Graph Neural Networks with Bit Flips: Weisfeiler and Lehman Go  Indifferent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kummer%2C+L">Lorenz Kummer</a>, 
<a href="/search/cs?searchtype=author&query=Moustafa%2C+S">Samir Moustafa</a>, 
<a href="/search/cs?searchtype=author&query=Kriege%2C+N+N">Nils N. Kriege</a>, 
<a href="/search/cs?searchtype=author&query=Gansterer%2C+W+N">Wilfried N. Gansterer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Prior attacks on graph neural networks have mostly focused on graph poisoning
and evasion, neglecting the network's weights and biases. Traditional
weight-based fault injection attacks, such as bit flip attacks used for
convolutional neural networks, do not consider the unique properties of graph
neural networks. We propose the Injectivity Bit Flip Attack, the first bit flip
attack designed specifically for graph neural networks. Our attack targets the
learnable neighborhood aggregation functions in quantized message passing
neural networks, degrading their ability to distinguish graph structures and
losing the expressivity of the Weisfeiler-Lehman test. Our findings suggest
that exploiting mathematical properties specific to certain graph neural
network architectures can significantly increase their vulnerability to bit
flip attacks. Injectivity Bit Flip Attacks can degrade the maximal expressive
Graph Isomorphism Networks trained on various graph property prediction
datasets to random output by flipping only a small fraction of the network's
bits, demonstrating its higher destructive power compared to a bit flip attack
transferred from convolutional neural networks. Our attack is transparent and
motivated by theoretical insights which are confirmed by extensive empirical
results.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01212" title="Abstract">arXiv:2311.01212</a> [<a href="/pdf/2311.01212" title="Download PDF">pdf</a>, <a href="/format/2311.01212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-view Relation Learning for Cross-domain Few-shot Hyperspectral  Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Longwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhigang Han</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jianzhong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Junyong Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Cross-domain few-shot hyperspectral image classification focuses on learning
prior knowledge from a large number of labeled samples from source domain and
then transferring the knowledge to the tasks which contain only few labeled
samples in target domains. Following the metric-based manner, many current
methods first extract the features of the query and support samples, and then
directly predict the classes of query samples according to their distance to
the support samples or prototypes. The relations between samples have not been
fully explored and utilized. Different from current works, this paper proposes
to learn sample relations from different views and take them into the model
learning process, to improve the cross-domain few-shot hyperspectral image
classification. Building on current DCFSL method which adopts a domain
discriminator to deal with domain-level distribution difference, the proposed
method applys contrastive learning to learn the class-level sample relations to
obtain more discriminable sample features. In addition, it adopts a transformer
based cross-attention learning module to learn the set-level sample relations
and acquire the attentions from query samples to support samples. Our
experimental results have demonstrated the contribution of the multi-view
relation learning mechanism for few-shot hyperspectral image classification
when compared with the state of the art methods.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01214" title="Abstract">arXiv:2311.01214</a> [<a href="/pdf/2311.01214" title="Download PDF">pdf</a>, <a href="/format/2311.01214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Quality Animatable Dynamic Garment Reconstruction from Monocular  Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiongzheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinsong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">Yu-Kun Lai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jingyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kun Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Much progress has been made in reconstructing garments from an image or a
video. However, none of existing works meet the expectations of digitizing
high-quality animatable dynamic garments that can be adjusted to various unseen
poses. In this paper, we propose the first method to recover high-quality
animatable dynamic garments from monocular videos without depending on scanned
data. To generate reasonable deformations for various unseen poses, we propose
a learnable garment deformation network that formulates the garment
reconstruction task as a pose-driven deformation problem. To alleviate the
ambiguity estimating 3D garments from monocular videos, we design a
multi-hypothesis deformation module that learns spatial representations of
multiple plausible deformations. Experimental results on several public
datasets demonstrate that our method can reconstruct high-quality dynamic
garments with coherent surface details, which can be easily animated under
unseen poses. The code will be provided for research purposes.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01222" title="Abstract">arXiv:2311.01222</a> [<a href="/pdf/2311.01222" title="Download PDF">pdf</a>, <a href="/ps/2311.01222" title="Download PostScript">ps</a>, <a href="/format/2311.01222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Reflection on LLEE Charts -- Another Proof for the Completeness of  an Axiomatization of 1-Free Regular Expressions Modulo Bisimilarity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuanrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinxin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">We analyze a phenomenon called "image reflection" on a type of
characterization graphs -- LLEE charts -- of 1-free regular expressions modulo
bisimulation equivalence. Due to the correspondence between 1-free regular
expressions and the provable solutions of LEE/LLEE charts, this observation
naturally leads to a new proof for the completeness of the proof system
\MilIfree\ for 1-free regular expressions modulo bisimulation equivalence. The
critical part of the previous proof is to show that bisimulation collapse,
which plays the role in linking the provable solutions of two LLEE charts, is
still an LLEE chart. The difference of our proof, compared to the previous one,
is that we do not rely on the graph transformations from LLEE charts into their
bisimulation collapses by merging two bisimular nodes in each transformation
step. Instead, we directly show that the bisimulation collapse of an LLEE chart
possesses an LEE/LLEE structure based on its set of images mapped through the
bisimulation function from the LLEE chart, and the constrained relation between
the images and their so-called "well-structured" looping-back charts pre-images
on the LLEE chart. Our approach provides a novel angle to look at this problem
and related problems, and might introduce a different way for proving the
completeness problem of \Mil\ for regular expressions modulo bisimulation
equivalence, which had remained open until very recently.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01223" title="Abstract">arXiv:2311.01223</a> [<a href="/pdf/2311.01223" title="Download PDF">pdf</a>, <a href="/format/2311.01223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Models for Reinforcement Learning: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhengbang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hanye Zhao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">Haoran He</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yichao Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shenyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 2 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Diffusion models have emerged as a prominent class of generative models,
surpassing previous methods regarding sample quality and training stability.
Recent works have shown the advantages of diffusion models in improving
reinforcement learning (RL) solutions, including as trajectory planners,
expressive policy classes, data synthesizers, etc. This survey aims to provide
an overview of the advancements in this emerging field and hopes to inspire new
avenues of research. First, we examine several challenges encountered by
current RL algorithms. Then, we present a taxonomy of existing methods based on
the roles played by diffusion models in RL and explore how the existing
challenges are addressed. We further outline successful applications of
diffusion models in various RL-related tasks while discussing the limitations
of current approaches. Finally, we conclude the survey and offer insights into
future research directions, focusing on enhancing model performance and
applying diffusion models to broader tasks. We are actively maintaining a
GitHub repository for papers and other related resources in applying diffusion
models in RL: https://github.com/apexrl/Diff4RLSurvey .
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01224" title="Abstract">arXiv:2311.01224</a> [<a href="/pdf/2311.01224" title="Download PDF">pdf</a>, <a href="/format/2311.01224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EISim: A Platform for Simulating Intelligent Edge Orchestration  Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kokkonen%2C+H">Henna Kokkonen</a>, 
<a href="/search/cs?searchtype=author&query=Pirttikangas%2C+S">Susanna Pirttikangas</a>, 
<a href="/search/cs?searchtype=author&query=Lov%C3%A9n%2C+L">Lauri Lov&#xe9;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">To support the stringent requirements of the future intelligent and
interactive applications, intelligence needs to become an essential part of the
resource management in the edge environment. Developing intelligent
orchestration solutions is a challenging and arduous task, where the evaluation
and comparison of the proposed solution is a focal point. Simulation is
commonly used to evaluate and compare proposed solutions. However, the
currently existing, openly available simulators are lacking in terms of
supporting the research on intelligent edge orchestration methods. To address
this need, this article presents a simulation platform called Edge Intelligence
Simulator (EISim), the purpose of which is to facilitate the research on
intelligent edge orchestration solutions. EISim is extended from an existing
fog simulator called PureEdgeSim. In its current form, EISim supports
simulating deep reinforcement learning based solutions and different
orchestration control topologies in scenarios related to task offloading and
resource pricing on edge. The platform also includes additional tools for
creating simulation environments, running simulations for agent training and
evaluation, and plotting results.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01226" title="Abstract">arXiv:2311.01226</a> [<a href="/pdf/2311.01226" title="Download PDF">pdf</a>, <a href="/format/2311.01226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Transport-Guided Conditional Score-Based Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+X">Xiang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zongben Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Conditional score-based diffusion model (SBDM) is for conditional generation
of target data with paired data as condition, and has achieved great success in
image translation. However, it requires the paired data as condition, and there
would be insufficient paired data provided in real-world applications. To
tackle the applications with partially paired or even unpaired dataset, we
propose a novel Optimal Transport-guided Conditional Score-based diffusion
model (OTCS) in this paper. We build the coupling relationship for the unpaired
or partially paired dataset based on $L_2$-regularized unsupervised or
semi-supervised optimal transport, respectively. Based on the coupling
relationship, we develop the objective for training the conditional score-based
model for unpaired or partially paired settings, which is based on a
reformulation and generalization of the conditional SBDM for paired setting.
With the estimated coupling relationship, we effectively train the conditional
score-based model by designing a ``resampling-by-compatibility'' strategy to
choose the sampled data with high compatibility as guidance. Extensive
experiments on unpaired super-resolution and semi-paired image-to-image
translation demonstrated the effectiveness of the proposed OTCS model. From the
viewpoint of optimal transport, OTCS provides an approach to transport data
across distributions, which is a challenge for OT on large-scale datasets. We
theoretically prove that OTCS realizes the data transport in OT with a
theoretical bound. Code is available at \url{https://github.com/XJTU-XGU/OTCS}.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01227" title="Abstract">arXiv:2311.01227</a> [<a href="/pdf/2311.01227" title="Download PDF">pdf</a>, <a href="/format/2311.01227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Feature Learning and Global Variance-Driven Classifier Alignment  for Long-Tail Class Incremental Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalla%2C+J">Jayateja Kalla</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+S">Soma Biswas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper introduces a two-stage framework designed to enhance long-tail
class incremental learning, enabling the model to progressively learn new
classes, while mitigating catastrophic forgetting in the context of long-tailed
data distributions. Addressing the challenge posed by the under-representation
of tail classes in long-tail class incremental learning, our approach achieves
classifier alignment by leveraging global variance as an informative measure
and class prototypes in the second stage. This process effectively captures
class properties and eliminates the need for data balancing or additional layer
tuning. Alongside traditional class incremental learning losses in the first
stage, the proposed approach incorporates mixup classes to learn robust feature
representations, ensuring smoother boundaries. The proposed framework can
seamlessly integrate as a module with any class incremental learning method to
effectively handle long-tail class incremental learning scenarios. Extensive
experimentation on the CIFAR-100 and ImageNet-Subset datasets validates the
approach's efficacy, showcasing its superiority over state-of-the-art
techniques across various long-tail CIL settings.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01229" title="Abstract">arXiv:2311.01229</a> [<a href="/pdf/2311.01229" title="Download PDF">pdf</a>, <a href="/format/2311.01229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Theoretical Analysis of Impact of Delayed Updates on Decentralized  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yong Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Siyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jie Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Decentralized Federated learning is a distributed edge intelligence framework
by exchanging parameter updates instead of training data among participators,
in order to retrain or fine-tune deep learning models for mobile intelligent
applications. Considering the various topologies of edge networks in mobile
internet, the impact of transmission delay of updates during model training is
non-negligible for data-intensive intelligent applications on mobile devices,
e.g., intelligent medical services, automated driving vehicles, etc.. To
address this problem, we analyze the impact of delayed updates for
decentralized federated learning, and provide a theoretical bound for these
updates to achieve model convergence. Within the theoretical bound of updating
period, the latest versions for the delayed updates are reused to continue
aggregation, in case the model parameters from a specific neighbor are not
collected or updated in time.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01230" title="Abstract">arXiv:2311.01230</a> [<a href="/pdf/2311.01230" title="Download PDF">pdf</a>, <a href="/format/2311.01230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Operational Mathematical Derivations in Latent Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valentino%2C+M">Marco Valentino</a>, 
<a href="/search/cs?searchtype=author&query=Meadows%2C+J">Jordan Meadows</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Freitas%2C+A">Andr&#xe9; Freitas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Symbolic Computation (cs.SC)

</div>
<p class="mathjax">This paper investigates the possibility of approximating multiple
mathematical operations in latent space for expression derivation. To this end,
we introduce different multi-operational representation paradigms, modelling
mathematical operations as explicit geometric transformations. By leveraging a
symbolic engine, we construct a large-scale dataset comprising 1.7M derivation
steps stemming from 61K premises and 6 operators, analysing the properties of
each paradigm when instantiated with state-of-the-art neural encoders.
Specifically, we investigate how different encoding mechanisms can approximate
equational reasoning in latent space, exploring the trade-off between learning
different operators and specialising within single operations, as well as the
ability to support multi-step derivations and out-of-distribution
generalisation. Our empirical analysis reveals that the multi-operational
paradigm is crucial for disentangling different operators, while discriminating
the conclusions for a single operation is achievable in the original expression
encoder. Moreover, we show that architectural choices can heavily affect the
training dynamics, structural organisation, and generalisation of the latent
space, resulting in significant variations across paradigms and classes of
encoders.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01233" title="Abstract">arXiv:2311.01233</a> [<a href="/pdf/2311.01233" title="Download PDF">pdf</a>, <a href="/format/2311.01233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long Story Short: a Summarize-then-Search Method for Long Video Question  Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chung%2C+J">Jiwan Chung</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Youngjae Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in BMVC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models such as GPT-3 have demonstrated an impressive
capability to adapt to new tasks without requiring task-specific training data.
This capability has been particularly effective in settings such as narrative
question answering, where the diversity of tasks is immense, but the available
supervision data is small. In this work, we investigate if such language models
can extend their zero-shot reasoning abilities to long multimodal narratives in
multimedia content such as drama, movies, and animation, where the story plays
an essential role. We propose Long Story Short, a framework for narrative video
QA that first summarizes the narrative of the video to a short plot and then
searches parts of the video relevant to the question. We also propose to
enhance visual matching with CLIPCheck. Our model outperforms state-of-the-art
supervised models by a large margin, highlighting the potential of zero-shot QA
for long videos.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01235" title="Abstract">arXiv:2311.01235</a> [<a href="/pdf/2311.01235" title="Download PDF">pdf</a>, <a href="/format/2311.01235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating Complex Search Tasks with AI Copilots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=White%2C+R+W">Ryen W. White</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As many of us in the information retrieval (IR) research community know and
appreciate, search is far from being a solved problem. Millions of people
struggle with tasks on search engines every day. Often, their struggles relate
to the intrinsic complexity of their task and the failure of search systems to
fully understand the task and serve relevant results. The task motivates the
search, creating the gap/problematic situation that searchers attempt to
bridge/resolve and drives search behavior as they work through different task
facets. Complex search tasks require more than support for rudimentary fact
finding or re-finding. Research on methods to support complex tasks includes
work on generating query and website suggestions, personalizing and
contextualizing search, and developing new search experiences, including those
that span time and space. The recent emergence of generative artificial
intelligence (AI) and the arrival of assistive agents, or copilots, based on
this technology, has the potential to offer further assistance to searchers,
especially those engaged in complex tasks. There are profound implications from
these advances for the design of intelligent systems and for the future of
search itself. This article, based on a keynote by the author at the 2023 ACM
SIGIR Conference, explores these issues and charts a course toward new horizons
in information access guided by AI copilots.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01237" title="Abstract">arXiv:2311.01237</a> [<a href="/pdf/2311.01237" title="Download PDF">pdf</a>, <a href="/format/2311.01237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Log-Likelihood Score Level Fusion for Improved Cross-Sensor Smartphone  Periocular Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alonso-Fernandez%2C+F">Fernando Alonso-Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=Raja%2C+K+B">Kiran B. Raja</a>, 
<a href="/search/cs?searchtype=author&query=Busch%2C+C">Christoph Busch</a>, 
<a href="/search/cs?searchtype=author&query=Bigun%2C+J">Josef Bigun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at Proc. 25th European Signal Processing Conference, EUSIPCO 2017. arXiv admin note: text overlap with <a href="/abs/1902.08123">arXiv:1902.08123</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The proliferation of cameras and personal devices results in a wide
variability of imaging conditions, producing large intra-class variations and a
significant performance drop when images from heterogeneous environments are
compared. However, many applications require to deal with data from different
sources regularly, thus needing to overcome these interoperability problems.
Here, we employ fusion of several comparators to improve periocular performance
when images from different smartphones are compared. We use a probabilistic
fusion framework based on linear logistic regression, in which fused scores
tend to be log-likelihood ratios, obtaining a reduction in cross-sensor EER of
up to 40% due to the fusion. Our framework also provides an elegant and simple
solution to handle signals from different devices, since same-sensor and
cross-sensor score distributions are aligned and mapped to a common
probabilistic domain. This allows the use of Bayes thresholds for optimal
decision-making, eliminating the need of sensor-specific thresholds, which is
essential in operational conditions because the threshold setting critically
determines the accuracy of the authentication process in many applications.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01240" title="Abstract">arXiv:2311.01240</a> [<a href="/pdf/2311.01240" title="Download PDF">pdf</a>, <a href="/format/2311.01240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FacadeNet: Conditional Facade Synthesis via Selective Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Georgiou%2C+Y">Yiangos Georgiou</a>, 
<a href="/search/cs?searchtype=author&query=Loizou%2C+M">Marios Loizou</a>, 
<a href="/search/cs?searchtype=author&query=Kelly%2C+T">Tom Kelly</a>, 
<a href="/search/cs?searchtype=author&query=Averkiou%2C+M">Melinos Averkiou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We introduce FacadeNet, a deep learning approach for synthesizing building
facade images from diverse viewpoints. Our method employs a conditional GAN,
taking a single view of a facade along with the desired viewpoint information
and generates an image of the facade from the distinct viewpoint. To precisely
modify view-dependent elements like windows and doors while preserving the
structure of view-independent components such as walls, we introduce a
selective editing module. This module leverages image embeddings extracted from
a pre-trained vision transformer. Our experiments demonstrated state-of-the-art
performance on building facade generation, surpassing alternative methods.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01243" title="Abstract">arXiv:2311.01243</a> [<a href="/pdf/2311.01243" title="Download PDF">pdf</a>, <a href="/format/2311.01243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting MAB based approaches to recursive delegation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oren%2C+N">Nir Oren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">In this paper we examine the effectiveness of several multi-arm bandit
algorithms when used as a trust system to select agents to delegate tasks to.
In contrast to existing work, we allow for recursive delegation to occur. That
is, a task delegated to one agent can be delegated onwards by that agent, with
further delegation possible until some agent finally executes the task. We show
that modifications to the standard multi-arm bandit algorithms can provide
improvements in performance in such recursive delegation settings.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01245" title="Abstract">arXiv:2311.01245</a> [<a href="/pdf/2311.01245" title="Download PDF">pdf</a>, <a href="/format/2311.01245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustness for Free: Quality-Diversity Driven Discovery of Agile Soft  Robotic Gaits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daly%2C+J">John Daly</a>, 
<a href="/search/cs?searchtype=author&query=Casper%2C+D">Daniel Casper</a>, 
<a href="/search/cs?searchtype=author&query=Farooq%2C+M">Muhammad Farooq</a>, 
<a href="/search/cs?searchtype=author&query=James%2C+A">Andrew James</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Ali Khan</a>, 
<a href="/search/cs?searchtype=author&query=Mulgrew%2C+P">Phoenix Mulgrew</a>, 
<a href="/search/cs?searchtype=author&query=Tyebkhan%2C+D">Daniel Tyebkhan</a>, 
<a href="/search/cs?searchtype=author&query=Vo%2C+B">Bao Vo</a>, 
<a href="/search/cs?searchtype=author&query=Rieffel%2C+J">John Rieffel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, submitted to IEEE RoboSoft
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Soft robotics aims to develop robots able to adapt their behavior across a
wide range of unstructured and unknown environments. A critical challenge of
soft robotic control is that nonlinear dynamics often result in complex
behaviors hard to model and predict. Typically behaviors for mobile soft robots
are discovered through empirical trial and error and hand-tuning. More
recently, optimization algorithms such as Genetic Algorithms (GA) have been
used to discover gaits, but these behaviors are often optimized for a single
environment or terrain, and can be brittle to unplanned changes to terrain. In
this paper we demonstrate how Quality Diversity Algorithms, which search of a
range of high-performing behaviors, can produce repertoires of gaits that are
robust to changing terrains. This robustness significantly out-performs that of
gaits produced by a single objective optimization algorithm.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01247" title="Abstract">arXiv:2311.01247</a> [<a href="/pdf/2311.01247" title="Download PDF">pdf</a>, <a href="/format/2311.01247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergent (In)Security of Multi-Cloud Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reece%2C+M">Morgan Reece</a>, 
<a href="/search/cs?searchtype=author&query=Lander%2C+T">Theodore Lander Jr.</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+S">Sudip Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Rastogi%2C+N">Nidhi Rastogi</a>, 
<a href="/search/cs?searchtype=author&query=Dykstra%2C+J">Josiah Dykstra</a>, 
<a href="/search/cs?searchtype=author&query=Sampson%2C+A">Andy Sampson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">As organizations increasingly use cloud services to host their IT
infrastructure, there is a need to share data among these cloud hosted services
and systems. A majority of IT organizations have workloads spread across
different cloud service providers, growing their multi-cloud environments. When
an organization grows their multi-cloud environment, the threat vectors and
vulnerabilities for their cloud systems and services grow as well. The increase
in the number of attack vectors creates a challenge of how to prioritize
mitigations and countermeasures to best defend a multi-cloud environment
against attacks. Utilizing multiple industry standard risk analysis tools, we
conducted an analysis of multi-cloud threat vectors enabling calculation and
prioritization for the identified mitigations and countermeasures. The
prioritizations from the analysis showed that authentication and architecture
are the highest risk areas of threat vectors. Armed with this data, IT managers
are able to more appropriately budget cybersecurity expenditure to implement
the most impactful mitigations and countermeasures.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01248" title="Abstract">arXiv:2311.01248</a> [<a href="/pdf/2311.01248" title="Download PDF">pdf</a>, <a href="/format/2311.01248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Push it to the Demonstrated Limit: Multimodal Visuotactile Imitation  Learning with Force Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ablett%2C+T">Trevor Ablett</a>, 
<a href="/search/cs?searchtype=author&query=Limoyo%2C+O">Oliver Limoyo</a>, 
<a href="/search/cs?searchtype=author&query=Sigal%2C+A">Adam Sigal</a>, 
<a href="/search/cs?searchtype=author&query=Jilani%2C+A">Affan Jilani</a>, 
<a href="/search/cs?searchtype=author&query=Kelly%2C+J">Jonathan Kelly</a>, 
<a href="/search/cs?searchtype=author&query=Siddiqi%2C+K">Kaleem Siddiqi</a>, 
<a href="/search/cs?searchtype=author&query=Hogan%2C+F">Francois Hogan</a>, 
<a href="/search/cs?searchtype=author&query=Dudek%2C+G">Gregory Dudek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Optical tactile sensors have emerged as an effective means to acquire dense
contact information during robotic manipulation. A recently-introduced
`see-through-your-skin' (STS) variant of this type of sensor has both visual
and tactile modes, enabled by leveraging a semi-transparent surface and
controllable lighting. In this work, we investigate the benefits of pairing
visuotactile sensing with imitation learning for contact-rich manipulation
tasks. First, we use tactile force measurements and a novel algorithm during
kinesthetic teaching to yield a force profile that better matches that of the
human demonstrator. Second, we add visual/tactile STS mode switching as a
control policy output, simplifying the application of the sensor. Finally, we
study multiple observation configurations to compare and contrast the value of
visual/tactile data (both with and without mode switching) with visual data
from a wrist-mounted eye-in-hand camera. We perform an extensive series of
experiments on a real robotic manipulator with door-opening and closing tasks,
including over 3,000 real test episodes. Our results highlight the importance
of tactile sensing for imitation learning, both for data collection to allow
force matching, and for policy execution to allow accurate task feedback.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01252" title="Abstract">arXiv:2311.01252</a> [<a href="/pdf/2311.01252" title="Download PDF">pdf</a>, <a href="/format/2311.01252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sanitized Clustering against Confounding Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yinghua Yao</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yuangang Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jing Li</a>, 
<a href="/search/cs?searchtype=author&query=Tsang%2C+I+W">Ivor W. Tsang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xin Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Machine Learning, in press
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Real-world datasets inevitably contain biases that arise from different
sources or conditions during data collection. Consequently, such inconsistency
itself acts as a confounding factor that disturbs the cluster analysis.
Existing methods eliminate the biases by projecting data onto the orthogonal
complement of the subspace expanded by the confounding factor before
clustering. Therein, the interested clustering factor and the confounding
factor are coarsely considered in the raw feature space, where the correlation
between the data and the confounding factor is ideally assumed to be linear for
convenient solutions. These approaches are thus limited in scope as the data in
real applications is usually complex and non-linearly correlated with the
confounding factor. This paper presents a new clustering framework named
Sanitized Clustering Against confounding Bias (SCAB), which removes the
confounding factor in the semantic latent space of complex data through a
non-linear dependence measure. To be specific, we eliminate the bias
information in the latent space by minimizing the mutual information between
the confounding factor and the latent representation delivered by Variational
Auto-Encoder (VAE). Meanwhile, a clustering module is introduced to cluster
over the purified latent representations. Extensive experiments on complex
datasets demonstrate that our SCAB achieves a significant gain in clustering
performance by removing the confounding bias. The code is available at
\url{https://github.com/EvaFlower/SCAB}.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01253" title="Abstract">arXiv:2311.01253</a> [<a href="/pdf/2311.01253" title="Download PDF">pdf</a>, <a href="/format/2311.01253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Concept for User-Centered Delegation of Abstract High-Level Tasks to  Cobots for Flexible Lot Sizes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+M">Moritz Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Meitinger%2C+C">Claudia Meitinger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Technical advances in collaborative robots (cobots) are making them
increasingly attractive to companies. However, many human operators are not
trained to program complex machines. Instead, humans are used to communicating
with each other on a task-based level rather than through specific
instructions, as is common with machines. The gap between low-level
instruction-based and high-level task-based communication leads to low values
for usability scores of teach pendant programming. As a solution, we propose a
task-based interaction concept that allows human operators to delegate a
complex task to a machine without programming by specifying a task via
triplets. The concept is based on task decomposition and a reasoning system
using a cognitive architecture. The approach is evaluated in an industrial use
case where mineral cast basins have to be sanded by a cobot in a crafts
enterprise.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01254" title="Abstract">arXiv:2311.01254</a> [<a href="/pdf/2311.01254" title="Download PDF">pdf</a>, <a href="/format/2311.01254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human participants in AI research: Ethics and transparency in practice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McKee%2C+K+R">Kevin R. McKee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">In recent years, research involving human participants has been critical to
advances in artificial intelligence (AI) and machine learning (ML),
particularly in the areas of conversational, human-compatible, and cooperative
AI. For example, around 12% and 6% of publications at recent AAAI and NeurIPS
conferences indicate the collection of original human data, respectively. Yet
AI and ML researchers lack guidelines for ethical, transparent research
practices with human participants. Fewer than one out of every four of these
AAAI and NeurIPS papers provide details of ethical review, the collection of
informed consent, or participant compensation. This paper aims to bridge this
gap by exploring normative similarities and differences between AI research and
related fields that involve human participants. Though psychology,
human-computer interaction, and other adjacent fields offer historic lessons
and helpful insights, AI research raises several specific
concerns$\unicode{x2014}$namely, participatory design, crowdsourced dataset
development, and an expansive role of corporations$\unicode{x2014}$that
necessitate a contextual ethics framework. To address these concerns, this
paper outlines a set of guidelines for ethical and transparent practice with
human participants in AI and ML research. These guidelines can be found in
Section 4 on pp. 4$\unicode{x2013}$7.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01256" title="Abstract">arXiv:2311.01256</a> [<a href="/pdf/2311.01256" title="Download PDF">pdf</a>, <a href="/format/2311.01256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An energy-based comparative analysis of common approaches to text  classification in the Legal domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gultekin%2C+S">Sinan Gultekin</a>, 
<a href="/search/cs?searchtype=author&query=Globo%2C+A">Achille Globo</a>, 
<a href="/search/cs?searchtype=author&query=Zugarini%2C+A">Andrea Zugarini</a>, 
<a href="/search/cs?searchtype=author&query=Ernandes%2C+M">Marco Ernandes</a>, 
<a href="/search/cs?searchtype=author&query=Rigutini%2C+L">Leonardo Rigutini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at The 4th International Conference on NLP &amp; Text Mining (NLTM 2024), January 27-28 2024, Copenhagen, Denmark - 12 pages, 1 figure, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Performance (cs.PF)

</div>
<p class="mathjax">Most Machine Learning research evaluates the best solutions in terms of
performance. However, in the race for the best performing model, many important
aspects are often overlooked when, on the contrary, they should be carefully
considered. In fact, sometimes the gaps in performance between different
approaches are neglectable, whereas factors such as production costs, energy
consumption, and carbon footprint must take into consideration. Large Language
Models (LLMs) are extensively adopted to address NLP problems in academia and
industry. In this work, we present a detailed quantitative comparison of LLM
and traditional approaches (e.g. SVM) on the LexGLUE benchmark, which takes
into account both performance (standard indices) and alternative metrics such
as timing, power consumption and cost, in a word: the carbon-footprint. In our
analysis, we considered the prototyping phase (model selection by
training-validation-test iterations) and in-production phases separately, since
they follow different implementation procedures and also require different
resources. The results indicate that very often, the simplest algorithms
achieve performance very close to that of large LLMs but with very low power
consumption and lower resource demands. The results obtained could suggest
companies to include additional evaluations in the choice of Machine Learning
(ML) solutions.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01258" title="Abstract">arXiv:2311.01258</a> [<a href="/pdf/2311.01258" title="Download PDF">pdf</a>, <a href="/format/2311.01258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formal Methods for Autonomous Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wongpiromsarn%2C+T">Tichakorn Wongpiromsarn</a>, 
<a href="/search/cs?searchtype=author&query=Ghasemi%2C+M">Mahsa Ghasemi</a>, 
<a href="/search/cs?searchtype=author&query=Cubuktepe%2C+M">Murat Cubuktepe</a>, 
<a href="/search/cs?searchtype=author&query=Bakirtzis%2C+G">Georgios Bakirtzis</a>, 
<a href="/search/cs?searchtype=author&query=Carr%2C+S">Steven Carr</a>, 
<a href="/search/cs?searchtype=author&query=Karabag%2C+M+O">Mustafa O. Karabag</a>, 
<a href="/search/cs?searchtype=author&query=Neary%2C+C">Cyrus Neary</a>, 
<a href="/search/cs?searchtype=author&query=Gohari%2C+P">Parham Gohari</a>, 
<a href="/search/cs?searchtype=author&query=Topcu%2C+U">Ufuk Topcu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO); Systems and Control (eess.SY)

</div>
<p class="mathjax">Formal methods refer to rigorous, mathematical approaches to system
development and have played a key role in establishing the correctness of
safety-critical systems. The main building blocks of formal methods are models
and specifications, which are analogous to behaviors and requirements in system
design and give us the means to verify and synthesize system behaviors with
formal guarantees.
<br />This monograph provides a survey of the current state of the art on
applications of formal methods in the autonomous systems domain. We consider
correct-by-construction synthesis under various formulations, including closed
systems, reactive, and probabilistic settings. Beyond synthesizing systems in
known environments, we address the concept of uncertainty and bound the
behavior of systems that employ learning using formal methods. Further, we
examine the synthesis of systems with monitoring, a mitigation technique for
ensuring that once a system deviates from expected behavior, it knows a way of
returning to normalcy. We also show how to overcome some limitations of formal
methods themselves with learning. We conclude with future directions for formal
methods in reinforcement learning, uncertainty, privacy, explainability of
formal methods, and regulation and certification.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01263" title="Abstract">arXiv:2311.01263</a> [<a href="/pdf/2311.01263" title="Download PDF">pdf</a>, <a href="/format/2311.01263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Neural Ranking using Forward Indexes and Lightweight Encoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leonhardt%2C+J">Jurek Leonhardt</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+H">Henrik M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Rudra%2C+K">Koustav Rudra</a>, 
<a href="/search/cs?searchtype=author&query=Khosla%2C+M">Megha Khosla</a>, 
<a href="/search/cs?searchtype=author&query=Anand%2C+A">Abhijit Anand</a>, 
<a href="/search/cs?searchtype=author&query=Anand%2C+A">Avishek Anand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ACM TOIS. arXiv admin note: text overlap with <a href="/abs/2110.06051">arXiv:2110.06051</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Dual-encoder-based dense retrieval models have become the standard in IR.
They employ large Transformer-based language models, which are notoriously
inefficient in terms of resources and latency. We propose Fast-Forward indexes
-- vector forward indexes which exploit the semantic matching capabilities of
dual-encoder models for efficient and effective re-ranking. Our framework
enables re-ranking at very high retrieval depths and combines the merits of
both lexical and semantic matching via score interpolation. Furthermore, in
order to mitigate the limitations of dual-encoders, we tackle two main
challenges: Firstly, we improve computational efficiency by either
pre-computing representations, avoiding unnecessary computations altogether, or
reducing the complexity of encoders. This allows us to considerably improve
ranking efficiency and latency. Secondly, we optimize the memory footprint and
maintenance cost of indexes; we propose two complementary techniques to reduce
the index size and show that, by dynamically dropping irrelevant document
tokens, the index maintenance efficiency can be improved substantially. We
perform evaluation to show the effectiveness and efficiency of Fast-Forward
indexes -- our method has low latency and achieves competitive results without
the need for hardware acceleration, such as GPUs.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01264" title="Abstract">arXiv:2311.01264</a> [<a href="/pdf/2311.01264" title="Download PDF">pdf</a>, <a href="/ps/2311.01264" title="Download PostScript">ps</a>, <a href="/format/2311.01264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure preserving discontinuous Galerkin approximation of a  hyperbolic-parabolic system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bause%2C+M">Markus Bause</a>, 
<a href="/search/math?searchtype=author&query=Franz%2C+S">Sebastian Franz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We study the numerical approximation of a coupled hyperbolic-parabolic system
by a family of discontinuous Galerkin space-time finite element methods. The
model is rewritten as a first-order evolutionary problem that is treated by the
unified abstract solution theory of R.\ Picard. To preserve the mathematical
structure of the evolutionary equation on the fully discrete level, suitable
generalizations of the distribution gradient and divergence operators on broken
polynomial spaces on which the discontinuous Galerkin approach is built on are
defined. Well-posedness of the fully discrete problem and error estimates for
the discontinuous Galerkin approximation in space and time are proved.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01266" title="Abstract">arXiv:2311.01266</a> [<a href="/pdf/2311.01266" title="Download PDF">pdf</a>, <a href="/format/2311.01266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Let&#x27;s Discover More API Relations: A Large Language Model-based AI Chain  for Unsupervised API Relation Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yanbang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhenchang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yuanlong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jieshan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Huan Jin</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiaxing Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">APIs have intricate relations that can be described in text and represented
as knowledge graphs to aid software engineering tasks. Existing relation
extraction methods have limitations, such as limited API text corpus and
affected by the characteristics of the input text.To address these limitations,
we propose utilizing large language models (LLMs) (e.g., GPT-3.5) as a neural
knowledge base for API relation inference. This approach leverages the entire
Web used to pre-train LLMs as a knowledge base and is insensitive to the
context and complexity of input texts. To ensure accurate inference, we design
our analytic flow as an AI Chain with three AI modules: API FQN Parser, API
Knowledge Extractor, and API Relation Decider. The accuracy of the API FQN
parser and API Relation Decider module are 0.81 and 0.83, respectively. Using
the generative capacity of the LLM and our approach's inference capability, we
achieve an average F1 value of 0.76 under the three datasets, significantly
higher than the state-of-the-art method's average F1 value of 0.40. Compared to
CoT-based method, our AI Chain design improves the inference reliability by
67%, and the AI-crowd-intelligence strategy enhances the robustness of our
approach by 26%.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01267" title="Abstract">arXiv:2311.01267</a> [<a href="/pdf/2311.01267" title="Download PDF">pdf</a>, <a href="/format/2311.01267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniFolding: Towards Sample-efficient, Scalable, and Generalizable  Robotic Garment Folding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Han Xue</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yutong Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wenqiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huanyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">Dongzhe Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CoRL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper explores the development of UniFolding, a sample-efficient,
scalable, and generalizable robotic system for unfolding and folding various
garments. UniFolding employs the proposed UFONet neural network to integrate
unfolding and folding decisions into a single policy model that is adaptable to
different garment types and states. The design of UniFolding is based on a
garment's partial point cloud, which aids in generalization and reduces
sensitivity to variations in texture and shape. The training pipeline
prioritizes low-cost, sample-efficient data collection. Training data is
collected via a human-centric process with offline and online stages. The
offline stage involves human unfolding and folding actions via Virtual Reality,
while the online stage utilizes human-in-the-loop learning to fine-tune the
model in a real-world setting. The system is tested on two garment types:
long-sleeve and short-sleeve shirts. Performance is evaluated on 20 shirts with
significant variations in textures, shapes, and materials. More experiments and
videos can be found in the supplementary materials and on the website:
https://unifolding.robotflow.ai
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01270" title="Abstract">arXiv:2311.01270</a> [<a href="/pdf/2311.01270" title="Download PDF">pdf</a>, <a href="/format/2311.01270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> People Make Better Edits: Measuring the Efficacy of LLM-Generated  Counterfactually Augmented Data for Harmful Language Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sen%2C+I">Indira Sen</a>, 
<a href="/search/cs?searchtype=author&query=Assenmacher%2C+D">Dennis Assenmacher</a>, 
<a href="/search/cs?searchtype=author&query=Samory%2C+M">Mattia Samory</a>, 
<a href="/search/cs?searchtype=author&query=Augenstein%2C+I">Isabelle Augenstein</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Aalst%2C+W">Wil van der Aalst</a>, 
<a href="/search/cs?searchtype=author&query=Wagne%2C+C">Claudia Wagne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint of EMNLP'23 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">NLP models are used in a variety of critical social computing tasks, such as
detecting sexist, racist, or otherwise hateful content. Therefore, it is
imperative that these models are robust to spurious features. Past work has
attempted to tackle such spurious features using training data augmentation,
including Counterfactually Augmented Data (CADs). CADs introduce minimal
changes to existing training data points and flip their labels; training on
them may reduce model dependency on spurious features. However, manually
generating CADs can be time-consuming and expensive. Hence in this work, we
assess if this task can be automated using generative NLP models. We
automatically generate CADs using Polyjuice, ChatGPT, and Flan-T5, and evaluate
their usefulness in improving model robustness compared to manually-generated
CADs. By testing both model performance on multiple out-of-domain test sets and
individual data point efficacy, our results show that while manual CADs are
still the most effective, CADs generated by ChatGPT come a close second. One
key reason for the lower performance of automated methods is that the changes
they introduce are often insufficient to flip the original label.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01273" title="Abstract">arXiv:2311.01273</a> [<a href="/pdf/2311.01273" title="Download PDF">pdf</a>, <a href="/format/2311.01273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Common Ground: Annotating and Predicting Common Ground in Spoken  Conversations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Markowska%2C+M">Magdalena Markowska</a>, 
<a href="/search/cs?searchtype=author&query=Taghizadeh%2C+M">Mohammad Taghizadeh</a>, 
<a href="/search/cs?searchtype=author&query=Soubki%2C+A">Adil Soubki</a>, 
<a href="/search/cs?searchtype=author&query=Mirroshandel%2C+S+A">Seyed Abolghasem Mirroshandel</a>, 
<a href="/search/cs?searchtype=author&query=Rambow%2C+O">Owen Rambow</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">When we communicate with other humans, we do not simply generate a sequence
of words. Rather, we use our cognitive state (beliefs, desires, intentions) and
our model of the audience's cognitive state to create utterances that affect
the audience's cognitive state in the intended manner. An important part of
cognitive state is the common ground, which is the content the speaker
believes, and the speaker believes the audience believes, and so on. While much
attention has been paid to common ground in cognitive science, there has not
been much work in natural language processing. In this paper, we introduce a
new annotation and corpus to capture common ground. We then describe some
initial experiments extracting propositions from dialog and tracking their
status in the common ground from the perspective of each speaker.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01274" title="Abstract">arXiv:2311.01274</a> [<a href="/pdf/2311.01274" title="Download PDF">pdf</a>, <a href="/format/2311.01274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Layer-adapted meshes for singularly perturbed problems via mesh partial  differential equations and a posteriori information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hill%2C+R">R&#xf3;is&#xed;n Hill</a>, 
<a href="/search/math?searchtype=author&query=Madden%2C+N">Niall Madden</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 5 figures, FEniCS code
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose a new method for the construction of layer-adapted meshes for
singularly perturbed differential equations (SPDEs), based on mesh partial
differential equations (MPDEs) that incorporate \emph{a posteriori} solution
information. There are numerous studies on the development of parameter robust
numerical methods for SPDEs that depend on the layer-adapted mesh of Bakhvalov.
In~\citep{HiMa2021}, a novel MPDE-based approach for constructing a
generalisation of these meshes was proposed. Like with most layer-adapted mesh
methods, the algorithms in that article depended on detailed derivations of
\emph{a priori} bounds on the SPDE's solution and its derivatives. In this work
we extend that approach so that it instead uses \emph{a posteriori} computed
estimates of the solution. We present detailed algorithms for the efficient
implementation of the method, and numerical results for the robust solution of
two-parameter reaction-convection-diffusion problems, in one and two
dimensions. We also provide full FEniCS code for a one-dimensional example.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01276" title="Abstract">arXiv:2311.01276</a> [<a href="/pdf/2311.01276" title="Download PDF">pdf</a>, <a href="/format/2311.01276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long-Range Neural Atom Learning for Molecular Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhanke Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiangchao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+Y">Yu Rong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bo Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Graph Neural Networks (GNNs) have been widely adopted for drug discovery with
molecular graphs. Nevertheless, current GNNs are mainly good at leveraging
short-range interactions (SRI) but struggle to capture long-range interactions
(LRI), both of which are crucial for determining molecular properties. To
tackle this issue, we propose a method that implicitly projects all original
atoms into a few Neural Atoms, which abstracts the collective information of
atomic groups within a molecule. Specifically, we explicitly exchange the
information among neural atoms and project them back to the atoms'
representations as an enhancement. With this mechanism, neural atoms establish
the communication channels among distant nodes, effectively reducing the
interaction scope of arbitrary node pairs into a single hop. To provide an
inspection of our method from a physical perspective, we reveal its connection
with the traditional LRI calculation method, Ewald Summation. We conduct
extensive experiments on three long-range graph benchmarks, covering both
graph-level and link-level tasks on molecular graphs. We empirically justify
that our method can be equipped with an arbitrary GNN and help to capture LRI.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01279" title="Abstract">arXiv:2311.01279</a> [<a href="/pdf/2311.01279" title="Download PDF">pdf</a>, <a href="/format/2311.01279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ExPECA: An Experimental Platform for Trustworthy Edge Computing  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mostafavi%2C+S">Samie Mostafavi</a>, 
<a href="/search/cs?searchtype=author&query=Moothedath%2C+V+N">Vishnu Narayanan Moothedath</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%B6nngren%2C+S">Stefan R&#xf6;nngren</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+N">Neelabhro Roy</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+G+P">Gourav Prateek Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+S">Sangwon Seo</a>, 
<a href="/search/cs?searchtype=author&query=Mu%C3%B1oz%2C+M+O">Manuel Olgu&#xed;n Mu&#xf1;oz</a>, 
<a href="/search/cs?searchtype=author&query=Gross%2C+J">James Gross</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper presents ExPECA, an edge computing and wireless communication
research testbed designed to tackle two pressing challenges: comprehensive
end-to-end experimentation and high levels of experimental reproducibility.
Leveraging OpenStack-based Chameleon Infrastructure (CHI) framework for its
proven flexibility and ease of operation, ExPECA is located in a unique,
isolated underground facility, providing a highly controlled setting for
wireless experiments. The testbed is engineered to facilitate integrated
studies of both communication and computation, offering a diverse array of
Software-Defined Radios (SDR) and Commercial Off-The-Shelf (COTS) wireless and
wired links, as well as containerized computational environments. We exemplify
the experimental possibilities of the testbed using OpenRTiST, a
latency-sensitive, bandwidth-intensive application, and analyze its
performance. Lastly, we highlight an array of research domains and experimental
setups that stand to gain from ExPECA's features, including closed-loop
applications and time-sensitive networking.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01282" title="Abstract">arXiv:2311.01282</a> [<a href="/pdf/2311.01282" title="Download PDF">pdf</a>, <a href="/format/2311.01282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlashDecoding++: Faster Large Language Model Inference on GPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+K">Ke Hong</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+G">Guohao Dai</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiaming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Q">Qiuli Mao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiuhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kangdi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hanyu Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">As the Large Language Model (LLM) becomes increasingly important in various
domains. However, the following challenges still remain unsolved in
accelerating LLM inference: (1) Synchronized partial softmax update. The
softmax operation requires a synchronized update operation among each partial
softmax result, leading to ~20% overheads for the attention computation in
LLMs. (2) Under-utilized computation of flat GEMM. The shape of matrices
performing GEMM in LLM inference is flat, leading to under-utilized computation
and &gt;50% performance loss after padding zeros in previous designs. (3)
Performance loss due to static dataflow. Kernel performance in LLM depends on
varied input data features, hardware configurations, etc. A single and static
dataflow may lead to a 50.25% performance loss for GEMMs of different shapes in
LLM inference.
<br />We present FlashDecoding++, a fast LLM inference engine supporting mainstream
LLMs and hardware back-ends. To tackle the above challenges, FlashDecoding++
creatively proposes: (1) Asynchronized softmax with unified max value.
FlashDecoding++ introduces a unified max value technique for different partial
softmax computations to avoid synchronization. (2) Flat GEMM optimization with
double buffering. FlashDecoding++ points out that flat GEMMs with different
shapes face varied bottlenecks. Then, techniques like double buffering are
introduced. (3) Heuristic dataflow with hardware resource adaptation.
FlashDecoding++ heuristically optimizes dataflow using different hardware
resource considering input dynamics. Due to the versatility of optimizations in
FlashDecoding++, FlashDecoding++ can achieve up to 4.86x and 2.18x speedup on
both NVIDIA and AMD GPUs compared to Hugging Face implementations.
FlashDecoding++ also achieves an average speedup of 1.37x compared to
state-of-the-art LLM inference engines on mainstream LLMs.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01283" title="Abstract">arXiv:2311.01283</a> [<a href="/pdf/2311.01283" title="Download PDF">pdf</a>, <a href="/format/2311.01283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distilling Knowledge from CNN-Transformer Models for Enhanced Human  Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmadabadi%2C+H">Hamid Ahmadabadi</a>, 
<a href="/search/cs?searchtype=author&query=Manzari%2C+O+N">Omid Nejati Manzari</a>, 
<a href="/search/cs?searchtype=author&query=Ayatollahi%2C+A">Ahmad Ayatollahi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents a study on improving human action recognition through the
utilization of knowledge distillation, and the combination of CNN and ViT
models. The research aims to enhance the performance and efficiency of smaller
student models by transferring knowledge from larger teacher models. The
proposed method employs a Transformer vision network as the student model,
while a convolutional network serves as the teacher model. The teacher model
extracts local image features, whereas the student model focuses on global
features using an attention mechanism. The Vision Transformer (ViT)
architecture is introduced as a robust framework for capturing global
dependencies in images. Additionally, advanced variants of ViT, namely PVT,
Convit, MVIT, Swin Transformer, and Twins, are discussed, highlighting their
contributions to computer vision tasks. The ConvNeXt model is introduced as a
teacher model, known for its efficiency and effectiveness in computer vision.
The paper presents performance results for human action recognition on the
Stanford 40 dataset, comparing the accuracy and mAP of student models trained
with and without knowledge distillation. The findings illustrate that the
suggested approach significantly improves the accuracy and mAP when compared to
training networks under regular settings. These findings emphasize the
potential of combining local and global features in action recognition tasks.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01288" title="Abstract">arXiv:2311.01288</a> [<a href="/pdf/2311.01288" title="Download PDF">pdf</a>, <a href="/format/2311.01288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unraveling Diffusion in Fusion Plasma: A Case Study of In Situ  Processing and Particle Sorting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Junmin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+P">Paul Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kesheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ku%2C+S">Seung-Hoe Ku</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+C+S">C.S. Chang</a>, 
<a href="/search/cs?searchtype=author&query=Churchill%2C+R+M">R. Michael Churchill</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jong Choi</a>, 
<a href="/search/cs?searchtype=author&query=Podhorszki%2C+N">Norbert Podhorszki</a>, 
<a href="/search/cs?searchtype=author&query=Klasky%2C+S">Scott Klasky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Plasma Physics (physics.plasm-ph)

</div>
<p class="mathjax">This work starts an in situ processing capability to study a certain
diffusion process in magnetic confinement fusion. This diffusion process
involves plasma particles that are likely to escape confinement. Such particles
carry a significant amount of energy from the burning plasma inside the tokamak
to the diverter and damaging the diverter plate. This study requires in situ
processing because of the fast changing nature of the particle diffusion
process. However, the in situ processing approach is challenging because the
amount of data to be retained for the diffusion calculations increases over
time, unlike in other in situ processing cases where the amount of data to be
processed is constant over time. Here we report our preliminary efforts to
control the memory usage while ensuring the necessary analysis tasks are
completed in a timely manner. Compared with an earlier naive attempt to
directly computing the same diffusion displacements in the simulation code,
this in situ version reduces the memory usage from particle information by
nearly 60% and computation time by about 20%.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01292" title="Abstract">arXiv:2311.01292</a> [<a href="/pdf/2311.01292" title="Download PDF">pdf</a>, <a href="/format/2311.01292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint 3D Shape and Motion Estimation from Rolling Shutter Light-Field  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McGriff%2C+H">Hermes McGriff</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+R">Renato Martins</a>, 
<a href="/search/cs?searchtype=author&query=Andreff%2C+N">Nicolas Andreff</a>, 
<a href="/search/cs?searchtype=author&query=Demonceaux%2C+C">C&#xe9;dric Demonceaux</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we propose an approach to address the problem of 3D
reconstruction of scenes from a single image captured by a light-field camera
equipped with a rolling shutter sensor. Our method leverages the 3D information
cues present in the light-field and the motion information provided by the
rolling shutter effect. We present a generic model for the imaging process of
this sensor and a two-stage algorithm that minimizes the re-projection error
while considering the position and motion of the camera in a motion-shape
bundle adjustment estimation strategy. Thereby, we provide an instantaneous 3D
shape-and-pose-and-velocity sensing paradigm. To the best of our knowledge,
this is the first study to leverage this type of sensor for this purpose. We
also present a new benchmark dataset composed of different light-fields showing
rolling shutter effects, which can be used as a common base to improve the
evaluation and tracking the progress in the field. We demonstrate the
effectiveness and advantages of our approach through several experiments
conducted for different scenes and types of motions. The source code and
dataset are publicly available at: https://github.com/ICB-Vision-AI/RSLF
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01295" title="Abstract">arXiv:2311.01295</a> [<a href="/pdf/2311.01295" title="Download PDF">pdf</a>, <a href="/ps/2311.01295" title="Download PostScript">ps</a>, <a href="/format/2311.01295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DP-Mix: Mixup-based Data Augmentation for Differentially Private  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+W">Wenxuan Bao</a>, 
<a href="/search/cs?searchtype=author&query=Pittaluga%2C+F">Francesco Pittaluga</a>, 
<a href="/search/cs?searchtype=author&query=G%2C+V+K+B">Vijay Kumar B G</a>, 
<a href="/search/cs?searchtype=author&query=Bindschaedler%2C+V">Vincent Bindschaedler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 2 figures, to be published in Neural Information Processing Systems 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Data augmentation techniques, such as simple image transformations and
combinations, are highly effective at improving the generalization of computer
vision models, especially when training data is limited. However, such
techniques are fundamentally incompatible with differentially private learning
approaches, due to the latter's built-in assumption that each training image's
contribution to the learned model is bounded. In this paper, we investigate why
naive applications of multi-sample data augmentation techniques, such as mixup,
fail to achieve good performance and propose two novel data augmentation
techniques specifically designed for the constraints of differentially private
learning. Our first technique, DP-Mix_Self, achieves SoTA classification
performance across a range of datasets and settings by performing mixup on
self-augmented data. Our second technique, DP-Mix_Diff, further improves
performance by incorporating synthetic data from a pre-trained diffusion model
into the mixup process. We open-source the code at
https://github.com/wenxuan-Bao/DP-Mix.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01301" title="Abstract">arXiv:2311.01301</a> [<a href="/pdf/2311.01301" title="Download PDF">pdf</a>, <a href="/format/2311.01301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TRIALSCOPE A Unifying Causal Framework for Scaling Real-World Evidence  Generation with Biomedical Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A1lez%2C+J">Javier Gonz&#xe1;lez</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+C">Cliff Wong</a>, 
<a href="/search/cs?searchtype=author&query=Gero%2C+Z">Zelalem Gero</a>, 
<a href="/search/cs?searchtype=author&query=Bagga%2C+J">Jass Bagga</a>, 
<a href="/search/cs?searchtype=author&query=Ueno%2C+R">Risa Ueno</a>, 
<a href="/search/cs?searchtype=author&query=Chien%2C+I">Isabel Chien</a>, 
<a href="/search/cs?searchtype=author&query=Orakvin%2C+E">Eduard Orakvin</a>, 
<a href="/search/cs?searchtype=author&query=Kiciman%2C+E">Emre Kiciman</a>, 
<a href="/search/cs?searchtype=author&query=Nori%2C+A">Aditya Nori</a>, 
<a href="/search/cs?searchtype=author&query=Weerasinghe%2C+R">Roshanthi Weerasinghe</a>, 
<a href="/search/cs?searchtype=author&query=Leidner%2C+R+S">Rom S. Leidner</a>, 
<a href="/search/cs?searchtype=author&query=Piening%2C+B">Brian Piening</a>, 
<a href="/search/cs?searchtype=author&query=Naumann%2C+T">Tristan Naumann</a>, 
<a href="/search/cs?searchtype=author&query=Bifulco%2C+C">Carlo Bifulco</a>, 
<a href="/search/cs?searchtype=author&query=Poon%2C+H">Hoifung Poon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 Figures, 22 Pages, 3 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
<p class="mathjax">The rapid digitization of real-world data offers an unprecedented opportunity
for optimizing healthcare delivery and accelerating biomedical discovery. In
practice, however, such data is most abundantly available in unstructured
forms, such as clinical notes in electronic medical records (EMRs), and it is
generally plagued by confounders. In this paper, we present TRIALSCOPE, a
unifying framework for distilling real-world evidence from population-level
observational data. TRIALSCOPE leverages biomedical language models to
structure clinical text at scale, employs advanced probabilistic modeling for
denoising and imputation, and incorporates state-of-the-art causal inference
techniques to combat common confounders. Using clinical trial specification as
generic representation, TRIALSCOPE provides a turn-key solution to generate and
reason with clinical hypotheses using observational data. In extensive
experiments and analyses on a large-scale real-world dataset with over one
million cancer patients from a large US healthcare network, we show that
TRIALSCOPE can produce high-quality structuring of real-world data and
generates comparable results to marquee cancer trials. In addition to
facilitating in-silicon clinical trial design and optimization, TRIALSCOPE may
be used to empower synthetic controls, pragmatic trials, post-market
surveillance, as well as support fine-grained patient-like-me reasoning in
precision diagnosis and treatment.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01302" title="Abstract">arXiv:2311.01302</a> [<a href="/pdf/2311.01302" title="Download PDF">pdf</a>, <a href="/ps/2311.01302" title="Download PostScript">ps</a>, <a href="/format/2311.01302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Petrification: Software Model Checking for Programs with Dynamic Thread  Management (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heizmann%2C+M">Matthias Heizmann</a>, 
<a href="/search/cs?searchtype=author&query=Klumpp%2C+D">Dominik Klumpp</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%BCssele%2C+F">Frank Sch&#xfc;ssele</a>, 
<a href="/search/cs?searchtype=author&query=Nitzke%2C+L">Lars Nitzke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 8 figures, 2 tables, extended version of the paper which is to appear at VMCAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">We address the verification problem for concurrent program that dynamically
create (fork) new threads or destroy (join) existing threads. We present a
reduction to the verification problem for concurrent programs with a fixed
number of threads. More precisely, we present petrification, a transformation
from programs with dynamic thread management to an existing, Petri net-based
formalism for programs with a fixed number of threads. Our approach is
implemented in a software model checking tool for C programs that use the
pthreads API.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01304" title="Abstract">arXiv:2311.01304</a> [<a href="/pdf/2311.01304" title="Download PDF">pdf</a>, <a href="/format/2311.01304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VM-Rec: A Variational Mapping Approach for Cold-start User  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Linan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiale Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Pengsheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guangfa Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Jinyun Fang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">The cold-start problem is a common challenge for most recommender systems.
With extremely limited interactions of cold-start users, conventional
recommender models often struggle to generate embeddings with sufficient
expressivity. Moreover, the absence of auxiliary content information of users
exacerbates the presence of challenges, rendering most cold-start methods
difficult to apply. To address this issue, our motivation is based on the
observation that if a model can generate expressive embeddings for existing
users with relatively more interactions, who were also initially cold-start
users, then we can establish a mapping from few initial interactions to
expressive embeddings, simulating the process of generating embeddings for
cold-start users. Based on this motivation, we propose a Variational Mapping
approach for cold-start user Recommendation (VM-Rec). Firstly, we generate a
personalized mapping function for cold-start users based on their initial
interactions, and parameters of the function are generated from a variational
distribution. For the sake of interpretability and computational efficiency, we
model the personalized mapping function as a sparse linear model, where each
parameter indicates the association to a specific existing user. Consequently,
we use this mapping function to map the embeddings of existing users to an
embedding of the cold-start user in the same space. The resulting embedding has
similar expressivity to that of existing users and can be directly integrated
into a pre-trained recommender model to predict click through rates or ranking
scores. We evaluate our method based on three widely used recommender models as
pre-trained base recommender models, outperforming four popular cold-start
methods on two datasets under the same base model.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01305" title="Abstract">arXiv:2311.01305</a> [<a href="/pdf/2311.01305" title="Download PDF">pdf</a>, <a href="/format/2311.01305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AWEQ: Post-Training Quantization with Activation-Weight Equalization for  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Baisong Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xingwang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haixiao Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models(LLMs) exhibit excellent performance across a variety of
tasks, but they come with significant computational and storage costs.
Quantizing these models is an effective way to alleviate this issue. However,
existing methods struggle to strike a balance between model accuracy and
hardware efficiency. This is where we introduce AWEQ, a post-training method
that requires no additional training overhead. AWEQ excels in both
ultra-low-bit quantization and 8-bit weight and activation (W8A8) quantization.
There is an observation that weight quantization is less challenging than
activation quantization. AWEQ transfers the difficulty of activation
quantization to weights using channel equalization, achieving a balance between
the quantization difficulties of both, and thereby maximizing performance. We
have further refined the equalization method to mitigate quantization bias
error, ensuring the robustness of the model. Extensive experiments on popular
models such as LLaMA and OPT demonstrate that AWEQ outperforms all existing
post-training quantization methods for large models.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01307" title="Abstract">arXiv:2311.01307</a> [<a href="/pdf/2311.01307" title="Download PDF">pdf</a>, <a href="/format/2311.01307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Effect of Scaling, Retrieval Augmentation and Form on the Factual  Consistency of Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hagstr%C3%B6m%2C+L">Lovisa Hagstr&#xf6;m</a>, 
<a href="/search/cs?searchtype=author&query=Saynova%2C+D">Denitsa Saynova</a>, 
<a href="/search/cs?searchtype=author&query=Norlund%2C+T">Tobias Norlund</a>, 
<a href="/search/cs?searchtype=author&query=Johansson%2C+M">Moa Johansson</a>, 
<a href="/search/cs?searchtype=author&query=Johansson%2C+R">Richard Johansson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) make natural interfaces to factual knowledge,
but their usefulness is limited by their tendency to deliver inconsistent
answers to semantically equivalent questions. For example, a model might
predict both "Anne Redpath passed away in Edinburgh." and "Anne Redpath's life
ended in London." In this work, we identify potential causes of inconsistency
and evaluate the effectiveness of two mitigation strategies: up-scaling and
augmenting the LM with a retrieval corpus. Our results on the LLaMA and Atlas
models show that both strategies reduce inconsistency while retrieval
augmentation is considerably more efficient. We further consider and
disentangle the consistency contributions of different components of Atlas. For
all LMs evaluated we find that syntactical form and other evaluation task
artifacts impact consistency. Taken together, our results provide a better
understanding of the factors affecting the factual consistency of language
models.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01310" title="Abstract">arXiv:2311.01310</a> [<a href="/pdf/2311.01310" title="Download PDF">pdf</a>, <a href="/format/2311.01310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scattering Vision Transformer: Spectral Mixing Matters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patro%2C+B+N">Badri N. Patro</a>, 
<a href="/search/cs?searchtype=author&query=Agneeswaran%2C+V+S">Vijay Srinivas Agneeswaran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted @NeurIPS 2023,
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Image and Video Processing (eess.IV); Signal Processing (eess.SP)

</div>
<p class="mathjax">Vision transformers have gained significant attention and achieved
state-of-the-art performance in various computer vision tasks, including image
classification, instance segmentation, and object detection. However,
challenges remain in addressing attention complexity and effectively capturing
fine-grained information within images. Existing solutions often resort to
down-sampling operations, such as pooling, to reduce computational cost.
Unfortunately, such operations are non-invertible and can result in information
loss. In this paper, we present a novel approach called Scattering Vision
Transformer (SVT) to tackle these challenges. SVT incorporates a spectrally
scattering network that enables the capture of intricate image details. SVT
overcomes the invertibility issue associated with down-sampling operations by
separating low-frequency and high-frequency components. Furthermore, SVT
introduces a unique spectral gating network utilizing Einstein multiplication
for token and channel mixing, effectively reducing complexity. We show that SVT
achieves state-of-the-art performance on the ImageNet dataset with a
significant reduction in a number of parameters and FLOPS. SVT shows 2\%
improvement over LiTv2 and iFormer. SVT-H-S reaches 84.2\% top-1 accuracy,
while SVT-H-B reaches 85.2\% (state-of-art for base versions) and SVT-H-L
reaches 85.7\% (again state-of-art for large versions). SVT also shows
comparable results in other vision tasks such as instance segmentation. SVT
also outperforms other transformers in transfer learning on standard datasets
such as CIFAR10, CIFAR100, Oxford Flower, and Stanford Car datasets. The
project page is available on this
webpage.\url{https://badripatro.github.io/svt/}.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01311" title="Abstract">arXiv:2311.01311</a> [<a href="/pdf/2311.01311" title="Download PDF">pdf</a>, <a href="/format/2311.01311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Software Engineering for OpenHarmony: A Research Roadmap
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hailong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chunming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaoyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+H">Haipeng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+T">Ting Su</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiapu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Bissyand%C3%A9%2C+T+F">Tegawend&#xe9; F. Bissyand&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+J">Jacques Klein</a>, 
<a href="/search/cs?searchtype=author&query=Grundy%2C+J">John Grundy</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+T">Tao Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haibo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huaimin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Mobile software engineering has been a hot research topic for decades. Our
fellow researchers have proposed various approaches (with over 7,000
publications for Android alone) in this field that essentially contributed to
the great success of the current mobile ecosystem. Existing research efforts
mainly focus on popular mobile platforms, namely Android and iOS. OpenHarmony,
a newly open-sourced mobile platform, has rarely been considered, although it
is the one requiring the most attention as OpenHarmony is expected to occupy
one-third of the market in China (if not in the world). To fill the gap, we
present to the mobile software engineering community a research roadmap for
encouraging our fellow researchers to contribute promising approaches to
OpenHarmony. Specifically, we start by presenting a literature review of mobile
software engineering, attempting to understand what problems have been targeted
by the mobile community and how they have been resolved. We then summarize the
existing (limited) achievements of OpenHarmony and subsequently highlight the
research gap between Android/iOS and OpenHarmony. This research gap eventually
helps in forming the roadmap for conducting software engineering research for
OpenHarmony.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01314" title="Abstract">arXiv:2311.01314</a> [<a href="/pdf/2311.01314" title="Download PDF">pdf</a>, <a href="/format/2311.01314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recommendations by Concise User Profiles from Review Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Torbati%2C+G+H">Ghazaleh Haratinezhad Torbati</a>, 
<a href="/search/cs?searchtype=author&query=Tigunova%2C+A">Anna Tigunova</a>, 
<a href="/search/cs?searchtype=author&query=Yates%2C+A">Andrew Yates</a>, 
<a href="/search/cs?searchtype=author&query=Weikum%2C+G">Gerhard Weikum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Recommender systems are most successful for popular items and users with
ample interactions (likes, ratings etc.). This work addresses the difficult and
underexplored case of supporting users who have very sparse interactions but
post informative review texts. Our experimental studies address two book
communities with these characteristics. We design a framework with
Transformer-based representation learning, covering user-item interactions,
item content, and user-provided reviews. To overcome interaction sparseness, we
devise techniques for selecting the most informative cues to construct concise
user profiles. Comprehensive experiments, with datasets from Amazon and
Goodreads, show that judicious selection of text snippets achieves the best
performance, even in comparison to ChatGPT-generated user profiles.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01315" title="Abstract">arXiv:2311.01315</a> [<a href="/pdf/2311.01315" title="Download PDF">pdf</a>, <a href="/format/2311.01315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generic Model Checking for Modal Fixpoint Logics in COOL-MC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hausmann%2C+D">Daniel Hausmann</a>, 
<a href="/search/cs?searchtype=author&query=Humml%2C+M">Merlin Humml</a>, 
<a href="/search/cs?searchtype=author&query=Prucker%2C+S">Simon Prucker</a>, 
<a href="/search/cs?searchtype=author&query=Schr%C3%B6der%2C+L">Lutz Schr&#xf6;der</a>, 
<a href="/search/cs?searchtype=author&query=Strahlberger%2C+A">Aaron Strahlberger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full Version of VMCAI 2024 publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">We report on COOL-MC, a model checking tool for fixpoint logics that is
parametric in the branching type of models (nondeterministic, game-based,
probabilistic etc.) and in the next-step modalities used in formulae. The tool
implements generic model checking algorithms developed in coalgebraic logic
that are easily adapted to concrete instance logics. Apart from the standard
modal $\mu$-calculus, COOL-MC currently supports alternating-time, graded,
probabilistic and monotone variants of the $\mu$-calculus, but is also
effortlessly extensible with new instance logics. The model checking process is
realized by polynomial reductions to parity game solving, or, alternatively, by
a local model checking algorithm that directly computes the extensions of
formulae in a lazy fashion, thereby potentially avoiding the construction of
the full parity game. We evaluate COOL-MC on informative benchmark sets.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01323" title="Abstract">arXiv:2311.01323</a> [<a href="/pdf/2311.01323" title="Download PDF">pdf</a>, <a href="/format/2311.01323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Evaluating Transfer-based Attacks Systematically, Practically,  and Fairly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qizhang Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yiwen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+W">Wangmeng Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The adversarial vulnerability of deep neural networks (DNNs) has drawn great
attention due to the security risk of applying these models in real-world
applications. Based on transferability of adversarial examples, an increasing
number of transfer-based methods have been developed to fool black-box DNN
models whose architecture and parameters are inaccessible. Although tremendous
effort has been exerted, there still lacks a standardized benchmark that could
be taken advantage of to compare these methods systematically, fairly, and
practically. Our investigation shows that the evaluation of some methods needs
to be more reasonable and more thorough to verify their effectiveness, to
avoid, for example, unfair comparison and insufficient consideration of
possible substitute/victim models. Therefore, we establish a transfer-based
attack benchmark (TA-Bench) which implements 30+ methods. In this paper, we
evaluate and compare them comprehensively on 25 popular substitute/victim
models on ImageNet. New insights about the effectiveness of these methods are
gained and guidelines for future evaluations are provided. Code at:
https://github.com/qizhangli/TA-Bench.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01325" title="Abstract">arXiv:2311.01325</a> [<a href="/pdf/2311.01325" title="Download PDF">pdf</a>, <a href="/format/2311.01325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pushdown Normal-Form Bisimulation: A Nominal Context-Free Approach to  Program Equivalence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koutavas%2C+V">Vasileios Koutavas</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yu-Yang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Tzevelekos%2C+N">Nikos Tzevelekos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">We propose Pushdown Normal Form (PDNF) Bisimulation to verify contextual
equivalence in higher-order functional programming languages with local state.
Similar to previous work on Normal Form (NF) bisimulation, PDNF Bisimulation is
sound and complete with respect to contextual equivalence. However, unlike
traditional NF Bisimulation, PDNF Bisimulation is also decidable for a class of
program terms that reach bounded configurations but can potentially have
unbounded call stacks and input an unbounded number of unknown functions from
their context. Our approach relies on the principle that, in model-checking for
reachability, pushdown systems can be simulated by finite-state automata
designed to accept their initial/final stack content. We embody this in a
stackless Labelled Transition System (LTS), together with an on-the-fly
saturation procedure for call stacks, upon which bisimulation is defined. To
enhance the effectiveness of our bisimulation, we develop up-to techniques and
confirm their soundness for PDNF Bisimulation. We develop a prototype
implementation of our technique which is able to verify equivalence in examples
from practice and the literature that were out of reach for previous work.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01326" title="Abstract">arXiv:2311.01326</a> [<a href="/pdf/2311.01326" title="Download PDF">pdf</a>, <a href="/format/2311.01326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Better Together: Enhancing Generative Knowledge Graph Completion with  Language Models and Neighborhood Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chepurova%2C+A">Alla Chepurova</a>, 
<a href="/search/cs?searchtype=author&query=Bulatov%2C+A">Aydar Bulatov</a>, 
<a href="/search/cs?searchtype=author&query=Kuratov%2C+Y">Yuri Kuratov</a>, 
<a href="/search/cs?searchtype=author&query=Burtsev%2C+M">Mikhail Burtsev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Findings of the Association for Computational Linguistics: EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Real-world Knowledge Graphs (KGs) often suffer from incompleteness, which
limits their potential performance. Knowledge Graph Completion (KGC) techniques
aim to address this issue. However, traditional KGC methods are computationally
intensive and impractical for large-scale KGs, necessitating the learning of
dense node embeddings and computing pairwise distances. Generative
transformer-based language models (e.g., T5 and recent KGT5) offer a promising
solution as they can predict the tail nodes directly. In this study, we propose
to include node neighborhoods as additional information to improve KGC methods
based on language models. We examine the effects of this imputation and show
that, on both inductive and transductive Wikidata subsets, our method
outperforms KGT5 and conventional KGC approaches. We also provide an extensive
analysis of the impact of neighborhood on model prediction and show its
importance. Furthermore, we point the way to significantly improve KGC through
more effective neighborhood selection.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01327" title="Abstract">arXiv:2311.01327</a> [<a href="/pdf/2311.01327" title="Download PDF">pdf</a>, <a href="/format/2311.01327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-dimensional Linear Bandits with Knapsacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wanteng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+D">Dong Xia</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jiashuo Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study the contextual bandits with knapsack (CBwK) problem under the
high-dimensional setting where the dimension of the feature is large. The
reward of pulling each arm equals the multiplication of a sparse
high-dimensional weight vector and the feature of the current arrival, with
additional random noise. In this paper, we investigate how to exploit this
sparsity structure to achieve improved regret for the CBwK problem. To this
end, we first develop an online variant of the hard thresholding algorithm that
performs the sparse estimation in an online manner. We further combine our
online estimator with a primal-dual framework, where we assign a dual variable
to each knapsack constraint and utilize an online learning algorithm to update
the dual variable, thereby controlling the consumption of the knapsack
capacity. We show that this integrated approach allows us to achieve a
sublinear regret that depends logarithmically on the feature dimension, thus
improving the polynomial dependency established in the previous literature. We
also apply our framework to the high-dimension contextual bandit problem
without the knapsack constraint and achieve optimal regret in both the
data-poor regime and the data-rich regime. We finally conduct numerical
experiments to show the efficient empirical performance of our algorithms under
the high dimensional setting.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01329" title="Abstract">arXiv:2311.01329</a> [<a href="/pdf/2311.01329" title="Download PDF">pdf</a>, <a href="/format/2311.01329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple Solution for Offline Imitation from Observations and Examples  with Possibly Incomplete Trajectories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+K">Kai Yan</a>, 
<a href="/search/cs?searchtype=author&query=Schwing%2C+A+G">Alexander G. Schwing</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Xiong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages; Accepted as a poster for NeurIPS2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Offline imitation from observations aims to solve MDPs where only
task-specific expert states and task-agnostic non-expert state-action pairs are
available. Offline imitation is useful in real-world scenarios where arbitrary
interactions are costly and expert actions are unavailable. The
state-of-the-art "DIstribution Correction Estimation" (DICE) methods minimize
divergence of state occupancy between expert and learner policies and retrieve
a policy with weighted behavior cloning; however, their results are unstable
when learning from incomplete trajectories, due to a non-robust optimization in
the dual domain. To address the issue, in this paper, we propose
Trajectory-Aware Imitation Learning from Observations (TAILO). TAILO uses a
discounted sum along the future trajectory as the weight for weighted behavior
cloning. The terms for the sum are scaled by the output of a discriminator,
which aims to identify expert states. Despite simplicity, TAILO works well if
there exist trajectories or segments of expert behavior in the task-agnostic
data, a common assumption in prior work. In experiments across multiple
testbeds, we find TAILO to be more robust and effective, particularly with
incomplete trajectories.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01331" title="Abstract">arXiv:2311.01331</a> [<a href="/pdf/2311.01331" title="Download PDF">pdf</a>, <a href="/format/2311.01331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Offline Imitation from Observation via Primal Wasserstein State  Occupancy Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+K">Kai Yan</a>, 
<a href="/search/cs?searchtype=author&query=Schwing%2C+A+G">Alexander G. Schwing</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-xiong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages. Accepted to the Optimal Transport and Machine Learning Workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In real-world scenarios, arbitrary interactions with the environment can
often be costly, and actions of expert demonstrations are not always available.
To reduce the need for both, Offline Learning from Observations (LfO) is
extensively studied, where the agent learns to solve a task with only expert
states and \textit{task-agnostic} non-expert state-action pairs. The
state-of-the-art DIstribution Correction Estimation (DICE) methods minimize the
state occupancy divergence between the learner and expert policies. However,
they are limited to either $f$-divergences (KL and $\chi^2$) or Wasserstein
distance with Rubinstein duality, the latter of which constrains the underlying
distance metric crucial to the performance of Wasserstein-based solutions. To
address this problem, we propose Primal Wasserstein DICE (PW-DICE), which
minimizes the primal Wasserstein distance between the expert and learner state
occupancies with a pessimistic regularizer and leverages a contrastively
learned distance as the underlying metric for the Wasserstein distance.
Theoretically, we prove that our framework is a generalization of the
state-of-the-art, SMODICE, and unifies $f$-divergence and Wasserstein
minimization. Empirically, we find that PW-DICE improves upon several
state-of-the-art methods on multiple testbeds.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01335" title="Abstract">arXiv:2311.01335</a> [<a href="/pdf/2311.01335" title="Download PDF">pdf</a>, <a href="/format/2311.01335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Look at Robot Base Once: Hand-Eye Calibration with Point Clouds of Robot  Base Leveraging Learning-Based 3D Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Leihui Li</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yixiong Du</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xingyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Riwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuping Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 19 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Hand-eye calibration, as a fundamental task in vision-based robotic systems,
aims to estimate the transformation matrix between the coordinate frame of the
camera and the robot flange. Most approaches to hand-eye calibration rely on
external markers or human assistance. We proposed Look at Robot Base Once
(LRBO), a novel methodology that addresses the hand-eye calibration problem
without external calibration objects or human support, but with the robot base.
Using point clouds of the robot base, a transformation matrix from the
coordinate frame of the camera to the robot base is established as I=AXB. To
this end, we exploit learning-based 3D detection and registration algorithms to
estimate the location and orientation of the robot base. The robustness and
accuracy of the method are quantified by ground-truth-based evaluation, and the
accuracy result is compared with other 3D vision-based calibration methods. To
assess the feasibility of our methodology, we carried out experiments utilizing
a low-cost structured light scanner across varying joint configurations and
groups of experiments. The proposed hand-eye calibration method achieved a
translation deviation of 0.930 mm and a rotation deviation of 0.265 degrees
according to the experimental results. Additionally, the 3D reconstruction
experiments demonstrated a rotation error of 0.994 degrees and a position error
of 1.697 mm. Moreover, our method offers the potential to be completed in 1
second, which is the fastest compared to other 3D hand-eye calibration methods.
Code is released at github.com/leihui6/LRBO.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01337" title="Abstract">arXiv:2311.01337</a> [<a href="/pdf/2311.01337" title="Download PDF">pdf</a>, <a href="/format/2311.01337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Identification of SIS Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Leung%2C+C+H">Chi Ho Leung</a>, 
<a href="/search/eess?searchtype=author&query=Retnaraj%2C+W+E">William E. Retnaraj</a>, 
<a href="/search/eess?searchtype=author&query=Hota%2C+A+R">Ashish R. Hota</a>, 
<a href="/search/eess?searchtype=author&query=Par%C3%A9%2C+P+E">Philip E. Par&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Effective containment of spreading processes such as epidemics requires
accurate knowledge of several key parameters that govern their dynamics. In
this work, we first show that the problem of identifying the underlying
parameters of epidemiological spreading processes is often ill-conditioned and
lacks the persistence of excitation required for the convergence of adaptive
learning schemes. To tackle this challenge, we leverage a relaxed property
called initial excitation combined with a recursive least squares algorithm to
design an online adaptive identifier to learn the parameters of the
susceptible-infected-susceptible (SIS) epidemic model from the knowledge of its
states. We prove that the iterates generated by the proposed algorithm minimize
an auxiliary weighted least squares cost function. We illustrate the
convergence of the error of the estimated epidemic parameters via several
numerical case studies and compare it with results obtained using conventional
approaches.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01338" title="Abstract">arXiv:2311.01338</a> [<a href="/pdf/2311.01338" title="Download PDF">pdf</a>, <a href="/format/2311.01338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Securing Wireless Communication in Critical Infrastructure: Challenges  and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bodenhausen%2C+J">J&#xf6;rn Bodenhausen</a>, 
<a href="/search/cs?searchtype=author&query=Sorgatz%2C+C">Christian Sorgatz</a>, 
<a href="/search/cs?searchtype=author&query=Vogt%2C+T">Thomas Vogt</a>, 
<a href="/search/cs?searchtype=author&query=Grafflage%2C+K">Kolja Grafflage</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%B6tzel%2C+S">Sebastian R&#xf6;tzel</a>, 
<a href="/search/cs?searchtype=author&query=Rademacher%2C+M">Michael Rademacher</a>, 
<a href="/search/cs?searchtype=author&query=Henze%2C+M">Martin Henze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Author's version of a paper accepted for publication in Proceedings of the 20th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services (MobiQuitous 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Critical infrastructure constitutes the foundation of every society. While
traditionally solely relying on dedicated cable-based communication, this
infrastructure rapidly transforms to highly digitized and interconnected
systems which increasingly rely on wireless communication. Besides providing
tremendous benefits, especially affording the easy, cheap, and flexible
interconnection of a large number of assets spread over larger geographic
areas, wireless communication in critical infrastructure also raises unique
security challenges. Most importantly, the shift from dedicated private wired
networks to heterogeneous wireless communication over public and shared
networks requires significantly more involved security measures. In this paper,
we identify the most relevant challenges resulting from the use of wireless
communication in critical infrastructure and use those to identify a
comprehensive set of promising opportunities to preserve the high security
standards of critical infrastructure even when switching from wired to wireless
communication.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01343" title="Abstract">arXiv:2311.01343</a> [<a href="/pdf/2311.01343" title="Download PDF">pdf</a>, <a href="/format/2311.01343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Large Language Model for Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yaochen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Liang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Liangjie Hong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jundong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Recently, there is a growing interest in developing next-generation
recommender systems (RSs) based on pretrained large language models (LLMs),
fully utilizing their encoded knowledge and reasoning ability. However, the
semantic gap between natural language and recommendation tasks is still not
well addressed, leading to multiple issues such as spuriously-correlated
user/item descriptors, ineffective language modeling on user/item contents, and
inefficient recommendations via auto-regression, etc. In this paper, we propose
CLLM4Rec, the first generative RS that tightly integrates the LLM paradigm and
ID paradigm of RS, aiming to address the above challenges simultaneously. We
first extend the vocabulary of pretrained LLMs with user/item ID tokens to
faithfully model the user/item collaborative and content semantics.
Accordingly, in the pretraining stage, a novel soft+hard prompting strategy is
proposed to effectively learn user/item collaborative/content token embeddings
via language modeling on RS-specific corpora established from user-item
interactions and user/item features, where each document is split into a prompt
consisting of heterogeneous soft (user/item) tokens and hard (vocab) tokens and
a main text consisting of homogeneous item tokens or vocab tokens that
facilitates stable and effective language modeling. In addition, a novel mutual
regularization strategy is introduced to encourage the CLLM4Rec to capture
recommendation-oriented information from user/item contents. Finally, we
propose a novel recommendation-oriented finetuning strategy for CLLM4Rec, where
an item prediction head with multinomial likelihood is added to the pretrained
CLLM4Rec backbone to predict hold-out items based on the soft+hard prompts
established from masked user-item interaction history, where recommendations of
multiple items can be generated efficiently.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01344" title="Abstract">arXiv:2311.01344</a> [<a href="/pdf/2311.01344" title="Download PDF">pdf</a>, <a href="/format/2311.01344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Like an Open Book? Read Neural Network Architecture with Simple Power  Analysis on 32-bit Microcontrollers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joud%2C+R">Raphael Joud</a>, 
<a href="/search/cs?searchtype=author&query=Moellic%2C+P">Pierre-Alain Moellic</a>, 
<a href="/search/cs?searchtype=author&query=Pontie%2C+S">Simon Pontie</a>, 
<a href="/search/cs?searchtype=author&query=Rigaud%2C+J">Jean-Baptiste Rigaud</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted CARDIS 2023; ANR PICTURE PROJECT (ANR-20-CE39-0013)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Model extraction is a growing concern for the security of AI systems. For
deep neural network models, the architecture is the most important information
an adversary aims to recover. Being a sequence of repeated computation blocks,
neural network models deployed on edge-devices will generate distinctive
side-channel leakages. The latter can be exploited to extract critical
information when targeted platforms are physically accessible. By combining
theoretical knowledge about deep learning practices and analysis of a
widespread implementation library (ARM CMSIS-NN), our purpose is to answer this
critical question: how far can we extract architecture information by simply
examining an EM side-channel trace? For the first time, we propose an
extraction methodology for traditional MLP and CNN models running on a high-end
32-bit microcontroller (Cortex-M7) that relies only on simple pattern
recognition analysis. Despite few challenging cases, we claim that, contrary to
parameters extraction, the complexity of the attack is relatively low and we
highlight the urgent need for practicable protections that could fit the strong
memory and latency requirements of such platforms.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01349" title="Abstract">arXiv:2311.01349</a> [<a href="/pdf/2311.01349" title="Download PDF">pdf</a>, <a href="/format/2311.01349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unreading Race: Purging Protected Features from Chest X-ray Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weber%2C+T">Tobias Weber</a>, 
<a href="/search/cs?searchtype=author&query=Ingrisch%2C+M">Michael Ingrisch</a>, 
<a href="/search/cs?searchtype=author&query=Bischl%2C+B">Bernd Bischl</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%BCgamer%2C+D">David R&#xfc;gamer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Machine Learning (stat.ML)

</div>
<p class="mathjax">Purpose: To analyze and remove protected feature effects in chest radiograph
embeddings of deep learning models.
<br />Materials and Methods: An orthogonalization is utilized to remove the
influence of protected features (e.g., age, sex, race) in chest radiograph
embeddings, ensuring feature-independent results. To validate the efficacy of
the approach, we retrospectively study the MIMIC and CheXpert datasets using
three pre-trained models, namely a supervised contrastive, a self-supervised
contrastive, and a baseline classifier model. Our statistical analysis involves
comparing the original versus the orthogonalized embeddings by estimating
protected feature influences and evaluating the ability to predict race, age,
or sex using the two types of embeddings.
<br />Results: Our experiments reveal a significant influence of protected features
on predictions of pathologies. Applying orthogonalization removes these feature
effects. Apart from removing any influence on pathology classification, while
maintaining competitive predictive performance, orthogonalized embeddings
further make it infeasible to directly predict protected attributes and
mitigate subgroup disparities.
<br />Conclusion: The presented work demonstrates the successful application and
evaluation of the orthogonalization technique in the domain of chest X-ray
classification.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01350" title="Abstract">arXiv:2311.01350</a> [<a href="/pdf/2311.01350" title="Download PDF">pdf</a>, <a href="/format/2311.01350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Adaptive Inertia Strategy in Large-Scale Electric Power Grids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fritzsch%2C+J">Julian Fritzsch</a>, 
<a href="/search/eess?searchtype=author&query=Jacquod%2C+P">Philippe Jacquod</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">The increasing penetration of new renewable sources of energy in today's
power grids is accompanied by a decrease in available electromechanical
inertia. This leads to a reduced dynamical stability. To counterbalance this
effect, virtual synchronous generators have been proposed to emulate
conventional generators and provide inertia to power systems. The high
flexibility of these devices makes it possible to control the synthetic inertia
they provide and to have them operate even more efficiently than the
electromechanical inertia they replace. Here, we propose a novel control scheme
for virtual synchronous generators, where the amount of inertia provided is
large at short times - thereby absorbing local faults and disturbances as
efficiently as conventional generators - but decreases over a tunable time
interval to prevent long-time coherent oscillations from setting in. This new
model is used to investigate the effect of adaptive inertia on large-scale
power grids. Our model outperforms conventional constant inertia in all
scenarios and for all performance measures considered. We show how an optimized
geographical distribution of adaptive inertia devices not only effectively
absorbs local faults, but also significantly improves the damping of inter-area
oscillations.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01351" title="Abstract">arXiv:2311.01351</a> [<a href="/pdf/2311.01351" title="Download PDF">pdf</a>, <a href="/format/2311.01351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simplicial Models for the Epistemic Logic of Faulty Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goubault%2C+E">Eric Goubault</a>, 
<a href="/search/cs?searchtype=author&query=Kniazev%2C+R">Roman Kniazev</a>, 
<a href="/search/cs?searchtype=author&query=Ledent%2C+J">Jeremy Ledent</a>, 
<a href="/search/cs?searchtype=author&query=Rajsbaum%2C+S">Sergio Rajsbaum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Algebraic Topology (math.AT)

</div>
<p class="mathjax">In recent years, several authors have been investigating simplicial models, a
model of epistemic logic based on higher-dimensional structures called
simplicial complexes. In the original formulation, simplicial models were
always assumed to be pure, meaning that all worlds have the same dimension.
This is equivalent to the standard S5n semantics of epistemic logic, based on
Kripke models. By removing the assumption that models must be pure, we can go
beyond the usual Kripke semantics and study epistemic logics where the number
of agents participating in a world can vary. This approach has been developed
in a number of papers, with applications in fault-tolerant distributed
computing where processes may crash during the execution of a system. A
difficulty that arises is that subtle design choices in the definition of
impure simplicial models can result in different axioms of the resulting logic.
In this paper, we classify those design choices systematically, and axiomatize
the corresponding logics. We illustrate them via distributed computing examples
of synchronous systems where processes may crash.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01354" title="Abstract">arXiv:2311.01354</a> [<a href="/pdf/2311.01354" title="Download PDF">pdf</a>, <a href="/ps/2311.01354" title="Download PostScript">ps</a>, <a href="/format/2311.01354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collective Tree Exploration via Potential Function Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cosson%2C+R">Romain Cosson</a>, 
<a href="/search/cs?searchtype=author&query=Massouli%C3%A9%2C+L">Laurent Massouli&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">We study the problem of collective tree exploration (CTE) where a team of $k$
agents is tasked to traverse all the edges of an unknown tree as fast as
possible, assuming complete communication between the agents. In this paper, we
present an algorithm performing collective tree exploration in only
$2n/k+O(kD)$ rounds, where $n$ is the number of nodes in the tree, and $D$ is
the tree depth. This leads to a competitive ratio of $O(\sqrt{k})$ for
collective tree exploration, the first polynomial improvement over the initial
$O(k/\log(k))$ ratio of [FGKP06]. Our analysis relies on a game with robots at
the leaves of a continuously growing tree, which is presented in a similar
manner as the `evolving tree game' of [BCR22], though its analysis and
applications differ significantly. This game extends the `tree-mining game'
(TM) of [Cos23] and leads to guarantees for an asynchronous extension of
collective tree exploration (ACTE). Another surprising consequence of our
results is the existence of algorithms $\{A_k\}_{k\in \mathbb{N}}$ for layered
tree traversal (LTT) with cost at most $2L/k+O(kD)$, where $L$ is the sum of
edge lengths and $D$ is the tree depth. For the case of layered trees of width
$w$ and unit edge lengths, our guarantee is thus in $O(\sqrt{w}D)$.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01357" title="Abstract">arXiv:2311.01357</a> [<a href="/pdf/2311.01357" title="Download PDF">pdf</a>, <a href="/format/2311.01357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Identity Perceptual Watermark Against Deepfake Face Swapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Mengxiao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Harry Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+B">Bin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yinglong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Notwithstanding offering convenience and entertainment to society, Deepfake
face swapping has caused critical privacy issues with the rapid development of
deep generative models. Due to imperceptible artifacts in high-quality
synthetic images, passive detection models against face swapping in recent
years usually suffer performance damping regarding the generalizability issue.
Therefore, several studies have been attempted to proactively protect the
original images against malicious manipulations by inserting invisible signals
in advance. However, the existing proactive defense approaches demonstrate
unsatisfactory results with respect to visual quality, detection accuracy, and
source tracing ability. In this study, we propose the first robust identity
perceptual watermarking framework that concurrently performs detection and
source tracing against Deepfake face swapping proactively. We assign identity
semantics regarding the image contents to the watermarks and devise an
unpredictable and unreversible chaotic encryption system to ensure watermark
confidentiality. The watermarks are encoded and recovered by jointly training
an encoder-decoder framework along with adversarial image manipulations.
Extensive experiments demonstrate state-of-the-art performance against Deepfake
face swapping under both cross-dataset and cross-manipulation settings.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01361" title="Abstract">arXiv:2311.01361</a> [<a href="/pdf/2311.01361" title="Download PDF">pdf</a>, <a href="/format/2311.01361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT-4V(ision) as a Generalist Evaluator for Vision-Language Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinlu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yujie Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weizhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+A">An Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jun Yan</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+L">Lianke Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Heng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xifeng Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W+Y">William Yang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Petzold%2C+L+R">Linda Ruth Petzold</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Automatically evaluating vision-language tasks is challenging, especially
when it comes to reflecting human judgments due to limitations in accounting
for fine-grained details. Although GPT-4V has shown promising results in
various multi-modal tasks, leveraging GPT-4V as a generalist evaluator for
these tasks has not yet been systematically explored. We comprehensively
validate GPT-4V's capabilities for evaluation purposes, addressing tasks
ranging from foundational image-to-text and text-to-image synthesis to
high-level image-to-image translations and multi-images to text alignment. We
employ two evaluation methods, single-answer grading and pairwise comparison,
using GPT-4V. Notably, GPT-4V shows promising agreement with humans across
various tasks and evaluation methods, demonstrating immense potential for
multi-modal LLMs as evaluators. Despite limitations like restricted visual
clarity grading and real-world complex reasoning, its ability to provide
human-aligned scores enriched with detailed explanations is promising for
universal automatic evaluator.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01366" title="Abstract">arXiv:2311.01366</a> [<a href="/pdf/2311.01366" title="Download PDF">pdf</a>, <a href="/format/2311.01366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Genetic Algorithm-based Beamforming in Subarray Architectures for GEO  Satellites
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=V%C3%A1squez-Peralvo%2C+J+A">Juan Andr&#xe9;s V&#xe1;squez-Peralvo</a>, 
<a href="/search/eess?searchtype=author&query=Querol%2C+J">Jorge Querol</a>, 
<a href="/search/eess?searchtype=author&query=Lagunas%2C+E">Eva Lagunas</a>, 
<a href="/search/eess?searchtype=author&query=Ortiz%2C+F">Flor Ortiz</a>, 
<a href="/search/eess?searchtype=author&query=Garc%C3%A9s-Socarr%C3%A1s%2C+L+M">Luis Manuel Garc&#xe9;s-Socarr&#xe1;s</a>, 
<a href="/search/eess?searchtype=author&query=Gonz%C3%A1lez-Rios%2C+J+L">Jorge Luis Gonz&#xe1;lez-Rios</a>, 
<a href="/search/eess?searchtype=author&query=Baeza%2C+V+M">Victor Monzon Baeza</a>, 
<a href="/search/eess?searchtype=author&query=Chatzinotas%2C+S">Symeon Chatzinotas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The incorporation of subarrays in Direct Radiating Arrays for satellite
missions is fundamental in reducing the number of Radio Frequency chains, which
correspondingly diminishes cost, power consumption, space, and mass. Despite
the advantages, previous beamforming schemes incur significant losses during
beam scanning, particularly when hybrid beamforming is not employed.
Consequently, this paper introduces an algorithm capable of compensating for
these losses by increasing the power, for this, the algorithm will activate
radiating elements required to address a specific Effective Isotropic Radiated
Power for a beam pattern over Earth, projected from a GeoStationary satellite.
In addition to the aforementioned compensation, other beam parameters have been
addressed in the algorithm, such as beamwidth and Side Lobe Levels. To achieve
these objectives, we propose employing the array thinning concept through the
use of genetic algorithms, which enable beam shaping with the desired
characteristics and power. The full array design considers an open-ended
waveguide, configured to operate in circular polarization within the Ka-band
frequency range of 17.7-20.2 GHz.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01372" title="Abstract">arXiv:2311.01372</a> [<a href="/pdf/2311.01372" title="Download PDF">pdf</a>, <a href="/format/2311.01372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Augmented and Retrieval-Augmented Context Enrichment in Chinese  Media Bias Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Luyang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jing Li</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kam-Fai Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">With the increasing pursuit of objective reports, automatically understanding
media bias has drawn more attention in recent research. However, most of the
previous work examines media bias from Western ideology, such as the left and
right in the political spectrum, which is not applicable to Chinese outlets.
Based on the previous lexical bias and informational bias structure, we refine
it from the Chinese perspective and go one step further to craft data with 7
fine-grained labels. To be specific, we first construct a dataset with Chinese
news reports about COVID-19 which is annotated by our newly designed system,
and then conduct substantial experiments on it to detect media bias. However,
the scale of the annotated data is not enough for the latest deep-learning
technology, and the cost of human annotation in media bias, which needs a lot
of professional knowledge, is too expensive. Thus, we explore some context
enrichment methods to automatically improve these problems. In Data-Augmented
Context Enrichment (DACE), we enlarge the training data; while in
Retrieval-Augmented Context Enrichment (RACE), we improve information retrieval
methods to select valuable information and integrate it into our models to
better understand bias. Extensive experiments are conducted on both our dataset
and an English dataset BASIL. Our results show that both methods outperform our
baselines, while the RACE methods are more efficient and have more potential.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01373" title="Abstract">arXiv:2311.01373</a> [<a href="/pdf/2311.01373" title="Download PDF">pdf</a>, <a href="/format/2311.01373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recognize Any Regions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Haosen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chuofan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+B">Bin Wen</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zehuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiatian Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Understanding the semantics of individual regions or patches within
unconstrained images, such as in open-world object detection, represents a
critical yet challenging task in computer vision. Building on the success of
powerful image-level vision-language (ViL) foundation models like CLIP, recent
efforts have sought to harness their capabilities by either training a
contrastive model from scratch with an extensive collection of region-label
pairs or aligning the outputs of a detection model with image-level
representations of region proposals. Despite notable progress, these approaches
are plagued by computationally intensive training requirements, susceptibility
to data noise, and deficiency in contextual information. To address these
limitations, we explore the synergistic potential of off-the-shelf foundation
models, leveraging their respective strengths in localization and semantics. We
introduce a novel, generic, and efficient region recognition architecture,
named RegionSpot, designed to integrate position-aware localization knowledge
from a localization foundation model (e.g., SAM) with semantic information
extracted from a ViL model (e.g., CLIP). To fully exploit pretrained knowledge
while minimizing training overhead, we keep both foundation models frozen,
focusing optimization efforts solely on a lightweight attention-based knowledge
integration module. Through extensive experiments in the context of open-world
object recognition, our RegionSpot demonstrates significant performance
improvements over prior alternatives, while also providing substantial
computational savings. For instance, training our model with 3 million data in
a single day using 8 V100 GPUs. Our model outperforms GLIP by 6.5 % in mean
average precision (mAP), with an even larger margin by 14.8 % for more
challenging and rare categories.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01375" title="Abstract">arXiv:2311.01375</a> [<a href="/pdf/2311.01375" title="Download PDF">pdf</a>, <a href="/format/2311.01375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monotone Generative Modeling via a Gromov-Monge Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+W">Wonjun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yifei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+D">Dongmian Zou</a>, 
<a href="/search/cs?searchtype=author&query=Lerman%2C+G">Gilad Lerman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages including main text and appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Generative Adversarial Networks (GANs) are powerful tools for creating new
content, but they face challenges such as sensitivity to starting conditions
and mode collapse. To address these issues, we propose a deep generative model
that utilizes the Gromov-Monge embedding (GME). It helps identify the
low-dimensional structure of the underlying measure of the data and then maps
it, while preserving its geometry, into a measure in a low-dimensional latent
space, which is then optimally transported to the reference measure. We
guarantee the preservation of the underlying geometry by the GME and
$c$-cyclical monotonicity of the generative map, where $c$ is an intrinsic
embedding cost employed by the GME. The latter property is a first step in
guaranteeing better robustness to initialization of parameters and mode
collapse. Numerical experiments demonstrate the effectiveness of our approach
in generating high-quality images, avoiding mode collapse, and exhibiting
robustness to different starting conditions.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01378" title="Abstract">arXiv:2311.01378</a> [<a href="/pdf/2311.01378" title="Download PDF">pdf</a>, <a href="/format/2311.01378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision-Language Foundation Models as Effective Robot Imitators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinghang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Minghuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanbo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Cunjun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hongtao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cheang%2C+C">Chilam Cheang</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+Y">Ya Jing</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huaping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hang Li</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+T">Tao Kong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://roboflamingo.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent progress in vision language foundation models has shown their ability
to understand multimodal data and resolve complicated vision language tasks,
including robotics manipulation. We seek a straightforward way of making use of
existing vision-language models (VLMs) with simple fine-tuning on robotics
data. To this end, we derive a simple and novel vision-language manipulation
framework, dubbed RoboFlamingo, built upon the open-source VLMs, OpenFlamingo.
Unlike prior works, RoboFlamingo utilizes pre-trained VLMs for single-step
vision-language comprehension, models sequential history information with an
explicit policy head, and is slightly fine-tuned by imitation learning only on
language-conditioned manipulation datasets. Such a decomposition provides
RoboFlamingo the flexibility for open-loop control and deployment on
low-performance platforms. By exceeding the state-of-the-art performance with a
large margin on the tested benchmark, we show RoboFlamingo can be an effective
and competitive alternative to adapt VLMs to robot control. Our extensive
experimental results also reveal several interesting conclusions regarding the
behavior of different pre-trained VLMs on manipulation tasks. We believe
RoboFlamingo has the potential to be a cost-effective and easy-to-use solution
for robotics manipulation, empowering everyone with the ability to fine-tune
their own robotics policy.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01379" title="Abstract">arXiv:2311.01379</a> [<a href="/pdf/2311.01379" title="Download PDF">pdf</a>, <a href="/format/2311.01379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Decision-Making and the k-Strong Price of Anarchy in  Common Interest Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferguson%2C+B+L">Bryce L. Ferguson</a>, 
<a href="/search/cs?searchtype=author&query=Paccagnan%2C+D">Dario Paccagnan</a>, 
<a href="/search/cs?searchtype=author&query=Pradelski%2C+B+S+R">Bary S. R. Pradelski</a>, 
<a href="/search/cs?searchtype=author&query=Marden%2C+J+R">Jason R. Marden</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2308.08045">arXiv:2308.08045</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The control of large-scale, multi-agent systems often entails distributing
decision-making across the system components. However, with advances in
communication and computation technologies, we can consider new collaborative
decision-making paradigms that exist somewhere between centralized and
distributed control. In this work, we seek to understand the benefits and costs
of increased collaborative communication in multi-agent systems. We
specifically study this in the context of common interest games in which groups
of up to k agents can coordinate their actions in maximizing the common
objective function. The equilibria that emerge in these systems are the
k-strong Nash equilibria of the common interest game; studying the properties
of these states can provide relevant insights into the efficacy of inter-agent
collaboration. Our contributions come threefold: 1) provide bounds on how well
k-strong Nash equilibria approximate the optimal system welfare, formalized by
the k-strong price of anarchy, 2) study the run-time and transient performance
of collaborative agent-based dynamics, and 3) consider the task of redesigning
objectives for groups of agents which improve system performance. We study
these three facets generally as well as in the context of resource allocation
problems, in which we provide tractable linear programs that give tight bounds
on the k-strong price of anarchy.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01380" title="Abstract">arXiv:2311.01380</a> [<a href="/pdf/2311.01380" title="Download PDF">pdf</a>, <a href="/format/2311.01380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sim2Real Bilevel Adaptation for Object Surface Classification using  Vision-Based Tactile Sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caddeo%2C+G+M">Gabriele M. Caddeo</a>, 
<a href="/search/cs?searchtype=author&query=Maracani%2C+A">Andrea Maracani</a>, 
<a href="/search/cs?searchtype=author&query=Alfano%2C+P+D">Paolo D. Alfano</a>, 
<a href="/search/cs?searchtype=author&query=Piga%2C+N+A">Nicola A. Piga</a>, 
<a href="/search/cs?searchtype=author&query=Rosasco%2C+L">Lorenzo Rosasco</a>, 
<a href="/search/cs?searchtype=author&query=Natale%2C+L">Lorenzo Natale</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this paper, we address the Sim2Real gap in the field of vision-based
tactile sensors for classifying object surfaces. We train a Diffusion Model to
bridge this gap using a relatively small dataset of real-world images randomly
collected from unlabeled everyday objects via the DIGIT sensor. Subsequently,
we employ a simulator to generate images by uniformly sampling the surface of
objects from the YCB Model Set. These simulated images are then translated into
the real domain using the Diffusion Model and automatically labeled to train a
classifier. During this training, we further align features of the two domains
using an adversarial procedure. Our evaluation is conducted on a dataset of
tactile images obtained from a set of ten 3D printed YCB objects. The results
reveal a total accuracy of 81.9%, a significant improvement compared to the
34.7% achieved by the classifier trained solely on simulated images. This
demonstrates the effectiveness of our approach. We further validate our
approach using the classifier on a 6D object pose estimation task from tactile
data.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01386" title="Abstract">arXiv:2311.01386</a> [<a href="/pdf/2311.01386" title="Download PDF">pdf</a>, <a href="/format/2311.01386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Language Models Be Tricked by Language Illusions? Easier with  Syntax, Harder with Semantics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gibson%2C+E">Edward Gibson</a>, 
<a href="/search/cs?searchtype=author&query=Davis%2C+F">Forrest Davis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by The SIGNLL Conference on Computational Natural Language Learning 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Language models (LMs) have been argued to overlap substantially with human
beings in grammaticality judgment tasks. But when humans systematically make
errors in language processing, should we expect LMs to behave like cognitive
models of language and mimic human behavior? We answer this question by
investigating LMs' more subtle judgments associated with "language illusions"
-- sentences that are vague in meaning, implausible, or ungrammatical but
receive unexpectedly high acceptability judgments by humans. We looked at three
illusions: the comparative illusion (e.g. "More people have been to Russia than
I have"), the depth-charge illusion (e.g. "No head injury is too trivial to be
ignored"), and the negative polarity item (NPI) illusion (e.g. "The hunter who
no villager believed to be trustworthy will ever shoot a bear"). We found that
probabilities represented by LMs were more likely to align with human judgments
of being "tricked" by the NPI illusion which examines a structural dependency,
compared to the comparative and the depth-charge illusions which require
sophisticated semantic understanding. No single LM or metric yielded results
that are entirely consistent with human behavior. Ultimately, we show that LMs
are limited both in their construal as cognitive models of human language
processing and in their capacity to recognize nuanced but critical information
in complicated language materials.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01394" title="Abstract">arXiv:2311.01394</a> [<a href="/pdf/2311.01394" title="Download PDF">pdf</a>, <a href="/format/2311.01394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Realistic Traffic Agents in Closed-loop
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chris Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+J">James Tu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lunjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kelvin Wong</a>, 
<a href="/search/cs?searchtype=author&query=Suo%2C+S">Simon Suo</a>, 
<a href="/search/cs?searchtype=author&query=Urtasun%2C+R">Raquel Urtasun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CORL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Realistic traffic simulation is crucial for developing self-driving software
in a safe and scalable manner prior to real-world deployment. Typically,
imitation learning (IL) is used to learn human-like traffic agents directly
from real-world observations collected offline, but without explicit
specification of traffic rules, agents trained from IL alone frequently display
unrealistic infractions like collisions and driving off the road. This problem
is exacerbated in out-of-distribution and long-tail scenarios. On the other
hand, reinforcement learning (RL) can train traffic agents to avoid
infractions, but using RL alone results in unhuman-like driving behaviors. We
propose Reinforcing Traffic Rules (RTR), a holistic closed-loop learning
objective to match expert demonstrations under a traffic compliance constraint,
which naturally gives rise to a joint IL + RL approach, obtaining the best of
both worlds. Our method learns in closed-loop simulations of both nominal
scenarios from real-world datasets as well as procedurally generated long-tail
scenarios. Our experiments show that RTR learns more realistic and
generalizable traffic simulation policies, achieving significantly better
tradeoffs between human-like driving and traffic compliance in both nominal and
long-tail scenarios. Moreover, when used as a data generation tool for training
prediction models, our learned traffic policy leads to considerably improved
downstream prediction metrics compared to baseline traffic agents. For more
information, visit the project website: https://waabi.ai/rtr
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01398" title="Abstract">arXiv:2311.01398</a> [<a href="/pdf/2311.01398" title="Download PDF">pdf</a>, <a href="/format/2311.01398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Server-side Rescoring of Spoken Entity-centric Knowledge Queries for  Virtual Assistants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Youyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gondala%2C+S">Sashank Gondala</a>, 
<a href="/search/cs?searchtype=author&query=Fraga-Silva%2C+T">Thiago Fraga-Silva</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gysel%2C+C">Christophe Van Gysel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">On-device Virtual Assistants (VAs) powered by Automatic Speech Recognition
(ASR) require effective knowledge integration for the challenging entity-rich
query recognition. In this paper, we conduct an empirical study of modeling
strategies for server-side rescoring of spoken information domain queries using
various categories of Language Models (LMs) (N-gram word LMs, sub-word neural
LMs). We investigate the combination of on-device and server-side signals, and
demonstrate significant WER improvements of 23%-35% on various entity-centric
query subpopulations by integrating various server-side LMs compared to
performing ASR on-device only. We also perform a comparison between LMs trained
on domain data and a GPT-3 variant offered by OpenAI as a baseline.
Furthermore, we also show that model fusion of multiple server-side LMs trained
from scratch most effectively combines complementary strengths of each model
and integrates knowledge learned from domain-specific data to a VA ASR system.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01403" title="Abstract">arXiv:2311.01403</a> [<a href="/pdf/2311.01403" title="Download PDF">pdf</a>, <a href="/format/2311.01403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> REAL: Resilience and Adaptation using Large Language Models on  Autonomous Aerial Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tagliabue%2C+A">Andrea Tagliabue</a>, 
<a href="/search/cs?searchtype=author&query=Kondo%2C+K">Kota Kondo</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Peterson%2C+M">Mason Peterson</a>, 
<a href="/search/cs?searchtype=author&query=Tewari%2C+C+T">Claudius T. Tewari</a>, 
<a href="/search/cs?searchtype=author&query=How%2C+J+P">Jonathan P. How</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures, conference workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) pre-trained on internet-scale datasets have
shown impressive capabilities in code understanding, synthesis, and general
purpose question-and-answering. Key to their performance is the substantial
prior knowledge acquired during training and their ability to reason over
extended sequences of symbols, often presented in natural language. In this
work, we aim to harness the extensive long-term reasoning, natural language
comprehension, and the available prior knowledge of LLMs for increased
resilience and adaptation in autonomous mobile robots. We introduce REAL, an
approach for REsilience and Adaptation using LLMs. REAL provides a strategy to
employ LLMs as a part of the mission planning and control framework of an
autonomous robot. The LLM employed by REAL provides (i) a source of prior
knowledge to increase resilience for challenging scenarios that the system had
not been explicitly designed for; (ii) a way to interpret natural-language and
other log/diagnostic information available in the autonomy stack, for mission
planning; (iii) a way to adapt the control inputs using minimal user-provided
prior knowledge about the dynamics/kinematics of the robot. We integrate REAL
in the autonomy stack of a real multirotor, querying onboard an offboard LLM at
0.1-1.0 Hz as part the robot's mission planning and control feedback loops. We
demonstrate in real-world experiments the ability of the LLM to reduce the
position tracking errors of a multirotor under the presence of (i) errors in
the parameters of the controller and (ii) unmodeled dynamics. We also show
(iii) decision making to avoid potentially dangerous scenarios (e.g., robot
oscillates) that had not been explicitly accounted for in the initial prompt
design.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01405" title="Abstract">arXiv:2311.01405</a> [<a href="/pdf/2311.01405" title="Download PDF">pdf</a>, <a href="/format/2311.01405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to See Physical Properties with Active Sensing Motor Policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Margolis%2C+G+B">Gabriel B. Margolis</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xiang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Y">Yandong Ji</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+P">Pulkit Agrawal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In CoRL 2023. Website: <a href="https://gmargo11.github.io/active-sensing-loco/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Knowledge of terrain's physical properties inferred from color images can aid
in making efficient robotic locomotion plans. However, unlike image
classification, it is unintuitive for humans to label image patches with
physical properties. Without labeled data, building a vision system that takes
as input the observed terrain and predicts physical properties remains
challenging. We present a method that overcomes this challenge by
self-supervised labeling of images captured by robots during real-world
traversal with physical property estimators trained in simulation. To ensure
accurate labeling, we introduce Active Sensing Motor Policies (ASMP), which are
trained to explore locomotion behaviors that increase the accuracy of
estimating physical parameters. For instance, the quadruped robot learns to
swipe its foot against the ground to estimate the friction coefficient
accurately. We show that the visual system trained with a small amount of
real-world traversal data accurately predicts physical parameters. The trained
system is robust and works even with overhead images captured by a drone
despite being trained on data collected by cameras attached to a quadruped
robot walking on the ground.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01406" title="Abstract">arXiv:2311.01406</a> [<a href="/pdf/2311.01406" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of Information Propagation in Ethereum Network Using Combined  Graph Attention Network and Reinforcement Learning to Optimize Network  Efficiency and Scalability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Behfar%2C+S+K">Stefan Kambiz Behfar</a>, 
<a href="/search/cs?searchtype=author&query=Crowcroft%2C+J">Jon Crowcroft</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Blockchain technology has revolutionized the way information is propagated in
decentralized networks. Ethereum plays a pivotal role in facilitating smart
contracts and decentralized applications. Understanding information propagation
dynamics in Ethereum is crucial for ensuring network efficiency, security, and
scalability. In this study, we propose an innovative approach that utilizes
Graph Convolutional Networks (GCNs) to analyze the information propagation
patterns in the Ethereum network. The first phase of our research involves data
collection from the Ethereum blockchain, consisting of blocks, transactions,
and node degrees. We construct a transaction graph representation using
adjacency matrices to capture the node embeddings; while our major contribution
is to develop a combined Graph Attention Network (GAT) and Reinforcement
Learning (RL) model to optimize the network efficiency and scalability. It
learns the best actions to take in various network states, ultimately leading
to improved network efficiency, throughput, and optimize gas limits for block
processing. In the experimental evaluation, we analyze the performance of our
model on a large-scale Ethereum dataset. We investigate effectively aggregating
information from neighboring nodes capturing graph structure and updating node
embeddings using GCN with the objective of transaction pattern prediction,
accounting for varying network loads and number of blocks. Not only we design a
gas limit optimization model and provide the algorithm, but also to address
scalability, we demonstrate the use and implementation of sparse matrices in
GraphConv, GraphSAGE, and GAT. The results indicate that our designed GAT-RL
model achieves superior results compared to other GCN models in terms of
performance. It effectively propagates information across the network,
optimizing gas limits for block processing and improving network efficiency.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01409" title="Abstract">arXiv:2311.01409</a> [<a href="/pdf/2311.01409" title="Download PDF">pdf</a>, <a href="/format/2311.01409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Coreset-based, Tempered Variational Posterior for Accurate and  Scalable Stochastic Gaussian Process Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ketenci%2C+M">Mert Ketenci</a>, 
<a href="/search/cs?searchtype=author&query=Perotte%2C+A">Adler Perotte</a>, 
<a href="/search/cs?searchtype=author&query=Elhadad%2C+N">No&#xe9;mie Elhadad</a>, 
<a href="/search/cs?searchtype=author&query=Urteaga%2C+I">I&#xf1;igo Urteaga</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We present a novel stochastic variational Gaussian process ($\mathcal{GP}$)
inference method, based on a posterior over a learnable set of weighted pseudo
input-output points (coresets). Instead of a free-form variational family, the
proposed coreset-based, variational tempered family for $\mathcal{GP}$s (CVTGP)
is defined in terms of the $\mathcal{GP}$ prior and the data-likelihood; hence,
accommodating the modeling inductive biases. We derive CVTGP's lower bound for
the log-marginal likelihood via marginalization of the proposed posterior over
latent $\mathcal{GP}$ coreset variables, and show it is amenable to stochastic
optimization. CVTGP reduces the learnable parameter size to $\mathcal{O}(M)$,
enjoys numerical stability, and maintains $\mathcal{O}(M^3)$ time- and
$\mathcal{O}(M^2)$ space-complexity, by leveraging a coreset-based tempered
posterior that, in turn, provides sparse and explainable representations of the
data. Results on simulated and real-world regression problems with Gaussian
observation noise validate that CVTGP provides better evidence lower-bound
estimates and predictive root mean squared error than alternative stochastic
$\mathcal{GP}$ inference methods.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01410" title="Abstract">arXiv:2311.01410</a> [<a href="/pdf/2311.01410" title="Download PDF">pdf</a>, <a href="/format/2311.01410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Blessing of Randomness: SDE Beats ODE in General Diffusion-based  Image Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nie%2C+S">Shen Nie</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H+A">Hanzhong Allan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuhao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chenyu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chongxuan Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a unified probabilistic formulation for diffusion-based image
editing, where a latent variable is edited in a task-specific manner and
generally deviates from the corresponding marginal distribution induced by the
original stochastic or ordinary differential equation (SDE or ODE). Instead, it
defines a corresponding SDE or ODE for editing. In the formulation, we prove
that the Kullback-Leibler divergence between the marginal distributions of the
two SDEs gradually decreases while that for the ODEs remains as the time
approaches zero, which shows the promise of SDE in image editing. Inspired by
it, we provide the SDE counterparts for widely used ODE baselines in various
tasks including inpainting and image-to-image translation, where SDE shows a
consistent and substantial improvement. Moreover, we propose SDE-Drag -- a
simple yet effective method built upon the SDE formulation for point-based
content dragging. We build a challenging benchmark (termed DragBench) with
open-set natural, art, and AI-generated images for evaluation. A user study on
DragBench indicates that SDE-Drag significantly outperforms our ODE baseline,
existing diffusion-based methods, and the renowned DragGAN. Our results
demonstrate the superiority and versatility of SDE in image editing and push
the boundary of diffusion-based editing methods.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01412" title="Abstract">arXiv:2311.01412</a> [<a href="/pdf/2311.01412" title="Download PDF">pdf</a>, <a href="/format/2311.01412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Castor: Causal Temporal Regime Structure Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahmani%2C+A">Abdellah Rahmani</a>, 
<a href="/search/cs?searchtype=author&query=Frossard%2C+P">Pascal Frossard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
<p class="mathjax">The task of uncovering causal relationships among multivariate time series
data stands as an essential and challenging objective that cuts across a broad
array of disciplines ranging from climate science to healthcare. Such data
entails linear or non-linear relationships, and usually follow multiple a
priori unknown regimes. Existing causal discovery methods can infer summary
causal graphs from heterogeneous data with known regimes, but they fall short
in comprehensively learning both regimes and the corresponding causal graph. In
this paper, we introduce CASTOR, a novel framework designed to learn causal
relationships in heterogeneous time series data composed of various regimes,
each governed by a distinct causal graph. Through the maximization of a score
function via the EM algorithm, CASTOR infers the number of regimes and learns
linear or non-linear causal relationships in each regime. We demonstrate the
robust convergence properties of CASTOR, specifically highlighting its
proficiency in accurately identifying unique regimes. Empirical evidence,
garnered from exhaustive synthetic experiments and two real-world benchmarks,
confirm CASTOR's superior performance in causal discovery compared to baseline
methods. By learning a full temporal causal graph for each regime, CASTOR
establishes itself as a distinctly interpretable method for causal discovery in
heterogeneous time series.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01414" title="Abstract">arXiv:2311.01414</a> [<a href="/pdf/2311.01414" title="Download PDF">pdf</a>, <a href="/ps/2311.01414" title="Download PostScript">ps</a>, <a href="/format/2311.01414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Dynamic Temporal Logic for Quality of Service in Choreographic Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pombo%2C+C+G+L">Carlos G. Lopez Pombo</a>, 
<a href="/search/cs?searchtype=author&query=Su%C3%B1%C3%A9%2C+A+E+M">Agust&#xed;n E. Martinez Su&#xf1;&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Tuosto%2C+E">Emilio Tuosto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, Accepted for publication at International Conference on Theoretical Aspects of Computing 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">We propose a framework for expressing and analyzing the Quality of Service
(QoS) of message-passing systems using a choreographic model that consists of
g-choreographies and Communicating Finite State machines (CFSMs). The following
are our three main contributions: (I) an extension of CFSMs with non-functional
contracts to specify quantitative constraints of local computations, (II) a
dynamic temporal logic capable of expressing QoS, properties of systems
relative to the g-choreography that specifies the communication protocol, (III)
the semi-decidability of our logic which enables a bounded model-checking
approach to verify QoS property of communicating systems.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01415" title="Abstract">arXiv:2311.01415</a> [<a href="/pdf/2311.01415" title="Download PDF">pdf</a>, <a href="/format/2311.01415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MoCheQoS: Automated Analysis of Quality of Service Properties of  Communicating Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pombo%2C+C+G+L">Carlos G. Lopez Pombo</a>, 
<a href="/search/cs?searchtype=author&query=Su%C3%B1%C3%A9%2C+A+E+M">Agust&#xed;n E. Martinez Su&#xf1;&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Tuosto%2C+E">Emilio Tuosto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">We present MoCheQoS, a tool to analyse quality of service (QoS) properties of
message-passing systems. Building on the logic and the choreographic model we
defined in recently published work, MoCheQoS implements a bounded model
checking algorithm. We discuss strengths and weaknesses of MoCheQoS through
some case studies.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01419" title="Abstract">arXiv:2311.01419</a> [<a href="/pdf/2311.01419" title="Download PDF">pdf</a>, <a href="/format/2311.01419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained-Context Conditional Diffusion Models for Imitation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saxena%2C+V">Vaibhav Saxena</a>, 
<a href="/search/cs?searchtype=author&query=Koga%2C+Y">Yotto Koga</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Danfei Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Offline Imitation Learning (IL) is a powerful paradigm to learn visuomotor
skills, especially for high-precision manipulation tasks. However, IL methods
are prone to spurious correlation - expressive models may focus on distractors
that are irrelevant to action prediction - and are thus fragile in real-world
deployment. Prior methods have addressed this challenge by exploring different
model architectures and action representations. However, none were able to
balance between sample efficiency, robustness against distractors, and solving
high-precision manipulation tasks with complex action space. To this end, we
present $\textbf{C}$onstrained-$\textbf{C}$ontext $\textbf{C}$onditional
$\textbf{D}$iffusion $\textbf{M}$odel (C3DM), a diffusion model policy for
solving 6-DoF robotic manipulation tasks with high precision and ability to
ignore distractions. A key component of C3DM is a fixation step that helps the
action denoiser to focus on task-relevant regions around the predicted action
while ignoring distractors in the context. We empirically show that C3DM is
able to consistently achieve high success rate on a wide array of tasks,
ranging from table top manipulation to industrial kitting, that require varying
levels of precision and robustness to distractors. For details, please visit
this https://sites.google.com/view/c3dm-imitation-learning
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01420" title="Abstract">arXiv:2311.01420</a> [<a href="/pdf/2311.01420" title="Download PDF">pdf</a>, <a href="/format/2311.01420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Holistic Transfer: Towards Non-Disruptive Fine-Tuning with Partial  Target Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tu%2C+C">Cheng-Hao Tu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hong-You Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+Z">Zheda Mai</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+J">Jike Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Pahuja%2C+V">Vardaan Pahuja</a>, 
<a href="/search/cs?searchtype=author&query=Berger-Wolf%2C+T">Tanya Berger-Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Song Gao</a>, 
<a href="/search/cs?searchtype=author&query=Stewart%2C+C">Charles Stewart</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yu Su</a>, 
<a href="/search/cs?searchtype=author&query=Chao%2C+W">Wei-Lun Chao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023 main track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We propose a learning problem involving adapting a pre-trained source model
to the target domain for classifying all classes that appeared in the source
data, using target data that covers only a partial label space. This problem is
practical, as it is unrealistic for the target end-users to collect data for
all classes prior to adaptation. However, it has received limited attention in
the literature. To shed light on this issue, we construct benchmark datasets
and conduct extensive experiments to uncover the inherent challenges. We found
a dilemma -- on the one hand, adapting to the new target domain is important to
claim better performance; on the other hand, we observe that preserving the
classification accuracy of classes missing in the target adaptation data is
highly challenging, let alone improving them. To tackle this, we identify two
key directions: 1) disentangling domain gradients from classification
gradients, and 2) preserving class relationships. We present several effective
solutions that maintain the accuracy of the missing classes and enhance the
overall performance, establishing solid baselines for holistic transfer of
pre-trained models with partial target data.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01423" title="Abstract">arXiv:2311.01423</a> [<a href="/pdf/2311.01423" title="Download PDF">pdf</a>, <a href="/format/2311.01423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CenterRadarNet: Joint 3D Object Detection and Tracking Framework using  4D FMCW Radar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jen-Hao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Kuan%2C+S">Sheng-Yao Kuan</a>, 
<a href="/search/cs?searchtype=author&query=Latapie%2C+H">Hugo Latapie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Gaowen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jenq-Neng Hwang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Robust perception is a vital component for ensuring safe autonomous and
assisted driving. Automotive radar (77 to 81 GHz), which offers
weather-resilient sensing, provides a complementary capability to the vision-
or LiDAR-based autonomous driving systems. Raw radio-frequency (RF) radar
tensors contain rich spatiotemporal semantics besides 3D location information.
The majority of previous methods take in 3D (Doppler-range-azimuth) RF radar
tensors, allowing prediction of an object's location, heading angle, and size
in bird's-eye-view (BEV). However, they lack the ability to at the same time
infer objects' size, orientation, and identity in the 3D space. To overcome
this limitation, we propose an efficient joint architecture called
CenterRadarNet, designed to facilitate high-resolution representation learning
from 4D (Doppler-range-azimuth-elevation) radar data for 3D object detection
and re-identification (re-ID) tasks. As a single-stage 3D object detector,
CenterRadarNet directly infers the BEV object distribution confidence maps,
corresponding 3D bounding box attributes, and appearance embedding for each
pixel. Moreover, we build an online tracker utilizing the learned appearance
embedding for re-ID. CenterRadarNet achieves the state-of-the-art result on the
K-Radar 3D object detection benchmark. In addition, we present the first 3D
object-tracking result using radar on the K-Radar dataset V2. In diverse
driving scenarios, CenterRadarNet shows consistent, robust performance,
emphasizing its wide applicability.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01428" title="Abstract">arXiv:2311.01428</a> [<a href="/pdf/2311.01428" title="Download PDF">pdf</a>, <a href="/format/2311.01428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying Alzheimer Disease Dementia Levels Using Machine Learning  Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hussain%2C+M+G">Md Gulzar Hussain</a>, 
<a href="/search/cs?searchtype=author&query=Shiren%2C+Y">Ye Shiren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Dementia, a prevalent neurodegenerative condition, is a major manifestation
of Alzheimer's disease (AD). As the condition progresses from mild to severe,
it significantly impairs the individual's ability to perform daily tasks
independently, necessitating the need for timely and accurate AD
classification. Machine learning or deep learning models have emerged as
effective tools for this purpose. In this study, we suggested an approach for
classifying the four stages of dementia using RF, SVM, and CNN algorithms,
augmented with watershed segmentation for feature extraction from MRI images.
Our results reveal that SVM with watershed features achieves an impressive
accuracy of 96.25%, surpassing other classification methods. The ADNI dataset
is utilized to evaluate the effectiveness of our method, and we observed that
the inclusion of watershed segmentation contributes to the enhanced performance
of the models.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01429" title="Abstract">arXiv:2311.01429</a> [<a href="/pdf/2311.01429" title="Download PDF">pdf</a>, <a href="/format/2311.01429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Vision Transformer for Accurate Traffic Sign Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaleybar%2C+J+M">Javad Mirzapour Kaleybar</a>, 
<a href="/search/cs?searchtype=author&query=Khaloo%2C+H">Hooman Khaloo</a>, 
<a href="/search/cs?searchtype=author&query=Naghipour%2C+A">Avaz Naghipour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This research paper addresses the challenges associated with traffic sign
detection in self-driving vehicles and driver assistance systems. The
development of reliable and highly accurate algorithms is crucial for the
widespread adoption of traffic sign recognition and detection (TSRD) in diverse
real-life scenarios. However, this task is complicated by suboptimal traffic
images affected by factors such as camera movement, adverse weather conditions,
and inadequate lighting. This study specifically focuses on traffic sign
detection methods and introduces the application of the Transformer model,
particularly the Vision Transformer variants, to tackle this task. The
Transformer's attention mechanism, originally designed for natural language
processing, offers improved parallel efficiency. Vision Transformers have
demonstrated success in various domains, including autonomous driving, object
detection, healthcare, and defense-related applications. To enhance the
efficiency of the Transformer model, the research proposes a novel strategy
that integrates a locality inductive bias and a transformer module. This
includes the introduction of the Efficient Convolution Block and the Local
Transformer Block, which effectively capture short-term and long-term
dependency information, thereby improving both detection speed and accuracy.
Experimental evaluations demonstrate the significant advancements achieved by
this approach, particularly when applied to the GTSDB dataset.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01431" title="Abstract">arXiv:2311.01431</a> [<a href="/pdf/2311.01431" title="Download PDF">pdf</a>, <a href="/ps/2311.01431" title="Download PostScript">ps</a>, <a href="/format/2311.01431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empirical Lossless Compression Bound of a Data Sequence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L+M">Lei M Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Statistics Theory (math.ST)

</div>
<p class="mathjax">We consider the lossless compression bound of any single data sequence. If we
fit the data by a parametric model, the entropy quantity $nH({\hat \theta}_n)$
obtained by plugging in the maximum likelihood estimate is an underestimate of
the bound, where $n$ is the number of words. Shtarkov showed that the
normalized maximum likelihood (NML) distribution or code length is optimal in a
minimax sense for any parametric family. We show by the local asymptotic
normality that the NML code length for the exponential families is $nH(\hat
\theta_n) +\frac{d}{2}\log \, \frac{n}{2\pi} +\log \int_{\Theta}
|I(\theta)|^{1/2}\, d\theta+o(1)$, where $d$ is the model dimension or
dictionary size, and $|I(\theta)|$ is the determinant of the Fisher information
matrix. We also demonstrate that sequentially predicting the optimal code
length for the next word via a Bayesian mechanism leads to the mixture code,
whose pathwise length is given by $nH({\hat \theta}_n) +\frac{d}{2}\log \,
\frac{n}{2\pi} +\log \frac{|\, I({\hat \theta}_n)|^{1/2}}{w({\hat
\theta}_n)}+o(1) $, where $w(\theta)$ is a prior. The asymptotics apply to not
only discrete symbols but also continuous data if the code length for the
former is replaced by the description length of the latter. The analytical
result is exemplified by calculating compression bounds of protein-encoding DNA
sequences under different parsing models. Typically, the highest compression is
achieved when the parsing is in phase of the amino acid codons. On the other
hand, the compression rates of pseudo-random sequences are larger than 1
regardless parsing models. These model-based results are in consistency with
that random sequences are incompressible as asserted by the Kolmogorov
complexity theory. The empirical lossless compression bound is particularly
more accurate when dictionary size is relatively large.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01432" title="Abstract">arXiv:2311.01432</a> [<a href="/pdf/2311.01432" title="Download PDF">pdf</a>, <a href="/format/2311.01432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformation Decoupling Strategy based on Screw Theory for  Deterministic Point Cloud Registration with Gravity Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zijian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yinlong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zimmer%2C+W">Walter Zimmer</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Hu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Feihu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Knoll%2C+A">Alois Knoll</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Point cloud registration is challenging in the presence of heavy outlier
correspondences. This paper focuses on addressing the robust
correspondence-based registration problem with gravity prior that often arises
in practice. The gravity directions are typically obtained by inertial
measurement units (IMUs) and can reduce the degree of freedom (DOF) of rotation
from 3 to 1. We propose a novel transformation decoupling strategy by
leveraging screw theory. This strategy decomposes the original 4-DOF problem
into three sub-problems with 1-DOF, 2-DOF, and 1-DOF, respectively, thereby
enhancing the computation efficiency. Specifically, the first 1-DOF represents
the translation along the rotation axis and we propose an interval
stabbing-based method to solve it. The second 2-DOF represents the pole which
is an auxiliary variable in screw theory and we utilize a branch-and-bound
method to solve it. The last 1-DOF represents the rotation angle and we propose
a global voting method for its estimation. The proposed method sequentially
solves three consensus maximization sub-problems, leading to efficient and
deterministic registration. In particular, it can even handle the
correspondence-free registration problem due to its significant robustness.
Extensive experiments on both synthetic and real-world datasets demonstrate
that our method is more efficient and robust than state-of-the-art methods,
even when dealing with outlier rates exceeding 99%.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01433" title="Abstract">arXiv:2311.01433</a> [<a href="/pdf/2311.01433" title="Download PDF">pdf</a>, <a href="/format/2311.01433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Study of Governance Issues in Decentralized Finance  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chenguang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Ye Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaofei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Decentralized finance (DeFi) is a prominent application of smart contracts,
representing a novel financial paradigm in contrast to centralized finance.
While DeFi applications are rapidly emerging on mainstream blockchain
platforms, their quality varies greatly, presenting numerous challenges,
particularly in terms of smart contract governance. This paper presents a
comprehensive study of governance issues in DeFi applications. Drawing upon
insights from industry reports and academic research papers, we develop a
governance taxonomy to examine these issues. We collect and analyze 4,446 audit
reports from 17 reputable Web3 security companies, categorizing the governance
issues according to our constructed taxonomy. In addition, we identify
vulnerabilities in the governance design and implementation processes, e.g.,
flash loan attacks and reentrancy attacks. To aid in the identification of the
main topics of governance issues, we employ Natural Language Processing (NLP)
techniques. Moreover, we explore the challenges associated with maintaining
consistency between the code and the whitepaper in DeFi applications, providing
valuable insights for addressing this issue in the future. We build a prototype
tool based on artificial intelligence (AI), representing an initial attempt to
uncover potential solutions. We validate this prototype across eight DeFi
projects, achieving a 56.14% F1 score and a 80% recall. Through this study, we
expect to assist the design and development teams of DeFi applications, as well
as users, researchers, and regulators, in better understanding and addressing
governance challenges, thereby fostering the healthy development of DeFi.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01434" title="Abstract">arXiv:2311.01434</a> [<a href="/pdf/2311.01434" title="Download PDF">pdf</a>, <a href="/format/2311.01434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tailoring Mixup to Data using Kernel Warping functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bouniot%2C+Q">Quentin Bouniot</a>, 
<a href="/search/cs?searchtype=author&query=Mozharovskyi%2C+P">Pavlo Mozharovskyi</a>, 
<a href="/search/cs?searchtype=author&query=d%27Alch%C3%A9-Buc%2C+F">Florence d&#x27;Alch&#xe9;-Buc</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Data augmentation is an essential building block for learning efficient deep
learning models. Among all augmentation techniques proposed so far, linear
interpolation of training data points, also called mixup, has found to be
effective for a large panel of applications. While the majority of works have
focused on selecting the right points to mix, or applying complex non-linear
interpolation, we are interested in mixing similar points more frequently and
strongly than less similar ones. To this end, we propose to dynamically change
the underlying distribution of interpolation coefficients through warping
functions, depending on the similarity between data points to combine. We
define an efficient and flexible framework to do so without losing in
diversity. We provide extensive experiments for classification and regression
tasks, showing that our proposed method improves both performance and
calibration of models. Code available in
https://github.com/ENSTA-U2IS/torch-uncertainty
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01435" title="Abstract">arXiv:2311.01435</a> [<a href="/pdf/2311.01435" title="Download PDF">pdf</a>, <a href="/format/2311.01435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Moments: Unsupervised Halfspace Learning in Polynomial Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xinyuan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Vempala%2C+S+S">Santosh S. Vempala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preliminary version in NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Probability (math.PR); Machine Learning (stat.ML)

</div>
<p class="mathjax">We give a polynomial-time algorithm for learning high-dimensional halfspaces
with margins in $d$-dimensional space to within desired TV distance when the
ambient distribution is an unknown affine transformation of the $d$-fold
product of an (unknown) symmetric one-dimensional logconcave distribution, and
the halfspace is introduced by deleting at least an $\epsilon$ fraction of the
data in one of the component distributions. Notably, our algorithm does not
need labels and establishes the unique (and efficient) identifiability of the
hidden halfspace under this distributional assumption. The sample and time
complexity of the algorithm are polynomial in the dimension and $1/\epsilon$.
The algorithm uses only the first two moments of suitable re-weightings of the
empirical distribution, which we call contrastive moments; its analysis uses
classical facts about generalized Dirichlet polynomials and relies crucially on
a new monotonicity property of the moment ratio of truncations of logconcave
distributions. Such algorithms, based only on first and second moments were
suggested in earlier work, but hitherto eluded rigorous guarantees.
<br />Prior work addressed the special case when the underlying distribution is
Gaussian via Non-Gaussian Component Analysis. We improve on this by providing
polytime guarantees based on Total Variation (TV) distance, in place of
existing moment-bound guarantees that can be super-polynomial. Our work is also
the first to go beyond Gaussians in this setting.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01441" title="Abstract">arXiv:2311.01441</a> [<a href="/pdf/2311.01441" title="Download PDF">pdf</a>, <a href="/format/2311.01441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distilling Out-of-Distribution Robustness from Vision-Language  Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A">Andy Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jindong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Xiong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haohan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We propose a conceptually simple and lightweight framework for improving the
robustness of vision models through the combination of knowledge distillation
and data augmentation. We address the conjecture that larger models do not make
for better teachers by showing strong gains in out-of-distribution robustness
when distilling from pretrained foundation models. Following this finding, we
propose Discrete Adversarial Distillation (DAD), which leverages a robust
teacher to generate adversarial examples and a VQGAN to discretize them,
creating more informative samples than standard data augmentation techniques.
We provide a theoretical framework for the use of a robust teacher in the
knowledge distillation with data augmentation setting and demonstrate strong
gains in out-of-distribution robustness and clean accuracy across different
student architectures. Notably, our method adds minor computational overhead
compared to similar techniques and can be easily combined with other data
augmentations for further improvements.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01442" title="Abstract">arXiv:2311.01442</a> [<a href="/pdf/2311.01442" title="Download PDF">pdf</a>, <a href="/format/2311.01442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Double Descent for Time Series Forecasting: Avoiding Undertrained  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Assandri%2C+V">Valentino Assandri</a>, 
<a href="/search/cs?searchtype=author&query=Heshmati%2C+S">Sam Heshmati</a>, 
<a href="/search/cs?searchtype=author&query=Yaman%2C+B">Burhaneddin Yaman</a>, 
<a href="/search/cs?searchtype=author&query=Iakovlev%2C+A">Anton Iakovlev</a>, 
<a href="/search/cs?searchtype=author&query=Repetur%2C+A+E">Ariel Emiliano Repetur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deep learning models, particularly Transformers, have achieved impressive
results in various domains, including time series forecasting. While existing
time series literature primarily focuses on model architecture modifications
and data augmentation techniques, this paper explores the training schema of
deep learning models for time series; how models are trained regardless of
their architecture. We perform extensive experiments to investigate the
occurrence of deep double descent in several Transformer models trained on
public time series data sets. We demonstrate epoch-wise deep double descent and
that overfitting can be reverted using more epochs. Leveraging these findings,
we achieve state-of-the-art results for long sequence time series forecasting
in nearly 70% of the 72 benchmarks tested. This suggests that many models in
the literature may possess untapped potential. Additionally, we introduce a
taxonomy for classifying training schema modifications, covering data
augmentation, model inputs, model targets, time series per model, and
computational budget.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01444" title="Abstract">arXiv:2311.01444</a> [<a href="/pdf/2311.01444" title="Download PDF">pdf</a>, <a href="/format/2311.01444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LabelFormer: Object Trajectory Refinement for Offboard Perception from  LiDAR Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+A+J">Anqi Joyce Yang</a>, 
<a href="/search/cs?searchtype=author&query=Casas%2C+S">Sergio Casas</a>, 
<a href="/search/cs?searchtype=author&query=Dvornik%2C+N">Nikita Dvornik</a>, 
<a href="/search/cs?searchtype=author&query=Segal%2C+S">Sean Segal</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yuwen Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J+S+K">Jordan Sir Kwang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Carter Fang</a>, 
<a href="/search/cs?searchtype=author&query=Urtasun%2C+R">Raquel Urtasun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 8 figures, 7 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> CoRL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">A major bottleneck to scaling-up training of self-driving perception systems
are the human annotations required for supervision. A promising alternative is
to leverage "auto-labelling" offboard perception models that are trained to
automatically generate annotations from raw LiDAR point clouds at a fraction of
the cost. Auto-labels are most commonly generated via a two-stage approach --
first objects are detected and tracked over time, and then each object
trajectory is passed to a learned refinement model to improve accuracy. Since
existing refinement models are overly complex and lack advanced temporal
reasoning capabilities, in this work we propose LabelFormer, a simple,
efficient, and effective trajectory-level refinement approach. Our approach
first encodes each frame's observations separately, then exploits
self-attention to reason about the trajectory with full temporal context, and
finally decodes the refined object size and per-frame poses. Evaluation on both
urban and highway datasets demonstrates that LabelFormer outperforms existing
works by a large margin. Finally, we show that training on a dataset augmented
with auto-labels generated by our method leads to improved downstream detection
performance compared to existing methods. Please visit the project website for
details https://waabi.ai/labelformer
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01446" title="Abstract">arXiv:2311.01446</a> [<a href="/pdf/2311.01446" title="Download PDF">pdf</a>, <a href="/format/2311.01446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adv3D: Generating Safety-Critical 3D Objects through Closed-Loop  Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarva%2C+J">Jay Sarva</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingkang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+J">James Tu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yuwen Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Manivasagam%2C+S">Sivabalan Manivasagam</a>, 
<a href="/search/cs?searchtype=author&query=Urtasun%2C+R">Raquel Urtasun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CoRL 2023. Project page: <a href="https://waabi.ai/adv3d/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Self-driving vehicles (SDVs) must be rigorously tested on a wide range of
scenarios to ensure safe deployment. The industry typically relies on
closed-loop simulation to evaluate how the SDV interacts on a corpus of
synthetic and real scenarios and verify it performs properly. However, they
primarily only test the system's motion planning module, and only consider
behavior variations. It is key to evaluate the full autonomy system in
closed-loop, and to understand how variations in sensor data based on scene
appearance, such as the shape of actors, affect system performance. In this
paper, we propose a framework, Adv3D, that takes real world scenarios and
performs closed-loop sensor simulation to evaluate autonomy performance, and
finds vehicle shapes that make the scenario more challenging, resulting in
autonomy failures and uncomfortable SDV maneuvers. Unlike prior works that add
contrived adversarial shapes to vehicle roof-tops or roadside to harm
perception only, we optimize a low-dimensional shape representation to modify
the vehicle shape itself in a realistic manner to degrade autonomy performance
(e.g., perception, prediction, and motion planning). Moreover, we find that the
shape variations found with Adv3D optimized in closed-loop are much more
effective than those in open-loop, demonstrating the importance of finding
scene appearance variations that affect autonomy in the interactive setting.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01447" title="Abstract">arXiv:2311.01447</a> [<a href="/pdf/2311.01447" title="Download PDF">pdf</a>, <a href="/format/2311.01447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CADSim: Robust and Scalable in-the-wild 3D Reconstruction for  Controllable Sensor Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingkang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Manivasagam%2C+S">Sivabalan Manivasagam</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ze Yang</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%A2rsan%2C+I+A">Ioan Andrei B&#xe2;rsan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+A+J">Anqi Joyce Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wei-Chiu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Urtasun%2C+R">Raquel Urtasun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CoRL 2022. Project page: <a href="https://waabi.ai/cadsim/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Realistic simulation is key to enabling safe and scalable development of %
self-driving vehicles. A core component is simulating the sensors so that the
entire autonomy system can be tested in simulation. Sensor simulation involves
modeling traffic participants, such as vehicles, with high quality appearance
and articulated geometry, and rendering them in real time. The self-driving
industry has typically employed artists to build these assets. However, this is
expensive, slow, and may not reflect reality. Instead, reconstructing assets
automatically from sensor data collected in the wild would provide a better
path to generating a diverse and large set with good real-world coverage.
Nevertheless, current reconstruction approaches struggle on in-the-wild sensor
data, due to its sparsity and noise. To tackle these issues, we present CADSim,
which combines part-aware object-class priors via a small set of CAD models
with differentiable rendering to automatically reconstruct vehicle geometry,
including articulated wheels, with high-quality appearance. Our experiments
show our method recovers more accurate shapes from sparse data compared to
existing approaches. Importantly, it also trains and renders efficiently. We
demonstrate our reconstructed vehicles in several applications, including
accurate testing of autonomy perception systems.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01448" title="Abstract">arXiv:2311.01448</a> [<a href="/pdf/2311.01448" title="Download PDF">pdf</a>, <a href="/format/2311.01448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UltraLiDAR: Learning Compact Representations for LiDAR Completion and  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yuwen Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wei-Chiu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingkang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Urtasun%2C+R">Raquel Urtasun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2023. Project page: <a href="https://waabi.ai/ultralidar/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">LiDAR provides accurate geometric measurements of the 3D world.
Unfortunately, dense LiDARs are very expensive and the point clouds captured by
low-beam LiDAR are often sparse. To address these issues, we present
UltraLiDAR, a data-driven framework for scene-level LiDAR completion, LiDAR
generation, and LiDAR manipulation. The crux of UltraLiDAR is a compact,
discrete representation that encodes the point cloud's geometric structure, is
robust to noise, and is easy to manipulate. We show that by aligning the
representation of a sparse point cloud to that of a dense point cloud, we can
densify the sparse point clouds as if they were captured by a real high-density
LiDAR, drastically reducing the cost. Furthermore, by learning a prior over the
discrete codebook, we can generate diverse, realistic LiDAR point clouds for
self-driving. We evaluate the effectiveness of UltraLiDAR on sparse-to-dense
LiDAR completion and LiDAR generation. Experiments show that densifying
real-world point clouds with our approach can significantly improve the
performance of downstream perception systems. Compared to prior art on LiDAR
generation, our approach generates much more realistic point clouds. According
to A/B test, over 98.5\% of the time human participants prefer our results over
those of previous methods.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01449" title="Abstract">arXiv:2311.01449</a> [<a href="/pdf/2311.01449" title="Download PDF">pdf</a>, <a href="/format/2311.01449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TopicGPT: A Prompt-based Topic Modeling Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pham%2C+C+M">Chau Minh Pham</a>, 
<a href="/search/cs?searchtype=author&query=Hoyle%2C+A">Alexander Hoyle</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Simeng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Iyyer%2C+M">Mohit Iyyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Topic modeling is a well-established technique for exploring text corpora.
Conventional topic models (e.g., LDA) represent topics as bags of words that
often require "reading the tea leaves" to interpret; additionally, they offer
users minimal semantic control over topics. To tackle these issues, we
introduce TopicGPT, a prompt-based framework that uses large language models
(LLMs) to uncover latent topics within a provided text collection. TopicGPT
produces topics that align better with human categorizations compared to
competing methods: for example, it achieves a harmonic mean purity of 0.74
against human-annotated Wikipedia topics compared to 0.64 for the strongest
baseline. Its topics are also more interpretable, dispensing with ambiguous
bags of words in favor of topics with natural language labels and associated
free-form descriptions. Moreover, the framework is highly adaptable, allowing
users to specify constraints and modify topics without the need for model
retraining. TopicGPT can be further extended to hierarchical topical modeling,
enabling users to explore topics at various levels of granularity. By
streamlining access to high-quality and interpretable topics, TopicGPT
represents a compelling, human-centered approach to topic modeling.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01450" title="Abstract">arXiv:2311.01450</a> [<a href="/pdf/2311.01450" title="Download PDF">pdf</a>, <a href="/format/2311.01450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreamSmooth: Improving Model-based Reinforcement Learning via Reward  Smoothing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+V">Vint Lee</a>, 
<a href="/search/cs?searchtype=author&query=Abbeel%2C+P">Pieter Abbeel</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Youngwoon Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Model-based reinforcement learning (MBRL) has gained much attention for its
ability to learn complex behaviors in a sample-efficient way: planning actions
by generating imaginary trajectories with predicted rewards. Despite its
success, we found that surprisingly, reward prediction is often a bottleneck of
MBRL, especially for sparse rewards that are challenging (or even ambiguous) to
predict. Motivated by the intuition that humans can learn from rough reward
estimates, we propose a simple yet effective reward smoothing approach,
DreamSmooth, which learns to predict a temporally-smoothed reward, instead of
the exact reward at the given timestep. We empirically show that DreamSmooth
achieves state-of-the-art performance on long-horizon sparse-reward tasks both
in sample efficiency and final performance without losing performance on common
benchmarks, such as Deepmind Control Suite and Atari benchmarks.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01451" title="Abstract">arXiv:2311.01451</a> [<a href="/pdf/2311.01451" title="Download PDF">pdf</a>, <a href="/format/2311.01451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Randomized Strong Recursive Skeletonization: Simultaneous compression  and factorization of $\mathcal{H}$-matrices in the Black-Box Setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yesypenko%2C+A">Anna Yesypenko</a>, 
<a href="/search/math?searchtype=author&query=Martinsson%2C+P">Per-Gunnar Martinsson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The hierarchical matrix ($\mathcal{H}^{2}$-matrix) formalism provides a way
to reinterpret the Fast Multipole Method and related fast summation schemes in
linear algebraic terms. The idea is to tessellate a matrix into blocks in such
as way that each block is either small or of numerically low rank; this enables
the storage of the matrix and the application of it to a vector in linear or
close to linear complexity. A key motivation for the reformulation is to extend
the range of dense matrices that can be represented. Additionally,
$\mathcal{H}^{2}$-matrices in principle also extend the range of operations
that can be executed to include matrix inversion and factorization. While such
algorithms can be highly efficient for certain specialized formats (such as
HBS/HSS matrices based on ``weak admissibility''), inversion algorithms for
general $\mathcal{H}^{2}$-matrices tend to be based on nested recursions and
recompressions, making them challenging to implement efficiently. An exception
is the \textit{strong recursive skeletonization (SRS)} algorithm by Minden, Ho,
Damle, and Ying, which involves a simpler algorithmic flow. However, SRS
greatly increases the number of blocks of the matrix that need to be stored
explicitly, leading to high memory requirements. This manuscript presents the
\textit{randomized strong recursive skeletonization (RSRS)} algorithm, which is
a reformulation of SRS that incorporates the randomized SVD (RSVD) to
simultaneously compress and factorize an $\mathcal{H}^{2}$-matrix. RSRS is a
``black box'' algorithm that interacts with the matrix to be compressed only
via its action on vectors; this extends the range of the SRS algorithm (which
relied on the ``proxy source'' compression technique) to include dense matrices
that arise in sparse direct solvers.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01452" title="Abstract">arXiv:2311.01452</a> [<a href="/pdf/2311.01452" title="Download PDF">pdf</a>, <a href="/format/2311.01452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time Series Anomaly Detection using Diffusion-based Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pintilie%2C+I">Ioana Pintilie</a>, 
<a href="/search/cs?searchtype=author&query=Manolache%2C+A">Andrei Manolache</a>, 
<a href="/search/cs?searchtype=author&query=Brad%2C+F">Florin Brad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the AI4TS workshop of the 23rd IEEE International Conference on Data Mining (ICDM 2023), 9 pages, 7 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Diffusion models have been recently used for anomaly detection (AD) in
images. In this paper we investigate whether they can also be leveraged for AD
on multivariate time series (MTS). We test two diffusion-based models and
compare them to several strong neural baselines. We also extend the PA%K
protocol, by computing a ROCK-AUC metric, which is agnostic to both the
detection threshold and the ratio K of correctly detected points. Our models
outperform the baselines on synthetic datasets and are competitive on
real-world datasets, illustrating the potential of diffusion-based methods for
AD in multivariate time series.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01454" title="Abstract">arXiv:2311.01454</a> [<a href="/pdf/2311.01454" title="Download PDF">pdf</a>, <a href="/format/2311.01454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NOIR: Neural Signal Operated Intelligent Robots for Everyday Activities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruohan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sharon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+M">Minjune Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Hiranaka%2C+A">Ayano Hiranaka</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+W">Wensi Ai</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+J+J+R">Jin Jie Ryan Tan</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Shreya Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yilun Hao</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+G">Gabrael Levine</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Ruohan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Norcia%2C+A">Anthony Norcia</a>, 
<a href="/search/cs?searchtype=author&query=Fei-Fei%2C+L">Li Fei-Fei</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present Neural Signal Operated Intelligent Robots (NOIR), a
general-purpose, intelligent brain-robot interface system that enables humans
to command robots to perform everyday activities through brain signals. Through
this interface, humans communicate their intended objects of interest and
actions to the robots using electroencephalography (EEG). Our novel system
demonstrates success in an expansive array of 20 challenging, everyday
household activities, including cooking, cleaning, personal care, and
entertainment. The effectiveness of the system is improved by its synergistic
integration of robot learning algorithms, allowing for NOIR to adapt to
individual users and predict their intentions. Our work enhances the way humans
interact with robots, replacing traditional channels of interaction with
direct, neural communication. Project website: https://noir-corl.github.io/.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01455" title="Abstract">arXiv:2311.01455</a> [<a href="/pdf/2311.01455" title="Download PDF">pdf</a>, <a href="/format/2311.01455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoboGen: Towards Unleashing Infinite Data for Automated Robot Learning  via Generative Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yufei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+Z">Zhou Xian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Feng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tsun-Hsuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fragkiadaki%2C+K">Katerina Fragkiadaki</a>, 
<a href="/search/cs?searchtype=author&query=Erickson%2C+Z">Zackory Erickson</a>, 
<a href="/search/cs?searchtype=author&query=Held%2C+D">David Held</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chuang Gan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present RoboGen, a generative robotic agent that automatically learns
diverse robotic skills at scale via generative simulation. RoboGen leverages
the latest advancements in foundation and generative models. Instead of
directly using or adapting these models to produce policies or low-level
actions, we advocate for a generative scheme, which uses these models to
automatically generate diversified tasks, scenes, and training supervisions,
thereby scaling up robotic skill learning with minimal human supervision. Our
approach equips a robotic agent with a self-guided propose-generate-learn
cycle: the agent first proposes interesting tasks and skills to develop, and
then generates corresponding simulation environments by populating pertinent
objects and assets with proper spatial configurations. Afterwards, the agent
decomposes the proposed high-level task into sub-tasks, selects the optimal
learning approach (reinforcement learning, motion planning, or trajectory
optimization), generates required training supervision, and then learns
policies to acquire the proposed skill. Our work attempts to extract the
extensive and versatile knowledge embedded in large-scale models and transfer
them to the field of robotics. Our fully generative pipeline can be queried
repeatedly, producing an endless stream of skill demonstrations associated with
diverse tasks and environments.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01457" title="Abstract">arXiv:2311.01457</a> [<a href="/pdf/2311.01457" title="Download PDF">pdf</a>, <a href="/format/2311.01457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conformal Policy Learning for Sensorimotor Control Under Distribution  Shifts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+S">Satvik Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Loquercio%2C+A">Antonio Loquercio</a>, 
<a href="/search/cs?searchtype=author&query=Angelopoulos%2C+A">Anastasios Angelopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Goldberg%2C+K">Ken Goldberg</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+J">Jitendra Malik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conformal Policy Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper focuses on the problem of detecting and reacting to changes in the
distribution of a sensorimotor controller's observables. The key idea is the
design of switching policies that can take conformal quantiles as input, which
we define as conformal policy learning, that allows robots to detect
distribution shifts with formal statistical guarantees. We show how to design
such policies by using conformal quantiles to switch between base policies with
different characteristics, e.g. safety or speed, or directly augmenting a
policy observation with a quantile and training it with reinforcement learning.
Theoretically, we show that such policies achieve the formal convergence
guarantees in finite time. In addition, we thoroughly evaluate their advantages
and limitations on two compelling use cases: simulated autonomous driving and
active perception with a physical quadruped. Empirical results demonstrate that
our approach outperforms five baselines. It is also the simplest of the
baseline strategies besides one ablation. Being easy to use, flexible, and with
formal guarantees, our work demonstrates how conformal prediction can be an
effective tool for sensorimotor learning under uncertainty.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01458" title="Abstract">arXiv:2311.01458</a> [<a href="/pdf/2311.01458" title="Download PDF">pdf</a>, <a href="/format/2311.01458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Deepfakes Without Seeing Any
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reiss%2C+T">Tal Reiss</a>, 
<a href="/search/cs?searchtype=author&query=Cavia%2C+B">Bar Cavia</a>, 
<a href="/search/cs?searchtype=author&query=Hoshen%2C+Y">Yedid Hoshen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our code is available at <a href="https://github.com/talreiss/FACTOR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deepfake attacks, malicious manipulation of media containing people, are a
serious concern for society. Conventional deepfake detection methods train
supervised classifiers to distinguish real media from previously encountered
deepfakes. Such techniques can only detect deepfakes similar to those
previously seen, but not zero-day (previously unseen) attack types. As current
deepfake generation techniques are changing at a breathtaking pace, new attack
types are proposed frequently, making this a major issue. Our main observations
are that: i) in many effective deepfake attacks, the fake media must be
accompanied by false facts i.e. claims about the identity, speech, motion, or
appearance of the person. For instance, when impersonating Obama, the attacker
explicitly or implicitly claims that the fake media show Obama; ii) current
generative techniques cannot perfectly synthesize the false facts claimed by
the attacker. We therefore introduce the concept of "fact checking", adapted
from fake news detection, for detecting zero-day deepfake attacks. Fact
checking verifies that the claimed facts (e.g. identity is Obama), agree with
the observed media (e.g. is the face really Obama's?), and thus can
differentiate between real and fake media. Consequently, we introduce FACTOR, a
practical recipe for deepfake fact checking and demonstrate its power in
critical attack settings: face swapping and audio-visual synthesis. Although it
is training-free, relies exclusively on off-the-shelf features, is very easy to
implement, and does not see any deepfakes, it achieves better than
state-of-the-art accuracy.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01459" title="Abstract">arXiv:2311.01459</a> [<a href="/pdf/2311.01459" title="Download PDF">pdf</a>, <a href="/format/2311.01459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Align Your Prompts: Test-Time Prompting with Distribution Alignment for  Zero-Shot Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hassan%2C+J">Jameel Hassan</a>, 
<a href="/search/cs?searchtype=author&query=Gani%2C+H">Hanan Gani</a>, 
<a href="/search/cs?searchtype=author&query=Hussein%2C+N">Noor Hussein</a>, 
<a href="/search/cs?searchtype=author&query=Khattak%2C+M+U">Muhammad Uzair Khattak</a>, 
<a href="/search/cs?searchtype=author&query=Naseer%2C+M">Muzammal Naseer</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+F+S">Fahad Shahbaz Khan</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Salman Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The promising zero-shot generalization of vision-language models such as CLIP
has led to their adoption using prompt learning for numerous downstream tasks.
Previous works have shown test-time prompt tuning using entropy minimization to
adapt text prompts for unseen domains. While effective, this overlooks the key
cause for performance degradation to unseen domains -- distribution shift. In
this work, we explicitly handle this problem by aligning the
out-of-distribution (OOD) test sample statistics to those of the source data
using prompt tuning. We use a single test sample to adapt multi-modal prompts
at test time by minimizing the feature distribution shift to bridge the gap in
the test domain. Evaluating against the domain generalization benchmark, our
method improves zero-shot top- 1 accuracy beyond existing prompt-learning
techniques, with a 3.08% improvement over the baseline MaPLe. In cross-dataset
generalization with unseen categories across 10 datasets, our method improves
consistently across all datasets compared to the existing state-of-the-art. Our
source code and models are available at
https://jameelhassan.github.io/promptalign.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01460" title="Abstract">arXiv:2311.01460</a> [<a href="/pdf/2311.01460" title="Download PDF">pdf</a>, <a href="/ps/2311.01460" title="Download PostScript">ps</a>, <a href="/format/2311.01460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Chain of Thought Reasoning via Knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yuntian Deng</a>, 
<a href="/search/cs?searchtype=author&query=Prasad%2C+K">Kiran Prasad</a>, 
<a href="/search/cs?searchtype=author&query=Fernandez%2C+R">Roland Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=Smolensky%2C+P">Paul Smolensky</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhary%2C+V">Vishrav Chaudhary</a>, 
<a href="/search/cs?searchtype=author&query=Shieber%2C+S">Stuart Shieber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">To augment language models with the ability to reason, researchers usually
prompt or finetune them to produce chain of thought reasoning steps before
producing the final answer. However, although people use natural language to
reason effectively, it may be that LMs could reason more effectively with some
intermediate computation that is not in natural language. In this work, we
explore an alternative reasoning approach: instead of explicitly producing the
chain of thought reasoning steps, we use the language model's internal hidden
states to perform implicit reasoning. The implicit reasoning steps are
distilled from a teacher model trained on explicit chain-of-thought reasoning,
and instead of doing reasoning "horizontally" by producing intermediate words
one-by-one, we distill it such that the reasoning happens "vertically" among
the hidden states in different layers. We conduct experiments on a multi-digit
multiplication task and a grade school math problem dataset and find that this
approach enables solving tasks previously not solvable without explicit
chain-of-thought, at a speed comparable to no chain-of-thought.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01461" title="Abstract">arXiv:2311.01461</a> [<a href="/pdf/2311.01461" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Property Law of Crypto Tokens
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wyczik%2C+J">Jakub Wyczik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Legal Status of Crypto Tokens (FT, NFT, etc.)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">This article addresses the lack of comprehensive studies on Web3
technologies, primarily due to lawyers' reluctance to explore technical
intricacies. Understanding the underlying technological foundations is crucial
to enhance the credibility of legal opinions. This article aims to illuminate
these foundations, debunk myths, and concentrate on determining the legal
status of crypto-assets in the context of property rights within the
distributed economy. In addition, this article notes that the intangible nature
of crypto-assets that derive value from distributed registries, and their
resistance to deletion, makes crypto-assets more akin to the autonomy of
intellectual property than physical media. The article presents illustrative
examples from common law (United States, United Kingdom, New Zealand) and civil
law (Germany, Austria, Poland) systems. Proposing a universal solution, it
advocates a comprehensive framework safeguarding digital property - data
ownership - extending beyond the confines of Web3.
<br />This article presents a comprehensive, multi-layered approach to the analysis
of tokens as digital content and virtual goods. The approach, universally
applicable to various of such goods, scrutinizes property on three distinct
layers: first, the rights to the virtual good itself; second, the rights to the
assets linked to the virtual good; and third, the rights to the intellectual
property intricately associated with the token. Additionally, the paper
provides concise analysis of the conflict of laws rules applicable to virtual
goods. It also delves into issues concerning formal requirements for the
transfer of intellectual property rights, licensing, the first sale
(exhaustion) doctrine, the concept of the lawful acquirer, and other crucial
aspects of intellectual property in the realm of virtual goods, particularly
within the emerging metaverse.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01462" title="Abstract">arXiv:2311.01462</a> [<a href="/pdf/2311.01462" title="Download PDF">pdf</a>, <a href="/format/2311.01462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Idempotent Generative Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shocher%2C+A">Assaf Shocher</a>, 
<a href="/search/cs?searchtype=author&query=Dravid%2C+A">Amil Dravid</a>, 
<a href="/search/cs?searchtype=author&query=Gandelsman%2C+Y">Yossi Gandelsman</a>, 
<a href="/search/cs?searchtype=author&query=Mosseri%2C+I">Inbar Mosseri</a>, 
<a href="/search/cs?searchtype=author&query=Rubinstein%2C+M">Michael Rubinstein</a>, 
<a href="/search/cs?searchtype=author&query=Efros%2C+A+A">Alexei A. Efros</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose a new approach for generative modeling based on training a neural
network to be idempotent. An idempotent operator is one that can be applied
sequentially without changing the result beyond the initial application, namely
$f(f(z))=f(z)$. The proposed model $f$ is trained to map a source distribution
(e.g, Gaussian noise) to a target distribution (e.g. realistic images) using
the following objectives: (1) Instances from the target distribution should map
to themselves, namely $f(x)=x$. We define the target manifold as the set of all
instances that $f$ maps to themselves. (2) Instances that form the source
distribution should map onto the defined target manifold. This is achieved by
optimizing the idempotence term, $f(f(z))=f(z)$ which encourages the range of
$f(z)$ to be on the target manifold. Under ideal assumptions such a process
provably converges to the target distribution. This strategy results in a model
capable of generating an output in one step, maintaining a consistent latent
space, while also allowing sequential applications for refinement.
Additionally, we find that by processing inputs from both target and source
distributions, the model adeptly projects corrupted or modified data back to
the target manifold. This work is a first step towards a ``global projector''
that enables projecting any input into a target data distribution.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Fri,  3 Nov 23</h3>
<dl>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14691" title="Abstract">arXiv:2310.14691</a> (cross-list from math.ST) [<a href="/pdf/2310.14691" title="Download PDF">pdf</a>, <a href="/ps/2310.14691" title="Download PostScript">ps</a>, <a href="/format/2310.14691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifiability of total effects from abstractions of time series causal  graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Assaad%2C+C+K">Charles K. Assaad</a>, 
<a href="/search/math?searchtype=author&query=Devijver%2C+E">Emilie Devijver</a> (LIG, UGA), 
<a href="/search/math?searchtype=author&query=Gaussier%2C+E">Eric Gaussier</a> (LIG, UGA), 
<a href="/search/math?searchtype=author&query=G%C3%B6ssler%2C+G">Gregor G&#xf6;ssler</a> (LIG, SPADES), 
<a href="/search/math?searchtype=author&query=Meynaoui%2C+A">Anouar Meynaoui</a> (IRMAR, UR2)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We study the problem of identifiability of the total effect of an
intervention from observational time series only given an abstraction of the
causal graph of the system. Specifically, we consider two types of
abstractions: the extended summary causal graph which conflates all lagged
causal relations but distinguishes between lagged and instantaneous relations;
and the summary causal graph which does not give any indication about the lag
between causal relations. We show that the total effect is always identifiable
in extended summary causal graphs and we provide necessary and sufficient
graphical conditions for identifiability in summary causal graphs. Furthermore,
we provide adjustment sets allowing to estimate the total effect whenever it is
identifiable.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00775" title="Abstract">arXiv:2311.00775</a> (cross-list from astro-ph.EP) [<a href="/pdf/2311.00775" title="Download PDF">pdf</a>, <a href="/format/2311.00775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing machine learning for accurate treatment of overlapping  opacity species in GCMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Schneider%2C+A+D">Aaron David Schneider</a>, 
<a href="/search/astro-ph?searchtype=author&query=Molli%C3%A8re%2C+P">Paul Molli&#xe8;re</a>, 
<a href="/search/astro-ph?searchtype=author&query=Louppe%2C+G">Gilles Louppe</a>, 
<a href="/search/astro-ph?searchtype=author&query=Carone%2C+L">Ludmila Carone</a>, 
<a href="/search/astro-ph?searchtype=author&query=J%C3%B8rgensen%2C+U+G">Uffe Gr&#xe5;e J&#xf8;rgensen</a>, 
<a href="/search/astro-ph?searchtype=author&query=Decin%2C+L">Leen Decin</a>, 
<a href="/search/astro-ph?searchtype=author&query=Helling%2C+C">Christiane Helling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to A&amp;A
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Earth and Planetary Astrophysics (astro-ph.EP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">To understand high precision observations of exoplanets and brown dwarfs, we
need detailed and complex general circulation models (GCMs) that incorporate
hydrodynamics, chemistry, and radiation. In this study, we specifically examine
the coupling between chemistry and radiation in GCMs and compare different
methods for mixing opacities of different chemical species in the correlated-k
assumption, when equilibrium chemistry cannot be assumed. We propose a fast
machine learning method based on DeepSets (DS), which effectively combines
individual correlated-k opacities (k-tables). We evaluate the DS method
alongside other published methods like adaptive equivalent extinction (AEE) and
random overlap with rebinning and resorting (RORR). We integrate these mixing
methods into our GCM (expeRT/MITgcm) and assess their accuracy and performance
for the example of the hot Jupiter HD~209458 b. Our findings indicate that the
DS method is both accurate and efficient for GCM usage, whereas RORR is too
slow. Additionally, we observe that the accuracy of AEE depends on its specific
implementation and may introduce numerical issues in achieving radiative
transfer solution convergence. We then apply the DS mixing method in a
simplified chemical disequilibrium situation, where we model the rainout of TiO
and VO, and confirm that the rainout of TiO and VO would hinder the formation
of a stratosphere. To further expedite the development of consistent
disequilibrium chemistry calculations in GCMs, we provide documentation and
code for coupling the DS mixing method with correlated-k radiative transfer
solvers. The DS method has been extensively tested to be accurate enough for
GCMs, however, other methods might be needed for accelerating atmospheric
retrievals.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00787" title="Abstract">arXiv:2311.00787</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2311.00787" title="Download PDF">pdf</a>, <a href="/format/2311.00787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Electronic Stopping Power Predictions by 10 Million Times  with a Combination of Time-Dependent Density Functional Theory and Machine  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Ward%2C+L">Logan Ward</a>, 
<a href="/search/cond-mat?searchtype=author&query=Blaiszik%2C+B">Ben Blaiszik</a>, 
<a href="/search/cond-mat?searchtype=author&query=Lee%2C+C">Cheng-Wei Lee</a>, 
<a href="/search/cond-mat?searchtype=author&query=Martin%2C+T">Troy Martin</a>, 
<a href="/search/cond-mat?searchtype=author&query=Foster%2C+I">Ian Foster</a>, 
<a href="/search/cond-mat?searchtype=author&query=Schleife%2C+A">Andr&#xe9; Schleife</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Knowing the rate at which particle radiation releases energy in a material,
the stopping power, is key to designing nuclear reactors, medical treatments,
semiconductor and quantum materials, and many other technologies. While the
nuclear contribution to stopping power, i.e., elastic scattering between atoms,
is well understood in the literature, the route for gathering data on the
electronic contribution has for decades remained costly and reliant on many
simplifying assumptions, including that materials are isotropic. We establish a
method that combines time-dependent density functional theory (TDDFT) and
machine learning to reduce the time to assess new materials to mere hours on a
supercomputer and provides valuable data on how atomic details influence
electronic stopping. Our approach uses TDDFT to compute the electronic stopping
contributions to stopping power from first principles in several directions and
then machine learning to interpolate to other directions at rates 10 million
times higher. We demonstrate the combined approach in a study of proton
irradiation in aluminum and employ it to predict how the depth of maximum
energy deposition, the "Bragg Peak," varies depending on incident angle -- a
quantity otherwise inaccessible to modelers. The lack of any experimental
information requirement makes our method applicable to most materials, and its
speed makes it a prime candidate for enabling quantum-to-continuum models of
radiation damage. The prospect of reusing valuable TDDFT data for training the
model make our approach appealing for applications in the age of materials data
science.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00811" title="Abstract">arXiv:2311.00811</a> (cross-list from quant-ph) [<a href="/pdf/2311.00811" title="Download PDF">pdf</a>, <a href="/format/2311.00811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A quantum-classical performance separation in nonconvex optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Leng%2C+J">Jiaqi Leng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zheng%2C+Y">Yufan Zheng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wu%2C+X">Xiaodi Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 7 figures. More details of the original Quantum Hamiltonian Descent (QHD) algorithm can be found at <a href="/abs/2303.01471">arXiv:2303.01471</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper, we identify a family of nonconvex continuous optimization
instances, each $d$-dimensional instance with $2^d$ local minima, to
demonstrate a quantum-classical performance separation. Specifically, we prove
that the recently proposed Quantum Hamiltonian Descent (QHD) algorithm [Leng et
al., <a href="/abs/2303.01471">arXiv:2303.01471</a>] is able to solve any $d$-dimensional instance from this
family using $\widetilde{\mathcal{O}}(d^3)$ quantum queries to the function
value and $\widetilde{\mathcal{O}}(d^4)$ additional 1-qubit and 2-qubit
elementary quantum gates. On the other side, a comprehensive empirical study
suggests that representative state-of-the-art classical optimization
algorithms/solvers (including Gurobi) would require a super-polynomial time to
solve such optimization instances.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00844" title="Abstract">arXiv:2311.00844</a> (cross-list from physics.chem-ph) [<a href="/pdf/2311.00844" title="Download PDF">pdf</a>, <a href="/format/2311.00844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Electronic excited states from physically-constrained machine learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Cignoni%2C+E">Edoardo Cignoni</a>, 
<a href="/search/physics?searchtype=author&query=Suman%2C+D">Divya Suman</a>, 
<a href="/search/physics?searchtype=author&query=Nigam%2C+J">Jigyasa Nigam</a>, 
<a href="/search/physics?searchtype=author&query=Cupellini%2C+L">Lorenzo Cupellini</a>, 
<a href="/search/physics?searchtype=author&query=Mennucci%2C+B">Benedetta Mennucci</a>, 
<a href="/search/physics?searchtype=author&query=Ceriotti%2C+M">Michele Ceriotti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Data-driven techniques are increasingly used to replace electronic-structure
calculations of matter. In this context, a relevant question is whether machine
learning (ML) should be applied directly to predict the desired properties or
be combined explicitly with physically-grounded operations. We present an
example of an integrated modeling approach, in which a symmetry-adapted ML
model of an effective Hamiltonian is trained to reproduce electronic
excitations from a quantum-mechanical calculation. The resulting model can make
predictions for molecules that are much larger and more complex than those that
it is trained on, and allows for dramatic computational savings by indirectly
targeting the outputs of well-converged calculations while using a
parameterization corresponding to a minimal atom-centered basis. These results
emphasize the merits of intertwining data-driven techniques with physical
approximations, improving the transferability and interpretability of ML models
without affecting their accuracy and computational efficiency, and providing a
blueprint for developing ML-augmented electronic-structure methods.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00862" title="Abstract">arXiv:2311.00862</a> (cross-list from physics.chem-ph) [<a href="/pdf/2311.00862" title="Download PDF">pdf</a>, <a href="/format/2311.00862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Role of Structural and Conformational Diversity for Machine Learning  Potentials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Shenoy%2C+N">Nikhil Shenoy</a>, 
<a href="/search/physics?searchtype=author&query=Tossou%2C+P">Prudencio Tossou</a>, 
<a href="/search/physics?searchtype=author&query=Noutahi%2C+E">Emmanuel Noutahi</a>, 
<a href="/search/physics?searchtype=author&query=Mary%2C+H">Hadrien Mary</a>, 
<a href="/search/physics?searchtype=author&query=Beaini%2C+D">Dominique Beaini</a>, 
<a href="/search/physics?searchtype=author&query=Ding%2C+J">Jiarui Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023 AI4D3 and AI4S workshops
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the field of Machine Learning Interatomic Potentials (MLIPs),
understanding the intricate relationship between data biases, specifically
conformational and structural diversity, and model generalization is critical
in improving the quality of Quantum Mechanics (QM) data generation efforts. We
investigate these dynamics through two distinct experiments: a fixed budget
one, where the dataset size remains constant, and a fixed molecular set one,
which focuses on fixed structural diversity while varying conformational
diversity. Our results reveal nuanced patterns in generalization metrics.
Notably, for optimal structural and conformational generalization, a careful
balance between structural and conformational diversity is required, but
existing QM datasets do not meet that trade-off. Additionally, our results
highlight the limitation of the MLIP models at generalizing beyond their
training distribution, emphasizing the importance of defining applicability
domain during model deployment. These findings provide valuable insights and
guidelines for QM data generation efforts.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00867" title="Abstract">arXiv:2311.00867</a> (cross-list from eess.AS) [<a href="/pdf/2311.00867" title="Download PDF">pdf</a>, <a href="/format/2311.00867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Disfluency Detection from Untranscribed Speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Romana%2C+A">Amrit Romana</a>, 
<a href="/search/eess?searchtype=author&query=Koishida%2C+K">Kazuhito Koishida</a>, 
<a href="/search/eess?searchtype=author&query=Provost%2C+E+M">Emily Mower Provost</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Speech disfluencies, such as filled pauses or repetitions, are disruptions in
the typical flow of speech. Stuttering is a speech disorder characterized by a
high rate of disfluencies, but all individuals speak with some disfluencies and
the rates of disfluencies may by increased by factors such as cognitive load.
Clinically, automatic disfluency detection may help in treatment planning for
individuals who stutter. Outside of the clinic, automatic disfluency detection
may serve as a pre-processing step to improve natural language understanding in
downstream applications. With this wide range of applications in mind, we
investigate language, acoustic, and multimodal methods for frame-level
automatic disfluency detection and categorization. Each of these methods relies
on audio as an input. First, we evaluate several automatic speech recognition
(ASR) systems in terms of their ability to transcribe disfluencies, measured
using disfluency error rates. We then use these ASR transcripts as input to a
language-based disfluency detection model. We find that disfluency detection
performance is largely limited by the quality of transcripts and alignments. We
find that an acoustic-based approach that does not require transcription as an
intermediate step outperforms the ASR language approach. Finally, we present
multimodal architectures which we find improve disfluency detection performance
over the unimodal approaches. Ultimately, this work introduces novel approaches
for automatic frame-level disfluency and categorization. In the long term, this
will help researchers incorporate automatic disfluency detection into a range
of applications.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00902" title="Abstract">arXiv:2311.00902</a> (cross-list from stat.ML) [<a href="/pdf/2311.00902" title="Download PDF">pdf</a>, <a href="/format/2311.00902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Model Selections of Second-Order Particle Dynamics via  Integrating Gaussian Processes with Low-Dimensional Interacting Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Feng%2C+J">Jinchao Feng</a>, 
<a href="/search/stat?searchtype=author&query=Kulick%2C+C">Charles Kulick</a>, 
<a href="/search/stat?searchtype=author&query=Tang%2C+S">Sui Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, Appendix 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA); Statistics Theory (math.ST)

</div>
<p class="mathjax">In this paper, we focus on the data-driven discovery of a general
second-order particle-based model that contains many state-of-the-art models
for modeling the aggregation and collective behavior of interacting agents of
similar size and body type. This model takes the form of a high-dimensional
system of ordinary differential equations parameterized by two interaction
kernels that appraise the alignment of positions and velocities. We propose a
Gaussian Process-based approach to this problem, where the unknown model
parameters are marginalized by using two independent Gaussian Process (GP)
priors on latent interaction kernels constrained to dynamics and observational
data. This results in a nonparametric model for interacting dynamical systems
that accounts for uncertainty quantification. We also develop acceleration
techniques to improve scalability. Moreover, we perform a theoretical analysis
to interpret the methodology and investigate the conditions under which the
kernels can be recovered. We demonstrate the effectiveness of the proposed
approach on various prototype systems, including the selection of the order of
the systems and the types of interactions. In particular, we present
applications to modeling two real-world fish motion datasets that display
flocking and milling patterns up to 248 dimensions. Despite the use of small
data sets, the GP-based approach learns an effective representation of the
nonlinear dynamics in these spaces and outperforms competitor methods.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00907" title="Abstract">arXiv:2311.00907</a> (cross-list from math.OC) [<a href="/pdf/2311.00907" title="Download PDF">pdf</a>, <a href="/ps/2311.00907" title="Download PostScript">ps</a>, <a href="/format/2311.00907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two novel vector transports for generalized Stiefel manifold with  non-standard metrics and its application to Riemannian conjugate gradient  method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+X">Xuejie Wang</a>, 
<a href="/search/math?searchtype=author&query=Deng%2C+K">Kangkang Deng</a>, 
<a href="/search/math?searchtype=author&query=Peng%2C+Z">Zheng Peng</a>, 
<a href="/search/math?searchtype=author&query=Yan%2C+C">Chengcheng Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">This paper proposes two innovative vector transport operators, leveraging the
Cayley transform, for the generalized Stiefel manifold embedded with a
non-standard inner product. Specifically, it introduces the differentiated
retraction and an approximation of the Cayley transform to the differentiated
matrix exponential. These vector transports are demonstrated to satisfy the
Ring-Wirth non-expansive condition under non-standard metrics while preserving
isometry. Building upon the novel vector transport operators, we extend the
modified Polak-Ribi$\acute{e}$re-Polyak (PRP) conjugate gradient method to the
generalized Stiefel manifold. Under a non-monotone line search condition, we
prove our algorithm globally converges to a stationary point. The efficiency of
the proposed vector transport operators is empirically validated through
numerical experiments involving generalized eigenvalue problems and canonical
correlation analysis.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00908" title="Abstract">arXiv:2311.00908</a> (cross-list from quant-ph) [<a href="/pdf/2311.00908" title="Download PDF">pdf</a>, <a href="/format/2311.00908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Real is Incomputability in Physics?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Trejo%2C+J+M+A">Jos&#xe9; Manuel Ag&#xfc;ero Trejo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Calude%2C+C+S">Cristian S. Calude</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dinneen%2C+M+J">Michael J. Dinneen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Fedorov%2C+A">Arkady Fedorov</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kulikov%2C+A">Anatoly Kulikov</a>, 
<a href="/search/quant-ph?searchtype=author&query=Navarathna%2C+R">Rohit Navarathna</a>, 
<a href="/search/quant-ph?searchtype=author&query=Svozil%2C+K">Karl Svozil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 3 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">A physical system is determined by a finite set of initial conditions and
laws represented by equations. The system is computable if we can solve the
equations in all instances using a ``finite body of mathematical knowledge". In
this case, if the laws of the system can be coded into a computer program, then
given the system's initial conditions of the system, one can compute the
system's evolution. This scenario is tacitly taken for granted. But is this
reasonable? The answer is negative, and a straightforward example is when the
initial conditions or equations use irrational numbers, like Chaitin's Omega
Number: no program can deal with such numbers because of their ``infinity''.
Are there incomputable physical systems? This question has been theoretically
studied in the last 30--40 years. This article presents a class of quantum
protocols producing quantum random bits. Theoretically, we prove that every
infinite sequence generated by these quantum protocols is strongly incomputable
-- no algorithm computing any bit of such a sequence can be proved correct.
This theoretical result is not only more robust than the ones in the
literature: experimental results support and complement it.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00912" title="Abstract">arXiv:2311.00912</a> (cross-list from math.CA) [<a href="/pdf/2311.00912" title="Download PDF">pdf</a>, <a href="/ps/2311.00912" title="Download PostScript">ps</a>, <a href="/format/2311.00912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Whitney-type estimates for convex functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Prymak%2C+A">Andriy Prymak</a>, 
<a href="/search/math?searchtype=author&query=Singh%2C+J">Jaskaran Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Classical Analysis and ODEs (math.CA)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We study Whitney-type estimates for approximation of convex functions in the
uniform norm on various convex multivariate domains while paying a particular
attention to the dependence of the involved constants on the dimension and the
geometry of the domain.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00927" title="Abstract">arXiv:2311.00927</a> (cross-list from stat.ML) [<a href="/pdf/2311.00927" title="Download PDF">pdf</a>, <a href="/format/2311.00927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Counterfactual Distribution Estimation in Multivariate Causal  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Pham%2C+T">Thong Pham</a>, 
<a href="/search/stat?searchtype=author&query=Shimizu%2C+S">Shohei Shimizu</a>, 
<a href="/search/stat?searchtype=author&query=Hino%2C+H">Hideitsu Hino</a>, 
<a href="/search/stat?searchtype=author&query=Le%2C+T">Tam Le</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">We consider the problem of estimating the counterfactual joint distribution
of multiple quantities of interests (e.g., outcomes) in a multivariate causal
model extended from the classical difference-in-difference design. Existing
methods for this task either ignore the correlation structures among dimensions
of the multivariate outcome by considering univariate causal models on each
dimension separately and hence produce incorrect counterfactual distributions,
or poorly scale even for moderate-size datasets when directly dealing with such
multivariate causal model. We propose a method that alleviates both issues
simultaneously by leveraging a robust latent one-dimensional subspace of the
original high-dimension space and exploiting the efficient estimation from the
univariate causal model on such space. Since the construction of the
one-dimensional subspace uses information from all the dimensions, our method
can capture the correlation structures and produce good estimates of the
counterfactual distribution. We demonstrate the advantages of our approach over
existing methods on both synthetic and real-world data.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00944" title="Abstract">arXiv:2311.00944</a> (cross-list from stat.ML) [<a href="/pdf/2311.00944" title="Download PDF">pdf</a>, <a href="/format/2311.00944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Smoothed Gradient Descent Ascent for Federated Minimax  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Shen%2C+W">Wei Shen</a>, 
<a href="/search/stat?searchtype=author&query=Huang%2C+M">Minhui Huang</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+J">Jiawei Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Shen%2C+C">Cong Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">In recent years, federated minimax optimization has attracted growing
interest due to its extensive applications in various machine learning tasks.
While Smoothed Alternative Gradient Descent Ascent (Smoothed-AGDA) has proved
its success in centralized nonconvex minimax optimization, how and whether
smoothing technique could be helpful in federated setting remains unexplored.
In this paper, we propose a new algorithm termed Federated Stochastic Smoothed
Gradient Descent Ascent (FESS-GDA), which utilizes the smoothing technique for
federated minimax optimization. We prove that FESS-GDA can be uniformly used to
solve several classes of federated minimax problems and prove new or better
analytical convergence results for these settings. We showcase the practical
efficiency of FESS-GDA in practical federated learning tasks of training
generative adversarial networks (GANs) and fair classification.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00970" title="Abstract">arXiv:2311.00970</a> (cross-list from eess.IV) [<a href="/pdf/2311.00970" title="Download PDF">pdf</a>, <a href="/format/2311.00970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightweight super resolution network for point cloud geometry  compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+D">Dingquan Li</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+G">Ge Li</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+W">Wen Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures, 2 tables, and 27 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)

</div>
<p class="mathjax">This paper presents an approach for compressing point cloud geometry by
leveraging a lightweight super-resolution network. The proposed method involves
decomposing a point cloud into a base point cloud and the interpolation
patterns for reconstructing the original point cloud. While the base point
cloud can be efficiently compressed using any lossless codec, such as
Geometry-based Point Cloud Compression, a distinct strategy is employed for
handling the interpolation patterns. Rather than directly compressing the
interpolation patterns, a lightweight super-resolution network is utilized to
learn this information through overfitting. Subsequently, the network parameter
is transmitted to assist in point cloud reconstruction at the decoder side.
Notably, our approach differentiates itself from lookup table-based methods,
allowing us to obtain more accurate interpolation patterns by accessing a
broader range of neighboring voxels at an acceptable computational cost.
Experiments on MPEG Cat1 (Solid) and Cat2 datasets demonstrate the remarkable
compression performance achieved by our method.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00975" title="Abstract">arXiv:2311.00975</a> (cross-list from q-bio.MN) [<a href="/pdf/2311.00975" title="Download PDF">pdf</a>, <a href="/format/2311.00975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Learning of Generative Models with Chemical Reaction Network  Ensembles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Poole%2C+W">William Poole</a>, 
<a href="/search/q-bio?searchtype=author&query=Ouldridge%2C+T+E">Thomas E. Ouldridge</a>, 
<a href="/search/q-bio?searchtype=author&query=Gopalkrishnan%2C+M">Manoj Gopalkrishnan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Molecular Networks (q-bio.MN)</span>; Emerging Technologies (cs.ET); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Systems and Control (eess.SY); Biological Physics (physics.bio-ph)

</div>
<p class="mathjax">Can a micron sized sack of interacting molecules autonomously learn an
internal model of a complex and fluctuating environment? We draw insights from
control theory, machine learning theory, chemical reaction network theory, and
statistical physics to develop a general architecture whereby a broad class of
chemical systems can autonomously learn complex distributions. Our construction
takes the form of a chemical implementation of machine learning's optimization
workhorse: gradient descent on the relative entropy cost function. We show how
this method can be applied to optimize any detailed balanced chemical reaction
network and that the construction is capable of using hidden units to learn
complex distributions. This result is then recast as a form of integral
feedback control. Finally, due to our use of an explicit physical model of
learning, we are able to derive thermodynamic costs and trade-offs associated
to this process.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00996" title="Abstract">arXiv:2311.00996</a> (cross-list from eess.IV) [<a href="/pdf/2311.00996" title="Download PDF">pdf</a>, <a href="/format/2311.00996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VCISR: Blind Single Image Super-Resolution with Video Compression  Synthetic Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+B">Boyang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+B">Bowen Liu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+S">Shiyu Liu</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+F">Fengyu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In the blind single image super-resolution (SISR) task, existing works have
been successful in restoring image-level unknown degradations. However, when a
single video frame becomes the input, these works usually fail to address
degradations caused by video compression, such as mosquito noise, ringing,
blockiness, and staircase noise. In this work, we for the first time, present a
video compression-based degradation model to synthesize low-resolution image
data in the blind SISR task. Our proposed image synthesizing method is widely
applicable to existing image datasets, so that a single degraded image can
contain distortions caused by the lossy video compression algorithms. This
overcomes the leak of feature diversity in video data and thus retains the
training efficiency. By introducing video coding artifacts to SISR degradation
models, neural networks can super-resolve images with the ability to restore
video compression degradations, and achieve better results on restoring generic
distortions caused by image compression as well. Our proposed approach achieves
superior performance in SOTA no-reference Image Quality Assessment, and shows
better visual quality on various datasets. In addition, we evaluate the SISR
neural network trained with our degradation model on video super-resolution
(VSR) datasets. Compared to architectures specifically designed for the VSR
purpose, our method exhibits similar or better performance, evidencing that the
presented strategy on infusing video-based degradation is generalizable to
address more complicated compression artifacts even without temporal cues.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01028" title="Abstract">arXiv:2311.01028</a> (cross-list from quant-ph) [<a href="/pdf/2311.01028" title="Download PDF">pdf</a>, <a href="/format/2311.01028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonnegative/Binary Matrix Factorization for Image Classification using  Quantum Annealing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Asaoka%2C+H">Hinako Asaoka</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kudo%2C+K">Kazue Kudo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sci. Rep. 13, 16527 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Classical computing has borne witness to the development of machine learning.
The integration of quantum technology into this mix will lead to unimaginable
benefits and be regarded as a giant leap forward in mankind's ability to
compute. Demonstrating the benefits of this integration now becomes essential.
With the advance of quantum computing, several machine-learning techniques have
been proposed that use quantum annealing. In this study, we implement a matrix
factorization method using quantum annealing for image classification and
compare the performance with traditional machine-learning methods.
Nonnegative/binary matrix factorization (NBMF) was originally introduced as a
generative model, and we propose a multiclass classification model as an
application. We extract the features of handwritten digit images using NBMF and
apply them to solve the classification problem. Our findings show that when the
amount of data, features, and epochs is small, the accuracy of models trained
by NBMF is superior to classical machine-learning methods, such as neural
networks. Moreover, we found that training models using a quantum annealing
solver significantly reduces computation time. Under certain conditions, there
is a benefit to using quantum annealing technology with machine learning.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01035" title="Abstract">arXiv:2311.01035</a> (cross-list from eess.SP) [<a href="/pdf/2311.01035" title="Download PDF">pdf</a>, <a href="/format/2311.01035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mathematical Properties of the Zadoff-Chu Sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gregoratti%2C+D">David Gregoratti</a>, 
<a href="/search/eess?searchtype=author&query=Arteaga%2C+X">Xavier Arteaga</a>, 
<a href="/search/eess?searchtype=author&query=Broquetas%2C+J">Joaquim Broquetas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 5 figures, not submitted for publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT); Number Theory (math.NT)

</div>
<p class="mathjax">This paper is a compilation of well-known results about Zadoff-Chu sequences,
including all proofs with a consistent mathematical notation, for easy
reference. Moreover, for a Zadoff-Chu sequence $x_u[n]$ of prime length
$N_{\text{ZC}}$ and root index $u$, a formula is derived that allows computing
the first term (frequency zero) of its discrete Fourier transform, $X_u[0]$,
with constant complexity independent of the sequence length, as opposed to
accumulating all its $N_{\text{ZC}}$ terms. The formula stems from a famous
result in analytic number theory and is an interesting complement to the fact
that the discrete Fourier transform of a Zadoff-Chu sequence is itself a
Zadoff-Chu sequence whose terms are scaled by $X_u[0]$. Finally, the paper
concludes with a brief analysis of time-continuous signals derived from
Zadoff-Chu sequences, especially those obtained by OFDM-modulating a Zadoff-Chu
sequence.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01052" title="Abstract">arXiv:2311.01052</a> (cross-list from stat.ML) [<a href="/pdf/2311.01052" title="Download PDF">pdf</a>, <a href="/format/2311.01052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resilient Multiple Choice Learning: A learned scoring scheme with  application to audio scene analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Letzelter%2C+V">Victor Letzelter</a> (S2A, IDS), 
<a href="/search/stat?searchtype=author&query=Fontaine%2C+M">Mathieu Fontaine</a> (S2A, IDS), 
<a href="/search/stat?searchtype=author&query=Chen%2C+M">Micka&#xeb;l Chen</a>, 
<a href="/search/stat?searchtype=author&query=P%C3%A9rez%2C+P">Patrick P&#xe9;rez</a>, 
<a href="/search/stat?searchtype=author&query=Richard%2C+G">Gael Richard</a> (S2A, IDS), 
<a href="/search/stat?searchtype=author&query=Essid%2C+S">Slim Essid</a> (IDS, S2A)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Advances in neural information processing systems, Dec 2023, New
  Orleans, United States
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce Resilient Multiple Choice Learning (rMCL), an extension of the
MCL approach for conditional distribution estimation in regression settings
where multiple targets may be sampled for each training input. Multiple Choice
Learning is a simple framework to tackle multimodal density estimation, using
the Winner-Takes-All (WTA) loss for a set of hypotheses. In regression
settings, the existing MCL variants focus on merging the hypotheses, thereby
eventually sacrificing the diversity of the predictions. In contrast, our
method relies on a novel learned scoring scheme underpinned by a mathematical
framework based on Voronoi tessellations of the output space, from which we can
derive a probabilistic interpretation. After empirically validating rMCL with
experiments on synthetic data, we further assess its merits on the sound source
localization problem, demonstrating its practical usefulness and the relevance
of its interpretation.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01066" title="Abstract">arXiv:2311.01066</a> (cross-list from eess.IV) [<a href="/pdf/2311.01066" title="Download PDF">pdf</a>, <a href="/format/2311.01066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Multimodal Information Bottleneck for Multimodality  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fang%2C+Y">Yingying Fang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+S">Shuang Wu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+S">Sheng Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+C">Chaoyan Huang</a>, 
<a href="/search/eess?searchtype=author&query=Zeng%2C+T">Tieyong Zeng</a>, 
<a href="/search/eess?searchtype=author&query=Xing%2C+X">Xiaodan Xing</a>, 
<a href="/search/eess?searchtype=author&query=Walsh%2C+S">Simon Walsh</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+G">Guang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Effectively leveraging multimodal data such as various images, laboratory
tests and clinical information is gaining traction in a variety of AI-based
medical diagnosis and prognosis tasks. Most existing multi-modal techniques
only focus on enhancing their performance by leveraging the differences or
shared features from various modalities and fusing feature across different
modalities. These approaches are generally not optimal for clinical settings,
which pose the additional challenges of limited training data, as well as being
rife with redundant data or noisy modality channels, leading to subpar
performance. To address this gap, we study the robustness of existing methods
to data redundancy and noise and propose a generalized dynamic multimodal
information bottleneck framework for attaining a robust fused feature
representation. Specifically, our information bottleneck module serves to
filter out the task-irrelevant information and noises in the fused feature, and
we further introduce a sufficiency loss to prevent dropping of task-relevant
information, thus explicitly preserving the sufficiency of prediction
information in the distilled feature. We validate our model on an in-house and
a public COVID19 dataset for mortality prediction as well as two public
biomedical datasets for diagnostic tasks. Extensive experiments show that our
method surpasses the state-of-the-art and is significantly more robust, being
the only method to remain performance when large-scale noisy channels exist.
Our code is publicly available at https://github.com/BII-wushuang/DMIB.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01119" title="Abstract">arXiv:2311.01119</a> (cross-list from math.AP) [<a href="/pdf/2311.01119" title="Download PDF">pdf</a>, <a href="/format/2311.01119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pattern formation in vector-valued phase fields under convex constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Vantzos%2C+O">Orestis Vantzos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 10 figures. Presented in Numerical Analysis and Scientific Computation with Applications (NASCA) 2023, in Athens Greece
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Graphics (cs.GR); Mathematical Physics (math-ph); Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this work, a new class of vector-valued phase field models is presented,
where the values of the phase parameters are constrained by a convex set. The
generated phase fields feature the partition of the domain into patches of
distinct phases, separated by thin interfaces. The configuration and dynamics
of the phases are directly dependent on the geometry and topology of the convex
constraint set, which makes it possible to engineer models of this type that
exhibit desired interactions and patterns. An efficient proximal gradient
solver is introduced to study numerically their L2-gradient flow, i.e.~the
associated Allen-Cahn-type equation. Applying the solver together with various
choices for the convex constraint set, yields numerical results that feature a
number of patterns observed in nature and engineering, such as multiphase
grains in metal alloys, traveling waves in reaction-diffusion systems, and
vortices in magnetic materials.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01165" title="Abstract">arXiv:2311.01165</a> (cross-list from math.OC) [<a href="/pdf/2311.01165" title="Download PDF">pdf</a>, <a href="/ps/2311.01165" title="Download PostScript">ps</a>, <a href="/format/2311.01165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chandrasekhar-based maximum correntropy Kalman filtering with the  adaptive kernel size selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kulikova%2C+M">Maria Kulikova</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Automatic Control, 65(2): 741-748, 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">This technical note is aimed to derive the Chandrasekhar-type recursion for
the maximum correntropy criterion (MCC) Kalman filtering (KF). For the
classical KF, the first Chandrasekhar difference equation was proposed at the
beginning of 1970s. This is the alternative to the traditionally used Riccati
recursion and it yields the so-called fast implementations known as the
Morf-Sidhu-Kailath-Sayed KF algorithms. They are proved to be computationally
cheap because of propagating the matrices of a smaller size than $n \times n$
error covariance matrix in the Riccati recursion. The problem of deriving the
Chandrasekhar-type recursion within the MCC estimation methodology has never
been raised yet in engineering literature. In this technical note, we do the
first step and derive the Chandrasekhar MCC-KF estimators for the case of
adaptive kernel size selection strategy, which implies a constant scalar
adjusting weight. Numerical examples substantiate a practical feasibility of
the newly suggested MCC-KF implementations and correctness of the presented
theoretical derivations.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01194" title="Abstract">arXiv:2311.01194</a> (cross-list from stat.AP) [<a href="/pdf/2311.01194" title="Download PDF">pdf</a>, <a href="/format/2311.01194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Statistical Approach for Improving HVOF Coating: Predictive Modelling  of Critical Variables using Generalized Linear Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ranetbauer%2C+W">Wolfgang Ranetbauer</a>, 
<a href="/search/stat?searchtype=author&query=Hubmer%2C+S">Simon Hubmer</a>, 
<a href="/search/stat?searchtype=author&query=Hambrock%2C+C">Carina Hambrock</a>, 
<a href="/search/stat?searchtype=author&query=Ramlau%2C+R">Ronny Ramlau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Numerical Analysis (math.NA); Applied Physics (physics.app-ph)

</div>
<p class="mathjax">Thermal spray coating is a critical process in many industries, involving the
application of coatings to surfaces to enhance their functionality. This paper
proposes a framework for modelling and predicting critical target variables in
thermal spray coating processes, based on the application of statistical design
of experiments (DoE) and the modelling of the data using generalized linear
models (GLMs) and gamma regression. Experimental data obtained from thermal
spray coating trials are used to validate the presented approach, demonstrating
that it is able to accurately model and predict critical target variables and
their intricate relationships. As such, the framework has significant potential
for the optimization of thermal spray coating processes, and can contribute to
the development of more efficient and effective coating technologies in various
industries.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01216" title="Abstract">arXiv:2311.01216</a> (cross-list from math.OC) [<a href="/pdf/2311.01216" title="Download PDF">pdf</a>, <a href="/format/2311.01216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergent plug-and-play with proximal denoiser and unconstrained  regularization parameter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hurault%2C+S">Samuel Hurault</a>, 
<a href="/search/math?searchtype=author&query=Chambolle%2C+A">Antonin Chambolle</a>, 
<a href="/search/math?searchtype=author&query=Leclaire%2C+A">Arthur Leclaire</a>, 
<a href="/search/math?searchtype=author&query=Papadakis%2C+N">Nicolas Papadakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2301.13731">arXiv:2301.13731</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this work, we present new proofs of convergence for Plug-and-Play (PnP)
algorithms. PnP methods are efficient iterative algorithms for solving image
inverse problems where regularization is performed by plugging a pre-trained
denoiser in a proximal algorithm, such as Proximal Gradient Descent (PGD) or
Douglas-Rachford Splitting (DRS). Recent research has explored convergence by
incorporating a denoiser that writes exactly as a proximal operator. However,
the corresponding PnP algorithm has then to be run with stepsize equal to $1$.
The stepsize condition for nonconvex convergence of the proximal algorithm in
use then translates to restrictive conditions on the regularization parameter
of the inverse problem. This can severely degrade the restoration capacity of
the algorithm. In this paper, we present two remedies for this limitation.
First, we provide a novel convergence proof for PnP-DRS that does not impose
any restrictions on the regularization parameter. Second, we examine a relaxed
version of the PGD algorithm that converges across a broader range of
regularization parameters. Our experimental study, conducted on deblurring and
super-resolution experiments, demonstrate that both of these solutions enhance
the accuracy of image restoration.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01241" title="Abstract">arXiv:2311.01241</a> (cross-list from eess.IV) [<a href="/pdf/2311.01241" title="Download PDF">pdf</a>, <a href="/format/2311.01241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Deep Learning Image Super-Resolution for Iris Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ribeiro%2C+E">Eduardo Ribeiro</a>, 
<a href="/search/eess?searchtype=author&query=Uhl%2C+A">Andreas Uhl</a>, 
<a href="/search/eess?searchtype=author&query=Alonso-Fernandez%2C+F">Fernando Alonso-Fernandez</a>, 
<a href="/search/eess?searchtype=author&query=Farrugia%2C+R+A">Reuben A. Farrugia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at Proc. 25th European Signal Processing Conference, EUSIPCO 2017
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this work we test the ability of deep learning methods to provide an
end-to-end mapping between low and high resolution images applying it to the
iris recognition problem. Here, we propose the use of two deep learning
single-image super-resolution approaches: Stacked Auto-Encoders (SAE) and
Convolutional Neural Networks (CNN) with the most possible lightweight
structure to achieve fast speed, preserve local information and reduce
artifacts at the same time. We validate the methods with a database of 1.872
near-infrared iris images with quality assessment and recognition experiments
showing the superiority of deep learning approaches over the compared
algorithms.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01242" title="Abstract">arXiv:2311.01242</a> (cross-list from quant-ph) [<a href="/pdf/2311.01242" title="Download PDF">pdf</a>, <a href="/format/2311.01242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pushing the Limits of Quantum Computing for Simulating PFAS Chemistry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Dimitrov%2C+E">Emil Dimitrov</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sanchez-Sanz%2C+G">Goar Sanchez-Sanz</a>, 
<a href="/search/quant-ph?searchtype=author&query=Nelson%2C+J">James Nelson</a>, 
<a href="/search/quant-ph?searchtype=author&query=O%27Riordan%2C+L">Lee O&#x27;Riordan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Doyle%2C+M">Myles Doyle</a>, 
<a href="/search/quant-ph?searchtype=author&query=Courtney%2C+S">Sean Courtney</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kannan%2C+V">Venkatesh Kannan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Naseri%2C+H">Hassan Naseri</a>, 
<a href="/search/quant-ph?searchtype=author&query=Garcia%2C+A+G">Alberto Garcia Garcia</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tricker%2C+J">James Tricker</a>, 
<a href="/search/quant-ph?searchtype=author&query=Faraggi%2C+M">Marisa Faraggi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Goings%2C+J">Joshua Goings</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhao%2C+L">Luning Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Accurate and scalable methods for computational quantum chemistry can
accelerate research and development in many fields, ranging from drug discovery
to advanced material design. Solving the electronic Schrodinger equation is the
core problem of computational chemistry. However, the combinatorial complexity
of this problem makes it intractable to find exact solutions, except for very
small systems. The idea of quantum computing originated from this computational
challenge in simulating quantum-mechanics. We propose an end-to-end quantum
chemistry pipeline based on the variational quantum eigensolver (VQE) algorithm
and integrated with both HPC-based simulators and a trapped-ion quantum
computer. Our platform orchestrates hundreds of simulation jobs on compute
resources to efficiently complete a set of ab initio chemistry experiments with
a wide range of parameterization. Per- and poly-fluoroalkyl substances (PFAS)
are a large family of human-made chemicals that pose a major environmental and
health issue globally. Our simulations includes breaking a Carbon-Fluorine bond
in trifluoroacetic acid (TFA), a common PFAS chemical. This is a common pathway
towards destruction and removal of PFAS. Molecules are modeled on both a
quantum simulator and a trapped-ion quantum computer, specifically IonQ Aria.
Using basic error mitigation techniques, the 11-qubit TFA model (56 entangling
gates) on IonQ Aria yields near-quantitative results with milli-Hartree
accuracy. Our novel results show the current state and future projections for
quantum computing in solving the electronic structure problem, push the
boundaries for the VQE algorithm and quantum computers, and facilitates
development of quantum chemistry workflows.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01260" title="Abstract">arXiv:2311.01260</a> (cross-list from eess.AS) [<a href="/pdf/2311.01260" title="Download PDF">pdf</a>, <a href="/format/2311.01260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expressive TTS Driven by Natural Language Prompts Using Few Human  Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Hanglei Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+Y">Yiwei Guo</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+S">Sen Liu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xie Chen</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+K">Kai Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages,3 figures, submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Sound (cs.SD)

</div>
<p class="mathjax">Expressive text-to-speech (TTS) aims to synthesize speeches with human-like
tones, moods, or even artistic attributes. Recent advancements in expressive
TTS empower users with the ability to directly control synthesis style through
natural language prompts. However, these methods often require excessive
training with a significant amount of style-annotated data, which can be
challenging to acquire. Moreover, they may have limited adaptability due to
fixed style annotations. In this work, we present FreeStyleTTS (FS-TTS), a
controllable expressive TTS model with minimal human annotations. Our approach
utilizes a large language model (LLM) to transform expressive TTS into a style
retrieval task. The LLM selects the best-matching style references from
annotated utterances based on external style prompts, which can be raw input
text or natural language style descriptions. The selected reference guides the
TTS pipeline to synthesize speeches with the intended style. This innovative
approach provides flexible, versatile, and precise style control with minimal
human workload. Experiments on a Mandarin storytelling corpus demonstrate
FS-TTS's proficiency in leveraging LLM's semantic inference ability to retrieve
desired styles from either input text or user-defined descriptions. This
results in synthetic speeches that are closely aligned with the specified
styles.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01308" title="Abstract">arXiv:2311.01308</a> (cross-list from eess.IV) [<a href="/pdf/2311.01308" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid-Fusion Transformer for Multisequence MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cho%2C+J">Jihoon Cho</a>, 
<a href="/search/eess?searchtype=author&query=Park%2C+J">Jinah Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Medical segmentation has grown exponentially through the advent of a fully
convolutional network (FCN), and we have now reached a turning point through
the success of Transformer. However, the different characteristics of the
modality have not been fully integrated into Transformer for medical
segmentation. In this work, we propose the novel hybrid fusion Transformer
(HFTrans) for multisequence MRI image segmentation. We take advantage of the
differences among multimodal MRI sequences and utilize the Transformer layers
to integrate the features extracted from each modality as well as the features
of the early fused modalities. We validate the effectiveness of our
hybrid-fusion method in three-dimensional (3D) medical segmentation.
Experiments on two public datasets, BraTS2020 and MRBrainS18, show that the
proposed method outperforms previous state-of-the-art methods on the task of
brain tumor segmentation and brain structure segmentation.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01328" title="Abstract">arXiv:2311.01328</a> (cross-list from quant-ph) [<a href="/pdf/2311.01328" title="Download PDF">pdf</a>, <a href="/format/2311.01328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analog information decoding of bosonic quantum LDPC codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Berent%2C+L">Lucas Berent</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hillmann%2C+T">Timo Hillmann</a>, 
<a href="/search/quant-ph?searchtype=author&query=Eisert%2C+J">Jens Eisert</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wille%2C+R">Robert Wille</a>, 
<a href="/search/quant-ph?searchtype=author&query=Roffe%2C+J">Joschka Roffe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Quantum error correction is crucial for scalable quantum information
processing applications. Traditional discrete-variable quantum codes that use
multiple two-level systems to encode logical information can be
hardware-intensive. An alternative approach is provided by bosonic codes, which
use the infinite-dimensional Hilbert space of harmonic oscillators to encode
quantum information. Two promising features of bosonic codes are that syndrome
measurements are natively analog and that they can be concatenated with
discrete-variable codes. In this work, we propose novel decoding methods that
explicitly exploit the analog syndrome information obtained from the bosonic
qubit readout in a concatenated architecture. Our methods are versatile and can
be generally applied to any bosonic code concatenated with a quantum
low-density parity-check (QLDPC) code. Furthermore, we introduce the concept of
quasi-single-shot protocols as a novel approach that significantly reduces the
number of repeated syndrome measurements required when decoding under
phenomenological noise. To realize the protocol, we present a first
implementation of time-domain decoding with the overlapping window method for
general QLDPC codes, and a novel analog single-shot decoding method. Our
results lay the foundation for general decoding algorithms using analog
information and demonstrate promising results in the direction of
fault-tolerant quantum computation with concatenated bosonic-QLDPC codes.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01336" title="Abstract">arXiv:2311.01336</a> (cross-list from math.ST) [<a href="/pdf/2311.01336" title="Download PDF">pdf</a>, <a href="/format/2311.01336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Covariance estimation using h-statistics in Monte Carlo and Multilevel  Monte Carlo methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shivanand%2C+S+K">Sharana Kumar Shivanand</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We present novel Monte Carlo (MC) and multilevel Monte Carlo (MLMC) methods
for determining the unbiased covariance of random variables using h-statistics.
The advantage of this procedure lies in the unbiased construction of the
estimator's mean square error in a closed form. This is in contrast to the
conventional MC and MLMC covariance estimators, which are based on biased mean
square errors defined solely by upper bounds, particularly within the MLMC.
Finally, the numerical results of the algorithms are demonstrated by estimating
the covariance of the stochastic response of a simple 1D stochastic elliptic
PDE such as Poisson's model.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01352" title="Abstract">arXiv:2311.01352</a> (cross-list from eess.IV) [<a href="/pdf/2311.01352" title="Download PDF">pdf</a>, <a href="/format/2311.01352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep learning based Image Compression for Microscopy Images: An  Empirical Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Yu Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Sollman%2C+J">Jan Sollman</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jianxu Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">With the fast development of modern microscopes and bioimaging techniques, an
unprecedentedly large amount of imaging data are being generated, stored,
analyzed, and even shared through networks. The size of the data poses great
challenges for current data infrastructure. One common way to reduce the data
size is by image compression. This present study analyzes classic and deep
learning based image compression methods, and their impact on deep learning
based image processing models. Deep learning based label-free prediction models
(i.e., predicting fluorescent images from bright field images) are used as an
example application for comparison and analysis. Effective image compression
methods could help reduce the data size significantly without losing necessary
information, and therefore reduce the burden on data management infrastructure
and permit fast transmission through the network for data sharing or cloud
computing. To compress images in such a wanted way, multiple classical lossy
image compression techniques are compared to several AI-based compression
models provided by and trained with the CompressAI toolbox using python. These
different compression techniques are compared in compression ratio, multiple
image similarity measures and, most importantly, the prediction accuracy from
label-free models on compressed images. We found that AI-based compression
techniques largely outperform the classic ones and will minimally affect the
downstream label-free task in 2D cases. In the end, we hope the present study
could shed light on the potential of deep learning based image compression and
the impact of image compression on downstream deep learning based image
analysis models.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01356" title="Abstract">arXiv:2311.01356</a> (cross-list from stat.ML) [<a href="/pdf/2311.01356" title="Download PDF">pdf</a>, <a href="/format/2311.01356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Lipschitz constant of random neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Geuchen%2C+P">Paul Geuchen</a>, 
<a href="/search/stat?searchtype=author&query=Heindl%2C+T">Thomas Heindl</a>, 
<a href="/search/stat?searchtype=author&query=St%C3%B6ger%2C+D">Dominik St&#xf6;ger</a>, 
<a href="/search/stat?searchtype=author&query=Voigtlaender%2C+F">Felix Voigtlaender</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Probability (math.PR)

</div>
<p class="mathjax">Empirical studies have widely demonstrated that neural networks are highly
sensitive to small, adversarial perturbations of the input. The worst-case
robustness against these so-called adversarial examples can be quantified by
the Lipschitz constant of the neural network. However, only few theoretical
results regarding this quantity exist in the literature. In this paper, we
initiate the study of the Lipschitz constant of random ReLU neural networks,
i.e., neural networks whose weights are chosen at random and which employ the
ReLU activation function. For shallow neural networks, we characterize the
Lipschitz constant up to an absolute numerical constant. Moreover, we extend
our analysis to deep neural networks of sufficiently large width where we prove
upper and lower bounds for the Lipschitz constant. These bounds match up to a
logarithmic factor that depends on the depth.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01367" title="Abstract">arXiv:2311.01367</a> (cross-list from eess.SP) [<a href="/pdf/2311.01367" title="Download PDF">pdf</a>, <a href="/format/2311.01367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Respiratory Anomaly Detection using Reflected Infrared Light-wave  Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Islam%2C+M+Z">Md Zobaer Islam</a>, 
<a href="/search/eess?searchtype=author&query=Martin%2C+B">Brenden Martin</a>, 
<a href="/search/eess?searchtype=author&query=Gotcher%2C+C">Carly Gotcher</a>, 
<a href="/search/eess?searchtype=author&query=Martinez%2C+T">Tyler Martinez</a>, 
<a href="/search/eess?searchtype=author&query=O%27Hara%2C+J+F">John F. O&#x27;Hara</a>, 
<a href="/search/eess?searchtype=author&query=Ekin%2C+S">Sabit Ekin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, submitted to IEEE conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this study, we present a non-contact respiratory anomaly detection method
using incoherent light-wave signals reflected from the chest of a mechanical
robot that can breathe like human beings. In comparison to existing radar and
camera-based sensing systems for vitals monitoring, this technology uses only a
low-cost ubiquitous light source (e.g., infrared light emitting diode) and
sensor (e.g., photodetector). This light-wave sensing (LWS) system recognizes
different breathing anomalies from the variations of light intensity reflected
from the chest of the robot within a 0.5m-1.5m range. The anomaly detection
model demonstrates up to 96.6% average accuracy in classifying 7 different
types of breathing data using machine learning. The model can also detect
faulty data collected by the system that does not contain breathing
information. The developed system can be utilized at home or healthcare
facilities as a smart, non-contact and discreet respiration monitoring method.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01388" title="Abstract">arXiv:2311.01388</a> (cross-list from stat.ML) [<a href="/pdf/2311.01388" title="Download PDF">pdf</a>, <a href="/format/2311.01388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-series Generation by Contrastive Imitation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Jarrett%2C+D">Daniel Jarrett</a>, 
<a href="/search/stat?searchtype=author&query=Bica%2C+I">Ioana Bica</a>, 
<a href="/search/stat?searchtype=author&query=van+der+Schaar%2C+M">Mihaela van der Schaar</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proc. 35th International Conference on Neural Information
  Processing Systems (NeurIPS 2021)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Consider learning a generative model for time-series data. The sequential
setting poses a unique challenge: Not only should the generator capture the
conditional dynamics of (stepwise) transitions, but its open-loop rollouts
should also preserve the joint distribution of (multi-step) trajectories. On
one hand, autoregressive models trained by MLE allow learning and computing
explicit transition distributions, but suffer from compounding error during
rollouts. On the other hand, adversarial models based on GAN training alleviate
such exposure bias, but transitions are implicit and hard to assess. In this
work, we study a generative framework that seeks to combine the strengths of
both: Motivated by a moment-matching objective to mitigate compounding error,
we optimize a local (but forward-looking) transition policy, where the
reinforcement signal is provided by a global (but stepwise-decomposable) energy
model trained by contrastive estimation. At training, the two components are
learned cooperatively, avoiding the instabilities typical of adversarial
objectives. At inference, the learned policy serves as the generator for
iterative sampling, and the learned energy serves as a trajectory-level measure
for evaluating sample quality. By expressly training a policy to imitate
sequential behavior of time-series features in a dataset, this approach
embodies "generation by imitation". Theoretically, we illustrate the
correctness of this formulation and the consistency of the algorithm.
Empirically, we evaluate its ability to generate predictively useful samples
from real-world datasets, verifying that it performs at the standard of
existing benchmarks.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01404" title="Abstract">arXiv:2311.01404</a> (cross-list from math.OC) [<a href="/pdf/2311.01404" title="Download PDF">pdf</a>, <a href="/ps/2311.01404" title="Download PostScript">ps</a>, <a href="/format/2311.01404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Normalizing flows as approximations of optimal transport maps via  linear-control neural ODEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Scagliotti%2C+A">Alessandro Scagliotti</a>, 
<a href="/search/math?searchtype=author&query=Farinelli%2C+S">Sara Farinelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The term "Normalizing Flows" is related to the task of constructing
invertible transport maps between probability measures by means of deep neural
networks. In this paper, we consider the problem of recovering the
$W_2$-optimal transport map $T$ between absolutely continuous measures
$\mu,\nu\in\mathcal{P}(\mathbb{R}^n)$ as the flow of a linear-control neural
ODE. We first show that, under suitable assumptions on $\mu,\nu$ and on the
controlled vector fields, the optimal transport map is contained in the
$C^0_c$-closure of the flows generated by the system. Assuming that discrete
approximations $\mu_N,\nu_N$ of the original measures $\mu,\nu$ are available,
we use a discrete optimal coupling $\gamma_N$ to define an optimal control
problem. With a $\Gamma$-convergence argument, we prove that its solutions
correspond to flows that approximate the optimal transport map $T$. Finally,
taking advantage of the Pontryagin Maximum Principle, we propose an iterative
numerical scheme for the resolution of the optimal control problem, resulting
in an algorithm for the practical computation of the approximated optimal
transport map.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01425" title="Abstract">arXiv:2311.01425</a> (cross-list from eess.IV) [<a href="/pdf/2311.01425" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Deep Learning Techniques for Glaucoma Detection: A  Comprehensive Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Soofi%2C+A+A">Aized Amin Soofi</a>, 
<a href="/search/eess?searchtype=author&query=Fazal-e-Amin">Fazal-e-Amin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Glaucoma is one of the primary causes of vision loss around the world,
necessitating accurate and efficient detection methods. Traditional manual
detection approaches have limitations in terms of cost, time, and subjectivity.
Recent developments in deep learning approaches demonstrate potential in
automating glaucoma detection by detecting relevant features from retinal
fundus images. This article provides a comprehensive overview of cutting-edge
deep learning methods used for the segmentation, classification, and detection
of glaucoma. By analyzing recent studies, the effectiveness and limitations of
these techniques are evaluated, key findings are highlighted, and potential
areas for further research are identified. The use of deep learning algorithms
may significantly improve the efficacy, usefulness, and accuracy of glaucoma
detection. The findings from this research contribute to the ongoing
advancements in automated glaucoma detection and have implications for
improving patient outcomes and reducing the global burden of glaucoma.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01453" title="Abstract">arXiv:2311.01453</a> (cross-list from stat.ML) [<a href="/pdf/2311.01453" title="Download PDF">pdf</a>, <a href="/format/2311.01453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PPI++: Efficient Prediction-Powered Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Angelopoulos%2C+A+N">Anastasios N. Angelopoulos</a>, 
<a href="/search/stat?searchtype=author&query=Duchi%2C+J+C">John C. Duchi</a>, 
<a href="/search/stat?searchtype=author&query=Zrnic%2C+T">Tijana Zrnic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code available at <a href="https://github.com/aangelopoulos/ppi_py">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">We present PPI++: a computationally lightweight methodology for estimation
and inference based on a small labeled dataset and a typically much larger
dataset of machine-learning predictions. The methods automatically adapt to the
quality of available predictions, yielding easy-to-compute confidence sets --
for parameters of any dimensionality -- that always improve on classical
intervals using only the labeled data. PPI++ builds on prediction-powered
inference (PPI), which targets the same problem setting, improving its
computational and statistical efficiency. Real and synthetic experiments
demonstrate the benefits of the proposed adaptations.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Fri,  3 Nov 23</h3>
<dl>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/math/0602575" title="Abstract">arXiv:math/0602575</a> (replaced) [<a href="/pdf/math/0602575" title="Download PDF">pdf</a>, <a href="/ps/math/0602575" title="Download PostScript">ps</a>, <a href="/format/math/0602575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matrix-Forest Theorems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chebotarev%2C+P">Pavel Chebotarev</a>, 
<a href="/search/math?searchtype=author&query=Shamis%2C+E">Elena Shamis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Unpublished manuscript (1994-1997); 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Rings and Algebras (math.RA)

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1005.0513" title="Abstract">arXiv:1005.0513</a> (replaced) [<a href="/pdf/1005.0513" title="Download PDF">pdf</a>, <a href="/format/1005.0513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local algorithms for the maximum flow and minimum cut in bounded-degree  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cs%C3%B3ka%2C+E">Endre Cs&#xf3;ka</a>, 
<a href="/search/cs?searchtype=author&query=Pongr%C3%A1cz%2C+A">Andr&#xe1;s Pongr&#xe1;cz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1202.1565" title="Abstract">arXiv:1202.1565</a> (replaced) [<a href="/pdf/1202.1565" title="Download PDF">pdf</a>, <a href="/format/1202.1565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variants of local algorithms on sparse graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cs%C3%B3ka%2C+E">Endre Cs&#xf3;ka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1806.11277" title="Abstract">arXiv:1806.11277</a> (replaced) [<a href="/pdf/1806.11277" title="Download PDF">pdf</a>, <a href="/ps/1806.11277" title="Download PostScript">ps</a>, <a href="/format/1806.11277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A hybrid shifted Laplacian multigrid and domain decomposition  preconditioner for the elastic Helmholtz equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Treister%2C+E">Eran Treister</a>, 
<a href="/search/cs?searchtype=author&query=Yovel%2C+R">Rachel Yovel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Journal of Computational Physics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1901.00156" title="Abstract">arXiv:1901.00156</a> (replaced) [<a href="/pdf/1901.00156" title="Download PDF">pdf</a>, <a href="/ps/1901.00156" title="Download PostScript">ps</a>, <a href="/format/1901.00156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cluster Editing with Vertex Splitting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abu-Khzam%2C+F+N">Faisal N. Abu-Khzam</a>, 
<a href="/search/cs?searchtype=author&query=Arrighi%2C+E">Emmanuel Arrighi</a>, 
<a href="/search/cs?searchtype=author&query=Bentert%2C+M">Matthias Bentert</a>, 
<a href="/search/cs?searchtype=author&query=Drange%2C+P+G">P&#xe5;l Gr&#xf8;n&#xe5;s Drange</a>, 
<a href="/search/cs?searchtype=author&query=Egan%2C+J">Judith Egan</a>, 
<a href="/search/cs?searchtype=author&query=Gaspers%2C+S">Serge Gaspers</a>, 
<a href="/search/cs?searchtype=author&query=Shaw%2C+A">Alexis Shaw</a>, 
<a href="/search/cs?searchtype=author&query=Shaw%2C+P">Peter Shaw</a>, 
<a href="/search/cs?searchtype=author&query=Sullivan%2C+B+D">Blair D. Sullivan</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+P">Petra Wolf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2002.07897" title="Abstract">arXiv:2002.07897</a> (replaced) [<a href="/pdf/2002.07897" title="Download PDF">pdf</a>, <a href="/format/2002.07897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LocoGAN -- Locally Convolutional GAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Struski%2C+%C5%81">&#x141;ukasz Struski</a>, 
<a href="/search/eess?searchtype=author&query=Knop%2C+S">Szymon Knop</a>, 
<a href="/search/eess?searchtype=author&query=Tabor%2C+J">Jacek Tabor</a>, 
<a href="/search/eess?searchtype=author&query=Daniec%2C+W">Wiktor Daniec</a>, 
<a href="/search/eess?searchtype=author&query=Spurek%2C+P">Przemys&#x142;aw Spurek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2005.05098" title="Abstract">arXiv:2005.05098</a> (replaced) [<a href="/pdf/2005.05098" title="Download PDF">pdf</a>, <a href="/ps/2005.05098" title="Download PostScript">ps</a>, <a href="/format/2005.05098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Positional Games and QBF: A Polished Encoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mayer-Eichberger%2C+V">Valentin Mayer-Eichberger</a>, 
<a href="/search/cs?searchtype=author&query=Saffidine%2C+A">Abdallah Saffidine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This technical report supersedes, extends and improves our SAT 2020 paper "Positional games and QBF: the corrective encoding"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Symbolic Computation (cs.SC)

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2005.05163" title="Abstract">arXiv:2005.05163</a> (replaced) [<a href="/pdf/2005.05163" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computable Phenotypes of Patient Acuity in the Intensive Care Unit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Ren%2C+Y">Yuanfang Ren</a> (1) (2), 
<a href="/search/q-bio?searchtype=author&query=Balch%2C+J">Jeremy Balch</a> (3), 
<a href="/search/q-bio?searchtype=author&query=Abbott%2C+K+L">Kenneth L. Abbott</a> (3), 
<a href="/search/q-bio?searchtype=author&query=Loftus%2C+T+J">Tyler J. Loftus</a> (1) (3), 
<a href="/search/q-bio?searchtype=author&query=Shickel%2C+B">Benjamin Shickel</a> (1) (2), 
<a href="/search/q-bio?searchtype=author&query=Rashidi%2C+P">Parisa Rashidi</a> (1) (4), 
<a href="/search/q-bio?searchtype=author&query=Bihorac%2C+A">Azra Bihorac</a> (1) (2), 
<a href="/search/q-bio?searchtype=author&query=Ozrazgat-Baslanti%2C+T">Tezcan Ozrazgat-Baslanti</a> (1) (2) ((1) Intelligent Clinical Care Center (IC3), University of Florida, Gainesville, FL, USA, (2) Department of Medicine, College of Medicine, University of Florida, Gainesville, FL, USA, (3) Department of Surgery, College of Medicine, University of Florida, Gainesville, FL, USA, (4) J. Crayton Pruitt Family Department of Biomedical Engineering, University of Florida, Gainesville, FL)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2011.13699" title="Abstract">arXiv:2011.13699</a> (replaced) [<a href="/pdf/2011.13699" title="Download PDF">pdf</a>, <a href="/format/2011.13699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Grassmann Manifold Handbook: Basic Geometry and Computational Aspects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bendokat%2C+T">Thomas Bendokat</a>, 
<a href="/search/math?searchtype=author&query=Zimmermann%2C+R">Ralf Zimmermann</a>, 
<a href="/search/math?searchtype=author&query=Absil%2C+P+-">P.-A. Absil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Differential Geometry (math.DG)

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.05147" title="Abstract">arXiv:2103.05147</a> (replaced) [<a href="/pdf/2103.05147" title="Download PDF">pdf</a>, <a href="/format/2103.05147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-free Policy Learning with Reward Gradients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lan%2C+Q">Qingfeng Lan</a>, 
<a href="/search/cs?searchtype=author&query=Tosatto%2C+S">Samuele Tosatto</a>, 
<a href="/search/cs?searchtype=author&query=Farrahi%2C+H">Homayoon Farrahi</a>, 
<a href="/search/cs?searchtype=author&query=Mahmood%2C+A+R">A. Rupam Mahmood</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AISTATS 2022 camera-ready (fixed a bug)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.04926" title="Abstract">arXiv:2104.04926</a> (replaced) [<a href="/pdf/2104.04926" title="Download PDF">pdf</a>, <a href="/format/2104.04926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep learning-based Edge-aware pre and post-processing methods for JPEG  compressed images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mishra%2C+D">Dipti Mishra</a>, 
<a href="/search/eess?searchtype=author&query=Singh%2C+S+K">Satish Kumar Singh</a>, 
<a href="/search/eess?searchtype=author&query=Singh%2C+R+K">Rajat Kumar Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 9 figures, 16 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.06943" title="Abstract">arXiv:2105.06943</a> (replaced) [<a href="/pdf/2105.06943" title="Download PDF">pdf</a>, <a href="/format/2105.06943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Spiking Neural Networks with Radix Encoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhehui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+X">Xiaozhe Gu</a>, 
<a href="/search/cs?searchtype=author&query=Goh%2C+R">Rick Goh</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J+T">Joey Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+T">Tao Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.10381" title="Abstract">arXiv:2105.10381</a> (replaced) [<a href="/pdf/2105.10381" title="Download PDF">pdf</a>, <a href="/ps/2105.10381" title="Download PostScript">ps</a>, <a href="/format/2105.10381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entropy-based Discovery of Summary Causal Graphs in Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Assaad%2C+C+K">Charles K. Assaad</a>, 
<a href="/search/cs?searchtype=author&query=Devijver%2C+E">Emilie Devijver</a>, 
<a href="/search/cs?searchtype=author&query=Gaussier%2C+E">Eric Gaussier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Entropy (2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.00839" title="Abstract">arXiv:2107.00839</a> (replaced) [<a href="/pdf/2107.00839" title="Download PDF">pdf</a>, <a href="/format/2107.00839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploration noise for learning linear-quadratic mean field games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Delarue%2C+F">Fran&#xe7;ois Delarue</a>, 
<a href="/search/math?searchtype=author&query=Vasileiadis%2C+A">Athanasios Vasileiadis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.10284" title="Abstract">arXiv:2108.10284</a> (replaced) [<a href="/pdf/2108.10284" title="Download PDF">pdf</a>, <a href="/format/2108.10284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exclusive Group Lasso for Structured Variable Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gregoratti%2C+D">David Gregoratti</a>, 
<a href="/search/cs?searchtype=author&query=Mestre%2C+X">Xavier Mestre</a>, 
<a href="/search/cs?searchtype=author&query=Buelga%2C+C">Carlos Buelga</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 2 figures. Not submitted for publication. New license
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.08907" title="Abstract">arXiv:2109.08907</a> (replaced) [<a href="/pdf/2109.08907" title="Download PDF">pdf</a>, <a href="/format/2109.08907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Releasing Graph Neural Networks with Differential Privacy Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Olatunji%2C+I+E">Iyiola E. Olatunji</a>, 
<a href="/search/cs?searchtype=author&query=Funke%2C+T">Thorben Funke</a>, 
<a href="/search/cs?searchtype=author&query=Khosla%2C+M">Megha Khosla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in TMLR 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transactions on Machine Learning Research (TMLR), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.03152" title="Abstract">arXiv:2112.03152</a> (replaced) [<a href="/pdf/2112.03152" title="Download PDF">pdf</a>, <a href="/format/2112.03152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bounding Wasserstein distance with couplings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Biswas%2C+N">Niloy Biswas</a>, 
<a href="/search/stat?searchtype=author&query=Mackey%2C+L">Lester Mackey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation (stat.CO)</span>; Machine Learning (cs.LG); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.08315" title="Abstract">arXiv:2112.08315</a> (replaced) [<a href="/pdf/2112.08315" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nirikshak: An Autonomous API Testing Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahalwal%2C+Y">Yash Mahalwal</a>, 
<a href="/search/cs?searchtype=author&query=Pratyush%2C+P">Pawel Pratyush</a>, 
<a href="/search/cs?searchtype=author&query=Poonia%2C+Y">Yogesh Poonia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.13398" title="Abstract">arXiv:2112.13398</a> (replaced) [<a href="/pdf/2112.13398" title="Download PDF">pdf</a>, <a href="/format/2112.13398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long Story Short: Omitted Variable Bias in Causal Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Chernozhukov%2C+V">Victor Chernozhukov</a>, 
<a href="/search/econ?searchtype=author&query=Cinelli%2C+C">Carlos Cinelli</a>, 
<a href="/search/econ?searchtype=author&query=Newey%2C+W">Whitney Newey</a>, 
<a href="/search/econ?searchtype=author&query=Sharma%2C+A">Amit Sharma</a>, 
<a href="/search/econ?searchtype=author&query=Syrgkanis%2C+V">Vasilis Syrgkanis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an extended version of the paper was prepared for the NeurIPS-2021 Workshop "Causal Inference &amp; Machine Learning: Why now?"; 55 pages; 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics (econ.EM)</span>; Machine Learning (cs.LG); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.14822" title="Abstract">arXiv:2112.14822</a> (replaced) [<a href="/pdf/2112.14822" title="Download PDF">pdf</a>, <a href="/ps/2112.14822" title="Download PostScript">ps</a>, <a href="/format/2112.14822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UCoDe: Unified Community Detection with Graph Convolutional Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moradan%2C+A">Atefeh Moradan</a>, 
<a href="/search/cs?searchtype=author&query=Draganov%2C+A">Andrew Draganov</a>, 
<a href="/search/cs?searchtype=author&query=Mottin%2C+D">Davide Mottin</a>, 
<a href="/search/cs?searchtype=author&query=Assent%2C+I">Ira Assent</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.11539" title="Abstract">arXiv:2201.11539</a> (replaced) [<a href="/pdf/2201.11539" title="Download PDF">pdf</a>, <a href="/ps/2201.11539" title="Download PostScript">ps</a>, <a href="/format/2201.11539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coded Caching with Private Demands and Caches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gholami%2C+A">Ali Gholami</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+K">Kai Wan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hua Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+M">Mingyue Ji</a>, 
<a href="/search/cs?searchtype=author&query=Caire%2C+G">Giuseppe Caire</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 46 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.12358" title="Abstract">arXiv:2201.12358</a> (replaced) [<a href="/pdf/2201.12358" title="Download PDF">pdf</a>, <a href="/format/2201.12358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EVBattery: A Large-Scale Electric Vehicle Dataset for Battery Health and  Capacity Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+H">Haowei He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingzhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Benben Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shaobo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+G">Gengang Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xuebing Han</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Dongxu Guo</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+G">Guannan He</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+M">Minggao Ouyang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.01209" title="Abstract">arXiv:2204.01209</a> (replaced) [<a href="/pdf/2204.01209" title="Download PDF">pdf</a>, <a href="/format/2204.01209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EResFD: Rediscovery of the Effectiveness of Standard Convolution for  Lightweight Face Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeong%2C+J">Joonhyun Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Beomyoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Joonsang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+Y">Youngjoon Yoo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.14724" title="Abstract">arXiv:2206.14724</a> (replaced) [<a href="/pdf/2206.14724" title="Download PDF">pdf</a>, <a href="/format/2206.14724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Private Graph Extraction via Feature Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Olatunji%2C+I+E">Iyiola E. Olatunji</a>, 
<a href="/search/cs?searchtype=author&query=Rathee%2C+M">Mandeep Rathee</a>, 
<a href="/search/cs?searchtype=author&query=Funke%2C+T">Thorben Funke</a>, 
<a href="/search/cs?searchtype=author&query=Khosla%2C+M">Megha Khosla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at PETS 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 23rd Privacy Enhancing Technologies Symposium
  (PETS), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.00563" title="Abstract">arXiv:2207.00563</a> (replaced) [<a href="/pdf/2207.00563" title="Download PDF">pdf</a>, <a href="/format/2207.00563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Power-Set Construction for Tree Algebras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blumensath%2C+A">Achim Blumensath</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.01964" title="Abstract">arXiv:2207.01964</a> (replaced) [<a href="/pdf/2207.01964" title="Download PDF">pdf</a>, <a href="/format/2207.01964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Circuit Compiler for a Shuttling-Based Trapped-Ion Quantum  Computer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Kreppel%2C+F">Fabian Kreppel</a>, 
<a href="/search/quant-ph?searchtype=author&query=Melzer%2C+C">Christian Melzer</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mill%C3%A1n%2C+D+O">Diego Olvera Mill&#xe1;n</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wagner%2C+J">Janis Wagner</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hilder%2C+J">Janine Hilder</a>, 
<a href="/search/quant-ph?searchtype=author&query=Poschinger%2C+U">Ulrich Poschinger</a>, 
<a href="/search/quant-ph?searchtype=author&query=Schmidt-Kaler%2C+F">Ferdinand Schmidt-Kaler</a>, 
<a href="/search/quant-ph?searchtype=author&query=Brinkmann%2C+A">Andr&#xe9; Brinkmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 25 figures, 4 tables, accepted in Quantum
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computation and Language (cs.CL); Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.11414" title="Abstract">arXiv:2207.11414</a> (replaced) [<a href="/pdf/2207.11414" title="Download PDF">pdf</a>, <a href="/format/2207.11414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling and Analysis of a Coupled SIS Bi-Virus Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Gracy%2C+S">Sebin Gracy</a>, 
<a href="/search/q-bio?searchtype=author&query=Par%C3%A9%2C+P+E">Philip E. Par&#xe9;</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+J">Ji Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Sandberg%2C+H">Henrik Sandberg</a>, 
<a href="/search/q-bio?searchtype=author&query=Beck%2C+C+L">Carolyn L. Beck</a>, 
<a href="/search/q-bio?searchtype=author&query=Johansson%2C+K+H">Karl Henrik Johansson</a>, 
<a href="/search/q-bio?searchtype=author&query=Ba%C5%9Far%2C+T">Tamer Ba&#x15f;ar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Populations and Evolution (q-bio.PE)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.08879" title="Abstract">arXiv:2208.08879</a> (replaced) [<a href="/pdf/2208.08879" title="Download PDF">pdf</a>, <a href="/format/2208.08879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SensorSCAN: Self-Supervised Learning and Deep Clustering for Fault  Diagnosis in Chemical Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Golyadkin%2C+M">Maksim Golyadkin</a>, 
<a href="/search/cs?searchtype=author&query=Pozdnyakov%2C+V">Vitaliy Pozdnyakov</a>, 
<a href="/search/cs?searchtype=author&query=Zhukov%2C+L">Leonid Zhukov</a>, 
<a href="/search/cs?searchtype=author&query=Makarov%2C+I">Ilya Makarov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.14741" title="Abstract">arXiv:2208.14741</a> (replaced) [<a href="/pdf/2208.14741" title="Download PDF">pdf</a>, <a href="/format/2208.14741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Failed Goal Aware Hindsight Experience Replay
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taeyoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Har%2C+D">Dongsoo Har</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> RiTA accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.07324" title="Abstract">arXiv:2209.07324</a> (replaced) [<a href="/pdf/2209.07324" title="Download PDF">pdf</a>, <a href="/format/2209.07324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Example When Local Optimal Policies Contain Unstable Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+B">Bing Song</a>, 
<a href="/search/cs?searchtype=author&query=Slotine%2C+J">Jean-Jacques Slotine</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+Q">Quang-Cuong Pham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.12835" title="Abstract">arXiv:2209.12835</a> (replaced) [<a href="/pdf/2209.12835" title="Download PDF">pdf</a>, <a href="/ps/2209.12835" title="Download PostScript">ps</a>, <a href="/format/2209.12835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Targeted Separation and Convergence with Kernel Discrepancies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Barp%2C+A">Alessandro Barp</a>, 
<a href="/search/stat?searchtype=author&query=Simon-Gabriel%2C+C">Carl-Johann Simon-Gabriel</a>, 
<a href="/search/stat?searchtype=author&query=Girolami%2C+M">Mark Girolami</a>, 
<a href="/search/stat?searchtype=author&query=Mackey%2C+L">Lester Mackey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.04366" title="Abstract">arXiv:2210.04366</a> (replaced) [<a href="/pdf/2210.04366" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KP-RNN: A Deep Learning Pipeline for Human Motion Prediction and  Synthesis of Performance Art
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perrine%2C+P">Patrick Perrine</a>, 
<a href="/search/cs?searchtype=author&query=Kirkby%2C+T">Trevor Kirkby</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in Proceedings of AIVR 2023, 11 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.12274" title="Abstract">arXiv:2210.12274</a> (replaced) [<a href="/pdf/2210.12274" title="Download PDF">pdf</a>, <a href="/format/2210.12274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeGroot-based opinion formation under a global steering mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Conjeaud%2C+I">Ivan Conjeaud</a>, 
<a href="/search/cs?searchtype=author&query=Lorenz-Spreen%2C+P">Philipp Lorenz-Spreen</a>, 
<a href="/search/cs?searchtype=author&query=Kalogeratos%2C+A">Argyris Kalogeratos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Transactions on Computational Social Systems. 17 double-column pages, 9 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.13441" title="Abstract">arXiv:2210.13441</a> (replaced) [<a href="/pdf/2210.13441" title="Download PDF">pdf</a>, <a href="/format/2210.13441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Machine Learning and Sciences: Opportunities and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Cheng%2C+T">Taoli Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex); High Energy Physics - Phenomenology (hep-ph); Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.06229" title="Abstract">arXiv:2211.06229</a> (replaced) [<a href="/pdf/2211.06229" title="Download PDF">pdf</a>, <a href="/format/2211.06229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving word mover&#x27;s distance by leveraging self-attention matrix
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yamagiwa%2C+H">Hiroaki Yamagiwa</a>, 
<a href="/search/cs?searchtype=author&query=Yokoi%2C+S">Sho Yokoi</a>, 
<a href="/search/cs?searchtype=author&query=Shimodaira%2C+H">Hidetoshi Shimodaira</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, accepted to EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.07440" title="Abstract">arXiv:2211.07440</a> (replaced) [<a href="/pdf/2211.07440" title="Download PDF">pdf</a>, <a href="/format/2211.07440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Automatic Personalised Nutrition: Food Image Recognition  Benchmark and Dataset based on Nutrition Taxonomy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Romero-Tapiador%2C+S">Sergio Romero-Tapiador</a>, 
<a href="/search/cs?searchtype=author&query=Tolosana%2C+R">Ruben Tolosana</a>, 
<a href="/search/cs?searchtype=author&query=Morales%2C+A">Aythami Morales</a>, 
<a href="/search/cs?searchtype=author&query=Fierrez%2C+J">Julian Fierrez</a>, 
<a href="/search/cs?searchtype=author&query=Vera-Rodriguez%2C+R">Ruben Vera-Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Espinosa-Salinas%2C+I">Isabel Espinosa-Salinas</a>, 
<a href="/search/cs?searchtype=author&query=Freixer%2C+G">Gala Freixer</a>, 
<a href="/search/cs?searchtype=author&query=de+Santa+Pau%2C+E+C">Enrique Carrillo de Santa Pau</a>, 
<a href="/search/cs?searchtype=author&query=de+Molina%2C+A+R">Ana Ram&#xed;rez de Molina</a>, 
<a href="/search/cs?searchtype=author&query=Ortega-Garcia%2C+J">Javier Ortega-Garcia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.09721" title="Abstract">arXiv:2211.09721</a> (replaced) [<a href="/pdf/2211.09721" title="Download PDF">pdf</a>, <a href="/ps/2211.09721" title="Download PostScript">ps</a>, <a href="/format/2211.09721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Finite-Particle Convergence Rate for Stein Variational Gradient  Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jiaxin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Mackey%2C+L">Lester Mackey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.15092" title="Abstract">arXiv:2211.15092</a> (replaced) [<a href="/pdf/2211.15092" title="Download PDF">pdf</a>, <a href="/format/2211.15092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Proxy Modeling for Improved HPO in Time Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jati%2C+A">Arindam Jati</a>, 
<a href="/search/cs?searchtype=author&query=Ekambaram%2C+V">Vijay Ekambaram</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+S">Shaonli Pal</a>, 
<a href="/search/cs?searchtype=author&query=Quanz%2C+B">Brian Quanz</a>, 
<a href="/search/cs?searchtype=author&query=Gifford%2C+W+M">Wesley M. Gifford</a>, 
<a href="/search/cs?searchtype=author&query=Harsha%2C+P">Pavithra Harsha</a>, 
<a href="/search/cs?searchtype=author&query=Siegel%2C+S">Stuart Siegel</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+S">Sumanta Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Narayanaswami%2C+C">Chandra Narayanaswami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.15856" title="Abstract">arXiv:2211.15856</a> (replaced) [<a href="/pdf/2211.15856" title="Download PDF">pdf</a>, <a href="/format/2211.15856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Ensemble Averages: Leveraging Climate Model Ensembles for  Subseasonal Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Orlova%2C+E">Elena Orlova</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haokun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Rossellini%2C+R">Raphael Rossellini</a>, 
<a href="/search/cs?searchtype=author&query=Cash%2C+B">Benjamin Cash</a>, 
<a href="/search/cs?searchtype=author&query=Willett%2C+R">Rebecca Willett</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.17182" title="Abstract">arXiv:2211.17182</a> (replaced) [<a href="/pdf/2211.17182" title="Download PDF">pdf</a>, <a href="/format/2211.17182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Direct Data-Driven State-Feedback Control of Linear Parameter-Varying  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Verhoek%2C+C">Chris Verhoek</a>, 
<a href="/search/eess?searchtype=author&query=T%C3%B3th%2C+R">Roland T&#xf3;th</a>, 
<a href="/search/eess?searchtype=author&query=Abbas%2C+H+S">Hossam S. Abbas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transactions on Automatic Control, extended version, 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.05652" title="Abstract">arXiv:2212.05652</a> (replaced) [<a href="/pdf/2212.05652" title="Download PDF">pdf</a>, <a href="/format/2212.05652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PyPop7: A Pure-Python Library for Population-Based Black-Box  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+Q">Qiqi Duan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Guochen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+C">Chang Shao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhuowei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+M">Mingyang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yijun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yuhui Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09171" title="Abstract">arXiv:2212.09171</a> (replaced) [<a href="/pdf/2212.09171" title="Download PDF">pdf</a>, <a href="/format/2212.09171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rainproof: An Umbrella To Shield Text Generators From  Out-Of-Distribution Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Darrin%2C+M">Maxime Darrin</a>, 
<a href="/search/cs?searchtype=author&query=Piantanida%2C+P">Pablo Piantanida</a>, 
<a href="/search/cs?searchtype=author&query=Colombo%2C+P">Pierre Colombo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09663" title="Abstract">arXiv:2212.09663</a> (replaced) [<a href="/pdf/2212.09663" title="Download PDF">pdf</a>, <a href="/format/2212.09663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Norm of Word Embedding Encodes Information Gain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oyama%2C+M">Momose Oyama</a>, 
<a href="/search/cs?searchtype=author&query=Yokoi%2C+S">Sho Yokoi</a>, 
<a href="/search/cs?searchtype=author&query=Shimodaira%2C+H">Hidetoshi Shimodaira</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.10649" title="Abstract">arXiv:2212.10649</a> (replaced) [<a href="/pdf/2212.10649" title="Download PDF">pdf</a>, <a href="/ps/2212.10649" title="Download PostScript">ps</a>, <a href="/format/2212.10649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inversion of Bayesian Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Oostrum%2C+J">Jesse van Oostrum</a>, 
<a href="/search/cs?searchtype=author&query=van+Hintum%2C+P">Peter van Hintum</a>, 
<a href="/search/cs?searchtype=author&query=Ay%2C+N">Nihat Ay</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Approximate Reasoning, Volume 164, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.14319" title="Abstract">arXiv:2212.14319</a> (replaced) [<a href="/pdf/2212.14319" title="Download PDF">pdf</a>, <a href="/format/2212.14319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Process Priors for Systems of Linear Partial Differential  Equations with Constant Coefficients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=H%C3%A4rk%C3%B6nen%2C+M">Marc H&#xe4;rk&#xf6;nen</a>, 
<a href="/search/stat?searchtype=author&query=Lange-Hegermann%2C+M">Markus Lange-Hegermann</a>, 
<a href="/search/stat?searchtype=author&query=Rai%C5%A3%C4%83%2C+B">Bogdan Rai&#x163;&#x103;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 8 figures; ICML 2023 (oral); updated with expanded appendices and ancillary files. Code available at <a href="https://github.com/haerski/EPGP.">this https URL</a> For animations, see <a href="https://mathrepo.mis.mpg.de/EPGP/index.html.">this https URL</a> For a presentation see <a href="https://icml.cc/virtual/2023/oral/25571.">this https URL</a> The paper and all ancillary files are released under CC-BY
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICML 2023 (oral); PMLR 202:12587-12615, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Commutative Algebra (math.AC); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.06781" title="Abstract">arXiv:2301.06781</a> (replaced) [<a href="/pdf/2301.06781" title="Download PDF">pdf</a>, <a href="/format/2301.06781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A nested divide-and-conquer method for tensor Sylvester equations with  positive definite hierarchically semiseparable coefficients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Massei%2C+S">Stefano Massei</a>, 
<a href="/search/math?searchtype=author&query=Robol%2C+L">Leonardo Robol</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07210" title="Abstract">arXiv:2301.07210</a> (replaced) [<a href="/pdf/2301.07210" title="Download PDF">pdf</a>, <a href="/format/2301.07210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Falsification of Digital Twins
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Cornish%2C+R">Rob Cornish</a>, 
<a href="/search/stat?searchtype=author&query=Taufiq%2C+M+F">Muhammad Faaiz Taufiq</a>, 
<a href="/search/stat?searchtype=author&query=Doucet%2C+A">Arnaud Doucet</a>, 
<a href="/search/stat?searchtype=author&query=Holmes%2C+C">Chris Holmes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.08317" title="Abstract">arXiv:2301.08317</a> (replaced) [<a href="/pdf/2301.08317" title="Download PDF">pdf</a>, <a href="/format/2301.08317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultrasound Plane Pose Regression: Assessing Generalized Pose Coordinates  in the Fetal Brain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di+Vece%2C+C">Chiara Di Vece</a>, 
<a href="/search/cs?searchtype=author&query=Lous%2C+M+L">Maela Le Lous</a>, 
<a href="/search/cs?searchtype=author&query=Dromey%2C+B">Brian Dromey</a>, 
<a href="/search/cs?searchtype=author&query=Vasconcelos%2C+F">Francisco Vasconcelos</a>, 
<a href="/search/cs?searchtype=author&query=David%2C+A+L">Anna L David</a>, 
<a href="/search/cs?searchtype=author&query=Peebles%2C+D">Donald Peebles</a>, 
<a href="/search/cs?searchtype=author&query=Stoyanov%2C+D">Danail Stoyanov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 9 figures, 2 tables. This article has been accepted for publication in IEEE Transactions on Medical Robotics and Bionics. This is the author's version which has not been fully edited and content may change prior to final publication. This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see <a href="https://creativecommons.org/licenses/by/4.0/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.08745" title="Abstract">arXiv:2301.08745</a> (replaced) [<a href="/pdf/2301.08745" title="Download PDF">pdf</a>, <a href="/format/2301.08745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is ChatGPT A Good Translator? Yes With GPT-4 As The Engine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiao%2C+W">Wenxiang Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jen-tse Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhaopeng Tu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Analyzed/compared the outputs between ChatGPT and Google Translate; both automatic and human evaluation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11201" title="Abstract">arXiv:2301.11201</a> (replaced) [<a href="/pdf/2301.11201" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relative-Interior Solution for (Incomplete) Linear Assignment Problem  with Applications to Quadratic Assignment Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dlask%2C+T">Tom&#xe1;&#x161; Dlask</a>, 
<a href="/search/math?searchtype=author&query=Savchynskyy%2C+B">Bogdan Savchynskyy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11356" title="Abstract">arXiv:2301.11356</a> (replaced) [<a href="/pdf/2301.11356" title="Download PDF">pdf</a>, <a href="/format/2301.11356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Automated Discovery of Kinetic Rate Models -- Methodological  Frameworks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Carvalho+Servia%2C+M+%C3%81">Miguel &#xc1;ngel de Carvalho Servia</a>, 
<a href="/search/cs?searchtype=author&query=Sandoval%2C+I+O">Ilya Orson Sandoval</a>, 
<a href="/search/cs?searchtype=author&query=Hellgardt%2C+K">Klaus Hellgardt</a>, 
<a href="/search/cs?searchtype=author&query=Kuok%2C+K">King Kuok</a> (Mimi)Hii, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongda Zhang</a>, 
<a href="/search/cs?searchtype=author&query=del+Rio+Chanona%2C+E+A">Ehecatl Antonio del Rio Chanona</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Computational Engineering, Finance, and Science (cs.CE); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12874" title="Abstract">arXiv:2301.12874</a> (replaced) [<a href="/pdf/2301.12874" title="Download PDF">pdf</a>, <a href="/format/2301.12874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extremal Domain Translation with Neural Optimal Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gazdieva%2C+M">Milena Gazdieva</a>, 
<a href="/search/cs?searchtype=author&query=Korotin%2C+A">Alexander Korotin</a>, 
<a href="/search/cs?searchtype=author&query=Selikhanovych%2C+D">Daniil Selikhanovych</a>, 
<a href="/search/cs?searchtype=author&query=Burnaev%2C+E">Evgeny Burnaev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13308" title="Abstract">arXiv:2301.13308</a> (replaced) [<a href="/pdf/2301.13308" title="Download PDF">pdf</a>, <a href="/format/2301.13308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can&#x27;t Touch This: Real-Time, Safe Motion Planning and Control for  Manipulators Under Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Michaux%2C+J">Jonathan Michaux</a>, 
<a href="/search/cs?searchtype=author&query=Holmes%2C+P">Patrick Holmes</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bohao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Che Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Baiyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sahgal%2C+S">Shrey Sahgal</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tiancheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+S">Sidhartha Dey</a>, 
<a href="/search/cs?searchtype=author&query=Kousik%2C+S">Shreyas Kousik</a>, 
<a href="/search/cs?searchtype=author&query=Vasudevan%2C+R">Ram Vasudevan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01675" title="Abstract">arXiv:2302.01675</a> (replaced) [<a href="/pdf/2302.01675" title="Download PDF">pdf</a>, <a href="/format/2302.01675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling Relational Database Analytical Processing in Bulk-Bitwise  Processing-In-Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perach%2C+B">Ben Perach</a>, 
<a href="/search/cs?searchtype=author&query=Ronen%2C+R">Ronny Ronen</a>, 
<a href="/search/cs?searchtype=author&query=Kvatinsky%2C+S">Shahar Kvatinsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Included in conference proceedings of the 2023 IEEE 36th International System-on-Chip Conference (SOCC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02473" title="Abstract">arXiv:2302.02473</a> (replaced) [<a href="/pdf/2302.02473" title="Download PDF">pdf</a>, <a href="/format/2302.02473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Level-p-complexity of Boolean Functions using Thinning, Memoization, and  Polynomials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jansson%2C+J">Julia Jansson</a>, 
<a href="/search/cs?searchtype=author&query=Jansson%2C+P">Patrik Jansson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03370" title="Abstract">arXiv:2302.03370</a> (replaced) [<a href="/pdf/2302.03370" title="Download PDF">pdf</a>, <a href="/format/2302.03370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A hybrid finite volume -- spectral element method for aeroacoustic  problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Artoni%2C+A">Alberto Artoni</a>, 
<a href="/search/math?searchtype=author&query=Antonietti%2C+P+F">Paola F. Antonietti</a>, 
<a href="/search/math?searchtype=author&query=Mazzieri%2C+I">Ilario Mazzieri</a>, 
<a href="/search/math?searchtype=author&query=Parolini%2C+N">Nicola Parolini</a>, 
<a href="/search/math?searchtype=author&query=Rocchi%2C+D">Daniele Rocchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04040" title="Abstract">arXiv:2302.04040</a> (replaced) [<a href="/pdf/2302.04040" title="Download PDF">pdf</a>, <a href="/format/2302.04040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample-efficient Multi-objective Molecular Optimization with GFlowNets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yiheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jialu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chaowen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Jiahuan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+C">Chang-Yu Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+T">Tingjun Hou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05187" title="Abstract">arXiv:2302.05187</a> (replaced) [<a href="/pdf/2302.05187" title="Download PDF">pdf</a>, <a href="/format/2302.05187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the approximability of Koopman-based operator Lyapunov equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Breiten%2C+T">Tobias Breiten</a>, 
<a href="/search/math?searchtype=author&query=H%C3%B6veler%2C+B">Bernhard H&#xf6;veler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Lyapunov equations, Koopman operator, infinite dimensional systems, semigroups
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06945" title="Abstract">arXiv:2302.06945</a> (replaced) [<a href="/pdf/2302.06945" title="Download PDF">pdf</a>, <a href="/format/2302.06945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial argmin for recovery and approximation of multivariate  discontinuous functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Henrion%2C+D">Didier Henrion</a> (LAAS-POP), 
<a href="/search/math?searchtype=author&query=Korda%2C+M">Milan Korda</a> (LAAS-POP), 
<a href="/search/math?searchtype=author&query=Lasserre%2C+J">Jean-Bernard Lasserre</a> (LAAS-POP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07126" title="Abstract">arXiv:2302.07126</a> (replaced) [<a href="/pdf/2302.07126" title="Download PDF">pdf</a>, <a href="/format/2302.07126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discontinuous Galerkin Methods for Fisher-Kolmogorov Equation with  Application to $&#x3b1;$-Synuclein Spreading in Parkinson&#x27;s Disease
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Corti%2C+M">Mattia Corti</a>, 
<a href="/search/math?searchtype=author&query=Bonizzoni%2C+F">Francesca Bonizzoni</a>, 
<a href="/search/math?searchtype=author&query=Dede%27%2C+L">Luca Dede&#x27;</a>, 
<a href="/search/math?searchtype=author&query=Quarteroni%2C+A">Alfio Quarteroni</a>, 
<a href="/search/math?searchtype=author&query=Antonietti%2C+P+F">Paola F. Antonietti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2210.02272">arXiv:2210.02272</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Methods in Applied Mechanics and Engineering (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01200" title="Abstract">arXiv:2303.01200</a> (replaced) [<a href="/pdf/2303.01200" title="Download PDF">pdf</a>, <a href="/format/2303.01200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval for Extremely Long Queries and Documents with RPRS: a Highly  Efficient and Effective Transformer-based Re-Ranker
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Askari%2C+A">Arian Askari</a>, 
<a href="/search/cs?searchtype=author&query=Verberne%2C+S">Suzan Verberne</a>, 
<a href="/search/cs?searchtype=author&query=Abolghasemi%2C+A">Amin Abolghasemi</a>, 
<a href="/search/cs?searchtype=author&query=Kraaij%2C+W">Wessel Kraaij</a>, 
<a href="/search/cs?searchtype=author&query=Pasi%2C+G">Gabriella Pasi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ACM Transactions on Information Systems (ACM TOIS journal)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08991" title="Abstract">arXiv:2303.08991</a> (replaced) [<a href="/pdf/2303.08991" title="Download PDF">pdf</a>, <a href="/format/2303.08991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeltaScore: Fine-Grained Story Evaluation with Perturbations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhuohan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Miao Li</a>, 
<a href="/search/cs?searchtype=author&query=Cohn%2C+T">Trevor Cohn</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+J+H">Jey Han Lau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 3 figures, 8 tables. Camera ready version for EMNLP 2023 findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10056" title="Abstract">arXiv:2303.10056</a> (replaced) [<a href="/pdf/2303.10056" title="Download PDF">pdf</a>, <a href="/format/2303.10056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GlueGen: Plug and Play Multi-modal Encoders for X-to-image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+C">Can Qin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+N">Ning Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+C">Chen Xing</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zeyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ermon%2C+S">Stefano Ermon</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yun Fu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Caiming Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ran Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10180" title="Abstract">arXiv:2303.10180</a> (replaced) [<a href="/pdf/2303.10180" title="Download PDF">pdf</a>, <a href="/format/2303.10180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Safe Propofol Dosing during General Anesthesia Using Deep  Offline Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xiuding Cai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yaoyao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Beimin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yu Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10725" title="Abstract">arXiv:2303.10725</a> (replaced) [<a href="/pdf/2303.10725" title="Download PDF">pdf</a>, <a href="/format/2303.10725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SIESTA: Efficient Online Continual Learning with Sleep
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harun%2C+M+Y">Md Yousuf Harun</a>, 
<a href="/search/cs?searchtype=author&query=Gallardo%2C+J">Jhair Gallardo</a>, 
<a href="/search/cs?searchtype=author&query=Hayes%2C+T+L">Tyler L. Hayes</a>, 
<a href="/search/cs?searchtype=author&query=Kemker%2C+R">Ronald Kemker</a>, 
<a href="/search/cs?searchtype=author&query=Kanan%2C+C">Christopher Kanan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to TMLR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12145" title="Abstract">arXiv:2303.12145</a> (replaced) [<a href="/pdf/2303.12145" title="Download PDF">pdf</a>, <a href="/format/2303.12145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Feature Distillation for Zero-shot Annotation Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhuoming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xuefeng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Nevatia%2C+R">Ram Nevatia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV2024 accepted paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12783" title="Abstract">arXiv:2303.12783</a> (replaced) [<a href="/pdf/2303.12783" title="Download PDF">pdf</a>, <a href="/format/2303.12783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conformal Prediction for Time Series with Modern Hopfield Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Auer%2C+A">Andreas Auer</a>, 
<a href="/search/cs?searchtype=author&query=Gauch%2C+M">Martin Gauch</a>, 
<a href="/search/cs?searchtype=author&query=Klotz%2C+D">Daniel Klotz</a>, 
<a href="/search/cs?searchtype=author&query=Hochreiter%2C+S">Sepp Hochreiter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> presented at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17760" title="Abstract">arXiv:2303.17760</a> (replaced) [<a href="/pdf/2303.17760" title="Download PDF">pdf</a>, <a href="/format/2303.17760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAMEL: Communicative Agents for &quot;Mind&quot; Exploration of Large Language  Model Society
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guohao Li</a>, 
<a href="/search/cs?searchtype=author&query=Hammoud%2C+H+A+A+K">Hasan Abed Al Kader Hammoud</a>, 
<a href="/search/cs?searchtype=author&query=Itani%2C+H">Hani Itani</a>, 
<a href="/search/cs?searchtype=author&query=Khizbullin%2C+D">Dmitrii Khizbullin</a>, 
<a href="/search/cs?searchtype=author&query=Ghanem%2C+B">Bernard Ghanem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS'2023, 77 pages, project website: <a href="https://www.camel-ai.org">this https URL</a>, github repository: <a href="https://github.com/camel-ai/camel">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY); Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17835" title="Abstract">arXiv:2303.17835</a> (replaced) [<a href="/pdf/2303.17835" title="Download PDF">pdf</a>, <a href="/format/2303.17835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Difference Images for Change Detection Classifiers in SAR  Imagery Using Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alatalo%2C+J">Janne Alatalo</a>, 
<a href="/search/cs?searchtype=author&query=Sipola%2C+T">Tuomo Sipola</a>, 
<a href="/search/cs?searchtype=author&query=Rantonen%2C+M">Mika Rantonen</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Trans. Geosci. Remote Sens. 61 (2023) 1-14
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02426" title="Abstract">arXiv:2304.02426</a> (replaced) [<a href="/pdf/2304.02426" title="Download PDF">pdf</a>, <a href="/format/2304.02426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ParroT: Translating during Chat using Large Language Models tuned with  Human Translation and Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiao%2C+W">Wenxiang Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jen-tse Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhiwei He</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+T">Tian Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhaopeng Tu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages; EMNLP 2023 (Findings)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06128" title="Abstract">arXiv:2304.06128</a> (replaced) [<a href="/pdf/2304.06128" title="Download PDF">pdf</a>, <a href="/ps/2304.06128" title="Download PostScript">ps</a>, <a href="/format/2304.06128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physical Layer Security for STAR-RIS-NOMA: A Stochastic Geometry  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Ziyi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+W">Wenqiang Yi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xuanli Wu</a>, 
<a href="/search/cs?searchtype=author&query=Nallanathan%2C+A">Arumugam Nallanathan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures. This work has been accepted by IEEE Transactions on Wireless Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07238" title="Abstract">arXiv:2304.07238</a> (replaced) [<a href="/pdf/2304.07238" title="Download PDF">pdf</a>, <a href="/format/2304.07238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustness of community structure under edge addition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Tian%2C+M">Moyi Tian</a>, 
<a href="/search/physics?searchtype=author&query=Moriano%2C+P">Pablo Moriano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 30 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Phys. Rev. E 108 (2023) 054302
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10168" title="Abstract">arXiv:2304.10168</a> (replaced) [<a href="/pdf/2304.10168" title="Download PDF">pdf</a>, <a href="/format/2304.10168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Fidelity and Freely Controllable Talking Head Video Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yue Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinglu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Ming%2C+X">Xiang Ming</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yan Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10832" title="Abstract">arXiv:2304.10832</a> (replaced) [<a href="/pdf/2304.10832" title="Download PDF">pdf</a>, <a href="/format/2304.10832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Deep Learning algorithm to accelerate Algebraic Multigrid methods in  Finite Element solvers of 3D elliptic PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Caldana%2C+M">Matteo Caldana</a>, 
<a href="/search/math?searchtype=author&query=Antonietti%2C+P+F">Paola F. Antonietti</a>, 
<a href="/search/math?searchtype=author&query=Dede%27%2C+L">Luca Dede&#x27;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12768" title="Abstract">arXiv:2304.12768</a> (replaced) [<a href="/pdf/2304.12768" title="Download PDF">pdf</a>, <a href="/ps/2304.12768" title="Download PostScript">ps</a>, <a href="/format/2304.12768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Characterizing the First-order Query Complexity of Learning  (Approximate) Nash Equilibria in Zero-sum Matrix Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hadiji%2C+H">H&#xe9;di Hadiji</a> (L2S), 
<a href="/search/cs?searchtype=author&query=Sachs%2C+S">Sarah Sachs</a> (UvA), 
<a href="/search/cs?searchtype=author&query=van+Erven%2C+T">Tim van Erven</a> (UvA), 
<a href="/search/cs?searchtype=author&query=Koolen%2C+W+M">Wouter M. Koolen</a> (CWI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13410" title="Abstract">arXiv:2304.13410</a> (replaced) [<a href="/pdf/2304.13410" title="Download PDF">pdf</a>, <a href="/format/2304.13410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Adversarial Transferability via Intermediate-level  Perturbation Decay
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qizhang Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yiwen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+W">Wangmeng Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13672" title="Abstract">arXiv:2304.13672</a> (replaced) [<a href="/pdf/2304.13672" title="Download PDF">pdf</a>, <a href="/format/2304.13672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FVP: Fourier Visual Prompting for Source-Free Unsupervised Domain  Adaptation of Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jian Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yixin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+S">Shuai Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lanyun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhenzhou Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Haogang Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14030" title="Abstract">arXiv:2304.14030</a> (replaced) [<a href="/pdf/2304.14030" title="Download PDF">pdf</a>, <a href="/format/2304.14030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COSST: Multi-organ Segmentation with Partially Labeled Datasets Using  Comprehensive Supervisions and Self-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Han Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhoubing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Riqiang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chabin%2C+G">Guillaume Chabin</a>, 
<a href="/search/cs?searchtype=author&query=Oguz%2C+I">Ipek Oguz</a>, 
<a href="/search/cs?searchtype=author&query=Grbic%2C+S">Sasa Grbic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14274" title="Abstract">arXiv:2304.14274</a> (replaced) [<a href="/pdf/2304.14274" title="Download PDF">pdf</a>, <a href="/format/2304.14274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Do Graph Neural Networks Help with Node Classification?  Investigating the Impact of Homophily Principle on Node Distinguishability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luan%2C+S">Sitao Luan</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+C">Chenqing Hua</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Minkai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Qincheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiaqi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiao-Wen Chang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Leskovec%2C+J">Jure Leskovec</a>, 
<a href="/search/cs?searchtype=author&query=Precup%2C+D">Doina Precup</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00586" title="Abstract">arXiv:2305.00586</a> (replaced) [<a href="/pdf/2305.00586" title="Download PDF">pdf</a>, <a href="/format/2305.00586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How does GPT-2 compute greater-than?: Interpreting mathematical  abilities in a pre-trained language model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hanna%2C+M">Michael Hanna</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+O">Ollie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Variengien%2C+A">Alexandre Variengien</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01638" title="Abstract">arXiv:2305.01638</a> (replaced) [<a href="/pdf/2305.01638" title="Download PDF">pdf</a>, <a href="/format/2305.01638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sequence Modeling with Multiresolution Convolutional Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jiaxin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K+A">Ke Alexander Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fox%2C+E+B">Emily B. Fox</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICML 2023, Source code: <a href="https://github.com/thjashin/multires-conv">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01951" title="Abstract">arXiv:2305.01951</a> (replaced) [<a href="/pdf/2305.01951" title="Download PDF">pdf</a>, <a href="/format/2305.01951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can LMs Generalize to Future Data? An Empirical Analysis on Text  Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheang%2C+C+S">Chi Seng Cheang</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+H+P">Hou Pong Chan</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+D+F">Derek F. Wong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuebo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhaocong Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yanming Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shudong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chao%2C+L+S">Lidia S. Chao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02305" title="Abstract">arXiv:2305.02305</a> (replaced) [<a href="/pdf/2305.02305" title="Download PDF">pdf</a>, <a href="/format/2305.02305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calibrated Explanations: with Uncertainty Information and  Counterfactuals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lofstrom%2C+H">Helena Lofstrom</a>, 
<a href="/search/cs?searchtype=author&query=Lofstrom%2C+T">Tuwe Lofstrom</a>, 
<a href="/search/cs?searchtype=author&query=Johansson%2C+U">Ulf Johansson</a>, 
<a href="/search/cs?searchtype=author&query=Sonstrod%2C+C">Cecilia Sonstrod</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 6 figures, 4 tables, submitted to journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03619" title="Abstract">arXiv:2305.03619</a> (replaced) [<a href="/pdf/2305.03619" title="Download PDF">pdf</a>, <a href="/format/2305.03619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Quantification for Fisher-Kolmogorov Equation on Graphs with  Application to Patient-Specific Alzheimer Disease
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Corti%2C+M">Mattia Corti</a>, 
<a href="/search/math?searchtype=author&query=Bonizzoni%2C+F">Francesca Bonizzoni</a>, 
<a href="/search/math?searchtype=author&query=Antonietti%2C+P+F">Paola F. Antonietti</a>, 
<a href="/search/math?searchtype=author&query=Quarteroni%2C+A+M">Alfio M. Quarteroni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06092" title="Abstract">arXiv:2305.06092</a> (replaced) [<a href="/pdf/2305.06092" title="Download PDF">pdf</a>, <a href="/ps/2305.06092" title="Download PostScript">ps</a>, <a href="/format/2305.06092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SafeLLVM: LLVM Without The ROP Gadgets!
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cassano%2C+F">Federico Cassano</a>, 
<a href="/search/cs?searchtype=author&query=Bershatsky%2C+C">Charles Bershatsky</a>, 
<a href="/search/cs?searchtype=author&query=Ginesin%2C+J">Jacob Ginesin</a>, 
<a href="/search/cs?searchtype=author&query=Bashenko%2C+S">Sasha Bashenko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07828" title="Abstract">arXiv:2305.07828</a> (replaced) [<a href="/pdf/2305.07828" title="Download PDF">pdf</a>, <a href="/format/2305.07828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Description and Discussion on DCASE 2023 Challenge Task 2: First-Shot  Unsupervised Anomalous Sound Detection for Machine Condition Monitoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dohi%2C+K">Kota Dohi</a>, 
<a href="/search/cs?searchtype=author&query=Imoto%2C+K">Keisuke Imoto</a>, 
<a href="/search/cs?searchtype=author&query=Harada%2C+N">Noboru Harada</a>, 
<a href="/search/cs?searchtype=author&query=Niizumi%2C+D">Daisuke Niizumi</a>, 
<a href="/search/cs?searchtype=author&query=Koizumi%2C+Y">Yuma Koizumi</a>, 
<a href="/search/cs?searchtype=author&query=Nishida%2C+T">Tomoya Nishida</a>, 
<a href="/search/cs?searchtype=author&query=Purohit%2C+H">Harsh Purohit</a>, 
<a href="/search/cs?searchtype=author&query=Tanabe%2C+R">Ryo Tanabe</a>, 
<a href="/search/cs?searchtype=author&query=Endo%2C+T">Takashi Endo</a>, 
<a href="/search/cs?searchtype=author&query=Kawaguchi%2C+Y">Yohei Kawaguchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> anomaly detection, acoustic condition monitoring, domain shift, first-shot problem, DCASE Challenge, Accepted in DCASE2023 Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08491" title="Abstract">arXiv:2305.08491</a> (replaced) [<a href="/pdf/2305.08491" title="Download PDF">pdf</a>, <a href="/format/2305.08491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Collaborative Contrast for Weakly Supervised Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fangwen Wu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jingxuan He</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yufei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yanbin Hao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lechao Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is accepted by WACV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08776" title="Abstract">arXiv:2305.08776</a> (replaced) [<a href="/pdf/2305.08776" title="Download PDF">pdf</a>, <a href="/format/2305.08776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging the Domain Gap: Self-Supervised 3D Scene Understanding with  Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhimin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+L">Longlong Jing</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bing Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09194" title="Abstract">arXiv:2305.09194</a> (replaced) [<a href="/pdf/2305.09194" title="Download PDF">pdf</a>, <a href="/format/2305.09194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing network circuity among heterogeneous urban amenities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Poudyal%2C+B">Bibandhan Poudyal</a>, 
<a href="/search/physics?searchtype=author&query=Ghoshal%2C+G">Gourab Ghoshal</a>, 
<a href="/search/physics?searchtype=author&query=Kirkley%2C+A">Alec Kirkley</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of the Royal Society Interface 20, 20230296 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09253" title="Abstract">arXiv:2305.09253</a> (replaced) [<a href="/pdf/2305.09253" title="Download PDF">pdf</a>, <a href="/format/2305.09253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Continual Learning Without the Storage Constraint
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prabhu%2C+A">Ameya Prabhu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhipeng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Dokania%2C+P">Puneet Dokania</a>, 
<a href="/search/cs?searchtype=author&query=Torr%2C+P">Philip Torr</a>, 
<a href="/search/cs?searchtype=author&query=Koltun%2C+V">Vladlen Koltun</a>, 
<a href="/search/cs?searchtype=author&query=Sener%2C+O">Ozan Sener</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tech Report [Additional Experiments and Improved ACM]
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11147" title="Abstract">arXiv:2305.11147</a> (replaced) [<a href="/pdf/2305.11147" title="Download PDF">pdf</a>, <a href="/format/2305.11147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniControl: A Unified Diffusion Model for Controllable Visual Generation  In the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+C">Can Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+N">Ning Yu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yihao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yingbo Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Niebles%2C+J+C">Juan Carlos Niebles</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Caiming Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Savarese%2C+S">Silvio Savarese</a>, 
<a href="/search/cs?searchtype=author&query=Ermon%2C+S">Stefano Ermon</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yun Fu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ran Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11356" title="Abstract">arXiv:2305.11356</a> (replaced) [<a href="/pdf/2305.11356" title="Download PDF">pdf</a>, <a href="/format/2305.11356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Div-Div-Conforming Symmetric Tensor Finite Element Space with  Applications to the Biharmonic Equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+L">Long Chen</a>, 
<a href="/search/math?searchtype=author&query=Huang%2C+X">Xuehai Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13009" title="Abstract">arXiv:2305.13009</a> (replaced) [<a href="/pdf/2305.13009" title="Download PDF">pdf</a>, <a href="/format/2305.13009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Textually Pretrained Speech Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hassid%2C+M">Michael Hassid</a>, 
<a href="/search/cs?searchtype=author&query=Remez%2C+T">Tal Remez</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+A">Tu Anh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Gat%2C+I">Itai Gat</a>, 
<a href="/search/cs?searchtype=author&query=Conneau%2C+A">Alexis Conneau</a>, 
<a href="/search/cs?searchtype=author&query=Kreuk%2C+F">Felix Kreuk</a>, 
<a href="/search/cs?searchtype=author&query=Copet%2C+J">Jade Copet</a>, 
<a href="/search/cs?searchtype=author&query=Defossez%2C+A">Alexandre Defossez</a>, 
<a href="/search/cs?searchtype=author&query=Synnaeve%2C+G">Gabriel Synnaeve</a>, 
<a href="/search/cs?searchtype=author&query=Dupoux%2C+E">Emmanuel Dupoux</a>, 
<a href="/search/cs?searchtype=author&query=Schwartz%2C+R">Roy Schwartz</a>, 
<a href="/search/cs?searchtype=author&query=Adi%2C+Y">Yossi Adi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13175" title="Abstract">arXiv:2305.13175</a> (replaced) [<a href="/pdf/2305.13175" title="Download PDF">pdf</a>, <a href="/format/2305.13175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering Universal Geometry in Embeddings with ICA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yamagiwa%2C+H">Hiroaki Yamagiwa</a>, 
<a href="/search/cs?searchtype=author&query=Oyama%2C+M">Momose Oyama</a>, 
<a href="/search/cs?searchtype=author&query=Shimodaira%2C+H">Hidetoshi Shimodaira</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13194" title="Abstract">arXiv:2305.13194</a> (replaced) [<a href="/pdf/2305.13194" title="Download PDF">pdf</a>, <a href="/format/2305.13194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEAHORSE: A Multilingual, Multifaceted Dataset for Summarization  Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Clark%2C+E">Elizabeth Clark</a>, 
<a href="/search/cs?searchtype=author&query=Rijhwani%2C+S">Shruti Rijhwani</a>, 
<a href="/search/cs?searchtype=author&query=Gehrmann%2C+S">Sebastian Gehrmann</a>, 
<a href="/search/cs?searchtype=author&query=Maynez%2C+J">Joshua Maynez</a>, 
<a href="/search/cs?searchtype=author&query=Aharoni%2C+R">Roee Aharoni</a>, 
<a href="/search/cs?searchtype=author&query=Nikolaev%2C+V">Vitaly Nikolaev</a>, 
<a href="/search/cs?searchtype=author&query=Sellam%2C+T">Thibault Sellam</a>, 
<a href="/search/cs?searchtype=author&query=Siddhant%2C+A">Aditya Siddhant</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+D">Dipanjan Das</a>, 
<a href="/search/cs?searchtype=author&query=Parikh%2C+A+P">Ankur P. Parikh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13533" title="Abstract">arXiv:2305.13533</a> (replaced) [<a href="/pdf/2305.13533" title="Download PDF">pdf</a>, <a href="/format/2305.13533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open-world Semi-supervised Generalized Relation Discovery Aligned in a  Real-world Setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hogan%2C+W">William Hogan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiacheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+J">Jingbo Shang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13677" title="Abstract">arXiv:2305.13677</a> (replaced) [<a href="/pdf/2305.13677" title="Download PDF">pdf</a>, <a href="/format/2305.13677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Legally Enforceable Hate Speech Detection for Public Forums
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+C+F">Chu Fei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Bhambhoria%2C+R">Rohan Bhambhoria</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaodan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Dahan%2C+S">Samuel Dahan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages; Accepted to the Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14690" title="Abstract">arXiv:2305.14690</a> (replaced) [<a href="/pdf/2305.14690" title="Download PDF">pdf</a>, <a href="/format/2305.14690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizing Importance Weighting to A Universal Solver for Distribution  Shift Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+T">Tongtong Fang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+N">Nan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+G">Gang Niu</a>, 
<a href="/search/cs?searchtype=author&query=Sugiyama%2C+M">Masashi Sugiyama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 camera-ready version (this paper was selected for spotlight presentation)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14764" title="Abstract">arXiv:2305.14764</a> (replaced) [<a href="/pdf/2305.14764" title="Download PDF">pdf</a>, <a href="/format/2305.14764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detection of Non-uniformity in Parameters for Magnetic Domain Pattern  Generation by Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Mamada%2C+N">Naoya Mamada</a>, 
<a href="/search/cond-mat?searchtype=author&query=Mizumaki%2C+M">Masaichiro Mizumaki</a>, 
<a href="/search/cond-mat?searchtype=author&query=Akai%2C+I">Ichiro Akai</a>, 
<a href="/search/cond-mat?searchtype=author&query=Aonishi%2C+T">Toru Aonishi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14909" title="Abstract">arXiv:2305.14909</a> (replaced) [<a href="/pdf/2305.14909" title="Download PDF">pdf</a>, <a href="/format/2305.14909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Pre-trained Large Language Models to Construct and Utilize  World Models for Model-based Task Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+L">Lin Guan</a>, 
<a href="/search/cs?searchtype=author&query=Valmeekam%2C+K">Karthik Valmeekam</a>, 
<a href="/search/cs?searchtype=author&query=Sreedharan%2C+S">Sarath Sreedharan</a>, 
<a href="/search/cs?searchtype=author&query=Kambhampati%2C+S">Subbarao Kambhampati</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14999" title="Abstract">arXiv:2305.14999</a> (replaced) [<a href="/pdf/2305.14999" title="Download PDF">pdf</a>, <a href="/format/2305.14999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Art of SOCRATIC QUESTIONING: Recursive Thinking with Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Jingyuan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Ying Shen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Minqian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+D">Di Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lifu Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACL 2023 main
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15208" title="Abstract">arXiv:2305.15208</a> (replaced) [<a href="/pdf/2305.15208" title="Download PDF">pdf</a>, <a href="/format/2305.15208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Bayesian Inference for Scientific Simulators via Amortized  Cost Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Gao%2C+R">Richard Gao</a>, 
<a href="/search/stat?searchtype=author&query=Deistler%2C+M">Michael Deistler</a>, 
<a href="/search/stat?searchtype=author&query=Macke%2C+J+H">Jakob H. Macke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15572" title="Abstract">arXiv:2305.15572</a> (replaced) [<a href="/pdf/2305.15572" title="Download PDF">pdf</a>, <a href="/format/2305.15572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Behavior and Convergence of Local Bayesian Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kaiwen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kyurae Kim</a>, 
<a href="/search/cs?searchtype=author&query=Garnett%2C+R">Roman Garnett</a>, 
<a href="/search/cs?searchtype=author&query=Gardner%2C+J+R">Jacob R. Gardner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16744" title="Abstract">arXiv:2305.16744</a> (replaced) [<a href="/pdf/2305.16744" title="Download PDF">pdf</a>, <a href="/format/2305.16744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demo2Code: From Summarizing Demonstrations to Synthesizing Code via  Extended Chain-of-Thought
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huaxiaoyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez-Pumariega%2C+G">Gonzalo Gonzalez-Pumariega</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+Y">Yash Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Choudhury%2C+S">Sanjiban Choudhury</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages (not including references and appendix), 14 figures (7 in main paper, 7 in appendix); (v3) camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17020" title="Abstract">arXiv:2305.17020</a> (replaced) [<a href="/pdf/2305.17020" title="Download PDF">pdf</a>, <a href="/format/2305.17020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diable: Efficient Dialogue State Tracking as Operations on Tables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lesci%2C+P">Pietro Lesci</a>, 
<a href="/search/cs?searchtype=author&query=Fujinuma%2C+Y">Yoshinari Fujinuma</a>, 
<a href="/search/cs?searchtype=author&query=Hardalov%2C+M">Momchil Hardalov</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+C">Chao Shang</a>, 
<a href="/search/cs?searchtype=author&query=Benajiba%2C+Y">Yassine Benajiba</a>, 
<a href="/search/cs?searchtype=author&query=Marquez%2C+L">Lluis Marquez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ACL 2023 (Findings)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18333" title="Abstract">arXiv:2305.18333</a> (replaced) [<a href="/pdf/2305.18333" title="Download PDF">pdf</a>, <a href="/format/2305.18333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ranking with Popularity Bias: User Welfare under Self-Amplification  Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tennenholtz%2C+G">Guy Tennenholtz</a>, 
<a href="/search/cs?searchtype=author&query=Mladenov%2C+M">Martin Mladenov</a>, 
<a href="/search/cs?searchtype=author&query=Merlis%2C+N">Nadav Merlis</a>, 
<a href="/search/cs?searchtype=author&query=Axtell%2C+R+L">Robert L. Axtell</a>, 
<a href="/search/cs?searchtype=author&query=Boutilier%2C+C">Craig Boutilier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18497" title="Abstract">arXiv:2305.18497</a> (replaced) [<a href="/pdf/2305.18497" title="Download PDF">pdf</a>, <a href="/format/2305.18497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Learning via Prediction Consensus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+D">Dongyang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Mendler-D%C3%BCnner%2C+C">Celestine Mendler-D&#xfc;nner</a>, 
<a href="/search/cs?searchtype=author&query=Jaggi%2C+M">Martin Jaggi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18666" title="Abstract">arXiv:2305.18666</a> (replaced) [<a href="/pdf/2305.18666" title="Download PDF">pdf</a>, <a href="/format/2305.18666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BiSLS/SPS: Auto-tune Step Sizes for Stable Bi-level Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chen Fan</a>, 
<a href="/search/cs?searchtype=author&query=Chon%C3%A9-Ducasse%2C+G">Gaspard Chon&#xe9;-Ducasse</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+M">Mark Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Thrampoulidis%2C+C">Christos Thrampoulidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18832" title="Abstract">arXiv:2305.18832</a> (replaced) [<a href="/pdf/2305.18832" title="Download PDF">pdf</a>, <a href="/format/2305.18832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReTR: Modeling Rendering Via Transformer for Generalizable Neural  Surface Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yixun Liang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">Hao He</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Ying-cong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 11 Figures, Our code will be released at <a href="https://github.com/YixunLiang/ReTR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19913" title="Abstract">arXiv:2305.19913</a> (replaced) [<a href="/pdf/2305.19913" title="Download PDF">pdf</a>, <a href="/format/2305.19913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representation Equivalent Neural Operators: a Framework for Alias-free  Operator Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bartolucci%2C+F">Francesca Bartolucci</a>, 
<a href="/search/cs?searchtype=author&query=de+B%C3%A9zenac%2C+E">Emmanuel de B&#xe9;zenac</a>, 
<a href="/search/cs?searchtype=author&query=Raoni%C4%87%2C+B">Bogdan Raoni&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Molinaro%2C+R">Roberto Molinaro</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Siddhartha Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Alaifari%2C+R">Rima Alaifari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01140" title="Abstract">arXiv:2306.01140</a> (replaced) [<a href="/pdf/2306.01140" title="Download PDF">pdf</a>, <a href="/format/2306.01140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A space-time discontinuous Galerkin method for coupled  poroelasticity-elasticity problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Antonietti%2C+P+F">Paola F. Antonietti</a>, 
<a href="/search/math?searchtype=author&query=Botti%2C+M">Michele Botti</a>, 
<a href="/search/math?searchtype=author&query=Mazzieri%2C+I">Ilario Mazzieri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03698" title="Abstract">arXiv:2306.03698</a> (replaced) [<a href="/pdf/2306.03698" title="Download PDF">pdf</a>, <a href="/format/2306.03698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-grained Expressivity of Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%B6ker%2C+J">Jan B&#xf6;ker</a>, 
<a href="/search/cs?searchtype=author&query=Levie%2C+R">Ron Levie</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+N">Ningyuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Villar%2C+S">Soledad Villar</a>, 
<a href="/search/cs?searchtype=author&query=Morris%2C+C">Christopher Morris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Discrete Mathematics (cs.DM); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04532" title="Abstract">arXiv:2306.04532</a> (replaced) [<a href="/pdf/2306.04532" title="Download PDF">pdf</a>, <a href="/format/2306.04532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long Sequence Hopfield Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaudhry%2C+H+T">Hamza Tahir Chaudhry</a>, 
<a href="/search/cs?searchtype=author&query=Zavatone-Veth%2C+J+A">Jacob A. Zavatone-Veth</a>, 
<a href="/search/cs?searchtype=author&query=Krotov%2C+D">Dmitry Krotov</a>, 
<a href="/search/cs?searchtype=author&query=Pehlevan%2C+C">Cengiz Pehlevan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Camera-Ready, 41 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Advances in Neural Information Processing Systems 36 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04699" title="Abstract">arXiv:2306.04699</a> (replaced) [<a href="/pdf/2306.04699" title="Download PDF">pdf</a>, <a href="/format/2306.04699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiViNeT: 3D Reconstruction from Disparate Views via Neural Template  Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vora%2C+A">Aditya Vora</a>, 
<a href="/search/cs?searchtype=author&query=Patil%2C+A+G">Akshay Gadi Patil</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be presented at NeurIPS, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05225" title="Abstract">arXiv:2306.05225</a> (replaced) [<a href="/pdf/2306.05225" title="Download PDF">pdf</a>, <a href="/format/2306.05225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Adversarial Transferability by Achieving Flat Local Maxima
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+Z">Zhijin Ge</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaosen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+F">Fanhua Shang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanyuan Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07684" title="Abstract">arXiv:2306.07684</a> (replaced) [<a href="/pdf/2306.07684" title="Download PDF">pdf</a>, <a href="/format/2306.07684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lookaround Optimizer: $k$ steps around, 1 step average
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiangtao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shunyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jie Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Tongtian Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhengqi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Mingli Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07962" title="Abstract">arXiv:2306.07962</a> (replaced) [<a href="/pdf/2306.07962" title="Download PDF">pdf</a>, <a href="/format/2306.07962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parting with Misconceptions about Learning-based Vehicle Motion Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dauner%2C+D">Daniel Dauner</a>, 
<a href="/search/cs?searchtype=author&query=Hallgarten%2C+M">Marcel Hallgarten</a>, 
<a href="/search/cs?searchtype=author&query=Geiger%2C+A">Andreas Geiger</a>, 
<a href="/search/cs?searchtype=author&query=Chitta%2C+K">Kashyap Chitta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CoRL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08129" title="Abstract">arXiv:2306.08129</a> (replaced) [<a href="/pdf/2306.08129" title="Download PDF">pdf</a>, <a href="/format/2306.08129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AVIS: Autonomous Visual Information Seeking with Large Language Model  Agent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Ziniu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Iscen%2C+A">Ahmet Iscen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Chen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kai-Wei Chang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yizhou Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ross%2C+D+A">David A Ross</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+C">Cordelia Schmid</a>, 
<a href="/search/cs?searchtype=author&query=Fathi%2C+A">Alireza Fathi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published on NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08153" title="Abstract">arXiv:2306.08153</a> (replaced) [<a href="/pdf/2306.08153" title="Download PDF">pdf</a>, <a href="/format/2306.08153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> (Amplified) Banded Matrix Factorization: A unified approach to private  training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choquette-Choo%2C+C+A">Christopher A. Choquette-Choo</a>, 
<a href="/search/cs?searchtype=author&query=Ganesh%2C+A">Arun Ganesh</a>, 
<a href="/search/cs?searchtype=author&query=McKenna%2C+R">Ryan McKenna</a>, 
<a href="/search/cs?searchtype=author&query=McMahan%2C+H+B">H. Brendan McMahan</a>, 
<a href="/search/cs?searchtype=author&query=Rush%2C+K">Keith Rush</a>, 
<a href="/search/cs?searchtype=author&query=Thakurta%2C+A">Abhradeep Thakurta</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zheng Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08288" title="Abstract">arXiv:2306.08288</a> (replaced) [<a href="/pdf/2306.08288" title="Download PDF">pdf</a>, <a href="/format/2306.08288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> System Information Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+A">Aobo Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+B">Bing Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+O">Ou Deng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mingzhe Yang</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+A">Andrew Clark</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09750" title="Abstract">arXiv:2306.09750</a> (replaced) [<a href="/pdf/2306.09750" title="Download PDF">pdf</a>, <a href="/format/2306.09750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fedstellar: A Platform for Decentralized Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beltr%C3%A1n%2C+E+T+M">Enrique Tom&#xe1;s Mart&#xed;nez Beltr&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez%2C+%C3%81+L+P">&#xc1;ngel Luis Perales G&#xf3;mez</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chao Feng</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez%2C+P+M+S">Pedro Miguel S&#xe1;nchez S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Bernal%2C+S+L">Sergio L&#xf3;pez Bernal</a>, 
<a href="/search/cs?searchtype=author&query=Bovet%2C+G">G&#xe9;r&#xf4;me Bovet</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+M+G">Manuel Gil P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+G+M">Gregorio Mart&#xed;nez P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Celdr%C3%A1n%2C+A+H">Alberto Huertas Celdr&#xe1;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10296" title="Abstract">arXiv:2306.10296</a> (replaced) [<a href="/pdf/2306.10296" title="Download PDF">pdf</a>, <a href="/format/2306.10296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenSBT: A Modular Framework for Search-based Testing of Automated  Driving Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sorokin%2C+L">Lev Sorokin</a>, 
<a href="/search/cs?searchtype=author&query=Munaro%2C+T">Tiziano Munaro</a>, 
<a href="/search/cs?searchtype=author&query=Safin%2C+D">Damir Safin</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+B+H">Brian Hsuan-Cheng Liao</a>, 
<a href="/search/cs?searchtype=author&query=Molin%2C+A">Adam Molin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10681" title="Abstract">arXiv:2306.10681</a> (replaced) [<a href="/pdf/2306.10681" title="Download PDF">pdf</a>, <a href="/format/2306.10681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VNVC: A Versatile Neural Video Coding Framework for Efficient  Human-Machine Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sheng%2C+X">Xihua Sheng</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+D">Dong Liu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Houqiang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12317" title="Abstract">arXiv:2306.12317</a> (replaced) [<a href="/pdf/2306.12317" title="Download PDF">pdf</a>, <a href="/format/2306.12317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterated Piecewise Affine (IPA) Approximation for Language Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shamsi%2C+D">Davood Shamsi</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+W">Wen-yu Hua</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+B">Brian Williams</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12658" title="Abstract">arXiv:2306.12658</a> (replaced) [<a href="/pdf/2306.12658" title="Download PDF">pdf</a>, <a href="/format/2306.12658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fitted Value Iteration Methods for Bicausal Optimal Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bayraktar%2C+E">Erhan Bayraktar</a>, 
<a href="/search/stat?searchtype=author&query=Han%2C+B">Bingyan Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Mathematical Finance (q-fin.MF)

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15111" title="Abstract">arXiv:2306.15111</a> (replaced) [<a href="/pdf/2306.15111" title="Download PDF">pdf</a>, <a href="/format/2306.15111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Image Captioning with CLIP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Chuanyang Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Self-Supervised Learning Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15668" title="Abstract">arXiv:2306.15668</a> (replaced) [<a href="/pdf/2306.15668" title="Download PDF">pdf</a>, <a href="/format/2306.15668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physion++: Evaluating Physical Scene Understanding that Requires Online  Inference of Different Physical Properties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tung%2C+H">Hsiao-Yu Tung</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Mingyu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenfang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bear%2C+D">Daniel Bear</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chuang Gan</a>, 
<a href="/search/cs?searchtype=author&query=Tenenbaum%2C+J+B">Joshua B. Tenenbaum</a>, 
<a href="/search/cs?searchtype=author&query=Yamins%2C+D+L">Daniel LK Yamins</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J+E">Judith E Fan</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+K+A">Kevin A. Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023 Datasets and Benchmarks Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16180" title="Abstract">arXiv:2306.16180</a> (replaced) [<a href="/pdf/2306.16180" title="Download PDF">pdf</a>, <a href="/format/2306.16180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pseudo-Bag Mixup Augmentation for Multiple Instance Learning-Based Whole  Slide Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Pei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+L">Luping Ji</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+F">Feng Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures, 10 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17820" title="Abstract">arXiv:2306.17820</a> (replaced) [<a href="/pdf/2306.17820" title="Download PDF">pdf</a>, <a href="/format/2306.17820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-Reasoning: Semantics-Symbol Deconstruction For Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhuosheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02028" title="Abstract">arXiv:2307.02028</a> (replaced) [<a href="/pdf/2307.02028" title="Download PDF">pdf</a>, <a href="/format/2307.02028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EHRSHOT: An EHR Benchmark for Few-Shot Evaluation of Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wornow%2C+M">Michael Wornow</a>, 
<a href="/search/cs?searchtype=author&query=Thapa%2C+R">Rahul Thapa</a>, 
<a href="/search/cs?searchtype=author&query=Steinberg%2C+E">Ethan Steinberg</a>, 
<a href="/search/cs?searchtype=author&query=Fries%2C+J+A">Jason A. Fries</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+N+H">Nigam H. Shah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02598" title="Abstract">arXiv:2307.02598</a> (replaced) [<a href="/pdf/2307.02598" title="Download PDF">pdf</a>, <a href="/format/2307.02598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Additive Decoders for Latent Variables Identification and  Cartesian-Product Extrapolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lachapelle%2C+S">S&#xe9;bastien Lachapelle</a>, 
<a href="/search/cs?searchtype=author&query=Mahajan%2C+D">Divyat Mahajan</a>, 
<a href="/search/cs?searchtype=author&query=Mitliagkas%2C+I">Ioannis Mitliagkas</a>, 
<a href="/search/cs?searchtype=author&query=Lacoste-Julien%2C+S">Simon Lacoste-Julien</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in: Advances in Neural Information Processing Systems 37 (NeurIPS 2023). 39 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02729" title="Abstract">arXiv:2307.02729</a> (replaced) [<a href="/pdf/2307.02729" title="Download PDF">pdf</a>, <a href="/format/2307.02729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text Alignment Is An Efficient Unified Model for Massive NLP Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zha%2C+Y">Yuheng Zha</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yichi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruichen Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhiting Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Camera Ready, Code available at <a href="https://github.com/yuh-zha/Align">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03486" title="Abstract">arXiv:2307.03486</a> (replaced) [<a href="/pdf/2307.03486" title="Download PDF">pdf</a>, <a href="/format/2307.03486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering Hierarchical Achievements in Reinforcement Learning via  Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moon%2C+S">Seungyong Moon</a>, 
<a href="/search/cs?searchtype=author&query=Yeom%2C+J">Junyoung Yeom</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+B">Bumsoo Park</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H+O">Hyun Oh Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05973" title="Abstract">arXiv:2307.05973</a> (replaced) [<a href="/pdf/2307.05973" title="Download PDF">pdf</a>, <a href="/format/2307.05973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VoxPoser: Composable 3D Value Maps for Robotic Manipulation with  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenlong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruohan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunzhu Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Fei-Fei%2C+L">Li Fei-Fei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06435" title="Abstract">arXiv:2307.06435</a> (replaced) [<a href="/pdf/2307.06435" title="Download PDF">pdf</a>, <a href="/format/2307.06435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Overview of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naveed%2C+H">Humza Naveed</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A+U">Asad Ullah Khan</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+S">Shi Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Saqib%2C+M">Muhammad Saqib</a>, 
<a href="/search/cs?searchtype=author&query=Anwar%2C+S">Saeed Anwar</a>, 
<a href="/search/cs?searchtype=author&query=Usman%2C+M">Muhammad Usman</a>, 
<a href="/search/cs?searchtype=author&query=Akhtar%2C+N">Naveed Akhtar</a>, 
<a href="/search/cs?searchtype=author&query=Barnes%2C+N">Nick Barnes</a>, 
<a href="/search/cs?searchtype=author&query=Mian%2C+A">Ajmal Mian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in-progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07050" title="Abstract">arXiv:2307.07050</a> (replaced) [<a href="/pdf/2307.07050" title="Download PDF">pdf</a>, <a href="/format/2307.07050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wasserstein Quantum Monte Carlo: A Novel Approach for Solving the  Quantum Many-Body Schr&#xf6;dinger Equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Neklyudov%2C+K">Kirill Neklyudov</a>, 
<a href="/search/physics?searchtype=author&query=Nys%2C+J">Jannes Nys</a>, 
<a href="/search/physics?searchtype=author&query=Thiede%2C+L">Luca Thiede</a>, 
<a href="/search/physics?searchtype=author&query=Carrasquilla%2C+J">Juan Carrasquilla</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+Q">Qiang Liu</a>, 
<a href="/search/physics?searchtype=author&query=Welling%2C+M">Max Welling</a>, 
<a href="/search/physics?searchtype=author&query=Makhzani%2C+A">Alireza Makhzani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Machine Learning (cs.LG); Chemical Physics (physics.chem-ph)

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07439" title="Abstract">arXiv:2307.07439</a> (replaced) [<a href="/pdf/2307.07439" title="Download PDF">pdf</a>, <a href="/format/2307.07439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Atlas-Based Interpretable Age Prediction In Whole-Body MR Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Starck%2C+S">Sophie Starck</a>, 
<a href="/search/eess?searchtype=author&query=Kini%2C+Y+V">Yadunandan Vivekanand Kini</a>, 
<a href="/search/eess?searchtype=author&query=Ritter%2C+J+J+M">Jessica Johanna Maria Ritter</a>, 
<a href="/search/eess?searchtype=author&query=Braren%2C+R">Rickmer Braren</a>, 
<a href="/search/eess?searchtype=author&query=Rueckert%2C+D">Daniel Rueckert</a>, 
<a href="/search/eess?searchtype=author&query=Mueller%2C+T">Tamara Mueller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10829" title="Abstract">arXiv:2307.10829</a> (replaced) [<a href="/pdf/2307.10829" title="Download PDF">pdf</a>, <a href="/format/2307.10829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact Diffusion Inversion via Bi-directional Integration Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guoqiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lewis%2C+J+P">J. P. Lewis</a>, 
<a href="/search/cs?searchtype=author&query=Kleijn%2C+W+B">W. Bastiaan Kleijn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2304.11328">arXiv:2304.11328</a>. Our code is available at <a href="https://github.com/guoqiang-zhang-x/BDIA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10943" title="Abstract">arXiv:2307.10943</a> (replaced) [<a href="/pdf/2307.10943" title="Download PDF">pdf</a>, <a href="/format/2307.10943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proxy Anchor-based Unsupervised Learning for Continuous Generalized  Category Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyungmin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Suh%2C+S">Sungho Suh</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Daehwan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+D">Daun Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+H">Hansang Cho</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Junmo Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12776" title="Abstract">arXiv:2307.12776</a> (replaced) [<a href="/pdf/2307.12776" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predict-AI-bility of how humans balance self-interest with the interest  of others
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Capraro%2C+V">Valerio Capraro</a>, 
<a href="/search/econ?searchtype=author&query=Di+Paolo%2C+R">Roberto Di Paolo</a>, 
<a href="/search/econ?searchtype=author&query=Pizziol%2C+V">Veronica Pizziol</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13601" title="Abstract">arXiv:2307.13601</a> (replaced) [<a href="/pdf/2307.13601" title="Download PDF">pdf</a>, <a href="/format/2307.13601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Importance of Distrust in AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peters%2C+T+M">Tobias M. Peters</a>, 
<a href="/search/cs?searchtype=author&query=Visser%2C+R+W">Roel W. Visser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This preprint has not undergone peer review or any post-submission improvements or corrections. The version of records of this contribution is published in Explainable Artificial Intelligence First World Conference, xAI 2023, Lisbon, Portugal, July 26-28, 2023, Proceedings, Part III (CCIS, volume 1903) and is available at <a href="https://doi.org/10.1007/978-3-031-44070-0">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Explainable Artificial Intelligence First World Conference, xAI
  2023, Lisbon, Portugal, July 26-28, 2023, Proceedings, Part III (CCIS, volume
  1903)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14837" title="Abstract">arXiv:2307.14837</a> (replaced) [<a href="/pdf/2307.14837" title="Download PDF">pdf</a>, <a href="/format/2307.14837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DNN-MG: A Hybrid Neural Network/Finite Element Method with Applications  to 3D Simulations of the Navier-Stokes Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Margenberg%2C+N">Nils Margenberg</a>, 
<a href="/search/math?searchtype=author&query=Jendersie%2C+R">Robert Jendersie</a>, 
<a href="/search/math?searchtype=author&query=Lessig%2C+C">Christian Lessig</a>, 
<a href="/search/math?searchtype=author&query=Richter%2C+T">Thomas Richter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 24 figures, 11 tables. Submitted to Computer Methods in Applied Mechanics and Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00547" title="Abstract">arXiv:2308.00547</a> (replaced) [<a href="/pdf/2308.00547" title="Download PDF">pdf</a>, <a href="/format/2308.00547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure Preserving Polytopal Discontinuous Galerkin Methods for the  Numerical Modeling of Neurodegenerative Diseases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Corti%2C+M">Mattia Corti</a>, 
<a href="/search/math?searchtype=author&query=Bonizzoni%2C+F">Francesca Bonizzoni</a>, 
<a href="/search/math?searchtype=author&query=Antonietti%2C+P+F">Paola F. Antonietti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01024" title="Abstract">arXiv:2308.01024</a> (replaced) [<a href="/pdf/2308.01024" title="Download PDF">pdf</a>, <a href="/format/2308.01024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-Matrix Domain-Wall: A Novel Technique for Generating Permutations  by QUBO and Ising Models with Quadratic Sizes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nakano%2C+K">Koji Nakano</a>, 
<a href="/search/cs?searchtype=author&query=Tsukiyama%2C+S">Shunsuke Tsukiyama</a>, 
<a href="/search/cs?searchtype=author&query=Ito%2C+Y">Yasuaki Ito</a>, 
<a href="/search/cs?searchtype=author&query=Yazane%2C+T">Takashi Yazane</a>, 
<a href="/search/cs?searchtype=author&query=Yano%2C+J">Junko Yano</a>, 
<a href="/search/cs?searchtype=author&query=Kato%2C+T">Takumi Kato</a>, 
<a href="/search/cs?searchtype=author&query=Ozaki%2C+S">Shiro Ozaki</a>, 
<a href="/search/cs?searchtype=author&query=Mori%2C+R">Rie Mori</a>, 
<a href="/search/cs?searchtype=author&query=Katsuki%2C+R">Ryota Katsuki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02453" title="Abstract">arXiv:2308.02453</a> (replaced) [<a href="/pdf/2308.02453" title="Download PDF">pdf</a>, <a href="/format/2308.02453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Getting the Ball Rolling: Learning a Dexterous Policy for a Biomimetic  Tendon-Driven Hand with Rolling Contact Joints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Toshimitsu%2C+Y">Yasunori Toshimitsu</a>, 
<a href="/search/cs?searchtype=author&query=Forrai%2C+B">Benedek Forrai</a>, 
<a href="/search/cs?searchtype=author&query=Cangan%2C+B+G">Barnabas Gavin Cangan</a>, 
<a href="/search/cs?searchtype=author&query=Steger%2C+U">Ulrich Steger</a>, 
<a href="/search/cs?searchtype=author&query=Knecht%2C+M">Manuel Knecht</a>, 
<a href="/search/cs?searchtype=author&query=Weirich%2C+S">Stefan Weirich</a>, 
<a href="/search/cs?searchtype=author&query=Katzschmann%2C+R+K">Robert K. Katzschmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> for project website, see <a href="https://srl-ethz.github.io/get-ball-rolling/">this https URL</a> . for video, see <a href="https://youtu.be/YahsMhqNU8o">this https URL</a> . for code, see <a href="https://github.com/srl-ethz/faive_gym_oss">this https URL</a> . Accepted to the 2023 IEEE-RAS International Conference on Humanoid Robots
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03900" title="Abstract">arXiv:2308.03900</a> (replaced) [<a href="/pdf/2308.03900" title="Download PDF">pdf</a>, <a href="/format/2308.03900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Developability Approximation for Neural Implicits through Rank  Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Selvaraju%2C+P">Pratheba Selvaraju</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted-3DV(2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06534" title="Abstract">arXiv:2308.06534</a> (replaced) [<a href="/pdf/2308.06534" title="Download PDF">pdf</a>, <a href="/format/2308.06534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Pre-Training with Contrastive and Masked Autoencoder  Methods for Dealing with Small Datasets in Deep Learning for Medical Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wolf%2C+D">Daniel Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Payer%2C+T">Tristan Payer</a>, 
<a href="/search/cs?searchtype=author&query=Lisson%2C+C+S">Catharina Silvia Lisson</a>, 
<a href="/search/cs?searchtype=author&query=Lisson%2C+C+G">Christoph Gerhard Lisson</a>, 
<a href="/search/cs?searchtype=author&query=Beer%2C+M">Meinrad Beer</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B6tz%2C+M">Michael G&#xf6;tz</a>, 
<a href="/search/cs?searchtype=author&query=Ropinski%2C+T">Timo Ropinski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Nature Scientific Reports
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07843" title="Abstract">arXiv:2308.07843</a> (replaced) [<a href="/pdf/2308.07843" title="Download PDF">pdf</a>, <a href="/format/2308.07843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dyadic Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuangning Li</a>, 
<a href="/search/cs?searchtype=author&query=Niell%2C+L+S">Lluis Salvat Niell</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S+W">Sung Won Choi</a>, 
<a href="/search/cs?searchtype=author&query=Nahum-Shani%2C+I">Inbal Nahum-Shani</a>, 
<a href="/search/cs?searchtype=author&query=Shani%2C+G">Guy Shani</a>, 
<a href="/search/cs?searchtype=author&query=Murphy%2C+S">Susan Murphy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08133" title="Abstract">arXiv:2308.08133</a> (replaced) [<a href="/pdf/2308.08133" title="Download PDF">pdf</a>, <a href="/ps/2308.08133" title="Download PostScript">ps</a>, <a href="/format/2308.08133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating the probe and singular sources methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ikehata%2C+M">Masaru Ikehata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10068" title="Abstract">arXiv:2308.10068</a> (replaced) [<a href="/pdf/2308.10068" title="Download PDF">pdf</a>, <a href="/format/2308.10068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ILCAS: Imitation Learning-Based Configuration-Adaptive Streaming for  Live Video Analytics with Cross-Camera Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Duo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dayou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Miao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruoyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fangxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shuguang Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article has been accepted for publication in IEEE Transactions on Mobile Computing. Citation information: DOI 10.1109/TMC.2023.3327097
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11809" title="Abstract">arXiv:2308.11809</a> (replaced) [<a href="/pdf/2308.11809" title="Download PDF">pdf</a>, <a href="/format/2308.11809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expressive probabilistic sampling in recurrent neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+S">Shirui Chen</a>, 
<a href="/search/q-bio?searchtype=author&query=Jiang%2C+L+P">Linxin Preston Jiang</a>, 
<a href="/search/q-bio?searchtype=author&query=Rao%2C+R+P+N">Rajesh P. N. Rao</a>, 
<a href="/search/q-bio?searchtype=author&query=Shea-Brown%2C+E">Eric Shea-Brown</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16741" title="Abstract">arXiv:2308.16741</a> (replaced) [<a href="/pdf/2308.16741" title="Download PDF">pdf</a>, <a href="/format/2308.16741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Socratis: Are large multimodal models emotionally aware?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+K">Katherine Deng</a>, 
<a href="/search/cs?searchtype=author&query=Ray%2C+A">Arijit Ray</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+R">Reuben Tan</a>, 
<a href="/search/cs?searchtype=author&query=Gabriel%2C+S">Saadia Gabriel</a>, 
<a href="/search/cs?searchtype=author&query=Plummer%2C+B+A">Bryan A. Plummer</a>, 
<a href="/search/cs?searchtype=author&query=Saenko%2C+K">Kate Saenko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 WECIA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00174" title="Abstract">arXiv:2309.00174</a> (replaced) [<a href="/pdf/2309.00174" title="Download PDF">pdf</a>, <a href="/format/2309.00174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Typing on Any Surface: A Deep Learning-based Method for Real-Time  Keystroke Detection in Augmented Reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xingyu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+M">Mingze Xi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00733" title="Abstract">arXiv:2309.00733</a> (replaced) [<a href="/pdf/2309.00733" title="Download PDF">pdf</a>, <a href="/format/2309.00733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learned Visual Features to Textual Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taghanaki%2C+S+A">Saeid Asgari Taghanaki</a>, 
<a href="/search/cs?searchtype=author&query=Khani%2C+A">Aliasghar Khani</a>, 
<a href="/search/cs?searchtype=author&query=Khasahmadi%2C+A">Amir Khasahmadi</a>, 
<a href="/search/cs?searchtype=author&query=Sanghi%2C+A">Aditya Sanghi</a>, 
<a href="/search/cs?searchtype=author&query=Willis%2C+K+D+D">Karl D.D. Willis</a>, 
<a href="/search/cs?searchtype=author&query=Mahdavi-Amiri%2C+A">Ali Mahdavi-Amiri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01267" title="Abstract">arXiv:2309.01267</a> (replaced) [<a href="/pdf/2309.01267" title="Download PDF">pdf</a>, <a href="/format/2309.01267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deception Game: Closing the Safety-Learning Loop in Interactive Robot  Autonomy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Haimin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zixu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nakamura%2C+K">Kensuke Nakamura</a>, 
<a href="/search/cs?searchtype=author&query=Bajcsy%2C+A">Andrea Bajcsy</a>, 
<a href="/search/cs?searchtype=author&query=Fisac%2C+J+F">Jaime F. Fisac</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference on Robot Learning 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01456" title="Abstract">arXiv:2309.01456</a> (replaced) [<a href="/pdf/2309.01456" title="Download PDF">pdf</a>, <a href="/format/2309.01456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM and Infrastructure as a Code use case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chanus%2C+T">Thibault Chanus</a> (ENS Rennes), 
<a href="/search/cs?searchtype=author&query=Aubertin%2C+M">Michael Aubertin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01632" title="Abstract">arXiv:2309.01632</a> (replaced) [<a href="/pdf/2309.01632" title="Download PDF">pdf</a>, <a href="/format/2309.01632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representing Edge Flows on Graphs via Sparse Cell Complexes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoppe%2C+J">Josef Hoppe</a>, 
<a href="/search/cs?searchtype=author&query=Schaub%2C+M+T">Michael T. Schaub</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures (plus appendix). For evaluation code, see <a href="https://github.com/josefhoppe/edge-flow-cell-complexes">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01859" title="Abstract">arXiv:2309.01859</a> (replaced) [<a href="/pdf/2309.01859" title="Download PDF">pdf</a>, <a href="/format/2309.01859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NLLB-CLIP -- train performant multilingual image retrieval model on a  budget
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Visheratin%2C+A">Alexander Visheratin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02629" title="Abstract">arXiv:2309.02629</a> (replaced) [<a href="/pdf/2309.02629" title="Download PDF">pdf</a>, <a href="/format/2309.02629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Search for a Moving and Camouflaging Target
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lejeune%2C+M">Miguel Lejeune</a>, 
<a href="/search/math?searchtype=author&query=Royset%2C+J+O">Johannes O. Royset</a>, 
<a href="/search/math?searchtype=author&query=Ma%2C+W">Wenbo Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04037" title="Abstract">arXiv:2309.04037</a> (replaced) [<a href="/pdf/2309.04037" title="Download PDF">pdf</a>, <a href="/format/2309.04037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SRN-SZ: Deep Leaning-Based Scientific Error-bounded Lossy Compression  with Super-resolution Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+S">Sheng Di</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Sian Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xin Liang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zizhong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cappello%2C+F">Franck Cappello</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04316" title="Abstract">arXiv:2309.04316</a> (replaced) [<a href="/pdf/2309.04316" title="Download PDF">pdf</a>, <a href="/format/2309.04316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incremental Learning of Humanoid Robot Behavior from Natural Interaction  and Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%A4rmann%2C+L">Leonard B&#xe4;rmann</a>, 
<a href="/search/cs?searchtype=author&query=Kartmann%2C+R">Rainer Kartmann</a>, 
<a href="/search/cs?searchtype=author&query=Peller-Konrad%2C+F">Fabian Peller-Konrad</a>, 
<a href="/search/cs?searchtype=author&query=Waibel%2C+A">Alex Waibel</a>, 
<a href="/search/cs?searchtype=author&query=Asfour%2C+T">Tamim Asfour</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the Workshop on Language and Robot Learning (LangRob) at the Conference on Robot Learning (CoRL) 2023. Supplementary video available at <a href="https://youtu.be/y5O2mRGtsLM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05090" title="Abstract">arXiv:2309.05090</a> (replaced) [<a href="/pdf/2309.05090" title="Download PDF">pdf</a>, <a href="/format/2309.05090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sculpting Efficiency: Pruning Medical Imaging Models for On-Device  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sreeram%2C+S">Sudarshan Sreeram</a>, 
<a href="/search/cs?searchtype=author&query=Kainz%2C+B">Bernhard Kainz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at MedNeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05183" title="Abstract">arXiv:2309.05183</a> (replaced) [<a href="/pdf/2309.05183" title="Download PDF">pdf</a>, <a href="/ps/2309.05183" title="Download PostScript">ps</a>, <a href="/format/2309.05183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Summarization beyond Monotonicity: Non-monotone Two-Stage  Submodular Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shaojie Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In this version, we have addressed several typos and corrected flaws in the proof
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11389" title="Abstract">arXiv:2309.11389</a> (replaced) [<a href="/pdf/2309.11389" title="Download PDF">pdf</a>, <a href="/format/2309.11389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Level set-fitted polytopal meshes with application to structural  topology optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferro%2C+N">Nicola Ferro</a>, 
<a href="/search/cs?searchtype=author&query=Micheletti%2C+S">Stefano Micheletti</a>, 
<a href="/search/cs?searchtype=author&query=Parolini%2C+N">Nicola Parolini</a>, 
<a href="/search/cs?searchtype=author&query=Perotto%2C+S">Simona Perotto</a>, 
<a href="/search/cs?searchtype=author&query=Verani%2C+M">Marco Verani</a>, 
<a href="/search/cs?searchtype=author&query=Antonietti%2C+P+F">Paola Francesca Antonietti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12148" title="Abstract">arXiv:2309.12148</a> (replaced) [<a href="/pdf/2309.12148" title="Download PDF">pdf</a>, <a href="/format/2309.12148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Modelling of Dynamic Systems with Time Delays Based on an  Adjusted NEAT Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laddach%2C+K">Krzysztof Laddach</a>, 
<a href="/search/cs?searchtype=author&query=%C5%81angowski%2C+R">Rafa&#x142; &#x141;angowski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference paper
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In: Kowalczuk, Z. (eds) Intelligent and Safe Computer Systems in
  Control and Diagnostics. DPS 2022 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12177" title="Abstract">arXiv:2309.12177</a> (replaced) [<a href="/pdf/2309.12177" title="Download PDF">pdf</a>, <a href="/format/2309.12177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Artificial Intelligence for Drug Discovery and Development  -- A Comprehensive Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alizadehsani%2C+R">Roohallah Alizadehsani</a>, 
<a href="/search/cs?searchtype=author&query=Oyelere%2C+S+S">Solomon Sunday Oyelere</a>, 
<a href="/search/cs?searchtype=author&query=Hussain%2C+S">Sadiq Hussain</a>, 
<a href="/search/cs?searchtype=author&query=Calixto%2C+R+R">Rene Ripardo Calixto</a>, 
<a href="/search/cs?searchtype=author&query=de+Albuquerque%2C+V+H+C">Victor Hugo C. de Albuquerque</a>, 
<a href="/search/cs?searchtype=author&query=Roshanzamir%2C+M">Mohamad Roshanzamir</a>, 
<a href="/search/cs?searchtype=author&query=Rahouti%2C+M">Mohamed Rahouti</a>, 
<a href="/search/cs?searchtype=author&query=Jagatheesaperumal%2C+S+K">Senthil Kumar Jagatheesaperumal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13425" title="Abstract">arXiv:2309.13425</a> (replaced) [<a href="/pdf/2309.13425" title="Download PDF">pdf</a>, <a href="/format/2309.13425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MiliPoint: A Point Cloud Dataset for mmWave Radar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+H">Han Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+S">Shu Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiacheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zichao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Dahnoun%2C+N">Naim Dahnoun</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yiren Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023 Datasets &amp; Benchmarks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13744" title="Abstract">arXiv:2309.13744</a> (replaced) [<a href="/e-print/2309.13744" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Systematic Literature Review of Computer Vision Applications in  Robotized Wire Harness Assembly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Salunkhe%2C+O">Omkar Salunkhe</a>, 
<a href="/search/cs?searchtype=author&query=Quadrini%2C+W">Walter Quadrini</a>, 
<a href="/search/cs?searchtype=author&query=Johansson%2C+B">Bj&#xf6;rn Johansson</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%A4mkull%2C+D">Dan L&#xe4;mkull</a>, 
<a href="/search/cs?searchtype=author&query=Ore%2C+F">Fredrik Ore</a>, 
<a href="/search/cs?searchtype=author&query=Despeisse%2C+M">M&#xe9;lanie Despeisse</a>, 
<a href="/search/cs?searchtype=author&query=Fumagalli%2C+L">Luca Fumagalli</a>, 
<a href="/search/cs?searchtype=author&query=Stahre%2C+J">Johan Stahre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The authors found new results from the analysis of new set of data and the article needs to be rewritten
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13745" title="Abstract">arXiv:2309.13745</a> (replaced) [<a href="/e-print/2309.13745" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computer Vision Technology for Robotized Wire Harness Assembly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Salunkhe%2C+O">Omkar Salunkhe</a>, 
<a href="/search/cs?searchtype=author&query=Quadrini%2C+W">Walter Quadrini</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%A4mkull%2C+D">Dan L&#xe4;mkull</a>, 
<a href="/search/cs?searchtype=author&query=Ore%2C+F">Fredrik Ore</a>, 
<a href="/search/cs?searchtype=author&query=Johansson%2C+B">Bj&#xf6;rn Johansson</a>, 
<a href="/search/cs?searchtype=author&query=Stahre%2C+J">Johan Stahre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The authors found new results from the analysis of new set of data and the article needs to be rewritten
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15631" title="Abstract">arXiv:2309.15631</a> (replaced) [<a href="/pdf/2309.15631" title="Download PDF">pdf</a>, <a href="/format/2309.15631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and Optimization of Residual Neural Network Accelerators for  Low-Power FPGAs Using High-Level Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Minnella%2C+F">Filippo Minnella</a>, 
<a href="/search/cs?searchtype=author&query=Urso%2C+T">Teodoro Urso</a>, 
<a href="/search/cs?searchtype=author&query=Lazarescu%2C+M+T">Mihai T. Lazarescu</a>, 
<a href="/search/cs?searchtype=author&query=Lavagno%2C+L">Luciano Lavagno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00402" title="Abstract">arXiv:2310.00402</a> (replaced) [<a href="/pdf/2310.00402" title="Download PDF">pdf</a>, <a href="/format/2310.00402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiskANN++: Efficient Page-based Search over Isomorphic Mapped Graph  Index using Query-sensitivity Entry Vertex
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+J">Jiongkang Ni</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaoliang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Can Li</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiajie Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+S">Shihai Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuecang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages including references, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00806" title="Abstract">arXiv:2310.00806</a> (replaced) [<a href="/pdf/2310.00806" title="Download PDF">pdf</a>, <a href="/format/2310.00806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Design Principles for Frequentist Sequential Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yunbei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zeevi%2C+A">Assaf Zeevi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01641" title="Abstract">arXiv:2310.01641</a> (replaced) [<a href="/pdf/2310.01641" title="Download PDF">pdf</a>, <a href="/format/2310.01641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> You Only Look at Once for Real-time and Generic Multi-Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiayuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q+M+J">Q. M. Jonathan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ning Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01853" title="Abstract">arXiv:2310.01853</a> (replaced) [<a href="/pdf/2310.01853" title="Download PDF">pdf</a>, <a href="/format/2310.01853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Score-based Data Assimilation for a Two-Layer Quasi-Geostrophic Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Rozet%2C+F">Fran&#xe7;ois Rozet</a>, 
<a href="/search/stat?searchtype=author&query=Louppe%2C+G">Gilles Louppe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02090" title="Abstract">arXiv:2310.02090</a> (replaced) [<a href="/pdf/2310.02090" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 1D-CapsNet-LSTM: A Deep Learning-Based Model for Multi-Step Stock Index  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sjarif%2C+N+N+A">Nilam Nur Amir Sjarif</a>, 
<a href="/search/cs?searchtype=author&query=Ibrahim%2C+R">Roslina Ibrahim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02230" title="Abstract">arXiv:2310.02230</a> (replaced) [<a href="/pdf/2310.02230" title="Download PDF">pdf</a>, <a href="/format/2310.02230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Diffusion Disentangled Representations to Mitigate Shortcuts  in Underspecified Visual Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scimeca%2C+L">Luca Scimeca</a>, 
<a href="/search/cs?searchtype=author&query=Rubinstein%2C+A">Alexander Rubinstein</a>, 
<a href="/search/cs?searchtype=author&query=Nicolicioiu%2C+A+M">Armand Mihai Nicolicioiu</a>, 
<a href="/search/cs?searchtype=author&query=Teney%2C+D">Damien Teney</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Neural Information Processing Systems(NeurIPS) 2023 - Workshop on Diffusion Models
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03047" title="Abstract">arXiv:2310.03047</a> (replaced) [<a href="/pdf/2310.03047" title="Download PDF">pdf</a>, <a href="/format/2310.03047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Modeling and Optimization of Battery Electrolyte Mixtures  Using Geometric Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Zhu%2C+S">Shang Zhu</a>, 
<a href="/search/physics?searchtype=author&query=Ramsundar%2C+B">Bharath Ramsundar</a>, 
<a href="/search/physics?searchtype=author&query=Annevelink%2C+E">Emil Annevelink</a>, 
<a href="/search/physics?searchtype=author&query=Lin%2C+H">Hongyi Lin</a>, 
<a href="/search/physics?searchtype=author&query=Dave%2C+A">Adarsh Dave</a>, 
<a href="/search/physics?searchtype=author&query=Guan%2C+P">Pin-Wen Guan</a>, 
<a href="/search/physics?searchtype=author&query=Gering%2C+K">Kevin Gering</a>, 
<a href="/search/physics?searchtype=author&query=Viswanathan%2C+V">Venkatasubramanian Viswanathan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03103" title="Abstract">arXiv:2310.03103</a> (replaced) [<a href="/pdf/2310.03103" title="Download PDF">pdf</a>, <a href="/format/2310.03103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual Prompt Tuning for Domain-Aware Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+G">Guoyizhe Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Feng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Anshul Shah</a>, 
<a href="/search/cs?searchtype=author&query=Chellappa%2C+R">Rama Chellappa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04015" title="Abstract">arXiv:2310.04015</a> (replaced) [<a href="/pdf/2310.04015" title="Download PDF">pdf</a>, <a href="/format/2310.04015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anonymous Learning via Look-Alike Clustering: A Precise Analysis of  Model Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Javanmard%2C+A">Adel Javanmard</a>, 
<a href="/search/cs?searchtype=author&query=Mirrokni%2C+V">Vahab Mirrokni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at the Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04691" title="Abstract">arXiv:2310.04691</a> (replaced) [<a href="/pdf/2310.04691" title="Download PDF">pdf</a>, <a href="/format/2310.04691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EMO: Earth Mover Distance Optimization for Auto-Regressive Language  Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Siyu Ren</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiyong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K+Q">Kenny Q. Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Instruction-tuning results updated. Code available at <a href="https://github.com/DRSY/EMO">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05377" title="Abstract">arXiv:2310.05377</a> (replaced) [<a href="/pdf/2310.05377" title="Download PDF">pdf</a>, <a href="/format/2310.05377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Evolution Strategies with Multi-Level Learning for  Large-Scale Black-Box Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+Q">Qiqi Duan</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+C">Chang Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Guochen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Minghan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yuhui Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06157" title="Abstract">arXiv:2310.06157</a> (replaced) [<a href="/pdf/2310.06157" title="Download PDF">pdf</a>, <a href="/format/2310.06157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Manifold-augmented Eikonal Equations: Geodesic Distances and Flows on  Differentiable Manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kelshaw%2C+D">Daniel Kelshaw</a>, 
<a href="/search/cs?searchtype=author&query=Magri%2C+L">Luca Magri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023: Symmetry and Geometry in Neural Representations Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06403" title="Abstract">arXiv:2310.06403</a> (replaced) [<a href="/pdf/2310.06403" title="Download PDF">pdf</a>, <a href="/format/2310.06403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boundary Discretization and Reliable Classification Network for Temporal  Action Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhenying Fang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07651" title="Abstract">arXiv:2310.07651</a> (replaced) [<a href="/pdf/2310.07651" title="Download PDF">pdf</a>, <a href="/format/2310.07651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polytopal discontinuous Galerkin discretization of brain multiphysics  flow dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fumagalli%2C+I">Ivan Fumagalli</a>, 
<a href="/search/math?searchtype=author&query=Corti%2C+M">Mattia Corti</a>, 
<a href="/search/math?searchtype=author&query=Parolini%2C+N">Nicola Parolini</a>, 
<a href="/search/math?searchtype=author&query=Antonietti%2C+P+F">Paola F. Antonietti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Biological Physics (physics.bio-ph)

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09259" title="Abstract">arXiv:2310.09259</a> (replaced) [<a href="/pdf/2310.09259" title="Download PDF">pdf</a>, <a href="/format/2310.09259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QUIK: Towards End-to-End 4-Bit Inference on Generative Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ashkboos%2C+S">Saleh Ashkboos</a>, 
<a href="/search/cs?searchtype=author&query=Markov%2C+I">Ilia Markov</a>, 
<a href="/search/cs?searchtype=author&query=Frantar%2C+E">Elias Frantar</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+T">Tingxuan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xincheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jie Ren</a>, 
<a href="/search/cs?searchtype=author&query=Hoefler%2C+T">Torsten Hoefler</a>, 
<a href="/search/cs?searchtype=author&query=Alistarh%2C+D">Dan Alistarh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09874" title="Abstract">arXiv:2310.09874</a> (replaced) [<a href="/pdf/2310.09874" title="Download PDF">pdf</a>, <a href="/format/2310.09874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Large Language Models (LLMs) to Empower Training-Free Dataset  Condensation for Content-Based Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiahao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qijiong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hengchang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+W">Wenqi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shengcai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiao-Ming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+K">Ke Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10030" title="Abstract">arXiv:2310.10030</a> (replaced) [<a href="/pdf/2310.10030" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unraveling Fundamental Properties of Power System Resilience Curves  using Unsupervised Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Mostafavi%2C+A">Ali Mostafavi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10702" title="Abstract">arXiv:2310.10702</a> (replaced) [<a href="/pdf/2310.10702" title="Download PDF">pdf</a>, <a href="/format/2310.10702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transparent Anomaly Detection via Concept-based Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sevyeri%2C+L+R">Laya Rafiee Sevyeri</a>, 
<a href="/search/cs?searchtype=author&query=Sheth%2C+I">Ivaxi Sheth</a>, 
<a href="/search/cs?searchtype=author&query=Farahnak%2C+F">Farhood Farahnak</a>, 
<a href="/search/cs?searchtype=author&query=Kahou%2C+S+E">Samira Ebrahimi Kahou</a>, 
<a href="/search/cs?searchtype=author&query=Enger%2C+S+A">Shirin Abbasinejad Enger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Neurips XAI in Action workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11778" title="Abstract">arXiv:2310.11778</a> (replaced) [<a href="/pdf/2310.11778" title="Download PDF">pdf</a>, <a href="/format/2310.11778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Agents for Detecting Implicit Stereotypes in Text-to-image  Models at Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qichao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+T">Tian Bian</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yian Yin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tingyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hong Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+H+M">Helen M. Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zibin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bingzhe Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12415" title="Abstract">arXiv:2310.12415</a> (replaced) [<a href="/pdf/2310.12415" title="Download PDF">pdf</a>, <a href="/format/2310.12415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SURE: A Visualized Failure Indexing Approach using Program Memory  Spectrum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yi Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaoyuan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Songqiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Quanming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Ruizhi Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Due to the limitation "The abstract field cannot be longer than 1,920 characters", the abstract here is shorter than that in the PDF file
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12560" title="Abstract">arXiv:2310.12560</a> (replaced) [<a href="/e-print/2310.12560" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Model Debias with Machine Unlearning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruizhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianfei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Huimin Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jianhong Bai</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+T">Tianxiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jin Hao</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J+T">Joey Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zuozhu Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We will update a new version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13018" title="Abstract">arXiv:2310.13018</a> (replaced) [<a href="/pdf/2310.13018" title="Download PDF">pdf</a>, <a href="/format/2310.13018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Getting aligned on representational alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Sucholutsky%2C+I">Ilia Sucholutsky</a>, 
<a href="/search/q-bio?searchtype=author&query=Muttenthaler%2C+L">Lukas Muttenthaler</a>, 
<a href="/search/q-bio?searchtype=author&query=Weller%2C+A">Adrian Weller</a>, 
<a href="/search/q-bio?searchtype=author&query=Peng%2C+A">Andi Peng</a>, 
<a href="/search/q-bio?searchtype=author&query=Bobu%2C+A">Andreea Bobu</a>, 
<a href="/search/q-bio?searchtype=author&query=Kim%2C+B">Been Kim</a>, 
<a href="/search/q-bio?searchtype=author&query=Love%2C+B+C">Bradley C. Love</a>, 
<a href="/search/q-bio?searchtype=author&query=Grant%2C+E">Erin Grant</a>, 
<a href="/search/q-bio?searchtype=author&query=Groen%2C+I">Iris Groen</a>, 
<a href="/search/q-bio?searchtype=author&query=Achterberg%2C+J">Jascha Achterberg</a>, 
<a href="/search/q-bio?searchtype=author&query=Tenenbaum%2C+J+B">Joshua B. Tenenbaum</a>, 
<a href="/search/q-bio?searchtype=author&query=Collins%2C+K+M">Katherine M. Collins</a>, 
<a href="/search/q-bio?searchtype=author&query=Hermann%2C+K+L">Katherine L. Hermann</a>, 
<a href="/search/q-bio?searchtype=author&query=Oktar%2C+K">Kerem Oktar</a>, 
<a href="/search/q-bio?searchtype=author&query=Greff%2C+K">Klaus Greff</a>, 
<a href="/search/q-bio?searchtype=author&query=Hebart%2C+M+N">Martin N. Hebart</a>, 
<a href="/search/q-bio?searchtype=author&query=Jacoby%2C+N">Nori Jacoby</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+Q">Qiuyi Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Marjieh%2C+R">Raja Marjieh</a>, 
<a href="/search/q-bio?searchtype=author&query=Geirhos%2C+R">Robert Geirhos</a>, 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+S">Sherol Chen</a>, 
<a href="/search/q-bio?searchtype=author&query=Kornblith%2C+S">Simon Kornblith</a>, 
<a href="/search/q-bio?searchtype=author&query=Rane%2C+S">Sunayana Rane</a>, 
<a href="/search/q-bio?searchtype=author&query=Konkle%2C+T">Talia Konkle</a>, 
<a href="/search/q-bio?searchtype=author&query=O%27Connell%2C+T+P">Thomas P. O&#x27;Connell</a>, 
<a href="/search/q-bio?searchtype=author&query=Unterthiner%2C+T">Thomas Unterthiner</a>, 
<a href="/search/q-bio?searchtype=author&query=Lampinen%2C+A+K">Andrew K. Lampinen</a>, 
<a href="/search/q-bio?searchtype=author&query=M%C3%BCller%2C+K">Klaus-Robert M&#xfc;ller</a>, 
<a href="/search/q-bio?searchtype=author&query=Toneva%2C+M">Mariya Toneva</a>, 
<a href="/search/q-bio?searchtype=author&query=Griffiths%2C+T+L">Thomas L. Griffiths</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Working paper, changes to be made in upcoming revisions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13229" title="Abstract">arXiv:2310.13229</a> (replaced) [<a href="/pdf/2310.13229" title="Download PDF">pdf</a>, <a href="/format/2310.13229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The GitHub Recent Bugs Dataset for Evaluating LLM-based Debugging  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+Y">Jae Yong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">Sungmin Kang</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+J">Juyeon Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+S">Shin Yoo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14520" title="Abstract">arXiv:2310.14520</a> (replaced) [<a href="/pdf/2310.14520" title="Download PDF">pdf</a>, <a href="/format/2310.14520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QUDEVAL: The Evaluation of Questions Under Discussion Discourse Parsing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yating Wu</a>, 
<a href="/search/cs?searchtype=author&query=Mangla%2C+R">Ritika Mangla</a>, 
<a href="/search/cs?searchtype=author&query=Durrett%2C+G">Greg Durrett</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J+J">Junyi Jessy Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera Ready for EMNLP Main Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14892" title="Abstract">arXiv:2310.14892</a> (replaced) [<a href="/pdf/2310.14892" title="Download PDF">pdf</a>, <a href="/format/2310.14892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Air-Decoding: Attribute Distribution Reconstruction for Decoding-Time  Controllable Text Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+T">Tianqi Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Quan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jingxuan Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongdong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Z">Zhendong Mao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as an EMNLP 2023 main paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16917" title="Abstract">arXiv:2310.16917</a> (replaced) [<a href="/pdf/2310.16917" title="Download PDF">pdf</a>, <a href="/format/2310.16917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MimicTouch: Learning Human&#x27;s Control Strategy with Multi-Modal Tactile  Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kelin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yunhai Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Matthew Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Ye Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at CoRL 2023 Deployable Workshop and NIPS 2023 Touch Processing Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17329" title="Abstract">arXiv:2310.17329</a> (replaced) [<a href="/pdf/2310.17329" title="Download PDF">pdf</a>, <a href="/format/2310.17329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tightening continuity bounds on entropies and bounds on quantum  capacities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Jabbour%2C+M+G">Michael G. Jabbour</a>, 
<a href="/search/quant-ph?searchtype=author&query=Datta%2C+N">Nilanjana Datta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 5 figures. v2: Removed Lemma 3 (which was already known), added some references, improved presentation and removed some calculation details
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17341" title="Abstract">arXiv:2310.17341</a> (replaced) [<a href="/pdf/2310.17341" title="Download PDF">pdf</a>, <a href="/format/2310.17341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> De-novo Chemical Reaction Generation by Means of Temporal Convolutional  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Buin%2C+A">Andrei Buin</a>, 
<a href="/search/cs?searchtype=author&query=Chiang%2C+H+Y">Hung Yi Chiang</a>, 
<a href="/search/cs?searchtype=author&query=Gadsden%2C+S+A">S. Andrew Gadsden</a>, 
<a href="/search/cs?searchtype=author&query=Alderson%2C+F+A">Faraz A. Alderson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17364" title="Abstract">arXiv:2310.17364</a> (replaced) [<a href="/pdf/2310.17364" title="Download PDF">pdf</a>, <a href="/ps/2310.17364" title="Download PostScript">ps</a>, <a href="/format/2310.17364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Adaptive Control for Uncertain Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Renganathan%2C+V">Venkatraman Renganathan</a>, 
<a href="/search/eess?searchtype=author&query=Rantzer%2C+A">Anders Rantzer</a>, 
<a href="/search/eess?searchtype=author&query=Kjellqvist%2C+O">Olle Kjellqvist</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2210.00081">arXiv:2210.00081</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17403" title="Abstract">arXiv:2310.17403</a> (replaced) [<a href="/pdf/2310.17403" title="Download PDF">pdf</a>, <a href="/format/2310.17403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detection Defenses: An Empty Promise against Adversarial Patch Attacks  on Optical Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scheurer%2C+E">Erik Scheurer</a>, 
<a href="/search/cs?searchtype=author&query=Schmalfuss%2C+J">Jenny Schmalfuss</a>, 
<a href="/search/cs?searchtype=author&query=Lis%2C+A">Alexander Lis</a>, 
<a href="/search/cs?searchtype=author&query=Bruhn%2C+A">Andr&#xe9;s Bruhn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17490" title="Abstract">arXiv:2310.17490</a> (replaced) [<a href="/pdf/2310.17490" title="Download PDF">pdf</a>, <a href="/format/2310.17490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Zero-shot Reader by Reducing Distractions from Irrelevant  Documents in Open-Domain Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+S">Sukmin Cho</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+J">Jeongyeon Seo</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+S">Soyeong Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J+C">Jong C. Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Findings of EMNLP 2023 Camera Ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18230" title="Abstract">arXiv:2310.18230</a> (replaced) [<a href="/pdf/2310.18230" title="Download PDF">pdf</a>, <a href="/format/2310.18230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Transformed Gaussian Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%C3%A1ez-Maldonado%2C+F+J">Francisco Javier S&#xe1;ez-Maldonado</a>, 
<a href="/search/cs?searchtype=author&query=Maro%C3%B1as%2C+J">Juan Maro&#xf1;as</a>, 
<a href="/search/cs?searchtype=author&query=Hern%C3%A1ndez-Lobato%2C+D">Daniel Hern&#xe1;ndez-Lobato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18301" title="Abstract">arXiv:2310.18301</a> (replaced) [<a href="/pdf/2310.18301" title="Download PDF">pdf</a>, <a href="/format/2310.18301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Motion Planning for Autonomous Vehicles with Joint  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuxiao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Veer%2C+S">Sushant Veer</a>, 
<a href="/search/cs?searchtype=author&query=Karkus%2C+P">Peter Karkus</a>, 
<a href="/search/cs?searchtype=author&query=Pavone%2C+M">Marco Pavone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18348" title="Abstract">arXiv:2310.18348</a> (replaced) [<a href="/pdf/2310.18348" title="Download PDF">pdf</a>, <a href="/format/2310.18348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meaning Representations from Trajectories in Autoregressive Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T+Y">Tian Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Trager%2C+M">Matthew Trager</a>, 
<a href="/search/cs?searchtype=author&query=Achille%2C+A">Alessandro Achille</a>, 
<a href="/search/cs?searchtype=author&query=Perera%2C+P">Pramuditha Perera</a>, 
<a href="/search/cs?searchtype=author&query=Zancato%2C+L">Luca Zancato</a>, 
<a href="/search/cs?searchtype=author&query=Soatto%2C+S">Stefano Soatto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18477" title="Abstract">arXiv:2310.18477</a> (replaced) [<a href="/pdf/2310.18477" title="Download PDF">pdf</a>, <a href="/format/2310.18477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding and Improving Ensemble Adversarial Defense
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yian Deng</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+T">Tingting Mu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19385" title="Abstract">arXiv:2310.19385</a> (replaced) [<a href="/pdf/2310.19385" title="Download PDF">pdf</a>, <a href="/format/2310.19385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient-free online learning of subgrid-scale dynamics with neural  emulators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Frezat%2C+H">Hugo Frezat</a>, 
<a href="/search/physics?searchtype=author&query=Fablet%2C+R">Ronan Fablet</a>, 
<a href="/search/physics?searchtype=author&query=Balarac%2C+G">Guillaume Balarac</a>, 
<a href="/search/physics?searchtype=author&query=Sommer%2C+J+L">Julien Le Sommer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures, submitted for publication in Journal of Computational Physics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Machine Learning (cs.LG); Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19514" title="Abstract">arXiv:2310.19514</a> (replaced) [<a href="/pdf/2310.19514" title="Download PDF">pdf</a>, <a href="/format/2310.19514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximate Earth Mover&#x27;s Distance in Truly-Subquadratic Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beretta%2C+L">Lorenzo Beretta</a>, 
<a href="/search/cs?searchtype=author&query=Rubinstein%2C+A">Aviad Rubinstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Geometry (cs.CG)

</div>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19559" title="Abstract">arXiv:2310.19559</a> (replaced) [<a href="/pdf/2310.19559" title="Download PDF">pdf</a>, <a href="/format/2310.19559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangled Counterfactual Learning for Physical Audiovisual  Commonsense Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lv%2C+C">Changsheng Lv</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yapeng Tian</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+M">Mengshi Qi</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Huadong Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in 37th Conference on Neural Information Processing Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19702" title="Abstract">arXiv:2310.19702</a> (replaced) [<a href="/pdf/2310.19702" title="Download PDF">pdf</a>, <a href="/format/2310.19702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rank and Select on Degenerate Strings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bille%2C+P">Philip Bille</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B8rtz%2C+I+L">Inge Li G&#xf8;rtz</a>, 
<a href="/search/cs?searchtype=author&query=Stordalen%2C+T">Tord Stordalen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19793" title="Abstract">arXiv:2310.19793</a> (replaced) [<a href="/pdf/2310.19793" title="Download PDF">pdf</a>, <a href="/format/2310.19793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Learning Gaussian Multi-index Models with Gradient Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bietti%2C+A">Alberto Bietti</a>, 
<a href="/search/stat?searchtype=author&query=Bruna%2C+J">Joan Bruna</a>, 
<a href="/search/stat?searchtype=author&query=Pillaud-Vivien%2C+L">Loucas Pillaud-Vivien</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20212" title="Abstract">arXiv:2310.20212</a> (replaced) [<a href="/pdf/2310.20212" title="Download PDF">pdf</a>, <a href="/format/2310.20212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative Evaluation of Automated Analysis Tools for Solidity Smart  Contracts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhiyuan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zijian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xianhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Meng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Liehuang Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 6 figure, IEEE Communications Surveys &amp; Tutorials
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20280" title="Abstract">arXiv:2310.20280</a> (replaced) [<a href="/pdf/2310.20280" title="Download PDF">pdf</a>, <a href="/format/2310.20280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoMixer for Improved Multivariate Time-Series Forecasting on Business  and IT Observability Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Palaskar%2C+S">Santosh Palaskar</a>, 
<a href="/search/cs?searchtype=author&query=Ekambaram%2C+V">Vijay Ekambaram</a>, 
<a href="/search/cs?searchtype=author&query=Jati%2C+A">Arindam Jati</a>, 
<a href="/search/cs?searchtype=author&query=Gantayat%2C+N">Neelamadhav Gantayat</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+A">Avirup Saha</a>, 
<a href="/search/cs?searchtype=author&query=Nagar%2C+S">Seema Nagar</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+N+H">Nam H. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Dayama%2C+P">Pankaj Dayama</a>, 
<a href="/search/cs?searchtype=author&query=Sindhgatta%2C+R">Renuka Sindhgatta</a>, 
<a href="/search/cs?searchtype=author&query=Mohapatra%2C+P">Prateeti Mohapatra</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+H">Harshit Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Kalagnanam%2C+J">Jayant Kalagnanam</a>, 
<a href="/search/cs?searchtype=author&query=Hemachandra%2C+N">Nandyala Hemachandra</a>, 
<a href="/search/cs?searchtype=author&query=Rangaraj%2C+N">Narayan Rangaraj</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the Thirty-Sixth Annual Conference on Innovative Applications of Artificial Intelligence (IAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00270" title="Abstract">arXiv:2311.00270</a> (replaced) [<a href="/pdf/2311.00270" title="Download PDF">pdf</a>, <a href="/format/2311.00270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survey on Quality Assurance of Smart Contracts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhiyuan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zijian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xianhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaoxuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Liehuang Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 6 figures, ACM Computing Surveys
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00277" title="Abstract">arXiv:2311.00277</a> (replaced) [<a href="/pdf/2311.00277" title="Download PDF">pdf</a>, <a href="/format/2311.00277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenForest: A data catalogue for machine learning in forest monitoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ouaknine%2C+A">Arthur Ouaknine</a>, 
<a href="/search/cs?searchtype=author&query=Kattenborn%2C+T">Teja Kattenborn</a>, 
<a href="/search/cs?searchtype=author&query=Lalibert%C3%A9%2C+E">Etienne Lalibert&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Rolnick%2C+D">David Rolnick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages, 3 figures, 9 tables. Preprint under review. The OpenForest catalogue is available at <a href="https://github.com/RolnickLab/OpenForest.git">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00279" title="Abstract">arXiv:2311.00279</a> (replaced) [<a href="/pdf/2311.00279" title="Download PDF">pdf</a>, <a href="/format/2311.00279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Maximal Clique Enumeration via Graph Reduction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+W">Wen Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Weiguo Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hong Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00286" title="Abstract">arXiv:2311.00286</a> (replaced) [<a href="/pdf/2311.00286" title="Download PDF">pdf</a>, <a href="/format/2311.00286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JADE: A Linguistics-based Safety Evaluation Platform for LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xudong Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Min Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A preprint work. Benchmark link: <a href="https://github.com/whitzard-ai/jade-db.">this https URL</a> Website link: <a href="https://whitzard-ai.github.io/jade.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00344" title="Abstract">arXiv:2311.00344</a> (replaced) [<a href="/pdf/2311.00344" title="Download PDF">pdf</a>, <a href="/format/2311.00344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Definition of Open-Ended Learning Problems for Goal-Conditioned Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sigaud%2C+O">Olivier Sigaud</a>, 
<a href="/search/cs?searchtype=author&query=Baldassarre%2C+G">Gianluca Baldassarre</a>, 
<a href="/search/cs?searchtype=author&query=Colas%2C+C">Cedric Colas</a>, 
<a href="/search/cs?searchtype=author&query=Doncieux%2C+S">Stephane Doncieux</a>, 
<a href="/search/cs?searchtype=author&query=Duro%2C+R">Richard Duro</a>, 
<a href="/search/cs?searchtype=author&query=Perrin-Gilbert%2C+N">Nicolas Perrin-Gilbert</a>, 
<a href="/search/cs?searchtype=author&query=Santucci%2C+V+G">Vieri Giuliano Santucci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00462" title="Abstract">arXiv:2311.00462</a> (replaced) [<a href="/pdf/2311.00462" title="Download PDF">pdf</a>, <a href="/format/2311.00462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Hyperbolic Embeddings for Coarse-to-Fine Robot Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Heng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chongjie Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00489" title="Abstract">arXiv:2311.00489</a> (replaced) [<a href="/pdf/2311.00489" title="Download PDF">pdf</a>, <a href="/format/2311.00489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Neural Networks for Automatic Speaker Recognition Do Not Learn  Supra-Segmental Temporal Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neururer%2C+D">Daniel Neururer</a>, 
<a href="/search/cs?searchtype=author&query=Dellwo%2C+V">Volker Dellwo</a>, 
<a href="/search/cs?searchtype=author&query=Stadelmann%2C+T">Thilo Stadelmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00548" title="Abstract">arXiv:2311.00548</a> (replaced) [<a href="/pdf/2311.00548" title="Download PDF">pdf</a>, <a href="/format/2311.00548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual atlas-based segmentation of prostate MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ranem%2C+A">Amin Ranem</a>, 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A1lez%2C+C">Camila Gonz&#xe1;lez</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+D+P+d">Daniel Pinto dos Santos</a>, 
<a href="/search/cs?searchtype=author&query=Bucher%2C+A+M">Andreas Michael Bucher</a>, 
<a href="/search/cs?searchtype=author&query=Othman%2C+A+E">Ahmed Ezzat Othman</a>, 
<a href="/search/cs?searchtype=author&query=Mukhopadhyay%2C+A">Anirban Mukhopadhyay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00582" title="Abstract">arXiv:2311.00582</a> (replaced) [<a href="/pdf/2311.00582" title="Download PDF">pdf</a>, <a href="/format/2311.00582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimally Modifying a Markov Game to Achieve Any Nash Equilibrium and  Value
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Young Wu</a>, 
<a href="/search/cs?searchtype=author&query=McMahan%2C+J">Jeremy McMahan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiding Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yudong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaojin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Q">Qiaomin Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00651" title="Abstract">arXiv:2311.00651</a> (replaced) [<a href="/pdf/2311.00651" title="Download PDF">pdf</a>, <a href="/format/2311.00651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergence of Collective Open-Ended Exploration from Decentralized  Meta-Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bornemann%2C+R">Richard Bornemann</a>, 
<a href="/search/cs?searchtype=author&query=Hamon%2C+G">Gautier Hamon</a>, 
<a href="/search/cs?searchtype=author&query=Nisioti%2C+E">Eleni Nisioti</a>, 
<a href="/search/cs?searchtype=author&query=Moulin-Frier%2C+C">Cl&#xe9;ment Moulin-Frier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item347">Cross-lists</a></li>
<li><a href="#item384">Replacements</a></li>
</ul>
<small>[ total of 605 entries:  <b>1-605</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2311">2311</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
