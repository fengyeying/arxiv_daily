<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Fri 24 Nov 23  to  Mon 27 Nov 23, announced Tue, 28 Nov 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item611">Cross-lists</a></li>
<li><a href="#item693">Replacements</a></li>
</ul>
<small>[ total of 1035 entries:  <b>1-1035</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Tue, 28 Nov 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14674" title="Abstract">arXiv:2311.14674</a> [<a href="/pdf/2311.14674" title="Download PDF">pdf</a>, <a href="/ps/2311.14674" title="Download PostScript">ps</a>, <a href="/format/2311.14674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emotion-Oriented Behavior Model Using Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raza%2C+M+A">Muhammad Arslan Raza</a>, 
<a href="/search/cs?searchtype=author&query=Farooq%2C+M+S">Muhammad Shoaib Farooq</a>, 
<a href="/search/cs?searchtype=author&query=Khelifi%2C+A">Adel Khelifi</a>, 
<a href="/search/cs?searchtype=author&query=Alvi%2C+A">Atif Alvi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT)

</div>
<p class="mathjax">Emotions, as a fundamental ingredient of any social interaction, lead to
behaviors that represent the effectiveness of the interaction through facial
expressions and gestures in humans. Hence an agent must possess the social and
cognitive abilities to understand human social parameters and behave
accordingly. However, no such emotion-oriented behavior model is presented yet
in the existing research. The emotion prediction may generate appropriate
agents' behaviors for effective interaction using conversation modality.
Considering the importance of emotions, and behaviors, for an agent's social
interaction, an Emotion-based Behavior model is presented in this paper for
Socio-cognitive artificial agents. The proposed model is implemented using
tweets data trained on multiple models like Long Short-Term Memory (LSTM),
Convolution Neural Network (CNN) and Bidirectional Encoder Representations from
Transformers (BERT) for emotion prediction with an average accuracy of 92%, and
55% respectively. Further, using emotion predictions from CNN-LSTM, the
behavior module responds using facial expressions and gestures using Behavioral
Markup Language (BML). The accuracy of emotion-based behavior predictions is
statistically validated using the 2-tailed Pearson correlation on the data
collected from human users through questionnaires. Analysis shows that all
emotion-based behaviors accurately depict human-like gestures and facial
expressions based on the significant correlation at the 0.01 and 0.05 levels.
This study is a steppingstone to a multi-faceted artificial agent interaction
based on emotion-oriented behaviors. Cognition has significance regarding
social interaction among humans.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14675" title="Abstract">arXiv:2311.14675</a> [<a href="/pdf/2311.14675" title="Download PDF">pdf</a>, <a href="/format/2311.14675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast and Expressive Gesture Recognition using a Combination-Homomorphic  Electromyogram Encoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Smedemark-Margulies%2C+N">Niklas Smedemark-Margulies</a>, 
<a href="/search/cs?searchtype=author&query=Bicer%2C+Y">Yunus Bicer</a>, 
<a href="/search/cs?searchtype=author&query=Sunger%2C+E">Elifnur Sunger</a>, 
<a href="/search/cs?searchtype=author&query=Imbiriba%2C+T">Tales Imbiriba</a>, 
<a href="/search/cs?searchtype=author&query=Tunik%2C+E">Eugene Tunik</a>, 
<a href="/search/cs?searchtype=author&query=Erdogmus%2C+D">Deniz Erdogmus</a>, 
<a href="/search/cs?searchtype=author&query=Yarossi%2C+M">Mathew Yarossi</a>, 
<a href="/search/cs?searchtype=author&query=Walters%2C+R">Robin Walters</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 7 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">We study the task of gesture recognition from electromyography (EMG), with
the goal of enabling expressive human-computer interaction at high accuracy,
while minimizing the time required for new subjects to provide calibration
data. To fulfill these goals, we define combination gestures consisting of a
direction component and a modifier component. New subjects only demonstrate the
single component gestures and we seek to extrapolate from these to all possible
single or combination gestures. We extrapolate to unseen combination gestures
by combining the feature vectors of real single gestures to produce synthetic
training data. This strategy allows us to provide a large and flexible gesture
vocabulary, while not requiring new subjects to demonstrate combinatorially
many example gestures. We pre-train an encoder and a combination operator using
self-supervision, so that we can produce useful synthetic training data for
unseen test subjects. To evaluate the proposed method, we collect a real-world
EMG dataset, and measure the effect of augmented supervision against two
baselines: a partially-supervised model trained with only single gesture data
from the unseen subject, and a fully-supervised model trained with real single
and real combination gesture data from the unseen subject. We find that the
proposed method provides a dramatic improvement over the partially-supervised
model, and achieves a useful classification accuracy that in some cases
approaches the performance of the fully-supervised model.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14676" title="Abstract">arXiv:2311.14676</a> [<a href="/pdf/2311.14676" title="Download PDF">pdf</a>, <a href="/format/2311.14676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoding Social Sentiment in DAO: A Comparative Analysis of Blockchain  Governance Communities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Quan%2C+Y">Yutong Quan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xintong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+W">Wanlin Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Luyao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Blockchain technology is leading a revolutionary transformation across
diverse industries, with effective governance standing as a critical
determinant for the success and sustainability of blockchain projects.
Community forums, pivotal in engaging decentralized autonomous organizations
(DAOs), wield a substantial impact on blockchain governance decisions.
Concurrently, Natural Language Processing (NLP), particularly sentiment
analysis, provides powerful insights from textual data. While prior research
has explored the potential of NLP tools in social media sentiment analysis, a
gap persists in understanding the sentiment landscape of blockchain governance
communities. The evolving discourse and sentiment dynamics on the forums of top
DAOs remain largely unknown. This paper delves deep into the evolving discourse
and sentiment dynamics on the public forums of leading DeFi projects -- Aave,
Uniswap, Curve Dao, Aragon, Yearn.finance, Merit Circle, and Balancer --
placing a primary focus on discussions related to governance issues. Despite
differing activity patterns, participants across these decentralized
communities consistently express positive sentiments in their Discord
discussions, indicating optimism towards governance decisions. Additionally,
our research suggests a potential interplay between discussion intensity and
sentiment dynamics, indicating that higher discussion volumes may contribute to
more stable and positive emotions. The insights gained from this study are
valuable for decision-makers in blockchain governance, underscoring the pivotal
role of sentiment analysis in interpreting community emotions and its evolving
impact on the landscape of blockchain governance. This research significantly
contributes to the interdisciplinary exploration of the intersection of
blockchain and society, with a specific emphasis on the decentralized
blockchain governance ecosystem.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14677" title="Abstract">arXiv:2311.14677</a> [<a href="/pdf/2311.14677" title="Download PDF">pdf</a>, <a href="/format/2311.14677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Filter bubbles and affective polarization in user-personalized large  language model outputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lazovich%2C+T">Tomo Lazovich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023 Workshop "I Can't Believe It's Not Better: Failure Modes in the Age of Foundation Models"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Echoing the history of search engines and social media content rankings, the
advent of large language models (LLMs) has led to a push for increased
personalization of model outputs to individual users. In the past, personalized
recommendations and ranking systems have been linked to the development of
filter bubbles (serving content that may confirm a user's existing biases) and
affective polarization (strong negative sentiment towards those with differing
views). In this work, we explore how prompting a leading large language model,
ChatGPT-3.5, with a user's political affiliation prior to asking factual
questions about public figures and organizations leads to differing results. We
observe that left-leaning users tend to receive more positive statements about
left-leaning political figures and media outlets, while right-leaning users see
more positive statements about right-leaning entities. This pattern holds
across presidential candidates, members of the U.S. Senate, and media
organizations with ratings from AllSides. When qualitatively evaluating some of
these outputs, there is evidence that particular facts are included or excluded
based on the user's political affiliation. These results illustrate that
personalizing LLMs based on user demographics carry the same risks of affective
polarization and filter bubbles that have been seen in other personalized
internet technologies. This ``failure mode" should be monitored closely as
there are more attempts to monetize and personalize these models.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14678" title="Abstract">arXiv:2311.14678</a> [<a href="/pdf/2311.14678" title="Download PDF">pdf</a>, <a href="/ps/2311.14678" title="Download PostScript">ps</a>, <a href="/format/2311.14678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven recommendations for enhancing real-time natural hazard  warnings, communication, and response
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saunders%2C+K+R">Kate R. Saunders</a>, 
<a href="/search/cs?searchtype=author&query=Forbes%2C+O">Owen Forbes</a>, 
<a href="/search/cs?searchtype=author&query=Hopf%2C+J+K">Jess K. Hopf</a>, 
<a href="/search/cs?searchtype=author&query=Patterson%2C+C+R">Charlotte R. Patterson</a>, 
<a href="/search/cs?searchtype=author&query=Vollert%2C+S+A">Sarah A. Vollert</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+K">Kaitlyn Brown</a>, 
<a href="/search/cs?searchtype=author&query=Browning%2C+R">Raiha Browning</a>, 
<a href="/search/cs?searchtype=author&query=Canizares%2C+M">Miguel Canizares</a>, 
<a href="/search/cs?searchtype=author&query=Cottrell%2C+R+S">Richard S. Cottrell</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lanxi Li</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C+J+S">Catherine J.S. Kim</a>, 
<a href="/search/cs?searchtype=author&query=Stewart%2C+T+P">Tace P. Stewart</a>, 
<a href="/search/cs?searchtype=author&query=Susilawati%2C+C">Connie Susilawati</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X+Y">Xiang Y. Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Helmstedt%2C+K+J">Kate J. Helmstedt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">The effectiveness and adequacy of natural hazard warnings hinges on the
availability of data and its transformation into actionable knowledge for the
public. Real-time warning communication and emergency response therefore need
to be evaluated from a data science perspective. However, there are currently
gaps between established data science best practices and their application in
supporting natural hazard warnings. This Perspective reviews existing
data-driven approaches that underpin real-time warning communication and
emergency response, highlighting limitations in hazard and impact forecasts.
Four main themes for enhancing warnings are emphasised: (i) applying
best-practice principles in visualising hazard forecasts, (ii) data
opportunities for more effective impact forecasts, (iii) utilising data for
more localised forecasts, and (iv) improving data-driven decision-making using
uncertainty. Motivating examples are provided from the extensive flooding
experienced in Australia in 2022. This Perspective shows the capacity for
improving the efficacy of natural hazard warnings using data science, and the
collaborative potential between the data science and natural hazards
communities.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14679" title="Abstract">arXiv:2311.14679</a> [<a href="/pdf/2311.14679" title="Download PDF">pdf</a>, <a href="/ps/2311.14679" title="Download PostScript">ps</a>, <a href="/format/2311.14679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Medium-n studies&quot; in computing education conferences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guerzhoy%2C+M">Michael Guerzhoy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Koli Calling 2023: 23rd International Conference on Computing Education Research
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Good (Frequentist) statistical practice requires that statistical tests be
performed in order to determine if the phenomenon being observed could
plausibly occur by chance if the null hypothesis is false. Good practice also
requires that a test is not performed if the study is underpowered: if the
number of observations is not sufficiently large to be able to reliably detect
the effect one hypothesizes, even if the effect exists. Running underpowered
studies runs the risk of false negative results. This creates tension in the
guidelines and expectations for computer science education conferences: while
things are clear for studies with a large number of observations, researchers
should in fact not compute p-values and perform statistical tests if the number
of observations is too small. The issue is particularly live in CSed venues,
since class sizes where those issues are salient are common. We outline the
considerations for when to compute and when not to compute p-values in
different settings encountered by computer science education researchers. We
survey the author and reviewer guidelines in different computer science
education conferences (ICER, SIGCSE TS, ITiCSE, EAAI, CompEd, Koli Calling). We
present summary data and make several preliminary observations about reviewer
guidelines: guidelines vary from conference to conference; guidelines allow for
qualitative studies, and, in some cases, experience reports, but guidelines do
not generally explicitly indicate that a paper should have at least one of (1)
an appropriately-powered statistical analysis or (2) rich qualitative
descriptions. We present preliminary ideas for addressing the tension in the
guidelines between small-n and large-n studies
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14680" title="Abstract">arXiv:2311.14680</a> [<a href="/pdf/2311.14680" title="Download PDF">pdf</a>, <a href="/ps/2311.14680" title="Download PostScript">ps</a>, <a href="/format/2311.14680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E-polis: A serious game for the gamification of sociological surveys
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alexandros%2C+G">Gazis Alexandros</a>, 
<a href="/search/cs?searchtype=author&query=Eleftheria%2C+K">Katsiri Eleftheria</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 11 figures, Proceedings of the International Conference on Applied Mathematics &amp; Computer Science (ICAMCS) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Graphics (cs.GR); Multimedia (cs.MM); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">E-polis is a multi-platform serious game that gamifies a sociological survey
for studying young people's opinions regarding their ideal society. The
gameplay is based on a user navigating through a digital city, experiencing the
changes inflicted, triggered by responses to social and pedagogical surveys,
known as "dilemmas". The game integrates elements of adventure, exploration,
and simulation. Unity was the selected game engine used for the development of
the game, while a middleware component was also developed to gather and process
the users' data. At the end of each game, users are presented with a blueprint
of the city they navigated to showcase how their choices influenced its
development. This motivates them to reflect on their answers and validate them.
The game can be used to collect data on a variety of topics, such as social
justice, and economic development, or to promote civic engagement and encourage
young people to think critically about the world around them.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14681" title="Abstract">arXiv:2311.14681</a> [<a href="/pdf/2311.14681" title="Download PDF">pdf</a>, <a href="/format/2311.14681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instance-Specific Asymmetric Sensitivity in Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Durfee%2C+D">David Durfee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">We provide a new algorithmic framework for differentially private estimation
of general functions that adapts to the hardness of the underlying dataset. We
build upon previous work that gives a paradigm for selecting an output through
the exponential mechanism based upon closeness of the inverse to the underlying
dataset, termed the inverse sensitivity mechanism. Our framework will slightly
modify the closeness metric and instead give a simple and efficient application
of the sparse vector technique. While the inverse sensitivity mechanism was
shown to be instance optimal, it was only with respect to a class of unbiased
mechanisms such that the most likely outcome matches the underlying data. We
break this assumption in order to more naturally navigate the bias-variance
tradeoff, which will also critically allow for extending our method to
unbounded data. In consideration of this tradeoff, we provide strong intuition
and empirical validation that our technique will be particularly effective when
the distances to the underlying dataset are asymmetric. This asymmetry is
inherent to a range of important problems including fundamental statistics such
as variance, as well as commonly used machine learning performance metrics for
both classification and regression tasks. We efficiently instantiate our method
in $O(n)$ time for these problems and empirically show that our techniques will
give substantially improved differentially private estimations.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14683" title="Abstract">arXiv:2311.14683</a> [<a href="/pdf/2311.14683" title="Download PDF">pdf</a>, <a href="/ps/2311.14683" title="Download PostScript">ps</a>, <a href="/format/2311.14683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Science for Social Good
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abbasi%2C+A">Ahmed Abbasi</a>, 
<a href="/search/cs?searchtype=author&query=Chiang%2C+R+H+L">Roger H. L. Chiang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J+J">Jennifer J. Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Data science has been described as the fourth paradigm for scientific
discovery. The latest wave of data science research, pertaining to machine
learning and artificial intelligence (AI), is growing exponentially and
garnering millions of annual citations. However, this growth has been
accompanied by a diminishing emphasis on social good challenges - our analysis
reveals that the proportion of data science research focusing on social good is
less than it has ever been. At the same time, the proliferation of machine
learning and generative AI have sparked debates about the socio-technical
prospects and challenges associated with data science for human flourishing,
organizations, and society. Against this backdrop, we present a framework for
"data science for social good" (DSSG) research that considers the interplay
between relevant data science research genres, social good challenges, and
different levels of socio-technical abstraction. We perform an analysis of the
literature to empirically demonstrate the paucity of work on DSSG in
information systems (and other related disciplines) and highlight current
impediments. We then use our proposed framework to introduce the articles
appearing in the special issue. We hope that this article and the special issue
will spur future DSSG research and help reverse the alarming trend across data
science research over the past 30-plus years in which social good challenges
are garnering proportionately less attention with each passing day.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14684" title="Abstract">arXiv:2311.14684</a> [<a href="/pdf/2311.14684" title="Download PDF">pdf</a>, <a href="/format/2311.14684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The risks of risk-based AI regulation: taking liability seriously
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kretschmer%2C+M">Martin Kretschmer</a>, 
<a href="/search/cs?searchtype=author&query=Kretschmer%2C+T">Tobias Kretschmer</a>, 
<a href="/search/cs?searchtype=author&query=Peukert%2C+A">Alexander Peukert</a>, 
<a href="/search/cs?searchtype=author&query=Peukert%2C+C">Christian Peukert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The development and regulation of multi-purpose, large "foundation models" of
AI seems to have reached a critical stage, with major investments and new
applications announced every other day. Some experts are calling for a
moratorium on the training of AI systems more powerful than GPT-4. Legislators
globally compete to set the blueprint for a new regulatory regime. This paper
analyses the most advanced legal proposal, the European Union's AI Act
currently in the stage of final "trilogue" negotiations between the EU
institutions. This legislation will likely have extra-territorial implications,
sometimes called "the Brussels effect". It also constitutes a radical departure
from conventional information and communications technology policy by
regulating AI ex-ante through a risk-based approach that seeks to prevent
certain harmful outcomes based on product safety principles. We offer a review
and critique, specifically discussing the AI Act's problematic obligations
regarding data quality and human oversight. Our proposal is to take liability
seriously as the key regulatory mechanism. This signals to industry that if a
breach of law occurs, firms are required to know in particular what their
inputs were and how to retrain the system to remedy the breach. Moreover, we
suggest differentiating between endogenous and exogenous sources of potential
harm, which can be mitigated by carefully allocating liability between
developers and deployers of AI technology.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14685" title="Abstract">arXiv:2311.14685</a> [<a href="/pdf/2311.14685" title="Download PDF">pdf</a>, <a href="/format/2311.14685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comprehensive Assessment of Toxicity in ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Boyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xinyue Shen</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+W+M">Wai Man Si</a>, 
<a href="/search/cs?searchtype=author&query=Sha%2C+Z">Zeyang Sha</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zeyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Salem%2C+A">Ahmed Salem</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Backes%2C+M">Michael Backes</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computation and Language (cs.CL); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Moderating offensive, hateful, and toxic language has always been an
important but challenging topic in the domain of safe use in NLP. The emerging
large language models (LLMs), such as ChatGPT, can potentially further
accentuate this threat. Previous works have discovered that ChatGPT can
generate toxic responses using carefully crafted inputs. However, limited
research has been done to systematically examine when ChatGPT generates toxic
responses. In this paper, we comprehensively evaluate the toxicity in ChatGPT
by utilizing instruction-tuning datasets that closely align with real-world
scenarios. Our results show that ChatGPT's toxicity varies based on different
properties and settings of the prompts, including tasks, domains, length, and
languages. Notably, prompts in creative writing tasks can be 2x more likely
than others to elicit toxic responses. Prompting in German and Portuguese can
also double the response toxicity. Additionally, we discover that certain
deliberately toxic prompts, designed in earlier studies, no longer yield
harmful responses. We hope our discoveries can guide model developers to better
regulate these AI systems and the users to avoid undesirable outputs.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14686" title="Abstract">arXiv:2311.14686</a> [<a href="/pdf/2311.14686" title="Download PDF">pdf</a>, <a href="/format/2311.14686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Models Applied to the Patterns of Human Migration due to Climate  Change
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+K">Kenneth Lai</a>, 
<a href="/search/cs?searchtype=author&query=Yanushkevich%2C+S">Svetlana Yanushkevich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE Symposium Series on Computational Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The impacts of mass migration, such as crisis induced by climate change,
extend beyond environmental concerns and can greatly affect social
infrastructure and public services, such as education, healthcare, and
security. These crises exacerbate certain elements like cultural barriers, and
discrimination by amplifying the challenges faced by these affected
communities. This paper proposes an innovative approach to address migration
crises in the context of crisis management through a combination of modeling
and imbalance assessment tools. By employing deep learning for forecasting and
integrating causal reasoning via Bayesian networks, this methodology enables
the evaluation of imbalances and risks in the socio-technological landscape,
providing crucial insights for informed decision-making. Through this
framework, critical systems can be analyzed to understand how fluctuations in
migration levels may impact them, facilitating effective crisis governance
strategies.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14687" title="Abstract">arXiv:2311.14687</a> [<a href="/pdf/2311.14687" title="Download PDF">pdf</a>, <a href="/format/2311.14687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does Explainable AI Have Moral Value?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brand%2C+J+L+M">Joshua L.M. Brand</a>, 
<a href="/search/cs?searchtype=author&query=Nannini%2C+L">Luca Nannini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Work in progress. Accepted at the workshop MP2 at NeurIPS 2023, 15 December 2023, New Orleans, US
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Explainable AI (XAI) aims to bridge the gap between complex algorithmic
systems and human stakeholders. Current discourse often examines XAI in
isolation as either a technological tool, user interface, or policy mechanism.
This paper proposes a unifying ethical framework grounded in moral duties and
the concept of reciprocity. We argue that XAI should be appreciated not merely
as a right, but as part of our moral duties that helps sustain a reciprocal
relationship between humans affected by AI systems. This is because, we argue,
explanations help sustain constitutive symmetry and agency in AI-led
decision-making processes. We then assess leading XAI communities and reveal
gaps between the ideal of reciprocity and practical feasibility. Machine
learning offers useful techniques but overlooks evaluation and adoption
challenges. Human-computer interaction provides preliminary insights but
oversimplifies organizational contexts. Policies espouse accountability but
lack technical nuance. Synthesizing these views exposes barriers to
implementable, ethical XAI. Still, positioning XAI as a moral duty transcends
rights-based discourse to capture a more robust and complete moral picture.
This paper provides an accessible, detailed analysis elucidating the moral
value of explainability.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14688" title="Abstract">arXiv:2311.14688</a> [<a href="/pdf/2311.14688" title="Download PDF">pdf</a>, <a href="/format/2311.14688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Procedural Fairness Through Decoupling Objectionable Data Generating  Components
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zeyu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jialu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Spirtes%2C+P">Peter Spirtes</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We reveal and address the frequently overlooked yet important issue of
disguised procedural unfairness, namely, the potentially inadvertent
alterations on the behavior of neutral (i.e., not problematic) aspects of data
generating process, and/or the lack of procedural assurance of the greatest
benefit of the least advantaged individuals. Inspired by John Rawls's advocacy
for pure procedural justice, we view automated decision-making as a microcosm
of social institutions, and consider how the data generating process itself can
satisfy the requirements of procedural fairness. We propose a framework that
decouples the objectionable data generating components from the neutral ones by
utilizing reference points and the associated value instantiation rule. Our
findings highlight the necessity of preventing disguised procedural unfairness,
drawing attention not only to the objectionable data generating components that
we aim to mitigate, but also more importantly, to the neutral components that
we intend to keep unaffected.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14689" title="Abstract">arXiv:2311.14689</a> [<a href="/pdf/2311.14689" title="Download PDF">pdf</a>, <a href="/ps/2311.14689" title="Download PostScript">ps</a>, <a href="/format/2311.14689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyze Factors Influencing Drivers&#x27; Cell Phone Online Ride-hailing  Software Using While driving: A Case Study in China
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xiangnan Song</a> (1), 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xianghong Li</a> (1), 
<a href="/search/cs?searchtype=author&query=Yin%2C+K">Kai Yin</a> (2), 
<a href="/search/cs?searchtype=author&query=Qi%2C+H">Huimin Qi</a> (1), 
<a href="/search/cs?searchtype=author&query=Fang%2C+X">Xufei Fang</a> (1) ((1) Department of Transportation, Henan Polytechnic University, Jiaozuo 454003, China,(2) School of traffic and transportation, Beijing Jiaotong University, Beijing 100044, China)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages,7 tables and 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">The road safety of traffic is greatly affected by the driving performance of
online ride-hailing, which has become an increasingly popular travel option for
many people. Little attention has been paid to the fact that the use of cell
phone online ride-hailing software by drivers to accept orders while driving is
one of the causes of traffic accidents involving online ride-hailing. This
paper, adopting the extended theory of planned behavior, investigates the
factors that factors influencing the behavior of Chinese online ride-hailing
drivers cell phone ride-hailing software usage to accept orders while driving.
Results showed that attitudes, subjective norms, and perceived behavioral
control have a significant and positive effect on behavioral intentions.
Behavioral intention is most strongly influenced by attitude. There is no
direct and significant impact of group norms on behavioral intention.
Nonetheless, group norms exert a substantial and beneficial influence on
attitude, subjective norms, and perceived behavioral control. This study has
discovered, through a mediating effect test, that attitude, subjective norm,
and perceived behavioral control play a mediating and moderating role in the
impact of group norm on behavioral intention. These findings can offer
theoretical guidance to relevant departments in developing effective measures
for promoting safe driving among online ride-hailing drivers.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14690" title="Abstract">arXiv:2311.14690</a> [<a href="/pdf/2311.14690" title="Download PDF">pdf</a>, <a href="/format/2311.14690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolutionary City: Towards a Flexible, Agile and Symbiotic System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jingru Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Ding Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+S">Shengyue Yao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yilun Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei-Yue Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Urban growth sometimes leads to rigid infrastructure that struggles to adapt
to changing demand. This paper introduces a novel approach, aiming to enable
cities to evolve and respond more effectively to such dynamic demand. It
identifies the limitations arising from the complexity and inflexibility of
existing urban systems. A framework is presented for enhancing the city's
adaptability perception through advanced sensing technologies, conducting
parallel simulation via graph-based techniques, and facilitating autonomous
decision-making across domains through decentralized and autonomous
organization and operation. Notably, a symbiotic mechanism is employed to
implement these technologies practically, thereby making urban management more
agile and responsive. In the case study, we explore how this approach can
optimize traffic flow by adjusting lane allocations. This case not only
enhances traffic efficiency but also reduces emissions. The proposed
evolutionary city offers a new perspective on sustainable urban development,
highliting the importance of integrated intelligence within urban systems.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14691" title="Abstract">arXiv:2311.14691</a> [<a href="/pdf/2311.14691" title="Download PDF">pdf</a>, <a href="/ps/2311.14691" title="Download PostScript">ps</a>, <a href="/format/2311.14691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time Digital Twins
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hartmann%2C+D">Dirk Hartmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">We live in a world of exploding complexity driven by technical evolution as
well as highly volatile socio-economic environments. Managing complexity is a
key issue in everyday decision making such as providing safe, sustainable, and
efficient industrial control solutions as well as solving today's global grand
challenges such as the climate change. However, the level of complexity has
well reached our cognitive capability to take informed decisions. Digital
Twins, tightly integrating the real and the digital world, are a key enabler to
support decision making for complex systems. They allow informing operational
as well as strategic decisions upfront through accepted virtual predictions and
optimizations of their real-world counter parts. Here we focus on real-time
Digital Twins for online prediction and optimization of highly dynamic
industrial assets and processes. They offer significant opportunities in the
context of the industrial Internet of Things for novel and more effective
control and optimization concepts. Thereby, they meet the Internet of Things
needs for novel technologies to overcome today's limitations in terms of data
availability in industrial contexts. Integrating today's seemingly
complementary technologies of model-based and data-based, as well as edge-based
and cloud-based approaches has the potential to re-imagine industrial process
performance optimization solutions.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14692" title="Abstract">arXiv:2311.14692</a> [<a href="/pdf/2311.14692" title="Download PDF">pdf</a>, <a href="/ps/2311.14692" title="Download PostScript">ps</a>, <a href="/format/2311.14692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COVID-19 Imposes Rethinking of Conferencing -- Environmental Impact  Assessment of Artificial Intelligence Conferences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mitsou%2C+P">Pavlina Mitsou</a>, 
<a href="/search/cs?searchtype=author&query=Tsakalidou%2C+N">Nikoleta-Victoria Tsakalidou</a>, 
<a href="/search/cs?searchtype=author&query=Vrochidou%2C+E">Eleni Vrochidou</a>, 
<a href="/search/cs?searchtype=author&query=Papakostas%2C+G+A">George A. Papakostas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">It has been noticed that through COVID-19 greenhouse gas emissions had a
sudden reduction. Based on this significant observation, we decided to conduct
a research to quantify the impact of scientific conferences' air-travelling,
explore and suggest alternative ways for greener conferences to re-duce the
global carbon footprint. Specifically, we focused on the most popular
conferences for the Artificial Intelligence community based on their scientific
impact factor, their scale, and the well-organized proceedings towards
measuring the impact of air travelling participation. This is the first time
that systematic quantification of a state-of-the-art subject like Artificial
Intelligence takes place to define its conferencing footprint in the broader
frames of environmental awareness. Our findings highlight that the virtual way
is the first on the list of green conferences' conduction although there are
serious concerns about it. Alternatives to optimal conferences' location
selection have demonstrated savings on air-travelling CO2 emissions of up to
63.9%.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14693" title="Abstract">arXiv:2311.14693</a> [<a href="/pdf/2311.14693" title="Download PDF">pdf</a>, <a href="/format/2311.14693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benefits and Harms of Large Language Models in Digital Mental Health
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Choudhury%2C+M">Munmun De Choudhury</a>, 
<a href="/search/cs?searchtype=author&query=Pendse%2C+S+R">Sachin R. Pendse</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+N">Neha Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">The past decade has been transformative for mental health research and
practice. The ability to harness large repositories of data, whether from
electronic health records (EHR), mobile devices, or social media, has revealed
a potential for valuable insights into patient experiences, promising early,
proactive interventions, as well as personalized treatment plans. Recent
developments in generative artificial intelligence, particularly large language
models (LLMs), show promise in leading digital mental health to uncharted
territory. Patients are arriving at doctors' appointments with information
sourced from chatbots, state-of-the-art LLMs are being incorporated in medical
software and EHR systems, and chatbots from an ever-increasing number of
startups promise to serve as AI companions, friends, and partners. This article
presents contemporary perspectives on the opportunities and risks posed by LLMs
in the design, development, and implementation of digital mental health tools.
We adopt an ecological framework and draw on the affordances offered by LLMs to
discuss four application areas -- care-seeking behaviors from individuals in
need of care, community care provision, institutional and medical care
provision, and larger care ecologies at the societal level. We engage in a
thoughtful consideration of whether and how LLM-based technologies could or
should be employed for enhancing mental health. The benefits and harms our
article surfaces could serve to help shape future research, advocacy, and
regulatory efforts focused on creating more responsible, user-friendly,
equitable, and secure LLM-based tools for mental health treatment and
intervention.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14694" title="Abstract">arXiv:2311.14694</a> [<a href="/pdf/2311.14694" title="Download PDF">pdf</a>, <a href="/ps/2311.14694" title="Download PostScript">ps</a>, <a href="/format/2311.14694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Standardized Analysis Ready (STAR) data cube for high-resolution Flood  mapping using Sentinel-1 data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Surajit Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Dawn%2C+A">Arpan Dawn</a>, 
<a href="/search/cs?searchtype=author&query=Kour%2C+S">Sneha Kour</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Susmita Ghosh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Floods are one of the most common disasters globally. Flood affects humans in
many ways. Therefore, rapid assessment is needed to assess the effect of floods
and to take early action to support the vulnerable community in time.
Sentinel-1 is one such Earth Observation (EO) mission widely used for mapping
the flooding conditions at a 10m scale. However, various preprocessing steps
are involved before analyses of the Sentinel-1 data. Researchers sometimes
avoid a few necessary corrections since it is time-consuming and complex.
Standardization of the Sentinel-1 data is the need of the hour, specifically
for supporting researchers to use the Standardized Analysis-Ready (STAR) data
cube without experiencing the complexity of the Sentinel-1 data processing. In
the present study, we proposed a workflow to use STAR in Google Earth Engine
(GEE) environment. The Nigeria Flood of 2022 has been used as a case study for
assessing the model performance.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14695" title="Abstract">arXiv:2311.14695</a> [<a href="/pdf/2311.14695" title="Download PDF">pdf</a>, <a href="/ps/2311.14695" title="Download PostScript">ps</a>, <a href="/format/2311.14695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI for All: Operationalising Diversity and Inclusion Requirements for AI  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bano%2C+M">Muneera Bano</a>, 
<a href="/search/cs?searchtype=author&query=Zowghi%2C+D">Didar Zowghi</a>, 
<a href="/search/cs?searchtype=author&query=Gervasi%2C+V">Vincenzo Gervasi</a>, 
<a href="/search/cs?searchtype=author&query=Shams%2C+R">Rifat Shams</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As Artificial Intelligence (AI) permeates many aspects of society, it brings
numerous advantages while at the same time raising ethical concerns and
potential risks, such as perpetuating inequalities through biased or
discriminatory decision-making. To develop AI systems that cater for the needs
of diverse users and uphold ethical values, it is essential to consider and
integrate diversity and inclusion (D&amp;I) principles throughout AI development
and deployment. Requirements engineering (RE) is a fundamental process in
developing software systems by eliciting and specifying relevant needs from
diverse stakeholders. This research aims to address the lack of research and
practice on how to elicit and capture D&amp;I requirements for AI systems. We have
conducted comprehensive data collection and synthesis from the literature
review to extract requirements themes related to D&amp;I in AI. We have proposed a
tailored user story template to capture D&amp;I requirements and conducted focus
group exercises to use the themes and user story template in writing D&amp;I
requirements for two example AI systems. Additionally, we have investigated the
capability of our solution by generating synthetic D&amp;I requirements captured in
user stories with the help of a Large Language Model.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14696" title="Abstract">arXiv:2311.14696</a> [<a href="/pdf/2311.14696" title="Download PDF">pdf</a>, <a href="/ps/2311.14696" title="Download PostScript">ps</a>, <a href="/format/2311.14696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating information and uncertainty: A fuzzy logic model to approach  transparency, democracy and social wellbeing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Medel-Ram%C3%ADrez%2C+C">Carlos Medel-Ram&#xed;rez</a>, 
<a href="/search/cs?searchtype=author&query=Medel-L%C3%B3pez%2C+H">Hilario Medel-L&#xf3;pez</a>, 
<a href="/search/cs?searchtype=author&query=Lara-M%C3%A9rida%2C+J">Jennifer Lara-M&#xe9;rida</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 60 pages, 14 figures,
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">In the digital age of information overload and uncertainty, the authors
propose the tDTSW model based on fuzzy logic to navigate governance
complexities. This model transcends binary thinking, analyzes democracy,
transparency, and social well-being, highlighting their roles in just societies
through case studies. It addresses challenges like capitalism, sustainability,
gender equality, and education in modern democracies, emphasizing their
interplay for positive change. "Navigating Information and Uncertainty"
introduces fuzzy logic, offering a structured approach. It calls for collective
efforts to create equitable, sustainable, and just societies, inviting readers
to shape a brighter future.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14699" title="Abstract">arXiv:2311.14699</a> [<a href="/pdf/2311.14699" title="Download PDF">pdf</a>, <a href="/ps/2311.14699" title="Download PostScript">ps</a>, <a href="/format/2311.14699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ontology Learning Using Formal Concept Analysis and WordNet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hassan%2C+B+A">Bryar A. Hassan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Manual ontology construction takes time, resources, and domain specialists.
Supporting a component of this process for automation or semi-automation would
be good. This project and dissertation provide a Formal Concept Analysis and
WordNet framework for learning concept hierarchies from free texts. The process
has steps. First, the document is Part-Of-Speech labeled, then parsed to
produce sentence parse trees. Verb/noun dependencies are derived from parse
trees next. After lemmatizing, pruning, and filtering the word pairings, the
formal context is created. The formal context may contain some erroneous and
uninteresting pairs because the parser output may be erroneous, not all derived
pairs are interesting, and it may be large due to constructing it from a large
free text corpus. Deriving lattice from the formal context may take longer,
depending on the size and complexity of the data. Thus, decreasing formal
context may eliminate erroneous and uninteresting pairs and speed up idea
lattice derivation. WordNet-based and Frequency-based approaches are tested.
Finally, we compute formal idea lattice and create a classical concept
hierarchy. The reduced concept lattice is compared to the original to evaluate
the outcomes. Despite several system constraints and component discrepancies
that may prevent logical conclusion, the following data imply idea hierarchies
in this project and dissertation are promising. First, the reduced idea lattice
and original concept have commonalities. Second, alternative language or
statistical methods can reduce formal context size. Finally, WordNet-based and
Frequency-based approaches reduce formal context differently, and the order of
applying them is examined to reduce context efficiently.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14700" title="Abstract">arXiv:2311.14700</a> [<a href="/pdf/2311.14700" title="Download PDF">pdf</a>, <a href="/ps/2311.14700" title="Download PostScript">ps</a>, <a href="/format/2311.14700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Feminist Metaethics of AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Siapka%2C+A">Anastasia Siapka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society (AIES' 22), August 1-3, 2022, Oxford, United Kingdom. ACM, New York, NY, USA, 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The proliferation of Artificial Intelligence (AI) has sparked an overwhelming
number of AI ethics guidelines, boards and codes of conduct. These outputs
primarily analyse competing theories, principles and values for AI development
and deployment. However, as a series of recent problematic incidents about AI
ethics/ethicists demonstrate, this orientation is insufficient. Before
proceeding to evaluate other professions, AI ethicists should critically
evaluate their own; yet, such an evaluation should be more explicitly and
systematically undertaken in the literature. I argue that these insufficiencies
could be mitigated by developing a research agenda for a feminist metaethics of
AI. Contrary to traditional metaethics, which reflects on the nature of
morality and moral judgements in a non-normative way, feminist metaethics
expands its scope to ask not only what ethics is but also what our engagement
with it should be like. Applying this perspective to the context of AI, I
suggest that a feminist metaethics of AI would examine: (i) the continuity
between theory and action in AI ethics; (ii) the real-life effects of AI
ethics; (iii) the role and profile of those involved in AI ethics; and (iv) the
effects of AI on power relations through methods that pay attention to context,
emotions and narrative.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14701" title="Abstract">arXiv:2311.14701</a> [<a href="/pdf/2311.14701" title="Download PDF">pdf</a>, <a href="/ps/2311.14701" title="Download PostScript">ps</a>, <a href="/format/2311.14701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT as Co-Advisor in Scientific Initiation: Action Research with  Project-Based Learning in Elementary Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Villan%2C+F">Fabiano Villan</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+R+P+d">Renato P. dos Santos</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Acta Sci. (Canoas), 25(6), 60-117, Nov./Dec. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Background: In the contemporary educational landscape, technology has the
power to drive innovative pedagogical practices. Overcoming the resistance of
teachers and students to adopting new methods and technologies is a challenge
that needs to be addressed. Objectives: To evaluate the effectiveness of
ChatGPT as a co-advisor in research projects and its influence on the
implementation of Project-Based Learning (PBL), as well as overcoming
resistance to the use of new pedagogical methodologies. Design: An
action-research methodology was employed, including unstructured interviews and
the application of questionnaires via Google Forms. Setting and Participants:
The research was conducted in an elementary school, involving 353 students and
16 teachers. Data Collection and Analysis: Data were gathered through
observations and notes in meetings and interviews, complemented by electronic
questionnaires, with quantitative and qualitative analyses performed via
Microsoft Excel and Google Forms. Results: The introduction of ChatGPT as a
pedagogical tool led to increased student engagement and decreased teacher
resistance, reflected in recognition at local science fairs. Conclusion: The
study confirmed the utility of ChatGPT in school research co-orientation,
highlighting its role in facilitating PBL and promoting cultural changes in
educational practice, with proactive school management identified as a
catalysing element in adapting to educational innovations.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14702" title="Abstract">arXiv:2311.14702</a> [<a href="/pdf/2311.14702" title="Download PDF">pdf</a>, <a href="/ps/2311.14702" title="Download PostScript">ps</a>, <a href="/format/2311.14702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transdisciplinary AI Education: The Confluence of Curricular and  Community Needs in the Instruction of Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aliabadi%2C+R">Roozbeh Aliabadi</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Aditi Singh</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+E">Eryka Wilson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 2 tables, Artificial Intelligence in Education Technologies: New Development and Innovative Practices. AIET 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The integration of artificial intelligence (AI) into education has the
potential to transform the way we learn and teach. In this paper, we examine
the current state of AI in education and explore the potential benefits and
challenges of incorporating this technology into the classroom. The approaches
currently available for AI education often present students with experiences
only focusing on discrete computer science concepts agnostic to a larger
curriculum. However, teaching AI must not be siloed or interdisciplinary.
Rather, AI instruction ought to be transdisciplinary, including connections to
the broad curriculum and community in which students are learning. This paper
delves into the AI program currently in development for Neom Community School
and the larger Education, Research, and Innovation Sector in Neom, Saudi Arabia
s new megacity under development. In this program, AI is both taught as a
subject and to learn other subjects within the curriculum through the school
systems International Baccalaureate (IB) approach, which deploys learning
through Units of Inquiry. This approach to education connects subjects across a
curriculum under one major guiding question at a time. The proposed method
offers a meaningful approach to introducing AI to students throughout these
Units of Inquiry, as it shifts AI from a subject that students like or not like
to a subject that is taught throughout the curriculum.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14703" title="Abstract">arXiv:2311.14703</a> [<a href="/pdf/2311.14703" title="Download PDF">pdf</a>, <a href="/ps/2311.14703" title="Download PostScript">ps</a>, <a href="/format/2311.14703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT Exhibits Gender and Racial Biases in Acute Coronary Syndrome  Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Angela Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yuksekgonul%2C+M">Mert Yuksekgonul</a>, 
<a href="/search/cs?searchtype=author&query=Guild%2C+J">Joshua Guild</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">James Zou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J+C">Joseph C. Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 2 tables, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Recent breakthroughs in large language models (LLMs) have led to their rapid
dissemination and widespread use. One early application has been to medicine,
where LLMs have been investigated to streamline clinical workflows and
facilitate clinical analysis and decision-making. However, a leading barrier to
the deployment of Artificial Intelligence (AI) and in particular LLMs has been
concern for embedded gender and racial biases. Here, we evaluate whether a
leading LLM, ChatGPT 3.5, exhibits gender and racial bias in clinical
management of acute coronary syndrome (ACS). We find that specifying patients
as female, African American, or Hispanic resulted in a decrease in guideline
recommended medical management, diagnosis, and symptom management of ACS. Most
notably, the largest disparities were seen in the recommendation of coronary
angiography or stress testing for the diagnosis and further intervention of ACS
and recommendation of high intensity statins. These disparities correlate with
biases that have been observed clinically and have been implicated in the
differential gender and racial morbidity and mortality outcomes of ACS and
coronary artery disease. Furthermore, we find that the largest disparities are
seen during unstable angina, where fewer explicit clinical guidelines exist.
Finally, we find that through asking ChatGPT 3.5 to explain its reasoning prior
to providing an answer, we are able to improve clinical accuracy and mitigate
instances of gender and racial biases. This is among the first studies to
demonstrate that the gender and racial biases that LLMs exhibit do in fact
affect clinical management. Additionally, we demonstrate that existing
strategies that improve LLM performance not only improve LLM performance in
clinical management, but can also be used to mitigate gender and racial biases.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14704" title="Abstract">arXiv:2311.14704</a> [<a href="/pdf/2311.14704" title="Download PDF">pdf</a>, <a href="/ps/2311.14704" title="Download PostScript">ps</a>, <a href="/format/2311.14704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An&#xe1;lise e modelagem de jogos digitais: Relato de uma experi&#xea;ncia  educacional utlizando PBL em um grupo multidisciplinar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Oliveira+Lemes%2C+D">David de Oliveira Lemes</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+E+F+d">Ezequiel Fran&#xe7;a dos Santos</a>, 
<a href="/search/cs?searchtype=author&query=Romanek%2C+E">Eduardo Romanek</a>, 
<a href="/search/cs?searchtype=author&query=Fujimoto%2C+C">Celso Fujimoto</a>, 
<a href="/search/cs?searchtype=author&query=Valente%2C+A+F">Adriano Felix Valente</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Portuguese language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Traditional software engineering education generally emphasizes strict
collaboration and technical skills However active teaching strategies where
students actively engage with the material transitioning from passive observers
to active manipulators of realworld tools have shown effectiveness in software
engineering The evolving market demands new skills in the context of digital
transformation presenting challenges such as modeling complex business
scenarios and navigating the interconnections between people systems and
technologies Shifting from conventional software engineering instruction to
active methodologies like ProblemBased Learning PBL has proven to bring
realworld market challenges and realities into the classroom This article
details an experience from the Digital Games Analysis and Modeling course in
the Digital Games Masters program at Pontifical Catholic University of Sao
Paulo It covers the discussed concepts case study rolebased work method and
steps of the meetings We also present examples of outcomes like requirement
diagrams context diagrams use case diagrams class diagrams interviews and
others that contributed to the Game Design Document GDD These were created by
each group during the meetings alongside their game prototypes Additionally a
discussion on the developed capabilities is included
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14705" title="Abstract">arXiv:2311.14705</a> [<a href="/pdf/2311.14705" title="Download PDF">pdf</a>, <a href="/ps/2311.14705" title="Download PostScript">ps</a>, <a href="/format/2311.14705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ethics and Responsible AI Deployment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Radanliev%2C+P">Petar Radanliev</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+O">Omar Santos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC); Social and Information Networks (cs.SI); Systems and Control (eess.SY)

</div>
<p class="mathjax">As Artificial Intelligence (AI) becomes more prevalent, protecting personal
privacy is a critical ethical issue that must be addressed. This article
explores the need for ethical AI systems that safeguard individual privacy
while complying with ethical standards. By taking a multidisciplinary approach,
the research examines innovative algorithmic techniques such as differential
privacy, homomorphic encryption, federated learning, international regulatory
frameworks, and ethical guidelines. The study concludes that these algorithms
effectively enhance privacy protection while balancing the utility of AI with
the need to protect personal data. The article emphasises the importance of a
comprehensive approach that combines technological innovation with ethical and
regulatory strategies to harness the power of AI in a way that respects and
protects individual privacy.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14706" title="Abstract">arXiv:2311.14706</a> [<a href="/pdf/2311.14706" title="Download PDF">pdf</a>, <a href="/ps/2311.14706" title="Download PostScript">ps</a>, <a href="/format/2311.14706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social AI Improves Well-Being Among Female Young Adults
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Buse%2C+I">I. Buse</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Ebony Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiaoding Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">The rise of language models like ChatGPT has introduced Social AI as a new
form of entertainment, particularly among young adults who engage with
AI-powered agents. This paper investigates the effects of these interactions on
users' social and mental well-being, a subject that has incited extensive
debate among both the public and scholars. Our study involved a survey of 5,260
users of Chai, a Social AI Platform. The findings indicate significant
benefits, with notable variations across demographics. Female users, in
particular, reported the most substantial improvements: 43.4% strongly agreed
that Social AI positively impacted their mental health, exceeding male users by
10.5%. In managing social anxieties, 38.9% of females strongly agreed on a
positive impact, compared to 30.0% for males and 27.1% for other genders.
Historically, new media and technology have often been met with groundless
moral panic, with societal figures raising concerns without substantial
evidence of harm. Our research indicates the importance of approaching such
claims with caution and emphasizes the necessity of an evidence-based
perspective in discussions about the behavioral effects of emerging
technologies.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14707" title="Abstract">arXiv:2311.14707</a> [<a href="/pdf/2311.14707" title="Download PDF">pdf</a>, <a href="/format/2311.14707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Tracing Challenge: Optimal Activity Sequencing for Students
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hicke%2C+Y">Yann Hicke</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Course Project, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Knowledge tracing is a method used in education to assess and track the
acquisition of knowledge by individual learners. It involves using a variety of
techniques, such as quizzes, tests, and other forms of assessment, to determine
what a learner knows and does not know about a particular subject. The goal of
knowledge tracing is to identify gaps in understanding and provide targeted
instruction to help learners improve their understanding and retention of
material. This can be particularly useful in situations where learners are
working at their own pace, such as in online learning environments. By
providing regular feedback and adjusting instruction based on individual needs,
knowledge tracing can help learners make more efficient progress and achieve
better outcomes. Effectively solving the KT problem would unlock the potential
of computer-aided education applications such as intelligent tutoring systems,
curriculum learning, and learning materials recommendations. In this paper, we
will present the results of the implementation of two Knowledge Tracing
algorithms on a newly released dataset as part of the AAAI2023 Global Knowledge
Tracing Challenge.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14708" title="Abstract">arXiv:2311.14708</a> [<a href="/pdf/2311.14708" title="Download PDF">pdf</a>, <a href="/format/2311.14708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model-Driven Classroom Flipping: Empowering  Student-Centric Peer Questioning with Flipped Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+C+W">Chee Wei Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Reciprocal questioning is essential for effective teaching and learning,
fostering active engagement and deeper understanding through collaborative
interactions, especially in large classrooms. Can large language model (LLM),
such as OpenAI's GPT (Generative Pre-trained Transformer) series, assist in
this? This paper investigates a pedagogical approach of classroom flipping
based on flipped interaction in LLMs. Flipped interaction involves using
language models to prioritize generating questions instead of answers to
prompts. We demonstrate how traditional classroom flipping techniques,
including Peer Instruction and Just-in-Time Teaching (JiTT), can be enhanced
through flipped interaction techniques, creating student-centric questions for
hybrid teaching. In particular, we propose a workflow to integrate prompt
engineering with clicker and JiTT quizzes by a poll-prompt-quiz routine and a
quiz-prompt-discuss routine to empower students to self-regulate their learning
capacity and enable teachers to swiftly personalize training pathways. We
develop an LLM-driven chatbot software that digitizes various elements of
classroom flipping and facilitates the assessment of students using these
routines to deliver peer-generated questions. We have applied our LLM-driven
chatbot software for teaching both undergraduate and graduate students from
2020 to 2022, effectively useful for bridging the gap between teachers and
students in remote teaching during the COVID-19 pandemic years. In particular,
LLM-driven classroom flipping can be particularly beneficial in large class
settings to optimize teaching pace and enable engaging classroom experiences.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14709" title="Abstract">arXiv:2311.14709</a> [<a href="/pdf/2311.14709" title="Download PDF">pdf</a>, <a href="/format/2311.14709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Long-term Annotators: A Supervised Label Aggregation Baseline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haoyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Minmin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Runze Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+R">Renyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shiwei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+T">Tangjie Lv</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Changjie Fan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Relying on crowdsourced workers, data crowdsourcing platforms are able to
efficiently provide vast amounts of labeled data. Due to the variability in the
annotation quality of crowd workers, modern techniques resort to redundant
annotations and subsequent label aggregation to infer true labels. However,
these methods require model updating during the inference, posing challenges in
real-world implementation. Meanwhile, in recent years, many data labeling tasks
have begun to require skilled and experienced annotators, leading to an
increasing demand for long-term annotators. These annotators could leave
substantial historical annotation records on the crowdsourcing platforms, which
can benefit label aggregation, but are ignored by previous works. Hereby, in
this paper, we propose a novel label aggregation technique, which does not need
any model updating during inference and can extensively explore the historical
annotation records. We call it SuperLA, a Supervised Label Aggregation method.
Inside this model, we design three types of input features and a
straightforward neural network structure to merge all the information together
and subsequently produce aggregated labels. Based on comparison experiments
conducted on 22 public datasets and 11 baseline methods, we find that SuperLA
not only outperforms all those baselines in inference performance but also
offers significant advantages in terms of efficiency.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14710" title="Abstract">arXiv:2311.14710</a> [<a href="/pdf/2311.14710" title="Download PDF">pdf</a>, <a href="/format/2311.14710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuroscience inspired scientific machine learning (Part-2): Variable  spiking wavelet neural operator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garg%2C+S">Shailesh Garg</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+S">Souvik Chakraborty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose, in this paper, a Variable Spiking Wavelet Neural Operator
(VS-WNO), which aims to bridge the gap between theoretical and practical
implementation of Artificial Intelligence (AI) algorithms for mechanics
applications. With recent developments like the introduction of neural
operators, AI's potential for being used in mechanics applications has
increased significantly. However, AI's immense energy and resource requirements
are a hurdle in its practical field use case. The proposed VS-WNO is based on
the principles of spiking neural networks, which have shown promise in reducing
the energy requirements of the neural networks. This makes possible the use of
such algorithms in edge computing. The proposed VS-WNO utilizes variable
spiking neurons, which promote sparse communication, thus conserving energy,
and its use is further supported by its ability to tackle regression tasks,
often faced in the field of mechanics. Various examples dealing with partial
differential equations, like Burger's equation, Allen Cahn's equation, and
Darcy's equation, have been shown. Comparisons have been shown against wavelet
neural operator utilizing leaky integrate and fire neurons (direct and encoded
inputs) and vanilla wavelet neural operator utilizing artificial neurons. The
results produced illustrate the ability of the proposed VS-WNO to converge to
ground truth while promoting sparse communication.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14711" title="Abstract">arXiv:2311.14711</a> [<a href="/pdf/2311.14711" title="Download PDF">pdf</a>, <a href="/format/2311.14711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Publicly Accountable Frontier LLMs: Building an External  Scrutiny Ecosystem under the ASPIRE Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anderljung%2C+M">Markus Anderljung</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+E+T">Everett Thornton Smith</a>, 
<a href="/search/cs?searchtype=author&query=O%27Brien%2C+J">Joe O&#x27;Brien</a>, 
<a href="/search/cs?searchtype=author&query=Soder%2C+L">Lisa Soder</a>, 
<a href="/search/cs?searchtype=author&query=Bucknall%2C+B">Benjamin Bucknall</a>, 
<a href="/search/cs?searchtype=author&query=Bluemke%2C+E">Emma Bluemke</a>, 
<a href="/search/cs?searchtype=author&query=Schuett%2C+J">Jonas Schuett</a>, 
<a href="/search/cs?searchtype=author&query=Trager%2C+R">Robert Trager</a>, 
<a href="/search/cs?searchtype=author&query=Strahm%2C+L">Lacey Strahm</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+R">Rumman Chowdhury</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Workshop on Socially Responsible Language Modelling Research (SoLaR) at the 2023 Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the increasing integration of frontier large language models (LLMs) into
society and the economy, decisions related to their training, deployment, and
use have far-reaching implications. These decisions should not be left solely
in the hands of frontier LLM developers. LLM users, civil society and
policymakers need trustworthy sources of information to steer such decisions
for the better. Involving outside actors in the evaluation of these systems -
what we term 'external scrutiny' - via red-teaming, auditing, and external
researcher access, offers a solution. Though there are encouraging signs of
increasing external scrutiny of frontier LLMs, its success is not assured. In
this paper, we survey six requirements for effective external scrutiny of
frontier AI systems and organize them under the ASPIRE framework: Access,
Searching attitude, Proportionality to the risks, Independence, Resources, and
Expertise. We then illustrate how external scrutiny might function throughout
the AI lifecycle and offer recommendations to policymakers.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14712" title="Abstract">arXiv:2311.14712</a> [<a href="/pdf/2311.14712" title="Download PDF">pdf</a>, <a href="/ps/2311.14712" title="Download PostScript">ps</a>, <a href="/format/2311.14712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiagent Simulators for Social Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Surve%2C+A">Aditya Surve</a>, 
<a href="/search/cs?searchtype=author&query=Rathod%2C+A">Archit Rathod</a>, 
<a href="/search/cs?searchtype=author&query=Surana%2C+M">Mokshit Surana</a>, 
<a href="/search/cs?searchtype=author&query=Malpani%2C+G">Gautam Malpani</a>, 
<a href="/search/cs?searchtype=author&query=Shamraj%2C+A">Aneesh Shamraj</a>, 
<a href="/search/cs?searchtype=author&query=Sankepally%2C+S+R">Sainath Reddy Sankepally</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+R">Raghav Jain</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+S+S">Swapneel S Mehta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Multiagent social network simulations are an avenue that can bridge the
communication gap between the public and private platforms in order to develop
solutions to a complex array of issues relating to online safety. While there
are significant challenges relating to the scale of multiagent simulations,
efficient learning from observational and interventional data to accurately
model micro and macro-level emergent effects, there are equally promising
opportunities not least with the advent of large language models that provide
an expressive approximation of user behavior. In this position paper, we review
prior art relating to social network simulation, highlighting challenges and
opportunities for future work exploring multiagent security using agent-based
models of social networks
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14713" title="Abstract">arXiv:2311.14713</a> [<a href="/pdf/2311.14713" title="Download PDF">pdf</a>, <a href="/ps/2311.14713" title="Download PostScript">ps</a>, <a href="/format/2311.14713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Rise of the AI Co-Pilot: Lessons for Design from Aviation and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sellen%2C+A">Abigail Sellen</a>, 
<a href="/search/cs?searchtype=author&query=Horvitz%2C+E">Eric Horvitz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, no figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The fast pace of advances in AI promises to revolutionize various aspects of
knowledge work, extending its influence to daily life and professional fields
alike. We advocate for a paradigm where AI is seen as a collaborative co-pilot,
working under human guidance rather than as a mere tool. Drawing from relevant
research and literature in the disciplines of Human-Computer Interaction and
Human Factors Engineering, we highlight the criticality of maintaining human
oversight in AI interactions. Reflecting on lessons from aviation, we address
the dangers of over-relying on automation, such as diminished human vigilance
and skill erosion. Our paper proposes a design approach that emphasizes active
human engagement, control, and skill enhancement in the AI partnership, aiming
to foster a harmonious, effective, and empowering human-AI relationship. We
particularly call out the critical need to design AI interaction capabilities
and software applications to enable and celebrate the primacy of human agency.
This calls for designs for human-AI partnership that cede ultimate control and
responsibility to the human user as pilot, with the AI co-pilot acting in a
well-defined supporting role.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14718" title="Abstract">arXiv:2311.14718</a> [<a href="/pdf/2311.14718" title="Download PDF">pdf</a>, <a href="/format/2311.14718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demonstrative Evidence and the Use of Algorithms in Jury Trials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rogers%2C+R">Rachel Rogers</a>, 
<a href="/search/cs?searchtype=author&query=VanderPlas%2C+S">Susan VanderPlas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">We investigate how the potential use of algorithms and demonstrative evidence
may affect potential jurors' feelings of reliability, credibility, and
understanding of expert witnesses and presented evidence. The use of
statistical methods in forensic science is motivated by a lack of scientific
validity and error rate issues present in many forensic analysis methods. We
explore how this new method may be perceived in the courtroom - where
individuals unfamiliar with advanced statistical methods are asked to evaluate
its use in order to assess guilt. In the course of our initial study, we
discovered issues in scale compression of responses and survey format. We
visually compare participants' notes to the provided transcript by highlighting
phrase frequency based on collocations.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14720" title="Abstract">arXiv:2311.14720</a> [<a href="/pdf/2311.14720" title="Download PDF">pdf</a>, <a href="/format/2311.14720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Use in Manuscript Preparation for Academic Journals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chemaya%2C+N">Nir Chemaya</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+D">Daniel Martin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); General Economics (econ.GN)

</div>
<p class="mathjax">The emergent abilities of Large Language Models (LLMs), which power tools
like ChatGPT and Bard, have produced both excitement and worry about how AI
will impact academic writing. In response to rising concerns about AI use,
authors of academic publications may decide to voluntarily disclose any AI
tools they use to revise their manuscripts, and journals and conferences could
begin mandating disclosure and/or turn to using detection services, as many
teachers have done with student writing in class settings. Given these looming
possibilities, we investigate whether academics view it as necessary to report
AI use in manuscript preparation and how detectors react to the use of AI in
academic writing.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14721" title="Abstract">arXiv:2311.14721</a> [<a href="/pdf/2311.14721" title="Download PDF">pdf</a>, <a href="/format/2311.14721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnySyn: A Cost-Generic Logic Synthesis Framework with Customizable Cost  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Siang-Yun Lee</a>, 
<a href="/search/cs?searchtype=author&query=De+Micheli%2C+G">Giovanni De Micheli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Modern technology-independent logic synthesis has been developed to optimize
for the size and depth of AND-Inverter Graphs (AIGs) as a proxy of CMOS circuit
area and delay. However, for non-CMOS-based emerging technologies, AIG size and
depth may not be good cost estimations. Dedicated algorithms optimizing for
more complex cost functions have been proven effective for their specific
target applications yet require time and experts in both logic synthesis and
the targeted technology to develop. In this work, we propose AnySyn, a
cost-generic optimization framework for agile experimentation and prototyping
of various customized cost functions before investing in developing specialized
algorithms. Experimental results show that AnySyn outperforms non-specialized
size and depth optimization algorithms by 14% and 19% on average and achieves
comparable results to specialized algorithms within acceptable CPU time.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14722" title="Abstract">arXiv:2311.14722</a> [<a href="/pdf/2311.14722" title="Download PDF">pdf</a>, <a href="/format/2311.14722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Question Answering over Financial Documents using Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phogat%2C+K+S">Karmvir Singh Phogat</a>, 
<a href="/search/cs?searchtype=author&query=Harsha%2C+C">Chetan Harsha</a>, 
<a href="/search/cs?searchtype=author&query=Dasaratha%2C+S">Sridhar Dasaratha</a>, 
<a href="/search/cs?searchtype=author&query=Ramakrishna%2C+S">Shashishekar Ramakrishna</a>, 
<a href="/search/cs?searchtype=author&query=Puranam%2C+S+A">Sai Akhil Puranam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce a large language model (LLM) based approach to answer complex
questions requiring multi-hop numerical reasoning over financial reports. While
LLMs have exhibited remarkable performance on various natural language and
reasoning tasks, complex reasoning problems often rely on few-shot prompts that
require carefully crafted examples. In contrast, our approach uses novel
zero-shot prompts that guide the LLM to encode the required reasoning into a
Python program or a domain specific language. The generated program is then
executed by a program interpreter, thus mitigating the limitations of LLM in
performing accurate arithmetic calculations.
<br />We evaluate the proposed approach on three financial datasets using some of
the recently developed generative pretrained transformer (GPT) models and
perform comparisons with various zero-shot baselines. The experimental results
demonstrate that our approach significantly improves the accuracy for all the
LLMs over their respective baselines. We provide a detailed analysis of the
results, generating insights to support our findings. The success of our
approach demonstrates the enormous potential to extract complex domain specific
numerical reasoning by designing zero-shot prompts to effectively exploit the
knowledge embedded in LLMs.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14726" title="Abstract">arXiv:2311.14726</a> [<a href="/pdf/2311.14726" title="Download PDF">pdf</a>, <a href="/format/2311.14726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Guitar Tab Comparison
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heyen%2C+F">Frank Heyen</a>, 
<a href="/search/cs?searchtype=author&query=Mendoza%2C+A+G+D">Alejandro Gabino Diaz Mendoza</a>, 
<a href="/search/cs?searchtype=author&query=Ngo%2C+Q+Q">Quynh Quang Ngo</a>, 
<a href="/search/cs?searchtype=author&query=Sedlmair%2C+M">Michael Sedlmair</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Late-breaking demo for ISMIR 2023 <a href="https://ismir2023program.ismir.net/lbd_357.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We designed a visual interface for comparing different guitar tablature (tab)
versions of the same piece. By automatically aligning the bars of these
versions and visually encoding different metrics, our interface helps determine
similarity, difficulty, and correctness. During our design, we collected and
integrated feedback from musicians and finally conducted a qualitative
evaluation with five guitarists. Results confirm that our interface effectively
supports comparison and helps musicians choose a version appropriate for their
personal skills and tastes.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14727" title="Abstract">arXiv:2311.14727</a> [<a href="/pdf/2311.14727" title="Download PDF">pdf</a>, <a href="/format/2311.14727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Strategies to Perform Multilingual Analysis of Social Content  for a Novel Dataset in the Tourism Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Masson%2C+M">Maxime Masson</a>, 
<a href="/search/cs?searchtype=author&query=Agerri%2C+R">Rodrigo Agerri</a>, 
<a href="/search/cs?searchtype=author&query=Sallaberry%2C+C">Christian Sallaberry</a>, 
<a href="/search/cs?searchtype=author&query=Bessagnet%2C+M">Marie-Noelle Bessagnet</a>, 
<a href="/search/cs?searchtype=author&query=Lacayrelle%2C+A+L+P">Annig Le Parc Lacayrelle</a>, 
<a href="/search/cs?searchtype=author&query=Roose%2C+P">Philippe Roose</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The rising influence of social media platforms in various domains, including
tourism, has highlighted the growing need for efficient and automated natural
language processing (NLP) approaches to take advantage of this valuable
resource. However, the transformation of multilingual, unstructured, and
informal texts into structured knowledge often poses significant challenges.
<br />In this work, we evaluate and compare few-shot, pattern-exploiting and
fine-tuning machine learning techniques on large multilingual language models
(LLMs) to establish the best strategy to address the lack of annotated data for
3 common NLP tasks in the tourism domain: (1) Sentiment Analysis, (2) Named
Entity Recognition, and (3) Fine-grained Thematic Concept Extraction (linked to
a semantic resource). Furthermore, we aim to ascertain the quantity of
annotated examples required to achieve good performance in those 3 tasks,
addressing a common challenge encountered by NLP researchers in the
construction of domain-specific datasets.
<br />Extensive experimentation on a newly collected and annotated multilingual
(French, English, and Spanish) dataset composed of tourism-related tweets shows
that current few-shot learning techniques allow us to obtain competitive
results for all three tasks with very little annotation data: 5 tweets per
label (15 in total) for Sentiment Analysis, 10% of the tweets for location
detection (around 160) and 13% (200 approx.) of the tweets annotated with
thematic concepts, a highly fine-grained sequence labeling task based on an
inventory of 315 classes.
<br />This comparative analysis, grounded in a novel dataset, paves the way for
applying NLP to new domain-specific applications, reducing the need for manual
annotations and circumventing the complexities of rule-based, ad hoc solutions.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14729" title="Abstract">arXiv:2311.14729</a> [<a href="/pdf/2311.14729" title="Download PDF">pdf</a>, <a href="/format/2311.14729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> App for Resume-Based Job Matching with Speech Interviews and Grammar  Analysis: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+T">Tanmay Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Pardeshi%2C+Y">Yuvraj Pardeshi</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+Y">Yash Shah</a>, 
<a href="/search/cs?searchtype=author&query=Sakat%2C+V">Vaishnvi Sakat</a>, 
<a href="/search/cs?searchtype=author&query=Bhirud%2C+S">Sapana Bhirud</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 2 figures, literature review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Through the advancement in natural language processing (NLP), specifically in
speech recognition, fully automated complex systems functioning on voice input
have started proliferating in areas such as home automation. These systems have
been termed Automatic Speech Recognition Systems (ASR). In this review paper,
we explore the feasibility of an end-to-end system providing speech and text
based natural language processing for job interview preparation as well as
recommendation of relevant job postings. We also explore existing
recommender-based systems and note their limitations. This literature review
would help us identify the approaches and limitations of the various similar
use-cases of NLP technology for our upcoming project.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14730" title="Abstract">arXiv:2311.14730</a> [<a href="/pdf/2311.14730" title="Download PDF">pdf</a>, <a href="/format/2311.14730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MemoryCompanion: A Smart Healthcare Solution to Empower Efficient  Alzheimer&#x27;s Care Via Unleashing Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Lifei Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Heo%2C+Y">Yeonie Heo</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yi Fang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Machine Learning for Health (ML4H 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">With the rise of Large Language Models (LLMs), notably characterized by GPT
frameworks, there emerges a catalyst for novel healthcare applications. Earlier
iterations of chatbot caregivers, though existent, have yet to achieve a
dimension of human-like authenticity. This paper unveils `MemoryCompanion' a
pioneering digital health solution explicitly tailored for Alzheimer's disease
(AD) patients and their caregivers. Drawing upon the nuances of GPT technology
and prompt engineering, MemoryCompanion manifests a personalized caregiving
paradigm, fostering interactions via voice-cloning and talking-face mechanisms
that resonate with the familiarity of known companions. Using advanced
prompt-engineering, the system intricately adapts to each patient's distinct
profile, curating its content and communication style accordingly. This
approach strives to counteract prevalent issues of social isolation and
loneliness frequently observed in AD demographics. Our methodology, grounded in
its innovative design, addresses both the caregiving and technological
challenges intrinsic to this domain.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14733" title="Abstract">arXiv:2311.14733</a> [<a href="/pdf/2311.14733" title="Download PDF">pdf</a>, <a href="/format/2311.14733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Thinking Outside the Box: Orthogonal Approach to Equalizing Protected  Attributes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiahui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xiaohao Cai</a>, 
<a href="/search/cs?searchtype=author&query=Niranjan%2C+M">Mahesan Niranjan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">There is growing concern that the potential of black box AI may exacerbate
health-related disparities and biases such as gender and ethnicity in clinical
decision-making. Biased decisions can arise from data availability and
collection processes, as well as from the underlying confounding effects of the
protected attributes themselves. This work proposes a machine learning-based
orthogonal approach aiming to analyze and suppress the effect of the confounder
through discriminant dimensionality reduction and orthogonalization of the
protected attributes against the primary attribute information. By doing so,
the impact of the protected attributes on disease diagnosis can be realized,
undesirable feature correlations can be mitigated, and the model prediction
performance can be enhanced.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14734" title="Abstract">arXiv:2311.14734</a> [<a href="/pdf/2311.14734" title="Download PDF">pdf</a>, <a href="/format/2311.14734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Internet of Mirrors for Connected Healthcare and Beauty: A Prospective  Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fatima%2C+H">Haneen Fatima</a>, 
<a href="/search/cs?searchtype=author&query=Imran%2C+M+A">Muhammad Ali Imran</a>, 
<a href="/search/cs?searchtype=author&query=Taha%2C+A">Ahmad Taha</a>, 
<a href="/search/cs?searchtype=author&query=Mohjazi%2C+L">Lina Mohjazi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">With the shift towards smart objects and automated services in many
industries, the health and beauty industries are also becoming increasingly
involved in AI-driven smart systems. There is a rising market demand for
personalised services and a need for unified platforms in many sectors,
specifically the cosmetics and healthcare industries. Alongside this rising
demand, there are two major gaps when considering the integration of autonomous
systems within these sectors. Firstly, the existing smart systems in the
cosmetics industry are limited to single-purpose products and the employed
technologies are not widespread enough to support the growing consumer demand
for personalisation. Secondly, despite the rise of smart devices in healthcare,
the current state-of-the-art services do not fulfil the accessibility demands
and holistic nature of healthcare. To bridge these gaps, we propose integrating
autonomous systems with health and beauty services through a unified visual
platform coined as the Internet-of-Mirrors (IoM), an interconnected system of
smart mirrors with sensing and communication capabilities where the smart
mirror functions as an immersive visual dashboard to provide personalised
services for health and beauty consultations and routines. We aim to present an
overview of current state-of-the-art technologies that will enable the
development of the IoM as well as provide a practical vision of this system
with innovative scenarios to give a forward-looking vision for assistive
technologies. We also discuss the missing capabilities and challenges the
development of the IoM would face and outline future research directions that
will support the realisation of our proposed framework.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14736" title="Abstract">arXiv:2311.14736</a> [<a href="/pdf/2311.14736" title="Download PDF">pdf</a>, <a href="/format/2311.14736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Diversity Matters for Robust Instruction Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bukharin%2C+A">Alexander Bukharin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tuo Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Instruction tuning has emerged as a key step in aligning large language
models. One of the central challenges of instruction tuning is dataset
selection, as the composition of the instruction tuning dataset can
significantly impact downstream performance. In particular, researchers have
hypothesized that dataset diversity and dataset quality are important
indicators of downstream performance. However, it is not clear how to
automatically select high quality and diverse data or how exactly quality and
diversity affect instruction following ability. To resolve these issues, we
propose a new algorithm, Quality-Diversity Instruction Tuning (QDIT). QDIT
provides a principled algorithm to control dataset diversity and quality,
allowing us to conduct an in depth study on the effect of diversity and quality
on instruction tuning performance. From this study we draw two key insights (1)
there is a natural tradeoff between dataset diversity and quality and (2)
increasing dataset diversity significantly improves the worst case instruction
following performance, therefore improving robustness. We validate the
performance of QDIT on several large scale instruction tuning datasets, where
we find it can improve worst case performance by 18% while maintaining or
improving average performance compared to quality driven baselines.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14737" title="Abstract">arXiv:2311.14737</a> [<a href="/pdf/2311.14737" title="Download PDF">pdf</a>, <a href="/format/2311.14737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Positional Description Matters for Transformers Arithmetic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+R">Ruoqi Shen</a>, 
<a href="/search/cs?searchtype=author&query=Bubeck%2C+S">S&#xe9;bastien Bubeck</a>, 
<a href="/search/cs?searchtype=author&query=Eldan%2C+R">Ronen Eldan</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y+T">Yin Tat Lee</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Transformers, central to the successes in modern Natural Language Processing,
often falter on arithmetic tasks despite their vast capabilities --which
paradoxically include remarkable coding abilities. We observe that a crucial
challenge is their naive reliance on positional information to solve arithmetic
problems with a small number of digits, leading to poor performance on larger
numbers. Herein, we delve deeper into the role of positional encoding, and
propose several ways to fix the issue, either by modifying the positional
encoding directly, or by modifying the representation of the arithmetic task to
leverage standard positional encoding differently. We investigate the value of
these modifications for three tasks: (i) classical multiplication, (ii) length
extrapolation in addition, and (iii) addition in natural language context. For
(i) we train a small model on a small dataset (100M parameters and 300k
samples) with remarkable aptitude in (direct, no scratchpad) 15 digits
multiplication and essentially perfect up to 12 digits, while usual training in
this context would give a model failing at 4 digits multiplication. In the
experiments on addition, we use a mere 120k samples to demonstrate: for (ii)
extrapolation from 10 digits to testing on 12 digits numbers while usual
training would have no extrapolation, and for (iii) almost perfect accuracy up
to 5 digits while usual training would be correct only up to 3 digits (which is
essentially memorization with a training set of 120k samples).
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14740" title="Abstract">arXiv:2311.14740</a> [<a href="/pdf/2311.14740" title="Download PDF">pdf</a>, <a href="/format/2311.14740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoKG: Efficient Automated Knowledge Graph Generation for Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bohan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bertozzi%2C+A+L">Andrea L. Bertozzi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, accepted by IEEE BigData 2023 as a workshop paper in GTA3
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Traditional methods of linking large language models (LLMs) to knowledge
bases via the semantic similarity search often fall short of capturing complex
relational dynamics. To address these limitations, we introduce AutoKG, a
lightweight and efficient approach for automated knowledge graph (KG)
construction. For a given knowledge base consisting of text blocks, AutoKG
first extracts keywords using a LLM and then evaluates the relationship weight
between each pair of keywords using graph Laplace learning. We employ a hybrid
search scheme combining vector similarity and graph-based associations to
enrich LLM responses. Preliminary experiments demonstrate that AutoKG offers a
more comprehensive and interconnected knowledge retrieval mechanism compared to
the semantic similarity search, thereby enhancing the capabilities of LLMs in
generating more insightful and relevant outputs.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14741" title="Abstract">arXiv:2311.14741</a> [<a href="/pdf/2311.14741" title="Download PDF">pdf</a>, <a href="/ps/2311.14741" title="Download PostScript">ps</a>, <a href="/format/2311.14741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> @ve: A Chatbot for Latin
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bendel%2C+O">Oliver Bendel</a>, 
<a href="/search/cs?searchtype=author&query=N%27diaye%2C+K">Karim N&#x27;diaye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Dead, extinct, and endangered languages have been preserved primarily through
audio conservation and the collection and digitization of scripts and have been
promoted through targeted language acquisition efforts. Another possibility
would be to build conversational agents that can master these languages. This
would provide an artificial, active conversational partner which has knowledge
of the vocabulary and grammar, and one learns with it in a different way. The
chatbot @ve, with which one can communicate in Latin, was developed in
2022/2023 based on GPT-3.0. It was additionally equipped with a manually
created knowledge base. After conceptual groundwork, this paper presents the
preparation and implementation of the project. In addition, it summarizes the
test that a Latin expert conducted with the chatbot. A critical discussion
elaborates advantages and disadvantages. @ve could be a new tool for teaching
Latin in a memorable and entertaining way through dialogue. However, the
present implementation is still too prone to glitches for stand-alone use -
i.e., without the accompaniment of a teacher. The use of GPT-4 could be a
solution as well as the extension of the knowledge base. In conclusion, it can
be argued that conversational agents are an innovative approach to promoting
and preserving languages.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14742" title="Abstract">arXiv:2311.14742</a> [<a href="/pdf/2311.14742" title="Download PDF">pdf</a>, <a href="/format/2311.14742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Query-LIFE: Query-aware Language Image Fusion Embedding for E-Commerce  Relevance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hai Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuankai Guo</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+R">Ronggang Dou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kai Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Relevance module plays a fundamental role in e-commerce search as they are
responsible for selecting relevant products from thousands of items based on
user queries, thereby enhancing users experience and efficiency. The
traditional approach models the relevance based product titles and queries, but
the information in titles alone maybe insufficient to describe the products
completely. A more general optimization approach is to further leverage product
image information. In recent years, vision-language pre-training models have
achieved impressive results in many scenarios, which leverage contrastive
learning to map both textual and visual features into a joint embedding space.
In e-commerce, a common practice is to fine-tune on the pre-trained model based
on e-commerce data. However, the performance is sub-optimal because the
vision-language pre-training models lack of alignment specifically designed for
queries. In this paper, we propose a method called Query-LIFE (Query-aware
Language Image Fusion Embedding) to address these challenges. Query-LIFE
utilizes a query-based multimodal fusion to effectively incorporate the image
and title based on the product types. Additionally, it employs query-aware
modal alignment to enhance the accuracy of the comprehensive representation of
products. Furthermore, we design GenFilt, which utilizes the generation
capability of large models to filter out false negative samples and further
improve the overall performance of the contrastive learning task in the model.
Experiments have demonstrated that Query-LIFE outperforms existing baselines.
We have conducted ablation studies and human evaluations to validate the
effectiveness of each module within Query-LIFE. Moreover, Query-LIFE has been
deployed on Miravia Search, resulting in improved both relevance and conversion
efficiency.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14743" title="Abstract">arXiv:2311.14743</a> [<a href="/pdf/2311.14743" title="Download PDF">pdf</a>, <a href="/format/2311.14743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Baseline Analysis of Reward Models&#x27; Ability To Accurately Analyze  Foundation Models Under Distribution Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pikus%2C+B">Ben Pikus</a>, 
<a href="/search/cs?searchtype=author&query=LeVine%2C+W">Will LeVine</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tony Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hendryx%2C+S">Sean Hendryx</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Foundation models, specifically Large Language Models (LLM's), have lately
gained wide-spread attention and adoption. Reinforcement Learning with Human
Feedback (RLHF) involves training a reward model to capture desired behaviors,
which is then used to align an LLM. These reward models are additionally used
at inference-time to estimate how well LLM responses adhere to those desired
behaviors. However, there is little work measuring how robust these reward
models are to distribution shifts. In this work, we evaluate how reward model
performance - measured via accuracy and calibration (i.e. alignment between
accuracy and confidence) - is affected by distribution shift. We show novel
calibration patterns and accuracy drops due to OOD prompts and responses, and
that the reward model is more sensitive to shifts in responses than prompts.
Additionally, we adapt an OOD detection technique commonly used in
classification to the reward model setting in order to detect these
distribution shifts in prompts and responses.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14746" title="Abstract">arXiv:2311.14746</a> [<a href="/pdf/2311.14746" title="Download PDF">pdf</a>, <a href="/format/2311.14746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> All in One: RGB, RGB-D, and RGB-T Salient Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xingzhao Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhongqiu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dongye%2C+C">Changlei Dongye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Salient object detection (SOD) aims to identify the most attractive objects
within an image. Depending on the type of data being detected, SOD can be
categorized into various forms, including RGB, RGB-D (Depth), RGB-T (Thermal)
and light field SOD. Previous researches have focused on saliency detection
with individual data type. If the RGB-D SOD model is forced to detect RGB-T
data it will perform poorly. We propose an innovative model framework that
provides a unified solution for the salient object detection task of three
types of data (RGB, RGB-D, and RGB-T). The three types of data can be handled
in one model (all in one) with the same weight parameters. In this framework,
the three types of data are concatenated in an ordered manner within a single
input batch, and features are extracted using a transformer network. Based on
this framework, we propose an efficient lightweight SOD model, namely AiOSOD,
which can detect any RGB, RGB-D, and RGB-T data with high speed (780FPS for RGB
data, 485FPS for RGB-D or RGB-T data). Notably, with only 6.25M parameters,
AiOSOD achieves excellent performance on RGB, RGB-D, and RGB-T datasets.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14747" title="Abstract">arXiv:2311.14747</a> [<a href="/pdf/2311.14747" title="Download PDF">pdf</a>, <a href="/format/2311.14747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HOMOE: A Memory-Based and Composition-Aware Framework for Zero-Shot  Learning with Hopfield Network and Soft Mixture of Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dat%2C+D+H">Do Huu Dat</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+P+Y">Po Yuan Mao</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+H">Tien Hoang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Buntine%2C+W">Wray Buntine</a>, 
<a href="/search/cs?searchtype=author&query=Bennamoun%2C+M">Mohammed Bennamoun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Compositional Zero-Shot Learning (CZSL) has emerged as an essential paradigm
in machine learning, aiming to overcome the constraints of traditional
zero-shot learning by incorporating compositional thinking into its
methodology. Conventional zero-shot learning has difficulty managing unfamiliar
combinations of seen and unseen classes because it depends on pre-defined class
embeddings. In contrast, Compositional Zero-Shot Learning uses the inherent
hierarchies and structural connections among classes, creating new class
representations by combining attributes, components, or other semantic
elements. In our paper, we propose a novel framework that for the first time
combines the Modern Hopfield Network with a Mixture of Experts (HOMOE) to
classify the compositions of previously unseen objects. Specifically, the
Modern Hopfield Network creates a memory that stores label prototypes and
identifies relevant labels for a given input image. Following this, the Mixture
of Expert models integrates the image with the fitting prototype to produce the
final composition classification. Our approach achieves SOTA performance on
several benchmarks, including MIT-States and UT-Zappos. We also examine how
each component contributes to improved generalization.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14748" title="Abstract">arXiv:2311.14748</a> [<a href="/pdf/2311.14748" title="Download PDF">pdf</a>, <a href="/ps/2311.14748" title="Download PostScript">ps</a>, <a href="/format/2311.14748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Application of Reconfigurable All-Optical Activation Unit based on  Optical Injection into Bistable Fabry-P&#xe9;rot Laser in Multilayer  Perceptron Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Crnjanski%2C+J+V">Jasna V. Crnjanski</a>, 
<a href="/search/cs?searchtype=author&query=Teofilovi%C4%87%2C+I">Isidora Teofilovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Krsti%C4%87%2C+M+M">Marko M. Krsti&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Gvozdi%C4%87%2C+D+M">Dejan M. Gvozdi&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Optics (physics.optics)

</div>
<p class="mathjax">In this paper we theoretically investigate application of a bistable
Fabry-P\'{e}rot semiconductor laser under optical-injection as all-optical
activation unit for multilayer perceptron optical neural networks. The proposed
device is programmed to provide reconfigurable sigmoid-like activation
functions with adjustable thresholds and saturation points and benchmarked on
machine learning image recognition problems. Due to the reconfigurability of
the activation unit, the accuracy can be increased by up to 2% simply by
adjusting the control parameter of the activation unit to suit the specific
problem. For a simple two-layer perceptron neural network, we achieve inference
accuracies of up to 95% and 85%, for the MNIST and Fashion-MNIST datasets,
respectively.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14749" title="Abstract">arXiv:2311.14749</a> [<a href="/pdf/2311.14749" title="Download PDF">pdf</a>, <a href="/format/2311.14749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Zero-shot Learning via Progressive Language-based  Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lin Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guikun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jun Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Long Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Compositional zero-shot learning aims to recognize unseen state-object
compositions by leveraging known primitives (state and object) during training.
However, effectively modeling interactions between primitives and generalizing
knowledge to novel compositions remains a perennial challenge. There are two
key factors: object-conditioned and state-conditioned variance, i.e., the
appearance of states (or objects) can vary significantly when combined with
different objects (or states). For instance, the state "old" can signify a
vintage design for a "car" or an advanced age for a "cat". In this paper, we
argue that these variances can be mitigated by predicting composition
categories based on pre-observed primitive. To this end, we propose Progressive
Language-based Observations (PLO), which can dynamically determine a better
observation order of primitives. These observations comprise a series of
concepts or languages that allow the model to understand image content in a
step-by-step manner. Specifically, PLO adopts pre-trained vision-language
models (VLMs) to empower the model with observation capabilities. We further
devise two variants: 1) PLO-VLM: a two-step method, where a pre-observing
classifier dynamically determines the observation order of two primitives. 2)
PLO-LLM: a multi-step scheme, which utilizes large language models (LLMs) to
craft composition-specific prompts for step-by-step observing. Extensive
ablations on three challenging datasets demonstrate the superiority of PLO
compared with state-of-the-art methods, affirming its abilities in
compositional recognition.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14750" title="Abstract">arXiv:2311.14750</a> [<a href="/pdf/2311.14750" title="Download PDF">pdf</a>, <a href="/format/2311.14750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attribute-Aware Representation Rectification for Generalized Zero-Shot  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rao%2C+Z">Zhijie Rao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jingcai Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiaocheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qihua Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+K">Kang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Song Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generalized Zero-shot Learning (GZSL) has yielded remarkable performance by
designing a series of unbiased visual-semantics mappings, wherein, the
precision relies heavily on the completeness of extracted visual features from
both seen and unseen classes. However, as a common practice in GZSL, the
pre-trained feature extractor may easily exhibit difficulty in capturing
domain-specific traits of the downstream tasks/datasets to provide fine-grained
discriminative features, i.e., domain bias, which hinders the overall
recognition performance, especially for unseen classes. Recent studies
partially address this issue by fine-tuning feature extractors, while may
inevitably incur catastrophic forgetting and overfitting issues. In this paper,
we propose a simple yet effective Attribute-Aware Representation Rectification
framework for GZSL, dubbed $\mathbf{(AR)^{2}}$, to adaptively rectify the
feature extractor to learn novel features while keeping original valuable
features. Specifically, our method consists of two key components, i.e.,
Unseen-Aware Distillation (UAD) and Attribute-Guided Learning (AGL). During
training, UAD exploits the prior knowledge of attribute texts that are shared
by both seen/unseen classes with attention mechanisms to detect and maintain
unseen class-sensitive visual features in a targeted manner, and meanwhile, AGL
aims to steer the model to focus on valuable features and suppress them to fit
noisy elements in the seen classes by attribute-guided representation learning.
Extensive experiments on various benchmark datasets demonstrate the
effectiveness of our method.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14754" title="Abstract">arXiv:2311.14754</a> [<a href="/pdf/2311.14754" title="Download PDF">pdf</a>, <a href="/format/2311.14754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ExCeL : Combined Extreme and Collective Logit Information for Enhancing  Out-of-Distribution Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karunanayake%2C+N">Naveen Karunanayake</a>, 
<a href="/search/cs?searchtype=author&query=Seneviratne%2C+S">Suranga Seneviratne</a>, 
<a href="/search/cs?searchtype=author&query=Chawla%2C+S">Sanjay Chawla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deep learning models often exhibit overconfidence in predicting
out-of-distribution (OOD) data, underscoring the crucial role of OOD detection
in ensuring reliability in predictions. Among various OOD detection approaches,
post-hoc detectors have gained significant popularity, primarily due to their
ease of use and implementation. However, the effectiveness of most post-hoc OOD
detectors has been constrained as they rely solely either on extreme
information, such as the maximum logit, or on the collective information (i.e.,
information spanned across classes or training samples) embedded within the
output layer. In this paper, we propose ExCeL that combines both extreme and
collective information within the output layer for enhanced accuracy in OOD
detection. We leverage the logit of the top predicted class as the extreme
information (i.e., the maximum logit), while the collective information is
derived in a novel approach that involves assessing the likelihood of other
classes appearing in subsequent ranks across various training samples. Our idea
is motivated by the observation that, for in-distribution (ID) data, the
ranking of classes beyond the predicted class is more deterministic compared to
that in OOD data. Experiments conducted on CIFAR100 and ImageNet-200 datasets
demonstrate that ExCeL consistently is among the five top-performing methods
out of twenty-one existing post-hoc baselines when the joint performance on
near-OOD and far-OOD is considered (i.e., in terms of AUROC and FPR95).
Furthermore, ExCeL shows the best overall performance across both datasets,
unlike other baselines that work best on one dataset but has a performance drop
in the other.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14756" title="Abstract">arXiv:2311.14756</a> [<a href="/pdf/2311.14756" title="Download PDF">pdf</a>, <a href="/format/2311.14756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task-Distributionally Robust Data-Free Meta-Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zixuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhenyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yongxian Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Baoyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chun Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Data-Free Meta-Learning (DFML) aims to efficiently learn new tasks by
leveraging multiple pre-trained models without requiring their original
training data. Existing inversion-based DFML methods construct pseudo tasks
from a learnable dataset, which is inversely generated from the pre-trained
model pool. For the first time, we reveal two major challenges hindering their
practical deployments: Task-Distribution Shift (TDS) and Task-Distribution
Corruption (TDC). TDS leads to a biased meta-learner because of the skewed task
distribution towards newly generated tasks. TDC occurs when untrusted models
characterized by misleading labels or poor quality pollute the task
distribution. To tackle these issues, we introduce a robust DFML framework that
ensures task distributional robustness. We propose to meta-learn from a pseudo
task distribution, diversified through task interpolation within a compact
task-memory buffer. This approach reduces the meta-learner's overreliance on
newly generated tasks by maintaining consistent performance across a broader
range of interpolated memory tasks, thus ensuring its generalization for unseen
tasks. Additionally, our framework seamlessly incorporates an automated model
selection mechanism into the meta-training phase, parameterizing each model's
reliability as a learnable weight. This is optimized with a policy gradient
algorithm inspired by reinforcement learning, effectively addressing the
non-differentiable challenge posed by model selection. Comprehensive
experiments across various datasets demonstrate the framework's effectiveness
in mitigating TDS and TDC, underscoring its potential to improve DFML in
real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14757" title="Abstract">arXiv:2311.14757</a> [<a href="/pdf/2311.14757" title="Download PDF">pdf</a>, <a href="/format/2311.14757" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PointOBB: Learning Oriented Object Detection via Single Point  Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Junwei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xue Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qingyun Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yansheng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages,5 figures, 6 tables. Code: <a href="https://github.com/Luo-Z13/pointobb">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Single point-supervised object detection is gaining attention due to its
cost-effectiveness. However, existing approaches focus on generating horizontal
bounding boxes (HBBs) while ignoring oriented bounding boxes (OBBs) commonly
used for objects in aerial images. This paper proposes PointOBB, the first
single Point-based OBB generation method, for oriented object detection.
PointOBB operates through the collaborative utilization of three distinctive
views: an original view, a resized view, and a rotated/flipped (rot/flp) view.
Upon the original view, we leverage the resized and rot/flp views to build a
scale augmentation module and an angle acquisition module, respectively. In the
former module, a Scale-Sensitive Consistency (SSC) loss is designed to enhance
the deep network's ability to perceive the object scale. For accurate object
angle predictions, the latter module incorporates self-supervised learning to
predict angles, which is associated with a scale-guided Dense-to-Sparse (DS)
matching strategy for aggregating dense angles corresponding to sparse objects.
The resized and rot/flp views are switched using a progressive multi-view
switching strategy during training to achieve coupled optimization of scale and
angle. Experimental results on the DIOR-R and DOTA-v1.0 datasets demonstrate
that PointOBB achieves promising performance, and significantly outperforms
potential point-supervised baselines.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14758" title="Abstract">arXiv:2311.14758</a> [<a href="/pdf/2311.14758" title="Download PDF">pdf</a>, <a href="/format/2311.14758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point2RBox: Combine Knowledge from Synthetic Visual Patterns for  End-to-end Oriented Object Detection with Single Point Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+Y">Yu Yi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xue Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qingyun Li</a>, 
<a href="/search/cs?searchtype=author&query=Da%2C+F">Feipeng Da</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jifeng Dai</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures, 5 tables, code: <a href="https://github.com/open-mmlab/mmrotate">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the rapidly increasing demand for oriented object detection (OOD),
recent research involving weakly-supervised detectors for learning rotated box
(RBox) from the horizontal box (HBox) has attracted more and more attention. In
this paper, we explore a more challenging yet label-efficient setting, namely
single point-supervised OOD, and present our approach called Point2RBox.
Specifically, we propose to leverage two principles: 1) Synthetic pattern
knowledge combination: By sampling around each labelled point on the image, we
transfer the object feature to synthetic visual patterns with the known
bounding box to provide the knowledge for box regression. 2) Transform
self-supervision: With a transformed input image (e.g. scaled/rotated), the
output RBoxes are trained to follow the same transformation so that the network
can perceive the relative size/rotation between objects. The detector is
further enhanced by a few devised techniques to cope with peripheral issues,
e.g. the anchor/layer assignment as the size of the object is not available in
our point supervision setting. To our best knowledge, Point2RBox is the first
end-to-end solution for point-supervised OOD. In particular, our method uses a
lightweight paradigm, yet it achieves a competitive performance among
point-supervised alternatives, 41.05%/27.62%/80.01% on DOTA/DIOR/HRSC datasets.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14760" title="Abstract">arXiv:2311.14760</a> [<a href="/pdf/2311.14760" title="Download PDF">pdf</a>, <a href="/format/2311.14760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SinSR: Diffusion-Based Image Super-Resolution in a Single Step
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yufei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenhan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaohui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Lanqing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chau%2C+L">Lap-Pui Chau</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Kot%2C+A+C">Alex C. Kot</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+B">Bihan Wen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While super-resolution (SR) methods based on diffusion models exhibit
promising results, their practical application is hindered by the substantial
number of required inference steps. Recent methods utilize degraded images in
the initial state, thereby shortening the Markov chain. Nevertheless, these
solutions either rely on a precise formulation of the degradation process or
still necessitate a relatively lengthy generation path (e.g., 15 iterations).
To enhance inference speed, we propose a simple yet effective method for
achieving single-step SR generation, named SinSR. Specifically, we first derive
a deterministic sampling process from the most recent state-of-the-art (SOTA)
method for accelerating diffusion-based SR. This allows the mapping between the
input random noise and the generated high-resolution image to be obtained in a
reduced and acceptable number of inference steps during training. We show that
this deterministic mapping can be distilled into a student model that performs
SR within only one inference step. Additionally, we propose a novel
consistency-preserving loss to simultaneously leverage the ground-truth image
during the distillation process, ensuring that the performance of the student
model is not solely bound by the feature manifold of the teacher model,
resulting in further performance improvement. Extensive experiments conducted
on synthetic and real-world datasets demonstrate that the proposed method can
achieve comparable or even superior performance compared to both previous SOTA
methods and the teacher model, in just one sampling step, resulting in a
remarkable up to x10 speedup for inference. Our code will be released at
https://github.com/wyf0912/SinSR
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14762" title="Abstract">arXiv:2311.14762</a> [<a href="/pdf/2311.14762" title="Download PDF">pdf</a>, <a href="/format/2311.14762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The 2nd Workshop on Maritime Computer Vision (MaCVi) 2024
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kiefer%2C+B">Benjamin Kiefer</a>, 
<a href="/search/cs?searchtype=author&query=%C5%BDust%2C+L">Lojze &#x17d;ust</a>, 
<a href="/search/cs?searchtype=author&query=Kristan%2C+M">Matej Kristan</a>, 
<a href="/search/cs?searchtype=author&query=Per%C5%A1%2C+J">Janez Per&#x161;</a>, 
<a href="/search/cs?searchtype=author&query=Ter%C5%A1ek%2C+M">Matija Ter&#x161;ek</a>, 
<a href="/search/cs?searchtype=author&query=Wiliem%2C+A">Arnold Wiliem</a>, 
<a href="/search/cs?searchtype=author&query=Messmer%2C+M">Martin Messmer</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cheng-Yen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hsiang-Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhongyu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Kuo%2C+H">Heng-Cheng Kuo</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+J">Jie Mei</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jenq-Neng Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Stadler%2C+D">Daniel Stadler</a>, 
<a href="/search/cs?searchtype=author&query=Sommer%2C+L">Lars Sommer</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaer Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+A">Aiguo Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chong%2C+W">Weitu Chong</a>, 
<a href="/search/cs?searchtype=author&query=Lertniphonphan%2C+K">Kanokphan Lertniphonphan</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Feng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jian Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhepeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zedda%2C+L">Luca Zedda</a>, 
<a href="/search/cs?searchtype=author&query=Loddo%2C+A">Andrea Loddo</a>, 
<a href="/search/cs?searchtype=author&query=Di+Ruberto%2C+C">Cecilia Di Ruberto</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+T">Tuan-Anh Vu</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen-Truong%2C+H">Hai Nguyen-Truong</a>, 
<a href="/search/cs?searchtype=author&query=Ha%2C+T">Tan-Sang Ha</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+Q">Quan-Dung Pham</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+S">Sai-Kit Yeung</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yuan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Thien%2C+N+T">Nguyen Thanh Thien</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+L">Lixin Tian</a>, 
<a href="/search/cs?searchtype=author&query=Kuan%2C+S">Sheng-Yao Kuan</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+Y">Yuan-Hao Ho</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+A+B">Angel Bueno Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Carrillo-Perez%2C+B">Borja Carrillo-Perez</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+A">Alexander Klein</a>, 
<a href="/search/cs?searchtype=author&query=Alex%2C+A">Antje Alex</a>, 
<a href="/search/cs?searchtype=author&query=Steiniger%2C+Y">Yannik Steiniger</a>, 
<a href="/search/cs?searchtype=author&query=Sattler%2C+F">Felix Sattler</a>, 
<a href="/search/cs?searchtype=author&query=Solano-Carrillo%2C+E">Edgardo Solano-Carrillo</a>, 
<a href="/search/cs?searchtype=author&query=Fabijani%C4%87%2C+M">Matej Fabijani&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0umunec%2C+M">Magdalena &#x160;umunec</a>, 
<a href="/search/cs?searchtype=author&query=Kapetanovi%C4%87%2C+N">Nadir Kapetanovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Michel%2C+A">Andreas Michel</a>, 
<a href="/search/cs?searchtype=author&query=Gross%2C+W">Wolfgang Gross</a>, 
<a href="/search/cs?searchtype=author&query=Weinmann%2C+M">Martin Weinmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Part of 2nd Workshop on Maritime Computer Vision (MaCVi) 2024 IEEE Xplore submission as part of WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The 2nd Workshop on Maritime Computer Vision (MaCVi) 2024 addresses maritime
computer vision for Unmanned Aerial Vehicles (UAV) and Unmanned Surface
Vehicles (USV). Three challenges categories are considered: (i) UAV-based
Maritime Object Tracking with Re-identification, (ii) USV-based Maritime
Obstacle Segmentation and Detection, (iii) USV-based Maritime Boat Tracking.
The USV-based Maritime Obstacle Segmentation and Detection features three
sub-challenges, including a new embedded challenge addressing efficicent
inference on real-world embedded devices. This report offers a comprehensive
overview of the findings from the challenges. We provide both statistical and
qualitative analyses, evaluating trends from over 195 submissions. All
datasets, evaluation code, and the leaderboard are available to the public at
https://macvi.org/workshop/macvi24.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14763" title="Abstract">arXiv:2311.14763</a> [<a href="/pdf/2311.14763" title="Download PDF">pdf</a>, <a href="/format/2311.14763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Front-End Rectifier Modeling and Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhetessov%2C+A">Aidar Zhetessov</a>, 
<a href="/search/eess?searchtype=author&query=Petersen%2C+N">Nathan Petersen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Modeling and comprehensive analysis of the Active Front-End (AFE) rectifier
is addressed in this work. The particular emphasis is on the comparison of two
state feedback control frameworks: state-space and frequency domain. The
equivalence of both frameworks for the AFE case was shown. Moreover, analytical
relations between control gains and system parameters was derived, allowing for
explicit gain scheduling as a function of operating point over the mission
profile. The state observation of grid currents has also been addressed.
Finally, the work shows the example of robustness evaluation in presence of
system variation using the Lyapunov functions approach. The system in nominal
conditions was shown to be robust with respect to $50\%$ AC hardware parameter
variations.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14764" title="Abstract">arXiv:2311.14764</a> [<a href="/pdf/2311.14764" title="Download PDF">pdf</a>, <a href="/format/2311.14764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SafeSea: Synthetic Data Generation for Adverse &amp; Low Probability  Maritime Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+M">Martin Tran</a>, 
<a href="/search/cs?searchtype=author&query=Shipard%2C+J">Jordan Shipard</a>, 
<a href="/search/cs?searchtype=author&query=Mulyono%2C+H">Hermawan Mulyono</a>, 
<a href="/search/cs?searchtype=author&query=Wiliem%2C+A">Arnold Wiliem</a>, 
<a href="/search/cs?searchtype=author&query=Fookes%2C+C">Clinton Fookes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV 2024 workshop on Maritime Computer Vision
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">High-quality training data is essential for enhancing the robustness of
object detection models. Within the maritime domain, obtaining a diverse real
image dataset is particularly challenging due to the difficulty of capturing
sea images with the presence of maritime objects , especially in stormy
conditions. These challenges arise due to resource limitations, in addition to
the unpredictable appearance of maritime objects. Nevertheless, acquiring data
from stormy conditions is essential for training effective maritime detection
models, particularly for search and rescue, where real-world conditions can be
unpredictable. In this work, we introduce SafeSea, which is a stepping stone
towards transforming actual sea images with various Sea State backgrounds while
retaining maritime objects. Compared to existing generative methods such as
Stable Diffusion Inpainting~\cite{stableDiffusion}, this approach reduces the
time and effort required to create synthetic datasets for training maritime
object detection models. The proposed method uses two automated filters to only
pass generated images that meet the criteria. In particular, these filters will
first classify the sea condition according to its Sea State level and then it
will check whether the objects from the input image are still preserved. This
method enabled the creation of the SafeSea dataset, offering diverse weather
condition backgrounds to supplement the training of maritime models. Lastly, we
observed that a maritime object detection model faced challenges in detecting
objects in stormy sea backgrounds, emphasizing the impact of weather conditions
on detection accuracy. The code, and dataset are available at
https://github.com/martin-3240/SafeSea.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14766" title="Abstract">arXiv:2311.14766</a> [<a href="/pdf/2311.14766" title="Download PDF">pdf</a>, <a href="/format/2311.14766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning from Statistical Feedback: the Journey from AB  Testing to ANT Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+F">Feiyang Han</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yimin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhaofeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yanxing Qi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Methodology (stat.ME)

</div>
<p class="mathjax">Reinforcement Learning from Human Feedback (RLHF) has played a crucial role
in the success of large models such as ChatGPT. RLHF is a reinforcement
learning framework which combines human feedback to improve learning
effectiveness and performance. However, obtaining preferences feedback manually
is quite expensive in commercial applications. Some statistical commercial
indicators are usually more valuable and always ignored in RLHF. There exists a
gap between commercial target and model training. In our research, we will
attempt to fill this gap with statistical business feedback instead of human
feedback, using AB testing which is a well-established statistical method.
Reinforcement Learning from Statistical Feedback (RLSF) based on AB testing is
proposed. Statistical inference methods are used to obtain preferences for
training the reward network, which fine-tunes the pre-trained model in
reinforcement learning framework, achieving greater business value.
Furthermore, we extend AB testing with double selections at a single time-point
to ANT testing with multiple selections at different feedback time points.
Moreover, we design numerical experiences to validate the effectiveness of our
algorithm framework.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14767" title="Abstract">arXiv:2311.14767</a> [<a href="/pdf/2311.14767" title="Download PDF">pdf</a>, <a href="/ps/2311.14767" title="Download PostScript">ps</a>, <a href="/format/2311.14767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Cost HEM with Arduino and Zigbee Technologies in the Energy Sector  in Colombia
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=de+la+Cruz+Severiche+Maury%2C+Z">Zurisaddai de la Cruz Severiche Maury</a>, 
<a href="/search/eess?searchtype=author&query=Vilas%2C+A+F">Ana Fernandez Vilas</a>, 
<a href="/search/eess?searchtype=author&query=Redondo%2C+R+D">Rebeca Diaz Redondo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Energies 2022, 15(10), 3819
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Since no solutions have been proposed in Colombia that seek to reduce the
consumption of electricity at the residential level, this paper describes the
design and implementation of a simple prototype of a low-cost home energy
management system (HEMS). The objective of this plat-form is to monitor the
energy consumption of typical household devices so that users can access the
consumption of each device separately and then establish the strategy that
allows them to reduce energy consumption at home. In order to demonstrate that
our system is viable, the system has been evaluated by measuring weekly energy
consumption with the on-line and off-line HEMS using a test bench with typical
household devices in a Sincelejo typical household. The evaluation has shown
that with the installation of this HEMS, consumption is reduced by 27%. This
shows that it is possible to achieve a good reduction percentage with a
low-cost system.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14768" title="Abstract">arXiv:2311.14768</a> [<a href="/pdf/2311.14768" title="Download PDF">pdf</a>, <a href="/format/2311.14768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaDiff: Adaptive Step Selection for Fast Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zuxuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhen Xing</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jie Shao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu-Gang Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Diffusion models, as a type of generative models, have achieved impressive
results in generating images and videos conditioned on textual conditions.
However, the generation process of diffusion models involves denoising for
dozens of steps to produce photorealistic images/videos, which is
computationally expensive. Unlike previous methods that design
``one-size-fits-all'' approaches for speed up, we argue denoising steps should
be sample-specific conditioned on the richness of input texts. To this end, we
introduce AdaDiff, a lightweight framework designed to learn instance-specific
step usage policies, which are then used by the diffusion model for generation.
AdaDiff is optimized using a policy gradient method to maximize a carefully
designed reward function, balancing inference time and generation quality. We
conduct experiments on three image generation and two video generation
benchmarks and demonstrate that our approach achieves similar results in terms
of visual quality compared to the baseline using a fixed 50 denoising steps
while reducing inference time by at least 33%, going as high as 40%.
Furthermore, our qualitative analysis shows that our method allocates more
steps to more informative text conditions and fewer steps to simpler text
conditions.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14770" title="Abstract">arXiv:2311.14770</a> [<a href="/pdf/2311.14770" title="Download PDF">pdf</a>, <a href="/format/2311.14770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Cooperate and Communicate Over Imperfect Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weil%2C+J">Jannis Weil</a>, 
<a href="/search/cs?searchtype=author&query=Ekinci%2C+G">Gizem Ekinci</a>, 
<a href="/search/cs?searchtype=author&query=Koeppl%2C+H">Heinz Koeppl</a>, 
<a href="/search/cs?searchtype=author&query=Meuser%2C+T">Tobias Meuser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Information exchange in multi-agent systems improves the cooperation among
agents, especially in partially observable settings. In the real world,
communication is often carried out over imperfect channels. This requires
agents to handle uncertainty due to potential information loss. In this paper,
we consider a cooperative multi-agent system where the agents act and exchange
information in a decentralized manner using a limited and unreliable channel.
To cope with such channel constraints, we propose a novel communication
approach based on independent Q-learning. Our method allows agents to
dynamically adapt how much information to share by sending messages of
different sizes, depending on their local observations and the channel's
properties. In addition to this message size selection, agents learn to encode
and decode messages to improve their jointly trained policies. We show that our
approach outperforms approaches without adaptive capabilities in a novel
cooperative digit-prediction environment and discuss its limitations in the
traffic junction environment.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14772" title="Abstract">arXiv:2311.14772</a> [<a href="/pdf/2311.14772" title="Download PDF">pdf</a>, <a href="/format/2311.14772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trainwreck: A damaging adversarial attack on image classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zah%C3%A1lka%2C+J">Jan Zah&#xe1;lka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Adversarial attacks are an important security concern for computer vision
(CV), as they enable malicious attackers to reliably manipulate CV models.
Existing attacks aim to elicit an output desired by the attacker, but keep the
model fully intact on clean data. With CV models becoming increasingly valuable
assets in applied practice, a new attack vector is emerging: disrupting the
models as a form of economic sabotage. This paper opens up the exploration of
damaging adversarial attacks (DAAs) that seek to damage the target model and
maximize the total cost incurred by the damage. As a pioneer DAA, this paper
proposes Trainwreck, a train-time attack that poisons the training data of
image classifiers to degrade their performance. Trainwreck conflates the data
of similar classes using stealthy ($\epsilon \leq 8/255$) class-pair universal
perturbations computed using a surrogate model. Trainwreck is a black-box,
transferable attack: it requires no knowledge of the target model's
architecture, and a single poisoned dataset degrades the performance of any
model trained on it. The experimental evaluation on CIFAR-10 and CIFAR-100
demonstrates that Trainwreck is indeed an effective attack across various model
architectures including EfficientNetV2, ResNeXt-101, and a finetuned ViT-L-16.
The strength of the attack can be customized by the poison rate parameter.
Finally, data redundancy with file hashing and/or pixel difference are
identified as a reliable defense technique against Trainwreck or similar DAAs.
The code is available at https://github.com/JanZahalka/trainwreck.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14773" title="Abstract">arXiv:2311.14773</a> [<a href="/pdf/2311.14773" title="Download PDF">pdf</a>, <a href="/format/2311.14773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Set Features for Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cohen%2C+N">Niv Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Tzachor%2C+I">Issar Tzachor</a>, 
<a href="/search/cs?searchtype=author&query=Hoshen%2C+Y">Yedid Hoshen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2302.12245">arXiv:2302.12245</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper proposes set features for detecting anomalies in samples that
consist of unusual combinations of normal elements. Many leading methods
discover anomalies by detecting an unusual part of a sample. For example,
state-of-the-art segmentation-based approaches, first classify each element of
the sample (e.g., image patch) as normal or anomalous and then classify the
entire sample as anomalous if it contains anomalous elements. However, such
approaches do not extend well to scenarios where the anomalies are expressed by
an unusual combination of normal elements. In this paper, we overcome this
limitation by proposing set features that model each sample by the distribution
of its elements. We compute the anomaly score of each sample using a simple
density estimation method, using fixed features. Our approach outperforms the
previous state-of-the-art in image-level logical anomaly detection and
sequence-level time series anomaly detection.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14775" title="Abstract">arXiv:2311.14775</a> [<a href="/pdf/2311.14775" title="Download PDF">pdf</a>, <a href="/format/2311.14775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> READS-V: Real-time Automated Detection of Epileptic Seizures from  Surveillance Videos via Skeleton-based Spatiotemporal ViG
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yankun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ming%2C+W">Wenjie Ming</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sawan%2C+M">Mohamad Sawan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">An accurate and efficient epileptic seizure onset detection system can
significantly benefit patients. Traditional diagnostic methods, primarily
relying on electroencephalograms (EEGs), often result in cumbersome and
non-portable solutions, making continuous patient monitoring challenging. The
video-based seizure detection system is expected to free patients from the
constraints of scalp or implanted EEG devices and enable remote monitoring in
residential settings. Previous video-based methods neither enable all-day
monitoring nor provide short detection latency due to insufficient resources
and ineffective patient action recognition techniques. Additionally,
skeleton-based action recognition approaches remain limitations in identifying
subtle seizure-related actions. To address these challenges, we propose a novel
skeleton-based spatiotemporal vision graph neural network (STViG) for
efficient, accurate, and timely REal-time Automated Detection of epileptic
Seizures from surveillance Videos (READS-V). Our experimental results indicate
STViG outperforms previous state-of-the-art action recognition models on our
collected patients' video data with higher accuracy (5.9% error) and lower
FLOPs (0.4G). Furthermore, by integrating a decision-making rule that combines
output probabilities and an accumulative function, our READS-V system achieves
a 5.1 s EEG onset detection latency, a 13.1 s advance in clinical onset
detection, and zero false detection rate.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14778" title="Abstract">arXiv:2311.14778</a> [<a href="/pdf/2311.14778" title="Download PDF">pdf</a>, <a href="/format/2311.14778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anomaly detection in cross-country money transfer temporal networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vilella%2C+S">Salvatore Vilella</a>, 
<a href="/search/cs?searchtype=author&query=Lupi%2C+A+T+E+C">Arthur Thomas Edward Capozzi Lupi</a>, 
<a href="/search/cs?searchtype=author&query=Fornasiero%2C+M">Marco Fornasiero</a>, 
<a href="/search/cs?searchtype=author&query=Moncalvo%2C+D">Dario Moncalvo</a>, 
<a href="/search/cs?searchtype=author&query=Ricci%2C+V">Valeria Ricci</a>, 
<a href="/search/cs?searchtype=author&query=Ronchiadin%2C+S">Silvia Ronchiadin</a>, 
<a href="/search/cs?searchtype=author&query=Ruffo%2C+G">Giancarlo Ruffo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computational Engineering, Finance, and Science (cs.CE); Information Retrieval (cs.IR)

</div>
<p class="mathjax">During the last decades, Anti-Financial Crime (AFC) entities and Financial
Institutions have put a constantly increasing effort to reduce financial crime
and detect fraudulent activities, that are changing and developing in extremely
complex ways. We propose an anomaly detection approach based on network
analysis to help AFC officers navigating through the high load of information
that is typical of AFC data-driven scenarios. By experimenting on a large
financial dataset of more than 80M cross-country wire transfers, we leverage on
the properties of complex networks to develop a tool for explainable anomaly
detection, that can help in identifying outliers that could be engaged in
potentially malicious activities according to financial regulations. We
identify a set of network centrality measures that provide useful insights on
individual nodes; by keeping track of the evolution over time of the
centrality-based node rankings, we are able to highlight sudden and unexpected
changes in the roles of individual nodes that deserve further attention by AFC
officers. Such changes can hardly be noticed by means of current AFC practices,
that sometimes can lack a higher-level, global vision of the system. This
approach represents a preliminary step in the automation of AFC and AML
processes, serving the purpose of facilitating the work of AFC officers by
providing them with a top-down view of the picture emerging from financial
data.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14782" title="Abstract">arXiv:2311.14782</a> [<a href="/pdf/2311.14782" title="Download PDF">pdf</a>, <a href="/format/2311.14782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One Fits All: Universal Time Series Analysis by Pretrained LM and  Specially Designed Adaptors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+P">Peisong Niu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Liang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+R">Rong Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> this article draws heavily from <a href="/abs/2302.11939">arXiv:2302.11939</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Despite the impressive achievements of pre-trained models in the fields of
natural language processing (NLP) and computer vision (CV), progress in the
domain of time series analysis has been limited. In contrast to NLP and CV,
where a single model can handle various tasks, time series analysis still
relies heavily on task-specific methods for activities such as classification,
anomaly detection, forecasting, and few-shot learning. The primary obstacle to
developing a pre-trained model for time series analysis is the scarcity of
sufficient training data. In our research, we overcome this obstacle by
utilizing pre-trained models from language or CV, which have been trained on
billions of data points, and apply them to time series analysis. We assess the
effectiveness of the pre-trained transformer model in two ways. Initially, we
maintain the original structure of the self-attention and feedforward layers in
the residual blocks of the pre-trained language or image model, using the
Frozen Pre-trained Transformer (FPT) for time series analysis with the addition
of projection matrices for input and output. Additionally, we introduce four
unique adapters, designed specifically for downstream tasks based on the
pre-trained model, including forecasting and anomaly detection. These adapters
are further enhanced with efficient parameter tuning, resulting in superior
performance compared to all state-of-the-art methods.Our comprehensive
experimental studies reveal that (a) the simple FPT achieves top-tier
performance across various time series analysis tasks; and (b) fine-tuning the
FPT with the custom-designed adapters can further elevate its performance,
outshining specialized task-specific models.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14783" title="Abstract">arXiv:2311.14783</a> [<a href="/pdf/2311.14783" title="Download PDF">pdf</a>, <a href="/ps/2311.14783" title="Download PostScript">ps</a>, <a href="/format/2311.14783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> cryptoRAN: A review on cryptojacking and ransomware attacks w.r.t.  banking industry -- threats, challenges, &amp; problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kshetri%2C+N">Naresh Kshetri</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+M">Mir Mehedi Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Sayeed%2C+S+A">Sayed Abu Sayeed</a>, 
<a href="/search/cs?searchtype=author&query=Sultana%2C+I">Irin Sultana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In the banking industry, ransomware is a well-known threat, but since the
beginning of 2022, cryptojacking, an emerging threat is posing a considerable
challenge to the banking industry. Ransomware has variants, and the attackers
keep changing the nature of these variants. This review paper studies the
complex background of these two threats and scrutinizes the actual challenges,
and problems that the banking industry and financial institutions face. These
threats, though distinct in nature, share commonalities, such as financial
motivations and sophisticated techniques. We focus on examining the newly
emerged variants of ransomware while we provide a comprehensive idea of
cryptojacking and its nature. This paper involves a detailed breakdown of the
specific threats posed by cryptojacking and ransomware. It explores the
techniques cybercriminals use, the variabilities they look for, and the
potential consequences for financial institutions and their customers. This
paper also finds out how cybercriminals change their techniques following the
security upgrades, and why financial firms including banks need to be proactive
about cyber threats. Additionally, this paper reviews the background study of
some existing papers, finds the research gaps that need to be addressed, and
provides suggestions including a conclusion and future scope on those disputes.
Lastly, we introduce a Digital Forensics and Incident Response (DFIR) approach
for up-to-date cyber threat hunting processes for minimizing both cryptojacking
and ransomware attacks in the banking industry.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14786" title="Abstract">arXiv:2311.14786</a> [<a href="/pdf/2311.14786" title="Download PDF">pdf</a>, <a href="/format/2311.14786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT-4V Takes the Wheel: Evaluating Promise and Challenges for Pedestrian  Behavior Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jia Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+P">Peng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Gautam%2C+A">Alvika Gautam</a>, 
<a href="/search/cs?searchtype=author&query=Saripalli%2C+S">Srikanth Saripalli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Existing pedestrian behavior prediction methods rely primarily on deep neural
networks that utilize features extracted from video frame sequences. Although
these vision-based models have shown promising results, they face limitations
in effectively capturing and utilizing the dynamic spatio-temporal interactions
between the target pedestrian and its surrounding traffic elements, crucial for
accurate reasoning. Additionally, training these models requires manually
annotating domain-specific datasets, a process that is expensive,
time-consuming, and difficult to generalize to new environments and scenarios.
The recent emergence of Large Multimodal Models (LMMs) offers potential
solutions to these limitations due to their superior visual understanding and
causal reasoning capabilities, which can be harnessed through semi-supervised
training. GPT-4V(ision), the latest iteration of the state-of-the-art
Large-Language Model GPTs, now incorporates vision input capabilities. This
report provides a comprehensive evaluation of the potential of GPT-4V for
pedestrian behavior prediction in autonomous driving using publicly available
datasets: JAAD, PIE, and WiDEVIEW. Quantitative and qualitative evaluations
demonstrate GPT-4V(ision)'s promise in zero-shot pedestrian behavior prediction
and driving scene understanding ability for autonomous driving. However, it
still falls short of the state-of-the-art traditional domain-specific models.
Challenges include difficulties in handling small pedestrians and vehicles in
motion. These limitations highlight the need for further research and
development in this area.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14788" title="Abstract">arXiv:2311.14788</a> [<a href="/pdf/2311.14788" title="Download PDF">pdf</a>, <a href="/format/2311.14788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Large Language Models through Gender and Racial Stereotypes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malik%2C+A">Ananya Malik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 12 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Language Models have ushered a new age of AI gaining traction within the NLP
community as well as amongst the general population. AI's ability to make
predictions, generations and its applications in sensitive decision-making
scenarios, makes it even more important to study these models for possible
biases that may exist and that can be exaggerated. We conduct a quality
comparative study and establish a framework to evaluate language models under
the premise of two kinds of biases: gender and race, in a professional setting.
We find out that while gender bias has reduced immensely in newer models, as
compared to older ones, racial bias still exists.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14790" title="Abstract">arXiv:2311.14790</a> [<a href="/pdf/2311.14790" title="Download PDF">pdf</a>, <a href="/format/2311.14790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tamper-Evident Pairing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manev%2C+A">Aleksandar Manev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Establishing a secure connection between wireless devices has become
significantly important with the increasing number of Wi-Fi products coming to
the market. In order to provide an easy and secure pairing standard, the Wi-Fi
Alliance has designed the Wi-Fi Protected Setup. Push-Button Configuration
(PBC) is part of this standard and is especially useful for pairing devices
with physical limitations. However, PBC is proven to be vulnerable to
man-in-the-middle (MITM) attacks. Tamper-Evident Pairing (TEP) is an
improvement of the PBC standard, which aims to fix the MITM vulnerability
without interfering the useful properties of PBC. It relies on the
Tamper-Evident Announcement (TEA), which guarantees that an adversary can
neither tamper a transmitted message without being detected, nor hide the fact
that the message has been sent. The security properties of TEP were proven
manually by its authors and tested with the Uppaal and Spin model checkers.
During the Uppaal model checking, no vulnerabilities were found. However, the
Spin model revealed a case, in which the TEP's security is not guaranteed. In
this paper, we first provide a comprehensive overview of the TEP protocol,
including all information needed to understand how it works. Furthermore, we
summarize the security checks performed on it, give the circumstances, under
which it is no longer resistant to MITM attacks and explain the reasons why
they could not be revealed with the first model. Nevertheless, future work is
required to gain full certainty of the TEP's security before applying it in the
industry.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14808" title="Abstract">arXiv:2311.14808</a> [<a href="/pdf/2311.14808" title="Download PDF">pdf</a>, <a href="/ps/2311.14808" title="Download PostScript">ps</a>, <a href="/format/2311.14808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-to-Text Bilingual Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lapalme%2C+G">Guy Lapalme</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This document illustrates the use of pyrealb for generating two parallel
texts (English and French) from a single source of data. The data selection and
text organisation processes are shared between the two languages. only language
dependent word and phrasing choices are distinct processes. The realized texts
thus convey identical information in both languages without the risk of being
lost in translation. This is especially important in cases where strict and
simultaneous bilingualism is required. We first present the types of
applications targeted by this approach and how the pyrealb English and French
realizer can be used for achieving this goal in a natural way. We describe an
object-oriented organization to ensure a convenient realization in both
languages. To illustrate the process, different types of applications are then
briefly sketched with links to the source code. A brief comparison of the text
generation is given with the output of an instance of a GPT.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14811" title="Abstract">arXiv:2311.14811</a> [<a href="/pdf/2311.14811" title="Download PDF">pdf</a>, <a href="/format/2311.14811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Message Complexity of Distributed Graph Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dufoulon%2C+F">Fabien Dufoulon</a>, 
<a href="/search/cs?searchtype=author&query=Pai%2C+S">Shreyas Pai</a>, 
<a href="/search/cs?searchtype=author&query=Pandurangan%2C+G">Gopal Pandurangan</a>, 
<a href="/search/cs?searchtype=author&query=Pemmaraju%2C+S+V">Sriram V. Pemmaraju</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+P">Peter Robinson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The message complexity of a distributed algorithm is the total number of
messages sent by all nodes over the course of the algorithm. This paper studies
the message complexity of distributed algorithms for fundamental graph
optimization problems. We focus on four classical graph optimization problems:
Maximum Matching (MaxM), Minimum Vertex Cover (MVC), Minimum Dominating Set
(MDS), and Maximum Independent Set (MaxIS). In the sequential setting, these
problems are representative of a wide spectrum of hardness of approximation.
While there has been some progress in understanding the round complexity of
distributed algorithms (for both exact and approximate versions) for these
problems, much less is known about their message complexity and its relation
with the quality of approximation. We almost fully quantify the message
complexity of distributed graph optimization by showing the following
results...[see paper for full abstract]
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14822" title="Abstract">arXiv:2311.14822</a> [<a href="/pdf/2311.14822" title="Download PDF">pdf</a>, <a href="/format/2311.14822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text and Click inputs for unambiguous open vocabulary instance  segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Warner%2C+N">Nikolai Warner</a>, 
<a href="/search/cs?searchtype=author&query=Hahn%2C+M">Meera Hahn</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jonathan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Essa%2C+I">Irfan Essa</a>, 
<a href="/search/cs?searchtype=author&query=Birodkar%2C+V">Vighnesh Birodkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 9 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Segmentation localizes objects in an image on a fine-grained per-pixel scale.
Segmentation benefits by humans-in-the-loop to provide additional input of
objects to segment using a combination of foreground or background clicks.
Tasks include photoediting or novel dataset annotation, where human annotators
leverage an existing segmentation model instead of drawing raw pixel level
annotations. We propose a new segmentation process, Text + Click segmentation,
where a model takes as input an image, a text phrase describing a class to
segment, and a single foreground click specifying the instance to segment.
Compared to previous approaches, we leverage open-vocabulary image-text models
to support a wide-range of text prompts. Conditioning segmentations on text
prompts improves the accuracy of segmentations on novel or unseen classes. We
demonstrate that the combination of a single user-specified foreground click
and a text prompt allows a model to better disambiguate overlapping or
co-occurring semantic categories, such as "tie", "suit", and "person". We study
these results across common segmentation datasets such as refCOCO, COCO, VOC,
and OpenImages. Source code available here.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14824" title="Abstract">arXiv:2311.14824</a> [<a href="/pdf/2311.14824" title="Download PDF">pdf</a>, <a href="/ps/2311.14824" title="Download PostScript">ps</a>, <a href="/format/2311.14824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Reusable AI-Enabled Defect Detection System for Railway Using  Ensembled CNN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferdousi%2C+R">Rahatara Ferdousi</a>, 
<a href="/search/cs?searchtype=author&query=Laamarti%2C+F">Fedwa Laamarti</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chunsheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Saddik%2C+A+E">Abdulmotaleb El Saddik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 13 Figures, Applied Intelligence Journal, Springer Nature
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Accurate Defect detection is crucial for ensuring the trustworthiness of
intelligent railway systems. Current approaches rely on single deep-learning
models, like CNNs, which employ a large amount of data to capture underlying
patterns. Training a new defect classifier with limited samples often leads to
overfitting and poor performance on unseen images. To address this, researchers
have advocated transfer learning and fine-tuning the pre-trained models.
However, using a single backbone network in transfer learning still may cause
bottleneck issues and inconsistent performance if it is not suitable for a
specific problem domain. To overcome these challenges, we propose a reusable
AI-enabled defect detection approach. By combining ensemble learning with
transfer learning models (VGG-19, MobileNetV3, and ResNet-50), we improved the
classification accuracy and achieved consistent performance at a certain phase
of training. Our empirical analysis demonstrates better and more consistent
performance compared to other state-of-the-art approaches. The consistency
substantiates the reusability of the defect detection system for newly evolved
defected rail parts. Therefore we anticipate these findings to benefit further
research and development of reusable AI-enabled solutions for railway systems.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14829" title="Abstract">arXiv:2311.14829</a> [<a href="/pdf/2311.14829" title="Download PDF">pdf</a>, <a href="/format/2311.14829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proximal Algorithms for Accelerated Langevin Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thai%2C+D+H">Duy H. Thai</a>, 
<a href="/search/cs?searchtype=author&query=Young%2C+A+L">Alexander L. Young</a>, 
<a href="/search/cs?searchtype=author&query=Dunson%2C+D+B">David B. Dunson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We develop a novel class of MCMC algorithms based on a stochastized Nesterov
scheme. With an appropriate addition of noise, the result is a
time-inhomogeneous underdamped Langevin equation, which we prove emits a
specified target distribution as its invariant measure. Convergence rates to
stationarity under Wasserstein-2 distance are established as well.
Metropolis-adjusted and stochastic gradient versions of the proposed Langevin
dynamics are also provided. Experimental illustrations show superior
performance of the proposed method over typical Langevin samplers for different
models in statistics and image processing including better mixing of the
resulting Markov chains.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14831" title="Abstract">arXiv:2311.14831</a> [<a href="/pdf/2311.14831" title="Download PDF">pdf</a>, <a href="/format/2311.14831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Study of MMSE-Based Resource Allocation for Clustered Cell-Free Massive  MIMO Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mashdour%2C+S">S. Mashdour</a>, 
<a href="/search/cs?searchtype=author&query=de+Lamare%2C+R+C">R. C. de Lamare</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, a downlink cell-free massive multiple-input multiple-output
(CF massive MIMO) system and a network clustering is considered. Closed form
sum-rate expressions are derived for CF and the clustered CF (CLCF) networks
where linear precoders included zero forcing (ZF) and minimum mean square error
(MMSE) are implemented. An MMSE-based resource allocation technique with
multiuser scheduling based on an enhanced greedy technique and power allocation
based on the gradient descent (GD) method is proposed in the CLCF network to
improve the system performance. Numerical results show that the proposed
technique is superior to the existing approaches and the computational cost and
the signaling load are essentially reduced in the CLCF network.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14835" title="Abstract">arXiv:2311.14835</a> [<a href="/pdf/2311.14835" title="Download PDF">pdf</a>, <a href="/format/2311.14835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weak Alignment Supervision from Hybrid Model Improves End-to-end ASR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jintao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yingbo Gao</a>, 
<a href="/search/cs?searchtype=author&query=Tuske%2C+Z">Zoltan Tuske</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures, and 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In this paper, we aim to create weak alignment supervision to aid the
end-to-end modeling. Towards this end, we use the existing hybrid ASR system to
produce triphone alignments of the training audios. We then create a
cross-entropy loss at a certain layer of the encoder using the derived
alignments. In contrast to the general one-hot cross-entropy losses with or
without loss weighting, here we use a cross-entropy loss with a label smoothing
parameter to regularize the supervision. As a comparison, we also conduct the
experiments with one-hot cross-entropy losses and CTC losses with loss
weighting. The results show that placing the weak alignment supervision with
the label smoothing parameter of 0.5 at the third encoder layer outperforms the
other two approaches and leads to about 5% relative WER reduction on the
TED-LIUM 2 dataset over the baseline. We see similar improvements when applying
the method out-of-the-box on a Tagalog end-to-end ASR system.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14836" title="Abstract">arXiv:2311.14836</a> [<a href="/pdf/2311.14836" title="Download PDF">pdf</a>, <a href="/ps/2311.14836" title="Download PostScript">ps</a>, <a href="/format/2311.14836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Custom Data Augmentation for low resource ASR using Bark and  Retrieval-Based Voice Conversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kamble%2C+A">Anand Kamble</a>, 
<a href="/search/cs?searchtype=author&query=Tathe%2C+A">Aniket Tathe</a>, 
<a href="/search/cs?searchtype=author&query=Kumbharkar%2C+S">Suyash Kumbharkar</a>, 
<a href="/search/cs?searchtype=author&query=Bhandare%2C+A">Atharva Bhandare</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+A+C">Anirban C. Mitra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This paper proposes two innovative methodologies to construct customized
Common Voice datasets for low-resource languages like Hindi. The first
methodology leverages Bark, a transformer-based text-to-audio model developed
by Suno, and incorporates Meta's enCodec and a pre-trained HuBert model to
enhance Bark's performance. The second methodology employs Retrieval-Based
Voice Conversion (RVC) and uses the Ozen toolkit for data preparation. Both
methodologies contribute to the advancement of ASR technology and offer
valuable insights into addressing the challenges of constructing customized
Common Voice datasets for under-resourced languages. Furthermore, they provide
a pathway to achieving high-quality, personalized voice generation for a range
of applications.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14837" title="Abstract">arXiv:2311.14837</a> [<a href="/pdf/2311.14837" title="Download PDF">pdf</a>, <a href="/format/2311.14837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Robustness of Text-Image Composed Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shitong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jindong Gu</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+S">Shaogang Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by R0-FoMo: Workshop on Robustness of Few-shot and Zero-shot Learning in Foundation Models at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Text-image composed retrieval aims to retrieve the target image through the
composed query, which is specified in the form of an image plus some text that
describes desired modifications to the input image. It has recently attracted
attention due to its ability to leverage both information-rich images and
concise language to precisely express the requirements for target images.
However, the robustness of these approaches against real-world corruptions or
further text understanding has never been studied. In this paper, we perform
the first robustness study and establish three new diversified benchmarks for
systematic analysis of text-image composed retrieval against natural
corruptions in both vision and text and further probe textural understanding.
For natural corruption analysis, we introduce two new large-scale benchmark
datasets, CIRR-C and FashionIQ-C for testing in open domain and fashion domain
respectively, both of which apply 15 visual corruptions and 7 textural
corruptions. For textural understanding analysis, we introduce a new diagnostic
dataset CIRR-D by expanding the original raw data with synthetic data, which
contains modified text to better probe textual understanding ability including
numerical variation, attribute variation, object removal, background variation,
and fine-grained evaluation. The code and benchmark datasets are available at
https://github.com/SunTongtongtong/Benchmark-Robustness-Text-Image-Compose-Retrieval.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14838" title="Abstract">arXiv:2311.14838</a> [<a href="/pdf/2311.14838" title="Download PDF">pdf</a>, <a href="/format/2311.14838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpusCleaner and OpusTrainer, open source toolkits for training Machine  Translation and Large language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bogoychev%2C+N">Nikolay Bogoychev</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Linde%2C+J">Jelmer van der Linde</a>, 
<a href="/search/cs?searchtype=author&query=Nail%2C+G">Graeme Nail</a>, 
<a href="/search/cs?searchtype=author&query=Haddow%2C+B">Barry Haddow</a>, 
<a href="/search/cs?searchtype=author&query=Zaragoza-Bernabeu%2C+J">Jaume Zaragoza-Bernabeu</a>, 
<a href="/search/cs?searchtype=author&query=Ram%C3%ADrez-S%C3%A1nchez%2C+G">Gema Ram&#xed;rez-S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Weymann%2C+L">Lukas Weymann</a>, 
<a href="/search/cs?searchtype=author&query=Mateiu%2C+T+N">Tudor Nicolae Mateiu</a>, 
<a href="/search/cs?searchtype=author&query=Helcl%2C+J">Jind&#x159;ich Helcl</a>, 
<a href="/search/cs?searchtype=author&query=Aulamo%2C+M">Mikko Aulamo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code on Github: <a href="https://github.com/hplt-project/OpusCleaner">this https URL</a> and <a href="https://github.com/hplt-project/OpusTrainer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Developing high quality machine translation systems is a labour intensive,
challenging and confusing process for newcomers to the field. We present a pair
of tools OpusCleaner and OpusTrainer that aim to simplify the process, reduce
the amount of work and lower the entry barrier for newcomers.
<br />OpusCleaner is a data downloading, cleaning, and proprocessing toolkit. It is
designed to allow researchers to quickly download, visualise and preprocess
bilingual (or monolingual) data that comes from many different sources, each of
them with different quality, issues, and unique filtering/preprocessing
requirements.
<br />OpusTrainer is a data scheduling and data augmenting tool aimed at building
large scale, robust machine translation systems and large language models. It
features deterministic data mixing from many different sources, on-the-fly data
augmentation and more.
<br />Using these tools, we showcase how we can use it to create high quality
machine translation model robust to noisy user input; multilingual models and
terminology aware models.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14842" title="Abstract">arXiv:2311.14842</a> [<a href="/pdf/2311.14842" title="Download PDF">pdf</a>, <a href="/format/2311.14842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Characterization of Optimal-Rate Linear Homomorphic Secret Sharing  Schemes, and Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blackwell%2C+K">Keller Blackwell</a>, 
<a href="/search/cs?searchtype=author&query=Wootters%2C+M">Mary Wootters</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">A Homomorphic Secret Sharing (HSS) scheme is a secret-sharing scheme that
shares a secret $x$ among $s$ servers, and additionally allows an output client
to reconstruct some function $f(x)$, using information that can be locally
computed by each server. A key parameter in HSS schemes is download rate, which
quantifies how much information the output client needs to download from each
server. Recent work (Fosli, Ishai, Kolobov, and Wootters, ITCS 2022)
established a fundamental limitation on the download rate of linear HSS schemes
for computing low-degree polynomials, and gave an example of HSS schemes that
meet this limit.
<br />In this paper, we further explore optimal-rate linear HSS schemes for
polynomials. Our main result is a complete characterization of such schemes, in
terms of a coding-theoretic notion that we introduce, termed optimal
labelweight codes. We use this characterization to answer open questions about
the amortization required by HSS schemes that achieve optimal download rate. In
more detail, the construction of Fosli et al. required amortization over $\ell$
instances of the problem, and only worked for particular values of $\ell$. We
show that -- perhaps surprisingly -- the set of $\ell$'s for which their
construction works is in fact nearly optimal, possibly leaving out only one
additional value of $\ell$. We show this by using our coding-theoretic
characterization to prove a necessary condition on the $\ell$'s admitting
optimal-rate linear HSS schemes. We then provide a slightly improved
construction of optimal-rate linear HSS schemes, where the set of allowable
$\ell$'s is optimal in even more parameter settings. Moreover, based on a
connection to the MDS conjecture, we conjecture that our construction is
optimal for all parameter regimes.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14845" title="Abstract">arXiv:2311.14845</a> [<a href="/pdf/2311.14845" title="Download PDF">pdf</a>, <a href="/format/2311.14845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightweight Public Key Encryption in Post-Quantum Computing Era
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hillmann%2C+P">Peter Hillmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS); Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Confidentiality in our digital world is based on the security of
cryptographic algorithms. These are usually executed transparently in the
background, with people often relying on them without further knowledge. In the
course of technological progress with quantum computers, the protective
function of common encryption algorithms is threatened. This particularly
affects public-key methods such as RSA and DH based on discrete logarithms and
prime factorization. Our concept describes the transformation of a classical
asymmetric encryption method to a modern complexity class. Thereby the approach
of Cramer-Shoup is put on the new basis of elliptic curves. The system is
provable cryptographically strong, especially against adaptive
chosen-ciphertext attacks. In addition, the new method features small key
lengths, making it suitable for Internet-of-Things. It represents an
intermediate step towards an encryption scheme based on isogeny elliptic
curves. This approach shows a way to a secure encryption scheme for the
post-quantum computing era.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14848" title="Abstract">arXiv:2311.14848</a> [<a href="/pdf/2311.14848" title="Download PDF">pdf</a>, <a href="/format/2311.14848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robotic Detection and Estimation of Single Scuba Diver Respiration Rate  from Underwater Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kutzke%2C+D+T">Demetrious T. Kutzke</a>, 
<a href="/search/cs?searchtype=author&query=Sattar%2C+J">Junaed Sattar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Human respiration rate (HRR) is an important physiological metric for
diagnosing a variety of health conditions from stress levels to heart
conditions. Estimation of HRR is well-studied in controlled terrestrial
environments, yet robotic estimation of HRR as an indicator of diver stress in
underwater for underwater human robot interaction (UHRI) scenarios is to our
knowledge unexplored. We introduce a novel system for robotic estimation of HRR
from underwater visual data by utilizing bubbles from exhalation cycles in
scuba diving to time respiration rate. We introduce a fuzzy labeling system
that utilizes audio information to label a diverse dataset of diver breathing
data on which we compare four different methods for characterizing the presence
of bubbles in images. Ultimately we show that our method is effective at
estimating HRR by comparing the respiration rate output with human analysts.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14850" title="Abstract">arXiv:2311.14850</a> [<a href="/pdf/2311.14850" title="Download PDF">pdf</a>, <a href="/format/2311.14850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TrojanedCM: A Repository for Poisoned Neural Models of Source Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hussain%2C+A">Aftab Hussain</a>, 
<a href="/search/cs?searchtype=author&query=Rabin%2C+M+R+I">Md Rafiqul Islam Rabin</a>, 
<a href="/search/cs?searchtype=author&query=Alipour%2C+M+A">Mohammad Amin Alipour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">With the rapid growth of research in trojaning deep neural models of source
code, we observe that there is a need of developing a benchmark trojaned models
for testing various trojan detection and unlearning techniques. In this work,
we aim to provide the scientific community with a diverse pool of trojaned code
models using which they can experiment with such techniques. We present
\textsc{TrojanedCM}, a publicly available repository of clean and poisoned
models of source code. We provide poisoned models for two code classification
tasks (defect detection and clone detection) and a code generation task
(text-to-code generation). We finetuned popular pretrained code models such as
CodeBERT, PLBART, CodeT5, CodeT5+, on poisoned datasets that we generated from
benchmark datasets (Devign, BigCloneBench, CONCODE) for the above mentioned
tasks. The repository also provides full access to the architecture and weights
of the models, allowing practitioners to investigate different white-box
analysis techniques. In addition to the poisoned models, we also provide a
poisoning framework using which practitioners can deploy various poisoning
strategies for the different tasks and models of source code. All the material
are accessible via this link: https://github.com/UH-SERG/TrojanedCM.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14851" title="Abstract">arXiv:2311.14851</a> [<a href="/pdf/2311.14851" title="Download PDF">pdf</a>, <a href="/format/2311.14851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified Medical Image Pre-training in Language-Guided Common Semantic  Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaoxuan He</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yifan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xinyang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xufang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Haoji Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Siyun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuqing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Lili Qiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision-Language Pre-training (VLP) has shown the merits of analysing medical
images, by leveraging the semantic congruence between medical images and their
corresponding reports. It efficiently learns visual representations, which in
turn facilitates enhanced analysis and interpretation of intricate imaging
data. However, such observation is predominantly justified on single-modality
data (mostly 2D images like X-rays), adapting VLP to learning unified
representations for medical images in real scenario remains an open challenge.
This arises from medical images often encompass a variety of modalities,
especially modalities with different various number of dimensions (e.g., 3D
images like Computed Tomography). To overcome the aforementioned challenges, we
propose an Unified Medical Image Pre-training framework, namely UniMedI, which
utilizes diagnostic reports as common semantic space to create unified
representations for diverse modalities of medical images (especially for 2D and
3D images). Under the text's guidance, we effectively uncover visual modality
information, identifying the affected areas in 2D X-rays and slices containing
lesion in sophisticated 3D CT scans, ultimately enhancing the consistency
across various medical imaging modalities. To demonstrate the effectiveness and
versatility of UniMedI, we evaluate its performance on both 2D and 3D images
across 10 different datasets, covering a wide range of medical image tasks such
as classification, segmentation, and retrieval. UniMedI has demonstrated
superior performance in downstream tasks, showcasing its effectiveness in
establishing a universal medical visual representation.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14858" title="Abstract">arXiv:2311.14858</a> [<a href="/pdf/2311.14858" title="Download PDF">pdf</a>, <a href="/ps/2311.14858" title="Download PostScript">ps</a>, <a href="/format/2311.14858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced MIMO-DCT-OFDM System Using Cosine Domain Equalizer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramadan%2C+K">Khaled Ramadan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Performance (cs.PF); Signal Processing (eess.SP)

</div>
<p class="mathjax">Discrete Cosine Transform (DCT) can be used instead of conventional Discrete
Fourier Transform (DFT) for the Orthogonal Frequency Division Multiplexing
(OFDM) construction, which offers many advantages. In this paper, the
Multiple-Input-Multiple-Output (MIMO) DCT-OFDM is enhanced using a proposed
Cosine Domain Equalizer (CDE) instead of a Frequency Domain Equalizer (FDE).
The results are evaluated through the Rayleigh fading channel with Co-Carrier
Frequency Offset (Co-CFO) of different MIMO configurations. The average bit
error probability and the simulated time of the proposed scheme and the
conventional one is compared, which indicates the importance of the proposed
scheme. Also, a closed formula for the number of arithmetic operations of the
proposed equalizer is developed. The proposed equalizer gives a simulation time
reduction of about 81.21%, 83.74% compared to that of the conventional LZF-FDE,
and LMMSE-FDE, respectively for the case of 4x4 configuration.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14859" title="Abstract">arXiv:2311.14859</a> [<a href="/pdf/2311.14859" title="Download PDF">pdf</a>, <a href="/format/2311.14859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Investigation into Benchmarking Model Multiplicity for  Trustworthy Machine Learning: A Case Study on Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ganesh%2C+P">Prakhar Ganesh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deep learning models have proven to be highly successful. Yet, their
over-parameterization gives rise to model multiplicity, a phenomenon in which
multiple models achieve similar performance but exhibit distinct underlying
behaviours. This multiplicity presents a significant challenge and necessitates
additional specifications in model selection to prevent unexpected failures
during deployment. While prior studies have examined these concerns, they focus
on individual metrics in isolation, making it difficult to obtain a
comprehensive view of multiplicity in trustworthy machine learning. Our work
stands out by offering a one-stop empirical benchmark of multiplicity across
various dimensions of model design and its impact on a diverse set of
trustworthy metrics. In this work, we establish a consistent language for
studying model multiplicity by translating several trustworthy metrics into
accuracy under appropriate interventions. We also develop a framework, which we
call multiplicity sheets, to benchmark multiplicity in various scenarios. We
demonstrate the advantages of our setup through a case study in image
classification and provide actionable insights into the impact and trends of
different hyperparameters on model multiplicity. Finally, we show that
multiplicity persists in deep learning models even after enforcing additional
specifications during model selection, highlighting the severity of
over-parameterization. The concerns of under-specification thus remain, and we
seek to promote a more comprehensive discussion of multiplicity in trustworthy
machine learning.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14861" title="Abstract">arXiv:2311.14861</a> [<a href="/pdf/2311.14861" title="Download PDF">pdf</a>, <a href="/format/2311.14861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Voltage Constrained Heavy Duty Vehicle Electrification: Formulation and  Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shukla%2C+A">Apurv Shukla</a>, 
<a href="/search/eess?searchtype=author&query=Helou%2C+R+E">Rayan El Helou</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+L">Le Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CDC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The electrification of heavy-duty vehicles (HDEVs) is a rapidly emerging
avenue for decarbonization of energy and transportation sectors. Compared to
light duty vehicles, HDEVs exhibit unique travel and charging patterns over
long distances. In this paper, we formulate an analytically tractable model
that considers the routing decisions for the HDEVs and their charging
implications on the power grid. Our model captures the impacts of increased
vehicle electrification on the transmission grid, with particular focus on
HDEVs. We jointly model transportation and power networks coupling them through
the demand generated for charging requirements of HDEVs. In particular, the
voltage constraint violation is explicitly accounted for in the proposed model
given the signifcant amount of charging power imposed by HDEVs. We obtain
optimal routing schedules and generator dispatch satisfying mobility
constraints of HDEVs while minimizing voltage violations in electric
transmission network. Case study based on an IEEE 24-bus system is presented
using realistic data of transit data of HDEVs. The numerical results suggest
that the proposed model and algorithm effectively mitigate the voltage
violation when a significant amount of HDEVs are integrated to the power
transmission network. Such mitigation includes reduction in the voltage
magnitude, geographical dispersion of voltage violations and worst-case voltage
violations at critical nodes.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14864" title="Abstract">arXiv:2311.14864</a> [<a href="/pdf/2311.14864" title="Download PDF">pdf</a>, <a href="/format/2311.14864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effective Structural Encodings via Local Curvature Profiles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fesser%2C+L">Lukas Fesser</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+M">Melanie Weber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Structural and Positional Encodings can significantly improve the performance
of Graph Neural Networks in downstream tasks. Recent literature has begun to
systematically investigate differences in the structural properties that these
approaches encode, as well as performance trade-offs between them. However, the
question of which structural properties yield the most effective encoding
remains open. In this paper, we investigate this question from a geometric
perspective. We propose a novel structural encoding based on discrete Ricci
curvature (Local Curvature Profiles, short LCP) and show that it significantly
outperforms existing encoding approaches. We further show that combining local
structural encodings, such as LCP, with global positional encodings improves
downstream performance, suggesting that they capture complementary geometric
information. Finally, we compare different encoding types with
(curvature-based) rewiring techniques. Rewiring has recently received a surge
of interest due to its ability to improve the performance of Graph Neural
Networks by mitigating over-smoothing and over-squashing effects. Our results
suggest that utilizing curvature information for structural encodings delivers
significantly larger performance increases than rewiring.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14865" title="Abstract">arXiv:2311.14865</a> [<a href="/pdf/2311.14865" title="Download PDF">pdf</a>, <a href="/format/2311.14865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Cross-Domain Hate Speech Generalizability with Emotion  Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+S+Y">Shi Yin Hong</a>, 
<a href="/search/cs?searchtype=author&query=Gauch%2C+S">Susan Gauch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Pacific Asia Conference on Language, Information and Computation (PACLIC 37)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Reliable automatic hate speech (HS) detection systems must adapt to the
in-flow of diverse new data to curtail hate speech. However, hate speech
detection systems commonly lack generalizability in identifying hate speech
dissimilar to data used in training, impeding their robustness in real-world
deployments. In this work, we propose a hate speech generalization framework
that leverages emotion knowledge in a multitask architecture to improve the
generalizability of hate speech detection in a cross-domain setting. We
investigate emotion corpora with varying emotion categorical scopes to
determine the best corpus scope for supplying emotion knowledge to foster
generalized hate speech detection. We further assess the relationship between
using pretrained Transformers models adapted for hate speech and its effect on
our emotion-enriched hate speech generalization model. We perform extensive
experiments on six publicly available datasets sourced from different online
domains and show that our emotion-enriched HS detection generalization method
demonstrates consistent generalization improvement in cross-domain evaluation,
increasing generalization performance up to 18.1% and average cross-domain
performance up to 8.5%, according to the F1 measure.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14869" title="Abstract">arXiv:2311.14869</a> [<a href="/pdf/2311.14869" title="Download PDF">pdf</a>, <a href="/ps/2311.14869" title="Download PostScript">ps</a>, <a href="/format/2311.14869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Complexity of Computing Sparse Equilibria and Lower Bounds for  No-Regret Learning in Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anagnostides%2C+I">Ioannis Anagnostides</a>, 
<a href="/search/cs?searchtype=author&query=Kalavasis%2C+A">Alkis Kalavasis</a>, 
<a href="/search/cs?searchtype=author&query=Sandholm%2C+T">Tuomas Sandholm</a>, 
<a href="/search/cs?searchtype=author&query=Zampetakis%2C+M">Manolis Zampetakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at ITCS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Characterizing the performance of no-regret dynamics in multi-player games is
a foundational problem at the interface of online learning and game theory.
Recent results have revealed that when all players adopt specific learning
algorithms, it is possible to improve exponentially over what is predicted by
the overly pessimistic no-regret framework in the traditional adversarial
regime, thereby leading to faster convergence to the set of coarse correlated
equilibria (CCE). Yet, despite considerable recent progress, the fundamental
complexity barriers for learning in normal- and extensive-form games are poorly
understood. In this paper, we make a step towards closing this gap by first
showing that -- barring major complexity breakthroughs -- any polynomial-time
learning algorithms in extensive-form games need at least $2^{\log^{1/2 - o(1)}
|\mathcal{T}|}$ iterations for the average regret to reach below even an
absolute constant, where $|\mathcal{T}|$ is the number of nodes in the game.
This establishes a superpolynomial separation between no-regret learning in
normal- and extensive-form games, as in the former class a logarithmic number
of iterations suffices to achieve constant average regret. Furthermore, our
results imply that algorithms such as multiplicative weights update, as well as
its \emph{optimistic} counterpart, require at least $2^{(\log \log m)^{1/2 -
o(1)}}$ iterations to attain an $O(1)$-CCE in $m$-action normal-form games.
These are the first non-trivial -- and dimension-dependent -- lower bounds in
that setting for the most well-studied algorithms in the literature. From a
technical standpoint, we follow a beautiful connection recently made by Foster,
Golowich, and Kakade (ICML '23) between sparse CCE and Nash equilibria in the
context of Markov games. Consequently, our lower bounds rule out
polynomial-time algorithms well beyond the traditional online learning
framework.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14871" title="Abstract">arXiv:2311.14871</a> [<a href="/pdf/2311.14871" title="Download PDF">pdf</a>, <a href="/format/2311.14871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tracing Influence at Scale: A Contrastive Learning Approach to Linking  Public Comments and Regulator Responses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+L">Linzi Xing</a>, 
<a href="/search/cs?searchtype=author&query=Hackinen%2C+B">Brad Hackinen</a>, 
<a href="/search/cs?searchtype=author&query=Carenini%2C+G">Giuseppe Carenini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the Natural Legal Language Processing Workshop 2023 (NLLP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">U.S. Federal Regulators receive over one million comment letters each year
from businesses, interest groups, and members of the public, all advocating for
changes to proposed regulations. These comments are believed to have
wide-ranging impacts on public policy. However, measuring the impact of
specific comments is challenging because regulators are required to respond to
comments but they do not have to specify which comments they are addressing. In
this paper, we propose a simple yet effective solution to this problem by using
an iterative contrastive method to train a neural model aiming for matching
text from public comments to responses written by regulators. We demonstrate
that our proposal substantially outperforms a set of selected text-matching
baselines on a human-annotated test set. Furthermore, it delivers performance
comparable to the most advanced gigantic language model (i.e., GPT-4), and is
more cost-effective when handling comments and regulator responses matching in
larger scale.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14873" title="Abstract">arXiv:2311.14873</a> [<a href="/pdf/2311.14873" title="Download PDF">pdf</a>, <a href="/format/2311.14873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RTSMS: Randomized Tucker with single-mode sketching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hashemi%2C+B">Behnam Hashemi</a>, 
<a href="/search/math?searchtype=author&query=Nakatsukasa%2C+Y">Yuji Nakatsukasa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose RTSMS (Randomized Tucker via Single-Mode-Sketching), a randomized
algorithm for approximately computing a low-rank Tucker decomposition of a
given tensor. It uses sketching and least-squares to compute the Tucker
decomposition in a sequentially truncated manner. The algorithm only sketches
one mode at a time, so the sketch matrices are significantly smaller than
alternative approaches. The algorithm is demonstrated to be competitive with
existing methods, sometimes outperforming them by a large margin.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14874" title="Abstract">arXiv:2311.14874</a> [<a href="/pdf/2311.14874" title="Download PDF">pdf</a>, <a href="/format/2311.14874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Fluid-Based Thermal Management Systems Design: Leveraging  Graph Neural Networks for Graph Regression and Efficient Enumeration  Reduction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bayat%2C+S">Saeid Bayat</a>, 
<a href="/search/eess?searchtype=author&query=Shahmansouri%2C+N">Nastaran Shahmansouri</a>, 
<a href="/search/eess?searchtype=author&query=Peddada%2C+S+R">Satya RT Peddada</a>, 
<a href="/search/eess?searchtype=author&query=Tessier%2C+A">Alex Tessier</a>, 
<a href="/search/eess?searchtype=author&query=Butscher%2C+A">Adrian Butscher</a>, 
<a href="/search/eess?searchtype=author&query=Allison%2C+J+T">James T Allison</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this research, we developed a graph-based framework to represent various
aspects of optimal thermal management system design, with the aim of rapidly
and efficiently identifying optimal design candidates. Initially, the
graph-based framework is utilized to generate diverse thermal management system
architectures. The dynamics of these system architectures are modeled under
various loading conditions, and an open-loop optimal controller is employed to
determine each system's optimal performance. These modeled cases constitute the
dataset, with the corresponding optimal performance values serving as the
labels for the data. In the subsequent step, a Graph Neural Network (GNN) model
is trained on 30% of the labeled data to predict the systems' performance,
effectively addressing a regression problem. Utilizing this trained model, we
estimate the performance values for the remaining 70% of the data, which serves
as the test set. In the third step, the predicted performance values are
employed to rank the test data, facilitating prioritized evaluation of the
design scenarios. Specifically, a small subset of the test data with the
highest estimated ranks undergoes evaluation via the open-loop optimal control
solver. This targeted approach concentrates on evaluating higher-ranked designs
identified by the GNN, replacing the exhaustive search (enumeration-based) of
all design cases. The results demonstrate a significant average reduction of
over 92% in the number of system dynamic modeling and optimal control analyses
required to identify optimal design scenarios.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14876" title="Abstract">arXiv:2311.14876</a> [<a href="/pdf/2311.14876" title="Download PDF">pdf</a>, <a href="/format/2311.14876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Large Language Models (LLMs) through Deception Techniques and  Persuasion Principles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Sonali Singh</a>, 
<a href="/search/cs?searchtype=author&query=Abri%2C+F">Faranak Abri</a>, 
<a href="/search/cs?searchtype=author&query=Namin%2C+A+S">Akbar Siami Namin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 16 tables, 5 figures, IEEE BigData 2023 (Workshops)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">With the recent advent of Large Language Models (LLMs), such as ChatGPT from
OpenAI, BARD from Google, Llama2 from Meta, and Claude from Anthropic AI, gain
widespread use, ensuring their security and robustness is critical. The
widespread use of these language models heavily relies on their reliability and
proper usage of this fascinating technology. It is crucial to thoroughly test
these models to not only ensure its quality but also possible misuses of such
models by potential adversaries for illegal activities such as hacking. This
paper presents a novel study focusing on exploitation of such large language
models against deceptive interactions. More specifically, the paper leverages
widespread and borrows well-known techniques in deception theory to investigate
whether these models are susceptible to deceitful interactions.
<br />This research aims not only to highlight these risks but also to pave the way
for robust countermeasures that enhance the security and integrity of language
models in the face of sophisticated social engineering tactics. Through
systematic experiments and analysis, we assess their performance in these
critical security domains. Our results demonstrate a significant finding in
that these large language models are susceptible to deception and social
engineering attacks.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14878" title="Abstract">arXiv:2311.14878</a> [<a href="/pdf/2311.14878" title="Download PDF">pdf</a>, <a href="/format/2311.14878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Strong a Kick Should be to Topple Northeastern&#x27;s Tumbling Robot?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salagame%2C+A">Adarsh Salagame</a>, 
<a href="/search/cs?searchtype=author&query=Bhattachan%2C+N">Neha Bhattachan</a>, 
<a href="/search/cs?searchtype=author&query=Caetano%2C+A">Andre Caetano</a>, 
<a href="/search/cs?searchtype=author&query=McCarthy%2C+I">Ian McCarthy</a>, 
<a href="/search/cs?searchtype=author&query=Noyes%2C+H">Henry Noyes</a>, 
<a href="/search/cs?searchtype=author&query=Petersen%2C+B">Brandon Petersen</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+A">Alexander Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Schroeter%2C+M">Matthew Schroeter</a>, 
<a href="/search/cs?searchtype=author&query=Smithwick%2C+N">Nolan Smithwick</a>, 
<a href="/search/cs?searchtype=author&query=Sroka%2C+K">Konrad Sroka</a>, 
<a href="/search/cs?searchtype=author&query=Widjaja%2C+J">Jason Widjaja</a>, 
<a href="/search/cs?searchtype=author&query=Bohra%2C+Y">Yash Bohra</a>, 
<a href="/search/cs?searchtype=author&query=Venkatesh%2C+K">Kaushik Venkatesh</a>, 
<a href="/search/cs?searchtype=author&query=Gangaraju%2C+K">Kruthika Gangaraju</a>, 
<a href="/search/cs?searchtype=author&query=Ghanem%2C+P">Paul Ghanem</a>, 
<a href="/search/cs?searchtype=author&query=Mandralis%2C+I">Ioannis Mandralis</a>, 
<a href="/search/cs?searchtype=author&query=Sihite%2C+E">Eric Sihite</a>, 
<a href="/search/cs?searchtype=author&query=Kalantari%2C+A">Arash Kalantari</a>, 
<a href="/search/cs?searchtype=author&query=Ramezani%2C+A">Alireza Ramezani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Rough terrain locomotion has remained one of the most challenging mobility
questions. In 2022, NASA's Innovative Advanced Concepts (NIAC) Program invited
US academic institutions to participate NASA's Breakthrough, Innovative \&amp;
Game-changing (BIG) Idea competition by proposing novel mobility systems that
can negotiate extremely rough terrain, lunar bumpy craters. In this
competition, Northeastern University won NASA's top Artemis Award award by
proposing an articulated robot tumbler called COBRA (Crater Observing
Bio-inspired Rolling Articulator). This report briefly explains the underlying
principles that made COBRA successful in competing with other concepts ranging
from cable-driven to multi-legged designs from six other participating US
institutions.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14883" title="Abstract">arXiv:2311.14883</a> [<a href="/pdf/2311.14883" title="Download PDF">pdf</a>, <a href="/ps/2311.14883" title="Download PostScript">ps</a>, <a href="/format/2311.14883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Potential School Shooters from Social Media Posts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cedeno%2C+A">Alana Cedeno</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+R">Rachel Liang</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+S+R">Sheikh Rabiul Islam</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Big Data 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">The rate of terror attacks has surged over the past decade, resulting in the
tragic and senseless loss or alteration of numerous lives. Offenders behind
mass shootings, bombings, or other domestic terrorism incidents have
historically exhibited warning signs on social media before carrying out actual
incidents. However, due to inadequate and comprehensive police procedures,
authorities and social media platforms are often unable to detect these early
indicators of intent. To tackle this issue, we aim to create a multimodal model
capable of predicting sentiments simultaneously from both images (i.e., social
media photos) and text (i.e., social media posts), generating a unified
prediction. The proposed method involves segregating the image and text
components of an online post and utilizing a captioning model to generate
sentences summarizing the image's contents. Subsequently, a sentiment analyzer
evaluates this caption, or description, along with the original post's text to
determine whether the post is positive (i.e., concerning) or negative (i.e.,
benign). This undertaking represents a significant step toward implementing the
developed system in real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14885" title="Abstract">arXiv:2311.14885</a> [<a href="/pdf/2311.14885" title="Download PDF">pdf</a>, <a href="/format/2311.14885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Projected Off-Policy Q-Learning (POP-QL) for Stabilizing Offline  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roderick%2C+M">Melrose Roderick</a>, 
<a href="/search/cs?searchtype=author&query=Manek%2C+G">Gaurav Manek</a>, 
<a href="/search/cs?searchtype=author&query=Berkenkamp%2C+F">Felix Berkenkamp</a>, 
<a href="/search/cs?searchtype=author&query=Kolter%2C+J+Z">J. Zico Kolter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">A key problem in off-policy Reinforcement Learning (RL) is the mismatch, or
distribution shift, between the dataset and the distribution over states and
actions visited by the learned policy. This problem is exacerbated in the fully
offline setting. The main approach to correct this shift has been through
importance sampling, which leads to high-variance gradients. Other approaches,
such as conservatism or behavior-regularization, regularize the policy at the
cost of performance. In this paper, we propose a new approach for stable
off-policy Q-Learning. Our method, Projected Off-Policy Q-Learning (POP-QL), is
a novel actor-critic algorithm that simultaneously reweights off-policy samples
and constrains the policy to prevent divergence and reduce value-approximation
error. In our experiments, POP-QL not only shows competitive performance on
standard benchmarks, but also out-performs competing methods in tasks where the
data-collection policy is significantly sub-optimal.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14886" title="Abstract">arXiv:2311.14886</a> [<a href="/pdf/2311.14886" title="Download PDF">pdf</a>, <a href="/ps/2311.14886" title="Download PostScript">ps</a>, <a href="/format/2311.14886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A unified framework for learning with nonlinear model classes from  arbitrary linear samples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adcock%2C+B">Ben Adcock</a>, 
<a href="/search/cs?searchtype=author&query=Cardenas%2C+J+M">Juan M. Cardenas</a>, 
<a href="/search/cs?searchtype=author&query=Dexter%2C+N">Nick Dexter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">This work considers the fundamental problem of learning an unknown object
from training data using a given model class. We introduce a unified framework
that allows for objects in arbitrary Hilbert spaces, general types of (random)
linear measurements as training data and general types of nonlinear model
classes. We establish a series of learning guarantees for this framework. These
guarantees provide explicit relations between the amount of training data and
properties of the model class to ensure near-best generalization bounds. In
doing so, we also introduce and develop the key notion of the variation of a
model class with respect to a distribution of sampling operators. To exhibit
the versatility of this framework, we show that it can accommodate many
different types of well-known problems of interest. We present examples such as
matrix sketching by random sampling, compressed sensing with isotropic vectors,
active learning in regression and compressed sensing with generative models. In
all cases, we show how known results become straightforward corollaries of our
general learning guarantees. For compressed sensing with generative models, we
also present a number of generalizations and improvements of recent results. In
summary, our work not only introduces a unified way to study learning unknown
objects from general types of data, but also establishes a series of general
theoretical guarantees which consolidate and improve various known results.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14887" title="Abstract">arXiv:2311.14887</a> [<a href="/pdf/2311.14887" title="Download PDF">pdf</a>, <a href="/ps/2311.14887" title="Download PostScript">ps</a>, <a href="/format/2311.14887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring Human-Robot Trust with the MDMT (Multi-Dimensional Measure of  Trust)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malle%2C+B+F">Bertram F. Malle</a>, 
<a href="/search/cs?searchtype=author&query=Ullman%2C+D">Daniel Ullman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In SCRITA 2023 Workshop Proceedings (<a href="/abs/2311.05401">arXiv:2311.05401</a>) held in conjunction with 32nd IEEE International Conference on Robot &amp; Human Interactive Communication, 08/28-31 2023, Busan (Korea)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">We describe the steps of developing the MDMT (Multi-Dimensional Measure of
Trust), an intuitive self-report measure of perceived trustworthiness of
various agents (human, robot, animal). We summarize the evidence that led to
the original four-dimensional form (v1) and to the most recent five-dimensional
form (v2). We examine the measure's strengths and limitations and point to
further necessary validations.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14891" title="Abstract">arXiv:2311.14891</a> [<a href="/pdf/2311.14891" title="Download PDF">pdf</a>, <a href="/format/2311.14891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simpson&#x27;s Paradox and Lagging Progress in Completion Trends of  Underrepresented Students in Computer Science
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taylor%2C+J+M">John Mason Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Drucker%2C+R">Rebecca Drucker</a>, 
<a href="/search/cs?searchtype=author&query=Alvin%2C+C">Chris Alvin</a>, 
<a href="/search/cs?searchtype=author&query=Sultan%2C+S+F">Syed Fahad Sultan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">It is imperative for the Computer Science (CS) community to ensure active
participation and success of students from diverse backgrounds. This work
compares CS to other areas of study with respect to success of students from
three underrepresented groups: Women, Black and Hispanic or Latino. Using a
data-driven approach, we show that trends of success over the years for
underrepresented groups in CS are lagging behind other disciplines. Completion
of CS programs by Black students in particular shows an alarming regression in
the years 2011 through 2019. This national level decline is most concentrated
in the Southeast of the United States and seems to be driven mostly by a small
number of institutes that produce a large number of graduates. We strongly
believe that more data-driven studies in this area are necessary to make
progress towards a more equitable and inclusive CS community. Without an
understanding of underlying dynamics, policy makers and practitioners will be
unable to make informed decisions about how and where to allocate resources to
address the problem.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14895" title="Abstract">arXiv:2311.14895</a> [<a href="/pdf/2311.14895" title="Download PDF">pdf</a>, <a href="/format/2311.14895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Nonlinear State Observation using Video Measurements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Weeks%2C+C">Cormak Weeks</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+W">Wentao Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures, submitted to the 12th IFAC Symposium on Advanced Control of Chemical Processes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">State observation is necessary for feedback control but often challenging for
nonlinear systems. While Kazantzis-Kravaris/Luenberger (KKL) observer gives a
generic design, its model-based numerical solution is difficult. In this paper,
we propose a simple method to determine a data-driven KKL observer, namely to
(i) transform the measured output signals by a linear time-invariant dynamics,
and (ii) reduce the dimensionality to principal components. This approach is
especially suitable for systems with rich measurements and low-dimensional
state space, for example, when videos can be obtained in real time. We present
an application to a video of the well-known Belousov-Zhabotinsky (B-Z) reaction
system with severe nonlinearity, where the data-driven KKL observer recovers an
oscillatory state orbit with slow damping.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14897" title="Abstract">arXiv:2311.14897</a> [<a href="/pdf/2311.14897" title="Download PDF">pdf</a>, <a href="/format/2311.14897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Scalable 3D Anomaly Detection and Localization: A Benchmark via  3D Anomaly Synthesis and A Self-Supervised Learning Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenqiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaohao Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, 3D anomaly detection, a crucial problem involving fine-grained
geometry discrimination, is getting more attention. However, the lack of
abundant real 3D anomaly data limits the scalability of current models. To
enable scalable anomaly data collection, we propose a 3D anomaly synthesis
pipeline to adapt existing large-scale 3Dmodels for 3D anomaly detection.
Specifically, we construct a synthetic dataset, i.e., Anomaly-ShapeNet, basedon
ShapeNet. Anomaly-ShapeNet consists of 1600 point cloud samples under 40
categories, which provides a rich and varied collection of data, enabling
efficient training and enhancing adaptability to industrial scenarios.
Meanwhile,to enable scalable representation learning for 3D anomaly
localization, we propose a self-supervised method, i.e., Iterative Mask
Reconstruction Network (IMRNet). During training, we propose a geometry-aware
sample module to preserve potentially anomalous local regions during point
cloud down-sampling. Then, we randomly mask out point patches and sent the
visible patches to a transformer for reconstruction-based self-supervision.
During testing, the point cloud repeatedly goes through the Mask Reconstruction
Network, with each iteration's output becoming the next input. By merging and
contrasting the final reconstructed point cloud with the initial input, our
method successfully locates anomalies. Experiments show that IMRNet outperforms
previous state-of-the-art methods, achieving 66.1% in I-AUC on Anomaly-ShapeNet
dataset and 72.5% in I-AUC on Real3D-AD dataset. Our dataset will be released
at https://github.com/Chopper-233/Anomaly-ShapeNet
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14898" title="Abstract">arXiv:2311.14898</a> [<a href="/pdf/2311.14898" title="Download PDF">pdf</a>, <a href="/format/2311.14898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HongTu: Scalable Full-Graph GNN Training on Multiple GPUs (via  communication-optimized CPU data offloading)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiange Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+W">Weng-Fai Wong</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bingsheng He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages 11 figures, SIGMOD2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Full-graph training on graph neural networks (GNN) has emerged as a promising
training method for its effectiveness. Full-graph training requires extensive
memory and computation resources. To accelerate this training process,
researchers have proposed employing multi-GPU processing. However the
scalability of existing frameworks is limited as they necessitate maintaining
the training data for every layer in GPU memory. To efficiently train on large
graphs, we present HongTu, a scalable full-graph GNN training system running on
GPU-accelerated platforms. HongTu stores vertex data in CPU memory and offloads
training to GPUs. HongTu employs a memory-efficient full-graph training
framework that reduces runtime memory consumption by using partition-based
training and recomputation-caching-hybrid intermediate data management. To
address the issue of increased host-GPU communication caused by duplicated
neighbor access among partitions, HongTu employs a deduplicated communication
framework that converts the redundant host-GPU communication to efficient
inter/intra-GPU data access. Further, HongTu uses a cost model-guided graph
reorganization method to minimize communication overhead. Experimental results
on a 4XA100 GPU server show that HongTu effectively supports billion-scale
full-graph GNN training while reducing host-GPU data communication by 25%-71%.
Compared to the full-graph GNN system DistGNN running on 16 CPU nodes, HongTu
achieves speedups ranging from 7.8X to 20.2X. For small graphs where the
training data fits into the GPUs, HongTu achieves performance comparable to
existing GPU-based GNN systems.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14899" title="Abstract">arXiv:2311.14899</a> [<a href="/pdf/2311.14899" title="Download PDF">pdf</a>, <a href="/format/2311.14899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperDID: Hyperspectral Intrinsic Image Decomposition with Deep Feature  Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+Z">Zhiqiang Gong</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Wen Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiaohu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+P">Ping Zhong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE TGRS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The dissection of hyperspectral images into intrinsic components through
hyperspectral intrinsic image decomposition (HIID) enhances the
interpretability of hyperspectral data, providing a foundation for more
accurate classification outcomes. However, the classification performance of
HIID is constrained by the model's representational ability. To address this
limitation, this study rethinks hyperspectral intrinsic image decomposition for
classification tasks by introducing deep feature embedding. The proposed
framework, HyperDID, incorporates the Environmental Feature Module (EFM) and
Categorical Feature Module (CFM) to extract intrinsic features. Additionally, a
Feature Discrimination Module (FDM) is introduced to separate
environment-related and category-related features. Experimental results across
three commonly used datasets validate the effectiveness of HyperDID in
improving hyperspectral image classification performance. This novel approach
holds promise for advancing the capabilities of hyperspectral image analysis by
leveraging deep feature embedding principles. The implementation of the
proposed method could be accessed soon at https://github.com/shendu-sw/HyperDID
for the sake of reproducibility.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14900" title="Abstract">arXiv:2311.14900</a> [<a href="/pdf/2311.14900" title="Download PDF">pdf</a>, <a href="/format/2311.14900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resfusion: Prior Residual Noise embedded Denoising Diffusion  Probabilistic Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhenning%2C+S">Shi Zhenning</a>, 
<a href="/search/cs?searchtype=author&query=Changsheng%2C+D">Dong Changsheng</a>, 
<a href="/search/cs?searchtype=author&query=Bin%2C+P">Pan Bin</a>, 
<a href="/search/cs?searchtype=author&query=Xueshuo%2C+X">Xie Xueshuo</a>, 
<a href="/search/cs?searchtype=author&query=Along%2C+H">He Along</a>, 
<a href="/search/cs?searchtype=author&query=Qiaoying%2C+Q">Qu Qiaoying</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+L">Li Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, Denoising Diffusion Probabilistic Models have been widely used in
image segmentation, by generating segmentation masks conditioned on the input
image. However, previous works can not seamlessly integrate existing end-to-end
models with denoising diffusion models. Existing research can only select
acceleration steps based on experience rather than calculating them
specifically. Moreover, most methods are limited to small models and
small-scale datasets, unable to generalize to general datasets and a wider
range of tasks. Therefore, we propose Resfusion with a novel resnoise-diffusion
process, which gradually generates segmentation masks or any type of target
image, seamlessly integrating state-of-the-art end-to-end models and denoising
diffusion models. Resfusion bridges the discrepancy between the likelihood
output and the ground truth output through a Markov process. Through the novel
smooth equivalence transformation in resnoise-diffusion process, we determine
the optimal acceleration step. Experimental results demonstrate that Resfusion
combines the capabilities of existing end-to-end models and denoising diffusion
models, further enhancing performance and achieving outstanding results.
Moreover, Resfusion is not limited to segmentation tasks, it can easily
generalize to any general tasks of image generation and exhibit strong
competitiveness.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14901" title="Abstract">arXiv:2311.14901</a> [<a href="/pdf/2311.14901" title="Download PDF">pdf</a>, <a href="/format/2311.14901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Code Search Debiasing:Improve Search Results beyond Overall Ranking  Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hui Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanlin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Xiu%2C+Y">Yong Xiu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Juhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+R">Rongong Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Findings of EMNLP 2023. 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Code search engine is an essential tool in software development. Many code
search methods have sprung up, focusing on the overall ranking performance of
code search. In this paper, we study code search from another perspective by
analyzing the bias of code search models. Biased code search engines provide
poor user experience, even though they show promising overall performance. Due
to different development conventions (e.g., prefer long queries or
abbreviations), some programmers will find the engine useful, while others may
find it hard to get desirable search results. To mitigate biases, we develop a
general debiasing framework that employs reranking to calibrate search results.
It can be easily plugged into existing engines and handle new code search
biases discovered in the future. Experiments show that our framework can
effectively reduce biases. Meanwhile, the overall ranking performance of code
search gets improved after debiasing.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14902" title="Abstract">arXiv:2311.14902</a> [<a href="/pdf/2311.14902" title="Download PDF">pdf</a>, <a href="/format/2311.14902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parkinson Disease classification Using Contrastive Graph Cross-View  Learning with Multimodal Fusion of SPECT Images and Clinical Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jun-En Ding</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+C">Chien-Chin Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Feng Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Parkinson's Disease (PD) is a neurodegenerative neurological disorder that
impacts movement and afflicts over 10 million people worldwide. Previous
researches have come up with deep learning models for predicting Parkinson's
disease primarily using medical images and didn't leverage the manifold
structure in the dataset. Our study introduces a multimodal approach with both
image and non-image features with a contrastive cross-view graph fusion for
Parkinson's disease classification. Specifically, we designed a multimodal
co-attention module to integrate embeddings from two distinct graph views
derived from low dimensional representation of images and clinical features,
enabling the extraction of more stable and structured features from the
multiview data. Additionally, we have devised a simplified fusion method
utilizing a contrastive loss for positive and negative pairs, to enhance the
model's overall cross-view fusion learning capabilities. In our experiments,
the graph-view multimodal approach can achieve an accuracy rate of 91% and an
AUC of 92.8% in five-fold cross-validation, and it also demonstrates superior
predictive capabilities on non-image data as compared to methods that rely
solely on machine learning methods.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14903" title="Abstract">arXiv:2311.14903</a> [<a href="/pdf/2311.14903" title="Download PDF">pdf</a>, <a href="/format/2311.14903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Code Generation Based Grading: Evaluating an Auto-grading Mechanism for  &quot;Explain-in-Plain-English&quot; Questions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Smith%2C+D+H">David H. Smith IV</a>, 
<a href="/search/cs?searchtype=author&query=Zilles%2C+C">Craig Zilles</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Comprehending and elucidating the purpose of code is often cited as being a
key learning objective within introductory programming courses. To address this
objective ``Explain-in-Plain-English'' questions, in which students are shown a
segment of code and asked to provide an abstract description of the code's
purpose, have been adopted. However, given EiPE questions require a natural
language response, they often require manual grading which is time-consuming
for course staff and delays feedback for students. With the advent of large
language models (LLMs) capable of generating code, responses to EiPE questions
can be used to generate code segments, the correctness of which can then be
easily verified using test cases. We refer to this approach as "Code Generation
Based Grading" (CGBG) and in this paper we explore its agreement with human
graders using EiPE responses from past exams in an introductory programming
course taught in Python. Overall, we find that CGBG achieves moderate agreement
with human graders with the primary area of disagreement being its leniency
with respect to low-level and line-by-line descriptions of code.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14904" title="Abstract">arXiv:2311.14904</a> [<a href="/pdf/2311.14904" title="Download PDF">pdf</a>, <a href="/format/2311.14904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-Assisted Code Cleaning For Training Accurate Code Generators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+N">Naman Jain</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chiang%2C+W">Wei-Lin Chiang</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+J+E">Joseph E. Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+K">Koushik Sen</a>, 
<a href="/search/cs?searchtype=author&query=Stoica%2C+I">Ion Stoica</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Natural language to code generation is an important application area of LLMs
and has received wide attention from the community. The majority of relevant
studies have exclusively concentrated on increasing the quantity and functional
correctness of training sets while disregarding other stylistic elements of
programs. More recently, data quality has garnered a lot of interest and
multiple works have showcased its importance for improving performance. In this
work, we investigate data quality for code and find that making the code more
structured and readable leads to improved code generation performance of the
system. We build a novel data-cleaning pipeline that uses these principles to
transform existing programs by 1.) renaming variables, 2.) modularizing and
decomposing complex code into smaller helper sub-functions, and 3.) inserting
natural-language based plans via LLM based transformations. We evaluate our
approach on two challenging algorithmic code generation benchmarks and find
that fine-tuning CodeLLaMa-7B on our transformed modularized programs improves
the performance by up to 30% compared to fine-tuning on the original dataset.
Additionally, we demonstrate improved performance from using a smaller amount
of higher-quality data, finding that a model fine-tuned on the entire original
dataset is outperformed by a model trained on 15% of our cleaned dataset. Even
in comparison to closed-source models, our models outperform the much larger
AlphaCoder models.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14905" title="Abstract">arXiv:2311.14905</a> [<a href="/pdf/2311.14905" title="Download PDF">pdf</a>, <a href="/format/2311.14905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Class Gradient Projection For Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Ji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jingkuan Song</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Lianli Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MM '22: Proceedings of the 30th ACM International Conference on Multimedia
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Catastrophic forgetting is one of the most critical challenges in Continual
Learning (CL). Recent approaches tackle this problem by projecting the gradient
update orthogonal to the gradient subspace of existing tasks. While the results
are remarkable, those approaches ignore the fact that these calculated
gradients are not guaranteed to be orthogonal to the gradient subspace of each
class due to the class deviation in tasks, e.g., distinguishing "Man" from
"Sea" v.s. differentiating "Boy" from "Girl". Therefore, this strategy may
still cause catastrophic forgetting for some classes. In this paper, we propose
Class Gradient Projection (CGP), which calculates the gradient subspace from
individual classes rather than tasks. Gradient update orthogonal to the
gradient subspace of existing classes can be effectively utilized to minimize
interference from other classes. To improve the generalization and efficiency,
we further design a Base Refining (BR) algorithm to combine similar classes and
refine class bases dynamically. Moreover, we leverage a contrastive learning
method to improve the model's ability to handle unseen tasks. Extensive
experiments on benchmark datasets demonstrate the effectiveness of our proposed
approach. It improves the previous methods by 2.0% on the CIFAR-100 dataset.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14906" title="Abstract">arXiv:2311.14906</a> [<a href="/pdf/2311.14906" title="Download PDF">pdf</a>, <a href="/format/2311.14906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoEval-Video: An Automatic Benchmark for Assessing Large Vision  Language Models in Open-Ended Video Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiuyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuchen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Weiran Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose a novel and challenging benchmark, AutoEval-Video, to
comprehensively evaluate large vision-language models in open-ended video
question answering. The comprehensiveness of AutoEval-Video is demonstrated in
two aspects: 1) AutoEval-Video constructs open-ended video-questions across 9
skill dimensions, addressing capabilities of perception, comprehension, and
generation. 2) AutoEval-Video contains newly collected videos that cover over
40 distinct themes. To efficiently evaluate responses to the open-ended
questions, we employ an LLM-based evaluation approach, but instead of merely
providing a reference answer, we annotate unique evaluation rules for every
single instance (video-question pair). To maximize the robustness of these
rules, we develop a novel adversarial annotation mechanism. By using
instance-specific rules as prompt, GPT-4, as an automatic evaluator, can
achieve a stable evaluation accuracy of around 97.0\%, comparable to the 94.9\%
- 97.5\% accuracy of a human evaluator. Furthermore, we assess the performance
of eight large vision-language models on AutoEval-Video. Among them,
GPT-4V(ision) significantly outperforms other models, achieving an accuracy of
32.2\%. However, there is still substantial room for improvement compared to
human accuracy of 72.8\%. By conducting an extensive case study, we uncover
several drawbacks of GPT-4V, such as limited temporal and dynamic
comprehension, and overly general responses. Code is available at
\href{https://github.com/Xiuyuan-Chen/AutoEval-Video}{\color{magenta}https://github.com/Xiuyuan-Chen/AutoEval-Video}.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14908" title="Abstract">arXiv:2311.14908</a> [<a href="/pdf/2311.14908" title="Download PDF">pdf</a>, <a href="/format/2311.14908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Support Vector Machine Implementation on MPI-CUDA and Tensorflow  Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elgarhy%2C+I">Islam Elgarhy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Support Vector Machine (SVM) algorithm requires a high computational cost
(both in memory and time) to solve a complex quadratic programming (QP)
optimization problem during the training process. Consequently, SVM
necessitates high computing hardware capabilities. The central processing unit
(CPU) clock frequency cannot be increased due to physical limitations in the
miniaturization process. However, the potential of parallel multi-architecture,
available in both multi-core CPUs and highly scalable GPUs, emerges as a
promising solution to enhance algorithm performance. Therefore, there is an
opportunity to reduce the high computational time required by SVM for solving
the QP optimization problem. This paper presents a comparative study that
implements the SVM algorithm on different parallel architecture frameworks. The
experimental results show that SVM MPI-CUDA implementation achieves a speedup
over SVM TensorFlow implementation on different datasets. Moreover, SVM
TensorFlow implementation provides a cross-platform solution that can be
migrated to alternative hardware components, which will reduces the development
time.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14909" title="Abstract">arXiv:2311.14909</a> [<a href="/pdf/2311.14909" title="Download PDF">pdf</a>, <a href="/format/2311.14909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Referring Expression Comprehension via Dual Modular  Memorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+H+T">Heng Tao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Lianli Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Meng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jingkuan Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Transactions on Image Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Referring Expression Comprehension (REC) aims to localize an image region of
a given object described by a natural-language expression. While promising
performance has been demonstrated, existing REC algorithms make a strong
assumption that training data feeding into a model are given upfront, which
degrades its practicality for real-world scenarios. In this paper, we propose
Continual Referring Expression Comprehension (CREC), a new setting for REC,
where a model is learning on a stream of incoming tasks. In order to
continuously improve the model on sequential tasks without forgetting prior
learned knowledge and without repeatedly re-training from a scratch, we propose
an effective baseline method named Dual Modular Memorization (DMM), which
alleviates the problem of catastrophic forgetting by two memorization modules:
Implicit-Memory and Explicit-Memory. Specifically, the former module aims to
constrain drastic changes to important parameters learned on old tasks when
learning a new task; while the latter module maintains a buffer pool to
dynamically select and store representative samples of each seen task for
future rehearsal. We create three benchmarks for the new CREC setting, by
respectively re-splitting three widely-used REC datasets RefCOCO, RefCOCO+ and
RefCOCOg into sequential tasks. Extensive experiments on the constructed
benchmarks demonstrate that our DMM method significantly outperforms other
alternatives, based on two popular REC backbones. We make the source code and
benchmarks publicly available to foster future progress in this field:
https://github.com/zackschen/DMM.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14911" title="Abstract">arXiv:2311.14911</a> [<a href="/pdf/2311.14911" title="Download PDF">pdf</a>, <a href="/format/2311.14911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CUCL: Codebook for Unsupervised Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+C">Chen Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jingkuan Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaosu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Junchen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Lianli Gao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Hengtao Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MM '23: Proceedings of the 31st ACM International Conference on Multimedia
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The focus of this study is on Unsupervised Continual Learning (UCL), as it
presents an alternative to Supervised Continual Learning which needs
high-quality manual labeled data. The experiments under the UCL paradigm
indicate a phenomenon where the results on the first few tasks are suboptimal.
This phenomenon can render the model inappropriate for practical applications.
To address this issue, after analyzing the phenomenon and identifying the lack
of diversity as a vital factor, we propose a method named Codebook for
Unsupervised Continual Learning (CUCL) which promotes the model to learn
discriminative features to complete the class boundary. Specifically, we first
introduce a Product Quantization to inject diversity into the representation
and apply a cross quantized contrastive loss between the original
representation and the quantized one to capture discriminative information.
Then, based on the quantizer, we propose an effective Codebook Rehearsal to
address catastrophic forgetting. This study involves conducting extensive
experiments on CIFAR100, TinyImageNet, and MiniImageNet benchmark datasets. Our
method significantly boosts the performances of supervised and unsupervised
methods. For instance, on TinyImageNet, our method led to a relative
improvement of 12.76% and 7% when compared with Simsiam and BYOL, respectively.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14916" title="Abstract">arXiv:2311.14916</a> [<a href="/pdf/2311.14916" title="Download PDF">pdf</a>, <a href="/format/2311.14916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient Game-Theoretic Planner for Automated Lane Merging with  Multi-Modal Behavior Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Luyao Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+S">Shaohang Han</a>, 
<a href="/search/eess?searchtype=author&query=Grammatico%2C+S">Sergio Grammatico</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">In this paper, we propose a novel behavior planner that combines game theory
with search-based planning for automated lane merging. Specifically, inspired
by human drivers, we model the interaction between vehicles as a gap selection
process. To overcome the challenge of multi-modal behavior exhibited by the
surrounding vehicles, we formulate the trajectory selection as a matrix game
and compute an equilibrium. Next, we validate our proposed planner in the
high-fidelity simulator CARLA and demonstrate its effectiveness in handling
interactions in dense traffic scenarios.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14917" title="Abstract">arXiv:2311.14917</a> [<a href="/pdf/2311.14917" title="Download PDF">pdf</a>, <a href="/format/2311.14917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consolidate Viability and Information Theories for Task-Oriented  Communications: A Homeostasis Solution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ercetin%2C+O">Ozgur Ercetin</a>, 
<a href="/search/cs?searchtype=author&query=Chraiti%2C+M">Mohaned Chraiti</a>, 
<a href="/search/cs?searchtype=author&query=Karakaya%2C+R+E">Rustu Erciyes Karakaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The next generation of cellular networks, 6G, is expected to offer a range of
exciting applications and services, including holographic communication,
machine-to-machine communication, and data sensing from millions of devices.
There is an incremental exhaustion of the spectral resources. It is crucial to
efficiently manage these resources through value-driven approaches that
eliminate waste and continually enhance the communication process. These
management principles align with the Task-Oriented Communications (TOC)
philosophy. The aim is to allocate the minimum necessary communication resource
according to the receiver's objective and continuously improve the
communication process. However, it is currently unclear how to build knowledge
of the receiver's goal and operate accordingly for efficient-resource
utilization. Our management approach combines viability theory and transfer
entropy to ensure that the actor remains within a viable space as per their
goal and to gradually reduce the information exchange through knowledge
accumulation. We discuss these theories in the context of TOC and examine their
application in the plant process control case. Finally, we provide insights
into future research directions from computational, performance, and protocol
perspectives.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14919" title="Abstract">arXiv:2311.14919</a> [<a href="/pdf/2311.14919" title="Download PDF">pdf</a>, <a href="/format/2311.14919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Minimum Bayes Risk Decoding with Confidence-based Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Julius Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Vlachos%2C+A">Andreas Vlachos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated from EMNLP 2023 version: typo fix, minor math notation change, updated citation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Minimum Bayes risk (MBR) decoding outputs the hypothesis with the highest
expected utility over the model distribution for some utility function. It has
been shown to improve accuracy over beam search in conditional language
generation problems and especially neural machine translation, in both human
and automatic evaluations. However, the standard sampling-based algorithm for
MBR is substantially more computationally expensive than beam search, requiring
a large number of samples as well as a quadratic number of calls to the utility
function, limiting its applicability. We describe an algorithm for MBR which
gradually grows the number of samples used to estimate the utility while
pruning hypotheses that are unlikely to have the highest utility according to
confidence estimates obtained with bootstrap sampling. Our method requires
fewer samples and drastically reduces the number of calls to the utility
function compared to standard MBR while being statistically indistinguishable
in terms of accuracy. We demonstrate the effectiveness of our approach in
experiments on three language pairs, using chrF++ and COMET as
utility/evaluation metrics.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14920" title="Abstract">arXiv:2311.14920</a> [<a href="/pdf/2311.14920" title="Download PDF">pdf</a>, <a href="/format/2311.14920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DECap: Towards Generalized Explicit Caption Editing via Diffusion  Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jun Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Long Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Explicit Caption Editing (ECE) -- refining reference image captions through a
sequence of explicit edit operations (e.g., KEEP, DETELE) -- has raised
significant attention due to its explainable and human-like nature. After
training with carefully designed reference and ground-truth caption pairs,
state-of-the-art ECE models exhibit limited generalization ability beyond the
original training data distribution, i.e., they are tailored to refine content
details only in in-domain samples but fail to correct errors in out-of-domain
samples. To this end, we propose a new Diffusion-based Explicit Caption editing
method: DECap. Specifically, we reformulate the ECE task as a denoising process
under the diffusion mechanism, and introduce innovative edit-based noising and
denoising processes. Thanks to this design, the noising process can help to
eliminate the need for meticulous paired data selection by directly introducing
word-level noises for training, learning diverse distribution over input
reference caption. The denoising process involves the explicit predictions of
edit operations and corresponding content words, refining reference captions
through iterative step-wise editing. To further efficiently implement our
diffusion process and improve the inference speed, DECap discards the prevalent
multi-stage design and directly generates edit operations and content words
simultaneously. Extensive ablations have demonstrated the strong generalization
ability of DECap in various scenarios. More interestingly, it even shows great
potential in improving the quality and controllability of caption generation.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14922" title="Abstract">arXiv:2311.14922</a> [<a href="/pdf/2311.14922" title="Download PDF">pdf</a>, <a href="/format/2311.14922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GBD-TS: Goal-based Pedestrian Trajectory Prediction with Diffusion using  Tree Sampling Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Ge Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yang Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Ming Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Predicting pedestrian trajectories is crucial for improving the safety and
effectiveness of autonomous driving and mobile robots. However, this task is
nontrivial due to the inherent stochasticity of human motion, which naturally
requires the predictor to generate multi-model prediction. Previous works have
used various generative methods, such as GAN and VAE, for pedestrian trajectory
prediction. Nevertheless, these methods may suffer from problems, including
mode collapse and relatively low-quality results. The denoising diffusion
probabilistic model (DDPM) has recently been applied to trajectory prediction
due to its simple training process and powerful reconstruction ability.
However, current diffusion-based methods are straightforward without fully
leveraging input information and usually require many denoising iterations
leading to a long inference time or an additional network for initialization.
To address these challenges and promote the application of diffusion models in
trajectory prediction, we propose a novel scene-aware multi-modal pedestrian
trajectory prediction framework called GBD. GBD combines goal prediction with
the diffusion network. First, the goal predictor produces multiple goals, and
then the diffusion network generates multi-modal trajectories conditioned on
these goals. Furthermore, we introduce a new diffusion sampling algorithm named
tree sampling (TS), which leverages common feature to reduce the inference time
and improve accuracy for multi-modal prediction. Experimental results
demonstrate that our GBD-TS method achieves state-of-the-art performance with
real-time inference speed.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14924" title="Abstract">arXiv:2311.14924</a> [<a href="/pdf/2311.14924" title="Download PDF">pdf</a>, <a href="/format/2311.14924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sequencing-enabled Hierarchical Cooperative CAV On-ramp Merging Control  with Enhanced Stability and Feasibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Sixu Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Yang Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Ye%2C+X">Xinyue Ye</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+J">Jiwan Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+M">Meng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper develops a sequencing-enabled hierarchical connected automated
vehicle (CAV) cooperative on-ramp merging control framework. The proposed
framework consists of a two-layer design: the upper level control sequences the
vehicles to harmonize the traffic density across mainline and on-ramp segments
while enhancing lower-level control efficiency through a mixed-integer linear
programming formulation. Subsequently, the lower-level control employs a
longitudinal distributed model predictive control (MPC) supplemented by a
virtual car-following (CF) concept to ensure asymptotic local stability, l_2
norm string stability, and safety. Proofs of asymptotic local stability and l_2
norm string stability are mathematically derived. Compared to other prevalent
asymptotic local-stable MPC controllers, the proposed distributed MPC
controller greatly expands the initial feasible set. Additionally, an auxiliary
lateral control is developed to maintain lane-keeping and merging smoothness
while accommodating ramp geometric curvature. To validate the proposed
framework, multiple numerical experiments are conducted. Results indicate a
notable outperformance of our upper-level controller against a distance-based
sequencing method. Furthermore, the lower-level control effectively ensures
smooth acceleration, safe merging with adequate spacing, adherence to proven
longitudinal local and string stability, and rapid regulation of lateral
deviations.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14925" title="Abstract">arXiv:2311.14925</a> [<a href="/pdf/2311.14925" title="Download PDF">pdf</a>, <a href="/format/2311.14925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coordinate-based Neural Network for Fourier Phase Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tingyou Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zixin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+Y+S">Yong S. Chu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaojing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jizhou Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Fourier phase retrieval is essential for high-definition imaging of nanoscale
structures across diverse fields, notably coherent diffraction imaging. This
study presents the Single impliCit neurAl Network (SCAN), a tool built upon
coordinate neural networks meticulously designed for enhanced phase retrieval
performance. Bypassing the pitfalls of conventional iterative methods, which
frequently face high computational loads and are prone to noise interference,
SCAN adeptly connects object coordinates to their amplitude and phase within a
unified network in an unsupervised manner. While many existing methods
primarily use Fourier magnitude in their loss function, our approach
incorporates both the predicted magnitude and phase, enhancing retrieval
accuracy. Comprehensive tests validate SCAN's superiority over traditional and
other deep learning models regarding accuracy and noise robustness. We also
demonstrate that SCAN excels in the ptychography setting.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14926" title="Abstract">arXiv:2311.14926</a> [<a href="/pdf/2311.14926" title="Download PDF">pdf</a>, <a href="/format/2311.14926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FreePIH: Training-Free Painterly Image Harmonization with Diffusion  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruibin Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jingcai Guo</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Song Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qihua Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper provides an efficient training-free painterly image harmonization
(PIH) method, dubbed FreePIH, that leverages only a pre-trained diffusion model
to achieve state-of-the-art harmonization results. Unlike existing methods that
require either training auxiliary networks or fine-tuning a large pre-trained
backbone, or both, to harmonize a foreground object with a painterly-style
background image, our FreePIH tames the denoising process as a plug-in module
for foreground image style transfer. Specifically, we find that the very last
few steps of the denoising (i.e., generation) process strongly correspond to
the stylistic information of images, and based on this, we propose to augment
the latent features of both the foreground and background images with Gaussians
for a direct denoising-based harmonization. To guarantee the fidelity of the
harmonized image, we make use of multi-scale features to enforce the
consistency of the content and stability of the foreground objects in the
latent space, and meanwhile, aligning both fore-/back-grounds with the same
style. Moreover, to accommodate the generation with more structural and
textural details, we further integrate text prompts to attend to the latent
features, hence improving the generation quality. Quantitative and qualitative
evaluations on COCO and LAION 5B datasets demonstrate that our method can
surpass representative baselines by large margins.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14927" title="Abstract">arXiv:2311.14927</a> [<a href="/pdf/2311.14927" title="Download PDF">pdf</a>, <a href="/ps/2311.14927" title="Download PostScript">ps</a>, <a href="/format/2311.14927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> View-Based Luminance Mapping in Open Workplace
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+G">Guanzhou Ji</a>, 
<a href="/search/cs?searchtype=author&query=Ou%2C+T">Tingsong Ou</a>, 
<a href="/search/cs?searchtype=author&query=Sawyer%2C+A+O">Azadeh O. Sawyer</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceeding of DESIGN COMPUTATION INPUT/OUTPUT CONFERENCE 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper introduces a novel computational method for mapping indoor
luminance values on the facade of an open workplace to improve its daylight
performance. 180-degree fisheye renderings from different indoor locations,
view positions, and times of the year are created. These renderings are then
transformed from two-dimensional (2D) images into three-dimensional (3D)
hemispheres. High luminance values are filtered and projected from the
hemisphere to the facade surface. This framework will highlight the areas of
the facade that allow too much light penetration into the interior environment.
The flexible workflow allows occupant centric lighting analysis that computes
multiple design parameters and synthesizes results for localized facade
optimization and daylight design.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14930" title="Abstract">arXiv:2311.14930</a> [<a href="/pdf/2311.14930" title="Download PDF">pdf</a>, <a href="/format/2311.14930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StreamFunnel: Facilitating Communication Between a VR Streamer and Many  Spectators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+H">Haohua Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Vachha%2C+C">Cyrus Vachha</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qianyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kumaravel%2C+B+T">Balasaravanan Thoravi Kumaravel</a>, 
<a href="/search/cs?searchtype=author&query=Hartmann%2C+B">Bj&#xf6;ern Hartmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The increasing adoption of Virtual Reality (VR) systems in different domains
have led to a need to support interaction between many spectators and a VR
user. This is common in game streaming, live performances, and webinars. Prior
CSCW systems for VR environments are limited to small groups of users. In this
work, we identify problems associated with interaction carried out with large
groups of users. To address this, we introduce an additional user role: the
co-host. They mediate communications between the VR user and many spectators.
To facilitate this mediation, we present StreamFunnel, which allows the co-host
to be part of the VR application's space and interact with it. The design of
StreamFunnel was informed by formative interviews with six experts.
StreamFunnel uses a cloud-based streaming solution to enable remote co-host and
many spectators to view and interact through standard web browsers, without
requiring any custom software. We present results of informal user testing
which provides insights into StreamFunnel's ability to facilitate these
scalable interactions. Our participants, who took the role of a co-host, found
that StreamFunnel enables them to add value in presenting the VR experience to
the spectators and relaying useful information from the live chat to the VR
user.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14931" title="Abstract">arXiv:2311.14931</a> [<a href="/pdf/2311.14931" title="Download PDF">pdf</a>, <a href="/format/2311.14931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-Shot Transfer Learning for Nonlinear ODEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+W">Wanzhou Lei</a>, 
<a href="/search/cs?searchtype=author&query=Protopapas%2C+P">Pavlos Protopapas</a>, 
<a href="/search/cs?searchtype=author&query=Parikh%2C+J">Joy Parikh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures, accepted to 2023 NeurIPS Workshop of The Symbiosis of Deep Learning and Differential Equations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We introduce a generalizable approach that combines perturbation method and
one-shot transfer learning to solve nonlinear ODEs with a single polynomial
term, using Physics-Informed Neural Networks (PINNs). Our method transforms
non-linear ODEs into linear ODE systems, trains a PINN across varied
conditions, and offers a closed-form solution for new instances within the same
non-linear ODE class. We demonstrate the effectiveness of this approach on the
Duffing equation and suggest its applicability to similarly structured PDEs and
ODE systems.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14933" title="Abstract">arXiv:2311.14933</a> [<a href="/pdf/2311.14933" title="Download PDF">pdf</a>, <a href="/format/2311.14933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ArcaDB: A Container-based Disaggregated Query Engine for Heterogenous  Computational Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruiz-Rohena%2C+K">Kristalys Ruiz-Rohena</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez-Martinez%2C+M">Manuel Rodriguez-Martinez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Modern enterprises rely on data management systems to collect, store, and
analyze vast amounts of data related with their operations. Nowadays, clusters
and hardware accelerators (e.g., GPUs, TPUs) have become a necessity to scale
with the data processing demands in many applications related to social media,
bioinformatics, surveillance systems, remote sensing, and medical informatics.
Given this new scenario, the architecture of data analytics engines must evolve
to take advantage of these new technological trends. In this paper, we present
ArcaDB: a disaggregated query engine that leverages container technology to
place operators at compute nodes that fit their performance profile. In ArcaDB,
a query plan is dispatched to worker nodes that have different computing
characteristics. Each operator is annotated with the preferred type of compute
node for execution, and ArcaDB ensures that the operator gets picked up by the
appropriate workers. We have implemented a prototype version of ArcaDB using
Java, Python, and Docker containers. We have also completed a preliminary
performance study of this prototype, using images and scientific data. This
study shows that ArcaDB can speed up query performance by a factor of 3.5x in
comparison with a shared-nothing, symmetric arrangement.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14934" title="Abstract">arXiv:2311.14934</a> [<a href="/pdf/2311.14934" title="Download PDF">pdf</a>, <a href="/format/2311.14934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Graph Neural Networks via Unbiased Aggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+R">Ruiqi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Z">Zhichao Hou</a>, 
<a href="/search/cs?searchtype=author&query=Derr%2C+T">Tyler Derr</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaorui Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The adversarial robustness of Graph Neural Networks (GNNs) has been
questioned due to the false sense of security uncovered by strong adaptive
attacks despite the existence of numerous defenses. In this work, we delve into
the robustness analysis of representative robust GNNs and provide a unified
robust estimation point of view to understand their robustness and limitations.
Our novel analysis of estimation bias motivates the design of a robust and
unbiased graph signal estimator. We then develop an efficient Quasi-Newton
iterative reweighted least squares algorithm to solve the estimation problem,
which unfolds as robust unbiased aggregation layers in GNNs with a theoretical
convergence guarantee. Our comprehensive experiments confirm the strong
robustness of our proposed model, and the ablation study provides a deep
understanding of its advantages.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14939" title="Abstract">arXiv:2311.14939</a> [<a href="/pdf/2311.14939" title="Download PDF">pdf</a>, <a href="/format/2311.14939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenNet: Incremental Learning for Autonomous Driving Object Detection  with Balanced Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zezhou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+G">Guitao Cao</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+X">Xidong Xi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiangtao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Automated driving object detection has always been a challenging task in
computer vision due to environmental uncertainties. These uncertainties include
significant differences in object sizes and encountering the class unseen. It
may result in poor performance when traditional object detection models are
directly applied to automated driving detection. Because they usually presume
fixed categories of common traffic participants, such as pedestrians and cars.
Worsely, the huge class imbalance between common and novel classes further
exacerbates performance degradation. To address the issues stated, we propose
OpenNet to moderate the class imbalance with the Balanced Loss, which is based
on Cross Entropy Loss. Besides, we adopt an inductive layer based on gradient
reshaping to fast learn new classes with limited samples during incremental
learning. To against catastrophic forgetting, we employ normalized feature
distillation. By the way, we improve multi-scale detection robustness and
unknown class recognition through FPN and energy-based detection, respectively.
The Experimental results upon the CODA dataset show that the proposed method
can obtain better performance than that of the existing methods.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14948" title="Abstract">arXiv:2311.14948</a> [<a href="/pdf/2311.14948" title="Download PDF">pdf</a>, <a href="/format/2311.14948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effective Backdoor Mitigation Depends on the Pre-training Objective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verma%2C+S">Sahil Verma</a>, 
<a href="/search/cs?searchtype=author&query=Bhatt%2C+G">Gantavya Bhatt</a>, 
<a href="/search/cs?searchtype=author&query=Schwarzschild%2C+A">Avi Schwarzschild</a>, 
<a href="/search/cs?searchtype=author&query=Singhal%2C+S">Soumye Singhal</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A+M">Arnav Mohanty Das</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+C">Chirag Shah</a>, 
<a href="/search/cs?searchtype=author&query=Dickerson%2C+J+P">John P Dickerson</a>, 
<a href="/search/cs?searchtype=author&query=Bilmes%2C+J">Jeff Bilmes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for oral presentation at BUGS workshop @ NeurIPS 2023 (<a href="https://neurips2023-bugs.github.io/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Despite the advanced capabilities of contemporary machine learning (ML)
models, they remain vulnerable to adversarial and backdoor attacks. This
vulnerability is particularly concerning in real-world deployments, where
compromised models may exhibit unpredictable behavior in critical scenarios.
Such risks are heightened by the prevalent practice of collecting massive,
internet-sourced datasets for pre-training multimodal models, as these datasets
may harbor backdoors. Various techniques have been proposed to mitigate the
effects of backdooring in these models such as CleanCLIP which is the current
state-of-the-art approach.
<br />In this work, we demonstrate that the efficacy of CleanCLIP in mitigating
backdoors is highly dependent on the particular objective used during model
pre-training.
<br />We observe that stronger pre-training objectives correlate with harder to
remove backdoors behaviors. We show this by training multimodal models on two
large datasets consisting of 3 million (CC3M) and 6 million (CC6M) datapoints,
under various pre-training objectives, followed by poison removal using
CleanCLIP. We find that CleanCLIP is ineffective when stronger pre-training
objectives are used, even with extensive hyperparameter tuning.
<br />Our findings underscore critical considerations for ML practitioners who
pre-train models using large-scale web-curated data and are concerned about
potential backdoor threats. Notably, our results suggest that simpler
pre-training objectives are more amenable to effective backdoor removal. This
insight is pivotal for practitioners seeking to balance the trade-offs between
using stronger pre-training objectives and security against backdoor attacks.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14949" title="Abstract">arXiv:2311.14949</a> [<a href="/pdf/2311.14949" title="Download PDF">pdf</a>, <a href="/format/2311.14949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vector-Quantized Prompt Learning for Paraphrase Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haotian Luo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yixin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Peidong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianggen Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP Findings, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Deep generative modeling of natural languages has achieved many successes,
such as producing fluent sentences and translating from one language into
another. However, the development of generative modeling techniques for
paraphrase generation still lags behind largely due to the challenges in
addressing the complex conflicts between expression diversity and semantic
preservation. This paper proposes to generate diverse and high-quality
paraphrases by exploiting the pre-trained models with instance-dependent
prompts. To learn generalizable prompts, we assume that the number of abstract
transforming patterns of paraphrase generation (governed by prompts) is finite
and usually not large. Therefore, we present vector-quantized prompts as the
cues to control the generation of pre-trained models. Extensive experiments
demonstrate that the proposed method achieves new state-of-art results on three
benchmark datasets, including Quora, Wikianswers, and MSCOCO. We will release
all the code upon acceptance.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14955" title="Abstract">arXiv:2311.14955</a> [<a href="/pdf/2311.14955" title="Download PDF">pdf</a>, <a href="/ps/2311.14955" title="Download PostScript">ps</a>, <a href="/format/2311.14955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identification of morphological fingerprint in perinatal brains using  quasi-conformal mapping and contrastive learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Boyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Weihao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Ying Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+Y">Yuchen Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Minmin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The morphological fingerprint in the brain is capable of identifying the
uniqueness of an individual. However, whether such individual patterns are
present in perinatal brains, and which morphological attributes or cortical
regions better characterize the individual differences of ne-onates remain
unclear. In this study, we proposed a deep learning framework that projected
three-dimensional spherical meshes of three morphological features (i.e.,
cortical thickness, mean curvature, and sulcal depth) onto two-dimensional
planes through quasi-conformal mapping, and employed the ResNet18 and
contrastive learning for individual identification. We used the cross-sectional
structural MRI data of 682 infants, incorporating with data augmentation, to
train the model and fine-tuned the parameters based on 60 infants who had
longitudinal scans. The model was validated on 30 longitudinal scanned infant
data, and remarkable Top1 and Top5 accuracies of 71.37% and 84.10% were
achieved, respectively. The sensorimotor and visual cortices were recognized as
the most contributive regions in individual identification. Moreover, the
folding morphology demonstrated greater discriminative capability than the
cortical thickness, which could serve as the morphological fingerprint in
perinatal brains. These findings provided evidence for the emergence of
morphological fingerprints in the brain at the beginning of the third
trimester, which may hold promising implications for understanding the
formation of in-dividual uniqueness in the brain during early development.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14957" title="Abstract">arXiv:2311.14957</a> [<a href="/pdf/2311.14957" title="Download PDF">pdf</a>, <a href="/format/2311.14957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Scale Sub-Band Constant-Q Transform Discriminator for  High-Fidelity Vocoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yicheng Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xueyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+L">Liumeng Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhizheng Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Generative Adversarial Network (GAN) based vocoders are superior in inference
speed and synthesis quality when reconstructing an audible waveform from an
acoustic representation. This study focuses on improving the discriminator to
promote GAN-based vocoders. Most existing time-frequency-representation-based
discriminators are rooted in Short-Time Fourier Transform (STFT), whose
time-frequency resolution in a spectrogram is fixed, making it incompatible
with signals like singing voices that require flexible attention for different
frequency bands. Motivated by that, our study utilizes the Constant-Q Transform
(CQT), which owns dynamic resolution among frequencies, contributing to a
better modeling ability in pitch accuracy and harmonic tracking. Specifically,
we propose a Multi-Scale Sub-Band CQT (MS-SB-CQT) Discriminator, which operates
on the CQT spectrogram at multiple scales and performs sub-band processing
according to different octaves. Experiments conducted on both speech and
singing voices confirm the effectiveness of our proposed method. Moreover, we
also verified that the CQT-based and the STFT-based discriminators could be
complementary under joint training. Specifically, enhanced by the proposed
MS-SB-CQT and the existing MS-STFT Discriminators, the MOS of HiFi-GAN can be
boosted from 3.27 to 3.87 for seen singers and from 3.40 to 3.78 for unseen
singers.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14960" title="Abstract">arXiv:2311.14960</a> [<a href="/pdf/2311.14960" title="Download PDF">pdf</a>, <a href="/format/2311.14960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point Cloud Pre-training with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaoshui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+G">Guofeng Mei</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yuenan Hou</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Z">Zhaoyang Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bo Dai</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yongshun Gong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Pre-training a model and then fine-tuning it on downstream tasks has
demonstrated significant success in the 2D image and NLP domains. However, due
to the unordered and non-uniform density characteristics of point clouds, it is
non-trivial to explore the prior knowledge of point clouds and pre-train a
point cloud backbone. In this paper, we propose a novel pre-training method
called Point cloud Diffusion pre-training (PointDif). We consider the point
cloud pre-training task as a conditional point-to-point generation problem and
introduce a conditional point generator. This generator aggregates the features
extracted by the backbone and employs them as the condition to guide the
point-to-point recovery from the noisy point cloud, thereby assisting the
backbone in capturing both local and global geometric priors as well as the
global point density distribution of the object. We also present a recurrent
uniform sampling optimization strategy, which enables the model to uniformly
recover from various noise levels and learn from balanced supervision. Our
PointDif achieves substantial improvement across various real-world datasets
for diverse downstream tasks such as classification, segmentation and
detection. Specifically, PointDif attains 70.0% mIoU on S3DIS Area 5 for the
segmentation task and achieves an average improvement of 2.4% on ScanObjectNN
for the classification task compared to TAP. Furthermore, our pre-training
framework can be flexibly applied to diverse point cloud backbones and bring
considerable gains.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14961" title="Abstract">arXiv:2311.14961</a> [<a href="/pdf/2311.14961" title="Download PDF">pdf</a>, <a href="/format/2311.14961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Repetition factorization of automatic sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shallit%2C+J">Jeffrey Shallit</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xinhao Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">Following Inoue et al., we define a word to be a repetition if it is a
(fractional) power of exponent at least 2. A word has a repetition
factorization if it is the product of repetitions. We study repetition
factorizations in several (generalized) automatic sequences, including the
infinite Fibonacci word, the Thue-Morse word, paperfolding words, and the
Rudin-Shapiro sequence.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14966" title="Abstract">arXiv:2311.14966</a> [<a href="/pdf/2311.14966" title="Download PDF">pdf</a>, <a href="/format/2311.14966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Walking a Tightrope -- Evaluating Large Language Models in High-Risk  Domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hung%2C+C">Chia-Chien Hung</a>, 
<a href="/search/cs?searchtype=author&query=Rim%2C+W+B">Wiem Ben Rim</a>, 
<a href="/search/cs?searchtype=author&query=Frost%2C+L">Lindsay Frost</a>, 
<a href="/search/cs?searchtype=author&query=Bruckner%2C+L">Lars Bruckner</a>, 
<a href="/search/cs?searchtype=author&query=Lawrence%2C+C">Carolin Lawrence</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Workshop on Benchmarking Generalisation in NLP (GenBench)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">High-risk domains pose unique challenges that require language models to
provide accurate and safe responses. Despite the great success of large
language models (LLMs), such as ChatGPT and its variants, their performance in
high-risk domains remains unclear. Our study delves into an in-depth analysis
of the performance of instruction-tuned LLMs, focusing on factual accuracy and
safety adherence. To comprehensively assess the capabilities of LLMs, we
conduct experiments on six NLP datasets including question answering and
summarization tasks within two high-risk domains: legal and medical. Further
qualitative analysis highlights the existing limitations inherent in current
LLMs when evaluating in high-risk domains. This underscores the essential
nature of not only improving LLM capabilities but also prioritizing the
refinement of domain-specific metrics, and embracing a more human-centric
approach to enhance safety and factual reliability. Our findings advance the
field toward the concerns of properly evaluating LLMs in high-risk domains,
aiming to steer the adaptability of LLMs in fulfilling societal obligations and
aligning with forthcoming regulations, such as the EU AI Act.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14968" title="Abstract">arXiv:2311.14968</a> [<a href="/pdf/2311.14968" title="Download PDF">pdf</a>, <a href="/format/2311.14968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hide Your Model: A Parameter Transmission-free Federated Recommender  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Wei Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chaoqun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+L">Liang Qu</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q+V+H">Quoc Viet Hung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongzhi Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">With the growing concerns regarding user data privacy, Federated Recommender
System (FedRec) has garnered significant attention recently due to its
privacy-preserving capabilities. Existing FedRecs generally adhere to a
learning protocol in which a central server shares a global recommendation
model with clients, and participants achieve collaborative learning by
frequently communicating the model's public parameters. Nevertheless, this
learning framework has two drawbacks that limit its practical usability: (1) It
necessitates a global-sharing recommendation model; however, in real-world
scenarios, information related to the recommender model, including its
algorithm and parameters, constitutes the platforms' intellectual property.
Hence, service providers are unlikely to release such information actively. (2)
The communication costs of model parameter transmission are expensive since the
model parameters are usually high-dimensional matrices. With the model size
increasing, the communication burden will be the bottleneck for such
traditional FedRecs.
<br />Given the above limitations, this paper introduces a novel parameter
transmission-free federated recommendation framework that balances the
protection between users' data privacy and platforms' model privacy, namely
PTF-FedRec. Specifically, participants in PTF-FedRec collaboratively exchange
knowledge by sharing their predictions within a privacy-preserving mechanism.
Through this way, the central server can learn a recommender model without
disclosing its model parameters or accessing clients' raw data, preserving both
the server's model privacy and users' data privacy. Besides, since clients and
the central server only need to communicate prediction scores which are just a
few real numbers, the overhead is significantly reduced compared to traditional
FedRecs.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14969" title="Abstract">arXiv:2311.14969</a> [<a href="/pdf/2311.14969" title="Download PDF">pdf</a>, <a href="/format/2311.14969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Completeness of Riemannian metrics: an application to the control of  constrained mechanical systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Acosta%2C+J+%C3%81">Jos&#xe9; &#xc1;ngel Acosta</a>, 
<a href="/search/eess?searchtype=author&query=Bloch%2C+A">Anthony Bloch</a>, 
<a href="/search/eess?searchtype=author&query=de+Diego%2C+D+M">David Mart&#xed;n de Diego</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Differential Geometry (math.DG); Dynamical Systems (math.DS)

</div>
<p class="mathjax">We introduce a mathematical technique based on modifying a given Riemannian
metric and we investigate its applicability to controlling and stabilizing
constrained mechanical systems. In essence our result is based on the
construction of a complete Riemannian metric in the modified space where the
constraint is included. In particular this can be applied to the controlled
Lagrangians technique Bloch et al. [2000b, 2001] modifying its metric to
additionally cover mechanical systems with configuration constraints via
control. The technique used consists of approximating incomplete Riemannian
metrics by complete ones, modifying the evolution near a boundary and finding a
controller satisfying a given design criterion.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14970" title="Abstract">arXiv:2311.14970</a> [<a href="/pdf/2311.14970" title="Download PDF">pdf</a>, <a href="/format/2311.14970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UWB Radar SLAM: an Anchorless Approach in Vision Denied Indoor  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Premachandra%2C+H+A+G+C">H. A. G. C. Premachandra</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ran Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yuen%2C+C">Chau Yuen</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+U">U-Xuan Tan</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in IEEE Robotics and Automation Letters, vol. 8, no. 9, pp.
  5299-5306, Sept. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">LiDAR and cameras are frequently used as sensors for simultaneous
localization and mapping (SLAM). However, these sensors are prone to failure
under low visibility (e.g. smoke) or places with reflective surfaces (e.g.
mirrors). On the other hand, electromagnetic waves exhibit better penetration
properties when the wavelength increases, thus are not affected by low
visibility. Hence, this paper presents ultra-wideband (UWB) radar as an
alternative to the existing sensors. UWB is generally known to be used in
anchor-tag SLAM systems. One or more anchors are installed in the environment
and the tags are attached to the robots. Although this method performs well
under low visibility, modifying the existing infrastructure is not always
feasible. UWB has also been used in peer-to-peer ranging collaborative SLAM
systems. However, this requires more than a single robot and does not include
mapping in the mentioned environment like smoke. Therefore, the presented
approach in this paper solely depends on the UWB transceivers mounted on-board.
In addition, an extended Kalman filter (EKF) SLAM is used to solve the SLAM
problem at the back-end. Experiments were conducted and demonstrated that the
proposed UWB-based radar SLAM is able to map natural point landmarks inside an
indoor environment while improving robot localization.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14971" title="Abstract">arXiv:2311.14971</a> [<a href="/pdf/2311.14971" title="Download PDF">pdf</a>, <a href="/ps/2311.14971" title="Download PostScript">ps</a>, <a href="/format/2311.14971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segmentation of diagnostic tissue compartments on whole slide images  with renal thrombotic microangiopathies (TMAs)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vo%2C+H+Q">Huy Q. Vo</a>, 
<a href="/search/cs?searchtype=author&query=Cicalese%2C+P+A">Pietro A. Cicalese</a>, 
<a href="/search/cs?searchtype=author&query=Seshan%2C+S">Surya Seshan</a>, 
<a href="/search/cs?searchtype=author&query=Rizvi%2C+S+A">Syed A. Rizvi</a>, 
<a href="/search/cs?searchtype=author&query=Vathul%2C+A">Aneesh Vathul</a>, 
<a href="/search/cs?searchtype=author&query=Bueno%2C+G">Gloria Bueno</a>, 
<a href="/search/cs?searchtype=author&query=Dorado%2C+A+P">Anibal Pedraza Dorado</a>, 
<a href="/search/cs?searchtype=author&query=Grabe%2C+N">Niels Grabe</a>, 
<a href="/search/cs?searchtype=author&query=Stolle%2C+K">Katharina Stolle</a>, 
<a href="/search/cs?searchtype=author&query=Pesce%2C+F">Francesco Pesce</a>, 
<a href="/search/cs?searchtype=author&query=Roelofs%2C+J+J+T+H">Joris J.T.H. Roelofs</a>, 
<a href="/search/cs?searchtype=author&query=Kers%2C+J">Jesper Kers</a>, 
<a href="/search/cs?searchtype=author&query=Bevilacqua%2C+V">Vitoantonio Bevilacqua</a>, 
<a href="/search/cs?searchtype=author&query=Altinini%2C+N">Nicola Altinini</a>, 
<a href="/search/cs?searchtype=author&query=Schr%C3%B6ppel%2C+B">Bernd Schr&#xf6;ppel</a>, 
<a href="/search/cs?searchtype=author&query=Roccatello%2C+D">Dario Roccatello</a>, 
<a href="/search/cs?searchtype=author&query=Barreca%2C+A">Antonella Barreca</a>, 
<a href="/search/cs?searchtype=author&query=Sciascia%2C+S">Savino Sciascia</a>, 
<a href="/search/cs?searchtype=author&query=Mohan%2C+C">Chandra Mohan</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H+V">Hien V. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Becker%2C+J+U">Jan U. Becker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Tissues and Organs (q-bio.TO)

</div>
<p class="mathjax">The thrombotic microangiopathies (TMAs) manifest in renal biopsy histology
with a broad spectrum of acute and chronic findings. Precise diagnostic
criteria for a renal biopsy diagnosis of TMA are missing. As a first step
towards a machine learning- and computer vision-based analysis of wholes slide
images from renal biopsies, we trained a segmentation model for the decisive
diagnostic kidney tissue compartments artery, arteriole, glomerulus on a set of
whole slide images from renal biopsies with TMAs and Mimickers (distinct
diseases with a similar nephropathological appearance as TMA like severe benign
nephrosclerosis, various vasculitides, Bevacizumab-plug glomerulopathy,
arteriolar light chain deposition disease). Our segmentation model combines a
U-Net-based tissue detection with a Shifted windows-transformer architecture to
reach excellent segmentation results for even the most severely altered
glomeruli, arterioles and arteries, even on unseen staining domains from a
different nephropathology lab. With accurate automatic segmentation of the
decisive renal biopsy compartments in human renal vasculopathies, we have laid
the foundation for large-scale compartment-specific machine learning and
computer vision analysis of renal biopsy repositories with TMAs.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14974" title="Abstract">arXiv:2311.14974</a> [<a href="/pdf/2311.14974" title="Download PDF">pdf</a>, <a href="/format/2311.14974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Surface with Passive Omni-Directional Adaptation of Soft  Polyhedral Fingers for In-Hand Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sen Li</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+F">Fang Wan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Chaoyang Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures, 2 tables, submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Track systems effectively distribute loads, augmenting traction and
maneuverability on unstable terrains, leveraging their expansive contact areas.
This tracked locomotion capability also aids in hand manipulation of not only
regular objects but also irregular objects. In this study, we present the
design of a soft robotic finger with an active surface on an omni-adaptive
network structure, which can be easily installed on existing grippers and
achieve stability and dexterity for in-hand manipulation. The system's active
surfaces initially transfer the object from the fingertip segment with less
compliance to the middle segment of the finger with superior adaptability.
Despite the omni-directional deformation of the finger, in-hand manipulation
can still be executed with controlled active surfaces. We characterized the
soft finger's stiffness distribution and simplified models to assess the
feasibility of repositioning and reorienting a grasped object. A set of
experiments on in-hand manipulation was performed with the proposed fingers,
demonstrating the dexterity and robustness of the strategy.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14975" title="Abstract">arXiv:2311.14975</a> [<a href="/pdf/2311.14975" title="Download PDF">pdf</a>, <a href="/format/2311.14975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eliminating Domain Bias for Federated Learning in Representation Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+Y">Yang Hua</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jian Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+T">Tao Song</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Z">Zhengui Xue</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+R">Ruhui Ma</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+H">Haibing Guan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023, 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Recently, federated learning (FL) is popular for its privacy-preserving and
collaborative learning abilities. However, under statistically heterogeneous
scenarios, we observe that biased data domains on clients cause a
representation bias phenomenon and further degenerate generic representations
during local training, i.e., the representation degeneration phenomenon. To
address these issues, we propose a general framework Domain Bias Eliminator
(DBE) for FL. Our theoretical analysis reveals that DBE can promote
bi-directional knowledge transfer between server and client, as it reduces the
domain discrepancy between server and client in representation space. Besides,
extensive experiments on four datasets show that DBE can greatly improve
existing FL methods in both generalization and personalization abilities. The
DBE-equipped FL method can outperform ten state-of-the-art personalized FL
methods by a large margin. Our code is public at
https://github.com/TsingZ0/DBE.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14977" title="Abstract">arXiv:2311.14977</a> [<a href="/pdf/2311.14977" title="Download PDF">pdf</a>, <a href="/ps/2311.14977" title="Download PostScript">ps</a>, <a href="/format/2311.14977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incorporating granularity bias as the margin into contrastive loss for  video captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiayang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+F">Fengming Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Video captioning models easily suffer from long-tail distribution of phrases,
which makes captioning models prone to generate vague sentences instead of
accurate ones. However, existing debiasing strategies tend to export external
knowledge to build dependency trees of words or refine frequency distribution
by complex losses and extra input features, which lack interpretability and are
hard to train. To mitigate the impact of granularity bias on the model, we
introduced a statistical-based bias extractor. This extractor quantifies the
information content within sentences and videos, providing an estimate of the
likelihood that a video-sentence pair is affected by granularity bias.
Furthermore, with the growing trend of integrating contrastive learning methods
into video captioning tasks, we use a bidirectional triplet loss to get more
negative samples in a batch. Subsequently, we incorporate the margin score into
the contrastive learning loss, establishing distinct training objectives for
head and tail sentences. This approach facilitates the model's training
effectiveness on tail samples. Our simple yet effective loss, incorporating
Granularity bias, is referred to as the Margin-Contrastive Loss (GMC Loss). The
proposed model demonstrates state-of-the-art performance on MSRVTT with a CIDEr
of 57.17, and MSVD, where CIDEr reaches up to 138.68.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14979" title="Abstract">arXiv:2311.14979</a> [<a href="/pdf/2311.14979" title="Download PDF">pdf</a>, <a href="/ps/2311.14979" title="Download PostScript">ps</a>, <a href="/format/2311.14979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive time delay based control of non-collocated oscillatory systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ruderman%2C+M">Michael Ruderman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Time delay based control, recently proposed for non-collocated fourth-order
systems, has several advantages over an observer-based state-feedback
cancellation of the low-damped oscillations. In this paper, we discuss a
practical infeasibility of such observer-based approach and bring forward the
application of the time delay based controller - simple in both the structure
and design. A robust estimation of the output oscillation frequency is used and
extended, in this work, by a bias cancellation that is required for tracking
the oscillatory load. This way, an adaptive tuning of the time delay based
controller is realized which does not require knowledge of the mass and
stiffness parameters. The results are demonstrated on the oscillatory
experimental setup with constraints in both the operation range and control
value.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14981" title="Abstract">arXiv:2311.14981</a> [<a href="/pdf/2311.14981" title="Download PDF">pdf</a>, <a href="/format/2311.14981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-task Planar Reconstruction with Feature Warping Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+L">Luan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Hilsmann%2C+A">Anna Hilsmann</a>, 
<a href="/search/cs?searchtype=author&query=Eisert%2C+P">Peter Eisert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Piece-wise planar 3D reconstruction simultaneously segments plane instances
and recovers their 3D plane parameters from an image, which is particularly
useful for indoor or man-made environments. Efficient reconstruction of 3D
planes coupled with semantic predictions offers advantages for a wide range of
applications requiring scene understanding and concurrent spatial mapping.
However, most existing planar reconstruction models either neglect semantic
predictions or do not run efficiently enough for real-time applications. We
introduce SoloPlanes, a real-time planar reconstruction model based on a
modified instance segmentation architecture which simultaneously predicts
semantics for each plane instance, along with plane parameters and piece-wise
plane instance masks. By providing multi-view guidance in feature space, we
achieve an improvement in instance mask segmentation despite only warping plane
features due to the nature of feature sharing in multi-task learning. Our model
simultaneously predicts semantics using single images at inference time, while
achieving real-time predictions at 43 FPS. The code will be released
post-publication.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14982" title="Abstract">arXiv:2311.14982</a> [<a href="/pdf/2311.14982" title="Download PDF">pdf</a>, <a href="/format/2311.14982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Queue Management with Data-Driven Delay Violation Probability  Predictors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mostafavi%2C+S">Samie Mostafavi</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+N">Neelabhro Roy</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%A1n%2C+G">Gy&#xf6;rgy D&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Gross%2C+J">James Gross</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The increasing demand for latency-sensitive applications has necessitated the
development of sophisticated algorithms that efficiently manage packets with
end-to-end delay targets traversing the networked infrastructure. Network
components must consider minimizing the packets' end-to-end delay violation
probabilities (DVP) as a guiding principle throughout the transmission path to
ensure timely deliveries. Active queue management (AQM) schemes are commonly
used to mitigate congestion by dropping packets and controlling queuing delay.
Today's established AQM schemes are threshold-driven, identifying congestion
and trigger packet dropping using a predefined criteria which is unaware of
packets' DVPs. In this work, we propose a novel framework, Delta, that combines
end-to-end delay characterization with AQM for minimizing DVP. In a queuing
theoretic environment, we show that such a policy is feasible by utilizing a
data-driven approach to predict the queued packets' DVPs. That enables Delta
AQM to effectively handle links with arbitrary stationary service time
processes. The implementation is described in detail, and its performance is
evaluated and compared with state of the art AQM algorithms. Our results show
the Delta outperforms current AQM schemes substantially, in particular in
scenarios where high reliability, i.e. high quantiles of the tail latency
distribution, are of interest.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14986" title="Abstract">arXiv:2311.14986</a> [<a href="/pdf/2311.14986" title="Download PDF">pdf</a>, <a href="/format/2311.14986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAME++: A Self-supervised Anatomical eMbeddings Enhanced medical image  registration framework using stable sampling and regularized transformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+L">Lin Tian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zi Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fengze Liu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiaoyu Bai</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+J">Jia Ge</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Le Lu</a>, 
<a href="/search/cs?searchtype=author&query=Niethammer%2C+M">Marc Niethammer</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xianghua Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+K">Ke Yan</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+D">Daikai Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image registration is a fundamental medical image analysis task. Ideally,
registration should focus on aligning semantically corresponding voxels, i.e.,
the same anatomical locations. However, existing methods often optimize
similarity measures computed directly on intensities or on hand-crafted
features, which lack anatomical semantic information. These similarity measures
may lead to sub-optimal solutions where large deformations, complex anatomical
differences, or cross-modality imagery exist. In this work, we introduce a fast
and accurate method for unsupervised 3D medical image registration building on
top of a Self-supervised Anatomical eMbedding (SAM) algorithm, which is capable
of computing dense anatomical correspondences between two images at the voxel
level. We name our approach SAM-Enhanced registration (SAME++), which
decomposes image registration into four steps: affine transformation, coarse
deformation, deep non-parametric transformation, and instance optimization.
Using SAM embeddings, we enhance these steps by finding more coherent
correspondence and providing features with better semantic guidance. We
extensively evaluated SAME++ using more than 50 labeled organs on three
challenging inter-subject registration tasks of different body parts. As a
complete registration framework, SAME++ markedly outperforms leading methods by
$4.2\%$ - $8.2\%$ in terms of Dice score while being orders of magnitude faster
than numerical optimization-based methods. Code is available at
\url{https://github.com/alibaba-damo-academy/same}.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14988" title="Abstract">arXiv:2311.14988</a> [<a href="/pdf/2311.14988" title="Download PDF">pdf</a>, <a href="/ps/2311.14988" title="Download PostScript">ps</a>, <a href="/format/2311.14988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Performance Analysis of Spectrum Sharing between UAV enabled  Wireless Mesh Networks and Ground Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhiqing Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jialin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zijun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+F">Fan Ning</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 13 figures, IEEE Sensors Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Performance (cs.PF)

</div>
<p class="mathjax">Unmanned aerial vehicle (UAV) has the advantages of large coverage and
flexibility, which could be applied in disaster management to provide wireless
services to the rescuers and victims. When UAVs forms an aerial mesh network,
line-of-sight (LoS) air-to-air (A2A) communications have long transmission
distance, which extends the coverage of multiple UAVs. However, the capacity of
UAV is constrained due to the multiple hop transmissions in aerial mesh
networks. In this paper, spectrum sharing between UAV enabled wireless mesh
networks and ground networks is studied to improve the capacity of UAV
networks. Considering two-dimensional (2D) and three-dimensional (3D)
homogeneous Poisson point process (PPP) modeling for the distribution of UAVs
within a vertical range {\Delta}h, stochastic geometry is applied to analyze
the impact of the height of UAVs, the transmit power of UAVs, the density of
UAVs and the vertical range, etc., on the coverage probability of ground
network user and UAV network user. Besides, performance improvement of spectrum
sharing with directional antenna is verified. With the object function of
maximizing the transmission capacity, the optimal altitude of UAVs is obtained.
This paper provides a theoretical guideline for the spectrum sharing of UAV
enabled wireless mesh networks, which may contribute significant value to the
study of spectrum sharing mechanisms for UAV enabled wireless mesh networks.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14993" title="Abstract">arXiv:2311.14993</a> [<a href="/pdf/2311.14993" title="Download PDF">pdf</a>, <a href="/format/2311.14993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coordinate-Aware Modulation for Neural Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+C">Joo Chan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Rho%2C+D">Daniel Rho</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+S">Seungtae Nam</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+J+H">Jong Hwan Ko</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+E">Eunbyung Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="http://maincold2.github.io/cam/">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural fields, mapping low-dimensional input coordinates to corresponding
signals, have shown promising results in representing various signals. Numerous
methodologies have been proposed, and techniques employing MLPs and grid
representations have achieved substantial success. MLPs allow compact and high
expressibility, yet often suffer from spectral bias and slow convergence speed.
On the other hand, methods using grids are free from spectral bias and achieve
fast training speed, however, at the expense of high spatial complexity. In
this work, we propose a novel way for exploiting both MLPs and grid
representations in neural fields. Unlike the prevalent methods that combine
them sequentially (extract features from the grids first and feed them to the
MLP), we inject spectral bias-free grid representations into the intermediate
features in the MLP. More specifically, we suggest a Coordinate-Aware
Modulation (CAM), which modulates the intermediate features using scale and
shift parameters extracted from the grid representations. This can maintain the
strengths of MLPs while mitigating any remaining potential biases, facilitating
the rapid learning of high-frequency components. In addition, we empirically
found that the feature normalizations, which have not been successful in neural
filed literature, proved to be effective when applied in conjunction with the
proposed CAM. Experimental results demonstrate that CAM enhances the
performance of neural representation and improves learning stability across a
range of signals. Especially in the novel view synthesis task, we achieved
state-of-the-art performance with the least number of parameters and fast
training speed for dynamic scenes and the best performance under 1MB memory for
static scenes. CAM also outperforms the best-performing video compression
methods using neural fields by a large margin.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14994" title="Abstract">arXiv:2311.14994</a> [<a href="/pdf/2311.14994" title="Download PDF">pdf</a>, <a href="/format/2311.14994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Causal Learning through Graph Neural Networks: An In-depth  Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Job%2C+S">Simi Job</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+X">Xiaohui Tao</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+T">Taotao Cai</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Haoran Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lin Li</a>, 
<a href="/search/cs?searchtype=author&query=Yong%2C+J">Jianming Yong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In machine learning, exploring data correlations to predict outcomes is a
fundamental task. Recognizing causal relationships embedded within data is
pivotal for a comprehensive understanding of system dynamics, the significance
of which is paramount in data-driven decision-making processes. Beyond
traditional methods, there has been a surge in the use of graph neural networks
(GNNs) for causal learning, given their capabilities as universal data
approximators. Thus, a thorough review of the advancements in causal learning
using GNNs is both relevant and timely. To structure this review, we introduce
a novel taxonomy that encompasses various state-of-the-art GNN methods employed
in studying causality. GNNs are further categorized based on their applications
in the causality domain. We further provide an exhaustive compilation of
datasets integral to causal learning with GNNs to serve as a resource for
practical study. This review also touches upon the application of causal
learning across diverse sectors. We conclude the review with insights into
potential challenges and promising avenues for future exploration in this
rapidly evolving field of machine learning.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15000" title="Abstract">arXiv:2311.15000</a> [<a href="/pdf/2311.15000" title="Download PDF">pdf</a>, <a href="/format/2311.15000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Satellite-based feature extraction and multivariate time-series  prediction of biotoxin contamination in shellfish
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tavares%2C+S">Sergio Tavares</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+P+R">Pedro R. Costa</a>, 
<a href="/search/cs?searchtype=author&query=Krippahl%2C+L">Ludwig Krippahl</a>, 
<a href="/search/cs?searchtype=author&query=Lopes%2C+M+B">Marta B. Lopes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Shellfish production constitutes an important sector for the economy of many
Portuguese coastal regions, yet the challenge of shellfish biotoxin
contamination poses both public health concerns and significant economic risks.
Thus, predicting shellfish contamination levels holds great potential for
enhancing production management and safeguarding public health. In our study,
we utilize a dataset with years of Sentinel-3 satellite imagery for marine
surveillance, along with shellfish biotoxin contamination data from various
production areas along Portugal's western coastline, collected by Portuguese
official control. Our goal is to evaluate the integration of satellite data in
forecasting models for predicting toxin concentrations in shellfish given
forecasting horizons up to four weeks, which implies extracting a small set of
useful features and assessing their impact on the predictive models. We framed
this challenge as a time-series forecasting problem, leveraging historical
contamination levels and satellite images for designated areas. While
contamination measurements occurred weekly, satellite images were accessible
multiple times per week. Unsupervised feature extraction was performed using
autoencoders able to handle non-valid pixels caused by factors like cloud
cover, land, or anomalies. Finally, several Artificial Neural Networks models
were applied to compare univariate (contamination only) and multivariate
(contamination and satellite data) time-series forecasting. Our findings show
that incorporating these features enhances predictions, especially beyond one
week in lagoon production areas (RIAV) and for the 1-week and 2-week horizons
in the L5B area (oceanic). The methodology shows the feasibility of integrating
information from a high-dimensional data source like remote sensing without
compromising the model's predictive ability.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15003" title="Abstract">arXiv:2311.15003</a> [<a href="/pdf/2311.15003" title="Download PDF">pdf</a>, <a href="/ps/2311.15003" title="Download PostScript">ps</a>, <a href="/format/2311.15003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enumerating Error Bounded Polytime Algorithms Through Arithmetical  Theories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Antonelli%2C+M">Melissa Antonelli</a>, 
<a href="/search/cs?searchtype=author&query=Lago%2C+U+D">Ugo Dal Lago</a>, 
<a href="/search/cs?searchtype=author&query=Davoli%2C+D">Davide Davoli</a>, 
<a href="/search/cs?searchtype=author&query=Oitavem%2C+I">Isabel Oitavem</a>, 
<a href="/search/cs?searchtype=author&query=Pistone%2C+P">Paolo Pistone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Logic (math.LO)

</div>
<p class="mathjax">We consider a minimal extension of the language of arithmetic, such that the
bounded formulas provably total in a suitably-defined theory \`a la Buss
(expressed in this new language) precisely capture polytime random functions.
Then, we provide two new characterizations of the semantic class BPP obtained
by internalizing the error-bound check within a logical system: the first
relies on measure-sensitive quantifiers, while the second is based on standard
first-order quantification. This leads us to introduce a family of effectively
enumerable subclasses of BPP, called BPP_T and consisting of languages captured
by those probabilistic Turing machines whose underlying error can be proved
bounded in the theory T. As a paradigmatic example of this approach, we
establish that polynomial identity testing is in BPP_T where
T=$\mathrm{I}\Delta_0+\mathrm{Exp}$ is a well-studied theory based on bounded
induction.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15005" title="Abstract">arXiv:2311.15005</a> [<a href="/pdf/2311.15005" title="Download PDF">pdf</a>, <a href="/ps/2311.15005" title="Download PostScript">ps</a>, <a href="/format/2311.15005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectrum Sharing between UAV-based Wireless Mesh Networks and Ground  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhiqing Wei</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zijun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhiyong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jialin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+C">Caijun Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qihui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Huici Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">The unmanned aerial vehicle (UAV)-based wireless mesh networks can
economically provide wireless services for the areas with disasters. However,
the capacity of air-to-air communications is limited due to the multi-hop
transmissions. In this paper, the spectrum sharing between UAV-based wireless
mesh networks and ground networks is studied to improve the capacity of the UAV
networks. Considering the distribution of UAVs as a three-dimensional (3D)
homogeneous Poisson point process (PPP) within a vertical range, the stochastic
geometry is applied to analyze the impact of the height of UAVs, the transmit
power of UAVs, the density of UAVs and the vertical range, etc., on the
coverage probability of ground network user and UAV network user, respectively.
The optimal height of UAVs is numerically achieved in maximizing the capacity
of UAV networks with the constraint of the coverage probability of ground
network user. This paper provides a basic guideline for the deployment of
UAV-based wireless mesh networks.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15006" title="Abstract">arXiv:2311.15006</a> [<a href="/pdf/2311.15006" title="Download PDF">pdf</a>, <a href="/format/2311.15006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey Examining Neuromorphic Architecture in Space and Challenges  from Radiation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naoukin%2C+J">Jonathan Naoukin</a>, 
<a href="/search/cs?searchtype=author&query=Isik%2C+M">Murat Isik</a>, 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+K">Karn Tiwari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Journal on Miniaturization for Air and Space Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
<p class="mathjax">Inspired by the human brain's structure and function, neuromorphic computing
has emerged as a promising approach for developing energy-efficient and
powerful computing systems. Neuromorphic computing offers significant
processing speed and power consumption advantages in aerospace applications.
These two factors are crucial for real-time data analysis and decision-making.
However, the harsh space environment, particularly with the presence of
radiation, poses significant challenges to the reliability and performance of
these computing systems. This paper comprehensively surveys the integration of
radiation-resistant neuromorphic computing systems in aerospace applications.
We explore the challenges posed by space radiation, review existing solutions
and developments, present case studies of neuromorphic computing systems used
in space applications, discuss future directions, and discuss the potential
benefits of this technology in future space missions.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15010" title="Abstract">arXiv:2311.15010</a> [<a href="/pdf/2311.15010" title="Download PDF">pdf</a>, <a href="/format/2311.15010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapter is All You Need for Tuning Visual Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Dongshuo Yin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L+H+B">Leiyi Hu. Bin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Youqun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Pre-training &amp; fine-tuning can enhance the transferring efficiency and
performance in visual tasks. Recent delta-tuning methods provide more options
for visual classification tasks. Despite their success, existing visual
delta-tuning art fails to exceed the upper limit of full fine-tuning on
challenging tasks like instance segmentation and semantic segmentation. To find
a competitive alternative to full fine-tuning, we propose the Multi-cognitive
Visual Adapter (Mona) tuning, a novel adapter-based tuning method. First, we
introduce multiple vision-friendly filters into the adapter to enhance its
ability to process visual signals, while previous methods mainly rely on
language-friendly linear filters. Second, we add the scaled normalization layer
in the adapter to regulate the distribution of input features for visual
filters. To fully demonstrate the practicality and generality of Mona, we
conduct experiments on multiple representative visual tasks, including instance
segmentation on COCO, semantic segmentation on ADE20K, object detection on
Pascal VOC, and image classification on several common datasets. Exciting
results illustrate that Mona surpasses full fine-tuning on all these tasks and
is the only delta-tuning method outperforming full fine-tuning on instance
segmentation and semantic segmentation tasks. For example, Mona achieves a 1%
performance gain on the COCO dataset compared to full fine-tuning.
Comprehensive results suggest that Mona-tuning is more suitable for retaining
and utilizing the capabilities of pre-trained models than full fine-tuning. The
code will be released at https://github.com/Leiyi-Hu/mona.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15011" title="Abstract">arXiv:2311.15011</a> [<a href="/pdf/2311.15011" title="Download PDF">pdf</a>, <a href="/format/2311.15011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VSCode: General Visual Salient and Camouflaged Object Detection with 2D  Prompt Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Ziyang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Nian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wangbo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xuguang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dingwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+D">Deng-Ping Fan</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+F">Fahad Khan</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Junwei Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Salient object detection (SOD) and camouflaged object detection (COD) are
related yet distinct binary mapping tasks. These tasks involve multiple
modalities, sharing commonalities and unique cues. Existing research often
employs intricate task-specific specialist models, potentially leading to
redundancy and suboptimal results. We introduce VSCode, a generalist model with
novel 2D prompt learning, to jointly address four SOD tasks and three COD
tasks. We utilize VST as the foundation model and introduce 2D prompts within
the encoder-decoder architecture to learn domain and task-specific knowledge on
two separate dimensions. A prompt discrimination loss helps disentangle
peculiarities to benefit model optimization. VSCode outperforms
state-of-the-art methods across six tasks on 26 datasets and exhibits zero-shot
generalization to unseen tasks by combining 2D prompts, such as RGB-D COD.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15016" title="Abstract">arXiv:2311.15016</a> [<a href="/pdf/2311.15016" title="Download PDF">pdf</a>, <a href="/format/2311.15016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E-CORE: Emotion Correlation Enhanced Empathetic Dialogue Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+F">Fengyi Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Quan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Z">Zhendong Mao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Conference on Empirical Methods in Natural Language Processing,
  EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Achieving empathy is a crucial step toward humanized dialogue systems.
Current approaches for empathetic dialogue generation mainly perceive an
emotional label to generate an empathetic response conditioned on it, which
simply treat emotions independently, but ignore the intrinsic emotion
correlation in dialogues, resulting in inaccurate emotion perception and
unsuitable response generation. In this paper, we propose a novel emotion
correlation enhanced empathetic dialogue generation framework, which
comprehensively realizes emotion correlation learning, utilization, and
supervising. Specifically, a multi-resolution emotion graph is devised to
capture context-based emotion interactions from different resolutions, further
modeling emotion correlation. Then we propose an emotion correlation enhanced
decoder, with a novel correlation-aware aggregation and soft/hard strategy,
respectively improving the emotion perception and response generation.
Experimental results on the benchmark dataset demonstrate the superiority of
our model in both empathetic perception and expression.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15017" title="Abstract">arXiv:2311.15017</a> [<a href="/pdf/2311.15017" title="Download PDF">pdf</a>, <a href="/format/2311.15017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Capacity and Delay of Unmanned Aerial Vehicle Networks with Mobility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhiqing Wei</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhiyong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Haibo Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Li Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Huici Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 10 figures, IEEE Internet of Things Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Unmanned aerial vehicles (UAVs) are widely exploited in environment
monitoring, search-and-rescue, etc. However, the mobility and short flight
duration of UAVs bring challenges for UAV networking. In this paper, we study
the UAV networks with n UAVs acting as aerial sensors. UAVs generally have
short flight duration and need to frequently get energy replenishment from the
control station. Hence the returning UAVs bring the data of the UAVs along the
returning paths to the control station with a store-carry-and-forward (SCF)
mode. A critical range for the distance between the UAV and the control station
is discovered. Within the critical range, the per-node capacity of the SCF mode
is O(n/log n) times higher than that of the multi-hop mode. However, the
per-node capacity of the SCF mode outside the critical range decreases with the
distance between the UAV and the control station. To eliminate the critical
range, a mobility control scheme is proposed such that the capacity scaling
laws of the SCF mode are the same for all UAVs, which improves the capacity
performance of UAV networks. Moreover, the delay of the SCF mode is derived.
The impact of the size of the entire region, the velocity of UAVs, the number
of UAVs and the flight duration of UAVs on the delay of SCF mode is analyzed.
This paper reveals that the mobility and short flight duration of UAVs have
beneficial effects on the performance of UAV networks, which may motivate the
study of SCF schemes for UAV networks.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15020" title="Abstract">arXiv:2311.15020</a> [<a href="/pdf/2311.15020" title="Download PDF">pdf</a>, <a href="/ps/2311.15020" title="Download PostScript">ps</a>, <a href="/format/2311.15020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Careful Synchronization of One-Cluster Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruszil%2C+J">Jakub Ruszil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 1 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">In this paper we investigate careful synchronization of one-cluster partial
automata. First we prove that in general case the shortest carefully
synchronizing word for such automata is of length $2^\frac{n}{2} + 1$, where
$n$ is the number of states of an automaton. Additionally we prove that
checking whether a given one-cluster partial automaton is carefully
synchronizing is NP-hard even in the case of binary alphabet.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15022" title="Abstract">arXiv:2311.15022</a> [<a href="/pdf/2311.15022" title="Download PDF">pdf</a>, <a href="/format/2311.15022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Occlusion Sensitivity Analysis with Augmentation Subspace Perturbation  in Deep Feature Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valois%2C+P">Pedro Valois</a>, 
<a href="/search/cs?searchtype=author&query=Niinuma%2C+K">Koichiro Niinuma</a>, 
<a href="/search/cs?searchtype=author&query=Fukui%2C+K">Kazuhiro Fukui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep Learning of neural networks has gained prominence in multiple
life-critical applications like medical diagnoses and autonomous vehicle
accident investigations. However, concerns about model transparency and biases
persist. Explainable methods are viewed as the solution to address these
challenges. In this study, we introduce the Occlusion Sensitivity Analysis with
Deep Feature Augmentation Subspace (OSA-DAS), a novel perturbation-based
interpretability approach for computer vision. While traditional perturbation
methods make only use of occlusions to explain the model predictions, OSA-DAS
extends standard occlusion sensitivity analysis by enabling the integration
with diverse image augmentations. Distinctly, our method utilizes the output
vector of a DNN to build low-dimensional subspaces within the deep feature
vector space, offering a more precise explanation of the model prediction. The
structural similarity between these subspaces encompasses the influence of
diverse augmentations and occlusions. We test extensively on the ImageNet-1k,
and our class- and model-agnostic approach outperforms commonly used
interpreters, setting it apart in the realm of explainable AI.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15023" title="Abstract">arXiv:2311.15023</a> [<a href="/pdf/2311.15023" title="Download PDF">pdf</a>, <a href="/format/2311.15023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Offensive Language Identification in Transliterated and Code-Mixed  Bangla
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raihan%2C+M+N">Md Nishat Raihan</a>, 
<a href="/search/cs?searchtype=author&query=Tanmoy%2C+U+H">Umma Hani Tanmoy</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+A+B">Anika Binte Islam</a>, 
<a href="/search/cs?searchtype=author&query=North%2C+K">Kai North</a>, 
<a href="/search/cs?searchtype=author&query=Ranasinghe%2C+T">Tharindu Ranasinghe</a>, 
<a href="/search/cs?searchtype=author&query=Anastasopoulos%2C+A">Antonios Anastasopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Zampieri%2C+M">Marcos Zampieri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Identifying offensive content in social media is vital for creating safe
online communities. Several recent studies have addressed this problem by
creating datasets for various languages. In this paper, we explore offensive
language identification in texts with transliterations and code-mixing,
linguistic phenomena common in multilingual societies, and a known challenge
for NLP systems. We introduce TB-OLID, a transliterated Bangla offensive
language dataset containing 5,000 manually annotated comments. We train and
fine-tune machine learning models on TB-OLID, and we evaluate their results on
this dataset. Our results show that English pre-trained transformer-based
models, such as fBERT and HateBERT achieve the best performance on this
dataset.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15024" title="Abstract">arXiv:2311.15024</a> [<a href="/pdf/2311.15024" title="Download PDF">pdf</a>, <a href="/ps/2311.15024" title="Download PostScript">ps</a>, <a href="/format/2311.15024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comperative Study of Watering Hole Attack Detection Using Supervised  Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aktar%2C+M+N">Mst. Nishita Aktar</a>, 
<a href="/search/cs?searchtype=author&query=Akter%2C+S">Sornali Akter</a>, 
<a href="/search/cs?searchtype=author&query=Saad%2C+M+N+I">Md. Nusaim Islam Saad</a>, 
<a href="/search/cs?searchtype=author&query=Jisun%2C+J+H">Jakir Hosen Jisun</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+K+M">Kh. Mustafizur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Sakib%2C+M+N">Md. Nazmus Sakib</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The security landscape necessitates creative solutions to defend against
targeted attacks due to the growing sophistication of cyber threats. This study
explores the nefarious tactic known as "watering hole attacks using supervised
neural networks to detect and prevent these attacks. The neural network
identifies patterns in website behavior and network traffic associated with
such attacks. Testing on a dataset of confirmed attacks shows a 99% detection
rate with a mere 0.1% false positive rate, demonstrating the model's
effectiveness. In terms of prevention, the model successfully stops 95% of
attacks, providing robust user protection. The study also suggests mitigation
strategies, including web filtering solutions, user education, and security
controls. Overall, this research presents a promising solution for countering
watering hole attacks, offering strong detection, prevention, and mitigation
strategies.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15027" title="Abstract">arXiv:2311.15027</a> [<a href="/pdf/2311.15027" title="Download PDF">pdf</a>, <a href="/format/2311.15027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Double-Flow-based Steganography without Embedding for Image-to-Image  Hiding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+B">Bingbing Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Derui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Renyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wei Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">As an emerging concept, steganography without embedding (SWE) hides a secret
message without directly embedding it into a cover. Thus, SWE has the unique
advantage of being immune to typical steganalysis methods and can better
protect the secret message from being exposed. However, existing SWE methods
are generally criticized for their poor payload capacity and low fidelity of
recovered secret messages. In this paper, we propose a novel
steganography-without-embedding technique, named DF-SWE, which addresses the
aforementioned drawbacks and produces diverse and natural stego images.
Specifically, DF-SWE employs a reversible circulation of double flow to build a
reversible bijective transformation between the secret image and the generated
stego image. Hence, it provides a way to directly generate stego images from
secret images without a cover image. Besides leveraging the invertible
property, DF-SWE can invert a secret image from a generated stego image in a
nearly lossless manner and increases the fidelity of extracted secret images.
To the best of our knowledge, DF-SWE is the first SWE method that can hide
large images and multiple images into one image with the same size,
significantly enhancing the payload capacity. According to the experimental
results, the payload capacity of DF-SWE achieves 24-72 BPP is 8000-16000 times
compared to its competitors while producing diverse images to minimize the
exposure risk. Importantly, DF-SWE can be applied in the steganography of
secret images in various domains without requiring training data from the
corresponding domains. This domain-agnostic property suggests that DF-SWE can
1) be applied to hiding private data and 2) be deployed in resource-limited
systems.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15029" title="Abstract">arXiv:2311.15029</a> [<a href="/pdf/2311.15029" title="Download PDF">pdf</a>, <a href="/format/2311.15029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> nlpBDpatriots at BLP-2023 Task 1: A Two-Step Classification for Violence  Inciting Text Detection in Bangla
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raihan%2C+M+N">Md Nishat Raihan</a>, 
<a href="/search/cs?searchtype=author&query=Goswami%2C+D">Dhiman Goswami</a>, 
<a href="/search/cs?searchtype=author&query=Puspo%2C+S+S+C">Sadiya Sayara Chowdhury Puspo</a>, 
<a href="/search/cs?searchtype=author&query=Zampieri%2C+M">Marcos Zampieri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this paper, we discuss the nlpBDpatriots entry to the shared task on
Violence Inciting Text Detection (VITD) organized as part of the first workshop
on Bangla Language Processing (BLP) co-located with EMNLP. The aim of this task
is to identify and classify the violent threats, that provoke further unlawful
violent acts. Our best-performing approach for the task is two-step
classification using back translation and multilinguality which ranked 6th out
of 27 teams with a macro F1 score of 0.74.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15030" title="Abstract">arXiv:2311.15030</a> [<a href="/pdf/2311.15030" title="Download PDF">pdf</a>, <a href="/format/2311.15030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Task-adaptive Quasi-stiffness Control for A Powered  Transfemoral Prosthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Teng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+S">Shucong Yin</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Z">Zhimin Hou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Binxin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chuheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haoyong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Chenglong Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">While significant advancements have been made in the mechanical and
task-specific controller designs of powered transfemoral prostheses, developing
a task-adaptive control framework that generalizes across various locomotion
modes and terrain conditions remains an open problem. This study proposes a
task-adaptive learning quasi-stiffness control framework for powered prostheses
that generalizes across tasks, including the torque-angle relationship
reconstruction part and the quasi-stiffness controller design part.
Quasi-stiffness is defined as the slope of the human joint's torque-angle
relationship. To accurately obtain the torque-angle relationship in a new task,
a Gaussian Process Regression (GPR) model is introduced to predict the target
features of the human joint's angle and torque in the task. Then a Kernelized
Movement Primitives (KMP) is employed to reconstruct the torque-angle
relationship of a new task from multiple human demonstrations and estimated
target features. Based on the torque-angle relationship of the new task, a
quasi-stiffness control approach is designed for a powered prosthesis. Finally,
the proposed framework is validated through practical examples, including
varying speed and incline walking tasks. The proposed framework has the
potential to expand to variable walking tasks in daily life for the
transfemoral amputees.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15032" title="Abstract">arXiv:2311.15032</a> [<a href="/pdf/2311.15032" title="Download PDF">pdf</a>, <a href="/format/2311.15032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> nlpBDpatriots at BLP-2023 Task 2: A Transfer Learning Approach to Bangla  Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goswami%2C+D">Dhiman Goswami</a>, 
<a href="/search/cs?searchtype=author&query=Raihan%2C+M+N">Md Nishat Raihan</a>, 
<a href="/search/cs?searchtype=author&query=Puspo%2C+S+S+C">Sadiya Sayara Chowdhury Puspo</a>, 
<a href="/search/cs?searchtype=author&query=Zampieri%2C+M">Marcos Zampieri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this paper, we discuss the nlpBDpatriots entry to the shared task on
Sentiment Analysis of Bangla Social Media Posts organized at the first workshop
on Bangla Language Processing (BLP) co-located with EMNLP. The main objective
of this task is to identify the polarity of social media content using a Bangla
dataset annotated with positive, neutral, and negative labels provided by the
shared task organizers. Our best system for this task is a transfer learning
approach with data augmentation which achieved a micro F1 score of 0.71. Our
best system ranked 12th among 30 teams that participated in the competition.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15033" title="Abstract">arXiv:2311.15033</a> [<a href="/pdf/2311.15033" title="Download PDF">pdf</a>, <a href="/format/2311.15033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agent as Cerebrum, Controller as Cerebellum: Implementing an Embodied  LMM-based Agent on Drones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haoran Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+F">Fengxing Pan</a>, 
<a href="/search/cs?searchtype=author&query=Ping%2C+H">Huqiuyue Ping</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yaoming Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this study, we present a novel paradigm for industrial robotic embodied
agents, encapsulating an 'agent as cerebrum, controller as cerebellum'
architecture. Our approach harnesses the power of Large Multimodal Models
(LMMs) within an agent framework known as AeroAgent, tailored for drone
technology in industrial settings. To facilitate seamless integration with
robotic systems, we introduce ROSchain, a bespoke linkage framework connecting
LMM-based agents to the Robot Operating System (ROS). We report findings from
extensive empirical research, including simulated experiments on the Airgen and
real-world case study, particularly in individual search and rescue operations.
The results demonstrate AeroAgent's superior performance in comparison to
existing Deep Reinforcement Learning (DRL)-based agents, highlighting the
advantages of the embodied LMM in complex, real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15036" title="Abstract">arXiv:2311.15036</a> [<a href="/pdf/2311.15036" title="Download PDF">pdf</a>, <a href="/format/2311.15036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On-Device Soft Sensors: Real-Time Fluid Flow Estimation from Level  Sensor Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ling%2C+T">Tianheng Ling</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chao Qian</a>, 
<a href="/search/cs?searchtype=author&query=Schiele%2C+G">Gregor Schiele</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, 1 Table, Accepted by the 1st AUTONOMOUS UBIQUITOUS SYSTEMS (AUTOQUITOUS) WORKSHOP of EAI MobiQuitous 2023 - 20th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Soft sensors are crucial in bridging autonomous systems' physical and digital
realms, enhancing sensor fusion and perception. Instead of deploying soft
sensors on the Cloud, this study shift towards employing on-device soft
sensors, promising heightened efficiency and bolstering data security. Our
approach substantially improves energy efficiency by deploying Artificial
Intelligence (AI) directly on devices within a wireless sensor network.
Furthermore, the synergistic integration of the Microcontroller Unit and
Field-Programmable Gate Array (FPGA) leverages the rapid AI inference
capabilities of the latter. Empirical evidence from our real-world use case
demonstrates that FPGA-based soft sensors achieve inference times ranging
remarkably from 1.04 to 12.04 microseconds. These compelling results highlight
the considerable potential of our innovative approach for executing real-time
inference tasks efficiently, thereby presenting a feasible alternative that
effectively addresses the latency challenges intrinsic to Cloud-based
deployments.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15038" title="Abstract">arXiv:2311.15038</a> [<a href="/pdf/2311.15038" title="Download PDF">pdf</a>, <a href="/format/2311.15038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-latency Visual Previews of Large Synchrotron Micro-CT Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jerome%2C+N+T">Nicholas Tan Jerome</a>, 
<a href="/search/cs?searchtype=author&query=Chilingaryan%2C+S">Suren Chilingaryan</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Kamp%2C+T">Thomas van de Kamp</a>, 
<a href="/search/cs?searchtype=author&query=Kopmann%2C+A">Andreas Kopmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The unprecedented rate at which synchrotron radiation facilities are
producing micro-computed (micro-CT) datasets has resulted in an overwhelming
amount of data that scientists struggle to browse and interact with in
real-time. Thousands of arthropods are scanned into micro-CT within the NOVA
project, producing a large collection of gigabyte-sized datasets. In this work,
we present methods to reduce the size of this data, scaling it from gigabytes
to megabytes, enabling the micro-CT dataset to be delivered in real-time. In
addition, arthropods can be identified by scientists even after implementing
data reduction methodologies. Our initial step is to devise three distinct
visual previews that comply with the best practices of data exploration.
Subsequently, each visual preview warrants its own design consideration,
thereby necessitating an individual data processing pipeline for each. We aim
to present data reduction algorithms applied across the data processing
pipelines. Particularly, we reduce size by using the multi-resolution
slicemaps, the server-side rendering, and the histogram filtering approaches.
In the evaluation, we examine the disparities of each method to identify the
most favorable arrangement for our operation, which can then be adjusted for
other experiments that have comparable necessities. Our demonstration proved
that reducing the dataset size to the megabyte range is achievable without
compromising the arthropod's geometry information.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15040" title="Abstract">arXiv:2311.15040</a> [<a href="/pdf/2311.15040" title="Download PDF">pdf</a>, <a href="/format/2311.15040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InstaStyle: Inversion Noise of a Stylized Image is Secretly a Style  Adviser
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+X">Xing Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zekun Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P+P">Pei Pei Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huaibo Huang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhaofeng He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages,20 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Stylized text-to-image generation focuses on creating images from textual
descriptions while adhering to a style specified by a few reference images.
However, subtle style variations within different reference images can hinder
the model from accurately learning the target style. In this paper, we propose
InstaStyle, a novel approach that excels in generating high-fidelity stylized
images with only a single reference image. Our approach is based on the finding
that the inversion noise from a stylized reference image inherently carries the
style signal, as evidenced by their non-zero signal-to-noise ratio. We employ
DDIM inversion to extract this noise from the reference image and leverage a
diffusion model to generate new stylized images from the ``style" noise.
Additionally, the inherent ambiguity and bias of textual prompts impede the
precise conveying of style. To address this, we introduce a learnable style
token via prompt refinement, which enhances the accuracy of the style
description for the reference image. Qualitative and quantitative experimental
results demonstrate that InstaStyle achieves superior performance compared to
current benchmarks. Furthermore, our approach also showcases its capability in
the creative task of style combination with mixed inversion noise.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15041" title="Abstract">arXiv:2311.15041</a> [<a href="/pdf/2311.15041" title="Download PDF">pdf</a>, <a href="/format/2311.15041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MPCNN: A Novel Matrix Profile Approach for CNN-based Sleep Apnea  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H+X">Hieu X. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+V">Duong V. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+H+H">Hieu H. Pham</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+C+D">Cuong D. Do</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Sleep apnea (SA) is a significant respiratory condition that poses a major
global health challenge. Previous studies have investigated several machine and
deep learning models for electrocardiogram (ECG)-based SA diagnoses. Despite
these advancements, conventional feature extractions derived from ECG signals,
such as R-peaks and RR intervals, may fail to capture crucial information
encompassed within the complete PQRST segments. In this study, we propose an
innovative approach to address this diagnostic gap by delving deeper into the
comprehensive segments of the ECG signal. The proposed methodology draws
inspiration from Matrix Profile algorithms, which generate an Euclidean
distance profile from fixed-length signal subsequences. From this, we derived
the Min Distance Profile (MinDP), Max Distance Profile (MaxDP), and Mean
Distance Profile (MeanDP) based on the minimum, maximum, and mean of the
profile distances, respectively. To validate the effectiveness of our approach,
we use the modified LeNet-5 architecture as the primary CNN model, along with
two existing lightweight models, BAFNet and SE-MSCNN, for ECG classification
tasks. Our extensive experimental results on the PhysioNet Apnea-ECG dataset
revealed that with the new feature extraction method, we achieved a per-segment
accuracy up to 92.11 \% and a per-recording accuracy of 100\%. Moreover, it
yielded the highest correlation compared to state-of-the-art methods, with a
correlation coefficient of 0.989. By introducing a new feature extraction
method based on distance relationships, we enhanced the performance of certain
lightweight models, showing potential for home sleep apnea test (HSAT) and SA
detection in IoT devices. The source code for this work is made publicly
available in GitHub: https://github.com/vinuni-vishc/MPCNN-Sleep-Apnea.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15043" title="Abstract">arXiv:2311.15043</a> [<a href="/pdf/2311.15043" title="Download PDF">pdf</a>, <a href="/format/2311.15043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Plane Multigraphs with One-Bend and Circular-Arc Edges of a Fixed Angle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=T%C3%B3th%2C+C+D">Csaba D. T&#xf3;th</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures, to be presented at WALCOM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">For an angle $\alpha\in (0,\pi)$, we consider plane graphs and multigraphs in
which the edges are either (i) one-bend polylines with an angle $\alpha$
between the two edge segments, or (ii) circular arcs of central angle
$2(\pi-\alpha)$. We derive upper and lower bounds on the maximum density of
such graphs in terms of $\alpha$. As an application, we improve upon bounds for
the number of edges in $\alpha AC_1^=$ graphs (i.e., graphs that can be drawn
in the plane with one-bend edges such that any two crossing edges meet at angle
$\alpha$). This is the first improvement on the size of $\alpha AC_1^=$ graphs
in over a decade.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15047" title="Abstract">arXiv:2311.15047</a> [<a href="/pdf/2311.15047" title="Download PDF">pdf</a>, <a href="/format/2311.15047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training a Hopfield Variational Autoencoder with Equilibrium Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van+Der+Meersch%2C+T">Tom Van Der Meersch</a>, 
<a href="/search/cs?searchtype=author&query=Deleu%2C+J">Johannes Deleu</a>, 
<a href="/search/cs?searchtype=author&query=Demeester%2C+T">Thomas Demeester</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Associative Memory &amp; Hopfield Networks in 2023 (NeurIPS 2023 workshop)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">On dedicated analog hardware, equilibrium propagation is an energy-efficient
alternative to backpropagation. In spite of its theoretical guarantees, its
application in the AI domain remains limited to the discriminative setting.
Meanwhile, despite its high computational demands, generative AI is on the
rise. In this paper, we demonstrate the application of Equilibrium Propagation
in training a variational autoencoder (VAE) for generative modeling. Leveraging
the symmetric nature of Hopfield networks, we propose using a single model to
serve as both the encoder and decoder which could effectively halve the
required chip size for VAE implementations, paving the way for more efficient
analog hardware configurations.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15051" title="Abstract">arXiv:2311.15051</a> [<a href="/pdf/2311.15051" title="Download PDF">pdf</a>, <a href="/format/2311.15051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Catapults in Momentum Gradient Descent with Warmup: An Empirical  Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phunyaphibarn%2C+P">Prin Phunyaphibarn</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Junghyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bohan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huishuai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+C">Chulhee Yun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 14 figures. Accepted to the NeurIPS 2023 M3L Workshop (oral). The first two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Although gradient descent with momentum is widely used in modern deep
learning, a concrete understanding of its effects on the training trajectory
still remains elusive. In this work, we empirically show that momentum gradient
descent with a large learning rate and learning rate warmup displays large
catapults, driving the iterates towards flatter minima than those found by
gradient descent. We then provide empirical evidence and theoretical intuition
that the large catapult is caused by momentum "amplifying" the
self-stabilization effect (Damian et al., 2023).
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15053" title="Abstract">arXiv:2311.15053</a> [<a href="/pdf/2311.15053" title="Download PDF">pdf</a>, <a href="/format/2311.15053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task adaption by biologically inspired stochastic comodulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boeshertz%2C+G">Gauthier Boeshertz</a>, 
<a href="/search/cs?searchtype=author&query=Haimerl%2C+C">Caroline Haimerl</a>, 
<a href="/search/cs?searchtype=author&query=Savin%2C+C">Cristina Savin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Brain representations must strike a balance between generalizability and
adaptability. Neural codes capture general statistical regularities in the
world, while dynamically adjusting to reflect current goals. One aspect of this
adaptation is stochastically co-modulating neurons' gains based on their task
relevance. These fluctuations then propagate downstream to guide
decision-making. Here, we test the computational viability of such a scheme in
the context of multi-task learning. We show that fine-tuning convolutional
networks by stochastic gain modulation improves on deterministic gain
modulation, achieving state-of-the-art results on the CelebA dataset. To better
understand the mechanisms supporting this improvement, we explore how
fine-tuning performance is affected by architecture using Cifar-100. Overall,
our results suggest that stochastic comodulation can enhance learning
efficiency and performance in multi-task learning, without additional learnable
parameters. This offers a promising new direction for developing more flexible
and robust intelligent systems.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15054" title="Abstract">arXiv:2311.15054</a> [<a href="/pdf/2311.15054" title="Download PDF">pdf</a>, <a href="/ps/2311.15054" title="Download PostScript">ps</a>, <a href="/format/2311.15054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detection of developmental language disorder in Cypriot Greek children  using a machine learning neural network algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Georgiou%2C+G+P">Georgios P. Georgiou</a>, 
<a href="/search/cs?searchtype=author&query=Theodorou%2C+E">Elena Theodorou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 figures, journal article
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Children with developmental language disorder (DLD) encounter difficulties in
acquiring various language structures. Early identification and intervention
are crucial to prevent negative long-term outcomes impacting the academic,
social, and emotional development of children. The study aims to develop an
automated method for the identification of DLD using artificial intelligence,
specifically a neural network machine learning algorithm. This protocol is
applied for the first time in Cypriot Greek children, which is generally
considered underresearched in the context of DLD. The neural network model was
trained using perceptual and production data elicited from children with DLD
and healthy controls. The k-fold technique was used to crossvalidate the
algorithm. The performance of the model was evaluated using metrics such as
accuracy, precision, recall, F1 score, and ROC/AUC curve to assess its ability
to make accurate predictions on a set of unseen data. The results demonstrated
high classification values for all metrics (between 0.92 and 0.98), indicating
the high accuracy of the neural model in classifying children with DLD.
Additionally, the variable importance analysis revealed that the language
production skills of children had a more significant impact on the performance
of the model compared to perception skills. Neural networks represent powerful
tools for detecting DLD, providing early and quick assessments of the disorder,
and having the potential to improve clinical outcomes.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15055" title="Abstract">arXiv:2311.15055</a> [<a href="/pdf/2311.15055" title="Download PDF">pdf</a>, <a href="/format/2311.15055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatically Finding and Categorizing Replication Studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Ruiter%2C+B">Bob de Ruiter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">In many fields of experimental science, papers that failed to replicate
continue to be cited as a result of the poor discoverability of replication
studies. As a first step to creating a system that automatically finds
replication studies for a given paper, 334 replication studies and 344
replicated studies were collected. Replication studies could be identified in
the dataset based on text content at a higher rate than chance (AUROC = 0.886).
<br />Additionally, successful replication studies could be distinguished from
failed replication studies at a higher rate than chance (AUROC = 0.664).
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15056" title="Abstract">arXiv:2311.15056</a> [<a href="/pdf/2311.15056" title="Download PDF">pdf</a>, <a href="/format/2311.15056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accurate and interpretable drug-drug interaction prediction enabled by  knowledge subgraph learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zaifei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Q">Quanming Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Background: Discovering potential drug-drug interactions (DDIs) is a
long-standing challenge in clinical treatments and drug developments. Recently,
deep learning techniques have been developed for DDI prediction. However, they
generally require a huge number of samples, while known DDIs are rare.
<br />Methods: In this work, we present KnowDDI, a graph neural network-based
method that addresses the above challenge. KnowDDI enhances drug
representations by adaptively leveraging rich neighborhood information from
large biomedical knowledge graphs. Then, it learns a knowledge subgraph for
each drug-pair to interpret the predicted DDI, where each of the edges is
associated with a connection strength indicating the importance of a known DDI
or resembling strength between a drug-pair whose connection is unknown. Thus,
the lack of DDIs is implicitly compensated by the enriched drug representations
and propagated drug similarities.
<br />Results: We evaluate KnowDDI on two benchmark DDI datasets. Results show that
KnowDDI obtains the state-of-the-art prediction performance with better
interpretability. We also find that KnowDDI suffers less than existing works
given a sparser knowledge graph. This indicates that the propagated drug
similarities play a more important role in compensating for the lack of DDIs
when the drug representations are less enriched.
<br />Conclusions: KnowDDI nicely combines the efficiency of deep learning
techniques and the rich prior knowledge in biomedical knowledge graphs. As an
original open-source tool, KnowDDI can help detect possible interactions in a
broad range of relevant interaction prediction tasks, such as protein-protein
interactions, drug-target interactions and disease-gene interactions,
eventually promoting the development of biomedicine and healthcare.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15057" title="Abstract">arXiv:2311.15057</a> [<a href="/pdf/2311.15057" title="Download PDF">pdf</a>, <a href="/format/2311.15057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Layered Area-Proportional Rectangle Contact Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haase%2C+C">Carolina Haase</a>, 
<a href="/search/cs?searchtype=author&query=Kindermann%2C+P">Philipp Kindermann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the Proceedings of the 18th International Conference and Workshops on Algorithms and Computation (WALCOM 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">A pair $\langle G_0, G_1 \rangle$ of graphs admits a mutual witness proximity
drawing $\langle \Gamma_0, \Gamma_1 \rangle$ when: (i) $\Gamma_i$ represents
$G_i$, and (ii) there is an edge $(u,v)$ in $\Gamma_i$ if and only if there is
no vertex $w$ in $\Gamma_{1-i}$ that is ``too close'' to both $u$ and $v$
($i=0,1$). In this paper, we consider infinitely many definitions of closeness
by adopting the $\beta$-proximity rule for any $\beta \in [1,\infty]$ and study
pairs of isomorphic trees that admit a mutual witness $\beta$-proximity
drawing. Specifically, we show that every two isomorphic trees admit a mutual
witness $\beta$-proximity drawing for any $\beta \in [1,\infty]$. The
constructive technique can be made ``robust'': For some tree pairs we can
suitably prune linearly many leaves from one of the two trees and still retain
their mutual witness $\beta$-proximity drawability. Notably, in the special
case of isomorphic caterpillars and $\beta=1$, we construct linearly separable
mutual witness Gabriel drawings.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15064" title="Abstract">arXiv:2311.15064</a> [<a href="/pdf/2311.15064" title="Download PDF">pdf</a>, <a href="/format/2311.15064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recursive lattice reduction -- A framework for finding short lattice  vectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+D">Divesh Aggarwal</a>, 
<a href="/search/cs?searchtype=author&query=Espitau%2C+T">Thomas Espitau</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+S">Spencer Peters</a>, 
<a href="/search/cs?searchtype=author&query=Stephens-Davidowitz%2C+N">Noah Stephens-Davidowitz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We propose a new framework called recursive lattice reduction for finding
short non-zero vectors in a lattice or for finding dense sublattices of a
lattice. At a high level, the framework works by recursively searching for
dense sublattices of dense sublattices (or their duals). Eventually, the
procedure encounters a recursive call on a lattice $\mathcal{L}$ with
relatively low rank $k$, at which point we simply use a known algorithm to find
a short non-zero vector in $\mathcal{L}$. We view our framework as
complementary to basis reduction algorithms, which similarly work to reduce an
$n$-dimensional lattice problem with some approximation factor $\gamma$ to an
exact lattice problem in dimension $k &lt; n$, with a tradeoff between $\gamma$,
$n$, and $k$. Our framework provides an alternative and arguably simpler
perspective, which in particular can be described without explicitly
referencing any specific basis of the lattice, Gram-Schmidt vectors, or even
projection (though implementations of algorithms in this framework will likely
make use of such things). We present a number of specific instantiations of our
framework. Our main concrete result is a reduction that matches the tradeoff
between $\gamma$, $n$, and $k$ achieved by the best-known basis reduction
algorithms (in terms of the Hermite factor, up to low-order terms) across all
parameter regimes. In fact, this reduction also can be used to find dense
sublattices with any rank $\ell$ satisfying $\min\{\ell,n-\ell\} \leq n-k+1$,
using only an oracle for SVP (or even just Hermite SVP) in $k$ dimensions,
which is itself a novel result (as far as the authors know). We also show a
very simple reduction that achieves the same tradeoff in quasipolynomial time.
Finally, we present an automated approach for searching for algorithms in this
framework that (provably) achieve better approximations with fewer oracle
calls.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15066" title="Abstract">arXiv:2311.15066</a> [<a href="/pdf/2311.15066" title="Download PDF">pdf</a>, <a href="/format/2311.15066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beam Training and Tracking for Extremely Large-Scale MIMO Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kangjian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+C">Chenhao Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cheng-Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G+Y">Geoffrey Ye Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, beam training and beam tracking are investigated for extremely
large-scale multiple-input-multiple-output communication systems with
partially-connected hybrid combining structures. Firstly, we propose a
two-stage hybrid-field beam training scheme for both the near field and the far
field. In the first stage, each subarray independently uses multiple far-field
channel steering vectors to approximate near-field ones for analog combining.
To find the codeword best fitting for the channel, digital combiners in the
second stage are designed to combine the outputs of the analog combiners from
the first stage. Then, based on the principle of stationary phase and the
time-frequency duality, the expressions of subarray signals after analog
combining are analytically derived and a beam refinement based on phase shifts
of subarrays~(BRPSS) scheme with closed-form solutions is proposed for
high-resolution channel parameter estimation. Moreover, a low-complexity
near-field beam tracking scheme is developed, where the kinematic model is
adopted to characterize the channel variations and the extended Kalman filter
is exploited for beam tracking. Simulation results verify the effectiveness of
the proposed schemes.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15069" title="Abstract">arXiv:2311.15069</a> [<a href="/pdf/2311.15069" title="Download PDF">pdf</a>, <a href="/ps/2311.15069" title="Download PostScript">ps</a>, <a href="/format/2311.15069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiuser Beamforming for Partially-Connected Millimeter Wave Massive  MIMO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+C">Chenhao Qi</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jinlin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yang Du</a>, 
<a href="/search/cs?searchtype=author&query=Nallanathan%2C+A">Arumugam Nallanathan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Multiuser beamforming is considered for partially-connected millimeter wave
massive MIMO systems. Based on perfect channel state information (CSI), a
low-complexity hybrid beamforming scheme that decouples the analog beamformer
and the digital beamformer is proposed to maximize the sum-rate. The analog
beamformer design is modeled as a phase alignment problem to harvest the array
gain. Given the analog beamformer, the digital beamformer is designed by
solving a weighted minimum mean squared error problem. Then based on imperfect
CSI, an analog-only beamformer design scheme is proposed, where the design
problem aims at maximizing the desired signal power on the current user and
minimizing the power on the other users to mitigate the multiuser interference.
The original problem is then transformed into a series of independent beam
nulling subproblems, where an efficient iterative algorithm using the
majorization-minimization framework is proposed to solve the subproblems.
Simulation results show that, under perfect CSI, the proposed scheme achieves
almost the same sum-rate performance as the existing schemes but with lower
computational complexity; and under imperfect CSI, the proposed analog-only
beamforming design scheme can effectively mitigate the multiuser interference.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15072" title="Abstract">arXiv:2311.15072</a> [<a href="/pdf/2311.15072" title="Download PDF">pdf</a>, <a href="/format/2311.15072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Introducing SSBD+ Dataset with a Convolutional Pipeline for detecting  Self-Stimulatory Behaviours in Children using raw videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lokegaonkar%2C+V">Vaibhavi Lokegaonkar</a>, 
<a href="/search/cs?searchtype=author&query=Jaisankar%2C+V">Vijay Jaisankar</a>, 
<a href="/search/cs?searchtype=author&query=Deepika%2C+P">Pon Deepika</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+M">Madhav Rao</a>, 
<a href="/search/cs?searchtype=author&query=Srikanth%2C+T+K">T K Srikanth</a>, 
<a href="/search/cs?searchtype=author&query=Mallick%2C+S">Sarbani Mallick</a>, 
<a href="/search/cs?searchtype=author&query=Sodhi%2C+M">Manjit Sodhi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Copyright 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Conventionally, evaluation for the diagnosis of Autism spectrum disorder is
done by a trained specialist through questionnaire-based formal assessments and
by observation of behavioral cues under various settings to capture the early
warning signs of autism. These evaluation techniques are highly subjective and
their accuracy relies on the experience of the specialist. In this regard,
machine learning-based methods for automated capturing of early signs of autism
from the recorded videos of the children is a promising alternative. In this
paper, the authors propose a novel pipelined deep learning architecture to
detect certain self-stimulatory behaviors that help in the diagnosis of autism
spectrum disorder (ASD). The authors also supplement their tool with an
augmented version of the Self Stimulatory Behavior Dataset (SSBD) and also
propose a new label in SSBD Action detection: no-class. The deep learning model
with the new dataset is made freely available for easy adoption to the
researchers and developers community. An overall accuracy of around 81% was
achieved from the proposed pipeline model that is targeted for real-time and
hands-free automated diagnosis. All of the source code, data, licenses of use,
and other relevant material is made freely available in
https://github.com/sarl-iiitb/
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15073" title="Abstract">arXiv:2311.15073</a> [<a href="/pdf/2311.15073" title="Download PDF">pdf</a>, <a href="/format/2311.15073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A discontinuous Galerkin method based isogeometric analysis framework  for flexoelectricity in micro-architected dielectric solids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+S">Saurav Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Anitescu%2C+C">Cosmin Anitescu</a>, 
<a href="/search/cs?searchtype=author&query=Rabczuk%2C+T">Timon Rabczuk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Flexoelectricity - the generation of electric field in response to a strain
gradient - is a universal electromechanical coupling, dominant only at small
scales due to its requirement of high strain gradients. This phenomenon is
governed by a set of coupled fourth-order partial differential equations
(PDEs), which require $C^1$ continuity of the basis in finite element methods
for the numerical solution. While Isogeometric analysis (IGA) has been proven
to meet this continuity requirement due to its higher-order B-spline basis
functions, it is limited to simple geometries that can be discretized with a
single IGA patch. For the domains, e.g., architected materials, requiring more
than one patch for discretization IGA faces the challenge of $C^0$ continuity
across the patch boundaries. Here we present a discontinuous Galerkin
method-based isogeometric analysis framework, capable of solving fourth-order
PDEs of flexoelectricity in the domain of truss-based architected materials. An
interior penalty-based stabilization is implemented to ensure the stability of
the solution. The present formulation is advantageous over the analogous finite
element methods since it only requires the computation of interior boundary
contributions on the boundaries of patches. As each strut can be modeled with
only two trapezoid patches, the number of $C^0$ continuous boundaries is
largely reduced. Further, we consider four unique unit cells to construct the
truss lattices and analyze their flexoelectric response. The truss lattices
show a higher magnitude of flexoelectricity compared to the solid beam, as well
as retain this superior electromechanical response with the increasing size of
the structure. These results indicate the potential of architected materials to
scale up the flexoelectricity to larger scales, towards achieving universal
electromechanical response in meso/macro scale dielectric materials.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15075" title="Abstract">arXiv:2311.15075</a> [<a href="/pdf/2311.15075" title="Download PDF">pdf</a>, <a href="/format/2311.15075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mug-STAN: Adapting Image-Language Pretrained Models for General Video  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jingjia Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Wei Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T+H">Thomas H. Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Ge Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large-scale image-language pretrained models, e.g., CLIP, have demonstrated
remarkable proficiency in acquiring general multi-modal knowledge through
web-scale image-text data. Despite the impressive performance of image-language
models on various image tasks, how to effectively expand them on general video
understanding remains an area of ongoing exploration. In this paper, we
investigate the image-to-video transferring from the perspective of the model
and the data, unveiling two key obstacles impeding the adaptation of
image-language models: non-generalizable temporal modeling and partially
misaligned video-text data. To address these challenges, we propose
Spatial-Temporal Auxiliary Network with Mutual-guided alignment module
(Mug-STAN), a simple yet effective framework extending image-text model to
diverse video tasks and video-text data.Specifically, STAN adopts a branch
structure with decomposed spatial-temporal modules to enable generalizable
temporal modeling, while Mug suppresses misalignment by introducing token-wise
feature aggregation of either modality from the other. Extensive experimental
results verify Mug-STAN significantly improves adaptation of language-image
pretrained models such as CLIP and CoCa at both video-text post-pretraining and
finetuning stages. With our solution, state-of-the-art zero-shot and finetuning
results on various downstream datasets, including MSR-VTT, DiDeMo, LSMDC,
Kinetics-400, Something-Something-2, HMDB-51, UCF- 101, and AVA, are achieved.
Moreover, by integrating pretrained Mug-STAN with the emerging multimodal
dialogue model, we can realize zero-shot video chatting. Codes are available at
https://github.com/farewellthree/STAN
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15077" title="Abstract">arXiv:2311.15077</a> [<a href="/pdf/2311.15077" title="Download PDF">pdf</a>, <a href="/format/2311.15077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilingual self-supervised speech representations improve the speech  recognition of low-resource African languages with codeswitching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%92g%C3%BAnr%C3%A8m%C3%AD%2C+T">Tol&#xfa;lop&#xe9; &#xd2;g&#xfa;nr&#xe8;m&#xed;</a>, 
<a href="/search/cs?searchtype=author&query=Manning%2C+C+D">Christopher D. Manning</a>, 
<a href="/search/cs?searchtype=author&query=Jurafsky%2C+D">Dan Jurafsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure. Computational Approaches to Linguistic Code-Switching, CALCS 2023 (co-located with EMNLP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">While many speakers of low-resource languages regularly code-switch between
their languages and other regional languages or English, datasets of
codeswitched speech are too small to train bespoke acoustic models from scratch
or do language model rescoring. Here we propose finetuning self-supervised
speech representations such as wav2vec 2.0 XLSR to recognize code-switched
data. We find that finetuning self-supervised multilingual representations and
augmenting them with n-gram language models trained from transcripts reduces
absolute word error rates by up to 20% compared to baselines of hybrid models
trained from scratch on code-switched data. Our findings suggest that in
circumstances with limited training data finetuning self-supervised
representations is a better performing and viable solution.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15080" title="Abstract">arXiv:2311.15080</a> [<a href="/pdf/2311.15080" title="Download PDF">pdf</a>, <a href="/format/2311.15080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly-Supervised Audio-Visual Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mo%2C+S">Shentong Mo</a>, 
<a href="/search/cs?searchtype=author&query=Raj%2C+B">Bhiksha Raj</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Audio-visual segmentation is a challenging task that aims to predict
pixel-level masks for sound sources in a video. Previous work applied a
comprehensive manually designed architecture with countless pixel-wise accurate
masks as supervision. However, these pixel-level masks are expensive and not
available in all cases. In this work, we aim to simplify the supervision as the
instance-level annotation, i.e., weakly-supervised audio-visual segmentation.
We present a novel Weakly-Supervised Audio-Visual Segmentation framework,
namely WS-AVS, that can learn multi-scale audio-visual alignment with
multi-scale multiple-instance contrastive learning for audio-visual
segmentation. Extensive experiments on AVSBench demonstrate the effectiveness
of our WS-AVS in the weakly-supervised audio-visual segmentation of
single-source and multi-source scenarios.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15087" title="Abstract">arXiv:2311.15087</a> [<a href="/pdf/2311.15087" title="Download PDF">pdf</a>, <a href="/format/2311.15087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> X-Ray to CT Rigid Registration Using Scene Coordinate Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shrestha%2C+P">Pragyan Shrestha</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Chun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Shishido%2C+H">Hidehiko Shishido</a>, 
<a href="/search/cs?searchtype=author&query=Yoshii%2C+Y">Yuichi Yoshii</a>, 
<a href="/search/cs?searchtype=author&query=Kitahara%2C+I">Itary Kitahara</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Medical Image Computing and Computer Assisted Intervention MICCAI
  2023. Lecture Notes in Computer Science, vol 14229
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Intraoperative fluoroscopy is a frequently used modality in minimally
invasive orthopedic surgeries. Aligning the intraoperatively acquired X-ray
image with the preoperatively acquired 3D model of a computed tomography (CT)
scan reduces the mental burden on surgeons induced by the overlapping
anatomical structures in the acquired images. This paper proposes a fully
automatic registration method that is robust to extreme viewpoints and does not
require manual annotation of landmark points during training. It is based on a
fully convolutional neural network (CNN) that regresses the scene coordinates
for a given X-ray image. The scene coordinates are defined as the intersection
of the back-projected rays from a pixel toward the 3D model. Training data for
a patient-specific model were generated through a realistic simulation of a
C-arm device using preoperative CT scans. In contrast, intraoperative
registration was achieved by solving the perspective-n-point (PnP) problem with
a random sample and consensus (RANSAC) algorithm. Experiments were conducted
using a pelvic CT dataset that included several real fluoroscopic (X-ray)
images with ground truth annotations. The proposed method achieved an average
mean target registration error (mTRE) of 3.79 mm in the 50th percentile of the
simulated test dataset and projected mTRE of 9.65 mm in the 50th percentile of
real fluoroscopic images for pelvis registration.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15089" title="Abstract">arXiv:2311.15089</a> [<a href="/pdf/2311.15089" title="Download PDF">pdf</a>, <a href="/format/2311.15089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Where2Start: Leveraging initial States for Robust and Sample-Efficient  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parsa%2C+P">Pouya Parsa</a>, 
<a href="/search/cs?searchtype=author&query=Moayedi%2C+R+Z">Raoof Zare Moayedi</a>, 
<a href="/search/cs?searchtype=author&query=Bornosi%2C+M">Mohammad Bornosi</a>, 
<a href="/search/cs?searchtype=author&query=Bejani%2C+M+M">Mohammad Mahdi Bejani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The reinforcement learning algorithms that focus on how to compute the
gradient and choose next actions, are effectively improved the performance of
the agents. However, these algorithms are environment-agnostic. This means that
the algorithms did not use the knowledge that has been captured by trajectory.
This poses that the algorithms should sample many trajectories to train the
model. By considering the essence of environment and how much the agent learn
from each scenario in that environment, the strategy of the learning procedure
can be changed. The strategy retrieves more informative trajectories, so the
agent can learn with fewer trajectory sample. We propose Where2Start algorithm
that selects the initial state so that the agent has more instability in
vicinity of that state. We show that this kind of selection decreases number of
trajectories that should be sampled that the agent reach to acceptable reward.
Our experiments shows that Where2Start can improve sample efficiency up to 8
times. Also Where2Start can combined with most of state-of-the-art algorithms
and improve that robustness and sample efficiency significantly.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15095" title="Abstract">arXiv:2311.15095</a> [<a href="/pdf/2311.15095" title="Download PDF">pdf</a>, <a href="/format/2311.15095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active disturbance rejection control for unmanned tracked vehicles in  leader-follower scenarios: discrete-time implementation and field test  validation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Amokrane%2C+S">Salem-Bilal Amokrane</a>, 
<a href="/search/eess?searchtype=author&query=Laidouni%2C+M+Z">Mohammed Zouaoui Laidouni</a>, 
<a href="/search/eess?searchtype=author&query=Adli%2C+T">Touati Adli</a>, 
<a href="/search/eess?searchtype=author&query=Madonski%2C+R">Rafal Madonski</a>, 
<a href="/search/eess?searchtype=author&query=Stankovi%C4%87%2C+M">Momir Stankovi&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents a systematic design of an active disturbance rejection
control (ADRC) system for unmanned tracked vehicles (UTVs) in leader-follow
formation. Two ADRC controllers are designed for the lateral and the
longitudinal channels of the UTV based on control errors in the cross-track and
the along-track directions. Through simulations, the proposed ADRC approach is
first shown to outperform the conventional PI/PID controllers in scenarios
involving sudden changes in the leader motion dynamics, slippage disturbances,
and measurement noise. Then, a comprehensive experimental validation of the
proposed leader-follower control is performed using a laboratory UTV equipped
with a camera and laser sensors (to enable the calculation of error signals).
In order to provide more effective interaction between the human (leader) and
the UTV (follower) during the leader-follower task, a camera-based subsystem
for human pose recognition is developed and deployed. Finally, the experimental
results obtained outdoors demonstrate that the proposed ADRC-based
leader-follower UTV control system achieves high tracking capabilities,
robustness against slippage disturbances, and adaptability to changing
environmental conditions.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15097" title="Abstract">arXiv:2311.15097</a> [<a href="/pdf/2311.15097" title="Download PDF">pdf</a>, <a href="/ps/2311.15097" title="Download PostScript">ps</a>, <a href="/format/2311.15097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AugmentTRAJ: A framework for point-based trajectory data augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haranwala%2C+Y+J">Yaksh J Haranwala</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Data augmentation has emerged as a powerful technique in machine learning,
strengthening model robustness while mitigating overfitting and under-fitting
issues by generating diverse synthetic data. Nevertheless, despite its success
in other domains, data augmentation's potential remains largely untapped in
mobility data analysis, primarily due to the intricate nature and unique format
of trajectory data. Additionally, there is a lack of frameworks capable of
point-wise data augmentation, which can reliably generate synthetic
trajectories while preserving the inherent characteristics of the original
data. To address these challenges, this research introduces AugmenTRAJ, an
open-source Python3 framework designed explicitly for trajectory data
augmentation. AugmenTRAJ offers a reliable and well-controlled approach for
generating synthetic trajectories, thereby enabling the harnessing of data
augmentation benefits in mobility analysis. This thesis presents a
comprehensive overview of the methodologies employed in developing AugmenTRAJ
and showcases the various data augmentation techniques available within the
framework. AugmenTRAJ opens new possibilities for enhancing mobility data
analysis models' performance and generalization capabilities by providing
researchers with a practical and versatile tool for augmenting trajectory data,
Its user-friendly implementation in Python3 facilitates easy integration into
existing workflows, offering the community an accessible resource to leverage
the full potential of data augmentation in trajectory-based applications.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15098" title="Abstract">arXiv:2311.15098</a> [<a href="/pdf/2311.15098" title="Download PDF">pdf</a>, <a href="/ps/2311.15098" title="Download PostScript">ps</a>, <a href="/format/2311.15098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speech-Based Blood Pressure Estimation with Enhanced Optimization and  Incremental Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajput%2C+V">Vaishali Rajput</a>, 
<a href="/search/cs?searchtype=author&query=Mulay%2C+P">Preeti Mulay</a>, 
<a href="/search/cs?searchtype=author&query=Raje%2C+R">Rajeev Raje</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 2 tables, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Blood Pressure (BP) estimation plays a pivotal role in diagnosing various
health conditions, highlighting the need for innovative approaches to overcome
conventional measurement challenges. Leveraging machine learning and speech
signals, this study investigates accurate BP estimation with a focus on
preprocessing, feature extraction, and real-time applications. An advanced
clustering-based strategy, incorporating the k-means algorithm and the proposed
Fact-Finding Instructor optimization algorithm, is introduced to enhance
accuracy. The combined outcome of these clustering techniques enables robust BP
estimation. Moreover, extending beyond these insights, this study delves into
the dynamic realm of contemporary digital content consumption. Platforms like
YouTube have emerged as influential spaces, presenting an array of videos that
evoke diverse emotions. From heartwarming and amusing content to intense
narratives, YouTube captures a spectrum of human experiences, influencing
information access and emotional engagement. Within this context, this research
investigates the interplay between YouTube videos and physiological responses,
particularly Blood Pressure (BP) levels. By integrating advanced BP estimation
techniques with the emotional dimensions of YouTube videos, this study enriches
our understanding of how modern media environments intersect with health
implications.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15099" title="Abstract">arXiv:2311.15099</a> [<a href="/pdf/2311.15099" title="Download PDF">pdf</a>, <a href="/format/2311.15099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WirePlanner: Fast, Secure and Cost-Efficient Route Configuration for  SD-WAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yunxi Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yongxiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Junxian Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Han Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">As enterprises increasingly migrate their applications to the cloud, the
demand for secure and cost-effective Wide Area Networking (WAN) solutions for
data transmission between branches and data centers grows. Among these
solutions, Software-Defined Wide Area Networking (SD-WAN) has emerged as a
promising approach. However, existing SD-WAN implementations largely rely on
IPSec tunnels for data encryption between edge routers, resulting in drawbacks
such as extended setup times and limited throughput. Additionally, the SD-WAN
control plane rarely takes both latency and monetary cost into consideration
when determining routes between nodes, resulting in unsatisfactory Quality of
Service (QoS). We propose WirePlanner, an SD-WAN solution that employs a novel
algorithm for path discovery, optimizing both latency and cost, and configures
WireGuard tunnels for secure and efficient data transmission. WirePlanner
considers two payment methods: Pay-As-You-Go, where users pay for a fixed
amount of bandwidth over a certain duration, and Pay-For-Data-Transfer, where
users pay for the volume of transmitted data. Given an underlay topology of
edge routers and a user-defined budget constraint, WirePlanner identifies a
path between nodes that minimizes latency and remains within the budget, while
utilizing WireGuard for secure data transmission.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15100" title="Abstract">arXiv:2311.15100</a> [<a href="/pdf/2311.15100" title="Download PDF">pdf</a>, <a href="/format/2311.15100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unbalancedness in Neural Monge Maps Improves Unpaired Domain Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eyring%2C+L">Luca Eyring</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+D">Dominik Klein</a>, 
<a href="/search/cs?searchtype=author&query=Uscidda%2C+T">Th&#xe9;o Uscidda</a>, 
<a href="/search/cs?searchtype=author&query=Palla%2C+G">Giovanni Palla</a>, 
<a href="/search/cs?searchtype=author&query=Kilbertus%2C+N">Niki Kilbertus</a>, 
<a href="/search/cs?searchtype=author&query=Akata%2C+Z">Zeynep Akata</a>, 
<a href="/search/cs?searchtype=author&query=Theis%2C+F">Fabian Theis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In optimal transport (OT), a Monge map is known as a mapping that transports
a source distribution to a target distribution in the most cost-efficient way.
Recently, multiple neural estimators for Monge maps have been developed and
applied in diverse unpaired domain translation tasks, e.g. in single-cell
biology and computer vision. However, the classic OT framework enforces mass
conservation, which makes it prone to outliers and limits its applicability in
real-world scenarios. The latter can be particularly harmful in OT domain
translation tasks, where the relative position of a sample within a
distribution is explicitly taken into account. While unbalanced OT tackles this
challenge in the discrete setting, its integration into neural Monge map
estimators has received limited attention. We propose a theoretically grounded
method to incorporate unbalancedness into any Monge map estimator. We improve
existing estimators to model cell trajectories over time and to predict
cellular responses to perturbations. Moreover, our approach seamlessly
integrates with the OT flow matching (OT-FM) framework. While we show that
OT-FM performs competitively in image translation, we further improve
performance by incorporating unbalancedness (UOT-FM), which better preserves
relevant features. We hence establish UOT-FM as a principled method for
unpaired image translation.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15106" title="Abstract">arXiv:2311.15106</a> [<a href="/pdf/2311.15106" title="Download PDF">pdf</a>, <a href="/format/2311.15106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving the Right Problem is Key for Translational NLP: A Case Study in  UMLS Vocabulary Insertion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gutierrez%2C+B+J">Bernal Jimenez Gutierrez</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yuqing Mao</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V">Vinh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Fung%2C+K+W">Kin Wah Fung</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yu Su</a>, 
<a href="/search/cs?searchtype=author&query=Bodenreider%2C+O">Olivier Bodenreider</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Findings; Code is available at <a href="https://github.com/OSU-NLP-Group/UMLS-Vocabulary-Insertion">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">As the immense opportunities enabled by large language models become more
apparent, NLP systems will be increasingly expected to excel in real-world
settings. However, in many instances, powerful models alone will not yield
translational NLP solutions, especially if the formulated problem is not well
aligned with the real-world task. In this work, we study the case of UMLS
vocabulary insertion, an important real-world task in which hundreds of
thousands of new terms, referred to as atoms, are added to the UMLS, one of the
most comprehensive open-source biomedical knowledge bases. Previous work aimed
to develop an automated NLP system to make this time-consuming, costly, and
error-prone task more efficient. Nevertheless, practical progress in this
direction has been difficult to achieve due to a problem formulation and
evaluation gap between research output and the real-world task. In order to
address this gap, we introduce a new formulation for UMLS vocabulary insertion
which mirrors the real-world task, datasets which faithfully represent it and
several strong baselines we developed through re-purposing existing solutions.
Additionally, we propose an effective rule-enhanced biomedical language model
which enables important new model behavior, outperforms all strong baselines
and provides measurable qualitative improvements to editors who carry out the
UVI task. We hope this case study provides insight into the considerable
importance of problem formulation for the success of translational NLP
solutions.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15108" title="Abstract">arXiv:2311.15108</a> [<a href="/pdf/2311.15108" title="Download PDF">pdf</a>, <a href="/format/2311.15108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Diffusion Perturbations for Measuring Fairness in Computer  Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lui%2C+N">Nicholas Lui</a>, 
<a href="/search/cs?searchtype=author&query=Chia%2C+B">Bryan Chia</a>, 
<a href="/search/cs?searchtype=author&query=Berrios%2C+W">William Berrios</a>, 
<a href="/search/cs?searchtype=author&query=Ross%2C+C">Candace Ross</a>, 
<a href="/search/cs?searchtype=author&query=Kiela%2C+D">Douwe Kiela</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The Appendix can be found at <a href="https://bit.ly/dp-appendix">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Computer vision models have been known to encode harmful biases, leading to
the potentially unfair treatment of historically marginalized groups, such as
people of color. However, there remains a lack of datasets balanced along
demographic traits that can be used to evaluate the downstream fairness of
these models. In this work, we demonstrate that diffusion models can be
leveraged to create such a dataset. We first use a diffusion model to generate
a large set of images depicting various occupations. Subsequently, each image
is edited using inpainting to generate multiple variants, where each variant
refers to a different perceived race. Using this dataset, we benchmark several
vision-language models on a multi-class occupation classification task. We find
that images generated with non-Caucasian labels have a significantly higher
occupation misclassification rate than images generated with Caucasian labels,
and that several misclassifications are suggestive of racial biases. We measure
a model's downstream fairness by computing the standard deviation in the
probability of predicting the true occupation label across the different
perceived identity groups. Using this fairness metric, we find significant
disparities between the evaluated vision-and-language models. We hope that our
work demonstrates the potential value of diffusion methods for fairness
evaluations.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15110" title="Abstract">arXiv:2311.15110</a> [<a href="/pdf/2311.15110" title="Download PDF">pdf</a>, <a href="/format/2311.15110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relevance feedback strategies for recall-oriented neural information  retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kats%2C+T">Timo Kats</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Putten%2C+P">Peter van der Putten</a>, 
<a href="/search/cs?searchtype=author&query=Scholtes%2C+J">Jan Scholtes</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Preproceedings Benelux Conference for Artificial Intelligence
  (BNAIC/BENELEARN 2023), Delft, November 8-10, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In a number of information retrieval applications (e.g., patent search,
literature review, due diligence, etc.), preventing false negatives is more
important than preventing false positives. However, approaches designed to
reduce review effort (like "technology assisted review") can create false
negatives, since they are often based on active learning systems that exclude
documents automatically based on user feedback. Therefore, this research
proposes a more recall-oriented approach to reducing review effort. More
specifically, through iteratively re-ranking the relevance rankings based on
user feedback, which is also referred to as relevance feedback. In our proposed
method, the relevance rankings are produced by a BERT-based dense-vector search
and the relevance feedback is based on cumulatively summing the queried and
selected embeddings. Our results show that this method can reduce review effort
between 17.85% and 59.04%, compared to a baseline approach (of no feedback),
given a fixed recall target
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15111" title="Abstract">arXiv:2311.15111</a> [<a href="/pdf/2311.15111" title="Download PDF">pdf</a>, <a href="/format/2311.15111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAMv2: A Unified Framework for Learning Appearance, Semantic and  Cross-Modality Anatomical Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiaoyu Bai</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+F">Fan Bai</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+X">Xiaofei Huo</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+J">Jia Ge</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jingjing Lu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xianghua Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+K">Ke Yan</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yong Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Identifying anatomical structures (e.g., lesions or landmarks) in medical
images plays a fundamental role in medical image analysis. As an exemplar-based
landmark detection method, Self-supervised Anatomical eMbedding (SAM) learns a
discriminative embedding for each voxel in the image and has shown promising
results on various tasks. However, SAM still faces challenges in: (1)
differentiating voxels with similar appearance but different semantic meanings
(\textit{e.g.}, two adjacent structures without clear borders); (2) matching
voxels with similar semantics but markedly different appearance (e.g., the same
vessel before and after contrast injection); and (3) cross-modality matching
(e.g., CT-MRI registration). To overcome these challenges, we propose SAMv2,
which is a unified framework designed to learn appearance, semantic, and
cross-modality anatomical embeddings. Specifically, SAMv2 incorporates three
key innovations: (1) semantic embedding learning with prototypical contrastive
loss; (2) a fixed-point-based matching strategy; and (3) an iterative approach
for cross-modality embedding learning. We thoroughly evaluated SAMv2 across
three tasks, including one-shot landmark detection, lesion tracking on
longitudinal CT scans, and CT-MRI affine/rigid registration with varying field
of view. Our results suggest that SAMv2 outperforms SAM and other
state-of-the-art methods, offering a robust and versatile approach for landmark
based medical image analysis tasks. Code and trained models are available at:
https://github.com/alibaba-damo-academy/self-supervised-anatomical-embedding-v2
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15112" title="Abstract">arXiv:2311.15112</a> [<a href="/pdf/2311.15112" title="Download PDF">pdf</a>, <a href="/format/2311.15112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Everybody Needs a Little HELP: Explaining Graphs via Hierarchical  Concepts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=J%C3%BCr%C3%9F%2C+J">Jonas J&#xfc;r&#xdf;</a>, 
<a href="/search/cs?searchtype=author&query=Magister%2C+L+C">Lucie Charlotte Magister</a>, 
<a href="/search/cs?searchtype=author&query=Barbiero%2C+P">Pietro Barbiero</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>, 
<a href="/search/cs?searchtype=author&query=Simidjievski%2C+N">Nikola Simidjievski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 16 figures, accepted at the NeurIPS 2023 GLFrontiers Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Graph neural networks (GNNs) have led to major breakthroughs in a variety of
domains such as drug discovery, social network analysis, and travel time
estimation. However, they lack interpretability which hinders human trust and
thereby deployment to settings with high-stakes decisions. A line of
interpretable methods approach this by discovering a small set of relevant
concepts as subgraphs in the last GNN layer that together explain the
prediction. This can yield oversimplified explanations, failing to explain the
interaction between GNN layers. To address this oversight, we provide HELP
(Hierarchical Explainable Latent Pooling), a novel, inherently interpretable
graph pooling approach that reveals how concepts from different GNN layers
compose to new ones in later steps. HELP is more than 1-WL expressive and is
the first non-spectral, end-to-end-learnable, hierarchical graph pooling method
that can learn to pool a variable number of arbitrary connected components. We
empirically demonstrate that it performs on-par with standard GCNs and popular
pooling methods in terms of accuracy while yielding explanations that are
aligned with expert knowledge in the domains of chemistry and social networks.
In addition to a qualitative analysis, we employ concept completeness scores as
well as concept conformity, a novel metric to measure the noise in discovered
concepts, quantitatively verifying that the discovered concepts are
significantly easier to fully understand than those from previous work. Our
work represents a first step towards an understanding of graph neural networks
that goes beyond a set of concepts from the final layer and instead explains
the complex interplay of concepts on different levels.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15113" title="Abstract">arXiv:2311.15113</a> [<a href="/pdf/2311.15113" title="Download PDF">pdf</a>, <a href="/format/2311.15113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NCL-SM: A Fully Annotated Dataset of Images from Human Skeletal Muscle  Biopsies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Atif Khan</a>, 
<a href="/search/cs?searchtype=author&query=Lawless%2C+C">Conor Lawless</a>, 
<a href="/search/cs?searchtype=author&query=Vincent%2C+A">Amy Vincent</a>, 
<a href="/search/cs?searchtype=author&query=Warren%2C+C">Charlotte Warren</a>, 
<a href="/search/cs?searchtype=author&query=Di+Leo%2C+V">Valeria Di Leo</a>, 
<a href="/search/cs?searchtype=author&query=Gomes%2C+T">Tiago Gomes</a>, 
<a href="/search/cs?searchtype=author&query=McGough%2C+A+S">A. Stephen McGough</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted at the Big Data Analytics for Health and Medicine (BDA4HM) workshop, IEEE BigData 2023, December 15th-18th, 2023, Sorrento, Italy, 07 pages. arXiv admin note: substantial text overlap with <a href="/abs/2311.11099">arXiv:2311.11099</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Tissues and Organs (q-bio.TO)

</div>
<p class="mathjax">Single cell analysis of human skeletal muscle (SM) tissue cross-sections is a
fundamental tool for understanding many neuromuscular disorders. For this
analysis to be reliable and reproducible, identification of individual fibres
within microscopy images (segmentation) of SM tissue should be automatic and
precise. Biomedical scientists in this field currently rely on custom tools and
general machine learning (ML) models, both followed by labour intensive and
subjective manual interventions to fine-tune segmentation. We believe that
fully automated, precise, reproducible segmentation is possible by training ML
models. However, in this important biomedical domain, there are currently no
good quality, publicly available annotated imaging datasets available for ML
model training. In this paper we release NCL-SM: a high quality bioimaging
dataset of 46 human SM tissue cross-sections from both healthy control subjects
and from patients with genetically diagnosed muscle pathology. These images
include $&gt;$ 50k manually segmented muscle fibres (myofibres). In addition we
also curated high quality myofibre segmentations, annotating reasons for
rejecting low quality myofibres and low quality regions in SM tissue images,
making these annotations completely ready for downstream analysis. This, we
believe, will pave the way for development of a fully automatic pipeline that
identifies individual myofibres within images of tissue sections and, in
particular, also classifies individual myofibres that are fit for further
analysis.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15117" title="Abstract">arXiv:2311.15117</a> [<a href="/pdf/2311.15117" title="Download PDF">pdf</a>, <a href="/format/2311.15117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resilience-driven Planning of Electric Power Systems Against Extreme  Weather Events
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Poudyal%2C+A">Abodh Poudyal</a>, 
<a href="/search/eess?searchtype=author&query=Lamichhane%2C+S">Shishir Lamichhane</a>, 
<a href="/search/eess?searchtype=author&query=Dubey%2C+A">Anamika Dubey</a>, 
<a href="/search/eess?searchtype=author&query=Prado%2C+J+C+d">Josue Campos do Prado</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">With the increasing frequency of natural disasters, operators must prioritize
improvements in the existing electric power grid infrastructure to enhance the
resilience of the grid. Resilience to extreme weather events necessitates
lowering the impacts of high-impact, low-probability (HILP) events, which is
only possible when such events are considered during the planning stage. This
paper proposes a two-stage stochastic planning model where the generation
dispatch, line hardening, line capacity expansion, and distributed generation
sizing and siting decisions are proactively decided to minimize the overall
load shed and its risk for extreme weather scenarios, where the risk is modeled
using conditional value-at-risk. To alleviate computational complexity without
sacrificing solution quality, a representative scenario sampling method is
used. Finally, the overall framework is tested on a standard IEEE reliability
test system to evaluate the effectiveness of the proposed approach. Several
planning portfolios are presented that can help system planners identify
trade-offs between system resilience, planning budget, and risk aversion.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15118" title="Abstract">arXiv:2311.15118</a> [<a href="/pdf/2311.15118" title="Download PDF">pdf</a>, <a href="/format/2311.15118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hurricane and Storm Surges-Induced Power System Vulnerabilities and  their Socioeconomic Impact
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Poudyal%2C+A">Abodh Poudyal</a>, 
<a href="/search/eess?searchtype=author&query=Lamichhane%2C+S">Shishir Lamichhane</a>, 
<a href="/search/eess?searchtype=author&query=Wertz%2C+C">Charlotte Wertz</a>, 
<a href="/search/eess?searchtype=author&query=Mahmud%2C+S+U">Sajjad Uddin Mahmud</a>, 
<a href="/search/eess?searchtype=author&query=Dubey%2C+A">Anamika Dubey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 6 figures, submitted to 2024 IEEE Power and Energy Society General Meeting for review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">This paper introduces a probabilistic framework to quantify community
vulnerability towards power losses due to extreme weather events. To analyze
the impact of weather events on the power grid, the wind fields of historical
hurricanes from 2000 to 2018 on the Texas coast are modeled using their
available parameters, and probabilistic storm surge scenarios are constructed
utilizing the hurricane characteristics. The vulnerability of hurricanes and
storm surges is evaluated on a 2000 bus synthetic power grid model on the
geographical footprint of Texas. The load losses, obtained via branch and
substation outages, are then geographically represented at the county level and
integrated with the publicly available Social Vulnerability Index to evaluate
the Integrated Community Vulnerability Index (ICVI), which reflects the impacts
of these extreme weather events on the socioeconomic and community power
systems. The analysis concludes that the compounded impact of power outages due
to extreme weather events can amplify the vulnerability of affected
communities. Such analysis can help the system planners and operators make an
informed decision.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15125" title="Abstract">arXiv:2311.15125</a> [<a href="/pdf/2311.15125" title="Download PDF">pdf</a>, <a href="/format/2311.15125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Assignment Incentives to Reduce Student Procrastination and  Encourage Code Review Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kevin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lawrence%2C+R">Ramon Lawrence</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, To be published in 2023 International Conference on Computational Science and Computational Intelligence Research Track on Education (CSCI-RTED) IEEE CPS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Procrastination causes student stress, reduced learning and performance, and
results in very busy help sessions immediately before deadlines. A key
challenge is encouraging students to complete assignments earlier rather than
waiting until right before the deadline, so the focus becomes on the learning
objectives rather than just meeting deadlines. This work presents an incentive
system encouraging students to complete assignments many days before deadlines.
Completed assignments are code reviewed by staff for correctness and providing
feedback, which results in more student-instructor interactions and may help
reduce student use of generative AI. The incentives result in a change in
student behavior with 45% of assignments completed early and 30% up to 4 days
before the deadline. Students receive real-time feedback with no increase in
marking time.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15127" title="Abstract">arXiv:2311.15127</a> [<a href="/pdf/2311.15127" title="Download PDF">pdf</a>, <a href="/format/2311.15127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large  Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blattmann%2C+A">Andreas Blattmann</a>, 
<a href="/search/cs?searchtype=author&query=Dockhorn%2C+T">Tim Dockhorn</a>, 
<a href="/search/cs?searchtype=author&query=Kulal%2C+S">Sumith Kulal</a>, 
<a href="/search/cs?searchtype=author&query=Mendelevitch%2C+D">Daniel Mendelevitch</a>, 
<a href="/search/cs?searchtype=author&query=Kilian%2C+M">Maciej Kilian</a>, 
<a href="/search/cs?searchtype=author&query=Lorenz%2C+D">Dominik Lorenz</a>, 
<a href="/search/cs?searchtype=author&query=Levi%2C+Y">Yam Levi</a>, 
<a href="/search/cs?searchtype=author&query=English%2C+Z">Zion English</a>, 
<a href="/search/cs?searchtype=author&query=Voleti%2C+V">Vikram Voleti</a>, 
<a href="/search/cs?searchtype=author&query=Letts%2C+A">Adam Letts</a>, 
<a href="/search/cs?searchtype=author&query=Jampani%2C+V">Varun Jampani</a>, 
<a href="/search/cs?searchtype=author&query=Rombach%2C+R">Robin Rombach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present Stable Video Diffusion - a latent video diffusion model for
high-resolution, state-of-the-art text-to-video and image-to-video generation.
Recently, latent diffusion models trained for 2D image synthesis have been
turned into generative video models by inserting temporal layers and finetuning
them on small, high-quality video datasets. However, training methods in the
literature vary widely, and the field has yet to agree on a unified strategy
for curating video data. In this paper, we identify and evaluate three
different stages for successful training of video LDMs: text-to-image
pretraining, video pretraining, and high-quality video finetuning. Furthermore,
we demonstrate the necessity of a well-curated pretraining dataset for
generating high-quality videos and present a systematic curation process to
train a strong base model, including captioning and filtering strategies. We
then explore the impact of finetuning our base model on high-quality data and
train a text-to-video model that is competitive with closed-source video
generation. We also show that our base model provides a powerful motion
representation for downstream tasks such as image-to-video generation and
adaptability to camera motion-specific LoRA modules. Finally, we demonstrate
that our model provides a strong multi-view 3D-prior and can serve as a base to
finetune a multi-view diffusion model that jointly generates multiple views of
objects in a feedforward fashion, outperforming image-based methods at a
fraction of their compute budget. We release code and model weights at
https://github.com/Stability-AI/generative-models .
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15131" title="Abstract">arXiv:2311.15131</a> [<a href="/pdf/2311.15131" title="Download PDF">pdf</a>, <a href="/format/2311.15131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Localizing Lying in Llama: Understanding Instructed Dishonesty on  True-False Questions Through Prompting, Probing, and Patching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Campbell%2C+J">James Campbell</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+R">Richard Ren</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+P">Phillip Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models (LLMs) demonstrate significant knowledge through their
outputs, though it is often unclear whether false outputs are due to a lack of
knowledge or dishonesty. In this paper, we investigate instructed dishonesty,
wherein we explicitly prompt LLaMA-2-70b-chat to lie. We perform prompt
engineering to find which prompts best induce lying behavior, and then use
mechanistic interpretability approaches to localize where in the network this
behavior occurs. Using linear probing and activation patching, we localize five
layers that appear especially important for lying. We then find just 46
attention heads within these layers that enable us to causally intervene such
that the lying model instead answers honestly. We show that these interventions
work robustly across many prompts and dataset splits. Overall, our work
contributes a greater understanding of dishonesty in LLMs so that we may hope
to prevent it.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15134" title="Abstract">arXiv:2311.15134</a> [<a href="/pdf/2311.15134" title="Download PDF">pdf</a>, <a href="/format/2311.15134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SwiftLearn: A Data-Efficient Training Method of Deep Learning Models  using Importance Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hajimolahoseini%2C+H">Habib Hajimolahoseini</a>, 
<a href="/search/cs?searchtype=author&query=Awad%2C+O+M">Omar Mohamed Awad</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+W">Walid Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+A">Austin Wen</a>, 
<a href="/search/cs?searchtype=author&query=Asani%2C+S">Saina Asani</a>, 
<a href="/search/cs?searchtype=author&query=Hassanpour%2C+M">Mohammad Hassanpour</a>, 
<a href="/search/cs?searchtype=author&query=Javadi%2C+F">Farnoosh Javadi</a>, 
<a href="/search/cs?searchtype=author&query=Ahmadi%2C+M">Mehdi Ahmadi</a>, 
<a href="/search/cs?searchtype=author&query=Ataiefard%2C+F">Foozhan Ataiefard</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kangling Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we present SwiftLearn, a data-efficient approach to accelerate
training of deep learning models using a subset of data samples selected during
the warm-up stages of training. This subset is selected based on an importance
criteria measured over the entire dataset during warm-up stages, aiming to
preserve the model performance with fewer examples during the rest of training.
The importance measure we propose could be updated during training every once
in a while, to make sure that all of the data samples have a chance to return
to the training loop if they show a higher importance. The model architecture
is unchanged but since the number of data samples controls the number of
forward and backward passes during training, we can reduce the training time by
reducing the number of training samples used in each epoch of training.
Experimental results on a variety of CV and NLP models during both pretraining
and finetuning show that the model performance could be preserved while
achieving a significant speed-up during training. More specifically, BERT
finetuning on GLUE benchmark shows that almost 90% of the data can be dropped
achieving an end-to-end average speedup of 3.36x while keeping the average
accuracy drop less than 0.92%.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15138" title="Abstract">arXiv:2311.15138</a> [<a href="/pdf/2311.15138" title="Download PDF">pdf</a>, <a href="/format/2311.15138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can SAM recognize crops? Quantifying the zero-shot performance of a  semantic segmentation foundation model on generating crop-type maps using  satellite imagery for precision agriculture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gurav%2C+R">Rutuja Gurav</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+H">Het Patel</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+Z">Zhuocheng Shang</a>, 
<a href="/search/cs?searchtype=author&query=Eldawy%2C+A">Ahmed Eldawy</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jia Chen</a>, 
<a href="/search/cs?searchtype=author&query=Scudiero%2C+E">Elia Scudiero</a>, 
<a href="/search/cs?searchtype=author&query=Papalexakis%2C+E">Evangelos Papalexakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Climate change is increasingly disrupting worldwide agriculture, making
global food production less reliable.To tackle the growing challenges in
feeding the planet, cutting-edge management strategies, such as precision
agriculture, empower farmers and decision-makers with rich and actionable
information to increase the efficiency and sustainability of their farming
practices.Crop-type maps are key information for decision-support tools but are
challenging and costly to generate.We investigate the capabilities of Meta AI's
Segment Anything Model (SAM) for crop-map prediction task, acknowledging its
recent successes at zero-shot image segmentation.However, SAM being limited to
up-to 3 channel inputs and its zero-shot usage being class-agnostic in nature
pose unique challenges in using it directly for crop-type mapping.We propose
using clustering consensus metrics to assess SAM's zero-shot performance in
segmenting satellite imagery and producing crop-type maps.Although direct
crop-type mapping is challenging using SAM in zero-shot setting, experiments
reveal SAM's potential for swiftly and accurately outlining fields in satellite
images, serving as a foundation for subsequent crop classification.This paper
attempts to highlight a use-case of state-of-the-art image segmentation models
like SAM for crop-type mapping and related specific needs of the agriculture
industry, offering a potential avenue for automatic, efficient, and
cost-effective data products for precision agriculture practices.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15142" title="Abstract">arXiv:2311.15142</a> [<a href="/pdf/2311.15142" title="Download PDF">pdf</a>, <a href="/ps/2311.15142" title="Download PostScript">ps</a>, <a href="/format/2311.15142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testable Learning with Distribution Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klivans%2C+A+R">Adam R. Klivans</a>, 
<a href="/search/cs?searchtype=author&query=Stavropoulos%2C+K">Konstantinos Stavropoulos</a>, 
<a href="/search/cs?searchtype=author&query=Vasilyan%2C+A">Arsen Vasilyan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We revisit the fundamental problem of learning with distribution shift, in
which a learner is given labeled samples from training distribution $D$,
unlabeled samples from test distribution $D'$ and is asked to output a
classifier with low test error. The standard approach in this setting is to
bound the loss of a classifier in terms of some notion of distance between $D$
and $D'$. These distances, however, seem difficult to compute and do not lead
to efficient algorithms.
<br />We depart from this paradigm and define a new model called testable learning
with distribution shift, where we can obtain provably efficient algorithms for
certifying the performance of a classifier on a test distribution. In this
model, a learner outputs a classifier with low test error whenever samples from
$D$ and $D'$ pass an associated test; moreover, the test must accept if the
marginal of $D$ equals the marginal of $D'$. We give several positive results
for learning well-studied concept classes such as halfspaces, intersections of
halfspaces, and decision trees when the marginal of $D$ is Gaussian or uniform
on $\{\pm 1\}^d$. Prior to our work, no efficient algorithms for these basic
cases were known without strong assumptions on $D'$.
<br />For halfspaces in the realizable case (where there exists a halfspace
consistent with both $D$ and $D'$), we combine a moment-matching approach with
ideas from active learning to simulate an efficient oracle for estimating
disagreement regions. To extend to the non-realizable setting, we apply recent
work from testable (agnostic) learning. More generally, we prove that any
function class with low-degree $L_2$-sandwiching polynomial approximators can
be learned in our model. We apply constructions from the pseudorandomness
literature to obtain the required approximators.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15143" title="Abstract">arXiv:2311.15143</a> [<a href="/pdf/2311.15143" title="Download PDF">pdf</a>, <a href="/format/2311.15143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reduced Augmentation Implicit Low-rank (RAIL) integrators for  advection-diffusion and Fokker-Planck models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Nakao%2C+J">Joseph Nakao</a>, 
<a href="/search/math?searchtype=author&query=Qiu%2C+J">Jing-Mei Qiu</a>, 
<a href="/search/math?searchtype=author&query=Einkemmer%2C+L">Lukas Einkemmer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper introduces a novel computational approach termed the Reduced
Augmentation Implicit Low-rank (RAIL) method by investigating two predominant
research directions in low-rank solutions to time-dependent partial
differential equations (PDEs): dynamical low-rank (DLR), and step and
truncation (SAT) tensor methods. The RAIL method, along with the development of
the SAT approach, is designed to enhance the efficiency of traditional
full-rank implicit solvers from method-of-lines discretizations of
time-dependent PDEs, while maintaining accuracy and stability. We consider
spectral methods for spatial discretization, and diagonally implicit
Runge-Kutta (DIRK) and implicit-explicit (IMEX) RK methods for time
discretization. The efficiency gain is achieved by investigating low-rank
structures within solutions at each RK stage using a singular value
decomposition (SVD). In particular, we develop a reduced augmentation procedure
to predict the basis functions to construct projection subspaces. This
procedure balances algorithm accuracy and efficiency by incorporating as many
bases as possible from previous RK stages and predictions, and by optimizing
the basis representation through SVD truncation. As such, one can form implicit
schemes for updating basis functions in a dimension-by-dimension manner,
similar in spirit to the K-L step in the DLR framework. We also apply a
globally mass conservative post-processing step at the end of each RK stage. We
validate the RAIL method through numerical simulations of advection-diffusion
problems and a Fokker-Planck model, showcasing its ability to efficiently
handle time-dependent PDEs while maintaining global mass conservation. Our
approach generalizes and bridges the DLR and SAT approaches, offering a
comprehensive framework for efficiently and accurately solving time-dependent
PDEs with implicit treatment.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15145" title="Abstract">arXiv:2311.15145</a> [<a href="/pdf/2311.15145" title="Download PDF">pdf</a>, <a href="/format/2311.15145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Choosing Wisely and Learning Deeply: Selective Cross-Modality  Distillation via CLIP for Domain Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leng%2C+J">Jixuan Leng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yijiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haohan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Domain Generalization (DG), a crucial research area, seeks to train models
across multiple domains and test them on unseen ones. In this paper, we
introduce a novel approach, namely, Selective Cross-Modality Distillation for
Domain Generalization (SCMD). SCMD leverages the capabilities of large
vision-language models, specifically the CLIP model, to train a more efficient
model, ensuring it acquires robust generalization capabilities across unseen
domains. Our primary contribution is a unique selection framework strategically
designed to identify hard-to-learn samples for distillation. In parallel, we
introduce a novel cross-modality module. This module seamlessly combines the
projected features of the student model with the text embeddings from CLIP,
ensuring the alignment of similarity distributions. We assess SCMD's
performance on various benchmarks, where it empowers a ResNet50 to deliver
state-of-the-art performance, surpassing existing domain generalization
methods. Furthermore, we provide a theoretical analysis of our selection
strategy, offering deeper insight into its effectiveness and potential in the
field of DG.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15153" title="Abstract">arXiv:2311.15153</a> [<a href="/pdf/2311.15153" title="Download PDF">pdf</a>, <a href="/format/2311.15153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Learning for SAR ATR with a Knowledge-Guided Predictive  Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weijie Li</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianpeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yuenan Hou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yongxiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Li Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Recently, the emergence of a large number of Synthetic Aperture Radar (SAR)
sensors and target datasets has made it possible to unify downstream tasks with
self-supervised learning techniques, which can pave the way for building the
foundation model in the SAR target recognition field. The major challenge of
self-supervised learning for SAR target recognition lies in the generalizable
representation learning in low data quality and noise.To address the
aforementioned problem, we propose a knowledge-guided predictive architecture
that uses local masked patches to predict the multiscale SAR feature
representations of unseen context. The core of the proposed architecture lies
in combining traditional SAR domain feature extraction with state-of-the-art
scalable self-supervised learning for accurate generalized feature
representations. The proposed framework is validated on various downstream
datasets (MSTAR, FUSAR-Ship, SAR-ACD and SSDD), and can bring consistent
performance improvement for SAR target recognition. The experimental results
strongly demonstrate the unified performance improvement of the self-supervised
learning technique for SAR target recognition across diverse targets, scenes
and sensors.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15156" title="Abstract">arXiv:2311.15156</a> [<a href="/pdf/2311.15156" title="Download PDF">pdf</a>, <a href="/format/2311.15156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> xTrimoGene: An Efficient and Scalable Representation Learner for  Single-Cell RNA-Seq Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+J">Jing Gong</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+M">Minsheng Hao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xingyi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xin Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chiming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jianzhu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuegong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Taifeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Le Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Genomics (q-bio.GN)

</div>
<p class="mathjax">Advances in high-throughput sequencing technology have led to significant
progress in measuring gene expressions at the single-cell level. The amount of
publicly available single-cell RNA-seq (scRNA-seq) data is already surpassing
50M records for humans with each record measuring 20,000 genes. This highlights
the need for unsupervised representation learning to fully ingest these data,
yet classical transformer architectures are prohibitive to train on such data
in terms of both computation and memory. To address this challenge, we propose
a novel asymmetric encoder-decoder transformer for scRNA-seq data, called
xTrimoGene$^\alpha$ (or xTrimoGene for short), which leverages the sparse
characteristic of the data to scale up the pre-training. This scalable design
of xTrimoGene reduces FLOPs by one to two orders of magnitude compared to
classical transformers while maintaining high accuracy, enabling us to train
the largest transformer models over the largest scRNA-seq dataset today. Our
experiments also show that the performance of xTrimoGene improves as we scale
up the model sizes, and it also leads to SOTA performance over various
downstream tasks, such as cell type annotation, perturb-seq effect prediction,
and drug combination prediction. xTrimoGene model is now available for use as a
service via the following link: https://api.biomap.com/xTrimoGene/apply.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15157" title="Abstract">arXiv:2311.15157</a> [<a href="/pdf/2311.15157" title="Download PDF">pdf</a>, <a href="/format/2311.15157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Vision Transformers with Group-Mix Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+C">Chongjian Ge</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+X">Xiaohan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+Z">Zhan Tong</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Li Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiangliu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yibing Song</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision Transformers (ViTs) have been shown to enhance visual recognition
through modeling long-range dependencies with multi-head self-attention (MHSA),
which is typically formulated as Query-Key-Value computation. However, the
attention map generated from the Query and Key captures only token-to-token
correlations at one single granularity. In this paper, we argue that
self-attention should have a more comprehensive mechanism to capture
correlations among tokens and groups (i.e., multiple adjacent tokens) for
higher representational capacity. Thereby, we propose Group-Mix Attention (GMA)
as an advanced replacement for traditional self-attention, which can
simultaneously capture token-to-token, token-to-group, and group-to-group
correlations with various group sizes. To this end, GMA splits the Query, Key,
and Value into segments uniformly and performs different group aggregations to
generate group proxies. The attention map is computed based on the mixtures of
tokens and group proxies and used to re-combine the tokens and groups in Value.
Based on GMA, we introduce a powerful backbone, namely GroupMixFormer, which
achieves state-of-the-art performance in image classification, object
detection, and semantic segmentation with fewer parameters than existing
models. For instance, GroupMixFormer-L (with 70.3M parameters and 384^2 input)
attains 86.2% Top-1 accuracy on ImageNet-1K without external data, while
GroupMixFormer-B (with 45.8M parameters) attains 51.2% mIoU on ADE20K.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15158" title="Abstract">arXiv:2311.15158</a> [<a href="/pdf/2311.15158" title="Download PDF">pdf</a>, <a href="/format/2311.15158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Angular-Distance Based Channel Estimation for Holographic MIMO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuanbin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Ying Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaocheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhu Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for publication in IEEE JSAC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper investigates the channel estimation for holographic MIMO systems
by unmasking their distinctions from the conventional one. Specifically, we
elucidate that the channel estimation, subject to holographic MIMO's
electromagnetically large antenna arrays, has to discriminate not only the
angles of a user/scatterer but also its distance information, namely the
three-dimensional (3D) azimuth and elevation angles plus the distance (AED)
parameters. As the angular-domain representation fails to characterize the
sparsity inherent in holographic MIMO channels, the tightly coupled 3D AED
parameters are firstly decomposed for independently constructing their own
covariance matrices. Then, the recovery of each individual parameter can be
structured as a compressive sensing (CS) problem by harnessing the covariance
matrix constructed. This pair of techniques contribute to a parametric
decomposition and compressed deconstruction (DeRe) framework, along with a
formulation of the maximum likelihood estimation for each parameter. Then, an
efficient algorithm, namely DeRe-based variational Bayesian inference and
message passing (DeRe-VM), is proposed for the sharp detection of the 3D AED
parameters and the robust recovery of sparse channels. Finally, the proposed
channel estimation regime is confirmed to be of great robustness in
accommodating different channel conditions, regardless of the near-field and
far-field contexts of a holographic MIMO system, as well as an improved
performance in comparison to the state-of-the-art benchmarks.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15161" title="Abstract">arXiv:2311.15161</a> [<a href="/pdf/2311.15161" title="Download PDF">pdf</a>, <a href="/format/2311.15161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hessian Aware Low-Rank Weight Perturbation for Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">Yuanhao Lai</a>, 
<a href="/search/cs?searchtype=author&query=Shui%2C+C">Changjian Shui</a>, 
<a href="/search/cs?searchtype=author&query=Sahoo%2C+S">Sabyasachi Sahoo</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+C+X">Charles X. Ling</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shichun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Boyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gagn%C3%A9%2C+C">Christian Gagn&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Fan Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Continual learning aims to learn a series of tasks sequentially without
forgetting the knowledge acquired from the previous ones. In this work, we
propose the Hessian Aware Low-Rank Perturbation algorithm for continual
learning. By modeling the parameter transitions along the sequential tasks with
the weight matrix transformation, we propose to apply the low-rank
approximation on the task-adaptive parameters in each layer of the neural
networks. Specifically, we theoretically demonstrate the quantitative
relationship between the Hessian and the proposed low-rank approximation. The
approximation ranks are then globally determined according to the marginal
increment of the empirical loss estimated by the layer-specific gradient and
low-rank approximation error. Furthermore, we control the model capacity by
pruning less important parameters to diminish the parameter growth. We conduct
extensive experiments on various benchmarks, including a dataset with
large-scale tasks, and compare our method against some recent state-of-the-art
methods to demonstrate the effectiveness and scalability of our proposed
method. Empirical results show that our method performs better on different
benchmarks, especially in achieving task order robustness and handling the
forgetting issue. A demo code can be found at https://github.com/lijiaqi/HALRP.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15162" title="Abstract">arXiv:2311.15162</a> [<a href="/pdf/2311.15162" title="Download PDF">pdf</a>, <a href="/ps/2311.15162" title="Download PostScript">ps</a>, <a href="/format/2311.15162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Knowledge Injection in Bayesian Search for New Materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zikai Xie</a>, 
<a href="/search/cs?searchtype=author&query=Evangelopoulos%2C+X">Xenophon Evangelopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Thacker%2C+J">Joseph Thacker</a>, 
<a href="/search/cs?searchtype=author&query=Cooper%2C+A">Andrew Cooper</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, published in ECAI23
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Twenty-sixth European Conference on Artificial Intelligence (ECAI
  2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In this paper we propose DKIBO, a Bayesian optimization (BO) algorithm that
accommodates domain knowledge to tune exploration in the search space. Bayesian
optimization has recently emerged as a sample-efficient optimizer for many
intractable scientific problems. While various existing BO frameworks allow the
input of prior beliefs to accelerate the search by narrowing down the space,
incorporating such knowledge is not always straightforward and can often
introduce bias and lead to poor performance. Here we propose a simple approach
to incorporate structural knowledge in the acquisition function by utilizing an
additional deterministic surrogate model to enrich the approximation power of
the Gaussian process. This is suitably chosen according to structural
information of the problem at hand and acts a corrective term towards a
better-informed sampling. We empirically demonstrate the practical utility of
the proposed method by successfully injecting domain knowledge in a materials
design task. We further validate our method's performance on different
experimental settings and ablation analyses.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15163" title="Abstract">arXiv:2311.15163</a> [<a href="/pdf/2311.15163" title="Download PDF">pdf</a>, <a href="/format/2311.15163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-Based Approaches for Contactless Fingerprints Segmentation  and Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Murshed%2C+M+G+S">M.G. Sarwar Murshed</a>, 
<a href="/search/cs?searchtype=author&query=Abbas%2C+S+K">Syed Konain Abbas</a>, 
<a href="/search/cs?searchtype=author&query=Purnapatra%2C+S">Sandip Purnapatra</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+D">Daqing Hou</a>, 
<a href="/search/cs?searchtype=author&query=Hussain%2C+F">Faraz Hussain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Fingerprints are widely recognized as one of the most unique and reliable
characteristics of human identity. Most modern fingerprint authentication
systems rely on contact-based fingerprints, which require the use of
fingerprint scanners or fingerprint sensors for capturing fingerprints during
the authentication process. Various types of fingerprint sensors, such as
optical, capacitive, and ultrasonic sensors, employ distinct techniques to
gather and analyze fingerprint data. This dependency on specific hardware or
sensors creates a barrier or challenge for the broader adoption of fingerprint
based biometric systems. This limitation hinders the widespread adoption of
fingerprint authentication in various applications and scenarios. Border
control, healthcare systems, educational institutions, financial transactions,
and airport security face challenges when fingerprint sensors are not
universally available. To mitigate the dependence on additional hardware, the
use of contactless fingerprints has emerged as an alternative. Developing
precise fingerprint segmentation methods, accurate fingerprint extraction
tools, and reliable fingerprint matchers are crucial for the successful
implementation of a robust contactless fingerprint authentication system. This
paper focuses on the development of a deep learning-based segmentation tool for
contactless fingerprint localization and segmentation. Our system leverages
deep learning techniques to achieve high segmentation accuracy and reliable
extraction of fingerprints from contactless fingerprint images. In our
evaluation, our segmentation method demonstrated an average mean absolute error
(MAE) of 30 pixels, an error in angle prediction (EAP) of 5.92 degrees, and a
labeling accuracy of 97.46%. These results demonstrate the effectiveness of our
novel contactless fingerprint segmentation and extraction tools.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15165" title="Abstract">arXiv:2311.15165</a> [<a href="/pdf/2311.15165" title="Download PDF">pdf</a>, <a href="/format/2311.15165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixing Classifiers to Alleviate the Accuracy-Robustness Trade-Off
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yatong Bai</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+B+G">Brendon G. Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Sojoudi%2C+S">Somayeh Sojoudi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE Conference on Control Technology and Applications. arXiv admin note: substantial text overlap with <a href="/abs/2301.12554">arXiv:2301.12554</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Machine learning models have recently found tremendous success in data-driven
control systems. However, standard learning models often suffer from an
accuracy-robustness trade-off, which is a limitation that must be overcome in
the control of safety-critical systems that require both high performance and
rigorous robustness guarantees. In this work, we build upon the recent "locally
biased smoothing" method to develop classifiers that simultaneously inherit
high accuracy from standard models and high robustness from robust models.
Specifically, we extend locally biased smoothing to the multi-class setting,
and then overcome its performance bottleneck by generalizing the formulation to
"mix" the outputs of a standard neural network and a robust neural network. We
prove that when the robustness of the robust base model is certifiable, within
a closed-form $\ell_p$ radius, no alteration or attack on an input can result
in misclassification of the mixed classifier; the proposed model inherits the
certified robustness. Moreover, we use numerical experiments on the CIFAR-10
benchmark dataset to verify that the mixed model noticeably improves the
accuracy-robustness trade-off.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15168" title="Abstract">arXiv:2311.15168</a> [<a href="/pdf/2311.15168" title="Download PDF">pdf</a>, <a href="/format/2311.15168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Data-Driven Approach for High-Impedance Fault Localization in  Distribution Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Yuqi Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Dong%2C+Y">Yuqing Dong</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+R">Rui Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Accurate and quick identification of high-impedance faults is critical for
the reliable operation of distribution systems. Unlike other faults in power
grids, HIFs are very difficult to detect by conventional overcurrent relays due
to the low fault current. Although HIFs can be affected by various factors, the
voltage current characteristics can substantially imply how the system responds
to the disturbance and thus provides opportunities to effectively localize
HIFs. In this work, we propose a data-driven approach for the identification of
HIF events. To tackle the nonlinearity of the voltage current trajectory,
first, we formulate optimization problems to approximate the trajectory with
piecewise functions. Then we collect the function features of all segments as
inputs and use the support vector machine approach to efficiently identify HIFs
at different locations. Numerical studies on the IEEE 123-node test feeder
demonstrate the validity and accuracy of the proposed approach for real-time
HIF identification.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15171" title="Abstract">arXiv:2311.15171</a> [<a href="/pdf/2311.15171" title="Download PDF">pdf</a>, <a href="/format/2311.15171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HumanRecon: Neural Reconstruction of Dynamic Human Using Geometric Cues  and Physical Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Junhui Yin</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+W">Wei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xuqian Ren</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhanyu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yifan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent methods for dynamic human reconstruction have attained promising
reconstruction results. Most of these methods rely only on RGB color
supervision without considering explicit geometric constraints. This leads to
existing human reconstruction techniques being more prone to overfitting to
color and causes geometrically inherent ambiguities, especially in the sparse
multi-view setup.
<br />Motivated by recent advances in the field of monocular geometry prediction,
we consider the geometric constraints of estimated depth and normals in the
learning of neural implicit representation for dynamic human reconstruction. As
a geometric regularization, this provides reliable yet explicit supervision
information, and improves reconstruction quality. We also exploit several
beneficial physical priors, such as adding noise into view direction and
maximizing the density on the human surface. These priors ensure the color
rendered along rays to be robust to view direction and reduce the inherent
ambiguities of density estimated along rays. Experimental results demonstrate
that depth and normal cues, predicted by human-specific monocular estimators,
can provide effective supervision signals and render more accurate images.
Finally, we also show that the proposed physical priors significantly reduce
overfitting and improve the overall quality of novel view synthesis. Our code
is available
at:~\href{https://github.com/PRIS-CV/HumanRecon}{https://github.com/PRIS-CV/HumanRecon}.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15178" title="Abstract">arXiv:2311.15178</a> [<a href="/pdf/2311.15178" title="Download PDF">pdf</a>, <a href="/format/2311.15178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combinatorial Analysis of Coded Caching Schemes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+R">Ruizhong Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Coded caching schemes are used to reduce computer network traffics in peak
time. To determine the efficiency of the schemes, \cite{MN} defined the
information rate of the schemes and gave a construction of optimal coded
caching schemes. However, their construction needs to split the data into a
large number of packets which may cause constraints in real applications. Many
researchers then constructed new coded caching schemes to reduce the number of
packets but that increased the information rate. We define an optimization of
coded caching schemes under the limitation of the number of packets which may
be used to verify the efficiency of these schemes. We also give some
constructions for several infinite classes of optimal coded caching schemes
under the new definition.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15179" title="Abstract">arXiv:2311.15179</a> [<a href="/pdf/2311.15179" title="Download PDF">pdf</a>, <a href="/format/2311.15179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimation of the User Contribution Rate by Leveraging Time Sequence in  Pairwise Matching function-point between Users Feedback and App Updating Log
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+S">Shiqi Duan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianxun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yong Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangping Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Mobile applications have become an inseparable part of people's daily life.
Nonetheless, the market competition is extremely fierce, and apps lacking
recognition among most users are susceptible to market elimination. To this
end, developers must swiftly and accurately apprehend the requirements of the
wider user base to effectively strategize and promote their apps' orderly and
healthy evolution. The rate at which general user requirements are adopted by
developers, or user contribution, is a very valuable metric that can be an
important tool for app developers or software engineering researchers to
measure or gain insight into the evolution of app requirements and predict the
evolution of app software. Regrettably, the landscape lacks refined
quantitative analysis approaches and tools for this pivotal indicator. To
address this problem, this paper exploratively proposes a quantitative analysis
approach based on the temporal correlation perception that exists in the app
update log and user reviews, which provides a feasible solution for
quantitatively obtaining the user contribution. The main idea of this scheme is
to consider valid user reviews as user requirements and app update logs as
developer responses, and to mine and analyze the pairwise and chronological
relationships existing between the two by text computing, thus constructing a
feasible approach for quantitatively calculating user contribution. To
demonstrate the feasibility of the approach, this paper collects data from four
Chinese apps in the App Store in mainland China and one English app in the U.S.
region, including 2,178 update logs and 4,236,417 user reviews, and from the
results of the experiment, it was found that 16.6%-43.2% of the feature of
these apps would be related to the drive from the online popular user
requirements.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15186" title="Abstract">arXiv:2311.15186</a> [<a href="/pdf/2311.15186" title="Download PDF">pdf</a>, <a href="/format/2311.15186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymptotically Compatible Schemes for Nonlocal Ohta Kawasaki Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Luo%2C+W">Wangbo Luo</a>, 
<a href="/search/math?searchtype=author&query=Zhao%2C+Y">Yanxiang Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We study the asymptotical compatibility of the Fourier spectral method in
multidimensional space for the Nonlocal Ohta-Kawasaka (NOK) model, which is
proposed in our previous work. By introducing the Fourier collocation
discretization for the spatial variable, we show that the asymptotical
compatibility holds in 2D and 3D over a periodic domain. For the temporal
discretization, we adopt the second-order backward differentiation formula
(BDF) method. We prove that for certain nonlocal kernels, the proposed time
discretization schemes inherit the energy dissipation law. In the numerical
experiments, we verify the asymptotical compatibility, the second-order
temporal convergence rate, and the energy stability of the proposed schemes.
More importantly, we discover a novel square lattice pattern when certain
nonlocal kernel are applied in the model. In addition, our numerical
experiments confirm the existence of an upper bound for the optimal number of
bubbles in 2D for some specific nonlocal kernels. Finally, we numerically
explore the promotion/demotion effect induced by the nonlocal horizon, which is
consistent with the theoretical studies presented in our earlier work.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15189" title="Abstract">arXiv:2311.15189</a> [<a href="/pdf/2311.15189" title="Download PDF">pdf</a>, <a href="/ps/2311.15189" title="Download PostScript">ps</a>, <a href="/format/2311.15189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Rely/Guarantee to Pinpoint Assumptions underlying Security  Protocols
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yatapanage%2C+N+P">Nisansala P. Yatapanage</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+C+B">Cliff B. Jones</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">The verification of security protocols is essential, in order to ensure the
absence of potential attacks. However, verification results are only valid with
respect to the assumptions under which the verification was performed. These
assumptions are often hidden and are difficult to identify, making it unclear
whether a given protocol is safe to deploy into a particular environment.
Rely/guarantee provides a mechanism for abstractly reasoning about the
interference from the environment. Using this approach, the assumptions are
made clear and precise. This paper investigates this approach on the
Needham-Schroeder Public Key protocol, showing that the technique can
effectively uncover the assumptions under which the protocol can withstand
attacks from intruders.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15193" title="Abstract">arXiv:2311.15193</a> [<a href="/pdf/2311.15193" title="Download PDF">pdf</a>, <a href="/format/2311.15193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IA-LSTM: Interaction-Aware LSTM for Pedestrian Trajectory Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuehai Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Predicting the trajectory of pedestrians in crowd scenarios is indispensable
in self-driving or autonomous mobile robot field because estimating the future
locations of pedestrians around is beneficial for policy decision to avoid
collision. It is a challenging issue because humans have different walking
motions and the interactions between humans and objects in the current
environment, especially between human themselves, are complex. Previous
researches have focused on how to model the human-human interactions, however,
neglecting the relative importance of interactions. In order to address this
issue, we introduce a novel mechanism based on the correntropy, which not only
can measure the relative importance of human-human interactions, but also can
build personal space for each pedestrian. We further propose an Interaction
Module including this data-driven mechanism that can effectively extract
feature representations of dynamic human-human interactions in the scene and
calculate corresponding weights to represent the importance of different
interactions. To share such social messages among pedestrians, we design an
interaction-aware architecture based on the Long Short-Term Memory (LSTM)
network for trajectory prediction. We demonstrate the performance of our model
on two public datasets and the experimental results demonstrate that our model
can achieve better performance than several latest methods with good
performance.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15194" title="Abstract">arXiv:2311.15194</a> [<a href="/pdf/2311.15194" title="Download PDF">pdf</a>, <a href="/format/2311.15194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Network Models of Becoming a Cardinal Principle Knower
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+V">Vima Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Varma%2C+S">Sashank Varma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As children enter elementary school, their understanding of the ordinal
structure of numbers transitions from a memorized count list of the first
50-100 numbers to knowing the successor function and understanding the
countably infinite. We investigate this developmental change in two neural
network models that learn the successor function on the pairs (N, N+1) for N in
(0, 98). The first uses a one-hot encoding of the input and output values and
corresponds to children memorizing a count list, while the second model uses a
place-value encoding and corresponds to children learning the language rules
for naming numbers. The place-value model showed a predicted drop in
representational similarity across tens boundaries. Counting across a tens
boundary can be understood as a vector operation in 2D space, where the numbers
with the same tens place are organized in a linearly separable manner, whereas
those with the same ones place are grouped together. A curriculum learning
simulation shows that, in the expanding numerical environment of the developing
child, representations of smaller numbers continue to be sharpened even as
larger numbers begin to be learned. These models set the stage for future work
using recurrent architectures to move beyond learning the successor function to
simulating the counting process more generally, and point towards a deeper
understanding of what it means to understand the countably infinite.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15198" title="Abstract">arXiv:2311.15198</a> [<a href="/pdf/2311.15198" title="Download PDF">pdf</a>, <a href="/format/2311.15198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT and Beyond: The Generative AI Revolution in Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=AL-Smadi%2C+M">Mohammad AL-Smadi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">The wide adoption and usage of generative artificial intelligence (AI)
models, particularly ChatGPT, has sparked a surge in research exploring their
potential applications in the educational landscape. This survey examines
academic literature published between November, 2022, and July, 2023,
specifically targeting high-impact research from Scopus-indexed Q1 and Q2
journals. This survey delves into the practical applications and implications
of generative AI models across a diverse range of educational contexts. Through
a comprehensive and rigorous evaluation of recent academic literature, this
survey seeks to illuminate the evolving role of generative AI models,
particularly ChatGPT, in education. By shedding light on the potential
benefits, challenges, and emerging trends in this dynamic field, the survey
endeavors to contribute to the understanding of the nexus between artificial
intelligence and education. The findings of this review will empower educators,
researchers, and policymakers to make informed decisions about the integration
of AI technologies into learning environments.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15200" title="Abstract">arXiv:2311.15200</a> [<a href="/pdf/2311.15200" title="Download PDF">pdf</a>, <a href="/format/2311.15200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpliceMix: A Cross-scale and Semantic Blending Augmentation Strategy for  Multi-label Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Y">Yibing Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Leilei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dapeng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Liang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+C">Chen Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently, Mix-style data augmentation methods (e.g., Mixup and CutMix) have
shown promising performance in various visual tasks. However, these methods are
primarily designed for single-label images, ignoring the considerable
discrepancies between single- and multi-label images, i.e., a multi-label image
involves multiple co-occurred categories and fickle object scales. On the other
hand, previous multi-label image classification (MLIC) methods tend to design
elaborate models, bringing expensive computation. In this paper, we introduce a
simple but effective augmentation strategy for multi-label image
classification, namely SpliceMix. The "splice" in our method is two-fold: 1)
Each mixed image is a splice of several downsampled images in the form of a
grid, where the semantics of images attending to mixing are blended without
object deficiencies for alleviating co-occurred bias; 2) We splice mixed images
and the original mini-batch to form a new SpliceMixed mini-batch, which allows
an image with different scales to contribute to training together. Furthermore,
such splice in our SpliceMixed mini-batch enables interactions between mixed
images and original regular images. We also offer a simple and non-parametric
extension based on consistency learning (SpliceMix-CL) to show the flexible
extensibility of our SpliceMix. Extensive experiments on various tasks
demonstrate that only using SpliceMix with a baseline model (e.g., ResNet)
achieves better performance than state-of-the-art methods. Moreover, the
generalizability of our SpliceMix is further validated by the improvements in
current MLIC methods when married with our SpliceMix. The code is available at
https://github.com/zuiran/SpliceMix.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15202" title="Abstract">arXiv:2311.15202</a> [<a href="/pdf/2311.15202" title="Download PDF">pdf</a>, <a href="/format/2311.15202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-stream contrastive predictive network with joint handcrafted  feature view for SAR ship classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xianting Feng</a>, 
<a href="/search/cs?searchtype=author&query=zheng%2C+H">Hao zheng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhigang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+M">Meiguang Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Most existing synthetic aperture radar (SAR) ship classification technologies
heavily rely on correctly labeled data, ignoring the discriminative features of
unlabeled SAR ship images. Even though researchers try to enrich CNN-based
features by introducing traditional handcrafted features, existing methods
easily cause information redundancy and fail to capture the interaction between
them. To address these issues, we propose a novel dual-stream contrastive
predictive network (DCPNet), which consists of two asymmetric task designs and
the false negative sample elimination module. The first task is to construct
positive sample pairs, guiding the core encoder to learn more general
representations. The second task is to encourage adaptive capture of the
correspondence between deep features and handcrated features, achieving
knowledge transfer within the model, and effectively improving the redundancy
caused by the feature fusion. To increase the separability between clusters, we
also design a cluster-level tasks. The experimental results on OpenSARShip and
FUSAR-Ship datasets demonstrate the improvement in classification accuracy of
supervised models and confirm the capability of learning effective
representations of DCPNet.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15203" title="Abstract">arXiv:2311.15203</a> [<a href="/pdf/2311.15203" title="Download PDF">pdf</a>, <a href="/ps/2311.15203" title="Download PostScript">ps</a>, <a href="/format/2311.15203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning against Non-credible Auctions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xuanzhi Xia</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zongjun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+X">Xiaotie Deng</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Y">Yuqing Kong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhilin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chuan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Bo Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">The standard framework of online bidding algorithm design assumes that the
seller commits himself to faithfully implementing the rules of the adopted
auction. However, the seller may attempt to cheat in execution to increase his
revenue if the auction belongs to the class of non-credible auctions. For
example, in a second-price auction, the seller could create a fake bid between
the highest bid and the second highest bid. This paper focuses on one such case
of online bidding in repeated second-price auctions. At each time $t$, the
winner with bid $b_t$ is charged not the highest competing bid $d_t$ but a
manipulated price $p_t = \alpha_0 d_t + (1-\alpha_0) b_t$, where the parameter
$\alpha_0 \in [0, 1]$ in essence measures the seller's credibility. Unlike
classic repeated-auction settings where the bidder has access to samples
$(d_s)_{s=1}^{t-1}$, she can only receive mixed signals of $(b_s)_{s=1}^{t-1}$,
$(d_s)_{s=1}^{t-1}$ and $\alpha_0$ in this problem. The task for the bidder is
to learn not only the bid distributions of her competitors but also the
seller's credibility. We establish regret lower bounds in various information
models and provide corresponding online bidding algorithms that can achieve
near-optimal performance. Specifically, we consider three cases of prior
information based on whether the credibility $\alpha_0$ and the distribution of
the highest competing bids are known. Our goal is to characterize the landscape
of online bidding in non-credible auctions and understand the impact of the
seller's credibility on online bidding algorithm design under different
information structures.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15204" title="Abstract">arXiv:2311.15204</a> [<a href="/pdf/2311.15204" title="Download PDF">pdf</a>, <a href="/ps/2311.15204" title="Download PostScript">ps</a>, <a href="/format/2311.15204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenDigger: Data Mining and Information Service System for Open  Collaboration Digital Ecosystem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xiaoya Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shengyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+F">Fanyu Han</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+F">Fenglin Bi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Chinese language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">The widespread development and adoption of open-source software have built an
ecosystem for open development and collaboration. In this ecosystem,
individuals and organizations collaborate to create high-quality software that
can be used by everyone. Social collaboration platforms like GitHub have
further facilitated large-scale, distributed, and fine-grained code
collaboration and technical interactions. Countless developers contribute code,
review code, report bugs, and propose new features on these platforms every
day, generating a massive amount of valuable behavioral data from the open
collaboration process. This paper presents the design and implementation of
OpenDigger, a comprehensive data mining and information service system for open
collaboration in the digital ecosystem. The goal is to build a data
infrastructure for the open-source domain and promote the continuous
development of the open-source ecosystem. The metrics and analysis models in
the OpenDigger system can mine various knowledge from the macro to micro levels
in the open-source digital ecosystem. Through a unified information service
interface, OpenDigger provides various open-source information services to
different user groups, including governments, enterprises, foundations, and
individuals. As a novel information service system in the open-source
ecosystem, this paper demonstrates the effectiveness of the metrics and models
in OpenDigger through several real-world scenarios, including products, tools,
applications, and courses. It showcases the significant and diverse practical
applications of the metrics and models in both algorithmic and business
aspects.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15206" title="Abstract">arXiv:2311.15206</a> [<a href="/pdf/2311.15206" title="Download PDF">pdf</a>, <a href="/format/2311.15206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Insect-Foundation: A Foundation Model and Large-scale 1M Dataset for  Visual Insect Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Hoang-Quan Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Truong%2C+T">Thanh-Dat Truong</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+X+B">Xuan Bac Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Dowling%2C+A">Ashley Dowling</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+K">Khoa Luu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In precision agriculture, the detection and recognition of insects play an
essential role in the ability of crops to grow healthy and produce a
high-quality yield. The current machine vision model requires a large volume of
data to achieve high performance. However, there are approximately 5.5 million
different insect species in the world. None of the existing insect datasets can
cover even a fraction of them due to varying geographic locations and
acquisition costs. In this paper, we introduce a novel ``Insect-1M'' dataset, a
game-changing resource poised to revolutionize insect-related foundation model
training. Covering a vast spectrum of insect species, our dataset, including 1
million images with dense identification labels of taxonomy hierarchy and
insect descriptions, offers a panoramic view of entomology, enabling foundation
models to comprehend visual and semantic information about insects like never
before. Then, to efficiently establish an Insect Foundation Model, we develop a
micro-feature self-supervised learning method with a Patch-wise Relevant
Attention mechanism capable of discerning the subtle differences among insect
images. In addition, we introduce Description Consistency loss to improve
micro-feature modeling via insect descriptions. Through our experiments, we
illustrate the effectiveness of our proposed approach in insect modeling and
achieve State-of-the-Art performance on standard benchmarks of insect-related
tasks. Our Insect Foundation Model and Dataset promise to empower the next
generation of insect-related vision models, bringing them closer to the
ultimate goal of precision agriculture.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15208" title="Abstract">arXiv:2311.15208</a> [<a href="/pdf/2311.15208" title="Download PDF">pdf</a>, <a href="/format/2311.15208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LongStory: Coherent, Complete and Length Controlled Long story  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+K">Kyeongman Park</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+N">Nakyeong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+K">Kyomin Jung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">A human author can write any length of story without losing coherence. Also,
they always bring the story to a proper ending, an ability that current
language models lack. In this work, we present the LongStory for coherent,
complete, and length-controlled long story generation. LongStory introduces two
novel methodologies: (1) the long and short-term contexts weight calibrator
(CWC) and (2) long story structural positions (LSP). The CWC adjusts weights
for long-term context Memory and short-term context Cheating, acknowledging
their distinct roles. The LSP employs discourse tokens to convey the structural
positions of a long story. Trained on three datasets with varied average story
lengths, LongStory outperforms other baselines, including the strong story
generator Plotmachine, in coherence, completeness, relevance, and
repetitiveness. We also perform zero-shot tests on each dataset to assess the
model's ability to predict outcomes beyond its training data and validate our
methodology by comparing its performance with variants of our model.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15209" title="Abstract">arXiv:2311.15209</a> [<a href="/pdf/2311.15209" title="Download PDF">pdf</a>, <a href="/format/2311.15209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> See and Think: Embodied Agent in Virtual Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhonghan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+W">Wenhao Chai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Boyi%2C+L">Li Boyi</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+S">Shengyu Hao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Shidong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+T">Tian Ye</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jenq-Neng Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gaoang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. First three authors contribute equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Large language models (LLMs) have achieved impressive progress on several
open-world tasks. Recently, using LLMs to build embodied agents has been a
hotspot. In this paper, we propose STEVE, a comprehensive and visionary
embodied agent in the Minecraft virtual environment. STEVE consists of three
key components: vision perception, language instruction, and code action.
Vision perception involves the interpretation of visual information in the
environment, which is then integrated into the LLMs component with agent state
and task instruction. Language instruction is responsible for iterative
reasoning and decomposing complex tasks into manageable guidelines. Code action
generates executable skill actions based on retrieval in skill database,
enabling the agent to interact effectively within the Minecraft environment. We
also collect STEVE-21K dataset, which includes 600$+$ vision-environment pairs,
20K knowledge question-answering pairs, and 200$+$ skill-code pairs. We conduct
continuous block search, knowledge question and answering, and tech tree
mastery to evaluate the performance. Extensive experiments show that STEVE
achieves at most $1.5 \times$ faster unlocking key tech trees and $2.5 \times$
quicker in block search tasks compared to previous state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15210" title="Abstract">arXiv:2311.15210</a> [<a href="/pdf/2311.15210" title="Download PDF">pdf</a>, <a href="/format/2311.15210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topology combined machine learning for consonant recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+P">Pingyao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+S">Siheng Yi</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Q">Qingrui Qu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhiwang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yifei Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST)

</div>
<p class="mathjax">In artificial-intelligence-aided signal processing, existing deep learning
models often exhibit a black-box structure, and their validity and
comprehensibility remain elusive. The integration of topological methods,
despite its relatively nascent application, serves a dual purpose of making
models more interpretable as well as extracting structural information from
time-dependent data for smarter learning. Here, we provide a transparent and
broadly applicable methodology, TopCap, to capture the most salient topological
features inherent in time series for machine learning. Rooted in
high-dimensional ambient spaces, TopCap is capable of capturing features rarely
detected in datasets with low intrinsic dimensionality. Applying time-delay
embedding and persistent homology, we obtain descriptors which encapsulate
information such as the vibration of a time series, in terms of its variability
of frequency, amplitude, and average line, demonstrated with simulated data.
This information is then vectorised and fed into multiple machine learning
algorithms such as k-nearest neighbours and support vector machine. Notably, in
classifying voiced and voiceless consonants, TopCap achieves an accuracy
exceeding 96% and is geared towards designing topological convolutional layers
for deep learning of speech and audio signals.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15211" title="Abstract">arXiv:2311.15211</a> [<a href="/pdf/2311.15211" title="Download PDF">pdf</a>, <a href="/format/2311.15211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Transformer: A Probabilistic Dependency Model for  Contextual Word Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoyi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+K">Kewei Tu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ACL2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Syntactic structures used to play a vital role in natural language processing
(NLP), but since the deep learning revolution, NLP has been gradually dominated
by neural models that do not consider syntactic structures in their design. One
vastly successful class of neural models is transformers. When used as an
encoder, a transformer produces contextual representation of words in the input
sentence. In this work, we propose a new model of contextual word
representation, not from a neural perspective, but from a purely syntactic and
probabilistic perspective. Specifically, we design a conditional random field
that models discrete latent representations of all words in a sentence as well
as dependency arcs between them; and we use mean field variational inference
for approximate inference. Strikingly, we find that the computation graph of
our model resembles transformers, with correspondences between dependencies and
self-attention and between distributions over latent representations and
contextual embeddings of words. Experiments show that our model performs
competitively to transformers on small to medium sized datasets. We hope that
our work could help bridge the gap between traditional syntactic and
probabilistic approaches and cutting-edge neural approaches to NLP, and inspire
more linguistically-principled neural approaches in the future.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15212" title="Abstract">arXiv:2311.15212</a> [<a href="/pdf/2311.15212" title="Download PDF">pdf</a>, <a href="/format/2311.15212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenPerf: A Benchmarking Framework for the Sustainable Development of  the Open-Source Ecosystem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bi%2C+F">Fenglin Bi</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+F">Fanyu Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shengyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinlu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanbin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Benchmarking involves designing scientific test methods, tools, and
frameworks to quantitatively and comparably assess specific performance
indicators of certain test subjects. With the development of artificial
intelligence, AI benchmarking datasets such as ImageNet and DataPerf have
gradually become consensus standards in both academic and industrial fields.
However, constructing a benchmarking framework remains a significant challenge
in the open-source domain due to the diverse range of data types, the wide
array of research issues, and the intricate nature of collaboration networks.
This paper introduces OpenPerf, a benchmarking framework designed for the
sustainable development of the open-source ecosystem. This framework defines 9
task benchmarking tasks in the open-source research, encompassing 3 data types:
time series, text, and graphics, and addresses 6 research problems including
regression, classification, recommendation, ranking, network building, and
anomaly detection. Based on the above tasks, we implemented 3 data science task
benchmarks, 2 index-based benchmarks, and 1 standard benchmark. Notably, the
index-based benchmarks have been adopted by the China Electronics
Standardization Institute as evaluation criteria for open-source community
governance. Additionally, we have developed a comprehensive toolkit for
OpenPerf, which not only offers robust data management, tool integration, and
user interface capabilities but also adopts a Benchmarking-as-a-Service (BaaS)
model to serve academic institutions, industries, and foundations. Through its
application in renowned companies and institutions such as Alibaba, Ant Group,
and East China Normal University, we have validated OpenPerf's pivotal role in
the healthy evolution of the open-source ecosystem.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15214" title="Abstract">arXiv:2311.15214</a> [<a href="/pdf/2311.15214" title="Download PDF">pdf</a>, <a href="/format/2311.15214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Normalized-Cut Solver with Nearest Neighbor Hierarchical  Initialization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nie%2C+F">Feiping Nie</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jitao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Danyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuelong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Normalized-Cut (N-Cut) is a famous model of spectral clustering. The
traditional N-Cut solvers are two-stage: 1) calculating the continuous spectral
embedding of normalized Laplacian matrix; 2) discretization via $K$-means or
spectral rotation. However, this paradigm brings two vital problems: 1)
two-stage methods solve a relaxed version of the original problem, so they
cannot obtain good solutions for the original N-Cut problem; 2) solving the
relaxed problem requires eigenvalue decomposition, which has $\mathcal{O}(n^3)$
time complexity ($n$ is the number of nodes). To address the problems, we
propose a novel N-Cut solver designed based on the famous coordinate descent
method. Since the vanilla coordinate descent method also has $\mathcal{O}(n^3)$
time complexity, we design various accelerating strategies to reduce the time
complexity to $\mathcal{O}(|E|)$ ($|E|$ is the number of edges). To avoid
reliance on random initialization which brings uncertainties to clustering, we
propose an efficient initialization method that gives deterministic outputs.
Extensive experiments on several benchmark datasets demonstrate that the
proposed solver can obtain larger objective values of N-Cut, meanwhile
achieving better clustering performance compared to traditional solvers.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15216" title="Abstract">arXiv:2311.15216</a> [<a href="/pdf/2311.15216" title="Download PDF">pdf</a>, <a href="/format/2311.15216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solve Large-scale Unit Commitment Problems by Physics-informed Graph  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Qin%2C+J">Jingtao Qin</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+N">Nanpeng Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Unit commitment (UC) problems are typically formulated as mixed-integer
programs (MIP) and solved by the branch-and-bound (B&amp;B) scheme. The recent
advances in graph neural networks (GNN) enable it to enhance the B&amp;B algorithm
in modern MIP solvers by learning to dive and branch. Existing GNN models that
tackle MIP problems are mostly constructed from mathematical formulation, which
is computationally expensive when dealing with large-scale UC problems. In this
paper, we propose a physics-informed hierarchical graph convolutional network
(PI-GCN) for neural diving that leverages the underlying features of various
components of power systems to find high-quality variable assignments.
Furthermore, we adopt the MIP model-based graph convolutional network (MB-GCN)
for neural branching to select the optimal variables for branching at each node
of the B&amp;B tree. Finally, we integrate neural diving and neural branching into
a modern MIP solver to establish a novel neural MIP solver designed for
large-scale UC problems. Numeral studies show that PI-GCN has better
performance and scalability than the baseline MB-GCN on neural diving.
Moreover, the neural MIP solver yields the lowest operational cost and
outperforms a modern MIP solver for all testing days after combining it with
our proposed neural diving model and the baseline neural branching model.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15218" title="Abstract">arXiv:2311.15218</a> [<a href="/pdf/2311.15218" title="Download PDF">pdf</a>, <a href="/format/2311.15218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dataset for Stock Market Forecasting Based on Quantitative Analysis and  Qualitative Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bathini%2C+S+A">Sai Akash Bathini</a>, 
<a href="/search/cs?searchtype=author&query=Cihan%2C+D">Dagli Cihan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
<p class="mathjax">The application of Machine learning to finance has become a familiar
approach, even more so in stock market forecasting. The stock market is highly
volatile and huge amounts of data are generated every minute globally. The
extraction of effective intelligence from this data is of critical importance.
However, a collaboration of numerical stock data with qualitative text data can
be a challenging task. In this work, we accomplish this and provide an
unprecedented, publicly available dataset with technical and fundamental data,
sentiment that we gathered from News Archives, TV news captions, Radio
Transcripts, Tweets, Daily financial newspapers, etc. The text data entries
used for sentiment extraction total more than 1.4 Million. The dataset
comprises of daily entries from January 2018 to December 2022 for 8 different
companies and Dow Jones Index as a whole. Holistic Fundamental and Technical
data is provided training ready for Model learning and deployment. The
predictive power of deep learning models is highly determined by the training
data provided. This dataset would be of benefit for research globally
incorporating qualitative intelligence for stock market forecasting. The
dataset is made available at https://github.com/batking24/Huge-Stock-Dataset.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15220" title="Abstract">arXiv:2311.15220</a> [<a href="/pdf/2311.15220" title="Download PDF">pdf</a>, <a href="/ps/2311.15220" title="Download PostScript">ps</a>, <a href="/format/2311.15220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimum Self Random Number Generation Rate and Its Application to Rate  Distortion Perception Function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nomura%2C+R">Ryo Nomura</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The self-random number generation (SRNG) problem is considered for general
setting. In the literature, the optimum SRNG rate with respect to the
variational distance has been discussed. In this paper, we first try to
characterize the optimum SRNG rate with respect to a subclass of
$f$-divergences. The subclass of $f$-divergences considered in this paper
includes typical distance measures such as the variational distance, the KL
divergence, the Hellinger distance and so on. Hence our result can be
considered as a generalization of the previous result with respect to the
variational distance. Next, we consider the obtained optimum SRNG rate from
several viewpoints. The $\varepsilon$-source coding problem is one of related
problems with the SRNG problem. Our results reveal how the SRNG problem with
the $f$-divergence relate to the $\varepsilon$-fixed-length source coding
problem. We also apply our results to the rate distortion perception (RDP)
function. As a result, we can establish a lower bound for the RDP function with
respect to $f$-divergences using our findings. Finally, we discuss the
representation of the optimum SRNG rate using the smooth R\'enyi entropy.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15221" title="Abstract">arXiv:2311.15221</a> [<a href="/pdf/2311.15221" title="Download PDF">pdf</a>, <a href="/format/2311.15221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Local Landscape of Phase Retrieval Under Limited Samples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kaizhao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lei Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP); Optimization and Control (math.OC); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">In this paper, we provide a fine-grained analysis of the local landscape of
phase retrieval under the regime with limited samples. Our aim is to ascertain
the minimal sample size necessary to guarantee a benign local landscape
surrounding global minima in high dimensions. Let $n$ and $d$ denote the sample
size and input dimension, respectively. We first explore the local convexity
and establish that when $n=o(d\log d)$, for almost every fixed point in the
local ball, the Hessian matrix must have negative eigenvalues as long as $d$ is
sufficiently large. Consequently, the local landscape is highly non-convex. We
next consider the one-point strong convexity and show that as long as
$n=\omega(d)$, with high probability, the landscape is one-point strongly
convex in the local annulus: $\{w\in\mathbb{R}^d: o_d(1)\leqslant
\|w-w^*\|\leqslant c\}$, where $w^*$ is the ground truth and $c$ is an absolute
constant. This implies that gradient descent initialized from any point in this
domain can converge to an $o_d(1)$-loss solution exponentially fast.
Furthermore, we show that when $n=o(d\log d)$, there is a radius of
$\widetilde\Theta\left(\sqrt{1/d}\right)$ such that one-point convexity breaks
in the corresponding smaller local ball. This indicates an impossibility to
establish a convergence to exact $w^*$ for gradient descent under limited
samples by relying solely on one-point convexity.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15222" title="Abstract">arXiv:2311.15222</a> [<a href="/pdf/2311.15222" title="Download PDF">pdf</a>, <a href="/format/2311.15222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decision Tree Psychological Risk Assessment in Currency Trading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pal%2C+J">Jai Pal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures, 7 listings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); General Finance (q-fin.GN)

</div>
<p class="mathjax">This research paper focuses on the integration of Artificial Intelligence
(AI) into the currency trading landscape, positing the development of
personalized AI models, essentially functioning as intelligent personal
assistants tailored to the idiosyncrasies of individual traders. The paper
posits that AI models are capable of identifying nuanced patterns within the
trader's historical data, facilitating a more accurate and insightful
assessment of psychological risk dynamics in currency trading. The PRI is a
dynamic metric that experiences fluctuations in response to market conditions
that foster psychological fragility among traders. By employing sophisticated
techniques, a classifying decision tree is crafted, enabling clearer
decision-making boundaries within the tree structure. By incorporating the
user's chronological trade entries, the model becomes adept at identifying
critical junctures when psychological risks are heightened. The real-time
nature of the calculations enhances the model's utility as a proactive tool,
offering timely alerts to traders about impending moments of psychological
risks. The implications of this research extend beyond the confines of currency
trading, reaching into the realms of other industries where the judicious
application of personalized modeling emerges as an efficient and strategic
approach. This paper positions itself at the intersection of cutting-edge
technology and the intricate nuances of human psychology, offering a
transformative paradigm for decision making support in dynamic and
high-pressure environments.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15225" title="Abstract">arXiv:2311.15225</a> [<a href="/pdf/2311.15225" title="Download PDF">pdf</a>, <a href="/format/2311.15225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-bit Supervision for Image Classification: Problem, Solution, and  Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hengtong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lingxi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Hue%2C+X">Xinyue Hue</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+R">Richang Hong</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qi Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM TOMM. arXiv admin note: text overlap with <a href="/abs/2009.06168">arXiv:2009.06168</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents one-bit supervision, a novel setting of learning with
fewer labels, for image classification. Instead of training model using the
accurate label of each sample, our setting requires the model to interact with
the system by predicting the class label of each sample and learn from the
answer whether the guess is correct, which provides one bit (yes or no) of
information. An intriguing property of the setting is that the burden of
annotation largely alleviates in comparison to offering the accurate label.
There are two keys to one-bit supervision, which are (i) improving the guess
accuracy and (ii) making good use of the incorrect guesses. To achieve these
goals, we propose a multi-stage training paradigm and incorporate negative
label suppression into an off-the-shelf semi-supervised learning algorithm.
Theoretical analysis shows that one-bit annotation is more efficient than
full-bit annotation in most cases and gives the conditions of combining our
approach with active learning. Inspired by this, we further integrate the
one-bit supervision framework into the self-supervised learning algorithm which
yields an even more efficient training schedule. Different from training from
scratch, when self-supervised learning is used for initialization, both hard
example mining and class balance are verified effective in boosting the
learning performance. However, these two frameworks still need full-bit labels
in the initial stage. To cast off this burden, we utilize unsupervised domain
adaptation to train the initial model and conduct pure one-bit annotations on
the target dataset. In multiple benchmarks, the learning efficiency of the
proposed approach surpasses that using full-bit, semi-supervised supervision.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15227" title="Abstract">arXiv:2311.15227</a> [<a href="/pdf/2311.15227" title="Download PDF">pdf</a>, <a href="/ps/2311.15227" title="Download PostScript">ps</a>, <a href="/format/2311.15227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Epidemic modeling and flattening the infection curve in social networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doostmohammadian%2C+M">Mohammadreza Doostmohammadian</a>, 
<a href="/search/cs?searchtype=author&query=Doustmohamadian%2C+S">Soraya Doustmohamadian</a>, 
<a href="/search/cs?searchtype=author&query=Doostmohammadian%2C+N">Najmeh Doostmohammadian</a>, 
<a href="/search/cs?searchtype=author&query=Doustmohammadian%2C+A">Azam Doustmohammadian</a>, 
<a href="/search/cs?searchtype=author&query=Zarrabi%2C+H">Houman Zarrabi</a>, 
<a href="/search/cs?searchtype=author&query=Rabiee%2C+H+R">Hamid R. Rabiee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Persian language. Journal of Modelling in Engineering 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">The main goal of this paper is to model the epidemic and flattening the
infection curve of the social networks. Flattening the infection curve implies
slowing down the spread of the disease and reducing the infection rate via
social-distancing, isolation (quarantine) and vaccination. The
nan-pharmaceutical methods are a much simpler and efficient way to control the
spread of epidemic and infection rate. By specifying a target group with high
centrality for isolation and quarantine one can reach a much flatter infection
curve (related to Corona for example) without adding extra costs to health
services. The aim of this research is, first, modeling the epidemic and, then,
giving strategies and structural algorithms for targeted vaccination or
targeted non-pharmaceutical methods for reducing the peak of the viral disease
and flattening the infection curve. These methods are more efficient for
nan-pharmaceutical interventions as finding the target quarantine group
flattens the infection curve much easier. For this purpose, a few number of
particular nodes with high centrality are isolated and the infection curve is
analyzed. Our research shows meaningful results for flattening the infection
curve only by isolating a few number of targeted nodes in the social network.
The proposed methods are independent of the type of the disease and are
effective for any viral disease, e.g., Covid-19.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15230" title="Abstract">arXiv:2311.15230</a> [<a href="/pdf/2311.15230" title="Download PDF">pdf</a>, <a href="/format/2311.15230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GAIA: Zero-shot Talking Avatar Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tianyu He</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Junliang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+R">Runyi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuchi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jialiang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+K">Kaikai An</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Leyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chunyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Han Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">HsiangTao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://microsoft.github.io/GAIA/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Zero-shot talking avatar generation aims at synthesizing natural talking
videos from speech and a single portrait image. Previous methods have relied on
domain-specific heuristics such as warping-based motion representation and 3D
Morphable Models, which limit the naturalness and diversity of the generated
avatars. In this work, we introduce GAIA (Generative AI for Avatar), which
eliminates the domain priors in talking avatar generation. In light of the
observation that the speech only drives the motion of the avatar while the
appearance of the avatar and the background typically remain the same
throughout the entire video, we divide our approach into two stages: 1)
disentangling each frame into motion and appearance representations; 2)
generating motion sequences conditioned on the speech and reference portrait
image. We collect a large-scale high-quality talking avatar dataset and train
the model on it with different scales (up to 2B parameters). Experimental
results verify the superiority, scalability, and flexibility of GAIA as 1) the
resulting model beats previous baseline models in terms of naturalness,
diversity, lip-sync quality, and visual quality; 2) the framework is scalable
since larger models yield better results; 3) it is general and enables
different applications like controllable talking avatar generation and
text-instructed avatar generation.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15231" title="Abstract">arXiv:2311.15231</a> [<a href="/pdf/2311.15231" title="Download PDF">pdf</a>, <a href="/format/2311.15231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Double Reverse Regularization Network Based on Self-Knowledge  Distillation for SAR Object Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhigang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+M">Meiguang Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">In current synthetic aperture radar (SAR) object classification, one of the
major challenges is the severe overfitting issue due to the limited dataset
(few-shot) and noisy data. Considering the advantages of knowledge distillation
as a learned label smoothing regularization, this paper proposes a novel Double
Reverse Regularization Network based on Self-Knowledge Distillation
(DRRNet-SKD). Specifically, through exploring the effect of distillation weight
on the process of distillation, we are inspired to adopt the double reverse
thought to implement an effective regularization network by combining offline
and online distillation in a complementary way. Then, the Adaptive Weight
Assignment (AWA) module is designed to adaptively assign two reverse-changing
weights based on the network performance, allowing the student network to
better benefit from both teachers. The experimental results on OpenSARShip and
FUSAR-Ship demonstrate that DRRNet-SKD exhibits remarkable performance
improvement on classical CNNs, outperforming state-of-the-art self-knowledge
distillation methods.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15238" title="Abstract">arXiv:2311.15238</a> [<a href="/pdf/2311.15238" title="Download PDF">pdf</a>, <a href="/format/2311.15238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning  with General Function Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Heyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiafan He</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Quanquan Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">The exploration-exploitation dilemma has been a central challenge in
reinforcement learning (RL) with complex model classes. In this paper, we
propose a new algorithm, Monotonic Q-Learning with Upper Confidence Bound
(MQL-UCB) for RL with general function approximation. Our key algorithmic
design includes (1) a general deterministic policy-switching strategy that
achieves low switching cost, (2) a monotonic value function structure with
carefully controlled function class complexity, and (3) a variance-weighted
regression scheme that exploits historical trajectories with high data
efficiency. MQL-UCB achieves minimax optimal regret of $\tilde{O}(d\sqrt{HK})$
when $K$ is sufficiently large and near-optimal policy switching cost of
$\tilde{O}(dH)$, with $d$ being the eluder dimension of the function class, $H$
being the planning horizon, and $K$ being the number of episodes.
<br />Our work sheds light on designing provably sample-efficient and
deployment-efficient Q-learning with nonlinear function approximation.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15241" title="Abstract">arXiv:2311.15241</a> [<a href="/pdf/2311.15241" title="Download PDF">pdf</a>, <a href="/format/2311.15241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CalibFormer: A Transformer-based Automatic LiDAR-Camera Calibration  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yuxuan Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yao Li</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+C">Chengzhen Meng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingchen Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanyong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">The fusion of LiDARs and cameras has been increasingly adopted in autonomous
driving for perception tasks. The performance of such fusion-based algorithms
largely depends on the accuracy of sensor calibration, which is challenging due
to the difficulty of identifying common features across different data
modalities. Previously, many calibration methods involved specific targets
and/or manual intervention, which has proven to be cumbersome and costly.
Learning-based online calibration methods have been proposed, but their
performance is barely satisfactory in most cases. These methods usually suffer
from issues such as sparse feature maps, unreliable cross-modality association,
inaccurate calibration parameter regression, etc. In this paper, to address
these issues, we propose CalibFormer, an end-to-end network for automatic
LiDAR-camera calibration. We aggregate multiple layers of camera and LiDAR
image features to achieve high-resolution representations. A multi-head
correlation module is utilized to identify correlations between features more
accurately. Lastly, we employ transformer architectures to estimate accurate
calibration parameters from the correlation information. Our method achieved a
mean translation error of $0.8751 \mathrm{cm}$ and a mean rotation error of
$0.0562 ^{\circ}$ on the KITTI dataset, surpassing existing state-of-the-art
methods and demonstrating strong robustness, accuracy, and generalization
capabilities.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15243" title="Abstract">arXiv:2311.15243</a> [<a href="/pdf/2311.15243" title="Download PDF">pdf</a>, <a href="/format/2311.15243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ID-like Prompt Learning for Few-Shot Out-of-Distribution Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yichen Bai</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zongbo Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Changqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+B">Bing Cao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiaoheng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qinghua Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Out-of-distribution (OOD) detection methods often exploit auxiliary outliers
to train model identifying OOD samples, especially discovering challenging
outliers from auxiliary outliers dataset to improve OOD detection. However,
they may still face limitations in effectively distinguishing between the most
challenging OOD samples that are much like in-distribution (ID) data, i.e.,
ID-like samples. To this end, we propose a novel OOD detection framework that
discovers ID-like outliers using CLIP from the vicinity space of the ID
samples, thus helping to identify these most challenging OOD samples. Then a
prompt learning framework is proposed that utilizes the identified ID-like
outliers to further leverage the capabilities of CLIP for OOD detection.
Benefiting from the powerful CLIP, we only need a small number of ID samples to
learn the prompts of the model without exposing other auxiliary outlier
datasets. By focusing on the most challenging ID-like OOD samples and elegantly
exploiting the capabilities of CLIP, our method achieves superior few-shot
learning performance on various real-world image datasets (e.g., in 4-shot OOD
detection on the ImageNet-1k dataset, our method reduces the average FPR95 by
12.16% and improves the average AUROC by 2.76%, compared to state-of-the-art
methods).
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15249" title="Abstract">arXiv:2311.15249</a> [<a href="/pdf/2311.15249" title="Download PDF">pdf</a>, <a href="/format/2311.15249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithm Evolution Using Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+X">Xialiang Tong</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+M">Mingxuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingfu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Optimization can be found in many real-life applications. Designing an
effective algorithm for a specific optimization problem typically requires a
tedious amount of effort from human experts with domain knowledge and algorithm
design skills. In this paper, we propose a novel approach called Algorithm
Evolution using Large Language Model (AEL). It utilizes a large language model
(LLM) to automatically generate optimization algorithms via an evolutionary
framework. AEL does algorithm-level evolution without model training. Human
effort and requirements for domain knowledge can be significantly reduced. We
take constructive methods for the salesman traveling problem as a test example,
we show that the constructive algorithm obtained by AEL outperforms simple
hand-crafted and LLM-generated heuristics. Compared with other domain deep
learning model-based algorithms, these methods exhibit excellent scalability
across different problem sizes. AEL is also very different from previous
attempts that utilize LLMs as search operators in algorithms.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15250" title="Abstract">arXiv:2311.15250</a> [<a href="/pdf/2311.15250" title="Download PDF">pdf</a>, <a href="/format/2311.15250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rely/Guarantee, Refinement and the ABA Problem: Part 1
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yatapanage%2C+N+P">Nisansala P. Yatapanage</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Rely/guarantee reasoning provides a compositional way of reasoning about
concurrency. The ABA problem occurs in many non-blocking concurrent data
structures, where a change made by a concurrent process may be undetected by
other processes. Guarantee conditions provide a useful mechanism for reasoning
about such changes, as is demonstrated by two non-blocking examples, the
Treiber stack and the Herlihy-Wing queue. The ABA problem can be identified by
the program making a step where the before and after states do not correspond
to a valid step at the sequential level. Therefore, such invalid behaviour
relates to a failure of the guarantee condition. As such behaviour is
non-linearisable, this suggests a strong relationship between refinement with
rely/guarantee and linearisability.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15251" title="Abstract">arXiv:2311.15251</a> [<a href="/pdf/2311.15251" title="Download PDF">pdf</a>, <a href="/ps/2311.15251" title="Download PostScript">ps</a>, <a href="/format/2311.15251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Should I use metaverse or not? An investigation of university students  behavioral intention to use MetaEducation technology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Misirlis%2C+N">Nikolaos Misirlis</a>, 
<a href="/search/cs?searchtype=author&query=Nikolaidis%2C+Y">Yiannis Nikolaidis</a>, 
<a href="/search/cs?searchtype=author&query=Sabidussi%2C+A">Anna Sabidussi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IADIS International Journal on Computer Science and Information
  Systems, 2023, Vol. 18, No. 1, pp. 18-29
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Metaverse, a burgeoning technological trend that combines virtual and
augmented reality, provides users with a fully digital environment where they
can assume a virtual identity through a digital avatar and interact with others
as they were in the real world. Its applications span diverse domains such as
economy (with its entry into the cryptocurrency field), finance, social life,
working environment, healthcare, real estate, and education. During the
COVID-19 and post-COVID-19 era, universities have rapidly adopted e-learning
technologies to provide students with online access to learning content and
platforms, rendering previous considerations on integrating such technologies
or preparing institutional infrastructures virtually obsolete. In light of this
context, the present study proposes a framework for analyzing university
students' acceptance and intention to use metaverse technologies in education,
drawing upon the Technology Acceptance Model (TAM). The study aims to
investigate the relationship between students' intention to use metaverse
technologies in education, hereafter referred to as MetaEducation, and selected
TAM constructs, including Attitude, Perceived Usefulness, Perceived Ease of
Use, Self-efficacy of metaverse technologies in education, and Subjective Norm.
Notably, Self-efficacy and Subjective Norm have a positive influence on
Attitude and Perceived Usefulness, whereas Perceived Ease of Use does not
exhibit a strong correlation with Attitude or Perceived Usefulness. The authors
postulate that the weak associations between the study's constructs may be
attributed to limited knowledge regarding MetaEducation and its potential
benefits. Further investigation and analysis of the study's proposed model are
warranted to comprehensively understand the complex dynamics involved in the
acceptance and utilization of MetaEducation technologies in the realm of higher
education
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15260" title="Abstract">arXiv:2311.15260</a> [<a href="/pdf/2311.15260" title="Download PDF">pdf</a>, <a href="/format/2311.15260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuRAD: Neural Rendering for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tonderski%2C+A">Adam Tonderski</a>, 
<a href="/search/cs?searchtype=author&query=Lindstr%C3%B6m%2C+C">Carl Lindstr&#xf6;m</a>, 
<a href="/search/cs?searchtype=author&query=Hess%2C+G">Georg Hess</a>, 
<a href="/search/cs?searchtype=author&query=Ljungbergh%2C+W">William Ljungbergh</a>, 
<a href="/search/cs?searchtype=author&query=Svensson%2C+L">Lennart Svensson</a>, 
<a href="/search/cs?searchtype=author&query=Petersson%2C+C">Christoffer Petersson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural radiance fields (NeRFs) have gained popularity in the autonomous
driving (AD) community. Recent methods show NeRFs' potential for closed-loop
simulation, enabling testing of AD systems, and as an advanced training data
augmentation technique. However, existing methods often require long training
times, dense semantic supervision, or lack generalizability. This, in turn,
hinders the application of NeRFs for AD at scale. In this paper, we propose
NeuRAD, a robust novel view synthesis method tailored to dynamic AD data. Our
method features simple network design, extensive sensor modeling for both
camera and lidar -- including rolling shutter, beam divergence and ray dropping
-- and is applicable to multiple datasets out of the box. We verify its
performance on five popular AD datasets, achieving state-of-the-art performance
across the board. To encourage further development, we openly release the
NeuRAD source code. See https://github.com/georghess/NeuRAD .
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15262" title="Abstract">arXiv:2311.15262</a> [<a href="/pdf/2311.15262" title="Download PDF">pdf</a>, <a href="/format/2311.15262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revealing Cortical Layers In Histological Brain Images With  Self-Supervised Graph Convolutional Networks Applied To Cell-Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vadori%2C+V">Valentina Vadori</a>, 
<a href="/search/cs?searchtype=author&query=Peruffo%2C+A">Antonella Peruffo</a>, 
<a href="/search/cs?searchtype=author&query=Gra%C3%AFc%2C+J">Jean-Marie Gra&#xef;c</a>, 
<a href="/search/cs?searchtype=author&query=Vadori%2C+G">Giulia Vadori</a>, 
<a href="/search/cs?searchtype=author&query=Finos%2C+L">Livio Finos</a>, 
<a href="/search/cs?searchtype=author&query=Grisan%2C+E">Enrico Grisan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Identifying cerebral cortex layers is crucial for comparative studies of the
cytoarchitecture aiming at providing insights into the relations between brain
structure and function across species. The absence of extensive annotated
datasets typically limits the adoption of machine learning approaches, leading
to the manual delineation of cortical layers by neuroanatomists. We introduce a
self-supervised approach to detect layers in 2D Nissl-stained histological
slices of the cerebral cortex. It starts with the segmentation of individual
cells and the creation of an attributed cell-graph. A self-supervised graph
convolutional network generates cell embeddings that encode morphological and
structural traits of the cellular environment and are exploited by a community
detection algorithm for the final layering. Our method, the first
self-supervised of its kind with no spatial transcriptomics data involved,
holds the potential to accelerate cytoarchitecture analyses, sidestepping
annotation needs and advancing cross-species investigation.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15264" title="Abstract">arXiv:2311.15264</a> [<a href="/pdf/2311.15264" title="Download PDF">pdf</a>, <a href="/format/2311.15264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChAda-ViT : Channel Adaptive Attention for Joint Representation Learning  of Heterogeneous Microscopy Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bourriez%2C+N">Nicolas Bourriez</a>, 
<a href="/search/cs?searchtype=author&query=Bendidi%2C+I">Ihab Bendidi</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+E">Ethan Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Watkinson%2C+G">Gabriel Watkinson</a>, 
<a href="/search/cs?searchtype=author&query=Sanchez%2C+M">Maxime Sanchez</a>, 
<a href="/search/cs?searchtype=author&query=Bollot%2C+G">Guillaume Bollot</a>, 
<a href="/search/cs?searchtype=author&query=Genovesio%2C+A">Auguste Genovesio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Unlike color photography images, which are consistently encoded into RGB
channels, biological images encompass various modalities, where the type of
microscopy and the meaning of each channel varies with each experiment.
Importantly, the number of channels can range from one to a dozen and their
correlation is often comparatively much lower than RGB, as each of them brings
specific information content. This aspect is largely overlooked by methods
designed out of the bioimage field, and current solutions mostly focus on
intra-channel spatial attention, often ignoring the relationship between
channels, yet crucial in most biological applications. Importantly, the
variable channel type and count prevent the projection of several experiments
to a unified representation for large scale pre-training. In this study, we
propose ChAda-ViT, a novel Channel Adaptive Vision Transformer architecture
employing an Inter-Channel Attention mechanism on images with an arbitrary
number, order and type of channels. We also introduce IDRCell100k, a bioimage
dataset with a rich set of 79 experiments covering 7 microscope modalities,
with a multitude of channel types, and channel counts varying from 1 to 10 per
experiment. Our proposed architecture, trained in a self-supervised manner,
outperforms existing approaches in several biologically relevant downstream
tasks. Additionally, it can be used to bridge the gap for the first time
between assays with different microscopes, channel numbers or types by
embedding various image and experimental modalities into a unified biological
image representation. The latter should facilitate interdisciplinary studies
and pave the way for better adoption of deep learning in biological image-based
analyses. Code and Data to be released soon.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15268" title="Abstract">arXiv:2311.15268</a> [<a href="/pdf/2311.15268" title="Download PDF">pdf</a>, <a href="/format/2311.15268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unlearning via Sparse Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+V">Vedant Shah</a>, 
<a href="/search/cs?searchtype=author&query=Tr%C3%A4uble%2C+F">Frederik Tr&#xe4;uble</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+A">Ashish Malik</a>, 
<a href="/search/cs?searchtype=author&query=Larochelle%2C+H">Hugo Larochelle</a>, 
<a href="/search/cs?searchtype=author&query=Mozer%2C+M">Michael Mozer</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+S">Sanjeev Arora</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+A">Anirudh Goyal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Machine \emph{unlearning}, which involves erasing knowledge about a
\emph{forget set} from a trained model, can prove to be costly and infeasible
by existing techniques. We propose a nearly compute-free zero-shot unlearning
technique based on a discrete representational bottleneck. We show that the
proposed technique efficiently unlearns the forget set and incurs negligible
damage to the model's performance on the rest of the data set. We evaluate the
proposed technique on the problem of \textit{class unlearning} using three
datasets: CIFAR-10, CIFAR-100, and LACUNA-100. We compare the proposed
technique to SCRUB, a state-of-the-art approach which uses knowledge
distillation for unlearning. Across all three datasets, the proposed technique
performs as well as, if not better than SCRUB while incurring almost no
computational cost.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15269" title="Abstract">arXiv:2311.15269</a> [<a href="/pdf/2311.15269" title="Download PDF">pdf</a>, <a href="/format/2311.15269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tessel: Boosting Distributed Execution of Large DNN Models via Flexible  Schedule Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhiqi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+Y">Youshan Miao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guanbin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Cheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Saarikivi%2C+O">Olli Saarikivi</a>, 
<a href="/search/cs?searchtype=author&query=Maleki%2C+S">Saeed Maleki</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper is accepted by HPCA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Increasingly complex and diverse deep neural network (DNN) models necessitate
distributing the execution across multiple devices for training and inference
tasks, and also require carefully planned schedules for performance. However,
existing practices often rely on predefined schedules that may not fully
exploit the benefits of emerging diverse model-aware operator placement
strategies. Handcrafting high-efficiency schedules can be challenging due to
the large and varying schedule space. This paper presents Tessel, an automated
system that searches for efficient schedules for distributed DNN training and
inference for diverse operator placement strategies. To reduce search costs,
Tessel leverages the insight that the most efficient schedules often exhibit
repetitive pattern (repetend) across different data inputs. This leads to a
two-phase approach: repetend construction and schedule completion. By exploring
schedules for various operator placement strategies, Tessel significantly
improves both training and inference performance. Experiments with
representative DNN models demonstrate that Tessel achieves up to 5.5x training
performance speedup and up to 38% inference latency reduction.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15273" title="Abstract">arXiv:2311.15273</a> [<a href="/pdf/2311.15273" title="Download PDF">pdf</a>, <a href="/ps/2311.15273" title="Download PostScript">ps</a>, <a href="/format/2311.15273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Intelligent-Detection Network for Handwritten Mathematical Expression  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Ziqi Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5figures, 31st International Conference on Computers in Education
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The use of artificial intelligence technology in education is growing
rapidly, with increasing attention being paid to handwritten mathematical
expression recognition (HMER) by researchers. However, many existing methods
for HMER may fail to accurately read formulas with complex structures, as the
attention results can be inaccurate due to illegible handwriting or large
variations in writing styles. Our proposed Intelligent-Detection Network (IDN)
for HMER differs from traditional encoder-decoder methods by utilizing object
detection techniques. Specifically, we have developed an enhanced YOLOv7
network that can accurately detect both digital and symbolic objects. The
detection results are then integrated into the bidirectional gated recurrent
unit (BiGRU) and the baseline symbol relationship tree (BSRT) to determine the
relationships between symbols and numbers. The experiments demonstrate that the
proposed method outperforms those encoder-decoder networks in recognizing
complex handwritten mathematical expressions. This is due to the precise
detection of symbols and numbers. Our research has the potential to make
valuable contributions to the field of HMER. This could be applied in various
practical scenarios, such as assignment grading in schools and information
entry of paper documents.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15276" title="Abstract">arXiv:2311.15276</a> [<a href="/pdf/2311.15276" title="Download PDF">pdf</a>, <a href="/format/2311.15276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Rehearsal Free Zero Forgetting Continual Learning using  Adaptive Weight Modulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sverdlov%2C+Y">Yonatan Sverdlov</a>, 
<a href="/search/cs?searchtype=author&query=Ullman%2C+S">Shimon Ullman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Artificial neural networks encounter a notable challenge known as continual
learning, which involves acquiring knowledge of multiple tasks over an extended
period. This challenge arises due to the tendency of previously learned weights
to be adjusted to suit the objectives of new tasks, resulting in a phenomenon
called catastrophic forgetting. Most approaches to this problem seek a balance
between maximizing performance on the new tasks and minimizing the forgetting
of previous tasks. In contrast, our approach attempts to maximize the
performance of the new task, while ensuring zero forgetting. This is
accomplished by creating a task-specific modulation parameters for each task.
Only these would be learnable parameters during learning of consecutive tasks.
Through comprehensive experimental evaluations, our model demonstrates superior
performance in acquiring and retaining novel tasks that pose difficulties for
other multi-task models. This emphasizes the efficacy of our approach in
preventing catastrophic forgetting while accommodating the acquisition of new
tasks
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15283" title="Abstract">arXiv:2311.15283</a> [<a href="/pdf/2311.15283" title="Download PDF">pdf</a>, <a href="/format/2311.15283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bias-Variance Trade-off in Physics-Informed Neural Networks with  Randomized Smoothing for High-Dimensional PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zheyuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhouhao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yezhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Karniadakis%2C+G+E">George Em Karniadakis</a>, 
<a href="/search/cs?searchtype=author&query=Kawaguchi%2C+K">Kenji Kawaguchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Dynamical Systems (math.DS); Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
<p class="mathjax">While physics-informed neural networks (PINNs) have been proven effective for
low-dimensional partial differential equations (PDEs), the computational cost
remains a hurdle in high-dimensional scenarios. This is particularly pronounced
when computing high-order and high-dimensional derivatives in the
physics-informed loss. Randomized Smoothing PINN (RS-PINN) introduces Gaussian
noise for stochastic smoothing of the original neural net model, enabling Monte
Carlo methods for derivative approximation, eliminating the need for costly
auto-differentiation. Despite its computational efficiency in high dimensions,
RS-PINN introduces biases in both loss and gradients, negatively impacting
convergence, especially when coupled with stochastic gradient descent (SGD). We
present a comprehensive analysis of biases in RS-PINN, attributing them to the
nonlinearity of the Mean Squared Error (MSE) loss and the PDE nonlinearity. We
propose tailored bias correction techniques based on the order of PDE
nonlinearity. The unbiased RS-PINN allows for a detailed examination of its
pros and cons compared to the biased version. Specifically, the biased version
has a lower variance and runs faster than the unbiased version, but it is less
accurate due to the bias. To optimize the bias-variance trade-off, we combine
the two approaches in a hybrid method that balances the rapid convergence of
the biased version with the high accuracy of the unbiased version. In addition,
we present an enhanced implementation of RS-PINN. Extensive experiments on
diverse high-dimensional PDEs, including Fokker-Planck, HJB, viscous Burgers',
Allen-Cahn, and Sine-Gordon equations, illustrate the bias-variance trade-off
and highlight the effectiveness of the hybrid RS-PINN. Empirical guidelines are
provided for selecting biased, unbiased, or hybrid versions, depending on the
dimensionality and nonlinearity of the specific PDE problem.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15284" title="Abstract">arXiv:2311.15284</a> [<a href="/pdf/2311.15284" title="Download PDF">pdf</a>, <a href="/ps/2311.15284" title="Download PostScript">ps</a>, <a href="/format/2311.15284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Frequency-Domain Version of Willems&#x27; Fundamental Lemma
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Meijer%2C+T+J">T.J. Meijer</a>, 
<a href="/search/eess?searchtype=author&query=Nouwens%2C+S+A+N">S.A.N. Nouwens</a>, 
<a href="/search/eess?searchtype=author&query=Dolk%2C+V+S">V.S. Dolk</a>, 
<a href="/search/eess?searchtype=author&query=Heemels%2C+W+P+M+H">W.P.M.H. Heemels</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Willems' fundamental lemma has recently received an impressive amount of
attention in the (data-driven) control community. In this paper, we formulate a
frequency-domain equivalent of this lemma. In doing so, we bridge the gap
between recent developments in data-driven analysis and control and the
extensive knowledge on non-parametric frequency-domain identification that has
accumulated, particularly in industry, through decades of working with
classical (frequency-domain) control and identification techniques. Our
formulation also allows for the combination of multiple data sets in the sense
that, in the data, multiple input directions may be excited at the same
frequency. We also illustrate the usefulness of our results by demonstrating
how they can be applied to perform frequency-domain-data-driven simulation.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15287" title="Abstract">arXiv:2311.15287</a> [<a href="/pdf/2311.15287" title="Download PDF">pdf</a>, <a href="/ps/2311.15287" title="Download PostScript">ps</a>, <a href="/format/2311.15287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial and Temporal Characteristics of Freight Tours: A Data-Driven  Exploratory Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nadi%2C+A">Ali Nadi</a>, 
<a href="/search/cs?searchtype=author&query=Tavasszy%2C+L">L&#xf3;r&#xe1;nt Tavasszy</a>, 
<a href="/search/cs?searchtype=author&query=van+Lint%2C+J+W+C">J.W.C. van Lint</a>, 
<a href="/search/cs?searchtype=author&query=Snelder%2C+M">Maaike Snelder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">This paper presents a modeling approach to infer scheduling and routing
patterns from digital freight transport activity data for different freight
markets. We provide a complete modeling framework including a new
discrete-continuous decision tree approach for extracting rules from the
freight transport data. We apply these models to collected tour data for the
Netherlands to understand departure time patterns and tour strategies, also
allowing us to evaluate the effectiveness of the proposed algorithm. We find
that spatial and temporal characteristics are important to capture the types of
tours and time-of-day patterns of freight activities. Also, the empirical
evidence indicates that carriers in most of the transport markets are sensitive
to the level of congestion. Many of them adjust the type of tour, departure
time, and the number of stops per tour when facing a congested zone. The
results can be used by practitioners to get more grip on transport markets and
develop freight and traffic management measures.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15290" title="Abstract">arXiv:2311.15290</a> [<a href="/pdf/2311.15290" title="Download PDF">pdf</a>, <a href="/ps/2311.15290" title="Download PostScript">ps</a>, <a href="/format/2311.15290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges in Blockchain as a Solution for IoT Ecosystem Threats and  Access Control: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Avik%2C+S+C">Suranjeet Chowdhury Avik</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+S">Sujit Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Ahad%2C+M+A+R">Md Atiqur Rahaman Ahad</a>, 
<a href="/search/cs?searchtype=author&query=Latif%2C+Z">Zohaib Latif</a>, 
<a href="/search/cs?searchtype=author&query=Alghamdi%2C+A">Abdullah Alghamdi</a>, 
<a href="/search/cs?searchtype=author&query=Abosaq%2C+H">Hamad Abosaq</a>, 
<a href="/search/cs?searchtype=author&query=Bairagi%2C+A+K">Anupam Kumar Bairagi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The Internet of Things (IoT) is increasingly influencing and transforming
various aspects of our daily lives. Contrary to popular belief, it raises
security and privacy issues as it is used to collect data from consumers or
automated systems. Numerous articles are published that discuss issues like
centralised control systems and potential alternatives like integration with
blockchain. Although a few recent surveys focused on the challenges and
solutions facing the IoT ecosystem, most of them did not concentrate on the
threats, difficulties, or blockchain-based solutions. Additionally, none of
them focused on blockchain and IoT integration challenges and attacks. In the
context of the IoT ecosystem, overall security measures are very important to
understand the overall challenges. This article summarises difficulties that
have been outlined in numerous recent articles and articulates various attacks
and security challenges in a variety of approaches, including blockchain-based
solutions and so on. More clearly, this contribution consolidates threats,
access control issues, and remedies in brief. In addition, this research has
listed some attacks on public blockchain protocols with some real-life examples
that can guide researchers in taking preventive measures for IoT use cases.
Finally, a future research direction concludes the research gaps by analysing
contemporary research contributions.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15291" title="Abstract">arXiv:2311.15291</a> [<a href="/pdf/2311.15291" title="Download PDF">pdf</a>, <a href="/format/2311.15291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Obj-NeRF: Extract Object NeRFs from Multi-view Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Lihe Ding</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+T">Tianfan Xue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural Radiance Fields (NeRFs) have demonstrated remarkable effectiveness in
novel view synthesis within 3D environments. However, extracting a radiance
field of one specific object from multi-view images encounters substantial
challenges due to occlusion and background complexity, thereby presenting
difficulties in downstream applications such as NeRF editing and 3D mesh
extraction. To solve this problem, in this paper, we propose Obj-NeRF, a
comprehensive pipeline that recovers the 3D geometry of a specific object from
multi-view images using a single prompt. This method combines the 2D
segmentation capabilities of the Segment Anything Model (SAM) in conjunction
with the 3D reconstruction ability of NeRF. Specifically, we first obtain
multi-view segmentation for the indicated object using SAM with a single
prompt. Then, we use the segmentation images to supervise NeRF construction,
integrating several effective techniques. Additionally, we construct a large
object-level NeRF dataset containing diverse objects, which can be useful in
various downstream tasks. To demonstrate the practicality of our method, we
also apply Obj-NeRF to various applications, including object removal,
rotation, replacement, and recoloring.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15292" title="Abstract">arXiv:2311.15292</a> [<a href="/pdf/2311.15292" title="Download PDF">pdf</a>, <a href="/format/2311.15292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active-Sensing-Based Beam Alignment for Near Field MIMO Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaolin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanwei Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">An active-sensing-based learning algorithm is proposed to solve the
near-field beam alignment problem with the aid of wavenumber-domain transform
matrices (WTMs). Specifically, WTMs can transform the antenna-domain channel
into a sparse representation in the wavenumber domain. The dimensions of WTMs
can be further reduced by exploiting the dominance of line-of-sight (LoS)
links. By employing these lower-dimensional WTMs as mapping functions, the
active-sensing-based algorithm is executed in the wavenumber domain, resulting
in an acceleration of convergence. Compared with the codebook-based beam
alignment methods, the proposed method finds the optimal beam pair in a
ping-pong fashion, thus avoiding high training overheads caused by beam
sweeping. Finally, the numerical results validate the effectiveness of the
proposed method.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15293" title="Abstract">arXiv:2311.15293</a> [<a href="/pdf/2311.15293" title="Download PDF">pdf</a>, <a href="/format/2311.15293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Student&#x27;s Interests Related to Web and Mobile Technologies Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Petrescu%2C+M">Manuela Petrescu</a>, 
<a href="/search/cs?searchtype=author&query=Sterca%2C+A">Adrian Sterca</a>, 
<a href="/search/cs?searchtype=author&query=Badarinza%2C+I">Ioan Badarinza</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of the 19th International Conference on Web
  Information Systems and Technologies - WEBIST ; ISBN 978-989-758-672-9; ISSN
  2184-3252, SciTePress, pages 242-249,2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Programming Languages (cs.PL); Software Engineering (cs.SE)

</div>
<p class="mathjax">We explore in this paper the interests and challenges of students regarding
web and mobile technologies. Our study is based on a survey among undergraduate
students, students that attend a Web Programming course. In particular, we
study the challenges students have in following a successful career in web or
mobile development and we have found that the most important one is the large
effort required for keeping up to date with the fast changing web and mobile
technologies. Overall, the attitude of the surveyed undergraduate students
towards web development and mobile development is rather positive, as more than
60% of them said that they are interested in a career in web or mobile
development. We also found out that most of them prefer working on back-end web
technologies. As for the specific web technologies students are interested on,
they are highly varied. Overall, our study provides valuable insights into the
interests and challenges of students regarding web and mobile technologies,
which can guide the development of effective teaching and learning approaches
in this area.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15294" title="Abstract">arXiv:2311.15294</a> [<a href="/pdf/2311.15294" title="Download PDF">pdf</a>, <a href="/format/2311.15294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study of Partisan News Sharing in the Russian invasion of Ukraine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yiming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Haq%2C+E">Ehsan-Ul Haq</a>, 
<a href="/search/cs?searchtype=author&query=Tyson%2C+G">Gareth Tyson</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+L">Lik-Hang Lee</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+P">Pan Hui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Since the Russian invasion of Ukraine, a large volume of biased and partisan
news has been spread via social media platforms. As this may lead to wider
societal issues, we argue that understanding how partisan news sharing impacts
users' communication is crucial for better governance of online communities. In
this paper, we perform a measurement study of partisan news sharing. We aim to
characterize the role of such sharing in influencing users' communications. Our
analysis covers an eight-month dataset across six Reddit communities related to
the Russian invasion. We first perform an analysis of the temporal evolution of
partisan news sharing. We confirm that the invasion stimulates discussion in
the observed communities, accompanied by an increased volume of partisan news
sharing. Next, we characterize users' response to such sharing. We observe that
partisan bias plays a role in narrowing its propagation. More biased media is
less likely to be spread across multiple subreddits. However, we find that
partisan news sharing attracts more users to engage in the discussion, by
generating more comments. We then built a predictive model to identify users
likely to spread partisan news. The prediction is challenging though, with
61.57% accuracy on average. Our centrality analysis on the commenting network
further indicates that the users who disseminate partisan news possess lower
network influence in comparison to those who propagate neutral news.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15296" title="Abstract">arXiv:2311.15296</a> [<a href="/pdf/2311.15296" title="Download PDF">pdf</a>, <a href="/format/2311.15296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UHGEval: Benchmarking the Hallucination of Chinese Large Language Models  via Unconstrained Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xun Liang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shichao Song</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+S">Simin Niu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+F">Feiyu Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+B">Bo Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wy%2C+Z">Zhaohui Wy</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+D">Dawei He</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Peng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhonghao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+H">Haiying Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 Pages, submitted to ICDE2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have emerged as pivotal contributors in
contemporary natural language processing and are increasingly being applied
across a diverse range of industries. However, these large-scale probabilistic
statistical models cannot currently ensure the requisite quality in
professional content generation. These models often produce hallucinated text,
compromising their practical utility in professional contexts. To assess the
authentic reliability of LLMs in text generation, numerous initiatives have
developed benchmark evaluations for hallucination phenomena. Nevertheless,
these benchmarks frequently utilize constrained generation techniques due to
cost and temporal constraints. These techniques encompass the use of directed
hallucination induction and strategies that deliberately alter authentic text
to produce hallucinations. These approaches are not congruent with the
unrestricted text generation demanded by real-world applications. Furthermore,
a well-established Chinese-language dataset dedicated to the evaluation of
hallucinations in text generation is presently lacking. Consequently, we have
developed an Unconstrained Hallucination Generation Evaluation (UHGEval)
benchmark, designed to compile outputs produced with minimal restrictions by
LLMs. Concurrently, we have established a comprehensive benchmark evaluation
framework to aid subsequent researchers in undertaking scalable and
reproducible experiments. We have also executed extensive experiments,
evaluating prominent Chinese language models and the GPT series models to
derive professional performance insights regarding hallucination challenges.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15297" title="Abstract">arXiv:2311.15297</a> [<a href="/pdf/2311.15297" title="Download PDF">pdf</a>, <a href="/format/2311.15297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controllable Expensive Multi-objective Optimization with Warm-starting  Gaussian Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q">Quang-Huy Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+L+P">Long P. Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Viet%2C+H+V">Hoang V. Viet</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+D+D">Dung D. Le</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Pareto Set Learning (PSL) is a promising approach for approximating the
entire Pareto front in multi-objective optimization (MOO) problems. However,
existing derivative-free PSL methods are often unstable and inefficient,
especially for expensive black-box MOO problems where objective function
evaluations are costly. In this work, we propose to address the instability and
inefficiency of existing PSL methods with a novel controllable PSL method,
called Co-PSL. Particularly, Co-PSL consists of two stages: (1) warm-starting
Bayesian optimization to obtain quality Gaussian Processes priors and (2)
controllable Pareto set learning to accurately acquire a parametric mapping
from preferences to the corresponding Pareto solutions. The former is to help
stabilize the PSL process and reduce the number of expensive function
evaluations. The latter is to support real-time trade-off control between
conflicting objectives. Performances across synthesis and real-world MOO
problems showcase the effectiveness of our Co-PSL for expensive multi-objective
optimization tasks.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15298" title="Abstract">arXiv:2311.15298</a> [<a href="/pdf/2311.15298" title="Download PDF">pdf</a>, <a href="/ps/2311.15298" title="Download PostScript">ps</a>, <a href="/format/2311.15298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Data-driven and multi-agent decision support system for time slot  management at container terminals: A case study for the Port of Rotterdam
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nadi%2C+A">Ali Nadi</a>, 
<a href="/search/cs?searchtype=author&query=Snelder%2C+M">Maaike Snelder</a>, 
<a href="/search/cs?searchtype=author&query=van+Lint%2C+J+W+C">J.W.C. van Lint</a>, 
<a href="/search/cs?searchtype=author&query=Tavasszy%2C+L">L&#xf3;r&#xe1;nt Tavasszy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Controlling the departure time of the trucks from a container hub is
important to both the traffic and the logistics systems. This, however,
requires an intelligent decision support system that can control and manage
truck arrival times at terminal gates. This paper introduces an integrated
model that can be used to understand, predict, and control logistics and
traffic interactions in the port-hinterland ecosystem. This approach is
context-aware and makes use of big historical data to predict system states and
apply control policies accordingly, on truck inflow and outflow. The control
policies ensure multiple stakeholders satisfaction including those of trucking
companies, terminal operators, and road traffic agencies. The proposed method
consists of five integrated modules orchestrated to systematically steer
truckers toward choosing those time slots that are expected to result in lower
gate waiting times and more cost-effective schedules. The simulation is
supported by real-world data and shows that significant gains can be obtained
in the system.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15299" title="Abstract">arXiv:2311.15299</a> [<a href="/pdf/2311.15299" title="Download PDF">pdf</a>, <a href="/ps/2311.15299" title="Download PostScript">ps</a>, <a href="/format/2311.15299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Covariance-Based Activity Detection in Cooperative Multi-Cell Massive  MIMO: Scaling Law and Efficient Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Ya-Feng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaorui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wei Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 54 pages, 11 figures, submitted for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP); Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper focuses on the covariance-based activity detection problem in a
multi-cell massive multiple-input multiple-output (MIMO) system. In this
system, active devices transmit their signature sequences to multiple base
stations (BSs), and the BSs cooperatively detect the active devices based on
the received signals. While the scaling law for the covariance-based activity
detection in the single-cell scenario has been extensively analyzed in the
literature, this paper aims to analyze the scaling law for the covariance-based
activity detection in the multi-cell massive MIMO system. Specifically, this
paper demonstrates a quadratic scaling law in the multi-cell system, under the
assumption that the exponent in the classical path-loss model is greater than
2. This finding shows that, in the multi-cell MIMO system, the maximum number
of active devices that can be detected correctly in each cell increases
quadratically with the length of the signature sequence and decreases
logarithmically with the number of cells (as the number of antennas tends to
infinity). Moreover, in addition to analyzing the scaling law for the signature
sequences randomly and uniformly distributed on a sphere, the paper also
establishes the scaling law for signature sequences generated from a finite
alphabet, which are easier to generate and store. Moreover, this paper proposes
two efficient accelerated coordinate descent (CD) algorithms with a convergence
guarantee for solving the device activity detection problem. The first
algorithm reduces the complexity of CD by using an inexact coordinate update
strategy. The second algorithm avoids unnecessary computations of CD by using
an active set selection strategy. Simulation results show that the proposed
algorithms exhibit excellent performance in terms of computational efficiency
and detection error probability.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15303" title="Abstract">arXiv:2311.15303</a> [<a href="/pdf/2311.15303" title="Download PDF">pdf</a>, <a href="/format/2311.15303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concept Distillation: Leveraging Human-Centered Explanations for Model  Improvement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Avani Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Saini%2C+S">Saurabh Saini</a>, 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+P+J">P J Narayanan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Neurips 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Humans use abstract concepts for understanding instead of hard features.
Recent interpretability research has focused on human-centered concept
explanations of neural networks. Concept Activation Vectors (CAVs) estimate a
model's sensitivity and possible biases to a given concept. In this paper, we
extend CAVs from post-hoc analysis to ante-hoc training in order to reduce
model bias through fine-tuning using an additional Concept Loss. Concepts were
defined on the final layer of the network in the past. We generalize it to
intermediate layers using class prototypes. This facilitates class learning in
the last convolution layer, which is known to be most informative. We also
introduce Concept Distillation to create richer concepts using a pre-trained
knowledgeable model as the teacher. Our method can sensitize or desensitize a
model towards concepts. We show applications of concept-sensitive training to
debias several classification problems. We also use concepts to induce prior
knowledge into IID, a reconstruction problem. Concept-sensitive training can
improve model interpretability, reduce biases, and induce prior knowledge.
Please visit https://avani17101.github.io/Concept-Distilllation/ for code and
more details.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15304" title="Abstract">arXiv:2311.15304</a> [<a href="/pdf/2311.15304" title="Download PDF">pdf</a>, <a href="/format/2311.15304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Singular layer Physics Informed Neural Network method for Plane Parallel  Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chang%2C+T">Teng-Yuan Chang</a>, 
<a href="/search/math?searchtype=author&query=Gie%2C+G">Gung-Min Gie</a>, 
<a href="/search/math?searchtype=author&query=Hong%2C+Y">Youngjoon Hong</a>, 
<a href="/search/math?searchtype=author&query=Jung%2C+C">Chang-Yeol Jung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We construct in this article the semi-analytic Physics Informed Neural
Networks (PINNs), called {\em singular layer PINNs} (or {\em sl-PINNs}), that
are suitable to predict the stiff solutions of plane-parallel flows at a small
viscosity. Recalling the boundary layer analysis, we first find the corrector
for the problem which describes the singular behavior of the viscous flow
inside boundary layers. Then, using the components of the corrector and its
curl, we build our new {\em sl-PINN} predictions for the velocity and the
vorticity by either embedding the explicit expression of the corrector (or its
curl) in the structure of PINNs or by training the implicit parts of the
corrector (or its curl) together with the PINN predictions. Numerical
experiments confirm that our new {\em sl-PINNs} produce stable and accurate
predicted solutions for the plane-parallel flows at a small viscosity.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15306" title="Abstract">arXiv:2311.15306</a> [<a href="/pdf/2311.15306" title="Download PDF">pdf</a>, <a href="/format/2311.15306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sketch Video Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yudian Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Cun%2C+X">Xiaodong Cun</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+M">Menghan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Pun%2C+C">Chi-Man Pun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Webpage: <a href="https://sketchvideo.github.io/">this https URL</a> Github: <a href="https://github.com/yudianzheng/SketchVideo">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Understanding semantic intricacies and high-level concepts is essential in
image sketch generation, and this challenge becomes even more formidable when
applied to the domain of videos. To address this, we propose a novel
optimization-based framework for sketching videos represented by the frame-wise
B\'ezier curve. In detail, we first propose a cross-frame stroke initialization
approach to warm up the location and the width of each curve. Then, we optimize
the locations of these curves by utilizing a semantic loss based on CLIP
features and a newly designed consistency loss using the self-decomposed 2D
atlas network. Built upon these design elements, the resulting sketch video
showcases impressive visual abstraction and temporal coherence. Furthermore, by
transforming a video into SVG lines through the sketching process, our method
unlocks applications in sketch-based video editing and video doodling, enabled
through video composition, as exemplified in the teaser.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15308" title="Abstract">arXiv:2311.15308</a> [<a href="/pdf/2311.15308" title="Download PDF">pdf</a>, <a href="/format/2311.15308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AV-Deepfake1M: A Large-Scale LLM-Driven Audio-Visual Deepfake Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhixi Cai</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Shreya Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Adatia%2C+A+P">Aman Pankaj Adatia</a>, 
<a href="/search/cs?searchtype=author&query=Hayat%2C+M">Munawar Hayat</a>, 
<a href="/search/cs?searchtype=author&query=Dhall%2C+A">Abhinav Dhall</a>, 
<a href="/search/cs?searchtype=author&query=Stefanov%2C+K">Kalin Stefanov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The detection and localization of highly realistic deepfake audio-visual
content are challenging even for the most advanced state-of-the-art methods.
While most of the research efforts in this domain are focused on detecting
high-quality deepfake images and videos, only a few works address the problem
of the localization of small segments of audio-visual manipulations embedded in
real videos. In this research, we emulate the process of such content
generation and propose the AV-Deepfake1M dataset. The dataset contains
content-driven (i) video manipulations, (ii) audio manipulations, and (iii)
audio-visual manipulations for more than 2K subjects resulting in a total of
more than 1M videos. The paper provides a thorough description of the proposed
data generation pipeline accompanied by a rigorous analysis of the quality of
the generated data. The comprehensive benchmark of the proposed dataset
utilizing state-of-the-art deepfake detection and localization methods
indicates a significant drop in performance compared to previous datasets. The
proposed dataset will play a vital role in building the next-generation
deepfake localization methods. The dataset and associated code are available at
https://github.com/ControlNet/AV-Deepfake1M .
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15310" title="Abstract">arXiv:2311.15310</a> [<a href="/pdf/2311.15310" title="Download PDF">pdf</a>, <a href="/format/2311.15310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure and Verifiable Data Collaboration with Low-Cost Zero-Knowledge  Proofs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yizheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuncheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhaojing Luo</a>, 
<a href="/search/cs?searchtype=author&query=Ooi%2C+B+C">Beng Chin Ooi</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xiaokui Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Databases (cs.DB); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Organizations are increasingly recognizing the value of data collaboration
for data analytics purposes. Yet, stringent data protection laws prohibit the
direct exchange of raw data. To facilitate data collaboration, federated
Learning (FL) emerges as a viable solution, which enables multiple clients to
collaboratively train a machine learning (ML) model under the supervision of a
central server while ensuring the confidentiality of their raw data. However,
existing studies have unveiled two main risks: (i) the potential for the server
to infer sensitive information from the client's uploaded updates (i.e., model
gradients), compromising client input privacy, and (ii) the risk of malicious
clients uploading malformed updates to poison the FL model, compromising input
integrity. Recent works utilize secure aggregation with zero-knowledge proofs
(ZKP) to guarantee input privacy and integrity in FL. Nevertheless, they suffer
from extremely low efficiency and, thus, are impractical for real deployment.
In this paper, we propose a novel and highly efficient solution RiseFL for
secure and verifiable data collaboration, ensuring input privacy and integrity
simultaneously.Firstly, we devise a probabilistic integrity check method that
significantly reduces the cost of ZKP generation and verification. Secondly, we
design a hybrid commitment scheme to satisfy Byzantine robustness with improved
performance. Thirdly, we theoretically prove the security guarantee of the
proposed solution. Extensive experiments on synthetic and real-world datasets
suggest that our solution is effective and is highly efficient in both client
computation and communication. For instance, RiseFL is up to 28x, 53x and 164x
faster than three state-of-the-art baselines ACORN, RoFL and EIFFeL for the
client computation.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15316" title="Abstract">arXiv:2311.15316</a> [<a href="/pdf/2311.15316" title="Download PDF">pdf</a>, <a href="/format/2311.15316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Empathetic and Emotion Support Dialogue Generation with  Prophetic Commonsense Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lanrui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiangnan Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chenxu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiping Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The interest in Empathetic and Emotional Support conversations among the
public has significantly increased. To offer more sensitive and understanding
responses, leveraging commonsense knowledge has become a common strategy to
better understand psychological aspects and causality. However, such
commonsense inferences can be out of context and unable to predict upcoming
dialogue themes, resulting in responses that lack coherence and empathy. To
remedy this issue, we present Prophetic Commonsense Inference, an innovative
paradigm for inferring commonsense knowledge. By harnessing the capabilities of
Large Language Models in understanding dialogue and making commonsense
deductions, we train tunable models to bridge the gap between past and
potential future dialogues. Extensive experiments conducted on
EmpatheticDialogues and Emotion Support Conversation show that equipping
dialogue agents with our proposed prophetic commonsense inference significantly
enhances the quality of their responses.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15317" title="Abstract">arXiv:2311.15317</a> [<a href="/pdf/2311.15317" title="Download PDF">pdf</a>, <a href="/format/2311.15317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Graph Prompt: Toward a Unification of Pre-Training and  Downstream Tasks on Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xingtong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zemin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sihong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinming Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages. Under review. arXiv admin note: substantial text overlap with <a href="/abs/2302.08043">arXiv:2302.08043</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph neural networks have emerged as a powerful tool for graph
representation learning, but their performance heavily relies on abundant
task-specific supervision. To reduce labeling requirement, the "pre-train,
prompt" paradigms have become increasingly common. However, existing study of
prompting on graphs is limited, lacking a universal treatment to appeal to
different downstream tasks. In this paper, we propose GraphPrompt, a novel
pre-training and prompting framework on graphs. GraphPrompt not only unifies
pre-training and downstream tasks into a common task template but also employs
a learnable prompt to assist a downstream task in locating the most relevant
knowledge from the pre-trained model in a task-specific manner. To further
enhance GraphPrompt in these two stages, we extend it into GraphPrompt+ with
two major enhancements. First, we generalize several popular graph pre-training
tasks beyond simple link prediction to broaden the compatibility with our task
template. Second, we propose a more generalized prompt design that incorporates
a series of prompt vectors within every layer of the pre-trained graph encoder,
in order to capitalize on the hierarchical information across different layers
beyond just the readout layer. Finally, we conduct extensive experiments on
five public datasets to evaluate and analyze GraphPrompt and GraphPrompt+.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15320" title="Abstract">arXiv:2311.15320</a> [<a href="/pdf/2311.15320" title="Download PDF">pdf</a>, <a href="/format/2311.15320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Coarse Propagators in Parareal Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jin%2C+B">Bangti Jin</a>, 
<a href="/search/math?searchtype=author&query=Lin%2C+Q">Qingle Lin</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+Z">Zhi Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The parareal algorithm represents an important class of parallel-in-time
algorithms for solving evolution equations and has been widely applied in
practice. To achieve effective speedup, the choice of the coarse propagator in
the algorithm is vital. In this work, we investigate the use of learned coarse
propagators. Building upon the error estimation framework, we present a
systematic procedure for constructing coarse propagators that enjoy desirable
stability and consistent order. Additionally, we provide preliminary
mathematical guarantees for the resulting parareal algorithm. Numerical
experiments on a variety of settings, e.g., linear diffusion model, Allen-Cahn
model, and viscous Burgers model, show that learning can significantly improve
parallel efficiency when compared with the more ad hoc choice of some
conventional and widely used coarse propagators.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15326" title="Abstract">arXiv:2311.15326</a> [<a href="/pdf/2311.15326" title="Download PDF">pdf</a>, <a href="/format/2311.15326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightweight Face Recognition: An Improved MobileFaceNet Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hassanpour%2C+A">Ahmad Hassanpour</a>, 
<a href="/search/cs?searchtype=author&query=Kowsari%2C+Y">Yasamin Kowsari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents an extensive exploration and comparative analysis of
lightweight face recognition (FR) models, specifically focusing on
MobileFaceNet and its modified variant, MMobileFaceNet. The need for efficient
FR models on devices with limited computational resources has led to the
development of models with reduced memory footprints and computational demands
without sacrificing accuracy. Our research delves into the impact of dataset
selection, model architecture, and optimization algorithms on the performance
of FR models. We highlight our participation in the EFaR-2023 competition,
where our models showcased exceptional performance, particularly in categories
restricted by the number of parameters. By employing a subset of the Webface42M
dataset and integrating sharpness-aware minimization (SAM) optimization, we
achieved significant improvements in accuracy across various benchmarks,
including those that test for cross-pose, cross-age, and cross-ethnicity
performance. The results underscore the efficacy of our approach in crafting
models that are not only computationally efficient but also maintain high
accuracy in diverse conditions.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15327" title="Abstract">arXiv:2311.15327</a> [<a href="/pdf/2311.15327" title="Download PDF">pdf</a>, <a href="/ps/2311.15327" title="Download PostScript">ps</a>, <a href="/format/2311.15327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FRAC-Q-Learning: A Reinforcement Learning with Boredom Avoidance  Processes for Social Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Onishi%2C+A">Akinari Onishi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">The reinforcement learning algorithms have often been applied to social
robots. However, most reinforcement learning algorithms were not optimized for
the use of social robots, and consequently they may bore users. We proposed a
new reinforcement learning method specialized for the social robot, the
FRAC-Q-learning, that can avoid user boredom. The proposed algorithm consists
of a forgetting process in addition to randomizing and categorizing processes.
This study evaluated interest and boredom hardness scores of the
FRAC-Q-learning by a comparison with the traditional Q-learning. The
FRAC-Q-learning showed significantly higher trend of interest score, and
indicated significantly harder to bore users compared to the traditional
Q-learning. Therefore, the FRAC-Q-learning can contribute to develop a social
robot that will not bore users. The proposed algorithm can also find
applications in Web-based communication and educational systems. This paper
presents the entire process, detailed implementation and a detailed evaluation
method of the of the FRAC-Q-learning for the first time.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15330" title="Abstract">arXiv:2311.15330</a> [<a href="/pdf/2311.15330" title="Download PDF">pdf</a>, <a href="/format/2311.15330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Combinatorial Path Finding with Heterogeneous Task Duration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuanhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hesheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhongqiang Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Multi-Agent Combinatorial Path Finding (MCPF) seeks collision-free paths for
multiple agents from their initial locations to destinations, visiting a set of
intermediate target locations in the middle of the paths, while minimizing the
sum of arrival times. While a few approaches have been developed to handle
MCPF, most of them simply direct the agent to visit the targets without
considering the task duration, i.e., the amount of time needed for an agent to
execute the task (such as picking an item) at a target location. MCPF is
NP-hard to solve to optimality, and the inclusion of task duration further
complicates the problem. This paper investigates heterogeneous task duration,
where the duration can be different with respect to both the agents and
targets. We develop two methods, where the first method post-processes the
paths planned by any MCPF planner to include the task duration and has no
solution optimality guarantee; and the second method considers task duration
during planning and is able to ensure solution optimality. The numerical and
simulation results show that our methods can handle up to 20 agents and 50
targets in the presence of task duration, and can execute the paths subject to
robot motion disturbance.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15331" title="Abstract">arXiv:2311.15331</a> [<a href="/pdf/2311.15331" title="Download PDF">pdf</a>, <a href="/format/2311.15331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How much data do I need? A case study on medical data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cengiz%2C+A+B">Ayse Betul Cengiz</a>, 
<a href="/search/cs?searchtype=author&query=McGough%2C+A+S">A. Stephen McGough</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The collection of data to train a Deep Learning network is costly in terms of
effort and resources. In many cases, especially in a medical context, it may
have detrimental impacts. Such as requiring invasive medical procedures or
processes which could in themselves cause medical harm. However, Deep Learning
is seen as a data hungry method. Here, we look at two commonly held adages i)
more data gives better results and ii) transfer learning will aid you when you
don't have enough data. These are widely assumed to be true and used as
evidence for choosing how to solve a problem when Deep Learning is involved. We
evaluate six medical datasets and six general datasets. Training a ResNet18
network on varying subsets of these datasets to evaluate `more data gives
better results'. We take eleven of these datasets as the sources for Transfer
Learning on subsets of the twelfth dataset -- Chest -- in order to determine
whether Transfer Learning is universally beneficial. We go further to see
whether multi-stage Transfer Learning provides a consistent benefit. Our
analysis shows that the real situation is more complex than these simple adages
-- more data could lead to a case of diminishing returns and an incorrect
choice of dataset for transfer learning can lead to worse performance, with
datasets which we would consider highly similar to the Chest dataset giving
worse results than datasets which are more dissimilar. Multi-stage transfer
learning likewise reveals complex relationships between datasets.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15332" title="Abstract">arXiv:2311.15332</a> [<a href="/pdf/2311.15332" title="Download PDF">pdf</a>, <a href="/ps/2311.15332" title="Download PostScript">ps</a>, <a href="/format/2311.15332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ASI: Accuracy-Stability Index for Evaluating Deep Learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+W">Wei Dai</a>, 
<a href="/search/cs?searchtype=author&query=Berleant%2C+D">Daniel Berleant</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Information Theory (cs.IT); Performance (cs.PF)

</div>
<p class="mathjax">In the context of deep learning research, where model introductions
continually occur, the need for effective and efficient evaluation remains
paramount. Existing methods often emphasize accuracy metrics, overlooking
stability. To address this, the paper introduces the Accuracy-Stability Index
(ASI), a quantitative measure incorporating both accuracy and stability for
assessing deep learning models. Experimental results demonstrate the
application of ASI, and a 3D surface model is presented for visualizing ASI,
mean accuracy, and coefficient of variation. This paper addresses the important
issue of quantitative benchmarking metrics for deep learning models, providing
a new approach for accurately evaluating accuracy and stability of deep
learning models. The paper concludes with discussions on potential weaknesses
and outlines future research directions.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15335" title="Abstract">arXiv:2311.15335</a> [<a href="/pdf/2311.15335" title="Download PDF">pdf</a>, <a href="/format/2311.15335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Token Recycling for Efficient Sequential Inference with Vision  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Olszewski%2C+J">Jan Olszewski</a>, 
<a href="/search/cs?searchtype=author&query=Rymarczyk%2C+D">Dawid Rymarczyk</a>, 
<a href="/search/cs?searchtype=author&query=W%C3%B3jcik%2C+P">Piotr W&#xf3;jcik</a>, 
<a href="/search/cs?searchtype=author&query=Pach%2C+M">Mateusz Pach</a>, 
<a href="/search/cs?searchtype=author&query=Zieli%C5%84ski%2C+B">Bartosz Zieli&#x144;ski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The code will be released upon acceptance
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Vision Transformers (ViTs) overpass Convolutional Neural Networks in
processing incomplete inputs because they do not require the imputation of
missing values. Therefore, ViTs are well suited for sequential decision-making,
e.g. in the Active Visual Exploration problem. However, they are
computationally inefficient because they perform a full forward pass each time
a piece of new sequential information arrives.
<br />To reduce this computational inefficiency, we introduce the TOken REcycling
(TORE) modification for the ViT inference, which can be used with any
architecture. TORE divides ViT into two parts, iterator and aggregator. An
iterator processes sequential information separately into midway tokens, which
are cached. The aggregator processes midway tokens jointly to obtain the
prediction. This way, we can reuse the results of computations made by
iterator.
<br />Except for efficient sequential inference, we propose a complementary
training policy, which significantly reduces the computational burden
associated with sequential decision-making while achieving state-of-the-art
accuracy.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15339" title="Abstract">arXiv:2311.15339</a> [<a href="/pdf/2311.15339" title="Download PDF">pdf</a>, <a href="/format/2311.15339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Purification of Information Masking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sitong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+Z">Zhichao Lian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuangquan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Liang Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Adversarial attacks meticulously generate minuscule, imperceptible
perturbations to images to deceive neural networks. Counteracting these,
adversarial purification methods seek to transform adversarial input samples
into clean output images to defend against adversarial attacks. Nonetheless,
extent generative models fail to effectively eliminate adversarial
perturbations, yielding less-than-ideal purification results. We emphasize the
potential threat of residual adversarial perturbations to target models,
quantitatively establishing a relationship between perturbation scale and
attack capability. Notably, the residual perturbations on the purified image
primarily stem from the same-position patch and similar patches of the
adversarial sample. We propose a novel adversarial purification approach named
Information Mask Purification (IMPure), aims to extensively eliminate
adversarial perturbations. To obtain an adversarial sample, we first mask part
of the patches information, then reconstruct the patches to resist adversarial
perturbations from the patches. We reconstruct all patches in parallel to
obtain a cohesive image. Then, in order to protect the purified samples against
potential similar regional perturbations, we simulate this risk by randomly
mixing the purified samples with the input samples before inputting them into
the feature extraction network. Finally, we establish a combined constraint of
pixel loss and perceptual loss to augment the model's reconstruction
adaptability. Extensive experiments on the ImageNet dataset with three
classifier models demonstrate that our approach achieves state-of-the-art
results against nine adversarial attack methods. Implementation code and
pre-trained weights can be accessed at
\textcolor{blue}{https://github.com/NoWindButRain/IMPure}.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15341" title="Abstract">arXiv:2311.15341</a> [<a href="/pdf/2311.15341" title="Download PDF">pdf</a>, <a href="/format/2311.15341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Modelling of Stochastic Actions with Arbitrary Constraints in  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Changyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Karunasena%2C+R">Ramesha Karunasena</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+H">Thanh Hong Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+A">Arunesh Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Varakantham%2C+P">Pradeep Varakantham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in NeurIPS 2023. Website: <a href="https://cameron-chen.github.io/flow-iar/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Many problems in Reinforcement Learning (RL) seek an optimal policy with
large discrete multidimensional yet unordered action spaces; these include
problems in randomized allocation of resources such as placements of multiple
security resources and emergency response units, etc. A challenge in this
setting is that the underlying action space is categorical (discrete and
unordered) and large, for which existing RL methods do not perform well.
Moreover, these problems require validity of the realized action (allocation);
this validity constraint is often difficult to express compactly in a closed
mathematical form. The allocation nature of the problem also prefers stochastic
optimal policies, if one exists. In this work, we address these challenges by
(1) applying a (state) conditional normalizing flow to compactly represent the
stochastic policy -- the compactness arises due to the network only producing
one sampled action and the corresponding log probability of the action, which
is then used by an actor-critic method; and (2) employing an invalid action
rejection method (via a valid action oracle) to update the base policy. The
action rejection is enabled by a modified policy gradient that we derive.
Finally, we conduct extensive experiments to show the scalability of our
approach compared to prior methods and the ability to enforce arbitrary
state-conditional constraints on the support of the distribution of actions in
any state.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15343" title="Abstract">arXiv:2311.15343</a> [<a href="/pdf/2311.15343" title="Download PDF">pdf</a>, <a href="/format/2311.15343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BDD for Complete Characterization of a Safety Violation in Linear  Systems with Inputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Goyal%2C+M">Manish Goyal</a>, 
<a href="/search/eess?searchtype=author&query=Bergman%2C+D">David Bergman</a>, 
<a href="/search/eess?searchtype=author&query=Duggirala%2C+P+S">Parasara Sridhar Duggirala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 5 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">The control design tools for linear systems typically involves pole placement
and computing Lyapunov functions which are useful for ensuring stability. But
given higher requirements on control design, a designer is expected to satisfy
other specification such as safety or temporal logic specification as well, and
a naive control design might not satisfy such specification. A control designer
can employ model checking as a tool for checking safety and obtain a
counterexample in case of a safety violation. While several scalable techniques
for verification have been developed for safety verification of linear
dynamical systems, such tools merely act as decision procedures to evaluate
system safety and, consequently, yield a counterexample as an evidence to
safety violation. However these model checking methods are not geared towards
discovering corner cases or re-using verification artifacts for another
sub-optimal safety specification. In this paper, we describe a technique for
obtaining complete characterization of counterexamples for a safety violation
in linear systems. The proposed technique uses the reachable set computed
during safety verification for a given temporal logic formula, performs
constraint propagation, and represents all modalities of counterexamples using
a binary decision diagram (BDD). We introduce an approach to dynamically
determine isomorphic nodes for obtaining a considerably reduced (in size)
decision diagram. A thorough experimental evaluation on various benchmarks
exhibits that the reduction technique achieves up to $67\%$ reduction in the
number of nodes and $75\%$ reduction in the width of the decision diagram.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15345" title="Abstract">arXiv:2311.15345</a> [<a href="/pdf/2311.15345" title="Download PDF">pdf</a>, <a href="/format/2311.15345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Sample Reuse Strategy for Dynamic Influence Maximization Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaofeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shengcai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+K">Ke Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Dynamic influence maximization problem (DIMP) aims to maintain a group of
influential users within an evolving social network, so that the influence
scope can be maximized at any given moment. A primary category of DIMP
algorithms focuses on the renewal of reverse reachable (RR) sets, which is
designed for static social network scenarios, to accelerate the estimation of
influence spread. And the generation time of RR sets plays a crucial role in
algorithm efficiency. However, their update approaches require sequential
updates for each edge change, leading to considerable computational cost. In
this paper, we propose a strategy for batch updating the changes in network
edge weights to efficiently maintain RR sets. By calculating the probability
that previous RR sets can be regenerated at the current moment, we retain those
with a high probability. This method can effectively avoid the computational
cost associated with updating and sampling these RR sets. Besides, we propose
an resampling strategy that generates high-probability RR sets to make the
final distribution of RR sets approximate to the sampling probability
distribution under the current social network. The experimental results
indicate that our strategy is both scalable and efficient. On the one hand,
compared to the previous update strategies, the running time of our strategy is
insensitive to the number of changes in network weight; on the other hand, for
various RR set-based algorithms, our strategy can reduce the running time while
maintaining the solution quality that is essentially consistent with the static
algorithms.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15349" title="Abstract">arXiv:2311.15349</a> [<a href="/pdf/2311.15349" title="Download PDF">pdf</a>, <a href="/ps/2311.15349" title="Download PostScript">ps</a>, <a href="/format/2311.15349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Search Systems through Field Codes and Classifications: The  Case of the First Published Swedish Nursing Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Holmberg%2C+C">Christopher Holmberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages in total (including first page and pages containing bibliography). 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Databases (cs.DB)

</div>
<p class="mathjax">The aim of the study was to assess and compare established search systems and
approaches by using the search goal of identifying the first (as in oldest)
nursing-related document, with reference to the first Swedish-affiliated
document, in Scopus, Web of Science, and PubMed (Medline). In doing so, the
objective was to provide concrete examples and illustrate how search systems
and field code searches versus classification-based searches differ. The Scopus
database, Web of Science database aggregator, and the PubMed (Medline) search
engine were used for evaluations. Two different search strategies were compared
in each database: one guided by field codes (i.e., text-based), and one guided
by pre-existing categorizations within database infrastructures. Findings
highlight several factors that are important to consider when formulating and
executing a search strategy. The findings illustrate important aspects of
search systems and search approaches, namely the publication year,
delimitations related to a country or region, and features related to a subject
or research area. The findings also highlight the importance of prioritizing
between different ideals in retrieval. For example, is it more important to
reach the oldest records (publication year), to identify as many records as
possible (exhaustiveness), or to make sure they are as subject-relevant as
possible (e.g., in terms of authors belonging to the same field)? Secondly,
researchers using bibliometric methods to analyze research literature should be
more transparent when reporting searches, as different search systems and
search approaches yield varied numbers and quality of records. While most
bibliometric researchers strive to combine different approaches, this is not
always made clear in reporting.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15351" title="Abstract">arXiv:2311.15351</a> [<a href="/pdf/2311.15351" title="Download PDF">pdf</a>, <a href="/format/2311.15351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Feeder Restoration using Multi-Microgrid Formation and Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Muthukaruppan%2C+V">Valliappan Muthukaruppan</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+R">Rongxing Hu</a>, 
<a href="/search/eess?searchtype=author&query=Shirsat%2C+A">Ashwin Shirsat</a>, 
<a href="/search/eess?searchtype=author&query=Baran%2C+M">Mesut Baran</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+N">Ning Lu</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+W">Wenyuan Tang</a>, 
<a href="/search/eess?searchtype=author&query=Lubkeman%2C+D">David Lubkeman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE PESGM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This papers highlights the benefit of coordinating resources on mulitple
active distribution feeders during severe long duration outages through
multi-microgrid formation. A graph-theory based multi-microgrid formation
algorithm is developed which is agnostic of the underlying energy management
scheme of the microgrids and solved in a rolling horizon fashion. The algorithm
is then enhanced to handle multiple feeders where formation of long laterals
needs to be avoided due to potential voltage control issues in distribution
systems. The algorithm is evaluated on a synthetic two feeder system derived
from interconnecting two IEEE 123 node system. The results indicate increased
service to loads in the system and better utilization of renewable resources.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15354" title="Abstract">arXiv:2311.15354</a> [<a href="/pdf/2311.15354" title="Download PDF">pdf</a>, <a href="/format/2311.15354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Web-Based Dynamic Paintings: Real-Time Interactive Artworks in Web Using  a 2.5D Pipeline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akleman%2C+E">Ergun Akleman</a>, 
<a href="/search/cs?searchtype=author&query=wang%2C+Y">Youyou wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yinan Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Shanker%2C+A">Anusha Shanker</a>, 
<a href="/search/cs?searchtype=author&query=Perumal%2C+F">Fermi Perumal</a>, 
<a href="/search/cs?searchtype=author&query=Gonen%2C+O">Ozgur Gonen</a>, 
<a href="/search/cs?searchtype=author&query=Fard%2C+M">Motahareh Fard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ISEA 1 (2022) 1-12
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In this work, we present a 2.5D pipeline approach to creating dynamic
paintings that can be re-rendered interactively in real-time on the Web. Using
this 2.5D approach, any existing simple painting such as portraits can be
turned into an interactive dynamic web-based artwork. Our interactive system
provides most global illumination effects such as reflection, refraction,
shadow, and subsurface scattering by processing images. In our system, the
scene is defined only by a set of images. These include (1) a shape image, (2)
two diffuse images, (3) a background image, (4) one foreground image, and (5)
one transparency image. A shape image is either a normal map or a height. Two
diffuse images are usually hand-painted. They are interpolated using
illumination information. The transparency image is used to define the
transparent and reflective regions that can reflect the foreground image and
refract the background image, both of which are also hand-drawn. This
framework, which mainly uses hand-drawn images, provides qualitatively
convincing painterly global illumination effects such as reflection and
refraction. We also include parameters to provide additional artistic controls.
For instance, using our piecewise linear Fresnel function, it is possible to
control the ratio of reflection and refraction. This system is the result of a
long line of research contributions. On the other hand, the art-directed
Fresnel function that provides physically plausible compositing of reflection
and refraction with artistic control is completely new. Art-directed warping
equations that provide qualitatively convincing refraction and reflection
effects with linearized artistic control are also new. You can try our
web-based system for interactive dynamic real-time paintings at
<a href="http://mock3d.tamu.edu/.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15356" title="Abstract">arXiv:2311.15356</a> [<a href="/pdf/2311.15356" title="Download PDF">pdf</a>, <a href="/format/2311.15356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Having Second Thoughts? Let&#x27;s hear it
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+H">Jung H. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Vijayan%2C+S">Sujith Vijayan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 11 figures, 1 table, 2 supplementary tables and 1 supplementary figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep learning models loosely mimic bottom-up signal pathways from low-order
sensory areas to high-order cognitive areas. After training, DL models can
outperform humans on some domain-specific tasks, but their decision-making
process has been known to be easily disrupted. Since the human brain consists
of multiple functional areas highly connected to one another and relies on
intricate interplays between bottom-up and top-down (from high-order to
low-order areas) processing, we hypothesize that incorporating top-down signal
processing may make DL models more robust. To address this hypothesis, we
propose a certification process mimicking selective attention and test if it
could make DL models more robust. Our empirical evaluations suggest that this
newly proposed certification can improve DL models' accuracy and help us build
safety measures to alleviate their vulnerabilities with both artificial and
natural adversarial examples.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15358" title="Abstract">arXiv:2311.15358</a> [<a href="/pdf/2311.15358" title="Download PDF">pdf</a>, <a href="/ps/2311.15358" title="Download PostScript">ps</a>, <a href="/format/2311.15358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An optimised cuckoo-based discrete symbiotic organisms search strategy  for tasks scheduling in cloud computing environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sa%27ad%2C+S">Suleiman Sa&#x27;ad</a>, 
<a href="/search/cs?searchtype=author&query=Muhammed%2C+A">Abdullah Muhammed</a>, 
<a href="/search/cs?searchtype=author&query=Abdullahi%2C+M">Mohammed Abdullahi</a>, 
<a href="/search/cs?searchtype=author&query=Abdullah%2C+A">Azizol Abdullah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 5 figures, 2 algorithms, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Currently, the cloud computing paradigm is experiencing rapid growth as there
is a shift from other distributed computing methods and traditional IT
infrastructure towards it. Consequently, optimised task scheduling techniques
have become crucial in managing the expanding cloud computing environment. In
cloud computing, numerous tasks need to be scheduled on a limited number of
diverse virtual machines to minimise the imbalance between the local and global
search space; and optimise system utilisation. Task scheduling is a challenging
problem known as NP-complete, which means that there is no exact solution, and
we can only achieve near-optimal results, particularly when using large-scale
tasks in the context of cloud computing. This paper proposes an optimised
strategy, Cuckoo-based Discrete Symbiotic Organisms Search (C-DSOS) that
incorporated with Levy-Flight for optimal task scheduling in the cloud
computing environment to minimise degree of imbalance. The strategy is based on
the Standard Symbiotic Organism Search (SOS), which is a nature-inspired
metaheuristic optimisation algorithm designed for numerical optimisation
problems. SOS simulates the symbiotic relationships observed in ecosystems,
such as mutualism, commensalism, and parasitism. To evaluate the proposed
technique, the CloudSim toolkit simulator was used to conduct experiments. The
results demonstrated that C-DSOS outperforms the Simulated Annealing Symbiotic
Organism Search (SASOS) algorithm, which is a benchmarked algorithm commonly
used in task scheduling problems. C-DSOS exhibits a favourable convergence
rate, especially when using larger search spaces, making it suitable for task
scheduling problems in the cloud. For the analysis, a t-test was employed,
reveals that C-DSOS is statistically significant compared to the benchmarked
SASOS algorithm, particularly for scenarios involving a large search space.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15360" title="Abstract">arXiv:2311.15360</a> [<a href="/pdf/2311.15360" title="Download PDF">pdf</a>, <a href="/format/2311.15360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Utilization of Cryptocurrency in the Metaverse and  Security Implications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adeniran%2C+A">Ayodeji Adeniran</a>, 
<a href="/search/cs?searchtype=author&query=Alkinoon%2C+M">Mohammed Alkinoon</a>, 
<a href="/search/cs?searchtype=author&query=Mohaisen%2C+D">David Mohaisen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures, 4 tables. To appear in CSoNet 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">We present our results on analyzing and understanding the behavior and
security of various metaverse platforms incorporating cryptocurrencies. We
obtained the top metaverse coins with a capitalization of at least 25 million
US dollars and the top metaverse domains for the coins, and augmented our data
with name registration information (via whois), including the hosting DNS IP
addresses, registrant location, registrar URL, DNS service provider, expiry
date and check each metaverse website for information on fiat currency for
cryptocurrency. The result from virustotal.com includes the communication
files, passive DNS, referrer files, and malicious detections for each metaverse
domain. Among other insights, we discovered various incidents of malicious
detection associated with metaverse websites. Our analysis highlights
indicators of (in)security, in the correlation sense, with the files and other
attributes that are potentially responsible for the malicious activities.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15361" title="Abstract">arXiv:2311.15361</a> [<a href="/pdf/2311.15361" title="Download PDF">pdf</a>, <a href="/format/2311.15361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultra-Range Gesture Recognition using an RGB Camera in Human-Robot  Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bamani%2C+E">Eran Bamani</a>, 
<a href="/search/cs?searchtype=author&query=Nissinman%2C+E">Eden Nissinman</a>, 
<a href="/search/cs?searchtype=author&query=Meir%2C+I">Inbar Meir</a>, 
<a href="/search/cs?searchtype=author&query=Koenigsberg%2C+L">Lisa Koenigsberg</a>, 
<a href="/search/cs?searchtype=author&query=Sintov%2C+A">Avishai Sintov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Hand gestures play a significant role in human interactions where non-verbal
intentions, thoughts and commands are conveyed. In Human-Robot Interaction
(HRI), hand gestures offer a similar and efficient medium for conveying clear
and rapid directives to a robotic agent. However, state-of-the-art vision-based
methods for gesture recognition have been shown to be effective only up to a
user-camera distance of seven meters. Such a short distance range limits
practical HRI with, for example, service robots, search and rescue robots and
drones. In this work, we address the Ultra-Range Gesture Recognition (URGR)
problem by aiming for a recognition distance of up to 25 meters and in the
context of HRI. We propose a novel deep-learning framework for URGR using
solely a simple RGB camera. First, a novel super-resolution model termed HQ-Net
is used to enhance the low-resolution image of the user. Then, we propose a
novel URGR classifier termed Graph Vision Transformer (GViT) which takes the
enhanced image as input. GViT combines the benefits of a Graph Convolutional
Network (GCN) and a modified Vision Transformer (ViT). Evaluation of the
proposed framework over diverse test data yields a high recognition rate of
98.1%. The framework has also exhibited superior performance compared to human
recognition in ultra-range distances. With the framework, we analyze and
demonstrate the performance of an autonomous quadruped robot directed by human
gestures in complex ultra-range indoor and outdoor environments.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15363" title="Abstract">arXiv:2311.15363</a> [<a href="/pdf/2311.15363" title="Download PDF">pdf</a>, <a href="/format/2311.15363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Infrastructure Utilization of Free Contents Websites Reveal their  Security Characteristics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alqadhi%2C+M">Mohamed Alqadhi</a>, 
<a href="/search/cs?searchtype=author&query=Mohaisen%2C+D">David Mohaisen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures, to appear in CSoNet 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Free Content Websites (FCWs) are a significant element of the Web, and
realizing their use is essential. This study analyzes FCWs worldwide by
studying how they correlate with different network sizes, cloud service
providers, and countries, depending on the type of content they offer.
Additionally, we compare these findings with those of premium content websites
(PCWs). Our analysis concluded that FCWs correlate mainly with networks of
medium size, which are associated with a higher concentration of malicious
websites. Moreover, we found a strong correlation between PCWs, cloud, and
country hosting patterns. At the same time, some correlations were also
observed concerning FCWs but with distinct patterns contrasting each other for
both types. Our investigation contributes to comprehending the FCW ecosystem
through correlation analysis, and the indicative results point toward
controlling the potential risks caused by these sites through adequate
segregation and filtering due to their concentration.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15365" title="Abstract">arXiv:2311.15365</a> [<a href="/pdf/2311.15365" title="Download PDF">pdf</a>, <a href="/ps/2311.15365" title="Download PostScript">ps</a>, <a href="/format/2311.15365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Convergence result of a continuous model of deep learning via  &#x141;ojasiewicz--Simon inequality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Isobe%2C+N">Noboru Isobe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Analysis of PDEs (math.AP); Functional Analysis (math.FA); Probability (math.PR)

</div>
<p class="mathjax">This study focuses on a Wasserstein-type gradient flow, which represents an
optimization process of a continuous model of a Deep Neural Network (DNN).
First, we establish the existence of a minimizer for an average loss of the
model under $L^2$-regularization. Subsequently, we show the existence of a
curve of maximal slope of the loss. Our main result is the convergence of flow
to a critical point of the loss as time goes to infinity. An essential aspect
of proving this result involves the establishment of the \L{}ojasiewicz--Simon
gradient inequality for the loss. We derive this inequality by assuming the
analyticity of NNs and loss functions. Our proofs offer a new approach for
analyzing the asymptotic behavior of Wasserstein-type gradient flows for
nonconvex functionals.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15366" title="Abstract">arXiv:2311.15366</a> [<a href="/pdf/2311.15366" title="Download PDF">pdf</a>, <a href="/format/2311.15366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Untargeted Code Authorship Evasion with Seq2Seq Transformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Soohyeon Choi</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+R">Rhongho Jang</a>, 
<a href="/search/cs?searchtype=author&query=Nyang%2C+D">DaeHun Nyang</a>, 
<a href="/search/cs?searchtype=author&query=Mohaisen%2C+D">David Mohaisen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 1 figure, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Code authorship attribution is the problem of identifying authors of
programming language codes through the stylistic features in their codes, a
topic that recently witnessed significant interest with outstanding
performance. In this work, we present SCAE, a code authorship obfuscation
technique that leverages a Seq2Seq code transformer called StructCoder. SCAE
customizes StructCoder, a system designed initially for function-level code
translation from one language to another (e.g., Java to C#), using transfer
learning. SCAE improved the efficiency at a slight accuracy degradation
compared to existing work. We also reduced the processing time by about 68%
while maintaining an 85% transformation success rate and up to 95.77% evasion
success rate in the untargeted setting.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15367" title="Abstract">arXiv:2311.15367</a> [<a href="/pdf/2311.15367" title="Download PDF">pdf</a>, <a href="/format/2311.15367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BatchNorm-based Weakly Supervised Video Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yixuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yi Qu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+F">Fumin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jingkuan Song</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Hengtao Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In weakly supervised video anomaly detection (WVAD), where only video-level
labels indicating the presence or absence of abnormal events are available, the
primary challenge arises from the inherent ambiguity in temporal annotations of
abnormal occurrences. Inspired by the statistical insight that temporal
features of abnormal events often exhibit outlier characteristics, we propose a
novel method, BN-WVAD, which incorporates BatchNorm into WVAD. In the proposed
BN-WVAD, we leverage the Divergence of Feature from Mean vector (DFM) of
BatchNorm as a reliable abnormality criterion to discern potential abnormal
snippets in abnormal videos. The proposed DFM criterion is also discriminative
for anomaly recognition and more resilient to label noise, serving as the
additional anomaly score to amend the prediction of the anomaly classifier that
is susceptible to noisy labels. Moreover, a batch-level selection strategy is
devised to filter more abnormal snippets in videos where more abnormal events
occur. The proposed BN-WVAD model demonstrates state-of-the-art performance on
UCF-Crime with an AUC of 87.24%, and XD-Violence, where AP reaches up to
84.93%. Our code implementation is accessible at
https://github.com/cool-xuan/BN-WVAD.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15368" title="Abstract">arXiv:2311.15368</a> [<a href="/pdf/2311.15368" title="Download PDF">pdf</a>, <a href="/format/2311.15368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flow-Guided Diffusion for Video Inpainting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+B">Bohai Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yongsheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Heng Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Libo Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video inpainting has been challenged by complex scenarios like large
movements and low-light conditions. Current methods, including emerging
diffusion models, face limitations in quality and efficiency. This paper
introduces the Flow-Guided Diffusion model for Video Inpainting (FGDVI), a
novel approach that significantly enhances temporal consistency and inpainting
quality via reusing an off-the-shelf image generation diffusion model. We
employ optical flow for precise one-step latent propagation and introduces a
model-agnostic flow-guided latent interpolation technique. This technique
expedites denoising, seamlessly integrating with any Video Diffusion Model
(VDM) without additional training. Our FGDVI demonstrates a remarkable 10%
improvement in flow warping error E_warp over existing state-of-the-art
methods. Our comprehensive experiments validate superior performance of FGDVI,
offering a promising direction for advanced video inpainting. The code and
detailed results will be publicly available in
https://github.com/NevSNev/FGDVI.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15372" title="Abstract">arXiv:2311.15372</a> [<a href="/pdf/2311.15372" title="Download PDF">pdf</a>, <a href="/format/2311.15372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Mid-Air Hand Interaction in Data Visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kostic%2C+Z">Zona Kostic</a>, 
<a href="/search/cs?searchtype=author&query=Dumas%2C+C">Catherine Dumas</a>, 
<a href="/search/cs?searchtype=author&query=Pratt%2C+S">Sarah Pratt</a>, 
<a href="/search/cs?searchtype=author&query=Beyer%2C+J">Johanna Beyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Interacting with data visualizations without an instrument or touch surface
is typically characterized by the use of mid-air hand gestures. While mid-air
expressions can be quite intuitive for interacting with digital content at a
distance, they frequently lack precision and necessitate a different way of
expressing users' data-related intentions. In this work, we aim to identify new
designs for mid-air hand gesture manipulations that can facilitate
instrument-free, touch-free, and embedded interactions with visualizations,
while utilizing the three-dimensional (3D) interaction space that mid-air
gestures afford. We explore mid-air hand gestures for data visualization by
searching for natural means to interact with content. We employ three studies -
an Elicitation Study, a User Study, and an Expert Study, to provide insight
into the users' mental models, explore the design space, and suggest
considerations for future mid-air hand gesture design. In addition to forming
strong associations with physical manipulations, we discovered that mid-air
hand gestures can: promote space-multiplexed interaction, which allows for a
greater degree of expression; play a functional role in visual cognition and
comprehension; and enhance creativity and engagement. We further highlight the
challenges that designers in this field may face to help set the stage for
developing effective gestures for a wide range of touchless interactions with
visualizations.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15373" title="Abstract">arXiv:2311.15373</a> [<a href="/pdf/2311.15373" title="Download PDF">pdf</a>, <a href="/format/2311.15373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Confidence Is All You Need for MI Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sinha%2C+A">Abhishek Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Tibrewal%2C+H">Himanshi Tibrewal</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+M">Mansi Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Waghela%2C+N">Nikhar Waghela</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+S">Shivank Garg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">In this evolving era of machine learning security, membership inference
attacks have emerged as a potent threat to the confidentiality of sensitive
data. In this attack, adversaries aim to determine whether a particular point
was used during the training of a target model. This paper proposes a new
method to gauge a data point's membership in a model's training set. Instead of
correlating loss with membership, as is traditionally done, we have leveraged
the fact that training examples generally exhibit higher confidence values when
classified into their actual class. During training, the model is essentially
being 'fit' to the training data and might face particular difficulties in
generalization to unseen data. This asymmetry leads to the model achieving
higher confidence on the training data as it exploits the specific patterns and
noise present in the training data. Our proposed approach leverages the
confidence values generated by the machine learning model. These confidence
values provide a probabilistic measure of the model's certainty in its
predictions and can further be used to infer the membership of a given data
point. Additionally, we also introduce another variant of our method that
allows us to carry out this attack without knowing the ground truth(true class)
of a given data point, thus offering an edge over existing label-dependent
attack methods.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15376" title="Abstract">arXiv:2311.15376</a> [<a href="/pdf/2311.15376" title="Download PDF">pdf</a>, <a href="/ps/2311.15376" title="Download PostScript">ps</a>, <a href="/format/2311.15376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constructive validity of a generalized Kreisel-Putnam rule
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pezlar%2C+I">Ivo Pezlar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Logic (math.LO)

</div>
<p class="mathjax">In this paper, we propose a computational interpretation of the generalized
Kreisel-Putnam rule, also known as the generalized Harrop rule or simply the
Split rule, in the style of BHK semantics. We will achieve this by exploiting
the Curry-Howard correspondence between formulas and types. First, we inspect
the inferential behavior of the Split rule in the setting of a natural
deduction system for the intuitionistic propositional logic. This will guide
our process of formulating an appropriate program that would capture the
corresponding computational content of the typed Split rule. In other words, we
want to find an appropriate selector function for the Split rule by considering
its typed variant. Our investigation can also be reframed as an effort to
answer the following questions: is the Split rule constructively valid in the
sense of BHK semantics? Our answer is positive for the Split rule as well as
for its newly proposed generalized version called the S rule.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15377" title="Abstract">arXiv:2311.15377</a> [<a href="/pdf/2311.15377" title="Download PDF">pdf</a>, <a href="/format/2311.15377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Increased Compute Efficiency and the Diffusion of AI Capabilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pilz%2C+K">Konstantin Pilz</a>, 
<a href="/search/cs?searchtype=author&query=Heim%2C+L">Lennart Heim</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+N">Nicholas Brown</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Training advanced AI models requires large investments in computational
resources, or compute. Yet, as hardware innovation reduces the price of compute
and algorithmic advances make its use more efficient, the cost of training an
AI model to a given performance falls over time. To analyze this phenomenon, we
introduce compute (investment) efficiency, which relates training compute
investment to the resulting AI model performance. We then present a conceptual
model of increases in compute efficiency and assess the social and governance
implications. We find that while an access effect increases the number of
actors who can train models to a given performance over time, a performance
effect simultaneously increases the performance available to every actor -
potentially enabling large compute investors to pioneer new capabilities and
maintain a performance advantage even as capabilities diffuse. The market
effects are multifaceted: while a relative performance advantage might grant
outsized benefits in zero-sum competition, performance ceilings might reduce
leaders' advantage. Nonetheless, we find that if the most severe risks arise
from the most advanced models, large compute investors warrant particular
scrutiny since they discover potentially dangerous capabilities first.
Consequently, governments should require large compute investors to warn them
about dangerous capabilities, thereby enabling timely preparation and
potentially using their superior model performance and compute access for
defensive measures. In cases of extreme risks, especially offense-dominant
capabilities, the government might need to actively restrict the proliferation
entirely.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15380" title="Abstract">arXiv:2311.15380</a> [<a href="/pdf/2311.15380" title="Download PDF">pdf</a>, <a href="/format/2311.15380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grafite: Taming Adversarial Queries with Optimal Range Filters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Costa%2C+M">Marco Costa</a>, 
<a href="/search/cs?searchtype=author&query=Ferragina%2C+P">Paolo Ferragina</a>, 
<a href="/search/cs?searchtype=author&query=Vinciguerra%2C+G">Giorgio Vinciguerra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Proceedings of the ACM on Management of Data (SIGMOD 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Databases (cs.DB)

</div>
<p class="mathjax">Range filters allow checking whether a query range intersects a given set of
keys with a chance of returning a false positive answer, thus generalising the
functionality of Bloom filters from point to range queries. Existing practical
range filters have addressed this problem heuristically, resulting in high
false positive rates and query times when dealing with adversarial inputs, such
as in the common scenario where queries are correlated with the keys.
<br />We introduce Grafite, a novel range filter that solves these issues with a
simple design and clear theoretical guarantees that hold regardless of the
input data and query distribution: given a fixed space budget of $B$ bits per
key, the query time is $O(1)$, and the false positive probability is upper
bounded by $\ell/2^{B-2}$, where $\ell$ is the query range size. Our
experimental evaluation shows that Grafite is the only range filter to date to
achieve robust and predictable false positive rates across all combinations of
datasets, query workloads, and range sizes, while providing faster queries and
construction times, and dominating all competitors in the case of correlated
queries.
<br />As a further contribution, we introduce a very simple heuristic range filter
whose performance on uncorrelated queries is very close to or better than the
one achieved by the best heuristic range filters proposed in the literature so
far.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15381" title="Abstract">arXiv:2311.15381</a> [<a href="/pdf/2311.15381" title="Download PDF">pdf</a>, <a href="/format/2311.15381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On universality of regular realizability problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rubtsov%2C+A">Alexander Rubtsov</a>, 
<a href="/search/cs?searchtype=author&query=Vyalyi%2C+M">Michael Vyalyi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">We prove universality of the regular realizability problems for several
classes of filters. The filters are descriptions of finite relations on the set
of non-negative integers in the format proposed by P. Wolf and H. Fernau. The
universality has proven up to reductions using NP-oracles. It corresponds to
the results of P. Wolf and H. Fernau about decidability of regular
realizability problems for many graph-theoretic properties.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15382" title="Abstract">arXiv:2311.15382</a> [<a href="/pdf/2311.15382" title="Download PDF">pdf</a>, <a href="/format/2311.15382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Multi-Global Server Architecture for Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kawnine%2C+A">Asfia Kawnine</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Hung Cao</a>, 
<a href="/search/cs?searchtype=author&query=Mih%2C+A+N">Atah Nuh Mih</a>, 
<a href="/search/cs?searchtype=author&query=Wachowicz%2C+M">Monica Wachowicz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Key words: Federated Learning, Edge AI, Multiple global servers, EV energy consumption
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated learning (FL) with a single global server framework is currently a
popular approach for training machine learning models on decentralized
environment, such as mobile devices and edge devices. However, the centralized
server architecture poses a risk as any challenge on the central/global server
would result in the failure of the entire system. To minimize this risk, we
propose a novel federated learning framework that leverages the deployment of
multiple global servers. We posit that implementing multiple global servers in
federated learning can enhance efficiency by capitalizing on local
collaborations and aggregating knowledge, and the error tolerance in regard to
communication failure in the single server framework would be handled. We
therefore propose a novel framework that leverages the deployment of multiple
global servers. We conducted a series of experiments using a dataset containing
the event history of electric vehicle (EV) charging at numerous stations. We
deployed a federated learning setup with multiple global servers and client
servers, where each client-server strategically represented a different region
and a global server was responsible for aggregating local updates from those
devices. Our preliminary results of the global models demonstrate that the
difference in performance attributed to multiple servers is less than 1%. While
the hypothesis of enhanced model efficiency was not as expected, the rule for
handling communication challenges added to the algorithm could resolve the
error tolerance issue. Future research can focus on identifying specific uses
for the deployment of multiple global servers.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15383" title="Abstract">arXiv:2311.15383</a> [<a href="/pdf/2311.15383" title="Download PDF">pdf</a>, <a href="/format/2311.15383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Programming for Zero-shot Open-Vocabulary 3D Visual Grounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhihao Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jinke Ren</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chun-Mei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hengshuang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shuguang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhen Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review, project website: <a href="https://curryyuan.github.io/ZSVG3D/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D Visual Grounding (3DVG) aims at localizing 3D object based on textual
descriptions. Conventional supervised methods for 3DVG often necessitate
extensive annotations and a predefined vocabulary, which can be restrictive. To
address this issue, we propose a novel visual programming approach for
zero-shot open-vocabulary 3DVG, leveraging the capabilities of large language
models (LLMs). Our approach begins with a unique dialog-based method, engaging
with LLMs to establish a foundational understanding of zero-shot 3DVG. Building
on this, we design a visual program that consists of three types of modules,
i.e., view-independent, view-dependent, and functional modules. These modules,
specifically tailored for 3D scenarios, work collaboratively to perform complex
reasoning and inference. Furthermore, we develop an innovative language-object
correlation module to extend the scope of existing 3D object detectors into
open-vocabulary scenarios. Extensive experiments demonstrate that our zero-shot
approach can outperform some supervised baselines, marking a significant stride
towards effective 3DVG.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15390" title="Abstract">arXiv:2311.15390</a> [<a href="/pdf/2311.15390" title="Download PDF">pdf</a>, <a href="/ps/2311.15390" title="Download PostScript">ps</a>, <a href="/format/2311.15390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local Convergence of Approximate Newton Method for Two Layer Nonlinear  Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhihang Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhao Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Junze Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">There have been significant advancements made by large language models (LLMs)
in various aspects of our daily lives. LLMs serve as a transformative force in
natural language processing, finding applications in text generation,
translation, sentiment analysis, and question-answering. The accomplishments of
LLMs have led to a substantial increase in research efforts in this domain. One
specific two-layer regression problem has been well-studied in prior works,
where the first layer is activated by a ReLU unit, and the second layer is
activated by a softmax unit. While previous works provide a solid analysis of
building a two-layer regression, there is still a gap in the analysis of
constructing regression problems with more than two layers.
<br />In this paper, we take a crucial step toward addressing this problem: we
provide an analysis of a two-layer regression problem. In contrast to previous
works, our first layer is activated by a softmax unit. This sets the stage for
future analyses of creating more activation functions based on the softmax
function. Rearranging the softmax function leads to significantly different
analyses. Our main results involve analyzing the convergence properties of an
approximate Newton method used to minimize the regularized training loss. We
prove that the loss function for the Hessian matrix is positive definite and
Lipschitz continuous under certain assumptions. This enables us to establish
local convergence guarantees for the proposed training algorithm. Specifically,
with an appropriate initialization and after $O(\log(1/\epsilon))$ iterations,
our algorithm can find an $\epsilon$-approximate minimizer of the training loss
with high probability. Each iteration requires approximately $O(\mathrm{nnz}(C)
+ d^\omega)$ time, where $d$ is the model size, $C$ is the input matrix, and
$\omega &lt; 2.374$ is the matrix multiplication exponent.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15393" title="Abstract">arXiv:2311.15393</a> [<a href="/pdf/2311.15393" title="Download PDF">pdf</a>, <a href="/ps/2311.15393" title="Download PostScript">ps</a>, <a href="/format/2311.15393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Half-Precision Kronecker Product SVD Preconditioner for Structured  Inverse Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+Y">Yizhou Chen</a>, 
<a href="/search/math?searchtype=author&query=Ji%2C+X">Xiang Ji</a>, 
<a href="/search/math?searchtype=author&query=Nagy%2C+J">James Nagy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper we investigate the use of half-precision Kronecker product
singular value decomposition (SVD) approximations as preconditioners for
large-scale Tikhonov regularized least squares problems. Half precision reduces
storage requirements and has the potential to greatly speedup computations on
certain GPU architectures. We consider both standard PCG and flexible PCG
algorithms, and investigate, through numerical experiments on image deblurring
problems, the trade-offs between potentially faster convergence with the
additional cost per iteration when using this preconditioning approach.
Moreover, we also investigate the use of several regularization parameter
choice methods, including generalized cross validation and the discrepancy
principle.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15395" title="Abstract">arXiv:2311.15395</a> [<a href="/pdf/2311.15395" title="Download PDF">pdf</a>, <a href="/format/2311.15395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConstraintMatch for Semi-constrained Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goschenhofer%2C+J">Jann Goschenhofer</a>, 
<a href="/search/cs?searchtype=author&query=Bischl%2C+B">Bernd Bischl</a>, 
<a href="/search/cs?searchtype=author&query=Kira%2C+Z">Zsolt Kira</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 International Joint Conference on Neural Networks (IJCNN)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
<p class="mathjax">Constrained clustering allows the training of classification models using
pairwise constraints only, which are weak and relatively easy to mine, while
still yielding full-supervision-level model performance. While they perform
well even in the absence of the true underlying class labels, constrained
clustering models still require large amounts of binary constraint annotations
for training. In this paper, we propose a semi-supervised context whereby a
large amount of \textit{unconstrained} data is available alongside a smaller
set of constraints, and propose \textit{ConstraintMatch} to leverage such
unconstrained data. While a great deal of progress has been made in
semi-supervised learning using full labels, there are a number of challenges
that prevent a naive application of the resulting methods in the
constraint-based label setting. Therefore, we reason about and analyze these
challenges, specifically 1) proposing a \textit{pseudo-constraining} mechanism
to overcome the confirmation bias, a major weakness of pseudo-labeling, 2)
developing new methods for pseudo-labeling towards the selection of
\textit{informative} unconstrained samples, 3) showing that this also allows
the use of pairwise loss functions for the initial and auxiliary losses which
facilitates semi-constrained model training. In extensive experiments, we
demonstrate the effectiveness of ConstraintMatch over relevant baselines in
both the regular clustering and overclustering scenarios on five challenging
benchmarks and provide analyses of its several components.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15396" title="Abstract">arXiv:2311.15396</a> [<a href="/pdf/2311.15396" title="Download PDF">pdf</a>, <a href="/format/2311.15396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EulerMerge: Simplifying Euler Diagrams Through Set Merges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xinyuan Yan</a>, 
<a href="/search/cs?searchtype=author&query=Rodgers%2C+P">Peter Rodgers</a>, 
<a href="/search/cs?searchtype=author&query=Rottmann%2C+P">Peter Rottmann</a>, 
<a href="/search/cs?searchtype=author&query=Archambault%2C+D">Daniel Archambault</a>, 
<a href="/search/cs?searchtype=author&query=Haunert%2C+J">Jan-Henrik Haunert</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">Euler diagrams are an intuitive and popular method to visualize set-based
data. In a Euler diagram, each set is represented as a closed curve, and set
intersections are shown by curve overlaps. However, Euler diagrams are not
visually scalable and automatic layout techniques struggle to display
real-world data sets in a comprehensible way. Prior state-of-the-art approaches
can embed Euler diagrams by splitting a closed curve into multiple curves so
that a set is represented by multiple disconnected enclosed areas. In addition,
these methods typically result in multiple curve segments being drawn
concurrently. Both of these features significantly impede understanding. In
this paper, we present a new and scalable method for embedding Euler diagrams
using set merges. Our approach simplifies the underlying data to ensure that
each set is represented by a single, connected enclosed area and that the
diagram is drawn without curve concurrency, leading to well formed and
understandable Euler diagrams.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15398" title="Abstract">arXiv:2311.15398</a> [<a href="/pdf/2311.15398" title="Download PDF">pdf</a>, <a href="/format/2311.15398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Convergence of Learning Algorithms in Bayesian Auction Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bichler%2C+M">Martin Bichler</a>, 
<a href="/search/cs?searchtype=author&query=Lunowa%2C+S+B">Stephan B. Lunowa</a>, 
<a href="/search/cs?searchtype=author&query=Oberlechner%2C+M">Matthias Oberlechner</a>, 
<a href="/search/cs?searchtype=author&query=Pieroth%2C+F+R">Fabian R. Pieroth</a>, 
<a href="/search/cs?searchtype=author&query=Wohlmuth%2C+B">Barbara Wohlmuth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Equilibrium problems in Bayesian auction games can be described as systems of
differential equations. Depending on the model assumptions, these equations
might be such that we do not have a rigorous mathematical solution theory. The
lack of analytical or numerical techniques with guaranteed convergence for the
equilibrium problem has plagued the field and limited equilibrium analysis to
rather simple auction models such as single-object auctions. Recent advances in
equilibrium learning led to algorithms that find equilibrium under a wide
variety of model assumptions. We analyze first- and second-price auctions where
simple learning algorithms converge to an equilibrium. The equilibrium problem
in auctions is equivalent to solving an infinite-dimensional variational
inequality (VI). Monotonicity and the Minty condition are the central
sufficient conditions for learning algorithms to converge to an equilibrium in
such VIs. We show that neither monotonicity nor pseudo- or quasi-monotonicity
holds for the respective VIs. The second-price auction's equilibrium is a
Minty-type solution, but the first-price auction is not. However, the
Bayes--Nash equilibrium is the unique solution to the VI within the class of
uniformly increasing bid functions, which ensures that gradient-based
algorithms attain the {equilibrium} in case of convergence, as also observed in
numerical experiments.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15399" title="Abstract">arXiv:2311.15399</a> [<a href="/pdf/2311.15399" title="Download PDF">pdf</a>, <a href="/format/2311.15399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimally Teaching a Linear Behavior Cloning Agent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bharti%2C+S+K">Shubham Kumar Bharti</a>, 
<a href="/search/cs?searchtype=author&query=Wright%2C+S">Stephen Wright</a>, 
<a href="/search/cs?searchtype=author&query=Singla%2C+A">Adish Singla</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaojin Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We study optimal teaching of Linear Behavior Cloning (LBC) learners. In this
setup, the teacher can select which states to demonstrate to an LBC learner.
The learner maintains a version space of infinite linear hypotheses consistent
with the demonstration. The goal of the teacher is to teach a realizable target
policy to the learner using minimum number of state demonstrations. This number
is known as the Teaching Dimension(TD). We present a teaching algorithm called
``Teach using Iterative Elimination(TIE)" that achieves instance optimal TD.
However, we also show that finding optimal teaching set computationally is
NP-hard. We further provide an approximation algorithm that guarantees an
approximation ratio of $\log(|A|-1)$ on the teaching dimension. Finally, we
provide experimental results to validate the efficiency and effectiveness of
our algorithm.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15400" title="Abstract">arXiv:2311.15400</a> [<a href="/pdf/2311.15400" title="Download PDF">pdf</a>, <a href="/format/2311.15400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Framework for Realistic Simulation of Daily Human Activity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Idrees%2C+I">Ifrah Idrees</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Siddharth Singh</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kerui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Glas%2C+D+F">Dylan F. Glas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted and Presented at IEEE International Conference on Robot and Human Communication (ROMAN) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">For social robots like Astro which interact with and adapt to the daily
movements of users within the home, realistic simulation of human activity is
needed for feature development and testing. This paper presents a framework for
simulating daily human activity patterns in home environments at scale,
supporting manual configurability of different personas or activity patterns,
variation of activity timings, and testing on multiple home layouts. We
introduce a method for specifying day-to-day variation in schedules and present
a bidirectional constraint propagation algorithm for generating schedules from
templates. We validate the expressive power of our framework through a use case
scenario analysis and demonstrate that our method can be used to generate data
closely resembling human behavior from three public datasets and a
self-collected dataset. Our contribution supports systematic testing of social
robot behaviors at scale, enables procedural generation of synthetic datasets
of human movement in different households, and can help minimize bias in
training data, leading to more robust and effective robots for home
environments.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15402" title="Abstract">arXiv:2311.15402</a> [<a href="/pdf/2311.15402" title="Download PDF">pdf</a>, <a href="/format/2311.15402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Section Weights for Multi-Label Document Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fard%2C+M+M">Maziar Moradi Fard</a>, 
<a href="/search/cs?searchtype=author&query=Bayod%2C+P+S">Paula Sorrolla Bayod</a>, 
<a href="/search/cs?searchtype=author&query=Motarjem%2C+K">Kiomars Motarjem</a>, 
<a href="/search/cs?searchtype=author&query=Nejadi%2C+M+A">Mohammad Alian Nejadi</a>, 
<a href="/search/cs?searchtype=author&query=Akhondi%2C+S">Saber Akhondi</a>, 
<a href="/search/cs?searchtype=author&query=Thorne%2C+C">Camilo Thorne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Multi-label document classification is a traditional task in NLP. Compared to
single-label classification, each document can be assigned multiple classes.
This problem is crucially important in various domains, such as tagging
scientific articles. Documents are often structured into several sections such
as abstract and title. Current approaches treat different sections equally for
multi-label classification. We argue that this is not a realistic assumption,
leading to sub-optimal results. Instead, we propose a new method called
Learning Section Weights (LSW), leveraging the contribution of each distinct
section for multi-label classification. Via multiple feed-forward layers, LSW
learns to assign weights to each section of, and incorporate the weights in the
prediction. We demonstrate our approach on scientific articles. Experimental
results on public (arXiv) and private (Elsevier) datasets confirm the
superiority of LSW, compared to state-of-the-art multi-label document
classification methods. In particular, LSW achieves a 1.3% improvement in terms
of macro averaged F1-score while it achieves 1.3% in terms of macro averaged
recall on the publicly available arXiv dataset.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15404" title="Abstract">arXiv:2311.15404</a> [<a href="/pdf/2311.15404" title="Download PDF">pdf</a>, <a href="/format/2311.15404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applying statistical learning theory to deep learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gerbelot%2C+C">C&#xe9;dric Gerbelot</a>, 
<a href="/search/cs?searchtype=author&query=Karagulyan%2C+A">Avetik Karagulyan</a>, 
<a href="/search/cs?searchtype=author&query=Karp%2C+S">Stefani Karp</a>, 
<a href="/search/cs?searchtype=author&query=Ravichandran%2C+K">Kavya Ravichandran</a>, 
<a href="/search/cs?searchtype=author&query=Stern%2C+M">Menachem Stern</a>, 
<a href="/search/cs?searchtype=author&query=Srebro%2C+N">Nathan Srebro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 51 pages, 20 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (stat.ML)

</div>
<p class="mathjax">Although statistical learning theory provides a robust framework to
understand supervised learning, many theoretical aspects of deep learning
remain unclear, in particular how different architectures may lead to inductive
bias when trained using gradient based methods. The goal of these lectures is
to provide an overview of some of the main questions that arise when attempting
to understand deep learning from a learning theory perspective. After a brief
reminder on statistical learning theory and stochastic optimization, we discuss
implicit bias in the context of benign overfitting. We then move to a general
description of the mirror descent algorithm, showing how we may go back and
forth between a parameter space and the corresponding function space for a
given learning problem, as well as how the geometry of the learning problem may
be represented by a metric tensor. Building on this framework, we provide a
detailed study of the implicit bias of gradient descent on linear diagonal
networks for various regression tasks, showing how the loss function, scale of
parameters at initialization and depth of the network may lead to various forms
of implicit bias, in particular transitioning between kernel or feature
learning.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15406" title="Abstract">arXiv:2311.15406</a> [<a href="/pdf/2311.15406" title="Download PDF">pdf</a>, <a href="/format/2311.15406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Optimize the Environmental Impact of Transformed NoSQL Schemas  through a Multidimensional Cost Model?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mali%2C+J">Jihane Mali</a>, 
<a href="/search/cs?searchtype=author&query=Atigui%2C+F">Faten Atigui</a>, 
<a href="/search/cs?searchtype=author&query=Azough%2C+A">Ahmed Azough</a>, 
<a href="/search/cs?searchtype=author&query=Travers%2C+N">Nicolas Travers</a>, 
<a href="/search/cs?searchtype=author&query=Ahvar%2C+S">Shohreh Ahvar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">The complexity of database systems has increased significantly along with the
continuous growth of data, resulting in NoSQL systems and forcing Information
Systems (IS) architects to constantly adapt their data models (i.e., the data
structure of information stored in the database) and carefully choose the best
option(s) for storing and managing data. In this context, we propose %in this
paper an automatic global approach for leading data models' transformation
process. This approach starts with the generation of all possible solutions. It
then relies on a cost model that helps to compare these generated data models
in a logical level to finally choose the best one for the given use case. This
cost model integrates both data model and queries cost. It also takes into
consideration the environmental impact of a data model as well as its financial
and its time costs. This work presents for the first time a multidimensional
cost model encompassing time, environmental and financial constraints, which
compares data models leading to the choice of the optimal one for a given use
case. In addition, a simulation for data model's transformation and cost
computation has been developed based on our approach.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15414" title="Abstract">arXiv:2311.15414</a> [<a href="/pdf/2311.15414" title="Download PDF">pdf</a>, <a href="/format/2311.15414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KOPPA: Improving Prompt-based Continual Learning with Key-Query  Orthogonal Projection and Prototype-based One-Versus-All
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+Q">Quyen Tran</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+L">Lam Tran</a>, 
<a href="/search/cs?searchtype=author&query=Than%2C+K">Khoat Than</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+T">Toan Tran</a>, 
<a href="/search/cs?searchtype=author&query=Phung%2C+D">Dinh Phung</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Trung Le</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Drawing inspiration from prompt tuning techniques applied to Large Language
Models, recent methods based on pre-trained ViT networks have achieved
remarkable results in the field of Continual Learning. Specifically, these
approaches propose to maintain a set of prompts and allocate a subset of them
to learn each task using a key-query matching strategy. However, they may
encounter limitations when lacking control over the correlations between old
task queries and keys of future tasks, the shift of features in the latent
space, and the relative separation of latent vectors learned in independent
tasks. In this work, we introduce a novel key-query learning strategy based on
orthogonal projection, inspired by model-agnostic meta-learning, to enhance
prompt matching efficiency and address the challenge of shifting features.
Furthermore, we introduce a One-Versus-All (OVA) prototype-based component that
enhances the classification head distinction. Experimental results on benchmark
datasets demonstrate that our method empowers the model to achieve results
surpassing those of current state-of-the-art approaches by a large margin of up
to 20%.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15415" title="Abstract">arXiv:2311.15415</a> [<a href="/pdf/2311.15415" title="Download PDF">pdf</a>, <a href="/format/2311.15415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GAN-Based LiDAR Intensity Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marcus%2C+R">Richard Marcus</a>, 
<a href="/search/cs?searchtype=author&query=Gabel%2C+F">Felix Gabel</a>, 
<a href="/search/cs?searchtype=author&query=Knoop%2C+N">Niklas Knoop</a>, 
<a href="/search/cs?searchtype=author&query=Stamminger%2C+M">Marc Stamminger</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Deep Learning Theory and Applications, 4th International
  Conference, DeLTA 2023, Rome, Italy, 2023, Proceedings, pp 419-433
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Realistic vehicle sensor simulation is an important element in developing
autonomous driving. As physics-based implementations of visual sensors like
LiDAR are complex in practice, data-based approaches promise solutions. Using
pairs of camera images and LiDAR scans from real test drives, GANs can be
trained to translate between them. For this process, we contribute two
additions. First, we exploit the camera images, acquiring segmentation data and
dense depth maps as additional input for training. Second, we test the
performance of the LiDAR simulation by testing how well an object detection
network generalizes between real and synthetic point clouds to enable
evaluation without ground truth point clouds. Combining both, we simulate LiDAR
point clouds and demonstrate their realism.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15419" title="Abstract">arXiv:2311.15419</a> [<a href="/pdf/2311.15419" title="Download PDF">pdf</a>, <a href="/format/2311.15419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frobenius-Type Norms and Inner Products of Matrices and Linear Maps with  Applications to Neural Network Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herzog%2C+R">Roland Herzog</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6hne%2C+F">Frederik K&#xf6;hne</a>, 
<a href="/search/cs?searchtype=author&query=Kreis%2C+L">Leonie Kreis</a>, 
<a href="/search/cs?searchtype=author&query=Schiela%2C+A">Anton Schiela</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">The Frobenius norm is a frequent choice of norm for matrices. In particular,
the underlying Frobenius inner product is typically used to evaluate the
gradient of an objective with respect to matrix variable, such as those
occuring in the training of neural networks. We provide a broader view on the
Frobenius norm and inner product for linear maps or matrices, and establish
their dependence on inner products in the domain and co-domain spaces. This
shows that the classical Frobenius norm is merely one special element of a
family of more general Frobenius-type norms. The significant extra freedom
furnished by this realization can be used, among other things, to precondition
neural network training.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15420" title="Abstract">arXiv:2311.15420</a> [<a href="/pdf/2311.15420" title="Download PDF">pdf</a>, <a href="/ps/2311.15420" title="Download PostScript">ps</a>, <a href="/format/2311.15420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Modelling for Harmonic Current Emission in Low-Voltage Grid  Using MCReSANet with Interpretability Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yao%2C+J">Jieyu Yao</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+H">Hao Yu</a>, 
<a href="/search/eess?searchtype=author&query=Judge%2C+P">Paul Judge</a>, 
<a href="/search/eess?searchtype=author&query=Jia%2C+J">Jiabin Jia</a>, 
<a href="/search/eess?searchtype=author&query=Djokic%2C+S">Sasa Djokic</a>, 
<a href="/search/eess?searchtype=author&query=P%C3%BCvi%2C+V">Verner P&#xfc;vi</a>, 
<a href="/search/eess?searchtype=author&query=Lehtonen%2C+M">Matti Lehtonen</a>, 
<a href="/search/eess?searchtype=author&query=Meyer%2C+J">Jan Meyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Even though the use of power electronics PE loads offers enhanced electrical
energy conversion efficiency and control, they remain the primary sources of
harmonics in grids. When diverse loads are connected in the distribution
system, their interactions complicate establishing analytical models for the
relationship between harmonic voltages and currents. To solve this, our paper
presents a data-driven model using MCReSANet to construct the highly nonlinear
between harmonic voltage and current. Two datasets from PCCs in Finland and
Germany are utilized, which demonstrates that MCReSANet is capable of
establishing accurate nonlinear mappings, even in the presence of various
network characteristics for selected Finland and Germany datasets. The model
built by MCReSANet can improve the MAE by 10% and 14% compared to the CNN, and
by 8% and 17% compared to the MLP for both Finnish and German datasets, also
showing much lower model uncertainty than others. This is a crucial
prerequisite for more precise SHAP value-based feature importance analysis,
which is a method for the model interpretability analysis in this paper. The
results by feature importance analysis show the detailed relationships between
each order of harmonic voltage and current in the distribution system. There is
an interactive impact on each order of harmonic current, but some orders of
harmonic voltages have a dominant influence on harmonic current emissions:
positive sequence and zero sequence harmonics have the dominant importance in
the Finnish and German networks, respectively, which conforms to the pattern of
connected load types in two selected Finnish and German datasets. This paper
enhances the potential for understanding and predicting harmonic current
emissions by diverse PE loads in distribution systems, which is beneficial to
more effective management for optimizing power quality in diverse grid
environments.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15421" title="Abstract">arXiv:2311.15421</a> [<a href="/pdf/2311.15421" title="Download PDF">pdf</a>, <a href="/format/2311.15421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wired Perspectives: Multi-View Wire Art Embraces Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+Z">Zhiyu Qu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Honggang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+T">Tao Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+K">Kaiyue Pang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yi-Zhe Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://dreamwireart.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Creating multi-view wire art (MVWA), a static 3D sculpture with diverse
interpretations from different viewpoints, is a complex task even for skilled
artists. In response, we present DreamWire, an AI system enabling everyone to
craft MVWA easily. Users express their vision through text prompts or
scribbles, freeing them from intricate 3D wire organisation. Our approach
synergises 3D B\'ezier curves, Prim's algorithm, and knowledge distillation
from diffusion models or their variants (e.g., ControlNet). This blend enables
the system to represent 3D wire art, ensuring spatial continuity and overcoming
data scarcity. Extensive evaluation and analysis are conducted to shed insight
on the inner workings of the proposed system, including the trade-off between
connectivity and visual aesthetics.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15425" title="Abstract">arXiv:2311.15425</a> [<a href="/pdf/2311.15425" title="Download PDF">pdf</a>, <a href="/format/2311.15425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine-Generated Text Detection using Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gaggar%2C+R">Raghav Gaggar</a>, 
<a href="/search/cs?searchtype=author&query=Bhagchandani%2C+A">Ashish Bhagchandani</a>, 
<a href="/search/cs?searchtype=author&query=Oza%2C+H">Harsh Oza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Our research focuses on the crucial challenge of discerning text produced by
Large Language Models (LLMs) from human-generated text, which holds
significance for various applications. With ongoing discussions about attaining
a model with such functionality, we present supporting evidence regarding the
feasibility of such models. We evaluated our models on multiple datasets,
including Twitter Sentiment, Football Commentary, Project Gutenberg, PubMedQA,
and SQuAD, confirming the efficacy of the enhanced detection approaches. These
datasets were sampled with intricate constraints encompassing every
possibility, laying the foundation for future research. We evaluate
GPT-3.5-Turbo against various detectors such as SVM, RoBERTa-base, and
RoBERTa-large. Based on the research findings, the results predominantly relied
on the sequence length of the sentence.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15426" title="Abstract">arXiv:2311.15426</a> [<a href="/pdf/2311.15426" title="Download PDF">pdf</a>, <a href="/format/2311.15426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Augmentation for Sample Efficient and Robust Document Ranking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anand%2C+A">Abhijit Anand</a>, 
<a href="/search/cs?searchtype=author&query=Leonhardt%2C+J">Jurek Leonhardt</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+J">Jaspreet Singh</a>, 
<a href="/search/cs?searchtype=author&query=Rudra%2C+K">Koustav Rudra</a>, 
<a href="/search/cs?searchtype=author&query=Anand%2C+A">Avishek Anand</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Contextual ranking models have delivered impressive performance improvements
over classical models in the document ranking task. However, these highly
over-parameterized models tend to be data-hungry and require large amounts of
data even for fine-tuning. In this paper, we propose data-augmentation methods
for effective and robust ranking performance. One of the key benefits of using
data augmentation is in achieving sample efficiency or learning effectively
when we have only a small amount of training data. We propose supervised and
unsupervised data augmentation schemes by creating training data using parts of
the relevant documents in the query-document pairs. We then adapt a family of
contrastive losses for the document ranking task that can exploit the augmented
data to learn an effective ranking model. Our extensive experiments on subsets
of the MS MARCO and TREC-DL test sets show that data augmentation, along with
the ranking-adapted contrastive losses, results in performance improvements
under most dataset sizes. Apart from sample efficiency, we conclusively show
that data augmentation results in robust models when transferred to
out-of-domain benchmarks. Our performance improvements in in-domain and more
prominently in out-of-domain benchmarks show that augmentation regularizes the
ranking model and improves its robustness and generalization capability.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15427" title="Abstract">arXiv:2311.15427</a> [<a href="/pdf/2311.15427" title="Download PDF">pdf</a>, <a href="/ps/2311.15427" title="Download PostScript">ps</a>, <a href="/format/2311.15427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lived experiences of online harm amongst marginalized and vulnerable  individuals in support-seeking communities on Reddit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yingfan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Squicciarini%2C+A">Anna Squicciarini</a>, 
<a href="/search/cs?searchtype=author&query=Rajtmajer%2C+S">Sarah Rajtmajer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Online communities can serve as meaningful sources of social support,
particularly for marginalized and vulnerable groups. Disclosure of personal
information facilitates integration into online communities but may also expose
individuals to harm, including cyberbullying and manipulation. To better
understand negative user experiences resulting from self-disclosure in online
conversations, we interviewed 25 participants from target populations on
Reddit. Through thematic analysis, we outline the harm they experience,
including damage to self- and group identities. We find that encountering
online harm can worsen offline adversity. We discuss how users protect
themselves and recover from harm in the context of current platform
affordances, highlighting ongoing challenges. Finally, we explore design
implications for a community-driven, bottom-up approach to enhance user
well-being and safety.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15431" title="Abstract">arXiv:2311.15431</a> [<a href="/pdf/2311.15431" title="Download PDF">pdf</a>, <a href="/ps/2311.15431" title="Download PostScript">ps</a>, <a href="/format/2311.15431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the piecewise complexity of words and periodic words
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Praveen%2C+M">M. Praveen</a>, 
<a href="/search/cs?searchtype=author&query=Schnoebelen%2C+P">Philippe Schnoebelen</a>, 
<a href="/search/cs?searchtype=author&query=Vialard%2C+I">Isa Vialard</a>, 
<a href="/search/cs?searchtype=author&query=Veron%2C+J">Julien Veron</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">The piecewise complexity $h(u)$ of a word is the minimal length of subwords
needed to exactly characterise $u$. Its piecewise minimality index $\rho(u)$ is
the smallest length $k$ such that $u$ is minimal among its order-$k$ class
$[u]_k$ in Simon's congruence.
<br />We study these two measures and provide efficient algorithms for computing
$h(u)$ and $\rho(u)$. We also provide efficient algorithms for the case where
$u$ is a periodic word, of the form $u=v^n$
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15432" title="Abstract">arXiv:2311.15432</a> [<a href="/pdf/2311.15432" title="Download PDF">pdf</a>, <a href="/ps/2311.15432" title="Download PostScript">ps</a>, <a href="/format/2311.15432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Importance of Collective Privacy in Digital Sexual and Reproductive  Health
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Almeida%2C+T">Teresa Almeida</a>, 
<a href="/search/cs?searchtype=author&query=Mehrnezhad%2C+M">Maryam Mehrnezhad</a>, 
<a href="/search/cs?searchtype=author&query=Cook%2C+S">Stephen Cook</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">There is an abundance of digital sexual and reproductive health technologies
that presents a concern regarding their potential sensitive data breaches. We
analyzed 15 Internet of Things (IoT) devices with sexual and reproductive
tracking services and found this ever-extending collection of data implicates
many beyond the individual including partner, child, and family. Results
suggest that digital sexual and reproductive health data privacy is both an
individual and collective endeavor.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15433" title="Abstract">arXiv:2311.15433</a> [<a href="/pdf/2311.15433" title="Download PDF">pdf</a>, <a href="/ps/2311.15433" title="Download PostScript">ps</a>, <a href="/format/2311.15433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An End-to-End Performance Comparison of Seven Permissioned Blockchain  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geyer%2C+F+C">Frank Christian Geyer</a>, 
<a href="/search/cs?searchtype=author&query=Jacobsen%2C+H">Hans-Arno Jacobsen</a>, 
<a href="/search/cs?searchtype=author&query=Mayer%2C+R">Ruben Mayer</a>, 
<a href="/search/cs?searchtype=author&query=Mandl%2C+P">Peter Mandl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures, 20 tables, Middleware Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The emergence of more and more blockchain solutions with innovative
approaches to optimising performance, scalability, privacy and governance
complicates performance analysis. Reasons for the difficulty of benchmarking
blockchains include, for example, the high number of system parameters to
configure and the effort to deploy a blockchain network. In addition,
performance data, which mostly comes from system vendors, is often
intransparent. We investigate and evaluate the performance of seven
permissioned blockchain systems using different parameter settings in a
reproducible manner. We employ an end-to-end approach, where the clients
sending the transactions are fully involved in the data collection approach.
Our results highlight the peculiarities and limitations of the systems under
investigation. Due to the insights given, our work forms the basis for
continued research to optimise the performance of blockchain systems.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15435" title="Abstract">arXiv:2311.15435</a> [<a href="/pdf/2311.15435" title="Download PDF">pdf</a>, <a href="/format/2311.15435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Functional Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Biao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wonka%2C+P">Peter Wonka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> For the project site, see <a href="https://1zb.github.io/functional-diffusion/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose a new class of generative diffusion models, called functional
diffusion. In contrast to previous work, functional diffusion works on samples
that are represented by functions with a continuous domain. Functional
diffusion can be seen as an extension of classical diffusion models to an
infinite-dimensional domain. Functional diffusion is very versatile as images,
videos, audio, 3D shapes, deformations, \etc, can be handled by the same
framework with minimal changes. In addition, functional diffusion is especially
suited for irregular data or data defined in non-standard domains. In our work,
we derive the necessary foundations for functional diffusion and propose a
first implementation based on the transformer architecture. We show generative
results on complicated signed distance functions and deformation functions
defined on 3D surfaces.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15436" title="Abstract">arXiv:2311.15436</a> [<a href="/pdf/2311.15436" title="Download PDF">pdf</a>, <a href="/format/2311.15436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Skip for Language Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+D">Dewen Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+N">Nan Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuanzhong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+T">Tao Lei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+C">Claire Cui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Overparameterized large-scale language models have impressive generalization
performance of in-context few-shot learning. However, most language models
allocate the same amount of parameters or computation to each token,
disregarding the complexity or importance of the input data. We argue that in
language model pretraining, a variable amount of computation should be assigned
to different tokens, and this can be efficiently achieved via a simple routing
mechanism. Different from conventional early stopping techniques where tokens
can early exit at only early layers, we propose a more general method that
dynamically skips the execution of a layer (or module) for any input token with
a binary router. In our extensive evaluation across 24 NLP tasks, we
demonstrate that the proposed method can significantly improve the 1-shot
performance compared to other competitive baselines only at mild extra cost for
inference.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15438" title="Abstract">arXiv:2311.15438</a> [<a href="/pdf/2311.15438" title="Download PDF">pdf</a>, <a href="/format/2311.15438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProtoArgNet: Interpretable Image Classification with Super-Prototypes  and Argumentation [Technical Report]
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ayoobi%2C+H">Hamed Ayoobi</a>, 
<a href="/search/cs?searchtype=author&query=Potyka%2C+N">Nico Potyka</a>, 
<a href="/search/cs?searchtype=author&query=Toni%2C+F">Francesca Toni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We propose ProtoArgNet, a novel interpretable deep neural architecture for
image classification in the spirit of prototypical-part-learning as found, e.g.
in ProtoPNet. While earlier approaches associate every class with multiple
prototypical-parts, ProtoArgNet uses super-prototypes that combine
prototypical-parts into single prototypical class representations. Furthermore,
while earlier approaches use interpretable classification layers, e.g. logistic
regression in ProtoPNet, ProtoArgNet improves accuracy with multi-layer
perceptrons while relying upon an interpretable reading thereof based on a form
of argumentation. ProtoArgNet is customisable to user cognitive requirements by
a process of sparsification of the multi-layer perceptron/argumentation
component. Also, as opposed to other prototypical-part-learning approaches,
ProtoArgNet can recognise spatial relations between different
prototypical-parts that are from different regions in images, similar to how
CNNs capture relations between patterns recognized in earlier layers.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15439" title="Abstract">arXiv:2311.15439</a> [<a href="/pdf/2311.15439" title="Download PDF">pdf</a>, <a href="/format/2311.15439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Encoding of Graphics Primitives with Simplex-based Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yibo Wen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yunfan Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Grid-based structures are commonly used to encode explicit features for
graphics primitives such as images, signed distance functions (SDF), and neural
radiance fields (NeRF) due to their simple implementation. However, in
$n$-dimensional space, calculating the value of a sampled point requires
interpolating the values of its $2^n$ neighboring vertices. The exponential
scaling with dimension leads to significant computational overheads. To address
this issue, we propose a simplex-based approach for encoding graphics
primitives. The number of vertices in a simplex-based structure increases
linearly with dimension, making it a more efficient and generalizable
alternative to grid-based representations. Using the non-axis-aligned
simplicial structure property, we derive and prove a coordinate transformation,
simplicial subdivision, and barycentric interpolation scheme for efficient
sampling, which resembles transformation procedures in the simplex noise
algorithm. Finally, we use hash tables to store multiresolution features of all
interest points in the simplicial grid, which are passed into a tiny fully
connected neural network to parameterize graphics primitives. We implemented a
detailed simplex-based structure encoding algorithm in C++ and CUDA using the
methods outlined in our approach. In the 2D image fitting task, the proposed
method is capable of fitting a giga-pixel image with 9.4% less time compared to
the baseline method proposed by instant-ngp, while maintaining the same quality
and compression rate. In the volumetric rendering setup, we observe a maximum
41.2% speedup when the samples are dense enough.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15443" title="Abstract">arXiv:2311.15443</a> [<a href="/pdf/2311.15443" title="Download PDF">pdf</a>, <a href="/format/2311.15443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DCRA: A Distributed Chiplet-based Reconfigurable Architecture for  Irregular Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Orenes-Vera%2C+M">Marcelo Orenes-Vera</a>, 
<a href="/search/cs?searchtype=author&query=Tureci%2C+E">Esin Tureci</a>, 
<a href="/search/cs?searchtype=author&query=Martonosi%2C+M">Margaret Martonosi</a>, 
<a href="/search/cs?searchtype=author&query=Wentzlaff%2C+D">David Wentzlaff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2304.09389">arXiv:2304.09389</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In recent years, the growing demand to process large graphs and sparse
datasets has led to increased research efforts to develop hardware- and
software-based architectural solutions to accelerate them. While some of these
approaches achieve scalable parallelization with up to thousands of cores,
adaptation of these proposals by the industry remained slow. To help solve this
dissonance, we identified a set of questions and considerations that current
research has not considered deeply. Starting from a tile-based architecture, we
put forward a Distributed Chiplet-based Reconfigurable Architecture (DCRA) for
irregular applications that carefully consider fabrication constraints that
made prior work either hard or costly to implement or too rigid to be applied.
We identify and study pre-silicon, package-time and compile-time configurations
that help optimize DCRA for different deployments and target metrics. To enable
that, we propose a practical path for manufacturing chip packages by composing
variable numbers of DCRA and memory dies, with a software-configurable Torus
network to connect them. We evaluate six applications and four datasets, with
several configurations and memory technologies, to provide a detailed analysis
of the performance, power, and cost of DCRA as a compute node for scale-out
sparse data processing. Finally, we present our findings and discuss how DCRA,
together with our framework for design exploration, can help guide architects
to build scalable and cost-efficient systems for irregular applications.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15445" title="Abstract">arXiv:2311.15445</a> [<a href="/pdf/2311.15445" title="Download PDF">pdf</a>, <a href="/format/2311.15445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FLAIR: A Conditional Diffusion Framework with Applications to Face Video  Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+Z">Zihao Zou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shoushtari%2C+S">Shirin Shoushtari</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yubo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+W">Weijie Gan</a>, 
<a href="/search/cs?searchtype=author&query=Kamilov%2C+U+S">Ulugbek S. Kamilov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 27 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Face video restoration (FVR) is a challenging but important problem where one
seeks to recover a perceptually realistic face videos from a low-quality input.
While diffusion probabilistic models (DPMs) have been shown to achieve
remarkable performance for face image restoration, they often fail to preserve
temporally coherent, high-quality videos, compromising the fidelity of
reconstructed faces. We present a new conditional diffusion framework called
FLAIR for FVR. FLAIR ensures temporal consistency across frames in a
computationally efficient fashion by converting a traditional image DPM into a
video DPM. The proposed conversion uses a recurrent video refinement layer and
a temporal self-attention at different scales. FLAIR also uses a conditional
iterative refinement process to balance the perceptual and distortion quality
during inference. This process consists of two key components: a
data-consistency module that analytically ensures that the generated video
precisely matches its degraded observation and a coarse-to-fine image
enhancement module specifically for facial regions. Our extensive experiments
show superiority of FLAIR over the current state-of-the-art (SOTA) for video
super-resolution, deblurring, JPEG restoration, and space-time frame
interpolation on two high-quality face video datasets.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15448" title="Abstract">arXiv:2311.15448</a> [<a href="/pdf/2311.15448" title="Download PDF">pdf</a>, <a href="/format/2311.15448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GGNNs : Generalizing GNNs using Residual Connections and Weighted  Message Passing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raghuvanshi%2C+A">Abhinav Raghuvanshi</a>, 
<a href="/search/cs?searchtype=author&query=Malleshappa%2C+K+S">Kushal Sokke Malleshappa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Many real-world phenomena can be modeled as a graph, making them extremely
valuable due to their ubiquitous presence. GNNs excel at capturing those
relationships and patterns within these graphs, enabling effective learning and
prediction tasks. GNNs are constructed using Multi-Layer Perceptrons (MLPs) and
incorporate additional layers for message passing to facilitate the flow of
features among nodes. It is commonly believed that the generalizing power of
GNNs is attributed to the message-passing mechanism between layers, where nodes
exchange information with their neighbors, enabling them to effectively capture
and propagate information across the nodes of a graph. Our technique builds on
these results, modifying the message-passing mechanism further: one by weighing
the messages before accumulating at each node and another by adding Residual
connections. These two mechanisms show significant improvements in learning and
faster convergence
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15451" title="Abstract">arXiv:2311.15451</a> [<a href="/pdf/2311.15451" title="Download PDF">pdf</a>, <a href="/format/2311.15451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-aware Language Modeling for Selective Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ravikumar%2C+S">Shreya Ravikumar</a>, 
<a href="/search/cs?searchtype=author&query=Schmitt-Ulms%2C+F">Fynn Schmitt-Ulms</a>, 
<a href="/search/cs?searchtype=author&query=Lolla%2C+S">Satvik Lolla</a>, 
<a href="/search/cs?searchtype=author&query=Demir%2C+E">Ege Demir</a>, 
<a href="/search/cs?searchtype=author&query=Elistratov%2C+I">Iaroslav Elistratov</a>, 
<a href="/search/cs?searchtype=author&query=Lavaee%2C+A">Alex Lavaee</a>, 
<a href="/search/cs?searchtype=author&query=Lolla%2C+S">Sadhana Lolla</a>, 
<a href="/search/cs?searchtype=author&query=Ahmadi%2C+E">Elaheh Ahmadi</a>, 
<a href="/search/cs?searchtype=author&query=Rus%2C+D">Daniela Rus</a>, 
<a href="/search/cs?searchtype=author&query=Amini%2C+A">Alexander Amini</a>, 
<a href="/search/cs?searchtype=author&query=Perez%2C+A">Alejandro Perez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present an automatic large language model (LLM) conversion approach that
produces uncertainty-aware LLMs capable of estimating uncertainty with every
prediction. Our approach is model- and data-agnostic, is
computationally-efficient, and does not rely on external models or systems. We
evaluate converted models on the selective question answering setting -- to
answer as many questions as possible while maintaining a given accuracy,
forgoing providing predictions when necessary. As part of our results, we test
BERT and Llama 2 model variants on the SQuAD extractive QA task and the
TruthfulQA generative QA task. We show that using the uncertainty estimates
provided by our approach to selectively answer questions leads to significantly
higher accuracy over directly using model probabilities.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15453" title="Abstract">arXiv:2311.15453</a> [<a href="/pdf/2311.15453" title="Download PDF">pdf</a>, <a href="/format/2311.15453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DISYRE: Diffusion-Inspired SYnthetic REstoration for Unsupervised  Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marimont%2C+S+N">Sergio Naval Marimont</a>, 
<a href="/search/cs?searchtype=author&query=Baugh%2C+M">Matthew Baugh</a>, 
<a href="/search/cs?searchtype=author&query=Siomos%2C+V">Vasilis Siomos</a>, 
<a href="/search/cs?searchtype=author&query=Tzelepis%2C+C">Christos Tzelepis</a>, 
<a href="/search/cs?searchtype=author&query=Kainz%2C+B">Bernhard Kainz</a>, 
<a href="/search/cs?searchtype=author&query=Tarroni%2C+G">Giacomo Tarroni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Unsupervised Anomaly Detection (UAD) techniques aim to identify and localize
anomalies without relying on annotations, only leveraging a model trained on a
dataset known to be free of anomalies. Diffusion models learn to modify inputs
$x$ to increase the probability of it belonging to a desired distribution,
i.e., they model the score function $\nabla_x \log p(x)$. Such a score function
is potentially relevant for UAD, since $\nabla_x \log p(x)$ is itself a
pixel-wise anomaly score. However, diffusion models are trained to invert a
corruption process based on Gaussian noise and the learned score function is
unlikely to generalize to medical anomalies. This work addresses the problem of
how to learn a score function relevant for UAD and proposes DISYRE:
Diffusion-Inspired SYnthetic REstoration. We retain the diffusion-like pipeline
but replace the Gaussian noise corruption with a gradual, synthetic anomaly
corruption so the learned score function generalizes to medical, naturally
occurring anomalies. We evaluate DISYRE on three common Brain MRI UAD
benchmarks and substantially outperform other methods in two out of the three
tasks.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15460" title="Abstract">arXiv:2311.15460</a> [<a href="/pdf/2311.15460" title="Download PDF">pdf</a>, <a href="/format/2311.15460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Preserving Data Sharing in Agriculture: Enforcing Policy Rules  for Secure and Confidential Data Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kotal%2C+A">Anantaa Kotal</a>, 
<a href="/search/cs?searchtype=author&query=Elluri%2C+L">Lavanya Elluri</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+D">Deepti Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Mandalapu%2C+V">Varun Mandalapu</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+A">Anupam Joshi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Big Data empowers the farming community with the information needed to
optimize resource usage, increase productivity, and enhance the sustainability
of agricultural practices. The use of Big Data in farming requires the
collection and analysis of data from various sources such as sensors,
satellites, and farmer surveys. While Big Data can provide the farming
community with valuable insights and improve efficiency, there is significant
concern regarding the security of this data as well as the privacy of the
participants. Privacy regulations, such as the EU GDPR, the EU Code of Conduct
on agricultural data sharing by contractual agreement, and the proposed EU AI
law, have been created to address the issue of data privacy and provide
specific guidelines on when and how data can be shared between organizations.
To make confidential agricultural data widely available for Big Data analysis
without violating the privacy of the data subjects, we consider
privacy-preserving methods of data sharing in agriculture. Deep learning-based
synthetic data generation has been proposed for privacy-preserving data
sharing. However, there is a lack of compliance with documented data privacy
policies in such privacy-preserving efforts. In this study, we propose a novel
framework for enforcing privacy policy rules in privacy-preserving data
generation algorithms. We explore several available agricultural codes of
conduct, extract knowledge related to the privacy constraints in data, and use
the extracted knowledge to define privacy bounds in a privacy-preserving
generative model. We use our framework to generate synthetic agricultural data
and present experimental results that demonstrate the utility of the synthetic
dataset in downstream tasks. We also show that our framework can evade
potential threats and secure data based on applicable regulatory policy rules.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15463" title="Abstract">arXiv:2311.15463</a> [<a href="/pdf/2311.15463" title="Download PDF">pdf</a>, <a href="/format/2311.15463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Where to Begin? From Random to Foundation Model Instructed  Initialization in Federated Learning for Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In medical image analysis, Federated Learning (FL) stands out as a key
technology that enables privacy-preserved, decentralized data processing,
crucial for handling sensitive medical data. Currently, most FL models employ
random initialization, which has been proven effective in various instances.
However, given the unique challenges posed by non-IID (independently and
identically distributed) data in FL, we propose a novel perspective: exploring
the impact of using the foundation model with enormous pre-trained knowledge,
such as the Segment Anything Model (SAM), as an instructive teacher for FL
model initialization in medical image segmentation task. This work for the
first time attempts to utilize the foundation model as an instructive teacher
for initialization in FL, assessing its impact on the performance of FL models,
especially in non-IID data scenarios. Our empirical evaluation on chest x-ray
lung segmentation showcases that FL with foundation model instructed
initialization not only achieves faster convergence but also improves
performance in complex data contexts. These findings offer a new perspective
for model initialization in FL.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15473" title="Abstract">arXiv:2311.15473</a> [<a href="/pdf/2311.15473" title="Download PDF">pdf</a>, <a href="/ps/2311.15473" title="Download PostScript">ps</a>, <a href="/format/2311.15473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M&#x101;ori algorithmic sovereignty: idea, principles, and use
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brown%2C+P+T">Paul T. Brown</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+D">Daniel Wilson</a>, 
<a href="/search/cs?searchtype=author&query=West%2C+K">Kiri West</a>, 
<a href="/search/cs?searchtype=author&query=Escott%2C+K">Kirita-Rose Escott</a>, 
<a href="/search/cs?searchtype=author&query=Basabas%2C+K">Kiya Basabas</a>, 
<a href="/search/cs?searchtype=author&query=Ritchie%2C+B">Ben Ritchie</a>, 
<a href="/search/cs?searchtype=author&query=Lucas%2C+D">Danielle Lucas</a>, 
<a href="/search/cs?searchtype=author&query=Taia%2C+I">Ivy Taia</a>, 
<a href="/search/cs?searchtype=author&query=Kusabs%2C+N">Natalie Kusabs</a>, 
<a href="/search/cs?searchtype=author&query=Keegan%2C+T+T">Te Taka Keegan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Due to the emergence of data-driven technologies in Aotearoa New Zealand that
use M\=aori data, there is a need for values-based frameworks to guide thinking
around balancing the tension between the opportunities these create, and the
inherent risks that these technologies can impose. Algorithms can be framed as
a particular use of data, therefore data frameworks that currently exist can be
extended to include algorithms. M\=aori data sovereignty principles are
well-known and are used by researchers and government agencies to guide the
culturally appropriate use of M\=aori data. Extending these principles to fit
the context of algorithms, and re-working the underlying sub-principles to
address issues related to responsible algorithms from a M\=aori perspective
leads to the M\=aori algorithmic sovereignty principles. We define this idea,
present the updated principles and subprinciples, and highlight how these can
be used to decolonise algorithms currently in use, and argue that these ideas
could potentially be used to developed Indigenised algorithms.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15474" title="Abstract">arXiv:2311.15474</a> [<a href="/pdf/2311.15474" title="Download PDF">pdf</a>, <a href="/format/2311.15474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demonstration of Programmable Brain-Inspired Optoelectronic Neuron in  Photonic Spiking Neural Network with Neural Heterogeneity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lee%2C+Y">Yun-Jhu Lee</a>, 
<a href="/search/eess?searchtype=author&query=On%2C+M+B">Mehmet Berkay On</a>, 
<a href="/search/eess?searchtype=author&query=Srouji%2C+L+E">Luis El Srouji</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Abdelghany%2C+M">Mahmoud Abdelghany</a>, 
<a href="/search/eess?searchtype=author&query=Yoo%2C+S+J+B">S.J. Ben Yoo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Photonic Spiking Neural Networks (PSNN) composed of the co-integrated CMOS
and photonic elements can offer low loss, low power, highly-parallel, and
high-throughput computing for brain-inspired neuromorphic systems. In addition,
heterogeneity of neuron dynamics can also bring greater diversity and
expressivity to brain-inspired networks, potentially allowing for the
implementation of complex functions with fewer neurons. In this paper, we
design, fabricate, and experimentally demonstrate an optoelectronic spiking
neuron that can simultaneously achieve high programmability for heterogeneous
biological neural networks and maintain high-speed computing. We demonstrate
that our neuron can be programmed to tune four essential parameters of neuron
dynamics under 1GSpike/s input spiking pattern signals. A single neuron circuit
can be tuned to output three spiking patterns, including chattering behaviors.
The PSNN consisting of the optoelectronic spiking neuron and a Mach-Zehnder
interferometer (MZI) mesh synaptic network achieves 89.3% accuracy on the Iris
dataset. Our neuron power consumption is 1.18 pJ/spike output, mainly limited
by the power efficiency of the vertical-cavity-lasers, optical coupling
efficiency, and the 45 nm CMOS platform used in this experiment, and is
predicted to achieve 36.84 fJ/spike output with a 7 nm CMOS platform (e.g.
ASAP7) integrated with silicon photonics containing on-chip micron-scale
lasers.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15475" title="Abstract">arXiv:2311.15475</a> [<a href="/pdf/2311.15475" title="Download PDF">pdf</a>, <a href="/format/2311.15475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MeshGPT: Generating Triangle Meshes with Decoder-Only Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Siddiqui%2C+Y">Yawar Siddiqui</a>, 
<a href="/search/cs?searchtype=author&query=Alliegro%2C+A">Antonio Alliegro</a>, 
<a href="/search/cs?searchtype=author&query=Artemov%2C+A">Alexey Artemov</a>, 
<a href="/search/cs?searchtype=author&query=Tommasi%2C+T">Tatiana Tommasi</a>, 
<a href="/search/cs?searchtype=author&query=Sirigatti%2C+D">Daniele Sirigatti</a>, 
<a href="/search/cs?searchtype=author&query=Rosov%2C+V">Vladislav Rosov</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+A">Angela Dai</a>, 
<a href="/search/cs?searchtype=author&query=Nie%C3%9Fner%2C+M">Matthias Nie&#xdf;ner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://nihalsid.github.io/mesh-gpt/">this https URL</a>, Video: <a href="https://youtu.be/UV90O1_69_o">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce MeshGPT, a new approach for generating triangle meshes that
reflects the compactness typical of artist-created meshes, in contrast to dense
triangle meshes extracted by iso-surfacing methods from neural fields. Inspired
by recent advances in powerful large language models, we adopt a sequence-based
approach to autoregressively generate triangle meshes as sequences of
triangles. We first learn a vocabulary of latent quantized embeddings, using
graph convolutions, which inform these embeddings of the local mesh geometry
and topology. These embeddings are sequenced and decoded into triangles by a
decoder, ensuring that they can effectively reconstruct the mesh. A transformer
is then trained on this learned vocabulary to predict the index of the next
embedding given previous embeddings. Once trained, our model can be
autoregressively sampled to generate new triangle meshes, directly generating
compact meshes with sharp edges, more closely imitating the efficient
triangulation patterns of human-crafted meshes. MeshGPT demonstrates a notable
improvement over state of the art mesh generation methods, with a 9% increase
in shape coverage and a 30-point enhancement in FID scores across various
categories.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15477" title="Abstract">arXiv:2311.15477</a> [<a href="/pdf/2311.15477" title="Download PDF">pdf</a>, <a href="/format/2311.15477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreamCreature: Crafting Photorealistic Virtual Creatures from  Imagination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ng%2C+K+W">Kam Woh Ng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiatian Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yi-Zhe Song</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+T">Tao Xiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Website: <a href="https://github.com/kamwoh/dreamcreature">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent text-to-image (T2I) generative models allow for high-quality synthesis
following either text instructions or visual examples. Despite their
capabilities, these models face limitations in creating new, detailed creatures
within specific categories (e.g., virtual dog or bird species), which are
valuable in digital asset creation and biodiversity analysis. To bridge this
gap, we introduce a novel task, Virtual Creatures Generation: Given a set of
unlabeled images of the target concepts (e.g., 200 bird species), we aim to
train a T2I model capable of creating new, hybrid concepts within diverse
backgrounds and contexts. We propose a new method called DreamCreature, which
identifies and extracts the underlying sub-concepts (e.g., body parts of a
specific species) in an unsupervised manner. The T2I thus adapts to generate
novel concepts (e.g., new bird species) with faithful structures and
photorealistic appearance by seamlessly and flexibly composing learned
sub-concepts. To enhance sub-concept fidelity and disentanglement, we extend
the textual inversion technique by incorporating an additional projector and
tailored attention loss regularization. Extensive experiments on two
fine-grained image benchmarks demonstrate the superiority of DreamCreature over
prior methods in both qualitative and quantitative evaluation. Ultimately, the
learned sub-concepts facilitate diverse creative applications, including
innovative consumer product designs and nuanced property modifications.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15478" title="Abstract">arXiv:2311.15478</a> [<a href="/pdf/2311.15478" title="Download PDF">pdf</a>, <a href="/format/2311.15478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AerialBooth: Mutual Information Guidance for Text Controlled Aerial View  Synthesis from a Single Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kothandaraman%2C+D">Divya Kothandaraman</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Ming Lin</a>, 
<a href="/search/cs?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a novel method, AerialBooth, for synthesizing the aerial view from
a single input image using its text description. We leverage the pretrained
text-to-2D image stable diffusion model as prior knowledge of the 3D world. The
model is finetuned in two steps to optimize for the text embedding and the UNet
that reconstruct the input image and its inverse perspective mapping
respectively. The inverse perspective mapping creates variance within the
text-image space of the diffusion model, while providing weak guidance for
aerial view synthesis. At inference, we steer the contents of the generated
image towards the input image using novel mutual information guidance that
maximizes the information content between the probability distributions of the
two images. We evaluate our approach on a wide spectrum of real and synthetic
data, including natural scenes, indoor scenes, human action, etc. Through
extensive experiments and ablation studies, we demonstrate the effectiveness of
AerialBooth and also its generalizability to other text-controlled views. We
also show that AerialBooth achieves the best viewpoint-fidelity trade-off
though quantitative evaluation on 7 metrics analyzing viewpoint and fidelity
w.r.t. input image. Code and data is available at
https://github.com/divyakraman/AerialBooth2023.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15480" title="Abstract">arXiv:2311.15480</a> [<a href="/pdf/2311.15480" title="Download PDF">pdf</a>, <a href="/ps/2311.15480" title="Download PostScript">ps</a>, <a href="/format/2311.15480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Time Signature Determination for New Scores Using Lyrics for  Latent Rhythmic Structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+C+C">Callie C. Liao</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+D">Duoduo Liao</a>, 
<a href="/search/cs?searchtype=author&query=Guessford%2C+J">Jesse Guessford</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Big Data 2023 Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multimedia (cs.MM); Sound (cs.SD)

</div>
<p class="mathjax">There has recently been a sharp increase in interest in Artificial
Intelligence-Generated Content (AIGC). Despite this, musical components such as
time signatures have not been studied sufficiently to form an algorithmic
determination approach for new compositions, especially lyrical songs. This is
likely because of the neglect of musical details, which is critical for
constructing a robust framework. Specifically, time signatures establish the
fundamental rhythmic structure for almost all aspects of a song, including the
phrases and notes. In this paper, we propose a novel approach that only uses
lyrics as input to automatically generate a fitting time signature for lyrical
songs and uncover the latent rhythmic structure utilizing explainable machine
learning models. In particular, we devise multiple methods that are associated
with discovering lyrical patterns and creating new features that simultaneously
contain lyrical, rhythmic, and statistical information. In this approach, the
best of our experimental results reveal a 97.6% F1 score and a 0.996 Area Under
the Curve (AUC) of the Receiver Operating Characteristic (ROC) score. In
conclusion, our research directly generates time signatures from lyrics
automatically for new scores utilizing machine learning, which is an innovative
idea that approaches an understudied component of musicology and therefore
contributes significantly to the future of Artificial Intelligence (AI) music
generation.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15482" title="Abstract">arXiv:2311.15482</a> [<a href="/pdf/2311.15482" title="Download PDF">pdf</a>, <a href="/format/2311.15482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributional Hessian and divdiv complexes on triangulation and  cohomology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hu%2C+K">Kaibo Hu</a>, 
<a href="/search/math?searchtype=author&query=Lin%2C+T">Ting Lin</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Q">Qian Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> keywords: Bernstein-Gelfand-Gelfand sequences, cohomology, finite element exterior calculus, discrete exterior calculus, Regge calculus
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Differential Geometry (math.DG)

</div>
<p class="mathjax">In this paper, we construct discrete versions of some
Bernstein-Gelfand-Gelfand (BGG) complexes, i.e., the Hessian and the divdiv
complexes, on triangulations in 2D and 3D. The sequences consist of finite
elements with local polynomial shape functions and various types of Dirac
measure on subsimplices. The construction generalizes Whitney forms (canonical
conforming finite elements) for the de Rham complex and Regge calculus/finite
elements for the elasticity (Riemannian deformation) complex from discrete
topological and Discrete Exterior Calculus perspectives. We show that the
cohomology of the resulting complexes is isomorphic to the continuous versions,
and thus isomorphic to the de~Rham cohomology with coefficients.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15487" title="Abstract">arXiv:2311.15487</a> [<a href="/pdf/2311.15487" title="Download PDF">pdf</a>, <a href="/ps/2311.15487" title="Download PostScript">ps</a>, <a href="/format/2311.15487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Global $\mathcal{L}^2$ minimization with certainty via geometrically  adapted gradient descent in Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Thomas Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AMS Latex, 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Mathematical Physics (math-ph); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">We consider the gradient descent flow widely used for the minimization of the
$\mathcal{L}^2$ cost function in Deep Learning networks, and introduce two
modified versions; one adapted for the overparametrized setting, and the other
for the underparametrized setting. Both have a clear and natural invariant
geometric meaning, taking into account the pullback vector bundle structure in
the overparametrized, and the pushforward vector bundle structure in the
underparametrized setting. In the overparametrized case, we prove that,
provided that a rank condition holds, all orbits of the modified gradient
descent drive the $\mathcal{L}^2$ cost to its global minimum at a uniform
exponential convergence rate. We point out relations of the latter to
sub-Riemannian geometry.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15490" title="Abstract">arXiv:2311.15490</a> [<a href="/pdf/2311.15490" title="Download PDF">pdf</a>, <a href="/ps/2311.15490" title="Download PostScript">ps</a>, <a href="/format/2311.15490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing and Fine-tuning Large Language Model for Urban Renewal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+X">Xianyao Ling</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tom Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuecao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shaolan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhixing Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+P">Peng Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 2 figures, 2 tables, 41 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study aims to innovatively explore adaptive applications of large
language models (LLM) in urban renewal. It also aims to improve its performance
and text generation quality for knowledge question-answering (QA) tasks. Based
on the ChatGLM, we automatically generate QA datasets using urban renewal
scientific literature corpora in a self-instruct manner and then conduct joint
fine-tuning training on the model using the Prefix and LoRA fine-tuning methods
to create an LLM for urban renewal. By guiding the LLM to automatically
generate QA data based on prompt words and given text, it is possible to
quickly obtain datasets in the urban renewal field and provide data support for
the fine-tuning training of LLMs. The experimental results show that the joint
fine-tuning training method proposed in this study can significantly improve
the performance of LLM on the QA tasks. Compared with LoRA fine-tuning, the
method improves the Bleu and Rouge metrics on the test by about 5%; compared
with the model before fine-tuning, the method improves the Bleu and Rouge
metrics by about 15%-20%. This study demonstrates the effectiveness and
superiority of the joint fine-tuning method using Prefix and LoRA for ChatGLM
in the urban renewal knowledge QA tasks. It provides a new approach for
fine-tuning LLMs on urban renewal-related tasks.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15493" title="Abstract">arXiv:2311.15493</a> [<a href="/pdf/2311.15493" title="Download PDF">pdf</a>, <a href="/format/2311.15493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UFIN: Universal Feature Interaction Network for Multi-Domain  Click-Through Rate Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhen Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Changwang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W+X">Wayne Xin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhao Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Click-Through Rate (CTR) prediction, which aims to estimate the probability
of a user clicking on an item, is a key task in online advertising. Numerous
existing CTR models concentrate on modeling the feature interactions within a
solitary domain, thereby rendering them inadequate for fulfilling the
requisites of multi-domain recommendations in real industrial scenarios. Some
recent approaches propose intricate architectures to enhance knowledge sharing
and augment model training across multiple domains. However, these approaches
encounter difficulties when being transferred to new recommendation domains,
owing to their reliance on the modeling of ID features (e.g., item id). To
address the above issue, we propose the Universal Feature Interaction Network
(UFIN) approach for CTR prediction. UFIN exploits textual data to learn
universal feature interactions that can be effectively transferred across
diverse domains. For learning universal feature representations, we regard the
text and feature as two different modalities and propose an encoder-decoder
network founded on a Large Language Model (LLM) to enforce the transfer of data
from the text modality to the feature modality. Building upon the above
foundation, we further develop a mixtureof-experts (MoE) enhanced adaptive
feature interaction model to learn transferable collaborative patterns across
multiple domains. Furthermore, we propose a multi-domain knowledge distillation
framework to enhance feature interaction learning. Based on the above methods,
UFIN can effectively bridge the semantic gap to learn common knowledge across
various domains, surpassing the constraints of ID-based models. Extensive
experiments conducted on eight datasets show the effectiveness of UFIN, in both
multidomain and cross-platform settings. Our code is available at
https://github.com/RUCAIBox/UFIN.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15496" title="Abstract">arXiv:2311.15496</a> [<a href="/pdf/2311.15496" title="Download PDF">pdf</a>, <a href="/ps/2311.15496" title="Download PostScript">ps</a>, <a href="/format/2311.15496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Critiquing Self-report Practices for Human Mental and Wellbeing  Computing at Ubicomp
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+N">Nan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ananthan%2C+S">Soundariya Ananthan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuntao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Salim%2C+F+D">Flora D. Salim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Computing human mental and wellbeing is crucial to various domains, including
health, education, and entertainment. However, the reliance on self-reporting
in traditional research to establish ground truth often leads to methodological
inconsistencies and susceptibility to response biases, thus hindering the
effectiveness of modelling. This paper presents the first systematic
methodological review of self-reporting practices in Ubicomp within the context
of human mental and wellbeing computing. Drawing from existing survey research,
we establish guidelines for self-reporting in human wellbeing studies and
identify shortcomings in current practices at Ubicomp community. Furthermore,
we explore the reliability of self-report as a means of ground truth and
propose directions for improving ground truth measurement in this field.
Ultimately, we emphasize the urgent need for methodological advancements to
enhance human mental and wellbeing computing.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15497" title="Abstract">arXiv:2311.15497</a> [<a href="/pdf/2311.15497" title="Download PDF">pdf</a>, <a href="/format/2311.15497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Image Registration: A Hybrid Approach Integrating Deep Learning  and Optimization Functions for Enhanced Precision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Araujo%2C+G">Gabriel De Araujo</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shanlin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaohui Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Image registration has traditionally been done using two distinct approaches:
learning based methods, relying on robust deep neural networks, and
optimization-based methods, applying complex mathematical transformations to
warp images accordingly. Of course, both paradigms offer advantages and
disadvantages, and, in this work, we seek to combine their respective strengths
into a single streamlined framework, using the outputs of the learning based
method as initial parameters for optimization while prioritizing computational
power for the image pairs that offer the greatest loss. Our investigations
showed that an improvement of 0.3\% in testing when utilizing the best
performing state-of-the-art model as the backbone of the framework, while
maintaining the same inference time and with only a 0.8\% loss in deformation
field smoothness.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15500" title="Abstract">arXiv:2311.15500</a> [<a href="/pdf/2311.15500" title="Download PDF">pdf</a>, <a href="/format/2311.15500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Function-constrained Program Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hajali%2C+P">Patrick Hajali</a>, 
<a href="/search/cs?searchtype=author&query=Budvytis%2C+I">Ignas Budvytis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 6 figures, 2023 NeurIPS R0-Fomo Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Programming Languages (cs.PL)

</div>
<p class="mathjax">This work introduces (1) a technique that allows large language models (LLMs)
to leverage user-provided code when solving programming tasks and (2) a method
to iteratively generate modular sub-functions that can aid future code
generation attempts when the initial code generated by the LLM is inadequate.
Generating computer programs in general-purpose programming languages like
Python poses a challenge for LLMs when instructed to use code provided in the
prompt. Code-specific LLMs (e.g., GitHub Copilot, CodeLlama2) can generate code
completions in real-time by drawing on all code available in a development
environment. However, restricting code-specific LLMs to use only in-context
code is not straightforward, as the model is not explicitly instructed to use
the user-provided code and users cannot highlight precisely which snippets of
code the model should incorporate into its context. Moreover, current systems
lack effective recovery methods, forcing users to iteratively re-prompt the
model with modified prompts until a sufficient solution is reached. Our method
differs from traditional LLM-powered code-generation by constraining
code-generation to an explicit function set and enabling recovery from failed
attempts through automatically generated sub-functions. When the LLM cannot
produce working code, we generate modular sub-functions to aid subsequent
attempts at generating functional code. A by-product of our method is a library
of reusable sub-functions that can solve related tasks, imitating a software
team where efficiency scales with experience. We also introduce a new
"half-shot" evaluation paradigm that provides tighter estimates of LLMs' coding
abilities compared to traditional zero-shot evaluation. Our proposed evaluation
method encourages models to output solutions in a structured format, decreasing
syntax errors that can be mistaken for poor coding ability.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15502" title="Abstract">arXiv:2311.15502</a> [<a href="/pdf/2311.15502" title="Download PDF">pdf</a>, <a href="/format/2311.15502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning with Complementary Labels Revisited: A Consistent Approach via  Negative-Unlabeled Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ishida%2C+T">Takashi Ishida</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu-Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+G">Gang Niu</a>, 
<a href="/search/cs?searchtype=author&query=Sugiyama%2C+M">Masashi Sugiyama</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Complementary-label learning is a weakly supervised learning problem in which
each training example is associated with one or multiple complementary labels
indicating the classes to which it does not belong. Existing consistent
approaches have relied on the uniform distribution assumption to model the
generation of complementary labels, or on an ordinary-label training set to
estimate the transition matrix. However, both conditions may not be satisfied
in real-world scenarios. In this paper, we propose a novel complementary-label
learning approach that does not rely on these conditions. We find that
complementary-label learning can be expressed as a set of negative-unlabeled
binary classification problems when using the one-versus-rest strategy. This
observation allows us to propose a risk-consistent approach with theoretical
guarantees. Furthermore, we introduce a risk correction approach to address
overfitting problems when using complex models. We also prove the statistical
consistency and convergence rate of the corrected risk estimator. Extensive
experimental results on both synthetic and real-world benchmark datasets
validate the superiority of our proposed approach over state-of-the-art
methods.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15504" title="Abstract">arXiv:2311.15504</a> [<a href="/pdf/2311.15504" title="Download PDF">pdf</a>, <a href="/ps/2311.15504" title="Download PostScript">ps</a>, <a href="/format/2311.15504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An efficient class of increasingly high-order ENO schemes with  multi-resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shen%2C+H">Hua Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We construct an efficient class of increasingly high-order (up to 17th-order)
essentially non-oscillatory schemes with multi-resolution (ENO-MR) for solving
hyperbolic conservation laws. The candidate stencils for constructing ENO-MR
schemes range from first-order one-point stencil increasingly up to the
designed very high-order stencil. The proposed ENO-MR schemes adopt a very
simple and efficient strategy that only requires the computation of the
highest-order derivatives of a part of candidate stencils. Besides simplicity
and high efficiency, ENO-MR schemes are completely parameter-free and
essentially scale-invariant. Theoretical analysis and numerical computations
show that ENO-MR schemes achieve designed high-order convergence in smooth
regions which may contain high-order critical points (local extrema) and retain
ENO property for strong shocks. In addition, ENO-MR schemes could capture
complex flow structures very well.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15505" title="Abstract">arXiv:2311.15505</a> [<a href="/pdf/2311.15505" title="Download PDF">pdf</a>, <a href="/ps/2311.15505" title="Download PostScript">ps</a>, <a href="/format/2311.15505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Trust and Risk during Online Bartering Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lakkanige%2C+K">Kalyani Lakkanige</a>, 
<a href="/search/cs?searchtype=author&query=Cooley-Russ%2C+L">Lamar Cooley-Russ</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+A+R">Alan R. Wagner</a>, 
<a href="/search/cs?searchtype=author&query=Rajtmajer%2C+S">Sarah Rajtmajer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted into Multittrust 2.0 @ HAI 2023 (<a href="https://multittrust.github.io/2ed/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This paper investigates how risk influences the way people barter. We used
Minecraft to create an experimental environment in which people bartered to
earn a monetary bonus. Our findings reveal that subjects exhibit risk-aversion
to competitive bartering environments and deliberate over their trades longer
when compared to cooperative environments. These initial experiments lay
groundwork for development of agents capable of strategically trading with
human counterparts in different environments.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15507" title="Abstract">arXiv:2311.15507</a> [<a href="/pdf/2311.15507" title="Download PDF">pdf</a>, <a href="/format/2311.15507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Word Sense Disambiguation in Neural Machine Translation with  Salient Document Context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rippeth%2C+E">Elijah Rippeth</a>, 
<a href="/search/cs?searchtype=author&query=Carpuat%2C+M">Marine Carpuat</a>, 
<a href="/search/cs?searchtype=author&query=Duh%2C+K">Kevin Duh</a>, 
<a href="/search/cs?searchtype=author&query=Post%2C+M">Matt Post</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Lexical ambiguity is a challenging and pervasive problem in machine
translation (\mt). We introduce a simple and scalable approach to resolve
translation ambiguity by incorporating a small amount of extra-sentential
context in neural \mt. Our approach requires no sense annotation and no change
to standard model architectures. Since actual document context is not available
for the vast majority of \mt training data, we collect related sentences for
each input to construct pseudo-documents. Salient words from pseudo-documents
are then encoded as a prefix to each source sentence to condition the
generation of the translation. To evaluate, we release \docmucow, a challenge
set for translation disambiguation based on the English-German \mucow
\cite{raganato-etal-2020-evaluation} augmented with document IDs. Extensive
experiments show that our method translates ambiguous source words better than
strong sentence-level baselines and comparable document-level baselines while
reducing training costs.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15509" title="Abstract">arXiv:2311.15509</a> [<a href="/pdf/2311.15509" title="Download PDF">pdf</a>, <a href="/format/2311.15509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Corpus for Named Entity Recognition in Chinese Novels with  Multi-genres
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hanjie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jinge Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yuchen Yan</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yuxiang Jia</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yawen Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zan%2C+H">Hongying Zan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Entities like person, location, organization are important for literary text
analysis. The lack of annotated data hinders the progress of named entity
recognition (NER) in literary domain. To promote the research of literary NER,
we build the largest multi-genre literary NER corpus containing 263,135
entities in 105,851 sentences from 260 online Chinese novels spanning 13
different genres. Based on the corpus, we investigate characteristics of
entities from different genres. We propose several baseline NER models and
conduct cross-genre and cross-domain experiments. Experimental results show
that genre difference significantly impact NER performance though not as much
as domain difference like literary domain and news domain. Compared with NER in
news domain, literary NER still needs much improvement and the
Out-of-Vocabulary (OOV) problem is more challenging due to the high variety of
entities in literary works.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15510" title="Abstract">arXiv:2311.15510</a> [<a href="/pdf/2311.15510" title="Download PDF">pdf</a>, <a href="/format/2311.15510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CaesarNeRF: Calibrated Semantic Representation for Few-shot  Generalizable Neural Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Haidong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+T">Tianyu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zharkov%2C+I">Ilya Zharkov</a>, 
<a href="/search/cs?searchtype=author&query=Nevatia%2C+R">Ram Nevatia</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+L">Luming Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generalizability and few-shot learning are key challenges in Neural Radiance
Fields (NeRF), often due to the lack of a holistic understanding in pixel-level
rendering. We introduce CaesarNeRF, an end-to-end approach that leverages
scene-level CAlibratEd SemAntic Representation along with pixel-level
representations to advance few-shot, generalizable neural rendering,
facilitating a holistic understanding without compromising high-quality
details. CaesarNeRF explicitly models pose differences of reference views to
combine scene-level semantic representations, providing a calibrated holistic
understanding. This calibration process aligns various viewpoints with precise
location and is further enhanced by sequential refinement to capture varying
details. Extensive experiments on public datasets, including LLFF, Shiny,
mip-NeRF 360, and MVImgNet, show that CaesarNeRF delivers state-of-the-art
performance across varying numbers of reference views, proving effective even
with a single reference image. The project page of this work can be found at
https://haidongz-usc.github.io/project/caesarnerf.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15512" title="Abstract">arXiv:2311.15512</a> [<a href="/pdf/2311.15512" title="Download PDF">pdf</a>, <a href="/format/2311.15512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Pedestrian Character Learning for Trajectory Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yonghao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Le Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Sanpin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+G">Gang Hua</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Changyin Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Pedestrian trajectory prediction in a first-person view has recently
attracted much attention due to its importance in autonomous driving. Recent
work utilizes pedestrian character information, \textit{i.e.}, action and
appearance, to improve the learned trajectory embedding and achieves
state-of-the-art performance. However, it neglects the invalid and negative
pedestrian character information, which is harmful to trajectory representation
and thus leads to performance degradation. To address this issue, we present a
two-stream sparse-character-based network~(TSNet) for pedestrian trajectory
prediction. Specifically, TSNet learns the negative-removed characters in the
sparse character representation stream to improve the trajectory embedding
obtained in the trajectory representation stream. Moreover, to model the
negative-removed characters, we propose a novel sparse character graph,
including the sparse category and sparse temporal character graphs, to learn
the different effects of various characters in category and temporal
dimensions, respectively. Extensive experiments on two first-person view
datasets, PIE and JAAD, show that our method outperforms existing
state-of-the-art methods. In addition, ablation studies demonstrate different
effects of various characters and prove that TSNet outperforms approaches
without eliminating negative characters.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15513" title="Abstract">arXiv:2311.15513</a> [<a href="/pdf/2311.15513" title="Download PDF">pdf</a>, <a href="/ps/2311.15513" title="Download PostScript">ps</a>, <a href="/format/2311.15513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative and Experimental Study on Automatic Question Answering  Systems and its Robustness against Word Jumbling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Javaji%2C+S+R">Shashidhar Reddy Javaji</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Haoran Hu</a>, 
<a href="/search/cs?searchtype=author&query=Vennam%2C+S+S">Sai Sameer Vennam</a>, 
<a href="/search/cs?searchtype=author&query=Buddhavarapu%2C+V+G">Vijaya Gajanan Buddhavarapu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Question answer generation using Natural Language Processing models is
ubiquitous in the world around us. It is used in many use cases such as the
building of chat bots, suggestive prompts in google search and also as a way of
navigating information in banking mobile applications etc. It is highly
relevant because a frequently asked questions (FAQ) list can only have a finite
amount of questions but a model which can perform question answer generation
could be able to answer completely new questions that are within the scope of
the data. This helps us to be able to answer new questions accurately as long
as it is a relevant question. In commercial applications, it can be used to
increase customer satisfaction and ease of usage. However a lot of data is
generated by humans so it is susceptible to human error and this can adversely
affect the model's performance and we are investigating this through our work
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15514" title="Abstract">arXiv:2311.15514</a> [<a href="/pdf/2311.15514" title="Download PDF">pdf</a>, <a href="/format/2311.15514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Development and Validation of a Dynamic Operating Envelopes-enabled  Demand Response Scheme in Low-voltage Distribution Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lankeshwara%2C+G">Gayan Lankeshwara</a>, 
<a href="/search/eess?searchtype=author&query=Sharma%2C+R">Rahul Sharma</a>, 
<a href="/search/eess?searchtype=author&query=Alam%2C+M+R">M. R. Alam</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+R">Ruifeng Yan</a>, 
<a href="/search/eess?searchtype=author&query=Saha%2C+T+K">Tapan K. Saha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE Transactions on Power Systems, 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Dynamic operating envelopes (DOEs) offer an attractive solution for
maintaining network integrity amidst increasing penetration of distributed
energy resources (DERs) in low-voltage (LV) networks. Currently, the focus of
DOEs primarily revolves around active power exports of rooftop photovoltaic
(PV) generation, often neglecting the impact of demand response (DR). This
paper presents a two-stage, coordinated approach for residential DR
participation in electricity markets under the DOE framework. In the first
stage, the distribution network service provider (DNSP) adopts a convex hull
technique to establish DOEs at each customer point-of-connection (POC). In the
second stage, the demand response aggregator (DRA) utilises DOEs assigned by
the DNSP to develop a hierarchical control scheme for tracking a load set-point
signal without jeopardising network statutory limits. To assess the
effectiveness of the proposed control scheme in a practical setting,
software-in-the-loop (SIL) tests are performed in a grid simulator, considering
a real residential feeder with realistic household load and generation
profiles. Simulation validations suggest that the DRA can provide precise DR
while honouring network statutory limits and maintaining end-user thermal
comfort. Furthermore, the overall approach is compliant with the market
dispatch interval and preserves end-user data privacy.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15516" title="Abstract">arXiv:2311.15516</a> [<a href="/pdf/2311.15516" title="Download PDF">pdf</a>, <a href="/format/2311.15516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Foundational Models for Fault Diagnosis of Electrical Motors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Anbalagan%2C+S">Sriram Anbalagan</a>, 
<a href="/search/eess?searchtype=author&query=GP%2C+S+S">Sai Shashank GP</a>, 
<a href="/search/eess?searchtype=author&query=Agarwal%2C+D">Deepesh Agarwal</a>, 
<a href="/search/eess?searchtype=author&query=Natarajan%2C+B">Balasubramaniam Natarajan</a>, 
<a href="/search/eess?searchtype=author&query=Srinivasan%2C+B">Babji Srinivasan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 2 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Fault detection and diagnosis of electrical motors are of utmost importance
in ensuring the safe and reliable operation of several industrial systems.
Detection and diagnosis of faults at the incipient stage allows corrective
actions to be taken in order to reduce the severity of faults. The existing
data-driven deep learning approaches for machine fault diagnosis rely
extensively on huge amounts of labeled samples, where annotations are expensive
and time-consuming. However, a major portion of unlabeled condition monitoring
data is not exploited in the training process. To overcome this limitation, we
propose a foundational model-based Active Learning framework that utilizes less
amount of labeled samples, which are most informative and harnesses a large
amount of available unlabeled data by effectively combining Active Learning and
Contrastive Self-Supervised Learning techniques. It consists of a transformer
network-based backbone model trained using an advanced nearest-neighbor
contrastive self-supervised learning method. This approach empowers the
backbone to learn improved representations of samples derived from raw,
unlabeled vibration data. Subsequently, the backbone can undergo fine-tuning to
address a range of downstream tasks, both within the same machines and across
different machines. The effectiveness of the proposed methodology has been
assessed through the fine-tuning of the backbone for multiple target tasks
using three distinct machine-bearing fault datasets. The experimental
evaluation demonstrates a superior performance as compared to existing
state-of-the-art fault diagnosis methods with less amount of labeled data.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15525" title="Abstract">arXiv:2311.15525</a> [<a href="/pdf/2311.15525" title="Download PDF">pdf</a>, <a href="/format/2311.15525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overview of the VLSP 2022 -- Abmusu Shared Task: A Data Challenge for  Vietnamese Abstractive Multi-document Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+M">Mai-Vu Tran</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+H">Hoang-Quynh Le</a>, 
<a href="/search/cs?searchtype=author&query=Can%2C+D">Duy-Cat Can</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q">Quoc-An Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> VLSP 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper reports the overview of the VLSP 2022 - Vietnamese abstractive
multi-document summarization (Abmusu) shared task for Vietnamese News. This
task is hosted at the 9$^{th}$ annual workshop on Vietnamese Language and
Speech Processing (VLSP 2022). The goal of Abmusu shared task is to develop
summarization systems that could create abstractive summaries automatically for
a set of documents on a topic. The model input is multiple news documents on
the same topic, and the corresponding output is a related abstractive summary.
In the scope of Abmusu shared task, we only focus on Vietnamese news
summarization and build a human-annotated dataset of 1,839 documents in 600
clusters, collected from Vietnamese news in 8 categories. Participated models
are evaluated and ranked in terms of \texttt{ROUGE2-F1} score, the most typical
evaluation metric for document summarization problem.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15526" title="Abstract">arXiv:2311.15526</a> [<a href="/pdf/2311.15526" title="Download PDF">pdf</a>, <a href="/format/2311.15526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unfitted finite element method for the quad-curl interface problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Guo%2C+H">Hailong Guo</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+M">Mingyan Zhang</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Q">Qian Zhang</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Z">Zhimin Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we introduce a novel unfitted finite element method to solve
the quad-curl interface problem. We adapt Nitsche's method for
curlcurl-conforming elements and double the degrees of freedom on interface
elements. To ensure stability, we incorporate ghost penalty terms and a
discrete divergence-free term. We establish the well-posedness of our method
and demonstrate an optimal error bound in the discrete energy norm. We also
analyze the stiffness matrix's condition number. Our numerical tests back up
our theory on convergence rates and condition numbers.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15529" title="Abstract">arXiv:2311.15529</a> [<a href="/pdf/2311.15529" title="Download PDF">pdf</a>, <a href="/format/2311.15529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Dataset Distillation via Minimax Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jianyang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Vahidian%2C+S">Saeed Vahidian</a>, 
<a href="/search/cs?searchtype=author&query=Kungurtsev%2C+V">Vyacheslav Kungurtsev</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haonan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yang You</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiran Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Dataset distillation reduces the storage and computational consumption of
training a network by generating a small surrogate dataset that encapsulates
rich information of the original large-scale one. However, previous
distillation methods heavily rely on the sample-wise iterative optimization
scheme. As the images-per-class (IPC) setting or image resolution grows larger,
the necessary computation will demand overwhelming time and resources. In this
work, we intend to incorporate generative diffusion techniques for computing
the surrogate dataset. Observing that key factors for constructing an effective
surrogate dataset are representativeness and diversity, we design additional
minimax criteria in the generative training to enhance these facets for the
generated images of diffusion models. We present a theoretical model of the
process as hierarchical diffusion control demonstrating the flexibility of the
diffusion process to target these criteria without jeopardizing the
faithfulness of the sample to the desired distribution. The proposed method
achieves state-of-the-art validation performance while demanding much less
computational resources. Under the 100-IPC setting on ImageWoof, our method
requires less than one-twentieth the distillation time of previous methods, yet
yields even better performance. Source code available in
https://github.com/vimar-gu/MinimaxDiffusion.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15530" title="Abstract">arXiv:2311.15530</a> [<a href="/pdf/2311.15530" title="Download PDF">pdf</a>, <a href="/format/2311.15530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SSIN: Self-Supervised Learning for Rainfall Spatial Interpolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yanyan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lei Chen</a>, 
<a href="/search/cs?searchtype=author&query=NG%2C+C+W+W">Charles Wang Wai NG</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGMOD 2023 Data-intensive Applications (DIA) Track; Code is available at <a href="https://github.com/jlidw/SSIN">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">The acquisition of accurate rainfall distribution in space is an important
task in hydrological analysis and natural disaster pre-warning. However, it is
impossible to install rain gauges on every corner. Spatial interpolation is a
common way to infer rainfall distribution based on available raingauge data.
However, the existing works rely on some unrealistic pre-settings to capture
spatial correlations, which limits their performance in real scenarios. To
tackle this issue, we propose the SSIN, which is a novel data-driven
self-supervised learning framework for rainfall spatial interpolation by mining
latent spatial patterns from historical observation data. Inspired by the Cloze
task and BERT, we fully consider the characteristics of spatial interpolation
and design the SpaFormer model based on the Transformer architecture as the
core of SSIN. Our main idea is: by constructing rich self-supervision signals
via random masking, SpaFormer can learn informative embeddings for raw data and
then adaptively model spatial correlations based on rainfall spatial context.
Extensive experiments on two real-world raingauge datasets show that our method
outperforms the state-of-the-art solutions. In addition, we take traffic
spatial interpolation as another use case to further explore the performance of
our method, and SpaFormer achieves the best performance on one large real-world
traffic dataset, which further confirms the effectiveness and generality of our
method.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15531" title="Abstract">arXiv:2311.15531</a> [<a href="/pdf/2311.15531" title="Download PDF">pdf</a>, <a href="/format/2311.15531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sleep When Everything Looks Fine: Self-Triggered Monitoring for Signal  Temporal Logic Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Chuwei Wang</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+X">Xinyi Yu</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+J">Jianing Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Lindemann%2C+L">Lars Lindemann</a>, 
<a href="/search/eess?searchtype=author&query=Yin%2C+X">Xiang Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Online monitoring is a widely used technique in assessing if the performance
of the system satisfies some desired requirements during run-time operation.
Existing works on online monitoring usually assume that the monitor can acquire
system information periodically at each time instant. However, such a periodic
mechanism may be unnecessarily energy-consuming as it essentially requires to
turn on sensors consistently. In this paper, we proposed a novel self-triggered
mechanism for model-based online monitoring of discrete-time dynamical system
under specifications described by signal temporal logic (STL) formulae.
Specifically, instead of sampling the system state at each time instant, a
self-triggered monitor can actively determine when the next system state is
sampled in addition to its monitoring decision regarding the satisfaction of
the task. We propose an effective algorithm for synthesizing such a
self-triggered monitor that can correctly evaluate a given STL formula
on-the-fly while maximizing the time interval between two observations. We show
that, compared with the standard online monitor with periodic information, the
proposed self-triggered monitor can significantly reduce observation burden
while ensuring that no information of the STL formula is lost. Case studies are
provided to illustrate the proposed monitoring mechanism.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15536" title="Abstract">arXiv:2311.15536</a> [<a href="/pdf/2311.15536" title="Download PDF">pdf</a>, <a href="/format/2311.15536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SVRDA: A Web-based Dataset Annotation Tool for Slice-to-Volume  Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Weixun Luo</a>, 
<a href="/search/cs?searchtype=author&query=Bagur%2C+A+T">Alexandre Triay Bagur</a>, 
<a href="/search/cs?searchtype=author&query=Aljabar%2C+P">Paul Aljabar</a>, 
<a href="/search/cs?searchtype=author&query=Ralli%2C+G">George Ralli</a>, 
<a href="/search/cs?searchtype=author&query=Brady%2C+S+M">Sir Michael Brady</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 11 figures, In submission to Computer Methods and Programs in Biomedicine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Background and Objective: The lack of benchmark datasets has impeded the
development of slice-to-volume registration algorithms. Such datasets are
difficult to annotate, primarily due to the dimensional difference within data
and the dearth of task-specific software. We aim to develop a user-friendly
tool to streamline dataset annotation for slice-to-volume registration.
<br />Methods: The proposed tool, named SVRDA, is an installation-free web
application for platform-agnostic collaborative dataset annotation. It enables
efficient transformation manipulation via keyboard shortcuts and smooth case
transitions with auto-saving. SVRDA supports configuration-based data loading
and adheres to the separation of concerns, offering great flexibility and
extensibility for future research. Various supplementary features have been
implemented to facilitate slice-to-volume registration.
<br />Results: We validated the effectiveness of SVRDA by indirectly evaluating the
post-registration segmentation quality on UK Biobank data, observing a dramatic
overall improvement (24.02% in the Dice Similarity Coefficient and 48.93% in
the 95th percentile Hausdorff distance, respectively) supported by highly
statistically significant evidence ($p&lt;0.001$).We further showcased the
clinical usage of SVRDA by integrating it into test-retest T1 quantification on
in-house magnetic resonance images, leading to more consistent results after
registration.
<br />Conclusions: SVRDA can facilitate collaborative annotation of benchmark
datasets while being potentially applicable to other pipelines incorporating
slice-to-volume registration. Full source code and documentation are available
at https://github.com/Roldbach/SVRDA
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15537" title="Abstract">arXiv:2311.15537</a> [<a href="/pdf/2311.15537" title="Download PDF">pdf</a>, <a href="/format/2311.15537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SED: A Simple Encoder-Decoder for Open-Vocabulary Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+B">Bin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiale Cao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+F+S">Fahad Shahbaz Khan</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+Y">Yanwei Pang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Open-vocabulary semantic segmentation strives to distinguish pixels into
different semantic groups from an open set of categories. Most existing methods
explore utilizing pre-trained vision-language models, in which the key is to
adopt the image-level model for pixel-level segmentation task. In this paper,
we propose a simple encoder-decoder, named SED, for open-vocabulary semantic
segmentation, which comprises a hierarchical encoder-based cost map generation
and a gradual fusion decoder with category early rejection. The hierarchical
encoder-based cost map generation employs hierarchical backbone, instead of
plain transformer, to predict pixel-level image-text cost map. Compared to
plain transformer, hierarchical backbone better captures local spatial
information and has linear computational complexity with respect to input size.
Our gradual fusion decoder employs a top-down structure to combine cost map and
the feature maps of different backbone levels for segmentation. To accelerate
inference speed, we introduce a category early rejection scheme in the decoder
that rejects many no-existing categories at the early layer of decoder,
resulting in at most 4.7 times acceleration without accuracy degradation.
Experiments are performed on multiple open-vocabulary semantic segmentation
datasets, which demonstrates the efficacy of our SED method. When using
ConvNeXt-B, our SED method achieves mIoU score of 31.6\% on ADE20K with 150
categories at 82 millisecond ($ms$) per image on a single A6000. We will
release it at \url{https://github.com/xb534/SED.git}.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15540" title="Abstract">arXiv:2311.15540</a> [<a href="/pdf/2311.15540" title="Download PDF">pdf</a>, <a href="/ps/2311.15540" title="Download PostScript">ps</a>, <a href="/format/2311.15540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EAFP-Med: An Efficient Adaptive Feature Processing Module Based on  Prompts for Medical Image Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+L">Long Lan</a>, 
<a href="/search/cs?searchtype=author&query=Lahza%2C+H">Husam Lahza</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shaowu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuihua Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenjing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hengzhu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yudong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">In the face of rapid advances in medical imaging, cross-domain adaptive
medical image detection is challenging due to the differences in lesion
representations across various medical imaging technologies. To address this
issue, we draw inspiration from large language models to propose EAFP-Med, an
efficient adaptive feature processing module based on prompts for medical image
detection. EAFP-Med can efficiently extract lesion features of different scales
from a diverse range of medical images based on prompts while being flexible
and not limited by specific imaging techniques. Furthermore, it serves as a
feature preprocessing module that can be connected to any model front-end to
enhance the lesion features in input images. Moreover, we propose a novel
adaptive disease detection model named EAFP-Med ST, which utilizes the Swin
Transformer V2 - Tiny (SwinV2-T) as its backbone and connects it to EAFP-Med.
We have compared our method to nine state-of-the-art methods. Experimental
results demonstrate that EAFP-Med ST achieves the best performance on all three
datasets (chest X-ray images, cranial magnetic resonance imaging images, and
skin images). EAFP-Med can efficiently extract lesion features from various
medical images based on prompts, enhancing the model's performance. This holds
significant potential for improving medical image analysis and diagnosis.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15543" title="Abstract">arXiv:2311.15543</a> [<a href="/pdf/2311.15543" title="Download PDF">pdf</a>, <a href="/format/2311.15543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Pixels: Exploring Human-Readable SVG Generation for Simple Images  with Vision Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haoyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peiyan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yuxuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haohan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the field of computer graphics, the use of vector graphics, particularly
Scalable Vector Graphics (SVG), represents a notable development from
traditional pixel-based imagery. SVGs, with their XML-based format, are
distinct in their ability to directly and explicitly represent visual elements
such as shape, color, and path. This direct representation facilitates a more
accurate and logical depiction of graphical elements, enhancing reasoning and
interpretability. Recognizing the potential of SVGs, the machine learning
community has introduced multiple methods for image vectorization. However,
transforming images into SVG format while retaining the relational properties
and context of the original scene remains a key challenge. Most vectorization
methods often yield SVGs that are overly complex and not easily interpretable.
In response to this challenge, we introduce our method, Simple-SVG-Generation
(S\textsuperscript{2}VG\textsuperscript{2}). Our method focuses on producing
SVGs that are both accurate and simple, aligning with human readability and
understanding. With simple images, we evaluate our method with reasoning tasks
together with advanced language models, the results show a clear improvement
over previous SVG generation methods. We also conducted surveys for human
evaluation on the readability of our generated SVGs, the results also favor our
methods.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15544" title="Abstract">arXiv:2311.15544</a> [<a href="/pdf/2311.15544" title="Download PDF">pdf</a>, <a href="/format/2311.15544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The effect of source disclosure on evaluation of AI-generated messages:  A two-part study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Sue Lim</a>, 
<a href="/search/cs?searchtype=author&query=Schm%C3%A4lzle%2C+R">Ralf Schm&#xe4;lzle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Manuscript currently under review. Paper presented at 109th Annual National Communication Association (NCA) Conference, November 16-19, 2023. 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Advancements in artificial intelligence (AI) over the last decade demonstrate
that machines can exhibit communicative behavior and influence how humans
think, feel, and behave. In fact, the recent development of ChatGPT has shown
that large language models (LLMs) can be leveraged to generate high-quality
communication content at scale and across domains, suggesting that they will be
increasingly used in practice. However, many questions remain about how knowing
the source of the messages influences recipients' evaluation of and preference
for AI-generated messages compared to human-generated messages. This paper
investigated this topic in the context of vaping prevention messaging. In Study
1, which was pre-registered, we examined the influence of source disclosure on
people's evaluation of AI-generated health prevention messages compared to
human-generated messages. We found that source disclosure (i.e., labeling the
source of a message as AI vs. human) significantly impacted the evaluation of
the messages but did not significantly alter message rankings. In a follow-up
study (Study 2), we examined how the influence of source disclosure may vary by
the participants' negative attitudes towards AI. We found a significant
moderating effect of negative attitudes towards AI on message evaluation, but
not for message selection. However, for those with moderate levels of negative
attitudes towards AI, source disclosure decreased the preference for
AI-generated messages. Overall, the results of this series of studies showed a
slight bias against AI-generated messages once the source was disclosed, adding
to the emerging area of study that lies at the intersection of AI and
communication.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15545" title="Abstract">arXiv:2311.15545</a> [<a href="/pdf/2311.15545" title="Download PDF">pdf</a>, <a href="/format/2311.15545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Out-of-Distribution Generalized Dynamic Graph Neural Network for Human  Albumin Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingwang Li</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+F">Fei Teng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+N">Ning Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xueling Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenwu Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MedAI'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Human albumin is essential for indicating the body's overall health.
Accurately predicting plasma albumin levels and determining appropriate doses
are urgent clinical challenges, particularly in critically ill patients, to
maintain optimal blood levels. However, human albumin prediction is non-trivial
that has to leverage the dynamics of biochemical markers as well as the
experience of treating patients. Moreover, the problem of distribution shift is
often encountered in real clinical data, which may lead to a decline in the
model prediction performance and reduce the reliability of the model's
application. In this paper, we propose a framework named Out-of-Distribution
Generalized Dynamic Graph Neural Network for Human Albumin Prediction
(DyG-HAP), which is able to provide accurate albumin predictions for Intensity
Care Unit (ICU) patients during hospitalization. We first model human albumin
prediction as a dynamic graph regression problem to model the dynamics and
patient relationship. Then, we propose a disentangled dynamic graph attention
mechanism to capture and disentangle the patterns whose relationship to labels
under distribution shifts is invariant and variant respectively. Last, we
propose an invariant dynamic graph regression method to encourage the model to
rely on invariant patterns to make predictions. Moreover, we propose a dataset
named Albumin level testing and nutritional dosing data for Intensive Care
(ANIC) for evaluation. Extensive experiments demonstrate the superiority of our
method compared to several baseline methods in human albumin prediction.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15546" title="Abstract">arXiv:2311.15546</a> [<a href="/pdf/2311.15546" title="Download PDF">pdf</a>, <a href="/format/2311.15546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Move or Push? Studying Pseudo-Haptic Perceptions Obtained with Motion or  Force Input
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hirao%2C+Y">Yutaro Hirao</a>, 
<a href="/search/cs?searchtype=author&query=Narumi%2C+T">Takuji Narumi</a>, 
<a href="/search/cs?searchtype=author&query=Argelaguet%2C+F">Ferran Argelaguet</a>, 
<a href="/search/cs?searchtype=author&query=Lecuyer%2C+A">Anatole Lecuyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is now under review for IEEE Transactions on Visualization and Computer Graphics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Pseudo-haptics techniques are interesting alternatives for generating haptic
perceptions, which entails the manipulation of haptic perception through the
appropriate alteration of primarily visual feedback in response to body
movements. However, the use of pseudo-haptics techniques with a motion-input
system can sometimes be limited. This paper investigates a novel approach for
extending the potential of pseudo-haptics techniques in virtual reality (VR).
The proposed approach utilizes a reaction force from force-input as a
substitution of haptic cue for the pseudo-haptic perception. The paper
introduced a manipulation method in which the vertical acceleration of the
virtual hand is controlled by the extent of push-in of a force sensor. Such a
force-input manipulation of a virtual body can not only present pseudo-haptics
with less physical spaces and be used by more various users including
physically handicapped people, but also can present the reaction force
proportional to the user's input to the user. We hypothesized that such a
haptic force cue would contribute to the pseudo-haptic perception. Therefore,
the paper endeavors to investigate the force-input pseudo-haptic perception in
a comparison with the motion-input pseudo-haptics. The paper compared
force-input and motion-input manipulation in a point of achievable range and
resolution of pseudo-haptic weight. The experimental results suggest that the
force-input manipulation successfully extends the range of perceptible
pseudo-weight by 80\% in comparison to the motion-input manipulation. On the
other hand, it is revealed that the motion-input manipulation has 1 step larger
number of distinguishable weight levels and is easier to operate than the
force-input manipulation.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15547" title="Abstract">arXiv:2311.15547</a> [<a href="/pdf/2311.15547" title="Download PDF">pdf</a>, <a href="/format/2311.15547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dataset Distillation in Latent Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yuxuan Duan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianfu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liqing Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Dataset distillation (DD) is a newly emerging research area aiming at
alleviating the heavy computational load in training models on large datasets.
It tries to distill a large dataset into a small and condensed one so that
models trained on the distilled dataset can perform comparably with those
trained on the full dataset when performing downstream tasks. Among the
previous works in this area, there are three key problems that hinder the
performance and availability of the existing DD methods: high time complexity,
high space complexity, and low info-compactness. In this work, we
simultaneously attempt to settle these three problems by moving the DD
processes from conventionally used pixel space to latent space. Encoded by a
pretrained generic autoencoder, latent codes in the latent space are naturally
info-compact representations of the original images in much smaller sizes.
After transferring three mainstream DD algorithms to latent space, we
significantly reduce time and space consumption while achieving similar
performance, allowing us to distill high-resolution datasets or target at
greater data ratio that previous methods have failed. Besides, within the same
storage budget, we can also quantitatively deliver more latent codes than
pixel-level images, which further boosts the performance of our methods.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15548" title="Abstract">arXiv:2311.15548</a> [<a href="/pdf/2311.15548" title="Download PDF">pdf</a>, <a href="/format/2311.15548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deficiency of Large Language Models in Finance: An Empirical Examination  of Hallucination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+H">Haoqiang Kang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao-Yang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Statistical Finance (q-fin.ST)

</div>
<p class="mathjax">The hallucination issue is recognized as a fundamental deficiency of large
language models (LLMs), especially when applied to fields such as finance,
education, and law. Despite the growing concerns, there has been a lack of
empirical investigation. In this paper, we provide an empirical examination of
LLMs' hallucination behaviors in financial tasks. First, we empirically
investigate LLM model's ability of explaining financial concepts and
terminologies. Second, we assess LLM models' capacity of querying historical
stock prices. Third, to alleviate the hallucination issue, we evaluate the
efficacy of four practical methods, including few-shot learning, Decoding by
Contrasting Layers (DoLa), the Retrieval Augmentation Generation (RAG) method
and the prompt-based tool learning method for a function to generate a query
command. Finally, our major finding is that off-the-shelf LLMs experience
serious hallucination behaviors in financial tasks. Therefore, there is an
urgent need to call for research efforts in mitigating LLMs' hallucination.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15551" title="Abstract">arXiv:2311.15551</a> [<a href="/pdf/2311.15551" title="Download PDF">pdf</a>, <a href="/format/2311.15551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instruct2Attack: Language-Guided Semantic Adversarial Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+C">Chen Wei</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuxiang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Heng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yuille%2C+A">Alan Yuille</a>, 
<a href="/search/cs?searchtype=author&query=Feizi%2C+S">Soheil Feizi</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+C+P">Chun Pong Lau</a>, 
<a href="/search/cs?searchtype=author&query=Chellappa%2C+R">Rama Chellappa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under submission, code coming soon
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">We propose Instruct2Attack (I2A), a language-guided semantic attack that
generates semantically meaningful perturbations according to free-form language
instructions. We make use of state-of-the-art latent diffusion models, where we
adversarially guide the reverse diffusion process to search for an adversarial
latent code conditioned on the input image and text instruction. Compared to
existing noise-based and semantic attacks, I2A generates more natural and
diverse adversarial examples while providing better controllability and
interpretability. We further automate the attack process with GPT-4 to generate
diverse image-specific text instructions. We show that I2A can successfully
break state-of-the-art deep neural networks even under strong adversarial
defenses, and demonstrate great transferability among a variety of network
architectures.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15556" title="Abstract">arXiv:2311.15556</a> [<a href="/pdf/2311.15556" title="Download PDF">pdf</a>, <a href="/format/2311.15556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PKU-I2IQA: An Image-to-Image Quality Assessment Database for AI  Generated Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jiquan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xinyan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changjin Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fanyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jinlong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xixin Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">With the development of image generation technology, AI-based image
generation has been applied in various fields. However, the development of AIGC
image generative models also brings new problems and challenges. A significant
challenge is that AI-generated images (AIGI) compared to natural images may
have some unique distortions, and not all generated images meet the
requirements of the real world, so it is of great significance to evaluate
AI-generated images more comprehensively. Although previous work has
established some human perception-based AIGC image quality assessment databases
for text-generated images, the AI image generation technology includes
scenarios like text-to-image and image-to-image, and assessing only the images
generated by text-to-image models is insufficient. To address this issue, we
have established a human perception-based image-to-image AIGC image quality
assessment database, named PKU-I2IQA. We conducted a comprehensive analysis of
the PKU-I2IQA database. Furthermore, we introduced two benchmark models:
NR-AIGCIQA based on no-reference image quality assessment and FR-AIGCIQA based
on full-reference image quality assessment.Finally, leveraging this database,
we conducted benchmark experiments and compared the performance of the proposed
benchmark models. The PKU-I2IQA database and benchmarks will be released to
facilitate future research on https://github.com/jiquan123/I2IQA.
<br />Keywords: AIGC, image-to-image generation, image quality assessment,
NR-AIGCIQA, FR-AIGCIQA
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15561" title="Abstract">arXiv:2311.15561</a> [<a href="/pdf/2311.15561" title="Download PDF">pdf</a>, <a href="/format/2311.15561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ET3D: Efficient Text-to-3D Generation via Multi-View Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Peidong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent breakthroughs in text-to-image generation has shown encouraging
results via large generative models. Due to the scarcity of 3D assets, it is
hardly to transfer the success of text-to-image generation to that of
text-to-3D generation. Existing text-to-3D generation methods usually adopt the
paradigm of DreamFusion, which conducts per-asset optimization by distilling a
pretrained text-to-image diffusion model. The generation speed usually ranges
from several minutes to tens of minutes per 3D asset, which degrades the user
experience and also imposes a burden to the service providers due to the high
computational budget.
<br />In this work, we present an efficient text-to-3D generation method, which
requires only around 8 $ms$ to generate a 3D asset given the text prompt on a
consumer graphic card. The main insight is that we exploit the images generated
by a large pre-trained text-to-image diffusion model, to supervise the training
of a text conditioned 3D generative adversarial network. Once the network is
trained, we are able to efficiently generate a 3D asset via a single forward
pass. Our method requires no 3D training data and provides an alternative
approach for efficient text-to-3D generation by distilling pre-trained image
diffusion models.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15562" title="Abstract">arXiv:2311.15562</a> [<a href="/pdf/2311.15562" title="Download PDF">pdf</a>, <a href="/format/2311.15562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fully Authentic Visual Question Answering Dataset from Online  Communities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chongyan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mengchen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Codella%2C+N">Noel Codella</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Lu Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Gurari%2C+D">Danna Gurari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual Question Answering (VQA) entails answering questions about images. We
introduce the first VQA dataset in which all contents originate from an
authentic use case. Sourced from online question answering community forums, we
call it VQAonline. We then characterize our dataset and how it relates to eight
other VQA datasets. Observing that answers in our dataset tend to be much
longer (e.g., with a mean of 173 words) and thus incompatible with standard VQA
evaluation metrics, we next analyze which of the six popular metrics for longer
text evaluation align best with human judgments. We then use the best-suited
metrics to evaluate six state-of-the-art vision and language foundation models
on VQAonline and reveal where they struggle most. We will release the dataset
soon to facilitate future extensions.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15563" title="Abstract">arXiv:2311.15563</a> [<a href="/pdf/2311.15563" title="Download PDF">pdf</a>, <a href="/format/2311.15563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noisy Self-Training with Synthetic Queries for Dense Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+F">Fan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Drummond%2C+T">Tom Drummond</a>, 
<a href="/search/cs?searchtype=author&query=Cohn%2C+T">Trevor Cohn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Although existing neural retrieval models reveal promising results when
training data is abundant and the performance keeps improving as training data
increases, collecting high-quality annotated data is prohibitively costly. To
this end, we introduce a novel noisy self-training framework combined with
synthetic queries, showing that neural retrievers can be improved in a
self-evolution manner with no reliance on any external models. Experimental
results show that our method improves consistently over existing methods on
both general-domain (e.g., MS-MARCO) and out-of-domain (i.e., BEIR) retrieval
benchmarks. Extra analysis on low-resource settings reveals that our method is
data efficient and outperforms competitive baselines, with as little as 30% of
labelled training data. Further extending the framework for reranker training
demonstrates that the proposed method is general and yields additional gains on
tasks of diverse domains.\footnote{Source code is available at
\url{https://github.com/Fantabulous-J/Self-Training-DPR}}
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15564" title="Abstract">arXiv:2311.15564</a> [<a href="/pdf/2311.15564" title="Download PDF">pdf</a>, <a href="/format/2311.15564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boot and Switch: Alternating Distillation for Zero-Shot Dense Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+F">Fan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qiongkai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Drummond%2C+T">Tom Drummond</a>, 
<a href="/search/cs?searchtype=author&query=Cohn%2C+T">Trevor Cohn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP 2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Neural 'dense' retrieval models are state of the art for many datasets,
however these models often exhibit limited domain transfer ability. Existing
approaches to adaptation are unwieldy, such as requiring explicit supervision,
complex model architectures, or massive external models. We present
$\texttt{ABEL}$, a simple but effective unsupervised method to enhance passage
retrieval in zero-shot settings. Our technique follows a straightforward loop:
a dense retriever learns from supervision signals provided by a reranker, and
subsequently, the reranker is updated based on feedback from the improved
retriever. By iterating this loop, the two components mutually enhance one
another's performance. Experimental results demonstrate that our unsupervised
$\texttt{ABEL}$ model outperforms both leading supervised and unsupervised
retrievers on the BEIR benchmark. Meanwhile, it exhibits strong adaptation
abilities to tasks and domains that were unseen during training. By either
fine-tuning $\texttt{ABEL}$ on labelled data or integrating it with existing
supervised dense retrievers, we achieve state-of-the-art
results.\footnote{Source code is available at
\url{https://github.com/Fantabulous-J/BootSwitch}.}
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15565" title="Abstract">arXiv:2311.15565</a> [<a href="/pdf/2311.15565" title="Download PDF">pdf</a>, <a href="/ps/2311.15565" title="Download PostScript">ps</a>, <a href="/format/2311.15565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Efficacy of Hybrid Deep Learning Models in Distinguishing  AI-Generated Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oketunji%2C+F">Finbarrs Oketunji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">My research investigates the use of cutting-edge hybrid deep learning models
to accurately differentiate between AI-generated text and human writing. I
applied a robust methodology, utilising a carefully selected dataset comprising
AI and human texts from various sources, each tagged with instructions.
Advanced natural language processing techniques facilitated the analysis of
textual features. Combining sophisticated neural networks, the custom model
enabled it to detect nuanced differences between AI and human content.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15566" title="Abstract">arXiv:2311.15566</a> [<a href="/pdf/2311.15566" title="Download PDF">pdf</a>, <a href="/format/2311.15566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpotServe: Serving Generative Large Language Models on Preemptible  Instances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miao%2C+X">Xupeng Miao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chunan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+J">Jiangfei Duan</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+X">Xiaoli Xi</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+B">Bin Cui</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Z">Zhihao Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ASPLOS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">The high computational and memory requirements of generative large language
models (LLMs) make it challenging to serve them cheaply. This paper aims to
reduce the monetary cost for serving LLMs by leveraging preemptible GPU
instances on modern clouds, which offer accesses to spare GPUs at a much
cheaper price than regular instances but may be preempted by the cloud at any
time. Serving LLMs on preemptible instances requires addressing challenges
induced by frequent instance preemptions and the necessity of migrating
instances to handle these preemptions.
<br />This paper presents SpotServe, the first distributed LLM serving system on
preemptible instances. Several key techniques in SpotServe realize fast and
reliable serving of generative LLMs on cheap preemptible instances. First,
SpotServe dynamically adapts the LLM parallelization configuration for dynamic
instance availability and fluctuating workload, while balancing the trade-off
among the overall throughput, inference latency and monetary costs. Second, to
minimize the cost of migrating instances for dynamic reparallelization, the
task of migrating instances is formulated as a bipartite graph matching
problem, which uses the Kuhn-Munkres algorithm to identify an optimal migration
plan that minimizes communications. Finally, to take advantage of the grace
period offered by modern clouds, we introduce stateful inference recovery, a
new inference mechanism that commits inference progress at a much finer
granularity and allows SpotServe to cheaply resume inference upon preemption.
We evaluate on real spot instance preemption traces and various popular LLMs
and show that SpotServe can reduce the P99 tail latency by 2.4 - 9.1x compared
with the best existing LLM serving systems. We also show that SpotServe can
leverage the price advantage of preemptive instances, saving 54% monetary cost
compared with only using on-demand instances.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15569" title="Abstract">arXiv:2311.15569</a> [<a href="/pdf/2311.15569" title="Download PDF">pdf</a>, <a href="/format/2311.15569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Adaptability and Generalizability of Efficient Transfer  Learning for Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yongjin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+J">Jongwoo Ko</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+S">Se-Young Yun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages (19 pages including supplementary), 10 figures (12 figures including supplementary), 6 tables (17 tables including supplementary)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Vision-Language Models (VLMs) like CLIP have demonstrated remarkable
applicability across a variety of downstream tasks, including zero-shot image
classification. Recently, the use of prompts or adapters for efficient transfer
learning has gained significant attention for effectively adapting to
downstream tasks. However, the roles of vision and text prompts, as well as
adapters in terms of generalization and transfer difficulty, have been
overlooked, limiting performance on unseen tasks. In this paper, we empirically
analyze how VLMs behave when using vision and text prompts, adapters, and a
combination of these components, marking a novel exploration by our study. Our
observations find that utilizing vision prompts for class separability and text
adapters for task adaptation is crucial for adaptability and generalizability.
Moreover, to improve generalization across every domain, we propose an adaptive
ensemble method that effectively combines the general knowledge of VLMs with
task-specific knowledge according to transfer difficulty. Upon experimenting
with extensive benchmarks, our method consistently outperforms all baselines,
particularly on unseen tasks, demonstrating the effectiveness of our proposed
approach.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15570" title="Abstract">arXiv:2311.15570</a> [<a href="/pdf/2311.15570" title="Download PDF">pdf</a>, <a href="/format/2311.15570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UFDA: Universal Federated Domain Adaptation with Practical Assumptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinhui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenghao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Luping Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+W">Wei Xi</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+G">Gairui Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yihan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jizhong Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Conventional Federated Domain Adaptation (FDA) approaches usually demand an
abundance of assumptions, such as label set consistency, which makes them
significantly less feasible for real-world situations and introduces security
hazards. In this work, we propose a more practical scenario named Universal
Federated Domain Adaptation (UFDA). It only requires the black-box model and
the label set information of each source domain, while the label sets of
different source domains could be inconsistent and the target-domain label set
is totally blind. This relaxes the assumptions made by FDA, which are often
challenging to meet in real-world cases and diminish model security. To address
the UFDA scenario, we propose a corresponding framework called Hot-Learning
with Contrastive Label Disambiguation (HCLD), which tackles UFDA's domain
shifts and category gaps problem by using one-hot outputs from the black-box
models of various source domains. Moreover, to better distinguish the shared
and unknown classes, we further present a cluster-level strategy named
Mutual-Voting Decision (MVD) to extract robust consensus knowledge across peer
classes from both source and target domains. The extensive experiments on three
benchmarks demonstrate that our HCLD achieves comparable performance for our
UFDA scenario with much fewer assumptions, compared to the previous
methodologies with many additional assumptions.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15571" title="Abstract">arXiv:2311.15571</a> [<a href="/pdf/2311.15571" title="Download PDF">pdf</a>, <a href="/format/2311.15571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video-based Visible-Infrared Person Re-Identification with Auxiliary  Samples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yunhao Du</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+C">Cheng Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhicheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+F">Fei Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Transactions on Information Forensics &amp; Security 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visible-infrared person re-identification (VI-ReID) aims to match persons
captured by visible and infrared cameras, allowing person retrieval and
tracking in 24-hour surveillance systems. Previous methods focus on learning
from cross-modality person images in different cameras. However, temporal
information and single-camera samples tend to be neglected. To crack this nut,
in this paper, we first contribute a large-scale VI-ReID dataset named
BUPTCampus. Different from most existing VI-ReID datasets, it 1) collects
tracklets instead of images to introduce rich temporal information, 2) contains
pixel-aligned cross-modality sample pairs for better modality-invariant
learning, 3) provides one auxiliary set to help enhance the optimization, in
which each identity only appears in a single camera. Based on our constructed
dataset, we present a two-stream framework as baseline and apply Generative
Adversarial Network (GAN) to narrow the gap between the two modalities. To
exploit the advantages introduced by the auxiliary set, we propose a curriculum
learning based strategy to jointly learn from both primary and auxiliary sets.
Moreover, we design a novel temporal k-reciprocal re-ranking method to refine
the ranking list with fine-grained temporal correlation cues. Experimental
results demonstrate the effectiveness of the proposed methods. We also
reproduce 9 state-of-the-art image-based and video-based VI-ReID methods on
BUPTCampus and our methods show substantial superiority to them. The codes and
dataset are available at: https://github.com/dyhBUPT/BUPTCampus.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15573" title="Abstract">arXiv:2311.15573</a> [<a href="/pdf/2311.15573" title="Download PDF">pdf</a>, <a href="/format/2311.15573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EucliDreamer: Fast and High-Quality Texturing for 3D Models with Stable  Diffusion Depth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+C">Cindy Le</a>, 
<a href="/search/cs?searchtype=author&query=Hetang%2C+C">Congrui Hetang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+A">Ang Cao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yihui He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">This paper presents a novel method to generate textures for 3D models given
text prompts and 3D meshes. Additional depth information is taken into account
to perform the Score Distillation Sampling (SDS) process [28] with depth
conditional Stable Diffusion [34]. We ran our model over the open-source
dataset Objaverse [7] and conducted a user study to compare the results with
those of various 3D texturing methods. We have shown that our model can
generate more satisfactory results and produce various art styles for the same
object. In addition, we achieved faster time when generating textures of
comparable quality. We also conduct thorough ablation studies of how different
factors may affect generation quality, including sampling steps, guidance
scale, negative prompts, data augmentation, elevation range, and alternatives
to SDS.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15576" title="Abstract">arXiv:2311.15576</a> [<a href="/pdf/2311.15576" title="Download PDF">pdf</a>, <a href="/format/2311.15576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quadrature Rules on Triangles and Tetrahedra for Multidimensional  Summation-By-Parts Operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Worku%2C+Z+A">Zelalem Arega Worku</a>, 
<a href="/search/math?searchtype=author&query=Hicken%2C+J+E">Jason E. Hicken</a>, 
<a href="/search/math?searchtype=author&query=Zingg%2C+D+W">David W. Zingg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Multidimensional diagonal-norm summation-by-parts (SBP) operators with
collocated volume and facet nodes, known as diagonal-$ \mathsf{E} $ operators,
are attractive for entropy-stable discretizations from an efficiency
standpoint. However, there is a limited number of such operators, and those
currently in existence often have a relatively high node count for a given
polynomial order due to a scarcity of suitable quadrature rules. We present
several new symmetric positive-weight quadrature rules on triangles and
tetrahedra that are suitable for construction of diagonal-$ \mathsf{E} $ SBP
operators. For triangles, quadrature rules of degree one through twenty with
facet nodes that correspond to the Legendre-Gauss-Lobatto (LGL) and
Legendre-Gauss (LG) quadrature rules are derived. For tetrahedra, quadrature
rules of degree one through ten are presented along with the corresponding
facet quadrature rules. All of the quadrature rules are provided in a
supplementary data repository. The quadrature rules are used to construct novel
SBP diagonal-$ \mathsf{E} $ operators, whose accuracy and maximum timestep
restrictions are studied numerically.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15578" title="Abstract">arXiv:2311.15578</a> [<a href="/pdf/2311.15578" title="Download PDF">pdf</a>, <a href="/format/2311.15578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimental Analysis of Large-scale Learnable Vector Storage  Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hailin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Penghao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+X">Xupeng Miao</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Yingxia Shao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zirui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+B">Bin Cui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Databases (cs.DB); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Learnable embedding vector is one of the most important applications in
machine learning, and is widely used in various database-related domains.
However, the high dimensionality of sparse data in recommendation tasks and the
huge volume of corpus in retrieval-related tasks lead to a large memory
consumption of the embedding table, which poses a great challenge to the
training and deployment of models. Recent research has proposed various methods
to compress the embeddings at the cost of a slight decrease in model quality or
the introduction of other overheads. Nevertheless, the relative performance of
these methods remains unclear. Existing experimental comparisons only cover a
subset of these methods and focus on limited metrics. In this paper, we perform
a comprehensive comparative analysis and experimental evaluation of embedding
compression. We introduce a new taxonomy that categorizes these techniques
based on their characteristics and methodologies, and further develop a modular
benchmarking framework that integrates 14 representative methods. Under a
uniform test environment, our benchmark fairly evaluates each approach,
presents their strengths and weaknesses under different memory budgets, and
recommends the best method based on the use case. In addition to providing
useful guidelines, our study also uncovers the limitations of current methods
and suggests potential directions for future research.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15581" title="Abstract">arXiv:2311.15581</a> [<a href="/pdf/2311.15581" title="Download PDF">pdf</a>, <a href="/format/2311.15581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real Time GAZED: Online Shot Selection and Editing of Virtual Cameras  from Wide-Angle Monocular Video Recordings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Achary%2C+S">Sudheer Achary</a>, 
<a href="/search/cs?searchtype=author&query=Girmaji%2C+R">Rohit Girmaji</a>, 
<a href="/search/cs?searchtype=author&query=Deshmukh%2C+A+A">Adhiraj Anil Deshmukh</a>, 
<a href="/search/cs?searchtype=author&query=Gandhi%2C+V">Vineet Gandhi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Human-Computer Interaction (cs.HC); Multimedia (cs.MM)

</div>
<p class="mathjax">Eliminating time-consuming post-production processes and delivering
high-quality videos in today's fast-paced digital landscape are the key
advantages of real-time approaches. To address these needs, we present Real
Time GAZED: a real-time adaptation of the GAZED framework integrated with
CineFilter, a novel real-time camera trajectory stabilization approach. It
enables users to create professionally edited videos in real-time. Comparative
evaluations against baseline methods, including the non-real-time GAZED,
demonstrate that Real Time GAZED achieves similar editing results, ensuring
high-quality video output. Furthermore, a user study confirms the aesthetic
quality of the video edits produced by the Real Time GAZED approach. With these
advancements in real-time camera trajectory optimization and video editing
presented, the demand for immediate and dynamic content creation in industries
such as live broadcasting, sports coverage, news reporting, and social media
content creation can be met more efficiently.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15582" title="Abstract">arXiv:2311.15582</a> [<a href="/pdf/2311.15582" title="Download PDF">pdf</a>, <a href="/format/2311.15582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightly Weighted Automatic Audio Parameter Extraction for the Quality  Assessment of Consensus Auditory-Perceptual Evaluation of Voice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yi-Heng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Tseng%2C+W">Wen-Hsuan Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li-Chin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Ching-Ting Tan</a>, 
<a href="/search/cs?searchtype=author&query=Tsao%2C+Y">Yu Tsao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in IEEE 42th International Conference on Consumer Electronics (ICCE 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The Consensus Auditory-Perceptual Evaluation of Voice is a widely employed
tool in clinical voice quality assessment that is significant for streaming
communication among clinical professionals and benchmarking for the
determination of further treatment. Currently, because the assessment relies on
experienced clinicians, it tends to be inconsistent, and thus, difficult to
standardize. To address this problem, we propose to leverage lightly weighted
automatic audio parameter extraction, to increase the clinical relevance,
reduce the complexity, and enhance the interpretability of voice quality
assessment. The proposed method utilizes age, sex, and five audio parameters:
jitter, absolute jitter, shimmer, harmonic-to-noise ratio (HNR), and zero
crossing. A classical machine learning approach is employed. The result reveals
that our approach performs similar to state-of-the-art (SOTA) methods, and
outperforms the latent representation obtained by using popular audio
pre-trained models. This approach provide insights into the feasibility of
different feature extraction approaches for voice evaluation. Audio parameters
such as jitter and the HNR are proven to be suitable for characterizing voice
quality attributes, such as roughness and strain. Conversely, pre-trained
models exhibit limitations in effectively addressing noise-related scorings.
This study contributes toward more comprehensive and precise voice quality
evaluations, achieved by a comprehensively exploring diverse assessment
methodologies.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15583" title="Abstract">arXiv:2311.15583</a> [<a href="/pdf/2311.15583" title="Download PDF">pdf</a>, <a href="/format/2311.15583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple Geometric-Aware Indoor Positioning Interpolation Algorithm  Based on Manifold Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Suorong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Geng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+F">Furao Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Interpolation methodologies have been widely used within the domain of indoor
positioning systems. However, existing indoor positioning interpolation
algorithms exhibit several inherent limitations, including reliance on complex
mathematical models, limited flexibility, and relatively low precision. To
enhance the accuracy and efficiency of indoor positioning interpolation
techniques, this paper proposes a simple yet powerful geometric-aware
interpolation algorithm for indoor positioning tasks. The key to our algorithm
is to exploit the geometric attributes of the local topological manifold using
manifold learning principles. Therefore, instead of constructing complicated
mathematical models, the proposed algorithm facilitates the more precise and
efficient estimation of points grounded in the local topological manifold.
Moreover, our proposed method can be effortlessly integrated into any indoor
positioning system, thereby bolstering its adaptability. Through a systematic
array of experiments and comprehensive performance analyses conducted on both
simulated and real-world datasets, we demonstrate that the proposed algorithm
consistently outperforms the most commonly used and representative
interpolation approaches regarding interpolation accuracy and efficiency.
Furthermore, the experimental results also underscore the substantial practical
utility of our method and its potential applicability in real-time indoor
positioning scenarios.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15592" title="Abstract">arXiv:2311.15592</a> [<a href="/pdf/2311.15592" title="Download PDF">pdf</a>, <a href="/format/2311.15592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calder&#xf3;n Strategies for the Convolution Quadrature Time Domain  Electric Field Integral Equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cordel%2C+P">Pierrick Cordel</a>, 
<a href="/search/math?searchtype=author&query=D%C3%A9ly%2C+A">Alexandre D&#xe9;ly</a>, 
<a href="/search/math?searchtype=author&query=Merlini%2C+A">Adrien Merlini</a>, 
<a href="/search/math?searchtype=author&query=Andriulli%2C+F+P">Francesco P. Andriulli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 9 images, 1 table, Journal paper submitted to IEEE OJAP (Open Journal of Antennas and Propagation)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this work, we introduce new integral formulations based on the convolution
quadrature method for the time-domain modeling of perfectly electrically
conducting scatterers that overcome some of the most critical issues of the
standard schemes based on the electric field integral equation (EFIE). The
standard time-domain EFIE-based approaches typically yield matrices that become
increasingly ill-conditioned as the time-step or the mesh discretization
density increase and suffer from the well-known DC instability. This work
presents solutions to these issues that are based both on new Calder\'on
strategies and quasi-Helmholtz projectors regularizations. In addition, to
ensure an efficient computation of the marching-on-in-time, the proposed
schemes leverage properties of the Z-transform -- involved in the convolution
quadrature discretization scheme -- when computing the stabilized operators.
The two resulting formulations compare favorably with standard,
well-established schemes. The properties and practical relevance of these new
formulations will be showcased through relevant numerical examples that include
canonical geometries and more complex structures.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15593" title="Abstract">arXiv:2311.15593</a> [<a href="/pdf/2311.15593" title="Download PDF">pdf</a>, <a href="/format/2311.15593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance Analysis of MDMA-Based Cooperative MRC Networks with Relays  in Dissimilar Rayleigh Fading Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teng%2C+L">Lei Teng</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+W">Wannian An</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+C">Chen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+X">Xiaoqi Qin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaodong Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Performance (cs.PF); Signal Processing (eess.SP)

</div>
<p class="mathjax">Multiple access technology is a key technology in various generations of
wireless communication systems. As a potential multiple access technology for
the next generation wireless communication systems, model division multiple
access (MDMA) technology improves spectrum efficiency and feasibility regions.
This implies that the MDMA scheme can achieve greater performance gains
compared to traditional schemes. Relayassisted cooperative networks, as a
infrastructure of wireless communication, can effectively utilize resources and
improve performance when MDMA is applied. In this paper, a communication relay
cooperative network based on MDMA in dissimilar rayleigh fading channels is
proposed, which consists of two source nodes, any number of decode-and-forward
(DF) relay nodes, and one destination node, as well as using the maximal ratio
combining (MRC) at the destination to combine the signals received from the
source and relays. By applying the state transition matrix (STM) and moment
generating function (MGF), closed-form analytical solutions for outage
probability and resource utilization efficiency are derived. Theoretical and
simulation results are conducted to verify the validity of the theoretical
analysis.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15594" title="Abstract">arXiv:2311.15594</a> [<a href="/pdf/2311.15594" title="Download PDF">pdf</a>, <a href="/ps/2311.15594" title="Download PostScript">ps</a>, <a href="/format/2311.15594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Networked Multiagent Safe Reinforcement Learning for Low-carbon Demand  Management in Distribution Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jichen Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Sang%2C+L">Linwei Sang</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Y">Yinliang Xu</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+H">Hongbin Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transactions on Sustainable Energy
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper proposes a multiagent based bi-level operation framework for the
low-carbon demand management in distribution networks considering the carbon
emission allowance on the demand side. In the upper level, the aggregate load
agents optimize the control signals for various types of loads to maximize the
profits; in the lower level, the distribution network operator makes optimal
dispatching decisions to minimize the operational costs and calculates the
distribution locational marginal price and carbon intensity. The distributed
flexible load agent has only incomplete information of the distribution network
and cooperates with other agents using networked communication. Finally, the
problem is formulated into a networked multi-agent constrained Markov decision
process, which is solved using a safe reinforcement learning algorithm called
consensus multi-agent constrained policy optimization considering the carbon
emission allowance for each agent. Case studies with the IEEE 33-bus and
123-bus distribution network systems demonstrate the effectiveness of the
proposed approach, in terms of satisfying the carbon emission constraint on
demand side, ensuring the safe operation of the distribution network and
preserving privacy of both sides.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15595" title="Abstract">arXiv:2311.15595</a> [<a href="/pdf/2311.15595" title="Download PDF">pdf</a>, <a href="/format/2311.15595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error Performance of Coded AFDM Systems in Doubly Selective Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Haoran Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Affine frequency division multiplexing (AFDM) is a strong candidate for the
sixth-generation wireless network thanks to its strong resilience to
delay-Doppler spreads. In this letter, we investigate the error performance of
coded AFDM systems in doubly selective channels. We first study the conditional
pairwise-error probability (PEP) of AFDM system and derive its conditional
coding gain. Then, we show that there is a fundamental trade-off between the
diversity gain and the coding gain of AFDM system, namely the coding gain
declines with a descending speed with respect to the number of separable paths,
while the diversity gain increases linearly. Moreover, we propose a
near-optimal turbo decoder based on the sum-product algorithm for coded AFDM
systems to improve its error performance. Simulation results verify our
analyses and the effectiveness of the proposed turbo decoder, showing that AFDM
outperforms orthogonal frequency division multiplexing (OFDM) and orthogonal
time frequency space (OTFS) in both coded and uncoded cases over high-mobility
channels.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15596" title="Abstract">arXiv:2311.15596</a> [<a href="/pdf/2311.15596" title="Download PDF">pdf</a>, <a href="/format/2311.15596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Vision-Language Models Think from a First-Person Perspective?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Sijie Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhicheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jingwen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+K">Kechen Fang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huaping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Vision-language models (VLMs) have recently shown promising results in
traditional downstream tasks. Evaluation studies have emerged to assess their
abilities, with the majority focusing on the third-person perspective, and only
a few addressing specific tasks from the first-person perspective. However, the
capability of VLMs to "think" from a first-person perspective, a crucial
attribute for advancing autonomous agents and robotics, remains largely
unexplored. To bridge this research gap, we introduce EgoThink, a novel visual
question-answering benchmark that encompasses six core capabilities with twelve
detailed dimensions. The benchmark is constructed using selected clips from
egocentric videos, with manually annotated question-answer pairs containing
first-person information. To comprehensively assess VLMs, we evaluate eighteen
popular VLMs on EgoThink. Moreover, given the open-ended format of the answers,
we use GPT-4 as the automatic judge to compute single-answer grading.
Experimental results indicate that although GPT-4V leads in numerous
dimensions, all evaluated VLMs still possess considerable potential for
improvement in first-person perspective tasks. Meanwhile, enlarging the number
of trainable parameters has the most significant impact on model performance on
EgoThink. In conclusion, EgoThink serves as a valuable addition to existing
evaluation benchmarks for VLMs, providing an indispensable resource for future
research in the realm of embodied artificial intelligence and robotics.
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15599" title="Abstract">arXiv:2311.15599</a> [<a href="/pdf/2311.15599" title="Download PDF">pdf</a>, <a href="/format/2311.15599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniRepLKNet: A Universal Perception Large-Kernel ConvNet for Audio,  Video, Point Cloud, Time-Series and Image Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+X">Xiaohan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yixiao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sijie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Lin Song</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+X">Xiangyu Yue</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code, all the models and reproducible training scripts at <a href="https://github.com/AILab-CVC/UniRepLKNet">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large-kernel convolutional neural networks (ConvNets) have recently received
extensive research attention, but there are two unresolved and critical issues
that demand further investigation. 1) The architectures of existing
large-kernel ConvNets largely follow the design principles of conventional
ConvNets or transformers, while the architectural design for large-kernel
ConvNets remains under-addressed. 2) As transformers have dominated multiple
modalities, it remains to be investigated whether ConvNets also have a strong
universal perception ability in domains beyond vision. In this paper, we
contribute from two aspects. 1) We propose four architectural guidelines for
designing large-kernel ConvNets, the core of which is to exploit the essential
characteristics of large kernels that distinguish them from small kernels -
they can see wide without going deep. Following such guidelines, our proposed
large-kernel ConvNet shows leading performance in image recognition. For
example, our models achieve an ImageNet accuracy of 88.0%, ADE20K mIoU of
55.6%, and COCO box AP of 56.4%, demonstrating better performance and higher
speed than a number of recently proposed powerful competitors. 2) We discover
that large kernels are the key to unlocking the exceptional performance of
ConvNets in domains where they were originally not proficient. With certain
modality-related preprocessing approaches, the proposed model achieves
state-of-the-art performance on time-series forecasting and audio recognition
tasks even without modality-specific customization to the architecture. Code
and all the models at https://github.com/AILab-CVC/UniRepLKNet.
</p>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15602" title="Abstract">arXiv:2311.15602</a> [<a href="/pdf/2311.15602" title="Download PDF">pdf</a>, <a href="/format/2311.15602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A nodally bound-preserving finite element method for  reaction-convection-diffusion equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Amiri%2C+A">Abdolreza Amiri</a>, 
<a href="/search/math?searchtype=author&query=Barrenechea%2C+G+R">Gabriel R. Barrenechea</a>, 
<a href="/search/math?searchtype=author&query=Pryer%2C+T">Tristan Pryer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 8 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper introduces a novel approach to approximate a broad range of
reaction-convection-diffusion equations using conforming finite element methods
while providing a discrete solution respecting the physical bounds given by the
underlying differential equation. The main result of this work demonstrates
that the numerical solution achieves accuracy of $O(h^k)$ in the energy norm,
where $k$ represents the underlying polynomial degree. To validate the
approach, a series of numerical experiments is conducted for various problem
instances. Comparisons with the linear continuous interior penalty stabilised
method, and the algebraic flux-correction scheme (for the piecewise linear
finite element case) have been carried out, where we can observe the favourable
performance of the current approach.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15603" title="Abstract">arXiv:2311.15603</a> [<a href="/pdf/2311.15603" title="Download PDF">pdf</a>, <a href="/format/2311.15603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QuickDrop: Efficient Federated Unlearning by Integrated Dataset  Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhasade%2C+A">Akash Dhasade</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yaohong Ding</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Song Guo</a>, 
<a href="/search/cs?searchtype=author&query=Kermarrec%2C+A">Anne-marie Kermarrec</a>, 
<a href="/search/cs?searchtype=author&query=De+Vos%2C+M">Martijn De Vos</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Leijie Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Federated Unlearning (FU) aims to delete specific training data from an ML
model trained using Federated Learning (FL). We introduce QuickDrop, an
efficient and original FU method that utilizes dataset distillation (DD) to
accelerate unlearning and drastically reduces computational overhead compared
to existing approaches. In QuickDrop, each client uses DD to generate a compact
dataset representative of the original training dataset, called a distilled
dataset, and uses this compact dataset during unlearning. To unlearn specific
knowledge from the global model, QuickDrop has clients execute Stochastic
Gradient Ascent with samples from the distilled datasets, thus significantly
reducing computational overhead compared to conventional FU methods. We further
increase the efficiency of QuickDrop by ingeniously integrating DD into the FL
training process. By reusing the gradient updates produced during FL training
for DD, the overhead of creating distilled datasets becomes close to
negligible. Evaluations on three standard datasets show that, with comparable
accuracy guarantees, QuickDrop reduces the duration of unlearning by 463.8x
compared to model retraining from scratch and 65.1x compared to existing FU
approaches. We also demonstrate the scalability of QuickDrop with 100 clients
and show its effectiveness while handling multiple unlearning operations.
</p>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15605" title="Abstract">arXiv:2311.15605</a> [<a href="/pdf/2311.15605" title="Download PDF">pdf</a>, <a href="/format/2311.15605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 2D Feature Distillation for Weakly- and Semi-Supervised 3D Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Unal%2C+O">Ozan Unal</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+D">Dengxin Dai</a>, 
<a href="/search/cs?searchtype=author&query=Hoyer%2C+L">Lukas Hoyer</a>, 
<a href="/search/cs?searchtype=author&query=Can%2C+Y+B">Yigit Baran Can</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">As 3D perception problems grow in popularity and the need for large-scale
labeled datasets for LiDAR semantic segmentation increase, new methods arise
that aim to reduce the necessity for dense annotations by employing
weakly-supervised training. However these methods continue to show weak
boundary estimation and high false negative rates for small objects and distant
sparse regions. We argue that such weaknesses can be compensated by using RGB
images which provide a denser representation of the scene. We propose an
image-guidance network (IGNet) which builds upon the idea of distilling high
level feature information from a domain adapted synthetically trained 2D
semantic segmentation network. We further utilize a one-way contrastive
learning scheme alongside a novel mixing strategy called FOVMix, to combat the
horizontal field-of-view mismatch between the two sensors and enhance the
effects of image guidance. IGNet achieves state-of-the-art results for
weakly-supervised LiDAR semantic segmentation on ScribbleKITTI, boasting up to
98% relative performance to fully supervised training with only 8% labeled
points, while introducing no additional annotation burden or
computational/memory cost during inference. Furthermore, we show that our
contributions also prove effective for semi-supervised training, where IGNet
claims state-of-the-art results on both ScribbleKITTI and SemanticKITTI.
</p>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15609" title="Abstract">arXiv:2311.15609</a> [<a href="/pdf/2311.15609" title="Download PDF">pdf</a>, <a href="/format/2311.15609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A manometric feature descriptor with linear-SVM to distinguish  esophageal contraction vigor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jialin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Lu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaowei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yuzhuo Dai</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+F">Fanggen Lu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yuanting Ma</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+M">Muzhou Hou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zheng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">n clinical, if a patient presents with nonmechanical obstructive dysphagia,
esophageal chest pain, and gastro esophageal reflux symptoms, the physician
will usually assess the esophageal dynamic function. High-resolution manometry
(HRM) is a clinically commonly used technique for detection of esophageal
dynamic function comprehensively and objectively. However, after the results of
HRM are obtained, doctors still need to evaluate by a variety of parameters.
This work is burdensome, and the process is complex. We conducted image
processing of HRM to predict the esophageal contraction vigor for assisting the
evaluation of esophageal dynamic function. Firstly, we used Feature-Extraction
and Histogram of Gradients (FE-HOG) to analyses feature of proposal of swallow
(PoS) to further extract higher-order features. Then we determine the
classification of esophageal contraction vigor normal, weak and failed by using
linear-SVM according to these features. Our data set includes 3000 training
sets, 500 validation sets and 411 test sets. After verification our accuracy
reaches 86.83%, which is higher than other common machine learning methods.
</p>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15614" title="Abstract">arXiv:2311.15614</a> [<a href="/pdf/2311.15614" title="Download PDF">pdf</a>, <a href="/format/2311.15614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FreeAL: Towards Human-Free Active Learning in the Era of Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+R">Ruixuan Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yiwen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Junbo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Runze Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Minmin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Gang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haobo Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP 2023 (Main conference)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Collecting high-quality labeled data for model training is notoriously
time-consuming and labor-intensive for various NLP tasks. While copious
solutions, such as active learning for small language models (SLMs) and
prevalent in-context learning in the era of large language models (LLMs), have
been proposed and alleviate the labeling burden to some extent, their
performances are still subject to human intervention. It is still underexplored
how to reduce the annotation cost in the LLMs era. To bridge this, we
revolutionize traditional active learning and propose an innovative
collaborative learning framework FreeAL to interactively distill and filter the
task-specific knowledge from LLMs. During collaborative training, an LLM serves
as an active annotator inculcating its coarse-grained knowledge, while a
downstream SLM is incurred as a student to filter out high-quality in-context
samples to feedback LLM for the subsequent label refinery. Extensive
experiments on eight benchmark datasets demonstrate that FreeAL largely
enhances the zero-shot performances for both SLM and LLM without any human
supervision. The code is available at https://github.com/Justherozen/FreeAL .
</p>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15615" title="Abstract">arXiv:2311.15615</a> [<a href="/pdf/2311.15615" title="Download PDF">pdf</a>, <a href="/format/2311.15615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Technical Report for Argoverse Challenges on Unified Sensor-based  Detection, Tracking, and Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhepeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Feng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lertniphonphan%2C+K">Kanokphan Lertniphonphan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+J">Jinyao Bao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+P">Pengfei Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinbao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaer Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This report presents our Le3DE2E solution for unified sensor-based detection,
tracking, and forecasting in Argoverse Challenges at CVPR 2023 Workshop on
Autonomous Driving (WAD). We propose a unified network that incorporates three
tasks, including detection, tracking, and forecasting. This solution adopts a
strong Bird's Eye View (BEV) encoder with spatial and temporal fusion and
generates unified representations for multi-tasks. The solution was tested in
the Argoverse 2 sensor dataset to evaluate the detection, tracking, and
forecasting of 26 object categories. We achieved 1st place in Detection,
Tracking, and Forecasting on the E2E Forecasting track in Argoverse Challenges
at CVPR 2023 WAD.
</p>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15617" title="Abstract">arXiv:2311.15617</a> [<a href="/pdf/2311.15617" title="Download PDF">pdf</a>, <a href="/format/2311.15617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VeryFL: A Verify Federated Learning Framework Embedded with Blockchain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yihao Li</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">Yanyi Lai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zibin Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Blockchain-empowered federated learning (FL) has provoked extensive research
recently. Various blockchain-based federated learning algorithm, architecture
and mechanism have been designed to solve issues like single point failure and
data falsification brought by centralized FL paradigm. Moreover, it is easier
to allocate incentives to nodes with the help of the blockchain. Various
centralized federated learning frameworks like FedML, have emerged in the
community to help boost the research on FL. However, decentralized
blockchain-based federated learning framework is still missing, which cause
inconvenience for researcher to reproduce or verify the algorithm performance
based on blockchain. Inspired by the above issues, we have designed and
developed a blockchain-based federated learning framework by embedding Ethereum
network. This report will present the overall structure of this framework,
which proposes a code practice paradigm for the combination of FL with
blockchain and, at the same time, compatible with normal FL training task. In
addition to implement some blockchain federated learning algorithms on smart
contract to help execute a FL training, we also propose a model ownership
authentication architecture based on blockchain and model watermarking to
protect the intellectual property rights of models. These mechanism on
blockchain shows an underlying support of blockchain for federated learning to
provide a verifiable training, aggregation and incentive distribution procedure
and thus we named this framework VeryFL (A Verify Federated Learninig Framework
Embedded with Blockchain). The source code is avaliable on
https://github.com/GTMLLab/VeryFL.
</p>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15619" title="Abstract">arXiv:2311.15619</a> [<a href="/pdf/2311.15619" title="Download PDF">pdf</a>, <a href="/format/2311.15619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Align before Adapt: Leveraging Entity-to-Region Alignments for  Generalizable Video Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yifei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dapeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruijin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Sai Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+W">Wenyuan Xue</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wei Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large-scale visual-language pre-trained models have achieved significant
success in various video tasks. However, most existing methods follow an "adapt
then align" paradigm, which adapts pre-trained image encoders to model
video-level representations and utilizes one-hot or text embedding of the
action labels for supervision. This paradigm overlooks the challenge of mapping
from static images to complicated activity concepts. In this paper, we propose
a novel "Align before Adapt" (ALT) paradigm. Prior to adapting to video
representation learning, we exploit the entity-to-region alignments for each
frame. The alignments are fulfilled by matching the region-aware image
embeddings to an offline-constructed text corpus. With the aligned entities, we
feed their text embeddings to a transformer-based video adapter as the queries,
which can help extract the semantics of the most important entities from a
video to a vector. This paradigm reuses the visual-language alignment of VLP
during adaptation and tries to explain an action by the underlying entities.
This helps understand actions by bridging the gap with complex activity
semantics, particularly when facing unfamiliar or unseen categories. ALT
achieves competitive performance and superior generalizability while requiring
significantly low computational costs. In fully supervised scenarios, it
achieves 88.1% top-1 accuracy on Kinetics-400 with only 4947 GFLOPs. In 2-shot
experiments, ALT outperforms the previous state-of-the-art by 7.1% and 9.2% on
HMDB-51 and UCF-101, respectively.
</p>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15623" title="Abstract">arXiv:2311.15623</a> [<a href="/pdf/2311.15623" title="Download PDF">pdf</a>, <a href="/format/2311.15623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Injecting linguistic knowledge into BERT for Dialogue State Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xiaohan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xixin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+H">Helen Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Dialogue State Tracking (DST) models often employ intricate neural network
architectures, necessitating substantial training data, and their inference
processes lack transparency. This paper proposes a method that extracts
linguistic knowledge via an unsupervised framework and subsequently utilizes
this knowledge to augment BERT's performance and interpretability in DST tasks.
The knowledge extraction procedure is computationally economical and does not
necessitate annotations or additional training data. The injection of the
extracted knowledge necessitates the addition of only simple neural modules. We
employ the Convex Polytopic Model (CPM) as a feature extraction tool for DST
tasks and illustrate that the acquired features correlate with the syntactic
and semantic patterns in the dialogues. This correlation facilitates a
comprehensive understanding of the linguistic features influencing the DST
model's decision-making process. We benchmark this framework on various DST
tasks and observe a notable improvement in accuracy.
</p>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15625" title="Abstract">arXiv:2311.15625</a> [<a href="/pdf/2311.15625" title="Download PDF">pdf</a>, <a href="/format/2311.15625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Only Positive Cases: 5-fold High-order Attention Interaction Model for  Skin Segmentation Derived Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Renkai Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yinghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Pengchen Liang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Q">Qing Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Computer-aided diagnosis of skin diseases is an important tool. However, the
interpretability of computer-aided diagnosis is currently poor. Dermatologists
and patients cannot intuitively understand the learning and prediction process
of neural networks, which will lead to a decrease in the credibility of
computer-aided diagnosis. In addition, traditional methods need to be trained
using negative samples in order to predict the presence or absence of a lesion,
but medical data is often in short supply. In this paper, we propose a multiple
high-order attention interaction model (MHA-UNet) for use in a highly
explainable skin lesion segmentation task. MHA-UNet is able to obtain the
presence or absence of a lesion by explainable reasoning without the need for
training on negative samples. Specifically, we propose a high-order attention
interaction mechanism that introduces squeeze attention to a higher level for
feature attention. In addition, a multiple high-order attention interaction
(MHAblock) module is proposed by combining the different features of different
orders. For classifying the presence or absence of lesions, we conducted
classification experiments on several publicly available datasets in the
absence of negative samples, based on explainable reasoning about the
interaction of 5 attention orders of MHAblock. The highest positive detection
rate obtained from the experiments was 81.0% and the highest negative detection
rate was 83.5%. For segmentation experiments, comparison experiments of the
proposed method with 13 medical segmentation models and external validation
experiments with 8 state-of-the-art models in three public datasets and our
clinical dataset demonstrate the state-of-the-art performance of our model. The
code is available from https://github.com/wurenkai/MHA-UNet.
</p>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15626" title="Abstract">arXiv:2311.15626</a> [<a href="/pdf/2311.15626" title="Download PDF">pdf</a>, <a href="/format/2311.15626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The WebCrow French Crossword Solver
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Angelini%2C+G">Giovanni Angelini</a>, 
<a href="/search/cs?searchtype=author&query=Ernandes%2C+M">Marco Ernandes</a>, 
<a href="/search/cs?searchtype=author&query=laquinta%2C+T">Tommaso laquinta</a>, 
<a href="/search/cs?searchtype=author&query=Stehl%C3%A9%2C+C">Caroline Stehl&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Sim%C3%B5es%2C+F">Fanny Sim&#xf5;es</a>, 
<a href="/search/cs?searchtype=author&query=Zeinalipour%2C+K">Kamyar Zeinalipour</a>, 
<a href="/search/cs?searchtype=author&query=Zugarini%2C+A">Andrea Zugarini</a>, 
<a href="/search/cs?searchtype=author&query=Gori%2C+M">Marco Gori</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted Paper for EAI Intetain 2023 - 14th EAI International Conference on Intelligent Technologies for Interactive Entertainment
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Crossword puzzles are one of the most popular word games, played in different
languages all across the world, where riddle style can vary significantly from
one country to another. Automated crossword resolution is challenging, and
typical solvers rely on large databases of previously solved crosswords. In
this work, we extend WebCrow 2.0, an automatic crossword solver, to French,
making it the first program for crossword solving in the French language. To
cope with the lack of a large repository of clue-answer crossword data, WebCrow
2.0 exploits multiple modules, called experts, that retrieve candidate answers
from heterogeneous resources, such as the web, knowledge graphs, and linguistic
rules. We compared WebCrow's performance against humans in two different
challenges. Despite the limited amount of past crosswords, French WebCrow was
competitive, actually outperforming humans in terms of speed and accuracy, thus
proving its capabilities to generalize to new languages.
</p>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15627" title="Abstract">arXiv:2311.15627</a> [<a href="/pdf/2311.15627" title="Download PDF">pdf</a>, <a href="/format/2311.15627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phonetic-aware speaker embedding for far-field speaker verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zezhong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Y">Youzhi Tu</a>, 
<a href="/search/cs?searchtype=author&query=Mak%2C+M">Man-Wai Mak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">When a speaker verification (SV) system operates far from the sound sourced,
significant challenges arise due to the interference of noise and
reverberation. Studies have shown that incorporating phonetic information into
speaker embedding can improve the performance of text-independent SV. Inspired
by this observation, we propose a joint-training speech recognition and speaker
recognition (JTSS) framework to exploit phonetic content for far-field SV. The
framework encourages speaker embeddings to preserve phonetic information by
matching the frame-based feature maps of a speaker embedding network with
wav2vec's vectors. The intuition is that phonetic information can preserve
low-level acoustic dynamics with speaker information and thus partly compensate
for the degradation due to noise and reverberation. Results show that the
proposed framework outperforms the standard speaker embedding on the VOiCES
Challenge 2019 evaluation set and the VoxCeleb1 test set. This indicates that
leveraging phonetic information under far-field conditions is effective for
learning robust speaker representations.
</p>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15633" title="Abstract">arXiv:2311.15633</a> [<a href="/pdf/2311.15633" title="Download PDF">pdf</a>, <a href="/format/2311.15633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward a real-time TCP SYN Flood DDoS mitigation using Adaptive  Neuro-Fuzzy classifier and SDN Assistance in Fog Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bensaid%2C+R">Radjaa Bensaid</a>, 
<a href="/search/cs?searchtype=author&query=Labraoui%2C+N">Nabila Labraoui</a>, 
<a href="/search/cs?searchtype=author&query=Ari%2C+A+A+A">Ado Adamou Abba Ari</a>, 
<a href="/search/cs?searchtype=author&query=Maglaras%2C+L">Leandros Maglaras</a>, 
<a href="/search/cs?searchtype=author&query=Saidi%2C+H">Hafida Saidi</a>, 
<a href="/search/cs?searchtype=author&query=Lwahhab%2C+A+M+A">Ahmed Mahmoud Abdu Lwahhab</a>, 
<a href="/search/cs?searchtype=author&query=Benfriha%2C+S">Sihem Benfriha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The growth of the Internet of Things (IoT) has recently impacted our daily
lives in many ways. As a result, a massive volume of data is generated and
needs to be processed in a short period of time. Therefore, the combination of
computing models such as cloud computing is necessary. The main disadvantage of
the cloud platform is its high latency due to the centralized mainframe.
Fortunately, a distributed paradigm known as fog computing has emerged to
overcome this problem, offering cloud services with low latency and high-access
bandwidth to support many IoT application scenarios. However, Attacks against
fog servers can take many forms, such as Distributed Denial of Service (DDoS)
attacks that severely affect the reliability and availability of fog services.
To address these challenges, we propose mitigation of Fog computing-based SYN
Flood DDoS attacks using an Adaptive Neuro-Fuzzy Inference System (ANFIS) and
Software Defined Networking (SDN) Assistance (FASA). The simulation results
show that FASA system outperforms other algorithms in terms of accuracy,
precision, recall, and F1-score. This shows how crucial our system is for
detecting and mitigating TCP SYN floods DDoS attacks.
</p>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15637" title="Abstract">arXiv:2311.15637</a> [<a href="/pdf/2311.15637" title="Download PDF">pdf</a>, <a href="/format/2311.15637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PaintNeSF: Artistic Creation of Stylized Scenes with Vectorized 3D  Strokes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+H">Hao-Bin Duan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Miao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yan-Xun Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yong-Liang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We present Paint Neural Stroke Field (PaintNeSF), a novel technique to
generate stylized images of a 3D scene at arbitrary novel views from multi-view
2D images. Different from existing methods which apply stylization to trained
neural radiance fields at the voxel level, our approach draws inspiration from
image-to-painting methods, simulating the progressive painting process of human
artwork with vector strokes. We develop a palette of stylized 3D strokes from
basic primitives and splines, and consider the 3D scene stylization task as a
multi-view reconstruction process based on these 3D stroke primitives. Instead
of directly searching for the parameters of these 3D strokes, which would be
too costly, we introduce a differentiable renderer that allows optimizing
stroke parameters using gradient descent, and propose a training scheme to
alleviate the vanishing gradient issue. The extensive evaluation demonstrates
that our approach effectively synthesizes 3D scenes with significant geometric
and aesthetic stylization while maintaining a consistent appearance across
different views. Our method can be further integrated with style loss and
image-text contrastive models to extend its applications, including color
transfer and text-driven 3D scene drawing.
</p>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15639" title="Abstract">arXiv:2311.15639</a> [<a href="/pdf/2311.15639" title="Download PDF">pdf</a>, <a href="/format/2311.15639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Almost Logarithmic Approximation for Cutwidth and Pathwidth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bansal%2C+N">Nikhil Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Katzelnick%2C+D">Dor Katzelnick</a>, 
<a href="/search/cs?searchtype=author&query=Schwartz%2C+R">Roy Schwartz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study several graph layout problems with a min max objective. Here, given
a graph we wish to find a linear ordering of the vertices that minimizes some
worst case objective over the natural cuts in the ordering; which separate an
initial segment of the vertices from the rest. A prototypical problem here is
cutwidth, where we want to minimize the maximum number of edges crossing a cut.
The only known algorithm here is by [Leighton-Rao J.ACM 99] based on
recursively partitioning the graph using balanced cuts. This achieves an
$O(\log^{3/2}{n})$ approximation using the $ O(\log^{1/2}{n})$ approximation of
[Arora-Rao-Vazirani J.ACM 09] for balanced cuts.
<br />We depart from the above approach and give an improved $ O(\log^{1+o(1)}{n})$
approximation for cutwidth. Our approach also gives a similarly improved $
O(\log^{1+o(1)}{n})$ approximation for finding the pathwidth of a graph.
Previously, the best known approximation for pathwidth was $O(\log^{3/2}{n})$.
</p>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15641" title="Abstract">arXiv:2311.15641</a> [<a href="/pdf/2311.15641" title="Download PDF">pdf</a>, <a href="/ps/2311.15641" title="Download PostScript">ps</a>, <a href="/format/2311.15641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A generalized nonstandard finite difference method for a class of  autonomous dynamical systems and its applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hoang%2C+M+T">Manh Tuan Hoang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Classical Analysis and ODEs (math.CA); Dynamical Systems (math.DS)

</div>
<p class="mathjax">In this work, a class of continuous-time autonomous dynamical systems
describing many important phenomena and processes arising in real-world
applications is considered. We apply the nonstandard finite difference (NSFD)
methodology proposed by Mickens to design a generalized NSFD method for the
dynamical system models under consideration. This method is constructed based
on a novel non-local approximation for the right-side functions of the
dynamical systems. It is proved by rigorous mathematical analyses that the NSFD
method is dynamically consistent with respect to positivity, asymptotic
stability and three classes of conservation laws, including direct
conservation, generalized conservation and sub-conservation laws. Furthermore,
the NSFD method is easy to be implemented and can be applied to solve a broad
range of mathematical models arising in real-life. Finally, a set of numerical
experiments is performed to illustrate the theoretical findings and to show
advantages of the proposed NSFD method.
</p>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15642" title="Abstract">arXiv:2311.15642</a> [<a href="/pdf/2311.15642" title="Download PDF">pdf</a>, <a href="/format/2311.15642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InfoPattern: Unveiling Information Propagation Patterns in Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+C">Chi Han</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jialiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Manling Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Abdelzaher%2C+T">Tarek Abdelzaher</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Heng Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Social media play a significant role in shaping public opinion and
influencing ideological communities through information propagation. Our demo
InfoPattern centers on the interplay between language and human ideology. The
demo (Code: https://github.com/blender-nlp/InfoPattern ) is capable of: (1) red
teaming to simulate adversary responses from opposite ideology communities; (2)
stance detection to identify the underlying political sentiments in each
message; (3) information propagation graph discovery to reveal the evolution of
claims across various communities over time. (Live Demo:
https://incas.csl.illinois.edu/blender/About )
</p>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15643" title="Abstract">arXiv:2311.15643</a> [<a href="/pdf/2311.15643" title="Download PDF">pdf</a>, <a href="/format/2311.15643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Monocular Re-Localization: From the Perspective of Scene Map  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miao%2C+J">Jinyu Miao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+K">Kun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+T">Tuopu Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunlong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+P">Peijing Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xuhe Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zhongyang Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zhihua Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Diange Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 108 pages, 9 tables, 17 figures, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Monocular Re-Localization (MRL) is a critical component in numerous
autonomous applications, which estimates 6 degree-of-freedom poses with regards
to the scene map based on a single monocular image. In recent decades,
significant progress has been made in the development of MRL techniques.
Numerous landmark algorithms have accomplished extraordinary success in terms
of localization accuracy and robustness against visual interference. In MRL
research, scene maps are represented in various forms, and they determine how
MRL methods work and even how MRL methods perform. However, to the best of our
knowledge, existing surveys do not provide systematic reviews of MRL from the
respective of map. This survey fills the gap by comprehensively reviewing MRL
methods employing monocular cameras as main sensors, promoting further
research. 1) We commence by delving into the problem definition of MRL and
exploring current challenges, while also comparing ours with with previous
published surveys. 2) MRL methods are then categorized into five classes
according to the representation forms of utilized map, i.e., geo-tagged frames,
visual landmarks, point clouds, and vectorized semantic map, and we review the
milestone MRL works of each category. 3) To quantitatively and fairly compare
MRL methods with various map, we also review some public datasets and provide
the performances of some typical MRL methods. The strengths and weakness of
different types of MRL methods are analyzed. 4) We finally introduce some
topics of interest in this field and give personal opinions. This survey can
serve as a valuable referenced materials for newcomers and researchers
interested in MRL, and a continuously updated summary of this survey, including
reviewed papers and datasets, is publicly available to the community at:
https://github.com/jinyummiao/map-in-mono-reloc.
</p>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15647" title="Abstract">arXiv:2311.15647</a> [<a href="/pdf/2311.15647" title="Download PDF">pdf</a>, <a href="/format/2311.15647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bandits Meet Mechanism Design to Combat Clickbait in Online  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Buening%2C+T+K">Thomas Kleine Buening</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+A">Aadirupa Saha</a>, 
<a href="/search/cs?searchtype=author&query=Dimitrakakis%2C+C">Christos Dimitrakakis</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haifeng Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">We study a strategic variant of the multi-armed bandit problem, which we coin
the strategic click-bandit. This model is motivated by applications in online
recommendation where the choice of recommended items depends on both the
click-through rates and the post-click rewards. Like in classical bandits,
rewards follow a fixed unknown distribution. However, we assume that the
click-rate of each arm is chosen strategically by the arm (e.g., a host on
Airbnb) in order to maximize the number of times it gets clicked. The algorithm
designer does not know the post-click rewards nor the arms' actions (i.e.,
strategically chosen click-rates) in advance, and must learn both values over
time. To solve this problem, we design an incentive-aware learning algorithm,
UCB-S, which achieves two goals simultaneously: (a) incentivizing desirable arm
behavior under uncertainty; (b) minimizing regret by learning unknown
parameters. We characterize all approximate Nash equilibria among arms under
UCB-S and show a $\tilde{\mathcal{O}} (\sqrt{KT})$ regret bound uniformly in
every equilibrium. We also show that incentive-unaware algorithms generally
fail to achieve low regret in the strategic click-bandit. Finally, we support
our theoretical results by simulations of strategic arm behavior which confirm
the effectiveness and robustness of our proposed incentive design.
</p>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15648" title="Abstract">arXiv:2311.15648</a> [<a href="/pdf/2311.15648" title="Download PDF">pdf</a>, <a href="/format/2311.15648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning from Diffusion Feedback: Q* for Image Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marathe%2C+A">Aboli Marathe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Large vision-language models are steadily gaining personalization
capabilities at the cost of fine-tuning or data augmentation. We present two
models for image generation using model-agnostic learning that align semantic
priors with generative capabilities. RLDF, or Reinforcement Learning from
Diffusion Feedback, is a singular approach for visual imitation through
prior-preserving reward function guidance. This employs Q-learning (with
standard Q*) for generation and follows a semantic-rewarded trajectory for
image search through finite encoding-tailored actions. The second proposed
method, noisy diffusion gradient, is optimization driven. At the root of both
methods is a special CFG encoding that we propose for continual semantic
guidance. Using only a single input image and no text input, RLDF generates
high-quality images over varied domains including retail, sports and
agriculture showcasing class-consistency and strong visual diversity. Project
website is available at https://infernolia.github.io/RLDF.
</p>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15649" title="Abstract">arXiv:2311.15649</a> [<a href="/pdf/2311.15649" title="Download PDF">pdf</a>, <a href="/format/2311.15649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoboGPT: an intelligent agent of making embodied long-term decisions for  daily instruction tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yaran Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+W">Wenbo Cui</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuanwen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+M">Mining Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongbin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">He Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Robotic agents must master common sense and long-term sequential decisions to
solve daily tasks through natural language instruction. The developments in
Large Language Models (LLMs) in natural language processing have inspired
efforts to use LLMs in complex robot planning. Despite LLMs' great
generalization and comprehension of instruction tasks, LLMs-generated task
plans sometimes lack feasibility and correctness. To address the problem, we
propose a RoboGPT agent\footnote{our code and dataset will be released soon}
for making embodied long-term decisions for daily tasks, with two modules: 1)
LLMs-based planning with re-plan to break the task into multiple sub-goals; 2)
RoboSkill individually designed for sub-goals to learn better navigation and
manipulation skills. The LLMs-based planning is enhanced with a new robotic
dataset and re-plan, called RoboGPT. The new robotic dataset of 67k daily
instruction tasks is gathered for fine-tuning the Llama model and obtaining
RoboGPT. RoboGPT planner with strong generalization can plan hundreds of daily
instruction tasks. Additionally, a low-computational Re-Plan module is designed
to allow plans to flexibly adapt to the environment, thereby addressing the
nomenclature diversity challenge. The proposed RoboGPT agent outperforms SOTA
methods on the ALFRED daily tasks. Moreover, RoboGPT planner exceeds SOTA
LLM-based planners like ChatGPT in task-planning rationality for hundreds of
unseen daily tasks, and even other domain tasks, while keeping the large
model's original broad application and generality.
</p>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15653" title="Abstract">arXiv:2311.15653</a> [<a href="/pdf/2311.15653" title="Download PDF">pdf</a>, <a href="/format/2311.15653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MoDS: Model-oriented Data Selection for Instruction Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+Q">Qianlong Du</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+C">Chengqing Zong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiajun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Instruction tuning has become the de facto method to equip large language
models (LLMs) with the ability of following user instructions. Usually,
hundreds of thousands or millions of instruction-following pairs are employed
to fine-tune the foundation LLMs. Recently, some studies show that a small
number of high-quality instruction data is enough. However, how to select
appropriate instruction data for a given LLM is still an open problem. To
address this problem, in this paper we present a model-oriented data selection
(MoDS) approach, which selects instruction data based on a new criteria
considering three aspects: quality, coverage and necessity. First, our approach
utilizes a quality evaluation model to filter out the high-quality subset from
the original instruction dataset, and then designs an algorithm to further
select from the high-quality subset a seed instruction dataset with good
coverage. The seed dataset is applied to fine-tune the foundation LLM to obtain
an initial instruction-following LLM. Finally, we develop a necessity
evaluation model to find out the instruction data which are performed badly in
the initial instruction-following LLM and consider them necessary instructions
to further improve the LLMs. In this way, we can get a small high-quality,
broad-coverage and high-necessity subset from the original instruction
datasets. Experimental results show that, the model fine-tuned with 4,000
instruction pairs selected by our approach could perform better than the model
fine-tuned with the full original dataset which includes 214k instruction data.
</p>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15657" title="Abstract">arXiv:2311.15657</a> [<a href="/pdf/2311.15657" title="Download PDF">pdf</a>, <a href="/format/2311.15657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Diffusion Models with Text-Encoder Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaofeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Annan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoning Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+L">Liang Liao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wenxiu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Q">Qiong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weisi Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-to-image diffusion models are typically trained to optimize the
log-likelihood objective, which presents challenges in meeting specific
requirements for downstream tasks, such as image aesthetics and image-text
alignment. Recent research addresses this issue by refining the diffusion U-Net
using human rewards through reinforcement learning or direct backpropagation.
However, many of them overlook the importance of the text encoder, which is
typically pretrained and fixed during training. In this paper, we demonstrate
that by finetuning the text encoder through reinforcement learning, we can
enhance the text-image alignment of the results, thereby improving the visual
quality. Our primary motivation comes from the observation that the current
text encoder is suboptimal, often requiring careful prompt adjustment. While
fine-tuning the U-Net can partially improve performance, it remains suffering
from the suboptimal text encoder. Therefore, we propose to use reinforcement
learning with low-rank adaptation to finetune the text encoder based on
task-specific rewards, referred as \textbf{TexForce}. We first show that
finetuning the text encoder can improve the performance of diffusion models.
Then, we illustrate that TexForce can be simply combined with existing U-Net
finetuned models to get much better results without additional training.
Finally, we showcase the adaptability of our method in diverse applications,
including the generation of high-quality face and hand images.
</p>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15658" title="Abstract">arXiv:2311.15658</a> [<a href="/pdf/2311.15658" title="Download PDF">pdf</a>, <a href="/format/2311.15658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regularization by Texts for Latent Diffusion Inverse Solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jeongsol Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+G+Y">Geon Yeong Park</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+H">Hyungjin Chung</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J+C">Jong Chul Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The recent advent of diffusion models has led to significant progress in
solving inverse problems, leveraging these models as effective generative
priors. Nonetheless, challenges related to the ill-posed nature of such
problems remain, often due to inherent ambiguities in measurements. Drawing
inspiration from the human ability to resolve visual ambiguities through
perceptual biases, here we introduce a novel latent diffusion inverse solver by
incorporating regularization by texts (TReg). Specifically, TReg applies the
textual description of the preconception of the solution during the reverse
sampling phase, of which description isndynamically reinforced through
null-text optimization for adaptive negation. Our comprehensive experimental
results demonstrate that TReg successfully mitigates ambiguity in latent
diffusion inverse solvers, enhancing their effectiveness and accuracy.
</p>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15660" title="Abstract">arXiv:2311.15660</a> [<a href="/pdf/2311.15660" title="Download PDF">pdf</a>, <a href="/format/2311.15660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Technical Report for Argoverse Challenges on 4D Occupancy Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+P">Pengfei Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Lertniphonphan%2C+K">Kanokphan Lertniphonphan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Feng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Bingchuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhepeng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This report presents our Le3DE2E_Occ solution for 4D Occupancy Forecasting in
Argoverse Challenges at CVPR 2023 Workshop on Autonomous Driving (WAD). Our
solution consists of a strong LiDAR-based Bird's Eye View (BEV) encoder with
temporal fusion and a two-stage decoder, which combines a DETR head and a UNet
decoder. The solution was tested on the Argoverse 2 sensor dataset to evaluate
the occupancy state 3 seconds in the future. Our solution achieved 18% lower L1
Error (3.57) than the baseline and got the 1 place on the 4D Occupancy
Forecasting task in Argoverse Challenges at CVPR 2023.
</p>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15665" title="Abstract">arXiv:2311.15665</a> [<a href="/pdf/2311.15665" title="Download PDF">pdf</a>, <a href="/ps/2311.15665" title="Download PostScript">ps</a>, <a href="/format/2311.15665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust discontinuous Galerkin-based scheme for the fully-coupled  non-linear thermo-hydro-mechanical problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bonetti%2C+S">Stefano Bonetti</a>, 
<a href="/search/math?searchtype=author&query=Botti%2C+M">Michele Botti</a>, 
<a href="/search/math?searchtype=author&query=Antonietti%2C+P+F">Paola F. Antonietti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present and analyze a discontinuous Galerkin method for the numerical
modeling of the non-linear fully-coupled thermo-hydro-mechanic problem. We
propose a high-order symmetric weighted interior penalty scheme that supports
general polytopal grids and is robust with respect to strong heteorgeneities in
the model coefficients. We focus on the treatment of the non-linear convective
transport term in the energy conservation equation and we propose suitable
stabilization techniques that make the scheme robust for advection-dominated
regimes. The stability analysis of the problem and the convergence of the
fixed-point linearization strategy are addressed theoretically under mild
requirements on the problem's data. A complete set of numerical simulations is
presented in order to assess the convergence and robustness properties of the
proposed method.
</p>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15668" title="Abstract">arXiv:2311.15668</a> [<a href="/pdf/2311.15668" title="Download PDF">pdf</a>, <a href="/format/2311.15668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deformation-Guided Unsupervised Non-Rigid Shape Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Merrouche%2C+A">Aymen Merrouche</a>, 
<a href="/search/cs?searchtype=author&query=Regateiro%2C+J">Joao Regateiro</a>, 
<a href="/search/cs?searchtype=author&query=Wuhrer%2C+S">Stefanie Wuhrer</a>, 
<a href="/search/cs?searchtype=author&query=Boyer%2C+E">Edmond Boyer</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 34th British Machine Vision Conference, Nov 2023, Aberdeen, United
  Kingdom
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present an unsupervised data-driven approach for non-rigid shape matching.
Shape matching identifies correspondences between two shapes and is a
fundamental step in many computer vision and graphics applications. Our
approach is designed to be particularly robust when matching shapes digitized
using 3D scanners that contain fine geometric detail and suffer from different
types of noise including topological noise caused by the coalescence of
spatially close surface regions. We build on two strategies. First, using a
hierarchical patch based shape representation we match shapes consistently in a
coarse to fine manner, allowing for robustness to noise. This multi-scale
representation drastically reduces the dimensionality of the problem when
matching at the coarsest scale, rendering unsupervised learning feasible.
Second, we constrain this hierarchical matching to be reflected in 3D by
fitting a patch-wise near-rigid deformation model. Using this constraint, we
leverage spatial continuity at different scales to capture global shape
properties, resulting in matchings that generalize well to data with different
deformations and noise characteristics. Experiments demonstrate that our
approach obtains significantly better results on raw 3D scans than
state-of-the-art methods, while performing on-par on standard test scenarios.
</p>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15670" title="Abstract">arXiv:2311.15670</a> [<a href="/pdf/2311.15670" title="Download PDF">pdf</a>, <a href="/format/2311.15670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noninterference Analysis of Reversible Systems: An Approach Based on  Branching Bisimilarity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esposito%2C+A">Andrea Esposito</a>, 
<a href="/search/cs?searchtype=author&query=Aldini%2C+A">Alessandro Aldini</a>, 
<a href="/search/cs?searchtype=author&query=Bernardo%2C+M">Marco Bernardo</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+S">Sabina Rossi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The theory of noninterference supports the analysis and the execution of
secure computations in multi-level security systems. Classical
equivalence-based approaches to noninterference mainly rely on weak
bisimulation semantics. We show that this approach is not sufficient to
identify potential covert channels in the presence of reversible computations.
As illustrated via a database management system example, the activation of
backward computations may trigger information flows that are not observable
when proceeding in the standard forward direction. To capture the effects of
back and forth computations, it is necessary to switch to a more expressive
semantics that, in an interleaving framework, has been proven to be branching
bisimilarity in a previous work by De Nicola, Montanari, and Vaandrager. In
this paper we investigate a taxonomy of noninterference properties based on
branching bisimilarity along with their preservation and compositionality
features, then we compare it with the classical hierarchy based on weak
bisimilarity.
</p>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15672" title="Abstract">arXiv:2311.15672</a> [<a href="/pdf/2311.15672" title="Download PDF">pdf</a>, <a href="/format/2311.15672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HAVE-FUN: Human Avatar Reconstruction from Few-Shot Unconstrained Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xihe Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xingyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shaohui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+D">Daiheng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaoguang Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Baoyuan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">As for human avatar reconstruction, contemporary techniques commonly
necessitate the acquisition of costly data and struggle to achieve satisfactory
results from a small number of casual images. In this paper, we investigate
this task from a few-shot unconstrained photo album. The reconstruction of
human avatars from such data sources is challenging because of limited data
amount and dynamic articulated poses. For handling dynamic data, we integrate a
skinning mechanism with deep marching tetrahedra (DMTet) to form a drivable
tetrahedral representation, which drives arbitrary mesh topologies generated by
the DMTet for the adaptation of unconstrained images. To effectively mine
instructive information from few-shot data, we devise a two-phase optimization
method with few-shot reference and few-shot guidance. The former focuses on
aligning avatar identity with reference images, while the latter aims to
generate plausible appearances for unseen regions. Overall, our framework,
called HaveFun, can undertake avatar reconstruction, rendering, and animation.
Extensive experiments on our developed benchmarks demonstrate that HaveFun
exhibits substantially superior performance in reconstructing the human body
and hand. Project website: https://seanchenxy.github.io/HaveFunWeb/.
</p>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15673" title="Abstract">arXiv:2311.15673</a> [<a href="/pdf/2311.15673" title="Download PDF">pdf</a>, <a href="/format/2311.15673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Hierarchical Associative Memory: A Deep Equilibrium  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goemaere%2C+C">C&#xe9;dric Goemaere</a>, 
<a href="/search/cs?searchtype=author&query=Deleu%2C+J">Johannes Deleu</a>, 
<a href="/search/cs?searchtype=author&query=Demeester%2C+T">Thomas Demeester</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the "Associative Memory &amp; Hopfield Networks'' workshop at NeurIPS, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Hierarchical Associative Memory models have recently been proposed as a
versatile extension of continuous Hopfield networks. In order to facilitate
future research on such models, especially at scale, we focus on increasing
their simulation efficiency on digital hardware. In particular, we propose two
strategies to speed up memory retrieval in these models, which corresponds to
their use at inference, but is equally important during training. First, we
show how they can be cast as Deep Equilibrium Models, which allows using faster
and more stable solvers. Second, inspired by earlier work, we show that
alternating optimization of the even and odd layers accelerates memory
retrieval by a factor close to two. Combined, these two techniques allow for a
much faster energy minimization, as shown in our proof-of-concept experimental
results. The code is available at https://github.com/cgoemaere/hamdeq
</p>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15674" title="Abstract">arXiv:2311.15674</a> [<a href="/pdf/2311.15674" title="Download PDF">pdf</a>, <a href="/format/2311.15674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MOT-DETR: 3D Single Shot Detection and Tracking with Transformers to  build 3D representations for Agro-Food Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rapado-Rincon%2C+D">David Rapado-Rincon</a>, 
<a href="/search/cs?searchtype=author&query=Nap%2C+H">Henk Nap</a>, 
<a href="/search/cs?searchtype=author&query=Smolenova%2C+K">Katarina Smolenova</a>, 
<a href="/search/cs?searchtype=author&query=van+Henten%2C+E+J">Eldert J. van Henten</a>, 
<a href="/search/cs?searchtype=author&query=Kootstra%2C+G">Gert Kootstra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. Submitted to ICRA2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In the current demand for automation in the agro-food industry, accurately
detecting and localizing relevant objects in 3D is essential for successful
robotic operations. However, this is a challenge due the presence of
occlusions. Multi-view perception approaches allow robots to overcome
occlusions, but a tracking component is needed to associate the objects
detected by the robot over multiple viewpoints. Most multi-object tracking
(MOT) algorithms are designed for high frame rate sequences and struggle with
the occlusions generated by robots' motions and 3D environments. In this paper,
we introduce MOT-DETR, a novel approach to detect and track objects in 3D over
time using a combination of convolutional networks and transformers. Our method
processes 2D and 3D data, and employs a transformer architecture to perform
data fusion. We show that MOT-DETR outperforms state-of-the-art multi-object
tracking methods. Furthermore, we prove that MOT-DETR can leverage 3D data to
deal with long-term occlusions and large frame-to-frame distances better than
state-of-the-art methods. Finally, we show how our method is resilient to
camera pose noise that can affect the accuracy of point clouds. The
implementation of MOT-DETR can be found here:
https://github.com/drapado/mot-detr
</p>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15675" title="Abstract">arXiv:2311.15675</a> [<a href="/pdf/2311.15675" title="Download PDF">pdf</a>, <a href="/ps/2311.15675" title="Download PostScript">ps</a>, <a href="/format/2311.15675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Complexity of Second-order HyperLTL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zimmermann%2C+M">Martin Zimmermann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">We determine the complexity of second-order HyperLTL satisfiability and
model-checking: Both are as hard as truth in third-order arithmetic.
</p>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15679" title="Abstract">arXiv:2311.15679</a> [<a href="/pdf/2311.15679" title="Download PDF">pdf</a>, <a href="/format/2311.15679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-agnostic Body Part Relevance Assessment for Pedestrian Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%C3%BCnder%2C+M">Maurice G&#xfc;nder</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Sneha Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Sifa%2C+R">Rafet Sifa</a>, 
<a href="/search/cs?searchtype=author&query=Bauckhage%2C+C">Christian Bauckhage</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Model-agnostic explanation methods for deep learning models are flexible
regarding usability and availability. However, due to the fact that they can
only manipulate input to see changes in output, they suffer from weak
performance when used with complex model architectures. For models with large
inputs as, for instance, in object detection, sampling-based methods like
KernelSHAP are inefficient due to many computation-heavy forward passes through
the model. In this work, we present a framework for using sampling-based
explanation models in a computer vision context by body part relevance
assessment for pedestrian detection. Furthermore, we introduce a novel
sampling-based method similar to KernelSHAP that shows more robustness for
lower sampling sizes and, thus, is more efficient for explainability analyses
on large-scale datasets.
</p>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15682" title="Abstract">arXiv:2311.15682</a> [<a href="/pdf/2311.15682" title="Download PDF">pdf</a>, <a href="/format/2311.15682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information theoretic study of the neural geometry induced by category  learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bonnasse-Gahot%2C+L">Laurent Bonnasse-Gahot</a>, 
<a href="/search/cs?searchtype=author&query=Nadal%2C+J">Jean-Pierre Nadal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures, Accepted (Oral) to InfoCog@NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Categorization is an important topic both for biological and artificial
neural networks. Here, we take an information theoretic approach to assess the
efficiency of the representations induced by category learning. We show that
one can decompose the relevant Bayesian cost into two components, one for the
coding part and one for the decoding part. Minimizing the coding cost implies
maximizing the mutual information between the set of categories and the neural
activities. We analytically show that this mutual information can be written as
the sum of two terms that can be interpreted as (i) finding an appropriate
representation space, and, (ii) building a representation with the appropriate
metrics, based on the neural Fisher information on this space. One main
consequence is that category learning induces an expansion of neural space near
decision boundaries. Finally, we provide numerical illustrations that show how
Fisher information of the coding neural population aligns with the boundaries
between categories.
</p>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15685" title="Abstract">arXiv:2311.15685</a> [<a href="/pdf/2311.15685" title="Download PDF">pdf</a>, <a href="/format/2311.15685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Battleship Approach to the Low Resource Entity Matching Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Genossar%2C+B">Bar Genossar</a> (1), 
<a href="/search/cs?searchtype=author&query=Gal%2C+A">Avigdor Gal</a> (1), 
<a href="/search/cs?searchtype=author&query=Shraga%2C+R">Roee Shraga</a> (2) ((1) Technion - Israel Institute of Technology, (2) Worcester Polytechnic Institute)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Entity matching, a core data integration problem, is the task of deciding
whether two data tuples refer to the same real-world entity. Recent advances in
deep learning methods, using pre-trained language models, were proposed for
resolving entity matching. Although demonstrating unprecedented results, these
solutions suffer from a major drawback as they require large amounts of labeled
data for training, and, as such, are inadequate to be applied to low resource
entity matching problems. To overcome the challenge of obtaining sufficient
labeled data we offer a new active learning approach, focusing on a selection
mechanism that exploits unique properties of entity matching. We argue that a
distributed representation of a tuple pair indicates its informativeness when
considered among other pairs. This is used consequently in our approach that
iteratively utilizes space-aware considerations. Bringing it all together, we
treat the low resource entity matching problem as a Battleship game, hunting
indicative samples, focusing on positive ones, through awareness of the latent
space along with careful planning of next sampling iterations. An extensive
experimental analysis shows that the proposed algorithm outperforms
state-of-the-art active learning solutions to low resource entity matching, and
although using less samples, can be as successful as state-of-the-art fully
trained known algorithms.
</p>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15688" title="Abstract">arXiv:2311.15688</a> [<a href="/pdf/2311.15688" title="Download PDF">pdf</a>, <a href="/format/2311.15688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Knowledge Graph Approach for Exploratory Search in Research  Institutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schopf%2C+T">Tim Schopf</a>, 
<a href="/search/cs?searchtype=author&query=Machner%2C+N">Nektrios Machner</a>, 
<a href="/search/cs?searchtype=author&query=Matthes%2C+F">Florian Matthes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to 15th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management - KMIS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">Over the past decades, research institutions have grown increasingly and
consequently also their research output. This poses a significant challenge for
researchers seeking to understand the research landscape of an institution. The
process of exploring the research landscape of institutions has a vague
information need, no precise goal, and is open-ended. Current applications are
not designed to fulfill the requirements for exploratory search in research
institutions. In this paper, we analyze exploratory search in research
institutions and propose a knowledge graph-based approach to enhance this
process.
</p>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15689" title="Abstract">arXiv:2311.15689</a> [<a href="/pdf/2311.15689" title="Download PDF">pdf</a>, <a href="/ps/2311.15689" title="Download PostScript">ps</a>, <a href="/format/2311.15689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two Approaches to the Identity of Processes in BFO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Toyoshima%2C+F">Fumiaki Toyoshima</a> (IRIT), 
<a href="/search/cs?searchtype=author&query=Barton%2C+A">Adrien Barton</a> (IRIT, UT)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">This paper aims to explore processes and their identity with a focus on the
upper ontology Basic Formal Ontology (BFO). We begin with a classification
based on two basic classes of changes of independent continuants: changes with
respect to a single specifically dependent continuant thereof or with respect
to the spatial region that its parts occupy. We accordingly distinguish two
kinds of simple processes: specifically dependent continuant changes and
spatial changes. Next, we investigate a compositional approach to the identity
of processes: the identity of any process is determined by the identity of the
simple processes that compose them. Then, we consider a causal approach to the
identity of processes with recourse to a dispositional view of processes
according to which any process is a realization of some disposition. We also
examine assumptions on which these two approaches to the identity of processes
are based.
</p>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15691" title="Abstract">arXiv:2311.15691</a> [<a href="/pdf/2311.15691" title="Download PDF">pdf</a>, <a href="/format/2311.15691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated discovery of trade-off between utility, privacy and fairness  in machine learning models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ficiu%2C+B">Bogdan Ficiu</a>, 
<a href="/search/cs?searchtype=author&query=Lawrence%2C+N+D">Neil D. Lawrence</a>, 
<a href="/search/cs?searchtype=author&query=Paleyes%2C+A">Andrei Paleyes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3rd Workshop on Bias and Fairness in AI (BIAS), ECML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computers and Society (cs.CY)

</div>
<p class="mathjax">Machine learning models are deployed as a central component in decision
making and policy operations with direct impact on individuals' lives. In order
to act ethically and comply with government regulations, these models need to
make fair decisions and protect the users' privacy. However, such requirements
can come with decrease in models' performance compared to their potentially
biased, privacy-leaking counterparts. Thus the trade-off between fairness,
privacy and performance of ML models emerges, and practitioners need a way of
quantifying this trade-off to enable deployment decisions. In this work we
interpret this trade-off as a multi-objective optimization problem, and propose
PFairDP, a pipeline that uses Bayesian optimization for discovery of
Pareto-optimal points between fairness, privacy and utility of ML models. We
show how PFairDP can be used to replicate known results that were achieved
through manual constraint setting process. We further demonstrate effectiveness
of PFairDP with experiments on multiple models and datasets.
</p>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15698" title="Abstract">arXiv:2311.15698</a> [<a href="/pdf/2311.15698" title="Download PDF">pdf</a>, <a href="/format/2311.15698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cerbero-7B: A Leap Forward in Language-Specific LLMs Through Enhanced  Chat Corpus Generation and Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Galatolo%2C+F+A">Federico A. Galatolo</a>, 
<a href="/search/cs?searchtype=author&query=Cimino%2C+M+G+C+A">Mario G.C.A. Cimino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study introduces a novel approach for generating high-quality,
language-specific chat corpora using a self-chat mechanism. We combine a
generator LLM for creating new samples and an embedder LLM to ensure diversity.
A new Masked Language Modelling (MLM) model-based quality assessment metric is
proposed for evaluating and filtering the corpora. Utilizing the llama2-70b as
the generator and a multilingual sentence transformer as embedder, we generate
an Italian chat corpus and refine the Fauno corpus, which is based on
translated English ChatGPT self-chat data. The refinement uses structural
assertions and Natural Language Processing techniques. Both corpora undergo a
comprehensive quality evaluation using the proposed MLM model-based quality
metric. The Italian LLM fine-tuned with these corpora demonstrates
significantly enhanced language comprehension and question-answering skills.
The resultant model, cerbero-7b, establishes a new state-of-the-art for Italian
LLMs. This approach marks a substantial advancement in the development of
language-specific LLMs, with a special emphasis on augmenting corpora for
underrepresented languages like Italian.
</p>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15704" title="Abstract">arXiv:2311.15704</a> [<a href="/pdf/2311.15704" title="Download PDF">pdf</a>, <a href="/ps/2311.15704" title="Download PostScript">ps</a>, <a href="/format/2311.15704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tropical Mathematics and the Lambda Calculus I: Metric and Differential  Analysis of Effectful Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barbarossa%2C+D">Davide Barbarossa</a>, 
<a href="/search/cs?searchtype=author&query=Pistone%2C+P">Paolo Pistone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL); Logic (math.LO)

</div>
<p class="mathjax">We study the interpretation of the lambda-calculus in a framework based on
tropical mathematics, and we show that it provides a unifying framework for two
well-developed quantitative approaches to program semantics: on the one hand
program metrics, based on the analysis of program sensitivity via Lipschitz
conditions, on the other hand resource analysis, based on linear logic and
higher-order program differentiation. To do that we focus on the semantic
arising from the relational model weighted over the tropical semiring, and we
discuss its application to the study of "best case" program behavior for
languages with probabilistic and non-deterministic effects. Finally, we show
that a general foundation for this approach is provided by an abstract
correspondence between tropical algebra and Lawvere's theory of generalized
metric spaces.
</p>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15707" title="Abstract">arXiv:2311.15707</a> [<a href="/pdf/2311.15707" title="Download PDF">pdf</a>, <a href="/format/2311.15707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAM-6D: Segment Anything Model Meets Zero-Shot 6D Object Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiehong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lihua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+D">Dekun Lu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+K">Kui Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Github Page: <a href="https://github.com/JiehongLin/SAM-6D">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Zero-shot 6D object pose estimation involves the detection of novel objects
with their 6D poses in cluttered scenes, presenting significant challenges for
model generalizability. Fortunately, the recent Segment Anything Model (SAM)
has showcased remarkable zero-shot transfer performance, which provides a
promising solution to tackle this task. Motivated by this, we introduce SAM-6D,
a novel framework designed to realize the task through two steps, including
instance segmentation and pose estimation. Given the target objects, SAM-6D
employs two dedicated sub-networks, namely Instance Segmentation Model (ISM)
and Pose Estimation Model (PEM), to perform these steps on cluttered RGB-D
images. ISM takes SAM as an advanced starting point to generate all possible
object proposals and selectively preserves valid ones through meticulously
crafted object matching scores in terms of semantics, appearance and geometry.
By treating pose estimation as a partial-to-partial point matching problem, PEM
performs a two-stage point matching process featuring a novel design of
background tokens to construct dense 3D-3D correspondence, ultimately yielding
the pose estimates. Without bells and whistles, SAM-6D outperforms the existing
methods on the seven core datasets of the BOP Benchmark for both instance
segmentation and pose estimation of novel objects.
</p>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15716" title="Abstract">arXiv:2311.15716</a> [<a href="/pdf/2311.15716" title="Download PDF">pdf</a>, <a href="/format/2311.15716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Justifiable Artificial Intelligence: Engineering Large Language Models  for Legal Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wehnert%2C+S">Sabine Wehnert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC); Information Retrieval (cs.IR)

</div>
<p class="mathjax">In this work, I discuss how Large Language Models can be applied in the legal
domain, circumventing their current drawbacks. Despite their large success and
acceptance, their lack of explainability hinders legal experts to trust in
their output, and this happens rightfully so. However, in this paper, I argue
in favor of a new view, Justifiable Artificial Intelligence, instead of
focusing on Explainable Artificial Intelligence. I discuss in this paper how
gaining evidence for and against a Large Language Model's output may make their
generated texts more trustworthy - or hold them accountable for misinformation.
</p>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15719" title="Abstract">arXiv:2311.15719</a> [<a href="/pdf/2311.15719" title="Download PDF">pdf</a>, <a href="/format/2311.15719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Autoencoders for Feature Exploration and Malignancy  Prediction of Lung Lesions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Keel%2C+B">Benjamin Keel</a>, 
<a href="/search/cs?searchtype=author&query=Quyn%2C+A">Aaron Quyn</a>, 
<a href="/search/cs?searchtype=author&query=Jayne%2C+D">David Jayne</a>, 
<a href="/search/cs?searchtype=author&query=Relton%2C+S+D">Samuel D. Relton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages (main paper), 5 pages (references), 5 figures, 2 tables, work accepted for BMVC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Lung cancer is responsible for 21% of cancer deaths in the UK and five-year
survival rates are heavily influenced by the stage the cancer was identified
at. Recent studies have demonstrated the capability of AI methods for accurate
and early diagnosis of lung cancer from routine scans. However, this evidence
has not translated into clinical practice with one barrier being a lack of
interpretable models. This study investigates the application Variational
Autoencoders (VAEs), a type of generative AI model, to lung cancer lesions.
Proposed models were trained on lesions extracted from 3D CT scans in the
LIDC-IDRI public dataset. Latent vector representations of 2D slices produced
by the VAEs were explored through clustering to justify their quality and used
in an MLP classifier model for lung cancer diagnosis, the best model achieved
state-of-the-art metrics of AUC 0.98 and 93.1% accuracy. Cluster analysis shows
the VAE latent space separates the dataset of malignant and benign lesions
based on meaningful feature components including tumour size, shape, patient
and malignancy class. We also include a comparative analysis of the standard
Gaussian VAE (GVAE) and the more recent Dirichlet VAE (DirVAE), which replaces
the prior with a Dirichlet distribution to encourage a more explainable latent
space with disentangled feature representation. Finally, we demonstrate the
potential for latent space traversals corresponding to clinically meaningful
feature changes.
</p>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15722" title="Abstract">arXiv:2311.15722</a> [<a href="/pdf/2311.15722" title="Download PDF">pdf</a>, <a href="/format/2311.15722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GLIME: General, Stable and Local LIME Explanation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zeren Tan</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yang Tian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jian Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023 as a Spotlight paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC); Machine Learning (stat.ML)

</div>
<p class="mathjax">As black-box machine learning models grow in complexity and find applications
in high-stakes scenarios, it is imperative to provide explanations for their
predictions. Although Local Interpretable Model-agnostic Explanations (LIME)
[22] is a widely adpoted method for understanding model behaviors, it is
unstable with respect to random seeds [35,24,3] and exhibits low local fidelity
(i.e., how well the explanation approximates the model's local behaviors)
[21,16]. Our study shows that this instability problem stems from small sample
weights, leading to the dominance of regularization and slow convergence.
Additionally, LIME's sampling neighborhood is non-local and biased towards the
reference, resulting in poor local fidelity and sensitivity to reference
choice. To tackle these challenges, we introduce GLIME, an enhanced framework
extending LIME and unifying several prior methods. Within the GLIME framework,
we derive an equivalent formulation of LIME that achieves significantly faster
convergence and improved stability. By employing a local and unbiased sampling
distribution, GLIME generates explanations with higher local fidelity compared
to LIME. GLIME explanations are independent of reference choice. Moreover,
GLIME offers users the flexibility to choose a sampling distribution based on
their specific scenarios.
</p>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15723" title="Abstract">arXiv:2311.15723</a> [<a href="/pdf/2311.15723" title="Download PDF">pdf</a>, <a href="/format/2311.15723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Italian Crossword Generator: Enhancing Education through Interactive  Word Puzzles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeinalipour%2C+K">Kamyar Zeinalipour</a>, 
<a href="/search/cs?searchtype=author&query=laquinta%2C+T">Tommaso laquinta</a>, 
<a href="/search/cs?searchtype=author&query=Zanollo%2C+A">Asya Zanollo</a>, 
<a href="/search/cs?searchtype=author&query=Angelini%2C+G">Giovanni Angelini</a>, 
<a href="/search/cs?searchtype=author&query=Rigutini%2C+L">Leonardo Rigutini</a>, 
<a href="/search/cs?searchtype=author&query=Maggini%2C+M">Marco Maggini</a>, 
<a href="/search/cs?searchtype=author&query=Gori%2C+M">Marco Gori</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted Paper for CLiC-it 2023 - 9th Italian Conference on Computational Linguistics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Educational crosswords offer numerous benefits for students, including
increased engagement, improved understanding, critical thinking, and memory
retention. Creating high-quality educational crosswords can be challenging, but
recent advances in natural language processing and machine learning have made
it possible to use language models to generate nice wordplays. The exploitation
of cutting-edge language models like GPT3-DaVinci, GPT3-Curie, GPT3-Babbage,
GPT3-Ada, and BERT-uncased has led to the development of a comprehensive system
for generating and verifying crossword clues. A large dataset of clue-answer
pairs was compiled to fine-tune the models in a supervised manner to generate
original and challenging clues from a given keyword. On the other hand, for
generating crossword clues from a given text, Zero/Few-shot learning techniques
were used to extract clues from the input text, adding variety and creativity
to the puzzles. We employed the fine-tuned model to generate data and labeled
the acceptability of clue-answer parts with human supervision. To ensure
quality, we developed a classifier by fine-tuning existing language models on
the labeled dataset. Conversely, to assess the quality of clues generated from
the given text using zero/few-shot learning, we employed a zero-shot learning
approach to check the quality of generated clues. The results of the evaluation
have been very promising, demonstrating the effectiveness of the approach in
creating high-standard educational crosswords that offer students engaging and
rewarding learning experiences.
</p>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15727" title="Abstract">arXiv:2311.15727</a> [<a href="/pdf/2311.15727" title="Download PDF">pdf</a>, <a href="/format/2311.15727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MARIS: Referring Image Segmentation via Mutual-Aware Attention Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengxi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xiangjun Yin</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+H">Huanjing Yue</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jingyu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Referring image segmentation (RIS) aims to segment a particular region based
on a language expression prompt. Existing methods incorporate linguistic
features into visual features and obtain multi-modal features for mask
decoding. However, these methods may segment the visually salient entity
instead of the correct referring region, as the multi-modal features are
dominated by the abundant visual context. In this paper, we propose MARIS, a
referring image segmentation method that leverages the Segment Anything Model
(SAM) and introduces a mutual-aware attention mechanism to enhance the
cross-modal fusion via two parallel branches. Specifically, our mutual-aware
attention mechanism consists of Vision-Guided Attention and Language-Guided
Attention, which bidirectionally model the relationship between visual and
linguistic features. Correspondingly, we design a Mask Decoder to enable
explicit linguistic guidance for more consistent segmentation with the language
expression. To this end, a multi-modal query token is proposed to integrate
linguistic information and interact with visual information simultaneously.
Extensive experiments on three benchmark datasets show that our method
outperforms the state-of-the-art RIS methods. Our code will be publicly
available.
</p>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15728" title="Abstract">arXiv:2311.15728</a> [<a href="/pdf/2311.15728" title="Download PDF">pdf</a>, <a href="/format/2311.15728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adinkra Symbol Recognition using Classical Machine Learning and Deep  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adjeisah%2C+M">Michael Adjeisah</a>, 
<a href="/search/cs?searchtype=author&query=Asamoah%2C+K+O">Kwame Omono Asamoah</a>, 
<a href="/search/cs?searchtype=author&query=Yeboah%2C+M+A">Martha Asamoah Yeboah</a>, 
<a href="/search/cs?searchtype=author&query=King%2C+R+R">Raji Rafiu King</a>, 
<a href="/search/cs?searchtype=author&query=Achaab%2C+G+F">Godwin Ferguson Achaab</a>, 
<a href="/search/cs?searchtype=author&query=Adjei%2C+K">Kingsley Adjei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 6 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Artificial intelligence (AI) has emerged as a transformative influence,
engendering paradigm shifts in global societies, spanning academia and
industry. However, in light of these rapid advances, addressing the
underrepresentation of black communities and African countries in AI is
crucial. Boosting enthusiasm for AI can be effectively accomplished by
showcasing straightforward applications around tasks like identifying and
categorizing traditional symbols, such as Adinkra symbols, or familiar objects
within the community. In this research endeavor, we dived into classical
machine learning and harnessed the power of deep learning models to tackle the
intricate task of classifying and recognizing Adinkra symbols. The idea led to
a newly constructed ADINKRA dataset comprising 174,338 images meticulously
organized into 62 distinct classes, each representing a singular and emblematic
symbol. We constructed a CNN model for classification and recognition using six
convolutional layers, three fully connected (FC) layers, and optional dropout
regularization. The model is a simpler and smaller version of VGG, with fewer
layers, smaller channel sizes, and a fixed kernel size. Additionally, we tap
into the transfer learning capabilities provided by pre-trained models like VGG
and ResNet. These models assist us in both classifying images and extracting
features that can be used with classical machine learning models. We assess the
model's performance by measuring its accuracy and convergence rate and
visualizing the areas that significantly influence its predictions. These
evaluations serve as a foundational benchmark for future assessments of the
ADINKRA dataset. We hope this application exemplar inspires ideas on the
various uses of AI in organizing our traditional and modern lives.
</p>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15730" title="Abstract">arXiv:2311.15730</a> [<a href="/pdf/2311.15730" title="Download PDF">pdf</a>, <a href="/format/2311.15730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analytical Queries: A Comprehensive Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kurapov%2C+P">Petr Kurapov</a>, 
<a href="/search/cs?searchtype=author&query=Melik-Adamyan%2C+A">Areg Melik-Adamyan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Performance (cs.PF)

</div>
<p class="mathjax">Modern hardware heterogeneity brings efficiency and performance opportunities
for analytical query processing. In the presence of continuous data volume and
complexity growth, bridging the gap between recent hardware advancements and
the data processing tools ecosystem is paramount for improving the speed of ETL
and model development. In this paper, we present a comprehensive overview of
existing analytical query processing approaches as well as the use and design
of systems that use heterogeneous hardware for the task. We then analyze
state-of-the-art solutions and identify missing pieces. The last two chapters
discuss the identified problems and present our view on how the ecosystem
should evolve.
</p>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15732" title="Abstract">arXiv:2311.15732</a> [<a href="/pdf/2311.15732" title="Download PDF">pdf</a>, <a href="/format/2311.15732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT4Vis: What Can GPT-4 Do for Zero-shot Visual Recognition?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenhao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Huanjin Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengxi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yuxin Song</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingdong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report. Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper does not present a novel method. Instead, it delves into an
essential, yet must-know baseline in light of the latest advancements in
Generative Artificial Intelligence (GenAI): the utilization of GPT-4 for visual
understanding. Our study centers on the evaluation of GPT-4's linguistic and
visual capabilities in zero-shot visual recognition tasks. Specifically, we
explore the potential of its generated rich textual descriptions across various
categories to enhance recognition performance without any training.
Additionally, we evaluate its visual proficiency in directly recognizing
diverse visual content. To achieve this, we conduct an extensive series of
experiments, systematically quantifying the performance of GPT-4 across three
modalities: images, videos, and point clouds. This comprehensive evaluation
encompasses a total of 16 widely recognized benchmark datasets, providing top-1
and top-5 accuracy metrics. Our study reveals that leveraging GPT-4's advanced
linguistic knowledge to generate rich descriptions markedly improves zero-shot
recognition. In terms of visual proficiency, GPT-4V's average performance
across 16 datasets sits roughly between the capabilities of OpenAI-CLIP's ViT-L
and EVA-CLIP's ViT-E. We hope that this research will contribute valuable data
points and experience for future studies. We release our code at
https://github.com/whwu95/GPT4Vis.
</p>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15736" title="Abstract">arXiv:2311.15736</a> [<a href="/pdf/2311.15736" title="Download PDF">pdf</a>, <a href="/format/2311.15736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SceneDM: Scene-level Multi-agent Trajectory Generation with Consistent  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhiming Guo</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xing Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jianlan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xinyu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Botian Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Realistic scene-level multi-agent motion simulations are crucial for
developing and evaluating self-driving algorithms. However, most existing works
focus on generating trajectories for a certain single agent type, and typically
ignore the consistency of generated trajectories. In this paper, we propose a
novel framework based on diffusion models, called SceneDM, to generate joint
and consistent future motions of all the agents, including vehicles, bicycles,
pedestrians, etc., in a scene. To enhance the consistency of the generated
trajectories, we resort to a new Transformer-based network to effectively
handle agent-agent interactions in the inverse process of motion diffusion. In
consideration of the smoothness of agent trajectories, we further design a
simple yet effective consistent diffusion approach, to improve the model in
exploiting short-term temporal dependencies. Furthermore, a scene-level scoring
function is attached to evaluate the safety and road-adherence of the generated
agent's motions and help filter out unrealistic simulations. Finally, SceneDM
achieves state-of-the-art results on the Waymo Sim Agents Benchmark. Project
webpage is available at https://alperen-hub.github.io/SceneDM.
</p>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15737" title="Abstract">arXiv:2311.15737</a> [<a href="/pdf/2311.15737" title="Download PDF">pdf</a>, <a href="/format/2311.15737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quasi-optimal Discontinuous Galerkin discretisations of the  $p$-Dirichlet problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Blechta%2C+J">J. Blechta</a>, 
<a href="/search/math?searchtype=author&query=Gazca-Orozco%2C+P+A">P. A. Gazca-Orozco</a>, 
<a href="/search/math?searchtype=author&query=Kaltenbach%2C+A">A. Kaltenbach</a>, 
<a href="/search/math?searchtype=author&query=R%C5%AF%C5%BEi%C4%8Dka%2C+M">M. R&#x16f;&#x17e;i&#x10d;ka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The classical arguments employed when obtaining error estimates of Finite
Element (FE) discretisations of elliptic problems lead to more restrictive
assumptions on the regularity of the exact solution when applied to
non-conforming methods. The so-called minimal regularity estimates available in
the literature relax some of these assumptions, but are not truly of -minimal
regularity-, since a data oscillation term appears in the error estimate.
Employing an approach based on a smoothing operator, we derive for the first
time error estimates for Discontinuous Galerkin (DG) type discretisations of
non-linear problems with $(p,\delta)$-structure that only assume the natural
$W^{1,p}$-regularity of the exact solution, and which do not contain any
oscillation terms.
</p>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15738" title="Abstract">arXiv:2311.15738</a> [<a href="/pdf/2311.15738" title="Download PDF">pdf</a>, <a href="/format/2311.15738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On full linear convergence and optimal complexity of adaptive FEM with  inexact solver
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bringmann%2C+P">Philipp Bringmann</a>, 
<a href="/search/math?searchtype=author&query=Feischl%2C+M">Michael Feischl</a>, 
<a href="/search/math?searchtype=author&query=Miraci%2C+A">Ani Miraci</a>, 
<a href="/search/math?searchtype=author&query=Praetorius%2C+D">Dirk Praetorius</a>, 
<a href="/search/math?searchtype=author&query=Streitberger%2C+J">Julian Streitberger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The ultimate goal of any numerical scheme for partial differential equations
(PDEs) is to compute an approximation of user-prescribed accuracy at
quasi-minimal computational time. To this end, algorithmically, the standard
adaptive finite element method (AFEM) integrates an inexact solver and nested
iterations with discerning stopping criteria balancing the different error
components. The analysis ensuring optimal convergence order of AFEM with
respect to the overall computational cost critically hinges on the concept of
R-linear convergence of a suitable quasi-error quantity. This work tackles
several shortcomings of previous approaches by introducing a new proof
strategy. First, the algorithm requires several fine-tuned parameters in order
to make the underlying analysis work. A redesign of the standard line of
reasoning and the introduction of a summability criterion for R-linear
convergence allows us to remove restrictions on those parameters. Second, the
usual assumption of a (quasi-)Pythagorean identity is replaced by the
generalized notion of quasi-orthogonality from [Feischl, Math. Comp., 91
(2022)]. Importantly, this paves the way towards extending the analysis to
general inf-sup stable problems beyond the energy minimization setting.
Numerical experiments investigate the choice of the adaptivity parameters.
</p>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15740" title="Abstract">arXiv:2311.15740</a> [<a href="/pdf/2311.15740" title="Download PDF">pdf</a>, <a href="/format/2311.15740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimization of Image Processing Algorithms for Character Recognition in  Cultural Typewritten Documents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dias%2C+M">Mariana Dias</a>, 
<a href="/search/cs?searchtype=author&query=Lopes%2C+C+T">Carla Teixeira Lopes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 4 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J. Comput. Cult. Herit. 16, 4, Article 77 (December 2023), 25
  pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Digital Libraries (cs.DL)

</div>
<p class="mathjax">Linked Data is used in various fields as a new way of structuring and
connecting data. Cultural heritage institutions have been using linked data to
improve archival descriptions and facilitate the discovery of information. Most
archival records have digital representations of physical artifacts in the form
of scanned images that are non-machine-readable. Optical Character Recognition
(OCR) recognizes text in images and translates it into machine-encoded text.
This paper evaluates the impact of image processing methods and parameter
tuning in OCR applied to typewritten cultural heritage documents. The approach
uses a multi-objective problem formulation to minimize Levenshtein edit
distance and maximize the number of words correctly identified with a
non-dominated sorting genetic algorithm (NSGA-II) to tune the methods'
parameters. Evaluation results show that parameterization by digital
representation typology benefits the performance of image pre-processing
algorithms in OCR. Furthermore, our findings suggest that employing image
pre-processing algorithms in OCR might be more suitable for typologies where
the text recognition task without pre-processing does not produce good results.
In particular, Adaptive Thresholding, Bilateral Filter, and Opening are the
best-performing algorithms for the theatre plays' covers, letters, and overall
dataset, respectively, and should be applied before OCR to improve its
performance.
</p>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15741" title="Abstract">arXiv:2311.15741</a> [<a href="/pdf/2311.15741" title="Download PDF">pdf</a>, <a href="/ps/2311.15741" title="Download PostScript">ps</a>, <a href="/format/2311.15741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning-Based Jamun Leaf Disease Detection: A Comprehensive  Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhowmik%2C+A+C">Auvick Chandra Bhowmik</a>, 
<a href="/search/cs?searchtype=author&query=Ahad%2C+D+M+T">Dr. Md. Taimur Ahad</a>, 
<a href="/search/cs?searchtype=author&query=Emon%2C+Y+R">Yousuf Rayhan Emon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Jamun leaf diseases pose a significant threat to agricultural productivity,
negatively impacting both yield and quality in the jamun industry. The advent
of machine learning has opened up new avenues for tackling these diseases
effectively. Early detection and diagnosis are essential for successful crop
management. While no automated systems have yet been developed specifically for
jamun leaf disease detection, various automated systems have been implemented
for similar types of disease detection using image processing techniques. This
paper presents a comprehensive review of machine learning methodologies
employed for diagnosing plant leaf diseases through image classification, which
can be adapted for jamun leaf disease detection. It meticulously assesses the
strengths and limitations of various Vision Transformer models, including
Transfer learning model and vision transformer (TLMViT), SLViT, SE-ViT,
IterationViT, Tiny-LeViT, IEM-ViT, GreenViT, and PMViT. Additionally, the paper
reviews models such as Dense Convolutional Network (DenseNet), Residual Neural
Network (ResNet)-50V2, EfficientNet, Ensemble model, Convolutional Neural
Network (CNN), and Locally Reversible Transformer. These machine-learning
models have been evaluated on various datasets, demonstrating their real-world
applicability. This review not only sheds light on current advancements in the
field but also provides valuable insights for future research directions in
machine learning-based jamun leaf disease detection and classification.
</p>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15744" title="Abstract">arXiv:2311.15744</a> [<a href="/pdf/2311.15744" title="Download PDF">pdf</a>, <a href="/format/2311.15744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One More Step: A Versatile Plug-and-Play Module for Rectifying Diffusion  Schedule Flaws and Enhancing Low-Frequency Controls
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+M">Minghui Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jianbin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chuanxia Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chaoyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Cham%2C+T">Tat-Jen Cham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://jabir-zheng.github.io/OneMoreStep/">this https URL</a>, Demo Page: <a href="https://huggingface.co/spaces/h1t/oms_sdxl_lcm">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">It is well known that many open-released foundational diffusion models have
difficulty in generating images that substantially depart from average
brightness, despite such images being present in the training data. This is due
to an inconsistency: while denoising starts from pure Gaussian noise during
inference, the training noise schedule retains residual data even in the final
timestep distribution, due to difficulties in numerical conditioning in
mainstream formulation, leading to unintended bias during inference. To
mitigate this issue, certain $\epsilon$-prediction models are combined with an
ad-hoc offset-noise methodology. In parallel, some contemporary models have
adopted zero-terminal SNR noise schedules together with
$\mathbf{v}$-prediction, which necessitate major alterations to pre-trained
models. However, such changes risk destabilizing a large multitude of
community-driven applications anchored on these pre-trained models. In light of
this, our investigation revisits the fundamental causes, leading to our
proposal of an innovative and principled remedy, called One More Step (OMS). By
integrating a compact network and incorporating an additional simple yet
effective step during inference, OMS elevates image fidelity and harmonizes the
dichotomy between training and inference, while preserving original model
parameters. Once trained, various pre-trained diffusion models with the same
latent domain can share the same OMS module.
</p>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15756" title="Abstract">arXiv:2311.15756</a> [<a href="/pdf/2311.15756" title="Download PDF">pdf</a>, <a href="/format/2311.15756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Multi-Frequency Partial Correlation Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%27Acunto%2C+G">Gabriele D&#x27;Acunto</a>, 
<a href="/search/cs?searchtype=author&query=Di+Lorenzo%2C+P">Paolo Di Lorenzo</a>, 
<a href="/search/cs?searchtype=author&query=Bonchi%2C+F">Francesco Bonchi</a>, 
<a href="/search/cs?searchtype=author&query=Sardellitti%2C+S">Stefania Sardellitti</a>, 
<a href="/search/cs?searchtype=author&query=Barbarossa%2C+S">Sergio Barbarossa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Machine Learning (stat.ML)

</div>
<p class="mathjax">Despite the large research effort devoted to learning dependencies between
time series, the state of the art still faces a major limitation: existing
methods learn partial correlations but fail to discriminate across distinct
frequency bands. Motivated by many applications in which this differentiation
is pivotal, we overcome this limitation by learning a block-sparse,
frequency-dependent, partial correlation graph, in which layers correspond to
different frequency bands, and partial correlations can occur over just a few
layers. To this aim, we formulate and solve two nonconvex learning problems:
the first has a closed-form solution and is suitable when there is prior
knowledge about the number of partial correlations; the second hinges on an
iterative solution based on successive convex approximation, and is effective
for the general case where no prior knowledge is available. Numerical results
on synthetic data show that the proposed methods outperform the current state
of the art. Finally, the analysis of financial time series confirms that
partial correlations exist only within a few frequency bands, underscoring how
our methods enable the gaining of valuable insights that would be undetected
without discriminating along the frequency domain.
</p>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15759" title="Abstract">arXiv:2311.15759</a> [<a href="/pdf/2311.15759" title="Download PDF">pdf</a>, <a href="/format/2311.15759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Vision Enhancing LLMs: Empowering Multimodal Knowledge Storage  and Sharing in LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Baotian Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xiaochun Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recent advancements in multimodal large language models (MLLMs) have achieved
significant multimodal generation capabilities, akin to GPT-4. These models
predominantly map visual information into language representation space,
leveraging the vast knowledge and powerful text generation abilities of LLMs to
produce multimodal instruction-following responses. We could term this method
as LLMs for Vision because of its employing LLMs for visual-language
understanding, yet observe that these MLLMs neglect the potential of harnessing
visual knowledge to enhance overall capabilities of LLMs, which could be
regraded as Vision Enhancing LLMs. In this paper, we propose an approach called
MKS2, aimed at enhancing LLMs through empowering Multimodal Knowledge Storage
and Sharing in LLMs. Specifically, we introduce the Modular Visual Memory, a
component integrated into the internal blocks of LLMs, designed to store
open-world visual information efficiently. Additionally, we present a soft
Mixtures-of-Multimodal Experts architecture in LLMs to invoke multimodal
knowledge collaboration during generation. Our comprehensive experiments
demonstrate that MKS2 substantially augments the reasoning capabilities of LLMs
in contexts necessitating physical or commonsense knowledge. It also delivers
competitive results on multimodal benchmarks.
</p>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15766" title="Abstract">arXiv:2311.15766</a> [<a href="/pdf/2311.15766" title="Download PDF">pdf</a>, <a href="/ps/2311.15766" title="Download PostScript">ps</a>, <a href="/format/2311.15766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Unlearning for LLMs: Tasks, Methods, and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Si%2C+N">Nianwen Si</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">Heyu Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenlin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+D">Dan Qu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiqiang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In recent years, large language models (LLMs) have spurred a new research
paradigm in natural language processing. Despite their excellent capability in
knowledge-based question answering and reasoning, their potential to retain
faulty or even harmful knowledge poses risks of malicious application. The
challenge of mitigating this issue and transforming these models into purer
assistants is crucial for their widespread applicability. Unfortunately,
Retraining LLMs repeatedly to eliminate undesirable knowledge is impractical
due to their immense parameters. Knowledge unlearning, derived from analogous
studies on machine unlearning, presents a promising avenue to address this
concern and is notably advantageous in the context of LLMs. It allows for the
removal of harmful knowledge in an efficient manner, without affecting
unrelated knowledge in the model. To this end, we provide a survey of knowledge
unlearning in the era of LLMs. Firstly, we formally define the knowledge
unlearning problem and distinguish it from related works. Subsequently, we
categorize existing knowledge unlearning methods into three classes: those
based on parameter optimization, parameter merging, and in-context learning,
and introduce details of these unlearning methods. We further present
evaluation datasets used in existing methods, and finally conclude this survey
by presenting the ongoing challenges and future directions.
</p>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15767" title="Abstract">arXiv:2311.15767</a> [<a href="/pdf/2311.15767" title="Download PDF">pdf</a>, <a href="/format/2311.15767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Homogeneous algorithms and solvable problems on cones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Krieg%2C+D">David Krieg</a>, 
<a href="/search/math?searchtype=author&query=Kritzer%2C+P">Peter Kritzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider linear problems in the worst case setting. That is, given a
linear operator and a pool of admissible linear measurements, we want to
approximate the values of the operator uniformly on a convex and balanced set
by means of algorithms that use at most $n$ such measurements. It is known
that, in general, linear algorithms do not yield an optimal approximation.
However, as we show in this paper, an optimal approximation can always be
obtained with a homogeneous algorithm. This is of interest to us for two
reasons. First, the homogeneity allows us to extend any error bound on the unit
ball to the full input space. Second, homogeneous algorithms are better suited
to tackle problems on cones, a scenario that is far less understood than the
classical situation of balls. We illustrate our results by several examples.
</p>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15769" title="Abstract">arXiv:2311.15769</a> [<a href="/pdf/2311.15769" title="Download PDF">pdf</a>, <a href="/format/2311.15769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Side4Video: Spatial-Temporal Side Network for Memory-Efficient  Image-to-Video Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Huanjin Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenhao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiheng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large pre-trained vision models achieve impressive success in computer
vision. However, fully fine-tuning large models for downstream tasks,
particularly in video understanding, can be prohibitively computationally
expensive. Recent studies turn their focus towards efficient image-to-video
transfer learning. Nevertheless, existing efficient fine-tuning methods lack
attention to training memory usage and exploration of transferring a larger
model to the video domain. In this paper, we present a novel Spatial-Temporal
Side Network for memory-efficient fine-tuning large image models to video
understanding, named Side4Video. Specifically, we introduce a lightweight
spatial-temporal side network attached to the frozen vision model, which avoids
the backpropagation through the heavy pre-trained model and utilizes
multi-level spatial features from the original image model. Extremely
memory-efficient architecture enables our method to reduce 75% memory usage
than previous adapter-based methods. In this way, we can transfer a huge ViT-E
(4.4B) for video understanding tasks which is 14x larger than ViT-L (304M). Our
approach achieves remarkable performance on various video datasets across
unimodal and cross-modal tasks (i.e., action recognition and text-video
retrieval), especially in Something-Something V1&amp;V2 (67.3% &amp; 74.6%),
Kinetics-400 (88.6%), MSR-VTT (52.3%), MSVD (56.1%) and VATEX (68.8%). We
release our code at https://github.com/HJYao00/Side4Video.
</p>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15772" title="Abstract">arXiv:2311.15772</a> [<a href="/pdf/2311.15772" title="Download PDF">pdf</a>, <a href="/format/2311.15772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attend Who is Weak: Enhancing Graph Condensation via Cross-Free  Adversarial Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinglin Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+H">Hanhui Deng</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuxuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Di Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper, we study the \textit{graph condensation} problem by
compressing the large, complex graph into a concise, synthetic representation
that preserves the most essential and discriminative information of structure
and features. We seminally propose the concept of Shock Absorber (a type of
perturbation) that enhances the robustness and stability of the original graphs
against changes in an adversarial training fashion. Concretely, (I) we forcibly
match the gradients between pre-selected graph neural networks (GNNs) trained
on a synthetic, simplified graph and the original training graph at regularly
spaced intervals. (II) Before each update synthetic graph point, a Shock
Absorber serves as a gradient attacker to maximize the distance between the
synthetic dataset and the original graph by selectively perturbing the parts
that are underrepresented or insufficiently informative. We iteratively repeat
the above two processes (I and II) in an adversarial training fashion to
maintain the highly-informative context without losing correlation with the
original dataset. More importantly, our shock absorber and the synthesized
graph parallelly share the backward process in a free training manner. Compared
to the original adversarial training, it introduces almost no additional time
overhead.
<br />We validate our framework across 8 datasets (3 graph and 5 node
classification datasets) and achieve prominent results: for example, on Cora,
Citeseer and Ogbn-Arxiv, we can gain nearly 1.13% to 5.03% improvements compare
with SOTA models. Moreover, our algorithm adds only about 0.2% to 2.2%
additional time overhead over Flicker, Citeseer and Ogbn-Arxiv. Compared to the
general adversarial training, our approach improves time efficiency by nearly
4-fold.
</p>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15773" title="Abstract">arXiv:2311.15773</a> [<a href="/pdf/2311.15773" title="Download PDF">pdf</a>, <a href="/format/2311.15773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Check, Locate, Rectify: A Training-Free Layout Calibration System for  Text-to-Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+B">Biao Gong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Siteng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yutong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion models have recently achieved remarkable progress in generating
realistic images. However, challenges remain in accurately understanding and
synthesizing the layout requirements in the textual prompts. To align the
generated image with layout instructions, we present a training-free layout
calibration system SimM that intervenes in the generative process on the fly
during inference time. Specifically, following a "check-locate-rectify"
pipeline, the system first analyses the prompt to generate the target layout
and compares it with the intermediate outputs to automatically detect errors.
Then, by moving the located activations and making intra- and inter-map
adjustments, the rectification process can be performed with negligible
computational overhead. To evaluate SimM over a range of layout requirements,
we present a benchmark SimMBench that compensates for the lack of superlative
spatial relations in existing datasets. And both quantitative and qualitative
results demonstrate the effectiveness of the proposed SimM in calibrating the
layout inconsistencies.
</p>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15776" title="Abstract">arXiv:2311.15776</a> [<a href="/pdf/2311.15776" title="Download PDF">pdf</a>, <a href="/format/2311.15776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable Segment Anything Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Q">Qi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+X">Xin Tao</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+L">Lei Ke</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+M">Mingqiao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+P">Pengfei Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+Y">Yu-Wing Tai</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chi-Keung Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Codes will be released upon acceptance
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The Segment Anything Model (SAM) achieves remarkable promptable segmentation
given high-quality prompts which, however, often require good skills to
specify. To make SAM robust to casual prompts, this paper presents the first
comprehensive analysis on SAM's segmentation stability across a diverse
spectrum of prompt qualities, notably imprecise bounding boxes and insufficient
points. Our key finding reveals that given such low-quality prompts, SAM's mask
decoder tends to activate image features that are biased towards the background
or confined to specific object parts. To mitigate this issue, our key idea
consists of adjusting the sampling locations of image feature using learnable
deformable offsets, while the original SAM model architecture and weights
remain unchanged. Consequently, our deformable sampling plugin (DSP) enables
SAM to adaptively shift attention to the prompted target regions in a
data-driven manner, facilitated by our effective robust training strategy
(RTS). During inference, dynamic routing plugin (DRP) is proposed that toggles
SAM between the deformable and regular grid sampling modes, conditioned on the
input prompt quality. Thus, our solution, termed Stable-SAM, is one of its kind
focusing on solely adjusting feature sampling locations, which offers several
advantages: 1) improved SAM's segmentation stability across a wide range of
prompt qualities, while 2) retaining SAM's powerful promptable segmentation
efficiency and generality, with 3) minimal learnable parameters (0.08 M) and
fast adaptation (by 1 training epoch). Extensive experiments across multiple
datasets validate the effectiveness and advantages of our approach,
underscoring Stable-SAM as a more robust solution for segmenting anything.
Codes will be released upon acceptance.
</p>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15777" title="Abstract">arXiv:2311.15777</a> [<a href="/pdf/2311.15777" title="Download PDF">pdf</a>, <a href="/format/2311.15777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Size-constrained Weighted Ancestors with Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bille%2C+P">Philip Bille</a>, 
<a href="/search/cs?searchtype=author&query=Nekrich%2C+Y">Yakov Nekrich</a>, 
<a href="/search/cs?searchtype=author&query=Pissis%2C+S+P">Solon P. Pissis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">The weighted ancestor problem on a rooted node-weighted tree $T$ is a
generalization of the classic predecessor problem: construct a data structure
for a set of integers that supports fast predecessor queries. Both problems are
known to require $\Omega(\log\log n)$ time for queries provided
$\mathcal{O}(n\text{ poly} \log n)$ space is available, where $n$ is the input
size. The weighted ancestor problem has attracted a lot of attention by the
combinatorial pattern matching community due to its direct application to
suffix trees. In this formulation of the problem, the nodes are weighted by
string depth. This attention has culminated in a data structure for weighted
ancestors in suffix trees with $\mathcal{O}(1)$ query time and an
$\mathcal{O}(n)$-time construction algorithm [Belazzougui et al., CPM 2021]. In
this paper, we consider a different version of the weighted ancestor problem,
where the nodes are weighted by any function $\textsf{weight}$ that maps the
nodes of $T$ to positive integers, such that $\textsf{weight}(u)\le
\textsf{size}(u)$ for any node $u$ and $\textsf{weight}(u_1)\le
\textsf{weight}(u_2)$ if node $u_1$ is a descendant of node $u_2$, where
$\textsf{size}(u)$ is the number of nodes in the subtree rooted at $u$. In the
size-constrained weighted ancestor (SWAQ) problem, for any node $u$ of $T$ and
any integer $k$, we are asked to return the lowest ancestor $w$ of $u$ with
weight at least $k$. We show that for any rooted tree with $n$ nodes, we can
locate node $w$ in $\mathcal{O}(1)$ time after $\mathcal{O}(n)$-time
preprocessing. In particular, this implies a data structure for the SWAQ
problem in suffix trees with $\mathcal{O}(1)$ query time and
$\mathcal{O}(n)$-time preprocessing, when the nodes are weighted by
$\textsf{weight}$. We also show several string-processing applications of this
result.
</p>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15780" title="Abstract">arXiv:2311.15780</a> [<a href="/pdf/2311.15780" title="Download PDF">pdf</a>, <a href="/ps/2311.15780" title="Download PostScript">ps</a>, <a href="/format/2311.15780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modular Customizable ROS-Based Framework for Rapid Development of Social  Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akhyani%2C+M">Mahta Akhyani</a>, 
<a href="/search/cs?searchtype=author&query=Moradi%2C+H">Hadi Moradi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Software Engineering (cs.SE); Image and Video Processing (eess.IV); Systems and Control (eess.SY)

</div>
<p class="mathjax">Developing socially competent robots requires tight integration of robotics,
computer vision, speech processing, and web technologies. We present the
Socially-interactive Robot Software platform (SROS), an open-source framework
addressing this need through a modular layered architecture. SROS bridges the
Robot Operating System (ROS) layer for mobility with web and Android interface
layers using standard messaging and APIs. Specialized perceptual and
interactive skills are implemented as ROS services for reusable deployment on
any robot. This facilitates rapid prototyping of collaborative behaviors that
synchronize perception with physical actuation. We experimentally validated
core SROS technologies including computer vision, speech processing, and GPT2
autocomplete speech implemented as plug-and-play ROS services. Modularity is
demonstrated through the successful integration of an additional ROS package,
without changes to hardware or software platforms. The capabilities enabled
confirm SROS's effectiveness in developing socially interactive robots through
synchronized cross-domain interaction. Through demonstrations showing
synchronized multimodal behaviors on an example platform, we illustrate how the
SROS architectural approach addresses shortcomings of previous work by lowering
barriers for researchers to advance the state-of-the-art in adaptive,
collaborative customizable human-robot systems through novel applications
integrating perceptual and social abilities.
</p>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15781" title="Abstract">arXiv:2311.15781</a> [<a href="/pdf/2311.15781" title="Download PDF">pdf</a>, <a href="/format/2311.15781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Increasing Coverage and Precision of Textual Information in Multilingual  Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Conia%2C+S">Simone Conia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Min Li</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Daniel Lee</a>, 
<a href="/search/cs?searchtype=author&query=Minhas%2C+U+F">Umar Farooq Minhas</a>, 
<a href="/search/cs?searchtype=author&query=Ilyas%2C+I">Ihab Ilyas</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunyao Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera ready for EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent work in Natural Language Processing and Computer Vision has been using
textual information -- e.g., entity names and descriptions -- available in
knowledge graphs to ground neural models to high-quality structured data.
However, when it comes to non-English languages, the quantity and quality of
textual information are comparatively scarce. To address this issue, we
introduce the novel task of automatic Knowledge Graph Enhancement (KGE) and
perform a thorough investigation on bridging the gap in both the quantity and
quality of textual information between English and non-English languages. More
specifically, we: i) bring to light the problem of increasing multilingual
coverage and precision of entity names and descriptions in Wikidata; ii)
demonstrate that state-of-the-art methods, namely, Machine Translation (MT),
Web Search (WS), and Large Language Models (LLMs), struggle with this task;
iii) present M-NTA, a novel unsupervised approach that combines MT, WS, and
LLMs to generate high-quality textual information; and, iv) study the impact of
increasing multilingual coverage and precision of non-English textual
information in Entity Linking, Knowledge Graph Completion, and Question
Answering. As part of our effort towards better multilingual knowledge graphs,
we also introduce WikiKGE-10, the first human-curated benchmark to evaluate KGE
approaches in 10 languages across 7 language families.
</p>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15782" title="Abstract">arXiv:2311.15782</a> [<a href="/pdf/2311.15782" title="Download PDF">pdf</a>, <a href="/ps/2311.15782" title="Download PostScript">ps</a>, <a href="/format/2311.15782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relationship between Model Compression and Adversarial Robustness: A  Review of Current Evidence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pavlitska%2C+S">Svetlana Pavlitska</a>, 
<a href="/search/cs?searchtype=author&query=Grolig%2C+H">Hannes Grolig</a>, 
<a href="/search/cs?searchtype=author&query=Z%C3%B6llner%2C+J+M">J. Marius Z&#xf6;llner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at SSCI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Increasing the model capacity is a known approach to enhance the adversarial
robustness of deep learning networks. On the other hand, various model
compression techniques, including pruning and quantization, can reduce the size
of the network while preserving its accuracy. Several recent studies have
addressed the relationship between model compression and adversarial
robustness, while some experiments have reported contradictory results. This
work summarizes available evidence and discusses possible explanations for the
observed effects.
</p>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15783" title="Abstract">arXiv:2311.15783</a> [<a href="/pdf/2311.15783" title="Download PDF">pdf</a>, <a href="/format/2311.15783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypernetworks for Generalizable BRDF Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gokbudak%2C+F">Fazilet Gokbudak</a>, 
<a href="/search/cs?searchtype=author&query=Sztrajman%2C+A">Alejandro Sztrajman</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chenliang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+F">Fangcheng Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Mantiuk%2C+R">Rafal Mantiuk</a>, 
<a href="/search/cs?searchtype=author&query=Oztireli%2C+C">Cengiz Oztireli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">In this paper, we introduce a technique to estimate measured BRDFs from a
sparse set of samples. Our approach offers accurate BRDF reconstructions that
are generalizable to new materials. This opens the door to BDRF reconstructions
from a variety of data sources. The success of our approach relies on the
ability of hypernetworks to generate a robust representation of BRDFs and a set
encoder that allows us to feed inputs of different sizes to the architecture.
We evaluate our technique both qualitatively and quantitatively on the
well-known MERL dataset of 100 isotropic materials. Our approach accurately
estimates the BRDFs of unseen materials even for an extremely sparse sampling.
</p>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15785" title="Abstract">arXiv:2311.15785</a> [<a href="/pdf/2311.15785" title="Download PDF">pdf</a>, <a href="/format/2311.15785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear Stability Boundary Assessment of Multi-Converter Systems Based  On Reverse Time Trajectory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Sujay Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Bakhshizadeh%2C+M+K">Mohammad Kazem Bakhshizadeh</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guangya Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kocewiak%2C+%C5%81">&#x141;ukasz Kocewiak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">As the integration of wind power accelerates, wind power plants (WPPs) are
expected to play a crucial role in ensuring stability in future power grids.
This paper examines the nonlinear stability boundary of a multi-converter
system in a wind power plant (WPP) connected to an AC power grid via a long
HVAC cable. Traditionally, for nonlinear analysis of WPPs, a simplification is
adopted wherein the WPP is treated as an aggregation of individual wind
turbines (WTs), with a simplified portrayal of the collector network. However,
in the presence of different technologies, such as STATCOM, that are placed
away from the WTs, the model aggregation will not hold. This paper presents a
unified methodology to model and investigate the high-dimensional stability
boundary of a WPP with a STATCOM. The stability region of the system, i.e. the
region of attraction (RoA), is determined by the reverse time (backwards)
trajectory technique. Furthermore, the estimated stability boundary is verified
using time-domain simulation studies in PSCAD.
</p>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15786" title="Abstract">arXiv:2311.15786</a> [<a href="/pdf/2311.15786" title="Download PDF">pdf</a>, <a href="/ps/2311.15786" title="Download PostScript">ps</a>, <a href="/format/2311.15786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> YUAN 2.0: A Large Language Model with Localized Filtering-based  Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shaohua Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xudong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shenling Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiangang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lingjun Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rongguo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiahua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In this work, the Localized Filtering-based Attention (LFA) is introduced to
incorporate prior knowledge of local dependencies of natural language into
Attention. Based on LFA, we develop and release Yuan 2.0, a large language
model with parameters ranging from 2.1 billion to 102.6 billion. A data
filtering and generation method is presented to build pretraining and
fine-tuning dataset in high quality. A distributed training method with
non-uniform pipeline parallel, data parallel, and optimizer parallel is
proposed, which greatly reduces the bandwidth requirements of intra-node
communication, and achieves good performance in large-scale distributed
training. Yuan 2.0 models display impressive ability in code generation, math
problem-solving, and chat compared with existing models. The latest version of
YUAN 2.0, including model weights and source code, is accessible at Github.
</p>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15790" title="Abstract">arXiv:2311.15790</a> [<a href="/pdf/2311.15790" title="Download PDF">pdf</a>, <a href="/format/2311.15790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Social-aware Gaussian Pre-trained Model for Effective Cold-start  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Siwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Macdonald%2C+C">Craig Macdonald</a>, 
<a href="/search/cs?searchtype=author&query=Ounis%2C+I">Iadh Ounis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The use of pre-training is an emerging technique to enhance a neural model's
performance, which has been shown to be effective for many neural language
models such as BERT. This technique has also been used to enhance the
performance of recommender systems. In such recommender systems, pre-training
models are used to learn a better initialisation for both users and items.
However, recent existing pre-trained recommender systems tend to only
incorporate the user interaction data at the pre-training stage, making it
difficult to deliver good recommendations, especially when the interaction data
is sparse. To alleviate this common data sparsity issue, we propose to
pre-train the recommendation model not only with the interaction data but also
with other available information such as the social relations among users,
thereby providing the recommender system with a better initialisation compared
with solely relying on the user interaction data. We propose a novel
recommendation model, the Social-aware Gaussian Pre-trained model (SGP), which
encodes the user social relations and interaction data at the pre-training
stage in a Graph Neural Network (GNN). Afterwards, in the subsequent
fine-tuning stage, our SGP model adopts a Gaussian Mixture Model (GMM) to
factorise these pre-trained embeddings for further training, thereby benefiting
the cold-start users from these pre-built social relations. Our extensive
experiments on three public datasets show that, in comparison to 16 competitive
baselines, our SGP model significantly outperforms the best baseline by upto
7.7% in terms of NDCG@10. In addition, we show that SGP permits to effectively
alleviate the cold-start problem, especially when users newly register to the
system through their friends' suggestions.
</p>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15792" title="Abstract">arXiv:2311.15792</a> [<a href="/pdf/2311.15792" title="Download PDF">pdf</a>, <a href="/format/2311.15792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Privacy in Machine Learning Pipelines from an Information  Flow Control Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wutschitz%2C+L">Lukas Wutschitz</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6pf%2C+B">Boris K&#xf6;pf</a>, 
<a href="/search/cs?searchtype=author&query=Paverd%2C+A">Andrew Paverd</a>, 
<a href="/search/cs?searchtype=author&query=Rajmohan%2C+S">Saravan Rajmohan</a>, 
<a href="/search/cs?searchtype=author&query=Salem%2C+A">Ahmed Salem</a>, 
<a href="/search/cs?searchtype=author&query=Tople%2C+S">Shruti Tople</a>, 
<a href="/search/cs?searchtype=author&query=Zanella-B%C3%A9guelin%2C+S">Santiago Zanella-B&#xe9;guelin</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+M">Menglin Xia</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%BChle%2C+V">Victor R&#xfc;hle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Modern machine learning systems use models trained on ever-growing corpora.
Typically, metadata such as ownership, access control, or licensing information
is ignored during training. Instead, to mitigate privacy risks, we rely on
generic techniques such as dataset sanitization and differentially private
model training, with inherent privacy/utility trade-offs that hurt model
performance. Moreover, these techniques have limitations in scenarios where
sensitive information is shared across multiple participants and fine-grained
access control is required. By ignoring metadata, we therefore miss an
opportunity to better address security, privacy, and confidentiality
challenges. In this paper, we take an information flow control perspective to
describe machine learning systems, which allows us to leverage metadata such as
access control policies and define clear-cut privacy and confidentiality
guarantees with interpretable information flows. Under this perspective, we
contrast two different approaches to achieve user-level non-interference: 1)
fine-tuning per-user models, and 2) retrieval augmented models that access
user-specific datasets at inference time. We compare these two approaches to a
trivially non-interfering zero-shot baseline using a public model and to a
baseline that fine-tunes this model on the whole corpus. We evaluate trained
models on two datasets of scientific articles and demonstrate that retrieval
augmented architectures deliver the best utility, scalability, and flexibility
while satisfying strict non-interference guarantees.
</p>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15800" title="Abstract">arXiv:2311.15800</a> [<a href="/pdf/2311.15800" title="Download PDF">pdf</a>, <a href="/ps/2311.15800" title="Download PostScript">ps</a>, <a href="/format/2311.15800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Public sentiment analysis and topic modeling regarding ChatGPT in mental  health on Reddit: Negative sentiments increase over time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yunna Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haowei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Q">Qianwen Qian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages.8 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">In order to uncover users' attitudes towards ChatGPT in mental health, this
study examines public opinions about ChatGPT in mental health discussions on
Reddit. Researchers used the bert-base-multilingual-uncased-sentiment
techniques for sentiment analysis and the BERTopic model for topic modeling. It
was found that overall, negative sentiments prevail, followed by positive ones,
with neutral sentiments being the least common. The prevalence of negative
emotions has increased over time. Negative emotions encompass discussions on
ChatGPT providing bad mental health advice, debates on machine vs. human value,
the fear of AI, and concerns about Universal Basic Income (UBI). In contrast,
positive emotions highlight ChatGPT's effectiveness in counseling, with
mentions of keywords like "time" and "wallet." Neutral discussions center
around private data concerns. These findings shed light on public attitudes
toward ChatGPT in mental health, potentially contributing to the development of
trustworthy AI in mental health from the public perspective.
</p>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15803" title="Abstract">arXiv:2311.15803</a> [<a href="/pdf/2311.15803" title="Download PDF">pdf</a>, <a href="/format/2311.15803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SOAC: Spatio-Temporal Overlap-Aware Multi-Sensor Calibration using  Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herau%2C+Q">Quentin Herau</a>, 
<a href="/search/cs?searchtype=author&query=Piasco%2C+N">Nathan Piasco</a>, 
<a href="/search/cs?searchtype=author&query=Bennehar%2C+M">Moussab Bennehar</a>, 
<a href="/search/cs?searchtype=author&query=Rold%C3%A3o%2C+L">Luis Rold&#xe3;o</a>, 
<a href="/search/cs?searchtype=author&query=Tsishkou%2C+D">Dzmitry Tsishkou</a>, 
<a href="/search/cs?searchtype=author&query=Migniot%2C+C">Cyrille Migniot</a>, 
<a href="/search/cs?searchtype=author&query=Vasseur%2C+P">Pascal Vasseur</a>, 
<a href="/search/cs?searchtype=author&query=Demonceaux%2C+C">C&#xe9;dric Demonceaux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper + Supplementary, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">In rapidly-evolving domains such as autonomous driving, the use of multiple
sensors with different modalities is crucial to ensure high operational
precision and stability. To correctly exploit the provided information by each
sensor in a single common frame, it is essential for these sensors to be
accurately calibrated. In this paper, we leverage the ability of Neural
Radiance Fields (NeRF) to represent different sensors modalities in a common
volumetric representation to achieve robust and accurate spatio-temporal sensor
calibration. By designing a partitioning approach based on the visible part of
the scene for each sensor, we formulate the calibration problem using only the
overlapping areas. This strategy results in a more robust and accurate
calibration that is less prone to failure. We demonstrate that our approach
works on outdoor urban scenes by validating it on multiple established driving
datasets. Results show that our method is able to get better accuracy and
robustness compared to existing methods.
</p>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15806" title="Abstract">arXiv:2311.15806</a> [<a href="/pdf/2311.15806" title="Download PDF">pdf</a>, <a href="/format/2311.15806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PIPE : Parallelized Inference Through Post-Training Quantization  Ensembling of Residual Expansions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yvinec%2C+E">Edouard Yvinec</a>, 
<a href="/search/cs?searchtype=author&query=Dapogny%2C+A">Arnaud Dapogny</a>, 
<a href="/search/cs?searchtype=author&query=Bailly%2C+K">Kevin Bailly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2203.14645">arXiv:2203.14645</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep neural networks (DNNs) are ubiquitous in computer vision and natural
language processing, but suffer from high inference cost. This problem can be
addressed by quantization, which consists in converting floating point
perations into a lower bit-width format. With the growing concerns on privacy
rights, we focus our efforts on data-free methods. However, such techniques
suffer from their lack of adaptability to the target devices, as a hardware
typically only support specific bit widths. Thus, to adapt to a variety of
devices, a quantization method shall be flexible enough to find good accuracy
v.s. speed trade-offs for every bit width and target device. To achieve this,
we propose PIPE, a quantization method that leverages residual error expansion,
along with group sparsity and an ensemble approximation for better
parallelization. PIPE is backed off by strong theoretical guarantees and
achieves superior performance on every benchmarked application (from vision to
NLP tasks), architecture (ConvNets, transformers) and bit-width (from int8 to
ternary quantization).
</p>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15807" title="Abstract">arXiv:2311.15807</a> [<a href="/pdf/2311.15807" title="Download PDF">pdf</a>, <a href="/ps/2311.15807" title="Download PostScript">ps</a>, <a href="/format/2311.15807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Artificial Intelligence Methods for Energy Prediction in  Healthcare Facilities: An In-Depth Extended Systematic Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=FatehiJananloo%2C+M">Marjan FatehiJananloo</a>, 
<a href="/search/cs?searchtype=author&query=Stopps%2C+H">Helen Stopps</a>, 
<a href="/search/cs?searchtype=author&query=McArthur%2C+J+J">J.J. McArthur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 1 figure, 3 tables, systematic literature review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Hospitals, due to their complexity and unique requirements, play a pivotal
role in global energy consumption patterns. This study conducted a
comprehensive literature review, utilizing the PRISMA framework, of articles
that employed machine learning and artificial intelligence techniques for
predicting energy consumption in hospital buildings. Of the 1884 publications
identified, 17 were found to address this specific domain and have been
thoroughly reviewed to establish the state-of-the-art and identify gaps where
future research is needed. This review revealed a diverse range of data inputs
influencing energy prediction, with occupancy and meteorological data emerging
as significant predictors. However, many studies failed to delve deep into the
implications of their data choices, and gaps were evident regarding the
understanding of time dynamics, operational status, and preprocessing methods.
Machine learning, especially deep learning models like ANNs, have shown
potential in this domain, yet they come with challenges, including
interpretability and computational demands. The findings underscore the immense
potential of AI in optimizing hospital energy consumption but also highlight
the need for more comprehensive and granular research. Key areas for future
research include the optimization of ANN approaches, new optimization and data
integration techniques, the integration of real-time data into Intelligent
Energy Management Systems, and increasing focus on long-term energy
forecasting.
</p>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15809" title="Abstract">arXiv:2311.15809</a> [<a href="/pdf/2311.15809" title="Download PDF">pdf</a>, <a href="/ps/2311.15809" title="Download PostScript">ps</a>, <a href="/format/2311.15809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From deepfake to deep useful: risks and opportunities through a  systematic literature review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Misirlis%2C+N">Nikolaos Misirlis</a>, 
<a href="/search/cs?searchtype=author&query=Munawar%2C+H+B">Harris Bin Munawar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, IADIS International Conference e-Society (2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Deepfake videos are defined as a resulting media from the synthesis of
different persons images and videos, mostly faces, replacing a real one. The
easy spread of such videos leads to elevated misinformation and represents a
threat to society and democracy today. The present study aims to collect and
analyze the relevant literature through a systematic procedure. We present 27
articles from scientific databases revealing threats to society, democracies,
the political life but present as well advantages of this technology in
entertainment, gaming, education, and public life. The research indicates high
scientific interest in deepfake detection algorithms as well as the ethical
aspect of such technology. This article covers the scientific gap since, to the
best of our knowledge, this is the first systematic literature review in the
field. A discussion has already started among academics and practitioners
concerning the spread of fake news. The next step of fake news considers the
use of artificial intelligence and machine learning algorithms that create
hyper-realistic videos, called deepfake. Deepfake technology has continuously
attracted the attention of scholars over the last 3 years more and more. The
importance of conducting research in this field derives from the necessity to
understand the theory. The first contextual approach is related to the
epistemological points of view of the concept. The second one is related to the
phenomenological disadvantages of the field. Despite that, the authors will try
to focus not only on the disadvantages of the field but also on the positive
aspects of the technology.
</p>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15810" title="Abstract">arXiv:2311.15810</a> [<a href="/pdf/2311.15810" title="Download PDF">pdf</a>, <a href="/format/2311.15810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tascade: Hardware Support for Atomic-free, Asynchronous and Efficient  Reduction Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Orenes-Vera%2C+M">Marcelo Orenes-Vera</a>, 
<a href="/search/cs?searchtype=author&query=Tureci%2C+E">Esin Tureci</a>, 
<a href="/search/cs?searchtype=author&query=Wentzlaff%2C+D">David Wentzlaff</a>, 
<a href="/search/cs?searchtype=author&query=Martonosi%2C+M">Margaret Martonosi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">As system parallelism at chip- and server-level increases, challenges that
arose with network-level systems a decade ago, are now being encountered with
these massively parallel systems that have become an important workhorse for
Machine Learning workloads as well as Graph and Sparse workloads. To tackle the
communication bottlenecks, recent works have introduced task-based
parallelization schemes to accelerate graph search and sparse data-structure
traversal, where some solutions scale up to thousands of processing units (PUs)
on a single chip. However, existing communication schemes do not scale to
larger than thousands of processing tiles. To address these challenges we
propose Tascade, a system that offers hardware-supported, efficient and
balanced reduction trees to reduce communication overheads in task-based
parallelization schemes and scales up to a million PUs. Tascade achieves this
by implementing an execution model utilizing proxy regions and cascading
updates, along with a supporting hardware design that enables the execution of
the reduction tree at the chip level. The Tascade approach reduces overall
communication and improves load balancing. We evaluate six applications and
four datasets to provide a detailed analysis of Tascade's performance, power,
and traffic-reduction gains over prior work. Our parallelization of
Breadth-First-Search with RMAT-26 across a million PUs, the largest of the
literature, reaches 5305 GTEPS.
</p>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15812" title="Abstract">arXiv:2311.15812</a> [<a href="/pdf/2311.15812" title="Download PDF">pdf</a>, <a href="/format/2311.15812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> C-SAW: Self-Supervised Prompt Learning for Image Generalization in  Remote Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+A">Avigyan Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Singha%2C+M">Mainak Singha</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+A">Ankit Jha</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+B">Biplab Banerjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ACM ICVGIP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We focus on domain and class generalization problems in analyzing optical
remote sensing images, using the large-scale pre-trained vision-language model
(VLM), CLIP. While contrastively trained VLMs show impressive zero-shot
generalization performance, their effectiveness is limited when dealing with
diverse domains during training and testing. Existing prompt learning
techniques overlook the importance of incorporating domain and content
information into the prompts, which results in a drop in performance while
dealing with such multi-domain data. To address these challenges, we propose a
solution that ensures domain-invariant prompt learning while enhancing the
expressiveness of visual features. We observe that CLIP's vision encoder
struggles to identify contextual image information, particularly when image
patches are jumbled up. This issue is especially severe in optical remote
sensing images, where land-cover classes exhibit well-defined contextual
appearances. To this end, we introduce C-SAW, a method that complements CLIP
with a self-supervised loss in the visual space and a novel prompt learning
technique that emphasizes both visual domain and content-specific features. We
keep the CLIP backbone frozen and introduce a small set of projectors for both
the CLIP encoders to train C-SAW contrastively. Experimental results
demonstrate the superiority of C-SAW across multiple remote sensing benchmarks
and different generalization tasks.
</p>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15813" title="Abstract">arXiv:2311.15813</a> [<a href="/pdf/2311.15813" title="Download PDF">pdf</a>, <a href="/format/2311.15813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlowZero: Zero-Shot Text-to-Video Synthesis with LLM-Driven Dynamic  Scene Syntax
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Linchao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Hehe Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://flowzero-video.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Text-to-video (T2V) generation is a rapidly growing research area that aims
to translate the scenes, objects, and actions within complex video text into a
sequence of coherent visual frames. We present FlowZero, a novel framework that
combines Large Language Models (LLMs) with image diffusion models to generate
temporally-coherent videos. FlowZero uses LLMs to understand complex
spatio-temporal dynamics from text, where LLMs can generate a comprehensive
dynamic scene syntax (DSS) containing scene descriptions, object layouts, and
background motion patterns. These elements in DSS are then used to guide the
image diffusion model for video generation with smooth object motions and
frame-to-frame coherence. Moreover, FlowZero incorporates an iterative
self-refinement process, enhancing the alignment between the spatio-temporal
layouts and the textual prompts for the videos. To enhance global coherence, we
propose enriching the initial noise of each frame with motion dynamics to
control the background movement and camera motion adaptively. By using
spatio-temporal syntaxes to guide the diffusion process, FlowZero achieves
improvement in zero-shot video synthesis, generating coherent videos with vivid
motion.
</p>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15816" title="Abstract">arXiv:2311.15816</a> [<a href="/pdf/2311.15816" title="Download PDF">pdf</a>, <a href="/format/2311.15816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scale-Dropout: Estimating Uncertainty in Deep Neural Networks Using  Stochastic Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S+T">Soyed Tuhin Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Danouchi%2C+K">Kamal Danouchi</a>, 
<a href="/search/cs?searchtype=author&query=Hefenbrock%2C+M">Michael Hefenbrock</a>, 
<a href="/search/cs?searchtype=author&query=Prenat%2C+G">Guillaume Prenat</a>, 
<a href="/search/cs?searchtype=author&query=Anghel%2C+L">Lorena Anghel</a>, 
<a href="/search/cs?searchtype=author&query=Tahoori%2C+M+B">Mehdi B. Tahoori</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Uncertainty estimation in Neural Networks (NNs) is vital in improving
reliability and confidence in predictions, particularly in safety-critical
applications. Bayesian Neural Networks (BayNNs) with Dropout as an
approximation offer a systematic approach to quantifying uncertainty, but they
inherently suffer from high hardware overhead in terms of power, memory, and
computation. Thus, the applicability of BayNNs to edge devices with limited
resources or to high-performance applications is challenging. Some of the
inherent costs of BayNNs can be reduced by accelerating them in hardware on a
Computation-In-Memory (CIM) architecture with spintronic memories and
binarizing their parameters. However, numerous stochastic units are required to
implement conventional dropout-based BayNN. In this paper, we propose the Scale
Dropout, a novel regularization technique for Binary Neural Networks (BNNs),
and Monte Carlo-Scale Dropout (MC-Scale Dropout)-based BayNNs for efficient
uncertainty estimation. Our approach requires only one stochastic unit for the
entire model, irrespective of the model size, leading to a highly scalable
Bayesian NN. Furthermore, we introduce a novel Spintronic memory-based CIM
architecture for the proposed BayNN that achieves more than $100\times$ energy
savings compared to the state-of-the-art. We validated our method to show up to
a $1\%$ improvement in predictive performance and superior uncertainty
estimates compared to related works.
</p>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15826" title="Abstract">arXiv:2311.15826</a> [<a href="/pdf/2311.15826" title="Download PDF">pdf</a>, <a href="/format/2311.15826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GeoChat: Grounded Large Vision-Language Model for Remote Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuckreja%2C+K">Kartik Kuckreja</a>, 
<a href="/search/cs?searchtype=author&query=Danish%2C+M+S">Muhammad Sohail Danish</a>, 
<a href="/search/cs?searchtype=author&query=Naseer%2C+M">Muzammal Naseer</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Abhijit Das</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Salman Khan</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+F+S">Fahad Shahbaz Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent advancements in Large Vision-Language Models (VLMs) have shown great
promise in natural image domains, allowing users to hold a dialogue about given
visual content. However, such general-domain VLMs perform poorly for Remote
Sensing (RS) scenarios, leading to inaccurate or fabricated information when
presented with RS domain-specific queries. Such a behavior emerges due to the
unique challenges introduced by RS imagery. For example, to handle
high-resolution RS imagery with diverse scale changes across categories and
many small objects, region-level reasoning is necessary alongside holistic
scene interpretation. Furthermore, the lack of domain-specific multimodal
instruction following data as well as strong backbone models for RS make it
hard for the models to align their behavior with user queries. To address these
limitations, we propose GeoChat - the first versatile remote sensing VLM that
offers multitask conversational capabilities with high-resolution RS images.
Specifically, GeoChat can not only answer image-level queries but also accepts
region inputs to hold region-specific dialogue. Furthermore, it can visually
ground objects in its responses by referring to their spatial coordinates. To
address the lack of domain-specific datasets, we generate a novel RS multimodal
instruction-following dataset by extending image-text pairs from existing
diverse RS datasets. We establish a comprehensive benchmark for RS multitask
conversations and compare with a number of baseline methods. GeoChat
demonstrates robust zero-shot performance on various RS tasks, e.g., image and
region captioning, visual question answering, scene classification, visually
grounded conversations and referring detection. Our code is available at
https://github.com/mbzuai-oryx/geochat.
</p>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15827" title="Abstract">arXiv:2311.15827</a> [<a href="/pdf/2311.15827" title="Download PDF">pdf</a>, <a href="/format/2311.15827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient iterative methods for hyperparameter estimation in large-scale  linear inverse problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hall-Hooper%2C+K+A">Khalil A Hall-Hooper</a>, 
<a href="/search/math?searchtype=author&query=Saibaba%2C+A+K">Arvind K Saibaba</a>, 
<a href="/search/math?searchtype=author&query=Chung%2C+J">Julianne Chung</a>, 
<a href="/search/math?searchtype=author&query=Miller%2C+S+M">Scot M Miller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We study Bayesian methods for large-scale linear inverse problems, focusing
on the challenging task of hyperparameter estimation. Typical hierarchical
Bayesian formulations that follow a Markov Chain Monte Carlo approach are
possible for small problems with very few hyperparameters but are not
computationally feasible for problems with a very large number of unknown
parameters. In this work, we describe an empirical Bayesian (EB) method to
estimate hyperparameters that maximize the marginal posterior, i.e., the
probability density of the hyperparameters conditioned on the data, and then we
use the estimated values to compute the posterior of the inverse parameters.
For problems where the computation of the square root and inverse of prior
covariance matrices are not feasible, we describe an approach based on the
generalized Golub-Kahan bidiagonalization to approximate the marginal posterior
and seek hyperparameters that minimize the approximate marginal posterior.
Numerical results from seismic and atmospheric tomography demonstrate the
accuracy, robustness, and potential benefits of the proposed approach.
</p>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15830" title="Abstract">arXiv:2311.15830</a> [<a href="/pdf/2311.15830" title="Download PDF">pdf</a>, <a href="/format/2311.15830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A-JEPA: Joint-Embedding Predictive Architecture Can Listen
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fei%2C+Z">Zhengcong Fei</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+M">Mingyuan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Junshi Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This paper presents that the masked-modeling principle driving the success of
large foundational vision models can be effectively applied to audio by making
predictions in a latent space. We introduce Audio-based Joint-Embedding
Predictive Architecture (A-JEPA), a simple extension method for self-supervised
learning from the audio spectrum. Following the design of I-JPEA, our A-JEPA
encodes visible audio spectrogram patches with a curriculum masking strategy
via context encoder, and predicts the representations of regions sampled at
well-designed locations. The target representations of those regions are
extracted by the exponential moving average of context encoder, \emph{i.e.},
target encoder, on the whole spectrogram. We find it beneficial to transfer
random block masking into time-frequency aware masking in a curriculum manner,
considering the complexity of highly correlated in local time and frequency in
audio spectrograms. To enhance contextual semantic understanding and
robustness, we fine-tune the encoder with a regularized masking on target
datasets, instead of input dropping or zero. Empirically, when built with
Vision Transformers structure, we find A-JEPA to be highly scalable and sets
new state-of-the-art performance on multiple audio and speech classification
tasks, outperforming other recent models that use externally supervised
pre-training.
</p>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15831" title="Abstract">arXiv:2311.15831</a> [<a href="/pdf/2311.15831" title="Download PDF">pdf</a>, <a href="/format/2311.15831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Action Localization for Inertial-based Human Activity  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bock%2C+M">Marius Bock</a>, 
<a href="/search/cs?searchtype=author&query=Moeller%2C+M">Michael Moeller</a>, 
<a href="/search/cs?searchtype=author&query=Van+Laerhoven%2C+K">Kristof Van Laerhoven</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 7 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC); Signal Processing (eess.SP)

</div>
<p class="mathjax">A persistent trend in Deep Learning has been the applicability of machine
learning concepts to other areas than originally introduced for. As of today,
state-of-the-art activity recognition from wearable sensors relies on
classifiers being trained on fixed windows of data. Contrarily, video-based
Human Activity Recognition has followed a segment-based prediction approach,
localizing activity occurrences from start to end. This paper is the first to
systematically demonstrate the applicability of state-of-the-art TAL models for
wearable Human Activity Recongition (HAR) using raw inertial data as input. Our
results show that state-of-the-art TAL models are able to outperform popular
inertial models on 4 out of 6 wearable activity recognition benchmark datasets,
with improvements ranging as much as 25% in F1-score. Introducing the TAL
community's most popular metric to inertial-based HAR, namely mean Average
Precision, our analysis shows that TAL models are able to produce more coherent
segments along with an overall higher NULL-class accuracy across all datasets.
Being the first to provide such an analysis, the TAL community offers an
interesting new perspective to inertial-based HAR with yet to be explored
design choices and training concepts, which could be of significant value for
the inertial-based HAR community.
</p>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15832" title="Abstract">arXiv:2311.15832</a> [<a href="/pdf/2311.15832" title="Download PDF">pdf</a>, <a href="/format/2311.15832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attacking at non-harmonic frequencies in screaming-channel attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guillaume%2C+J">Jeremy Guillaume</a>, 
<a href="/search/cs?searchtype=author&query=Pelcat%2C+M">Maxime Pelcat</a>, 
<a href="/search/cs?searchtype=author&query=Nafkha%2C+A">Amor Nafkha</a>, 
<a href="/search/cs?searchtype=author&query=Salvador%2C+R">Ruben Salvador</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22nd Smart Card Research and Advanced Application Conference (CARDIS 2023). This preprint has not undergone peer review or any post-submission improvements or corrections. 20 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Screaming-channel attacks enable Electromagnetic (EM) Side-Channel Attacks
(SCAs) at larger distances due to higher EM leakage energies than traditional
SCAs, relaxing the requirement of close access to the victim. This attack can
be mounted on devices integrating Radio Frequency (RF) modules on the same die
as digital circuits, where the RF can unintentionally capture, modulate,
amplify, and transmit the leakage along with legitimate signals. Leakage
results from digital switching activity, so the hypothesis of previous works
was that this leakage would appear at multiples of the digital clock frequency,
i.e., harmonics. This work demonstrates that compromising signals appear not
only at the harmonics and that leakage at non-harmonics can be exploited for
successful attacks. Indeed, the transformations undergone by the leaked signal
are complex due to propagation effects through the substrate and power and
ground planes, so the leakage also appears at other frequencies. We first
propose two methodologies to locate frequencies that contain leakage and
demonstrate that it appears at non-harmonic frequencies. Then, our experimental
results show that screaming-channel attacks at non-harmonic frequencies can be
as successful as at harmonics when retrieving a 16-byte AES key. As the RF
spectrum is polluted by interfering signals, we run experiments and show
successful attacks in a more realistic, noisy environment where harmonic
frequencies are contaminated by multi-path fading and interference. These
attacks at non-harmonic frequencies increase the attack surface by providing
attackers with an increased number of potential frequencies where attacks can
succeed.
</p>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15836" title="Abstract">arXiv:2311.15836</a> [<a href="/pdf/2311.15836" title="Download PDF">pdf</a>, <a href="/format/2311.15836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Syn3DWound: A Synthetic Dataset for 3D Wound Bed Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lebrat%2C+L">L&#xe9;o Lebrat</a>, 
<a href="/search/cs?searchtype=author&query=Cruz%2C+R+S">Rodrigo Santa Cruz</a>, 
<a href="/search/cs?searchtype=author&query=Chierchia%2C+R">Remi Chierchia</a>, 
<a href="/search/cs?searchtype=author&query=Arzhaeva%2C+Y">Yulia Arzhaeva</a>, 
<a href="/search/cs?searchtype=author&query=Armin%2C+M+A">Mohammad Ali Armin</a>, 
<a href="/search/cs?searchtype=author&query=Goldsmith%2C+J">Joshua Goldsmith</a>, 
<a href="/search/cs?searchtype=author&query=Oorloff%2C+J">Jeremy Oorloff</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+P">Prithvi Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+C">Chuong Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Petersson%2C+L">Lars Petersson</a>, 
<a href="/search/cs?searchtype=author&query=Barakat-Johnson%2C+M">Michelle Barakat-Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Luscombe%2C+G">Georgina Luscombe</a>, 
<a href="/search/cs?searchtype=author&query=Fookes%2C+C">Clinton Fookes</a>, 
<a href="/search/cs?searchtype=author&query=Salvado%2C+O">Olivier Salvado</a>, 
<a href="/search/cs?searchtype=author&query=Ahmedt-Aristizabal%2C+D">David Ahmedt-Aristizabal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Wound management poses a significant challenge, particularly for bedridden
patients and the elderly. Accurate diagnostic and healing monitoring can
significantly benefit from modern image analysis, providing accurate and
precise measurements of wounds. Despite several existing techniques, the
shortage of expansive and diverse training datasets remains a significant
obstacle to constructing machine learning-based frameworks. This paper
introduces Syn3DWound, an open-source dataset of high-fidelity simulated wounds
with 2D and 3D annotations. We propose baseline methods and a benchmarking
framework for automated 3D morphometry analysis and 2D/3D wound segmentation.
</p>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15838" title="Abstract">arXiv:2311.15838</a> [<a href="/pdf/2311.15838" title="Download PDF">pdf</a>, <a href="/format/2311.15838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utilizing Explainability Techniques for Reinforcement Learning Model  Assurance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tapley%2C+A">Alexander Tapley</a>, 
<a href="/search/cs?searchtype=author&query=Gatesman%2C+K">Kyle Gatesman</a>, 
<a href="/search/cs?searchtype=author&query=Robaina%2C+L">Luis Robaina</a>, 
<a href="/search/cs?searchtype=author&query=Bissey%2C+B">Brett Bissey</a>, 
<a href="/search/cs?searchtype=author&query=Weissman%2C+J">Joseph Weissman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures including appendices (A, B, C). Accepted as a poster presentation in the demo track at the "XAI in Action: Past, Present, and Future Applications" workshop at NeurIPS 2023. MITRE Public Release Case Number 23-3095
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Explainable Reinforcement Learning (XRL) can provide transparency into the
decision-making process of a Deep Reinforcement Learning (DRL) model and
increase user trust and adoption in real-world use cases. By utilizing XRL
techniques, researchers can identify potential vulnerabilities within a trained
DRL model prior to deployment, therefore limiting the potential for mission
failure or mistakes by the system. This paper introduces the ARLIN (Assured RL
Model Interrogation) Toolkit, an open-source Python library that identifies
potential vulnerabilities and critical points within trained DRL models through
detailed, human-interpretable explainability outputs. To illustrate ARLIN's
effectiveness, we provide explainability visualizations and vulnerability
analysis for a publicly available DRL model. The open-source code repository is
available for download at https://github.com/mitre/arlin.
</p>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15839" title="Abstract">arXiv:2311.15839</a> [<a href="/pdf/2311.15839" title="Download PDF">pdf</a>, <a href="/format/2311.15839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ontologising Trustworthy in the Telecommunications Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oliver%2C+I">Ian Oliver</a>, 
<a href="/search/cs?searchtype=author&query=Kuure%2C+P">Pekka Kuure</a>, 
<a href="/search/cs?searchtype=author&query=Sedkowski%2C+W">Wiktor Sedkowski</a>, 
<a href="/search/cs?searchtype=author&query=Sommer%2C+T">Thore Sommer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Based upon trusted and confidential computing platforms, telecommunications
systems must provide guaranteed security for the processes and data running
atop them. This in turn requires us to provide trustworthy systems. The term
trustworthy is poorly defined with corresponding misunderstanding and
misapplication. We present a definition of this term, as well as others,
demonstrate its application against certain telecommunications use cases and
address how the learnings from ontologising these structures contribute to
standardisation and the necessity for FAIR ontologies across telecommunications
standards and hosting organisations.
</p>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15841" title="Abstract">arXiv:2311.15841</a> [<a href="/pdf/2311.15841" title="Download PDF">pdf</a>, <a href="/format/2311.15841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Disentangled Identifiers for Action-Customized Text-to-Image  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Siteng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+B">Biao Gong</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yutong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yuqian Fu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Donglin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This study focuses on a novel task in text-to-image (T2I) generation, namely
action customization. The objective of this task is to learn the co-existing
action from limited data and generalize it to unseen humans or even animals.
Experimental results show that existing subject-driven customization methods
fail to learn the representative characteristics of actions and struggle in
decoupling actions from context features, including appearance. To overcome the
preference for low-level features and the entanglement of high-level features,
we propose an inversion-based method Action-Disentangled Identifier (ADI) to
learn action-specific identifiers from the exemplar images. ADI first expands
the semantic conditioning space by introducing layer-wise identifier tokens,
thereby increasing the representational richness while distributing the
inversion across different features. Then, to block the inversion of
action-agnostic features, ADI extracts the gradient invariance from the
constructed sample triples and masks the updates of irrelevant channels. To
comprehensively evaluate the task, we present an ActionBench that includes a
variety of actions, each accompanied by meticulously selected samples. Both
quantitative and qualitative results show that our ADI outperforms existing
baselines in action-customized T2I generation.
</p>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15842" title="Abstract">arXiv:2311.15842</a> [<a href="/pdf/2311.15842" title="Download PDF">pdf</a>, <a href="/format/2311.15842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IPv6 Bitcoin-Certified Addresses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ducroux%2C+M">Mathieu Ducroux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures, 3 tables, to be published in 2023 IEEE Future Networks World Forum (FNWF)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">A pivotal feature of IPv6 is its plug-and-play capability that enables hosts
to integrate seamlessly into networks. In the absence of a trusted authority or
security infrastructure, the challenge for hosts is generating their own
address and verifying ownership of others. Cryptographically Generated
Addresses (CGA) solves this problem by binding IPv6 addresses to hosts' public
keys to prove address ownership. CGA generation involves solving a
cryptographic puzzle similar to Bitcoin's Proof-of-Work (PoW) to deter address
spoofing. Unfortunately, solving the puzzle often causes undesirable address
generation delays, which has hindered the adoption of CGA. In this paper, we
present Bitcoin-Certified Addresses (BCA), a new technique to bind IPv6
addresses to hosts' public keys. BCA reduces the computational cost of
generating addresses by using the PoW computed by Bitcoin nodes to secure the
binding. Compared to CGA, BCA provides better protection against spoofing
attacks and improves the privacy of hosts. Due to the decentralized nature of
the Bitcoin network, BCA avoids reliance on a trusted authority, similar to
CGA. BCA shows how the PoW computed by Bitcoin nodes can be reused, which saves
costs for hosts and makes Bitcoin mining more efficient.
</p>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15843" title="Abstract">arXiv:2311.15843</a> [<a href="/pdf/2311.15843" title="Download PDF">pdf</a>, <a href="/format/2311.15843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust observer-based control with modularity and exponential stability  for interconnected systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Heydarishahna%2C+M">Mehdi Heydarishahna</a>, 
<a href="/search/eess?searchtype=author&query=Bahari%2C+M">Mohammad Bahari</a>, 
<a href="/search/eess?searchtype=author&query=Mattila%2C+J">Jouni Mattila</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted by possible publication in the ELSEVIER
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This article introduces a modular robust subsystem-based adaptive (RSBA)
control design with a new stability analysis for a class of uncertain
interconnected systems with unknown modeling errors and interactions. First, we
propose a nonlinear state observer for this class of systems that ensures
uniformly exponential convergence of the estimation error by utilizing a new
adaptive term, extending the conventional continuous Luenberger concept.
Second, we introduce a novel adaptive subsystem-based control strategy for
trajectory tracking, which incorporates an interesting term called the
"stability connector", designed to capture dynamic interactions among
subsystems during stability analysis, preventing excessive complexity as the
system order increases. This represents the first instance of this term
allowing modular control with exponential and uniform convergence rates,
effectively handling unknown non-triangular nonlinearities. In addition to
rigorous theoretical proofs by the Lyapunov theory, two complex systems are
explored in simulations to confirm the merits of the suggested control schemes.
</p>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15846" title="Abstract">arXiv:2311.15846</a> [<a href="/pdf/2311.15846" title="Download PDF">pdf</a>, <a href="/format/2311.15846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning with Noisy Low-Cost MOS for Image Quality Assessment via  Dual-Bias Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingbo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+D">Desen Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ngan%2C+K+N">King Ngi Ngan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fanman Meng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Linfeng Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Learning based image quality assessment (IQA) models have obtained impressive
performance with the help of reliable subjective quality labels, where mean
opinion score (MOS) is the most popular choice. However, in view of the
subjective bias of individual annotators, the labor-abundant MOS (LA-MOS)
typically requires a large collection of opinion scores from multiple
annotators for each image, which significantly increases the learning cost. In
this paper, we aim to learn robust IQA models from low-cost MOS (LC-MOS), which
only requires very few opinion scores or even a single opinion score for each
image. More specifically, we consider the LC-MOS as the noisy observation of
LA-MOS and enforce the IQA model learned from LC-MOS to approach the unbiased
estimation of LA-MOS. In this way, we represent the subjective bias between
LC-MOS and LA-MOS, and the model bias between IQA predictions learned from
LC-MOS and LA-MOS (i.e., dual-bias) as two latent variables with unknown
parameters. By means of the expectation-maximization based alternating
optimization, we can jointly estimate the parameters of the dual-bias, which
suppresses the misleading of LC-MOS via a gated dual-bias calibration (GDBC)
module. To the best of our knowledge, this is the first exploration of robust
IQA model learning from noisy low-cost labels. Theoretical analysis and
extensive experiments on four popular IQA datasets show that the proposed
method is robust toward different bias rates and annotation numbers and
significantly outperforms the other learning based IQA models when only LC-MOS
is available. Furthermore, we also achieve comparable performance with respect
to the other models learned with LA-MOS.
</p>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15851" title="Abstract">arXiv:2311.15851</a> [<a href="/pdf/2311.15851" title="Download PDF">pdf</a>, <a href="/format/2311.15851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-Model and Any-Modality for Video Object Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zongwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jilai Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiangxuan Ren</a>, 
<a href="/search/cs?searchtype=author&query=Vasluianu%2C+F">Florin-Alexandru Vasluianu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Paudel%2C+D+P">Danda Pani Paudel</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>, 
<a href="/search/cs?searchtype=author&query=Timofte%2C+R">Radu Timofte</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the realm of video object tracking, auxiliary modalities such as depth,
thermal, or event data have emerged as valuable assets to complement the RGB
trackers. In practice, most existing RGB trackers learn a single set of
parameters to use them across datasets and applications. However, a similar
single-model unification for multi-modality tracking presents several
challenges. These challenges stem from the inherent heterogeneity of inputs --
each with modality-specific representations, the scarcity of multi-modal
datasets, and the absence of all the modalities at all times. In this work, we
introduce Un-Track, a \underline{Un}ified Tracker of a single set of parameters
for any modality. To handle any modality, our method learns their common latent
space through low-rank factorization and reconstruction techniques. More
importantly, we use only the RGB-X pairs to learn the common latent space. This
unique shared representation seamlessly binds all modalities together, enabling
effective unification and accommodating any missing modality, all within a
single transformer-based architecture and without the need for
modality-specific fine-tuning. Our Un-Track achieves +8.1 absolute F-score
gain, on the DepthTrack dataset, by introducing only +2.14 (over 21.50) GFLOPs
with +6.6M (over 93M) parameters, through a simple yet efficient prompting
strategy. Extensive comparisons on five benchmark datasets with different
modalities show that Un-Track surpasses both SOTA unified trackers and
modality-specific finetuned counterparts, validating our effectiveness and
practicality.
</p>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15852" title="Abstract">arXiv:2311.15852</a> [<a href="/pdf/2311.15852" title="Download PDF">pdf</a>, <a href="/format/2311.15852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exponential Auto-Tuning Fault-Tolerant Control of N Degrees-of-Freedom  Manipulators Subject to Torque Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shahna%2C+M+H">Mehdi Heydari Shahna</a>, 
<a href="/search/cs?searchtype=author&query=Mattila%2C+J">Jouni Mattila</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted for possible publication in the IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper presents a novel auto-tuning subsystem-based fault-tolerant
control (SBFC) system designed for robot manipulator systems with n degrees of
freedom. It first employs an actuator fault model to account for various faults
that may occur, and second, a mathematical saturation function is incorporated
to address torque constraints. Subsequently, a novel robust subsystem-based
adaptive control method is proposed to direct system states to follow desired
trajectories closely in the presence of input constraints, unknown modeling
errors, and actuator faults, which are primary considerations of the proposed
system. This ensures uniform exponential stability and sustained performance.
In addition, optimal values are identified by tuning the SBFC gains and
customizing the JAYA algorithm (JA), a high-performance swarm intelligence
technique. Theoretical assertions are validated through the presentation of
simulation outcomes.
</p>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15854" title="Abstract">arXiv:2311.15854</a> [<a href="/pdf/2311.15854" title="Download PDF">pdf</a>, <a href="/format/2311.15854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A systematic study comparing hyperparameter optimization engines on  tabular data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kegl%2C+B">Balazs Kegl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We run an independent comparison of all hyperparameter optimization
(hyperopt) engines available in the Ray Tune library. We introduce two ways to
normalize and aggregate statistics across data sets and models, one rank-based,
and another one sandwiching the score between the random search score and the
full grid search score. This affords us i) to rank the hyperopt engines, ii) to
make generalized and statistically significant statements on how much they
improve over random search, and iii) to make recommendations on which engine
should be used to hyperopt a given learning algorithm. We find that most
engines beat random search, but that only three of them (HEBO, AX, and
BlendSearch) clearly stand out. We also found that some engines seem to
specialize in hyperopting certain learning algorithms, which makes it tricky to
use hyperopt in comparison studies, since the choice of the hyperopt technique
may favor some of the models in the comparison.
</p>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15855" title="Abstract">arXiv:2311.15855</a> [<a href="/pdf/2311.15855" title="Download PDF">pdf</a>, <a href="/format/2311.15855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SiTH: Single-view Textured Human Reconstruction with Image-Conditioned  Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ho%2C+H">Hsuan-I Ho</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jie Song</a>, 
<a href="/search/cs?searchtype=author&query=Hilliges%2C+O">Otmar Hilliges</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">A long-standing goal of 3D human reconstruction is to create lifelike and
fully detailed 3D humans from single images. The main challenge lies in
inferring unknown human shapes, clothing, and texture information in areas not
visible in the images. To address this, we propose SiTH, a novel pipeline that
uniquely integrates an image-conditioned diffusion model into a 3D mesh
reconstruction workflow. At the core of our method lies the decomposition of
the ill-posed single-view reconstruction problem into hallucination and
reconstruction subproblems. For the former, we employ a powerful generative
diffusion model to hallucinate back appearances from the input images. For the
latter, we leverage skinned body meshes as guidance to recover full-body
texture meshes from the input and back-view images. Our designs enable training
of the pipeline with only about 500 3D human scans while maintaining its
generality and robustness. Extensive experiments and user studies on two 3D
reconstruction benchmarks demonstrated the efficacy of our method in generating
realistic, fully textured 3D humans from a diverse range of unseen images.
</p>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15858" title="Abstract">arXiv:2311.15858</a> [<a href="/pdf/2311.15858" title="Download PDF">pdf</a>, <a href="/format/2311.15858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Reinforcement Learning for Power Control in Wireless  Networks via Adaptive Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amorosa%2C+L+M">Lorenzo Mario Amorosa</a>, 
<a href="/search/cs?searchtype=author&query=Skocaj%2C+M">Marco Skocaj</a>, 
<a href="/search/cs?searchtype=author&query=Verdone%2C+R">Roberto Verdone</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCnd%C3%BCz%2C+D">Deniz G&#xfc;nd&#xfc;z</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">The ever-increasing demand for high-quality and heterogeneous wireless
communication services has driven extensive research on dynamic optimization
strategies in wireless networks. Among several possible approaches, multi-agent
deep reinforcement learning (MADRL) has emerged as a promising method to
address a wide range of complex optimization problems like power control.
However, the seamless application of MADRL to a variety of network optimization
problems faces several challenges related to convergence. In this paper, we
present the use of graphs as communication-inducing structures among
distributed agents as an effective means to mitigate these challenges.
Specifically, we harness graph neural networks (GNNs) as neural architectures
for policy parameterization to introduce a relational inductive bias in the
collective decision-making process. Most importantly, we focus on modeling the
dynamic interactions among sets of neighboring agents through the introduction
of innovative methods for defining a graph-induced framework for integrated
communication and learning. Finally, the superior generalization capabilities
of the proposed methodology to larger networks and to networks with different
user categories is verified through simulations.
</p>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15864" title="Abstract">arXiv:2311.15864</a> [<a href="/pdf/2311.15864" title="Download PDF">pdf</a>, <a href="/format/2311.15864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InterControl: Generate Human Motion Interactions by Controlling Every  Joint
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhenzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingbo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bo Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Generate human interactions with only single-person motion diffusion model via LLM generated joint contact pairs, code <a href="https://github.com/zhenzhiwang/intercontrol">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-conditioned human motion generation model has achieved great progress by
introducing diffusion models and corresponding control signals. However, the
interaction between humans are still under explored. To model interactions of
arbitrary number of humans, we define interactions as human joint pairs that
are either in contact or separated, and leverage {\em Large Language Model
(LLM) Planner} to translate interaction descriptions into contact plans. Based
on the contact plans, interaction generation could be achieved by spatially
controllable motion generation methods by taking joint contacts as spatial
conditions. We present a novel approach named InterControl for flexible spatial
control of every joint in every person at any time by leveraging motion
diffusion model only trained on single-person data. We incorporate a motion
controlnet to generate coherent and realistic motions given sparse spatial
control signals and a loss guidance module to precisely align any joint to the
desired position in a classifier guidance manner via Inverse Kinematics (IK).
Extensive experiments on HumanML3D and KIT-ML dataset demonstrate its
effectiveness in versatile joint control. We also collect data of joint contact
pairs by LLMs to show InterControl's ability in human interaction generation.
</p>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15868" title="Abstract">arXiv:2311.15868</a> [<a href="/pdf/2311.15868" title="Download PDF">pdf</a>, <a href="/ps/2311.15868" title="Download PostScript">ps</a>, <a href="/format/2311.15868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning with Errors over Group Rings Constructed by Semi-direct Product
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+F">Fang-Wei Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">The Learning with Errors (LWE) problem has been widely utilized as a
foundation for numerous cryptographic tools over the years. In this study, we
focus on an algebraic variant of the LWE problem called Group ring LWE
(GR-LWE). We select group rings (or their direct summands) that underlie
specific families of finite groups constructed by taking the semi-direct
product of two cyclic groups. Unlike the Ring-LWE problem described in
\cite{lyubashevsky2010ideal}, the multiplication operation in the group rings
considered here is non-commutative. As an extension of Ring-LWE, it maintains
computational hardness and can be potentially applied in many cryptographic
scenarios. In this paper, we present two polynomial-time quantum reductions.
Firstly, we provide a quantum reduction from the worst-case shortest
independent vectors problem (SIVP) in ideal lattices with polynomial
approximate factor to the search version of GR-LWE. This reduction requires
that the underlying group ring possesses certain mild properties; Secondly, we
present another quantum reduction for two types of group rings, where the
worst-case SIVP problem is directly reduced to the (average-case) decision
GR-LWE problem. The pseudorandomness of GR-LWE samples guaranteed by this
reduction can be consequently leveraged to construct semantically secure
public-key cryptosystems.
</p>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15875" title="Abstract">arXiv:2311.15875</a> [<a href="/pdf/2311.15875" title="Download PDF">pdf</a>, <a href="/format/2311.15875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nodal Hydraulic Head Estimation through Unscented Kalman Filter for  Data-driven Leak Localization in Water Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Romero-Ben%2C+L">Luis Romero-Ben</a>, 
<a href="/search/eess?searchtype=author&query=Irofti%2C+P">Paul Irofti</a>, 
<a href="/search/eess?searchtype=author&query=Stoican%2C+F">Florin Stoican</a>, 
<a href="/search/eess?searchtype=author&query=Puig%2C+V">Vicen&#xe7; Puig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to IFAC for possible publication. It has 6 pages and 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this paper, we present a nodal hydraulic head estimation methodology for
water distribution networks (WDN) based on an Unscented Kalman Filter (UKF)
scheme with application to leak localization. The UKF refines an initial
estimation of the hydraulic state by considering the prediction model, as well
as available pressure and demand measurements. To this end, it provides
customized prediction and data assimilation steps. Additionally, the method is
enhanced by dynamically updating the prediction function weight matrices.
Performance testing on the Modena benchmark under realistic conditions
demonstrates the method's effectiveness in enhancing state estimation and
data-driven leak localization.
</p>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15876" title="Abstract">arXiv:2311.15876</a> [<a href="/pdf/2311.15876" title="Download PDF">pdf</a>, <a href="/format/2311.15876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RO-LLaMA: Generalist LLM for Radiation Oncology via Noise Augmentation  and Consistency Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kwanyoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+Y">Yujin Oh</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sangjoon Park</a>, 
<a href="/search/cs?searchtype=author&query=Byun%2C+H+K">Hwa Kyung Byun</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J+S">Jin Sung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y+B">Yong Bae Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J+C">Jong Chul Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advancements in Artificial Intelligence (AI) have profoundly
influenced medical fields, by providing tools to reduce clinical workloads.
However, most AI models are constrained to execute uni-modal tasks, in stark
contrast to the comprehensive approaches utilized by medical professionals. To
address this, here we present RO-LLaMA, a versatile generalist large language
model (LLM) tailored for the field of radiation oncology. This model seamlessly
covers a wide range of the workflow of radiation oncologists, adept at various
tasks such as clinical report summarization, radiation therapy plan suggestion,
and plan-guided therapy target volume segmentation. In particular, to maximize
the end-to-end performance, we further present a novel Consistency Embedding
Fine-Tuning (CEFTune) technique, which boosts LLM's robustness to additional
errors at the intermediates while preserving the capability of handling clean
inputs, and creatively transform this concept into LLM-driven segmentation
framework as Consistency Embedding Segmentation (CESEG). Experimental results
on multi-centre cohort sets demonstrate our proposed RO-LLaMA's promising
performance for diverse tasks with generalization capabilities.
</p>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15879" title="Abstract">arXiv:2311.15879</a> [<a href="/pdf/2311.15879" title="Download PDF">pdf</a>, <a href="/format/2311.15879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EVCap: Retrieval-Augmented Image Captioning with External Visual-Name  Memory for Open-World Comprehension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Vo%2C+D+M">Duc Minh Vo</a>, 
<a href="/search/cs?searchtype=author&query=Sugimoto%2C+A">Akihiro Sugimoto</a>, 
<a href="/search/cs?searchtype=author&query=Nakayama%2C+H">Hideki Nakayama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://jiaxuan-li.github.io/EVCap">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large language models (LLMs)-based image captioning has the capability of
describing objects not explicitly observed in training data; yet novel objects
occur frequently, necessitating the requirement of sustaining up-to-date object
knowledge for open-world comprehension. Instead of relying on large amounts of
data and scaling up network parameters, we introduce a highly effective
retrieval-augmented image captioning method that prompts LLMs with object names
retrieved from External Visual--name memory (EVCap). We build ever-changing
object knowledge memory using objects' visuals and names, enabling us to (i)
update the memory at a minimal cost and (ii) effortlessly augment LLMs with
retrieved object names utilizing a lightweight and fast-to-train model. Our
model, which was trained only on the COCO dataset, can be adapted to out-domain
data without additional fine-tuning or retraining. Our comprehensive
experiments conducted on various benchmarks and synthetic commonsense-violating
data demonstrate that EVCap, comprising solely 3.97M trainable parameters,
exhibits superior performance compared to other methods of equivalent model
size scale. Notably, it achieves competitive performance against specialist
SOTAs with an enormous number of parameters. Our code is available at
https://jiaxuan-li.github.io/EVCap.
</p>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15883" title="Abstract">arXiv:2311.15883</a> [<a href="/pdf/2311.15883" title="Download PDF">pdf</a>, <a href="/format/2311.15883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterising and Verifying the Core in Concurrent Multi-Player  Mean-Payoff Games (Full Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gutierrez%2C+J">Julian Gutierrez</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+A+W">Anthony W. Lin</a>, 
<a href="/search/cs?searchtype=author&query=Najib%2C+M">Muhammad Najib</a>, 
<a href="/search/cs?searchtype=author&query=Steeples%2C+T">Thomas Steeples</a>, 
<a href="/search/cs?searchtype=author&query=Wooldridge%2C+M">Michael Wooldridge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the full version of the paper with the same title that appears in the CSL'24 proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Formal Languages and Automata Theory (cs.FL); Logic in Computer Science (cs.LO); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Concurrent multi-player mean-payoff games are important models for systems of
agents with individual, non-dichotomous preferences. Whilst these games have
been extensively studied in terms of their equilibria in non-cooperative
settings, this paper explores an alternative solution concept: the core from
cooperative game theory. This concept is particularly relevant for cooperative
AI systems, as it enables the modelling of cooperation among agents, even when
their goals are not fully aligned. Our contribution is twofold. First, we
provide a characterisation of the core using discrete geometry techniques and
establish a necessary and sufficient condition for its non-emptiness. We then
use the characterisation to prove the existence of polynomial witnesses in the
core. Second, we use the existence of such witnesses to solve key decision
problems in rational verification and provide tight complexity bounds for the
problem of checking whether some/every equilibrium in a game satisfies a given
LTL or GR(1) specification. Our approach is general and can be adapted to
handle other specifications expressed in various fragments of LTL without
incurring additional computational costs.
</p>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15884" title="Abstract">arXiv:2311.15884</a> [<a href="/pdf/2311.15884" title="Download PDF">pdf</a>, <a href="/format/2311.15884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Elementary Quantum Recursion Schemes That Capture Quantum  Polylogarithmic Time Computability of Quantum Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yamakami%2C+T">Tomoyuki Yamakami</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> (A4, 10pt, 28 pages) This is a corrected and expanded version of the preliminary report that has appeared, under a different title, in the Proceedings of the 28th International Conference on Logic, Language, Information, and Computation (WoLLIC 2022), Ia\c{s}i, Romania, September 20--23, 2022, Lecture Notes in Computer Science, vol. 13468, pp. 88-104, Springer, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">Quantum computing has been studied over the past four decades based on two
computational models of quantum circuits and quantum Turing machines. To
capture quantum polynomial-time computability, a new recursion-theoretic
approach was taken lately by Yamakami [J. Symb. Logic 80, pp. 1546--1587, 2020]
by way of recursion schematic definitions, which constitute six initial quantum
functions and three construction schemes of composition, branching, and
multi-qubit quantum recursion. By taking a similar approach, we look into
quantum logarithmic-time computability and further explore the expressing power
of elementary schemes designed for such quantum computation. In particular, we
introduce an elementary form of the quantum recursion, called the fast quantum
recursion and formulate EQS (elementary quantum schemes) of "elementary"
quantum functions. This class EQS captures exactly quantum logarithmic-time
computability, represented by BQPOLYLOGTIME. We also demonstrate the separation
of BQPOLYLOGTIME from NLOGTIME and PPOLYLOGTIME. As a natural extension of EQS,
we further consider an algorithmic procedural scheme that implements the
well-known divide-and-conquer strategy. This divide-and-conquer scheme helps
compute the parity function but the scheme cannot be realized within our system
EQS.
</p>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15885" title="Abstract">arXiv:2311.15885</a> [<a href="/pdf/2311.15885" title="Download PDF">pdf</a>, <a href="/format/2311.15885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Quantifier Depth to Quantifier Number: Separating Structures with  $k$ Variables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vinall-Smeeth%2C+H">Harry Vinall-Smeeth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 50 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Given two $n$-element structures, $\mathcal{A}$ and $\mathcal{B}$, which can
be distinguished by a sentence of $k$-variable first-order logic
($\mathcal{L}^k$), what is the minimum $f(n)$ such that there is guaranteed to
be a sentence $\phi \in \mathcal{L}^k$ with at most $f(n)$ quantifiers, such
that $\mathcal{A} \models \phi$ but $\mathcal{B} \not \models \phi$? We will
present various results related to this question obtained by using the recently
introduced QVT games. In particular, we show that when we limit the number of
variables, there can be an exponential gap between the quantifier depth and the
quantifier number needed to separate two structures. Through the lens of this
question, we will highlight some difficulties that arise in analysing the QVT
game and some techniques which can help to overcome them. We also show, in the
setting of the existential-positive fragment, how to lift quantifier depth
lower bounds to quantifier number lower bounds. This leads to almost tight
bounds.
</p>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15887" title="Abstract">arXiv:2311.15887</a> [<a href="/pdf/2311.15887" title="Download PDF">pdf</a>, <a href="/format/2311.15887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FLASC: A Flare-Sensitive Clustering Algorithm: Extending HDBSCAN* for  Detecting Branches in Clusters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bot%2C+D+M">D. M. Bot</a>, 
<a href="/search/cs?searchtype=author&query=Peeters%2C+J">J. Peeters</a>, 
<a href="/search/cs?searchtype=author&query=Liesenborgs%2C+J">J. Liesenborgs</a>, 
<a href="/search/cs?searchtype=author&query=Aerts%2C+J">J. Aerts</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 11 figures, submitted to ACM TKDD
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Databases (cs.DB)

</div>
<p class="mathjax">We present FLASC, an algorithm for flare-sensitive clustering. Our algorithm
builds upon HDBSCAN* -- which provides high-quality density-based clustering
performance -- through a post-processing step that differentiates branches
within the detected clusters' manifold, adding a type of pattern that can be
discovered. Two variants of the algorithm are presented, which trade
computational cost for noise robustness. We show that both variants scale
similarly to HDBSCAN* in terms of computational cost and provide stable outputs
using synthetic data sets, resulting in an efficient flare-sensitive clustering
algorithm. In addition, we demonstrate the algorithm's benefit in data
exploration over HDBSCAN* clustering on two real-world data sets.
</p>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15888" title="Abstract">arXiv:2311.15888</a> [<a href="/pdf/2311.15888" title="Download PDF">pdf</a>, <a href="/format/2311.15888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Adaptive RF Fingerprint-based Authentication of IIoT devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lomba%2C+E">Emmanuel Lomba</a>, 
<a href="/search/cs?searchtype=author&query=Severino%2C+R">Ricardo Severino</a>, 
<a href="/search/cs?searchtype=author&query=Vilas%2C+A+F">Ana Fern&#xe1;ndez Vilas</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE 27th International Conference on Emerging Technologies and
  Factory Automation (ETFA), Stuttgart, Germany, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As IoT technologies mature, they are increasingly finding their way into more
sensitive domains, such as Medical and Industrial IoT, in which safety and
cyber-security are of great importance. While the number of deployed IoT
devices continues to increase exponentially, they still present severe
cyber-security vulnerabilities. Effective authentication is paramount to
support trustworthy IIoT communications, however, current solutions focus on
upper-layer identity verification or key-based cryptography which are often
inadequate to the heterogeneous IIoT environment. In this work, we present a
first step towards achieving powerful and flexible IIoT device authentication,
by leveraging AI adaptive Radio Frequency Fingerprinting technique selection
and tuning, at the PHY layer for highly accurate device authentication over
challenging RF environments.
</p>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15890" title="Abstract">arXiv:2311.15890</a> [<a href="/pdf/2311.15890" title="Download PDF">pdf</a>, <a href="/format/2311.15890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability-Informed Initialization of Neural Ordinary Differential  Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Westny%2C+T">Theodor Westny</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadi%2C+A">Arman Mohammadi</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+D">Daniel Jung</a>, 
<a href="/search/cs?searchtype=author&query=Frisk%2C+E">Erik Frisk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper addresses the training of Neural Ordinary Differential Equations
(neural ODEs), and in particular explores the interplay between numerical
integration techniques, stability regions, step size, and initialization
techniques. It is shown how the choice of integration technique implicitly
regularizes the learned model, and how the solver's corresponding stability
region affects training and prediction performance. From this analysis, a
stability-informed parameter initialization technique is introduced. The
effectiveness of the initialization method is displayed across several learning
benchmarks and industrial applications.
</p>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15894" title="Abstract">arXiv:2311.15894</a> [<a href="/pdf/2311.15894" title="Download PDF">pdf</a>, <a href="/format/2311.15894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Attacks over Federated Reinforcement Learning-enabled Cell  Sleep Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Han Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Elsayed%2C+M">Medhat Elsayed</a>, 
<a href="/search/cs?searchtype=author&query=Bavand%2C+M">Majid Bavand</a>, 
<a href="/search/cs?searchtype=author&query=Gaigalas%2C+R">Raimundas Gaigalas</a>, 
<a href="/search/cs?searchtype=author&query=Ozcan%2C+Y">Yigit Ozcan</a>, 
<a href="/search/cs?searchtype=author&query=Erol-Kantarci%2C+M">Melike Erol-Kantarci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Federated learning (FL) is particularly useful in wireless networks due to
its distributed implementation and privacy-preserving features. However, as a
distributed learning system, FL can be vulnerable to malicious attacks from
both internal and external sources. Our work aims to investigate the attack
models in a FL-enabled wireless networks. Specifically, we consider a cell
sleep control scenario, and apply federated reinforcement learning to improve
energy-efficiency. We design three attacks, namely free rider attacks,
Byzantine data poisoning attacks and backdoor attacks. The simulation results
show that the designed attacks can degrade the network performance and lead to
lower energy-efficiency. Moreover, we also explore possible ways to mitigate
the above attacks. We design a defense model called refined-Krum to defend
against attacks by enabling a secure aggregation on the global server. The
proposed refined- Krum scheme outperforms the existing Krum scheme and can
effectively prevent wireless networks from malicious attacks, improving the
system energy-efficiency performance.
</p>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15896" title="Abstract">arXiv:2311.15896</a> [<a href="/pdf/2311.15896" title="Download PDF">pdf</a>, <a href="/ps/2311.15896" title="Download PostScript">ps</a>, <a href="/format/2311.15896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Generation for Post-OCR correction of Cyrillic handwriting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Davydkin%2C+E">Evgenii Davydkin</a>, 
<a href="/search/cs?searchtype=author&query=Markelov%2C+A">Aleksandr Markelov</a>, 
<a href="/search/cs?searchtype=author&query=Iuldashev%2C+E">Egor Iuldashev</a>, 
<a href="/search/cs?searchtype=author&query=Dudkin%2C+A">Anton Dudkin</a>, 
<a href="/search/cs?searchtype=author&query=Krivorotov%2C+I">Ivan Krivorotov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 27 figures, 6 tables, 26 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">This paper introduces a novel approach to post-Optical Character Recognition
Correction (POC) for handwritten Cyrillic text, addressing a significant gap in
current research methodologies. This gap is due to the lack of large text
corporas that provide OCR errors for further training of language-based POC
models, which are demanding in terms of corpora size. Our study primarily
focuses on the development and application of a synthetic handwriting
generation engine based on B\'ezier curves. Such an engine generates highly
realistic handwritten text in any amounts, which we utilize to create a
substantial dataset by transforming Russian text corpora sourced from the
internet. We apply a Handwritten Text Recognition (HTR) model to this dataset
to identify OCR errors, forming the basis for our POC model training. The
correction model is trained on a 90-symbol input context, utilizing a
pre-trained T5 architecture with a seq2seq correction task. We evaluate our
approach on HWR200 and School_notebooks_RU datasets as they provide significant
challenges in the HTR domain. Furthermore, POC can be used to highlight errors
for teachers, evaluating student performance. This can be done simply by
comparing sentences before and after correction, displaying differences in
text. Our primary contribution lies in the innovative use of B\'ezier curves
for Cyrillic text generation and subsequent error correction using a
specialized POC model. We validate our approach by presenting Word Accuracy
Rate (WAR) and Character Accuracy Rate (CAR) results, both with and without
post-OCR correction, using real open corporas of handwritten Cyrillic text.
These results, coupled with our methodology, are designed to be reproducible,
paving the way for further advancements in the field of OCR and handwritten
text analysis. Paper contributions can be found in
https://github.com/dbrainio/CyrillicHandwritingPOC
</p>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15899" title="Abstract">arXiv:2311.15899</a> [<a href="/pdf/2311.15899" title="Download PDF">pdf</a>, <a href="/ps/2311.15899" title="Download PostScript">ps</a>, <a href="/format/2311.15899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact Methods for the Longest Induced Cycle Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anaqreh%2C+A+T">Ahmad T. Anaqreh</a>, 
<a href="/search/cs?searchtype=author&query=-T%C3%B3th%2C+B+G">Bogl&#xe1;rka G.-T&#xf3;th</a>, 
<a href="/search/cs?searchtype=author&query=Vink%C3%B3%2C+T">Tam&#xe1;s Vink&#xf3;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">The longest induced (or chordless) cycle problem is a graph problem
classified as NP-complete and involves the task of determining the largest
possible subset of vertices within a graph in such a way that the induced
subgraph forms a cycle. Within this paper, we present three integer linear
programs specifically formulated to yield optimal solutions for this problem.
The branch-and-cut algorithm has been used for two models. To demonstrate the
computational efficiency of these methods, we utilize them on a range of
real-world graphs as well as random graphs. Additionally, we conduct a
comparative analysis against approaches previously proposed in the literature.
</p>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15902" title="Abstract">arXiv:2311.15902</a> [<a href="/pdf/2311.15902" title="Download PDF">pdf</a>, <a href="/format/2311.15902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simple Lattice Basis Computation -- The Generalization of the Euclidean  Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klein%2C+K">Kim-Manuel Klein</a>, 
<a href="/search/cs?searchtype=author&query=Reuter%2C+J">Janina Reuter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Number Theory (math.NT)

</div>
<p class="mathjax">The Euclidean algorithm is one of the oldest algorithms known to mankind.
Given two integral numbers $a_1$ and $a_2$, it computes the greatest common
divisor (gcd) of $a_1$ and $a_2$ in a very elegant way. From a lattice
perspective, it computes a basis of the sum of two one-dimensional lattices
$a_1 \mathbb{Z}$ and $a_2 \mathbb{Z}$ as $\gcd(a_1,a_2) \mathbb{Z} = a_1
\mathbb{Z} + a_2 \mathbb{Z}$. In this paper, we show that the classical
Euclidean algorithm can be adapted in a very natural way to compute a basis of
a general lattice $L(a_1, \ldots , a_m)$ given vectors $a_1, \ldots , a_m \in
\mathbb{Z}^n$ with $m&gt; \mathrm{rank}(a_1, \ldots ,a_m)$. Similar to the
Euclidean algorithm, our algorithm is very easy to describe and implement and
can be written within 12 lines of pseudocode.
<br />While the Euclidean algorithm halves the largest number in every iteration,
our generalized algorithm halves the determinant of a full rank subsystem
leading to at most $\log (\det B)$ many iterations, for some initial subsystem
$B$. Therefore, we can compute a basis of the lattice using at most
$\tilde{O}((m-n)n\log(\det B) + mn^{\omega-1}\log(||A||_\infty))$ arithmetic
operations, where $\omega$ is the matrix multiplication exponent and $A = (a_1,
\ldots, a_m)$. Even using the worst case Hadamard bound for the determinant,
our algorithm improves upon existing algorithm.
<br />Another major advantage of our algorithm is that we can bound the entries of
the resulting lattice basis by $\tilde{O}(n^2\cdot ||A||_{\infty})$ using a
simple pivoting rule. This is in contrast to the typical approach for computing
lattice basis, where the Hermite normal form (HNF) is used. In the HNF, entries
can be as large as the determinant and hence can only be bounded by an
exponential term.
</p>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15906" title="Abstract">arXiv:2311.15906</a> [<a href="/pdf/2311.15906" title="Download PDF">pdf</a>, <a href="/format/2311.15906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MetaDefa: Meta-learning based on Domain Enhancement and Feature  Alignment for Single Domain Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Can Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhigang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+M">Meiguang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bo Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The single domain generalization(SDG) based on meta-learning has emerged as
an effective technique for solving the domain-shift problem. However, the
inadequate match of data distribution between source and augmented domains and
difficult separation of domain-invariant features from domain-related features
make SDG model hard to achieve great generalization. Therefore, a novel
meta-learning method based on domain enhancement and feature alignment
(MetaDefa) is proposed to improve the model generalization performance. First,
the background substitution and visual corruptions techniques are used to
generate diverse and effective augmented domains. Then, the multi-channel
feature alignment module based on class activation maps and class agnostic
activation maps is designed to effectively extract adequate transferability
knowledge. In this module, domain-invariant features can be fully explored by
focusing on similar target regions between source and augmented domains feature
space and suppressing the feature representation of non-similar target regions.
Extensive experiments on two publicly available datasets show that MetaDefa has
significant generalization performance advantages in unknown multiple target
domains.
</p>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15908" title="Abstract">arXiv:2311.15908</a> [<a href="/pdf/2311.15908" title="Download PDF">pdf</a>, <a href="/format/2311.15908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Perceptual Quality in Video Super-Resolution through  Temporally-Consistent Detail Synthesis using Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rota%2C+C">Claudio Rota</a>, 
<a href="/search/cs?searchtype=author&query=Buzzelli%2C+M">Marco Buzzelli</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Weijer%2C+J">Joost van de Weijer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we address the problem of video super-resolution (VSR) using
Diffusion Models (DM), and present StableVSR. Our method significantly enhances
the perceptual quality of upscaled videos by synthesizing realistic and
temporally-consistent details. We turn a pre-trained DM for single image
super-resolution into a VSR method by introducing the Temporal Conditioning
Module (TCM). TCM uses Temporal Texture Guidance, which provides
spatially-aligned and detail-rich texture information synthesized in adjacent
frames. This guides the generative process of the current frame toward
high-quality and temporally-consistent results. We introduce a Frame-wise
Bidirectional Sampling strategy to encourage the use of information from past
to future and vice-versa. This strategy improves the perceptual quality of the
results and the temporal consistency across frames. We demonstrate the
effectiveness of StableVSR in enhancing the perceptual quality of upscaled
videos compared to existing state-of-the-art methods for VSR. The code is
available at https://github.com/claudiom4sir/StableVSR.
</p>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15912" title="Abstract">arXiv:2311.15912</a> [<a href="/pdf/2311.15912" title="Download PDF">pdf</a>, <a href="/ps/2311.15912" title="Download PostScript">ps</a>, <a href="/format/2311.15912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LIFT OFF: LoRaWAN Installation and Fiducial Tracking Operations for the  Flightline of the Future
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goodman%2C+A">Ari Goodman</a>, 
<a href="/search/cs?searchtype=author&query=O%27Shea%2C+R">Ryan O&#x27;Shea</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 11 figures. Published in the Proceedings of the ASNE 2023 Technology, Systems &amp; Ships Symposium. Reproduced with permission from the American Society of Naval Engineers. Distribution Statement A: Approved for public release; distribution is unlimited, as submitted under NAVAIR Public Release Authorization 2023-020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Real-time situational awareness for the location of assets is critical to
ensure missions are completed efficiently and requirements are satisfied. In
many commercial settings, the application of global positioning system (GPS)
sensors is appropriate to achieve timely knowledge of the position of people
and equipment. However, GPS sensors are not appropriate for all situations due
to flight clearance and operations security concerns. LIFT OFF: LoRaWAN
Installation and Fiducial Tracking Operations for the Flightline of the Future
proposes a hybrid framework solution to achieve real-time situational awareness
for people, support equipment, and aircraft positions regardless of the
environment. This framework included a machine-vision component, which involved
setting up cameras to detect AprilTag decals that were installed on the sides
of aircraft. The framework included a geolocation sensor component, which
involved installing GPS sensors on support equipment and helmets. The framework
also included creating a long-range wide area network (LoRaWAN) to transfer
data and developing a user interface to display the data. The framework was
tested at Naval Air Station Oceana Flightline, the United States Naval Test
Pilot School, and at Naval Air Warfare Center Aircraft Division Lakehurst. LIFT
OFF successfully provided a real-time updating map of all tracked assets using
GPS sensors for people and support equipment and with visual fiducials for
aircraft. The trajectories of the assets were recorded for logistical analysis
and playback. Future follow-on work is anticipated to apply the technology to
other environments including carriers and amphibious assault ships in addition
to the flightline.
</p>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15914" title="Abstract">arXiv:2311.15914</a> [<a href="/pdf/2311.15914" title="Download PDF">pdf</a>, <a href="/ps/2311.15914" title="Download PostScript">ps</a>, <a href="/format/2311.15914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computer Vision for Carriers: PATRIOT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goodman%2C+A">Ari Goodman</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+G">Gurpreet Singh</a>, 
<a href="/search/cs?searchtype=author&query=Hing%2C+J">James Hing</a>, 
<a href="/search/cs?searchtype=author&query=O%27Shea%2C+R">Ryan O&#x27;Shea</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 18 figures. Published in the Proceedings of the ASNE 2023 Technology, Systems &amp; Ships Symposium. Reproduced with permission from the American Society of Naval Engineers. Distribution Statement A: Approved for public release; distribution is unlimited, as submitted under NAVAIR Public Release Authorization 2023-019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deck tracking performed on carriers currently involves a team of sailors
manually identifying aircraft and updating a digital user interface called the
Ouija Board. Improvements to the deck tracking process would result in
increased Sortie Generation Rates, and therefore applying automation is seen as
a critical method to improve deck tracking. However, the requirements on a
carrier ship do not allow for the installation of hardware-based location
sensing technologies like Global Positioning System (GPS) sensors. PATRIOT
(Panoramic Asset Tracking of Real-Time Information for the Ouija Tabletop) is a
research effort and proposed solution to performing deck tracking with passive
sensing and without the need for GPS sensors. PATRIOT is a prototype system
which takes existing camera feeds, calculates aircraft poses, and updates a
virtual Ouija board interface with the current status of the assets. PATRIOT
would allow for faster, more accurate, and less laborious asset tracking for
aircraft, people, and support equipment. PATRIOT is anticipated to benefit the
warfighter by reducing cognitive workload, reducing manning requirements,
collecting data to improve logistics, and enabling an automation gateway for
future efforts to improve efficiency and safety. The authors have developed and
tested algorithms to perform pose estimations of assets in real-time including
OpenPifPaf, High-Resolution Network (HRNet), HigherHRNet (HHRNet), Faster
R-CNN, and in-house developed encoder-decoder network. The software was tested
with synthetic and real-world data and was able to accurately extract the pose
of assets. Fusion, tracking, and real-world generality are planned to be
improved to ensure a successful transition to the fleet.
</p>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15916" title="Abstract">arXiv:2311.15916</a> [<a href="/pdf/2311.15916" title="Download PDF">pdf</a>, <a href="/format/2311.15916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ADM-Loc: Actionness Distribution Modeling for Point-supervised Temporal  Action Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vahdani%2C+E">Elahe Vahdani</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yingli Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper addresses the challenge of point-supervised temporal action
detection, in which only one frame per action instance is annotated in the
training set. Self-training aims to provide supplementary supervision for the
training process by generating pseudo-labels (action proposals) from a base
model. However, most current methods generate action proposals by applying
manually designed thresholds to action classification probabilities and
treating adjacent snippets as independent entities. As a result, these methods
struggle to generate complete action proposals, exhibit sensitivity to
fluctuations in action classification scores, and generate redundant and
overlapping action proposals. This paper proposes a novel framework termed
ADM-Loc, which stands for Actionness Distribution Modeling for point-supervised
action Localization. ADM-Loc generates action proposals by fitting a composite
distribution, comprising both Gaussian and uniform distributions, to the action
classification signals. This fitting process is tailored to each action class
present in the video and is applied separately for each action instance,
ensuring the distinctiveness of their distributions. ADM-Loc significantly
enhances the alignment between the generated action proposals and ground-truth
action instances and offers high-quality pseudo-labels for self-training.
Moreover, to model action boundary snippets, it enforces consistency in action
classification scores during training by employing Gaussian kernels, supervised
with the proposed loss functions. ADM-Loc outperforms the state-of-the-art
point-supervised methods on THUMOS14 and ActivityNet-v1.2 datasets.
</p>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15917" title="Abstract">arXiv:2311.15917</a> [<a href="/pdf/2311.15917" title="Download PDF">pdf</a>, <a href="/format/2311.15917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Graph Convolution Meets Double Attention: Online Privacy Disclosure  Detection with Multi-Label Text Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zhanbo Liang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jie Guo</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+W">Weidong Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shujun Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The manuscript is accepted by Data Mining and Knowledge Discovery(ECML PKDD Journal track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">With the rise of Web 2.0 platforms such as online social media, people's
private information, such as their location, occupation and even family
information, is often inadvertently disclosed through online discussions.
Therefore, it is important to detect such unwanted privacy disclosures to help
alert people affected and the online platform. In this paper, privacy
disclosure detection is modeled as a multi-label text classification (MLTC)
problem, and a new privacy disclosure detection model is proposed to construct
an MLTC classifier for detecting online privacy disclosures. This classifier
takes an online post as the input and outputs multiple labels, each reflecting
a possible privacy disclosure. The proposed presentation method combines three
different sources of information, the input text itself, the label-to-text
correlation and the label-to-label correlation. A double-attention mechanism is
used to combine the first two sources of information, and a graph convolutional
network (GCN) is employed to extract the third source of information that is
then used to help fuse features extracted from the first two sources of
information. Our extensive experimental results, obtained on a public dataset
of privacy-disclosing posts on Twitter, demonstrated that our proposed privacy
disclosure detection method significantly and consistently outperformed other
state-of-the-art methods in terms of all key performance indicators.
</p>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15918" title="Abstract">arXiv:2311.15918</a> [<a href="/pdf/2311.15918" title="Download PDF">pdf</a>, <a href="/format/2311.15918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A comparative study of micromorphic gradient-extensions for anisotropic  damage at finite strains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+der+Velden%2C+T">Tim van der Velden</a>, 
<a href="/search/cs?searchtype=author&query=Brepols%2C+T">Tim Brepols</a>, 
<a href="/search/cs?searchtype=author&query=Reese%2C+S">Stefanie Reese</a>, 
<a href="/search/cs?searchtype=author&query=Holthusen%2C+H">Hagen Holthusen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Modern inelastic material model formulations rely on the use of tensor-valued
internal variables. When inelastic phenomena include softening, simulations of
the former are prone to localization. Thus, an accurate regularization of the
tensor-valued internal variables is essential to obtain physically correct
results. Here, we focus on the regularization of anisotropic damage at finite
strains. Thus, a flexible anisotropic damage model with isotropic, kinematic,
and distortional hardening is equipped with three gradient-extensions using a
full and two reduced regularizations of the damage tensor. Theoretical and
numerical comparisons of the three gradient-extensions yield excellent
agreement between the full and the reduced regularization based on a
volumetric-deviatoric regularization using only two nonlocal degrees of
freedom.
</p>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15919" title="Abstract">arXiv:2311.15919</a> [<a href="/pdf/2311.15919" title="Download PDF">pdf</a>, <a href="/format/2311.15919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What monads can and cannot do with a bit of extra time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%B8gelberg%2C+R+E">Rasmus Ejlers M&#xf8;gelberg</a>, 
<a href="/search/cs?searchtype=author&query=Zwart%2C+M">Maaike Zwart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in Proceedings of CSL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">The delay monad provides a way to introduce general recursion in type theory.
To write programs that use a wide range of computational effects directly in
type theory, we need to combine the delay monad with the monads of these
effects. Here we present a first systematic study of such combinations.
<br />We study both the coinductive delay monad and its guarded recursive cousin,
giving concrete examples of combining these with well-known computational
effects. We also provide general theorems stating which algebraic effects
distribute over the delay monad, and which do not. Lastly, we salvage some of
the impossible cases by considering distributive laws up to weak bisimilarity.
</p>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15920" title="Abstract">arXiv:2311.15920</a> [<a href="/pdf/2311.15920" title="Download PDF">pdf</a>, <a href="/format/2311.15920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Fully Data-Driven Approach for Realistic Traffic Signal Control Using  Offline Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianxiong Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shichao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+T">Tianyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+C">Chujie Tian</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+Y">Yu Mei</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jian Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xianyuan Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruimin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The optimization of traffic signal control (TSC) is critical for an efficient
transportation system. In recent years, reinforcement learning (RL) techniques
have emerged as a popular approach for TSC and show promising results for
highly adaptive control. However, existing RL-based methods suffer from notably
poor real-world applicability and hardly have any successful deployments. The
reasons for such failures are mostly due to the reliance on over-idealized
traffic simulators for policy optimization, as well as using unrealistic
fine-grained state observations and reward signals that are not directly
obtainable from real-world sensors. In this paper, we propose a fully
Data-Driven and simulator-free framework for realistic Traffic Signal Control
(D2TSC). Specifically, we combine well-established traffic flow theory with
machine learning to construct a reward inference model to infer the reward
signals from coarse-grained traffic data. With the inferred rewards, we further
propose a sample-efficient offline RL method to enable direct signal control
policy learning from historical offline datasets of real-world intersections.
To evaluate our approach, we collect historical traffic data from a real-world
intersection, and develop a highly customized simulation environment that
strictly follows real data characteristics. We demonstrate through extensive
experiments that our approach achieves superior performance over conventional
and offline RL baselines, and also enjoys much better real-world applicability.
</p>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15923" title="Abstract">arXiv:2311.15923</a> [<a href="/pdf/2311.15923" title="Download PDF">pdf</a>, <a href="/format/2311.15923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEINE: SEgment-based Indexing for NEural information retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+S">Sibo Dong</a>, 
<a href="/search/cs?searchtype=author&query=Goldstein%2C+J">Justin Goldstein</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G+H">Grace Hui Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Many early neural Information Retrieval (NeurIR) methods are re-rankers that
rely on a traditional first-stage retriever due to expensive query time
computations. Recently, representation-based retrievers have gained much
attention, which learns query representation and document representation
separately, making it possible to pre-compute document representations offline
and reduce the workload at query time. Both dense and sparse
representation-based retrievers have been explored. However, these methods
focus on finding the representation that best represents a text (aka metric
learning) and the actual retrieval function that is responsible for similarity
matching between query and document is kept at a minimum by using dot product.
One drawback is that unlike traditional term-level inverted index, the index
formed by these embeddings cannot be easily re-used by another retrieval
method. Another drawback is that keeping the interaction at minimum hurts
retrieval effectiveness. On the contrary, interaction-based retrievers are
known for their better retrieval effectiveness. In this paper, we propose a
novel SEgment-based Neural Indexing method, SEINE, which provides a general
indexing framework that can flexibly support a variety of interaction-based
neural retrieval methods. We emphasize on a careful decomposition of common
components in existing neural retrieval methods and propose to use
segment-level inverted index to store the atomic query-document interaction
values. Experiments on LETOR MQ2007 and MQ2008 datasets show that our indexing
method can accelerate multiple neural retrieval methods up to 28-times faster
without sacrificing much effectiveness.
</p>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15924" title="Abstract">arXiv:2311.15924</a> [<a href="/pdf/2311.15924" title="Download PDF">pdf</a>, <a href="/format/2311.15924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diagnosis driven Anomaly Detection for CPS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Steude%2C+H+S">Henrik S. Steude</a>, 
<a href="/search/cs?searchtype=author&query=Moddemann%2C+L">Lukas Moddemann</a>, 
<a href="/search/cs?searchtype=author&query=Diedrich%2C+A">Alexander Diedrich</a>, 
<a href="/search/cs?searchtype=author&query=Ehrhardt%2C+J">Jonas Ehrhardt</a>, 
<a href="/search/cs?searchtype=author&query=Niggemann%2C+O">Oliver Niggemann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In Cyber-Physical Systems (CPS) research, anomaly detection (detecting
abnormal behavior) and diagnosis (identifying the underlying root cause) are
often treated as distinct, isolated tasks. However, diagnosis algorithms
require symptoms, i.e. temporally and spatially isolated anomalies, as input.
Thus, anomaly detection and diagnosis must be developed together to provide a
holistic solution for diagnosis in CPS. We therefore propose a method for
utilizing deep learning-based anomaly detection to generate inputs for
Consistency-Based Diagnosis (CBD). We evaluate our approach on a simulated and
a real-world CPS dataset, where our model demonstrates strong performance
relative to other state-of-the-art models.
</p>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15925" title="Abstract">arXiv:2311.15925</a> [<a href="/pdf/2311.15925" title="Download PDF">pdf</a>, <a href="/format/2311.15925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning for Wildfire Mitigation in Simulated Disaster  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tapley%2C+A">Alexander Tapley</a>, 
<a href="/search/cs?searchtype=author&query=Dotter%2C+M">Marissa Dotter</a>, 
<a href="/search/cs?searchtype=author&query=Doyle%2C+M">Michael Doyle</a>, 
<a href="/search/cs?searchtype=author&query=Fennelly%2C+A">Aidan Fennelly</a>, 
<a href="/search/cs?searchtype=author&query=Gandikota%2C+D">Dhanuj Gandikota</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+S">Savanna Smith</a>, 
<a href="/search/cs?searchtype=author&query=Threet%2C+M">Michael Threet</a>, 
<a href="/search/cs?searchtype=author&query=Welsh%2C+T">Tim Welsh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures including Appendices (A, B). Accepted as a paper in the Proposals track at the "Tackling Climate Change with Machine Learning" workshop at NeurIPS 2023. MITRE Public Release Case Number 23-3920
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Software Engineering (cs.SE)

</div>
<p class="mathjax">Climate change has resulted in a year over year increase in adverse weather
and weather conditions which contribute to increasingly severe fire seasons.
Without effective mitigation, these fires pose a threat to life, property,
ecology, cultural heritage, and critical infrastructure. To better prepare for
and react to the increasing threat of wildfires, more accurate fire modelers
and mitigation responses are necessary. In this paper, we introduce SimFire, a
versatile wildland fire projection simulator designed to generate realistic
wildfire scenarios, and SimHarness, a modular agent-based machine learning
wrapper capable of automatically generating land management strategies within
SimFire to reduce the overall damage to the area. Together, this publicly
available system allows researchers and practitioners the ability to emulate
and assess the effectiveness of firefighter interventions and formulate
strategic plans that prioritize value preservation and resource allocation
optimization. The repositories are available for download at
https://github.com/mitrefireline.
</p>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15929" title="Abstract">arXiv:2311.15929</a> [<a href="/pdf/2311.15929" title="Download PDF">pdf</a>, <a href="/format/2311.15929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Common Workflow Scheduler Interface: Status Quo and Future Plans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lehmann%2C+F">Fabian Lehmann</a>, 
<a href="/search/cs?searchtype=author&query=Bader%2C+J">Jonathan Bader</a>, 
<a href="/search/cs?searchtype=author&query=Thamsen%2C+L">Lauritz Thamsen</a>, 
<a href="/search/cs?searchtype=author&query=Leser%2C+U">Ulf Leser</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the SC '23 Workshops of The International
  Conference on High Performance Computing, Network, Storage, and Analysis
  (SC-W 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Nowadays, many scientific workflows from different domains, such as Remote
Sensing, Astronomy, and Bioinformatics, are executed on large computing
infrastructures managed by resource managers. Scientific workflow management
systems (SWMS) support the workflow execution and communicate with the
infrastructures' resource managers. However, the communication between SWMS and
resource managers is complicated by a) inconsistent interfaces between SMWS and
resource managers and b) the lack of support for workflow dependencies and
workflow-specific properties.
<br />To tackle these issues, we developed the Common Workflow Scheduler Interface
(CWSI), a simple yet powerful interface to exchange workflow-related
information between a SWMS and a resource manager, making the resource manager
workflow-aware. The first prototype implementations show that the CWSI can
reduce the makespan already with simple but workflow-aware strategies up to
25%. In this paper, we show how existing workflow resource management research
can be integrated into the CWSI.
</p>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15930" title="Abstract">arXiv:2311.15930</a> [<a href="/pdf/2311.15930" title="Download PDF">pdf</a>, <a href="/format/2311.15930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WorldSense: A Synthetic Benchmark for Grounded Reasoning in Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Benchekroun%2C+Y">Youssef Benchekroun</a>, 
<a href="/search/cs?searchtype=author&query=Dervishi%2C+M">Megi Dervishi</a>, 
<a href="/search/cs?searchtype=author&query=Ibrahim%2C+M">Mark Ibrahim</a>, 
<a href="/search/cs?searchtype=author&query=Gaya%2C+J">Jean-Baptiste Gaya</a>, 
<a href="/search/cs?searchtype=author&query=Martinet%2C+X">Xavier Martinet</a>, 
<a href="/search/cs?searchtype=author&query=Mialon%2C+G">Gr&#xe9;goire Mialon</a>, 
<a href="/search/cs?searchtype=author&query=Scialom%2C+T">Thomas Scialom</a>, 
<a href="/search/cs?searchtype=author&query=Dupoux%2C+E">Emmanuel Dupoux</a>, 
<a href="/search/cs?searchtype=author&query=Hupkes%2C+D">Dieuwke Hupkes</a>, 
<a href="/search/cs?searchtype=author&query=Vincent%2C+P">Pascal Vincent</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We propose WorldSense, a benchmark designed to assess the extent to which
LLMs are consistently able to sustain tacit world models, by testing how they
draw simple inferences from descriptions of simple arrangements of entities.
Worldsense is a synthetic benchmark with three problem types, each with their
own trivial control, which explicitly avoids bias by decorrelating the abstract
structure of problems from the vocabulary and expressions, and by decorrelating
all problem subparts with the correct response. We run our benchmark on three
state-of-the-art chat-LLMs (GPT3.5, GPT4 and Llama2-chat) and show that these
models make errors even with as few as three objects. Furthermore, they have
quite heavy response biases, preferring certain responses irrespective of the
question. Errors persist even with chain-of-thought prompting and in-context
learning. Lastly, we show that while finetuning on similar problems does result
in substantial improvements -- within- and out-of-distribution -- the finetuned
models do not generalise beyond a constraint problem space.
</p>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15931" title="Abstract">arXiv:2311.15931</a> [<a href="/pdf/2311.15931" title="Download PDF">pdf</a>, <a href="/ps/2311.15931" title="Download PostScript">ps</a>, <a href="/format/2311.15931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Degree Hardness of Detection for Correlated Erd&#x151;s-R&#xe9;nyi Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jian Ding</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Hang Du</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhangsong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Probability (math.PR); Statistics Theory (math.ST)

</div>
<p class="mathjax">Given two Erd\H{o}s-R\'enyi graphs with $n$ vertices whose edges are
correlated through a latent vertex correspondence, we study complexity lower
bounds for the associated correlation detection problem for the class of
low-degree polynomial algorithms. We provide evidence that any
degree-$O(\rho^{-1})$ polynomial algorithm fails for detection, where $\rho$ is
the edge correlation. Furthermore, in the sparse regime where the edge density
$q=n^{-1+o(1)}$, we provide evidence that any degree-$d$ polynomial algorithm
fails for detection, as long as $\log d=o\big( \frac{\log n}{\log nq} \wedge
\sqrt{\log n} \big)$ and the correlation $\rho&lt;\sqrt{\alpha}$ where
$\alpha\approx 0.338$ is the Otter's constant. Our result suggests that several
state-of-the-art algorithms on correlation detection and exact matching
recovery may be essentially the best possible.
</p>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15933" title="Abstract">arXiv:2311.15933</a> [<a href="/pdf/2311.15933" title="Download PDF">pdf</a>, <a href="/format/2311.15933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new fuzzy multi-attribute group decision-making method based on TOPSIS  and optimization models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qixiao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiquan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chaolang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuetong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In this paper, a new method based on TOPSIS and optimization models is
proposed for multi-attribute group decision-making in the environment of
interval-valued intuitionistic fuzzy sets.Firstly, by minimizing the sum of
differences between individual evaluations and the overallconsistent
evaluations of all experts, a new optimization model is established for
determining expert weights. Secondly, based on TOPSIS method, the improved
closeness index for evaluating each alternative is obtained. Finally, the
attribute weight is determined by establishing an optimization model with the
goal of maximizing the closeness of each alternative, and it is brought into
the closeness index so that the alternatives can be ranked. Combining all these
together, the complete fuzzy multi-attribute group decision-making algorithm is
formulated, which can give full play to the advantages of subjective and
objective weighting methods. In the end, the feasibility and effectiveness of
the provided method are verified by a real case study.
</p>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15936" title="Abstract">arXiv:2311.15936</a> [<a href="/pdf/2311.15936" title="Download PDF">pdf</a>, <a href="/format/2311.15936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Responsible Governance of Biological Design Tools
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moulange%2C+R">Richard Moulange</a>, 
<a href="/search/cs?searchtype=author&query=Langenkamp%2C+M">Max Langenkamp</a>, 
<a href="/search/cs?searchtype=author&query=Alexanian%2C+T">Tessa Alexanian</a>, 
<a href="/search/cs?searchtype=author&query=Curtis%2C+S">Samuel Curtis</a>, 
<a href="/search/cs?searchtype=author&query=Livingston%2C+M">Morgan Livingston</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages + references, 1 figure, accepted at NeurIPS 2023 Regulatable ML as oral presentation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advancements in generative machine learning have enabled rapid
progress in biological design tools (BDTs) such as protein structure and
sequence prediction models. The unprecedented predictive accuracy and novel
design capabilities of BDTs present new and significant dual-use risks. For
example, their predictive accuracy allows biological agents, whether vaccines
or pathogens, to be developed more quickly, while the design capabilities could
be used to discover drugs or evade DNA screening techniques. Similar to other
dual-use AI systems, BDTs present a wicked problem: how can regulators uphold
public safety without stifling innovation? We highlight how current regulatory
proposals that are primarily tailored toward large language models may be less
effective for BDTs, which require fewer computational resources to train and
are often developed in an open-source manner. We propose a range of measures to
mitigate the risk that BDTs are misused, across the areas of responsible
development, risk assessment, transparency, access management, cybersecurity,
and investing in resilience. Implementing such measures will require close
coordination between developers and governments.
</p>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15937" title="Abstract">arXiv:2311.15937</a> [<a href="/pdf/2311.15937" title="Download PDF">pdf</a>, <a href="/format/2311.15937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Transport Aggregation for Visual Place Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Izquierdo%2C+S">Sergio Izquierdo</a>, 
<a href="/search/cs?searchtype=author&query=Civera%2C+J">Javier Civera</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The task of Visual Place Recognition (VPR) aims to match a query image
against references from an extensive database of images from different places,
relying solely on visual cues. State-of-the-art pipelines focus on the
aggregation of features extracted from a deep backbone, in order to form a
global descriptor for each image. In this context, we introduce SALAD (Sinkhorn
Algorithm for Locally Aggregated Descriptors), which reformulates NetVLAD's
soft-assignment of local features to clusters as an optimal transport problem.
In SALAD, we consider both feature-to-cluster and cluster-to-feature relations
and we also introduce a 'dustbin' cluster, designed to selectively discard
features deemed non-informative, enhancing the overall descriptor quality.
Additionally, we leverage and fine-tune DINOv2 as a backbone, which provides
enhanced description power for the local features, and dramatically reduces the
required training time. As a result, our single-stage method not only surpasses
single-stage baselines in public VPR datasets, but also surpasses two-stage
methods that add a re-ranking with significantly higher cost. Code and models
are available at https://github.com/serizba/salad.
</p>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15939" title="Abstract">arXiv:2311.15939</a> [<a href="/pdf/2311.15939" title="Download PDF">pdf</a>, <a href="/format/2311.15939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unleashing the Power of Prompt-driven Nucleus Instance Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shui%2C+Z">Zhongyi Shui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunlong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+K">Kai Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chenglu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuxuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lin Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Nuclear instance segmentation in histology images is crucial for a broad
spectrum of clinical applications. Current prevailing nuclear instance
segmentation algorithms rely on regression of nuclei contours, distance maps,
watershed markers or a proxy nuclear representation of star-convex polygons.
Consequently, these methods necessitate sophisticated post-processing
operations to distinguish nuclei instances, which are commonly acknowledged to
be error-prone and parameter-sensitive. Recently, the segment anything model
(SAM) has earned attracted huge attention within the domain of medical image
segmentation due to its impressive generalization ability and promptable
property. Nevertheless, its potential on nuclear instance segmentation remains
largely underexplored. In this paper, we present a novel prompt-driven
framework that consists of a point prompter and a SAM for automatic nuclei
instance segmentation. Specifically, the prompter learns to generate a unique
point prompt for each nucleus while the SAM is fine tuned to output the
corresponding mask of the cued nucleus. Furthermore, we propose to add adjacent
nuclei as negative prompts to promote the model's ability to recognize
overlapping nuclei. Without bells and whistles, our proposed method sets a new
state-of-the-art performance on three challenging benchmarks. Our code is
available at
\textcolor{magenta}{\url{https://github.com/windygoo/PromptNucSeg}} .
</p>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15940" title="Abstract">arXiv:2311.15940</a> [<a href="/pdf/2311.15940" title="Download PDF">pdf</a>, <a href="/format/2311.15940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-informed neural networks for transformed geometries and  manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Burbulla%2C+S">Samuel Burbulla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Physics-informed neural networks (PINNs) effectively embed physical
principles into machine learning, but often struggle with complex or
alternating geometries. We propose a novel method for integrating geometric
transformations within PINNs to robustly accommodate geometric variations. Our
method incorporates a diffeomorphism as a mapping of a reference domain and
adapts the derivative computation of the physics-informed loss function. This
generalizes the applicability of PINNs not only to smoothly deformed domains,
but also to lower-dimensional manifolds and allows for direct shape
optimization while training the network. We demonstrate the effectivity of our
approach on several problems: (i) Eikonal equation on Archimedean spiral, (ii)
Poisson problem on surface manifold, (iii) Incompressible Stokes flow in
deformed tube, and (iv) Shape optimization with Laplace operator. Through these
examples, we demonstrate the enhanced flexibility over traditional PINNs,
especially under geometric variations. The proposed framework presents an
outlook for training deep neural operators over parametrized geometries, paving
the way for advanced modeling with PDEs on complex geometries in science and
engineering.
</p>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15941" title="Abstract">arXiv:2311.15941</a> [<a href="/pdf/2311.15941" title="Download PDF">pdf</a>, <a href="/format/2311.15941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tell2Design: A Dataset for Language-Guided Floor Plan Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leng%2C+S">Sicong Leng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Dupty%2C+M+H">Mohammed Haroon Dupty</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+W+S">Wee Sun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Joyce%2C+S+C">Sam Conrad Joyce</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wei Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper published in ACL2023; Area Chair Award; Best Paper Nomination
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We consider the task of generating designs directly from natural language
descriptions, and consider floor plan generation as the initial research area.
Language conditional generative models have recently been very successful in
generating high-quality artistic images. However, designs must satisfy
different constraints that are not present in generating artistic images,
particularly spatial and relational constraints. We make multiple contributions
to initiate research on this task. First, we introduce a novel dataset,
\textit{Tell2Design} (T2D), which contains more than $80k$ floor plan designs
associated with natural language instructions. Second, we propose a
Sequence-to-Sequence model that can serve as a strong baseline for future
research. Third, we benchmark this task with several text-conditional image
generation models. We conclude by conducting human evaluations on the generated
samples and providing an analysis of human performance. We hope our
contributions will propel the research on language-guided design generation
forward.
</p>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15945" title="Abstract">arXiv:2311.15945</a> [<a href="/pdf/2311.15945" title="Download PDF">pdf</a>, <a href="/format/2311.15945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Over-Squashing in Riemannian Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balla%2C+J">Julia Balla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Most graph neural networks (GNNs) are prone to the phenomenon of
over-squashing in which node features become insensitive to information from
distant nodes in the graph. Recent works have shown that the topology of the
graph has the greatest impact on over-squashing, suggesting graph rewiring
approaches as a suitable solution. In this work, we explore whether
over-squashing can be mitigated through the embedding space of the GNN. In
particular, we consider the generalization of Hyperbolic GNNs (HGNNs) to
Riemannian manifolds of variable curvature in which the geometry of the
embedding space is faithful to the graph's topology. We derive bounds on the
sensitivity of the node features in these Riemannian GNNs as the number of
layers increases, which yield promising theoretical and empirical results for
alleviating over-squashing in graphs with negative curvature.
</p>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15946" title="Abstract">arXiv:2311.15946</a> [<a href="/pdf/2311.15946" title="Download PDF">pdf</a>, <a href="/format/2311.15946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging deep active learning to identify low-resource mobility  functioning information in public clinical notes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Tuan-Dung Le</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+Z">Zhuqi Miao</a>, 
<a href="/search/cs?searchtype=author&query=Alvarado%2C+S">Samuel Alvarado</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+B">Brittany Smith</a>, 
<a href="/search/cs?searchtype=author&query=Paiva%2C+W">William Paiva</a>, 
<a href="/search/cs?searchtype=author&query=Thieu%2C+T">Thanh Thieu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Function is increasingly recognized as an important indicator of whole-person
health, although it receives little attention in clinical natural language
processing research. We introduce the first public annotated dataset
specifically on the Mobility domain of the International Classification of
Functioning, Disability and Health (ICF), aiming to facilitate automatic
extraction and analysis of functioning information from free-text clinical
notes. We utilize the National NLP Clinical Challenges (n2c2) research dataset
to construct a pool of candidate sentences using keyword expansion. Our active
learning approach, using query-by-committee sampling weighted by density
representativeness, selects informative sentences for human annotation. We
train BERT and CRF models, and use predictions from these models to guide the
selection of new sentences for subsequent annotation iterations. Our final
dataset consists of 4,265 sentences with a total of 11,784 entities, including
5,511 Action entities, 5,328 Mobility entities, 306 Assistance entities, and
639 Quantification entities. The inter-annotator agreement (IAA), averaged over
all entity types, is 0.72 for exact matching and 0.91 for partial matching. We
also train and evaluate common BERT models and state-of-the-art Nested NER
models. The best F1 scores are 0.84 for Action, 0.7 for Mobility, 0.62 for
Assistance, and 0.71 for Quantification. Empirical results demonstrate
promising potential of NER models to accurately extract mobility functioning
information from clinical text. The public availability of our annotated
dataset will facilitate further research to comprehensively capture functioning
information in electronic health records (EHRs).
</p>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15947" title="Abstract">arXiv:2311.15947</a> [<a href="/pdf/2311.15947" title="Download PDF">pdf</a>, <a href="/format/2311.15947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GloNets: Globally Connected Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di+Cecco%2C+A">Antonio Di Cecco</a>, 
<a href="/search/cs?searchtype=author&query=Metta%2C+C">Carlo Metta</a>, 
<a href="/search/cs?searchtype=author&query=Fantozzi%2C+M">Marco Fantozzi</a>, 
<a href="/search/cs?searchtype=author&query=Morandin%2C+F">Francesco Morandin</a>, 
<a href="/search/cs?searchtype=author&query=Parton%2C+M">Maurizio Parton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Deep learning architectures suffer from depth-related performance
degradation, limiting the effective depth of neural networks. Approaches like
ResNet are able to mitigate this, but they do not completely eliminate the
problem. We introduce Globally Connected Neural Networks (GloNet), a novel
architecture overcoming depth-related issues, designed to be superimposed on
any model, enhancing its depth without increasing complexity or reducing
performance. With GloNet, the network's head uniformly receives information
from all parts of the network, regardless of their level of abstraction. This
enables GloNet to self-regulate information flow during training, reducing the
influence of less effective deeper layers, and allowing for stable training
irrespective of network depth. This paper details GloNet's design, its
theoretical basis, and a comparison with existing similar architectures.
Experiments show GloNet's self-regulation ability and resilience to
depth-related learning challenges, like performance degradation. Our findings
suggest GloNet as a strong alternative to traditional architectures like
ResNets.
</p>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15950" title="Abstract">arXiv:2311.15950</a> [<a href="/pdf/2311.15950" title="Download PDF">pdf</a>, <a href="/format/2311.15950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auto-CsiNet: Scenario-customized Automatic Neural Network Architecture  Generation for Massive MIMO CSI Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiajia Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+C">Chao-Kai Wen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shi Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep learning has revolutionized the design of the channel state information
(CSI) feedback module in wireless communications. However, designing the
optimal neural network (NN) architecture for CSI feedback can be a laborious
and time-consuming process. Manual design can be prohibitively expensive for
customizing NNs to different scenarios. This paper proposes using neural
architecture search (NAS) to automate the generation of scenario-customized CSI
feedback NN architectures, thereby maximizing the potential of deep learning in
exclusive environments. By employing automated machine learning and
gradient-descent-based NAS, an efficient and cost-effective architecture design
process is achieved. The proposed approach leverages implicit scene knowledge,
integrating it into the scenario customization process in a data-driven manner,
and fully exploits the potential of deep learning for each specific scenario.
To address the issue of excessive search, early stopping and elastic selection
mechanisms are employed, enhancing the efficiency of the proposed scheme. The
experimental results demonstrate that the automatically generated architecture,
known as Auto-CsiNet, outperforms manually-designed models in both
reconstruction performance (achieving approximately a 14% improvement) and
complexity (reducing it by approximately 50%). Furthermore, the paper analyzes
the impact of the scenario on the NN architecture and its capacity.
</p>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15951" title="Abstract">arXiv:2311.15951</a> [<a href="/pdf/2311.15951" title="Download PDF">pdf</a>, <a href="/format/2311.15951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Replay across Experiments: A Natural Extension of Off-Policy RL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tirumala%2C+D">Dhruva Tirumala</a>, 
<a href="/search/cs?searchtype=author&query=Lampe%2C+T">Thomas Lampe</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J+E">Jose Enrique Chen</a>, 
<a href="/search/cs?searchtype=author&query=Haarnoja%2C+T">Tuomas Haarnoja</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Sandy Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lever%2C+G">Guy Lever</a>, 
<a href="/search/cs?searchtype=author&query=Moran%2C+B">Ben Moran</a>, 
<a href="/search/cs?searchtype=author&query=Hertweck%2C+T">Tim Hertweck</a>, 
<a href="/search/cs?searchtype=author&query=Hasenclever%2C+L">Leonard Hasenclever</a>, 
<a href="/search/cs?searchtype=author&query=Riedmiller%2C+M">Martin Riedmiller</a>, 
<a href="/search/cs?searchtype=author&query=Heess%2C+N">Nicolas Heess</a>, 
<a href="/search/cs?searchtype=author&query=Wulfmeier%2C+M">Markus Wulfmeier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Replaying data is a principal mechanism underlying the stability and data
efficiency of off-policy reinforcement learning (RL). We present an effective
yet simple framework to extend the use of replays across multiple experiments,
minimally adapting the RL workflow for sizeable improvements in controller
performance and research iteration times. At its core, Replay Across
Experiments (RaE) involves reusing experience from previous experiments to
improve exploration and bootstrap learning while reducing required changes to a
minimum in comparison to prior work. We empirically show benefits across a
number of RL algorithms and challenging control domains spanning both
locomotion and manipulation, including hard exploration tasks from egocentric
vision. Through comprehensive ablations, we demonstrate robustness to the
quality and amount of data available and various hyperparameter choices.
Finally, we discuss how our approach can be applied more broadly across
research life cycles and can increase resilience by reloading data across
random seeds or hyperparameter variations.
</p>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15954" title="Abstract">arXiv:2311.15954</a> [<a href="/pdf/2311.15954" title="Download PDF">pdf</a>, <a href="/format/2311.15954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Quantitative Approach to Understand Self-Supervised Models as  Cross-lingual Feature Extractors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S+S">Shuyue Stella Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Beining Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hexin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chao%2C+W">Wenhan Chao</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+L+P">Leibny Paola Garcia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In this work, we study the features extracted by English self-supervised
learning (SSL) models in cross-lingual contexts and propose a new metric to
predict the quality of feature representations. Using automatic speech
recognition (ASR) as a downstream task, we analyze the effect of model size,
training objectives, and model architecture on the models' performance as a
feature extractor for a set of topologically diverse corpora. We develop a
novel metric, the Phonetic-Syntax Ratio (PSR), to measure the phonetic and
synthetic information in the extracted representations using deep generalized
canonical correlation analysis. Results show the contrastive loss in the
wav2vec2.0 objective facilitates more effective cross-lingual feature
extraction. There is a positive correlation between PSR scores and ASR
performance, suggesting that phonetic information extracted by monolingual SSL
models can be used for downstream tasks in cross-lingual settings. The proposed
metric is an effective indicator of the quality of the representations and can
be useful for model selection.
</p>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15959" title="Abstract">arXiv:2311.15959</a> [<a href="/pdf/2311.15959" title="Download PDF">pdf</a>, <a href="/format/2311.15959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CheapNET: Improving Light-weight speech enhancement network by projected  loss function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+K">Kaijun Tan</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Benzhe Dai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiakui Li</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+W">Wenyu Mao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Noise suppression and echo cancellation are critical in speech enhancement
and essential for smart devices and real-time communication. Deployed in voice
processing front-ends and edge devices, these algorithms must ensure efficient
real-time inference with low computational demands. Traditional edge-based
noise suppression often uses MSE-based amplitude spectrum mask training, but
this approach has limitations. We introduce a novel projection loss function,
diverging from MSE, to enhance noise suppression. This method uses projection
techniques to isolate key audio components from noise, significantly improving
model performance. For echo cancellation, the function enables direct
predictions on LAEC pre-processed outputs, substantially enhancing performance.
Our noise suppression model achieves near state-of-the-art results with only
3.1M parameters and 0.4GFlops/s computational load. Moreover, our echo
cancellation model outperforms replicated industry-leading models, introducing
a new perspective in speech enhancement.
</p>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15960" title="Abstract">arXiv:2311.15960</a> [<a href="/pdf/2311.15960" title="Download PDF">pdf</a>, <a href="/format/2311.15960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Addressing Long-Horizon Tasks by Integrating Program Synthesis and State  Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yu-An Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Chen-Tao Lee</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guan-Ting Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Pu-Jen Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shao-Hua Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Programming Languages (cs.PL); Robotics (cs.RO)

</div>
<p class="mathjax">Deep reinforcement learning excels in various domains but lacks
generalizability and interoperability. Programmatic RL methods (Trivedi et al.,
2021; Liu et al., 2023) reformulate solving RL tasks as synthesizing
interpretable programs that can be executed in the environments. Despite
encouraging results, these methods are limited to short-horizon tasks. On the
other hand, representing RL policies using state machines (Inala et al., 2020)
can inductively generalize to long-horizon tasks; however, it struggles to
scale up to acquire diverse and complex behaviors. This work proposes Program
Machine Policies (POMPs), which bridge the advantages of programmatic RL and
state machine policies, allowing for the representation of complex behaviors
and the address of long-term tasks. Specifically, we introduce a method that
can retrieve a set of effective, diverse, compatible programs. Then, we use
these programs as modes of a state machine and learn a transition function to
transition among mode programs, allowing for capturing long-horizon repetitive
behaviors. Our proposed framework outperforms programmatic RL and deep RL
baselines on various tasks and demonstrates the ability to generalize to even
longer horizons without any fine-tuning inductively. Ablation studies justify
the effectiveness of our proposed search algorithm for retrieving a set of
programs as modes.
</p>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15963" title="Abstract">arXiv:2311.15963</a> [<a href="/pdf/2311.15963" title="Download PDF">pdf</a>, <a href="/format/2311.15963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Pixels to Titles: Video Game Identification by Screenshots using  Convolutional Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Breve%2C+F">Fabricio Breve</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">This paper investigates video game identification through single screenshots,
utilizing five convolutional neural network (CNN) architectures (MobileNet,
DenseNet, EfficientNetB0, EfficientNetB2, and EfficientNetB3) across 22 home
console systems, spanning from Atari 2600 to PlayStation 5. Confirming the
hypothesis, CNNs autonomously extract image features, enabling the
identification of game titles from screenshots without additional features.
Using ImageNet pre-trained weights, EfficientNetB3 achieves the highest average
accuracy (74.51%), while DenseNet169 excels in 14 of the 22 systems. Employing
alternative initial weights from another screenshots dataset boosts accuracy
for EfficientNetB2 and EfficientNetB3, with the latter reaching a peak accuracy
of 76.36% and demonstrating reduced convergence epochs from 23.7 to 20.5 on
average. Overall, the combination of optimal architecture and weights attains
77.67% accuracy, primarily led by EfficientNetB3 in 19 systems. These findings
underscore the efficacy of CNNs in video game identification through
screenshots.
</p>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15964" title="Abstract">arXiv:2311.15964</a> [<a href="/pdf/2311.15964" title="Download PDF">pdf</a>, <a href="/format/2311.15964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Pre-training for Localized Instruction Generation of Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Batra%2C+A">Anil Batra</a>, 
<a href="/search/cs?searchtype=author&query=Moltisanti%2C+D">Davide Moltisanti</a>, 
<a href="/search/cs?searchtype=author&query=Sevilla-Lara%2C+L">Laura Sevilla-Lara</a>, 
<a href="/search/cs?searchtype=author&query=Rohrbach%2C+M">Marcus Rohrbach</a>, 
<a href="/search/cs?searchtype=author&query=Keller%2C+F">Frank Keller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Procedural videos show step-by-step demonstrations of tasks like recipe
preparation. Understanding such videos is challenging, involving the precise
localization of steps and the generation of textual instructions. Manually
annotating steps and writing instructions is costly, which limits the size of
current datasets and hinders effective learning. Leveraging large but noisy
video-transcript datasets for pre-training can boost performance, but demands
significant computational resources. Furthermore, transcripts contain
irrelevant content and exhibit style variation compared to instructions written
by human annotators. To mitigate both issues, we propose a technique,
Sieve-&amp;-Swap, to automatically curate a smaller dataset: (i) Sieve filters
irrelevant transcripts and (ii) Swap enhances the quality of the text
instruction by automatically replacing the transcripts with human-written
instructions from a text-only recipe dataset. The curated dataset, three orders
of magnitude smaller than current web-scale datasets, enables efficient
training of large-scale models with competitive performance. We complement our
Sieve-\&amp;-Swap approach with a Procedure Transformer (ProcX) for end-to-end step
localization and instruction generation for procedural videos. When this model
is pre-trained on our curated dataset, it achieves state-of-the-art performance
in zero-shot and finetuning settings on YouCook2 and Tasty, while using a
fraction of the computational resources.
</p>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15965" title="Abstract">arXiv:2311.15965</a> [<a href="/pdf/2311.15965" title="Download PDF">pdf</a>, <a href="/format/2311.15965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FALCON: Fairness Learning via Contrastive Attention Approach to  Continual Semantic Scene Understanding in Open World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Truong%2C+T">Thanh-Dat Truong</a>, 
<a href="/search/cs?searchtype=author&query=Prabhu%2C+U">Utsav Prabhu</a>, 
<a href="/search/cs?searchtype=author&query=Raj%2C+B">Bhiksha Raj</a>, 
<a href="/search/cs?searchtype=author&query=Cothren%2C+J">Jackson Cothren</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+K">Khoa Luu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Continual Learning in semantic scene segmentation aims to continually learn
new unseen classes in dynamic environments while maintaining previously learned
knowledge. Prior studies focused on modeling the catastrophic forgetting and
background shift challenges in continual learning. However, fairness, another
major challenge that causes unfair predictions leading to low performance among
major and minor classes, still needs to be well addressed. In addition, prior
methods have yet to model the unknown classes well, thus resulting in producing
non-discriminative features among unknown classes. This paper presents a novel
Fairness Learning via Contrastive Attention Approach to continual learning in
semantic scene understanding. In particular, we first introduce a new Fairness
Contrastive Clustering loss to address the problems of catastrophic forgetting
and fairness. Then, we propose an attention-based visual grammar approach to
effectively model the background shift problem and unknown classes, producing
better feature representations for different unknown classes. Through our
experiments, our proposed approach achieves State-of-the-Art (SOTA) performance
on different continual learning settings of three standard benchmarks, i.e.,
ADE20K, Cityscapes, and Pascal VOC. It promotes the fairness of the continual
semantic segmentation model.
</p>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15967" title="Abstract">arXiv:2311.15967</a> [<a href="/pdf/2311.15967" title="Download PDF">pdf</a>, <a href="/ps/2311.15967" title="Download PostScript">ps</a>, <a href="/format/2311.15967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anti-Gauss cubature rules with applications to Fredholm integral  equations on the square
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=de+Alba%2C+P+D">Patricia Diaz de Alba</a>, 
<a href="/search/math?searchtype=author&query=Fermo%2C+L">Luisa Fermo</a>, 
<a href="/search/math?searchtype=author&query=Rodriguez%2C+G">Giuseppe Rodriguez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The purpose of this paper is to develop the anti-Gauss cubature rule for
approximating integrals defined on the square whose integrand function may have
algebraic singularities at the boundaries. An application of such a rule to the
numerical solution of second-kind Fredholm integral equations is also explored.
The stability, convergence, and conditioning of the proposed Nystr\"om-type
method are studied. The numerical solution of the resulting dense linear system
is also investigated and several numerical tests are presented.
</p>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15971" title="Abstract">arXiv:2311.15971</a> [<a href="/pdf/2311.15971" title="Download PDF">pdf</a>, <a href="/format/2311.15971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supply Chain Due Diligence Risk Assessment for the EU: A Network  Approach to estimate expected effectiveness of the planned EU directive
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hurt%2C+J">Jan Hurt</a>, 
<a href="/search/cs?searchtype=author&query=Ledebur%2C+K">Katharina Ledebur</a>, 
<a href="/search/cs?searchtype=author&query=Meyer%2C+B">Birgit Meyer</a>, 
<a href="/search/cs?searchtype=author&query=Friesenbichler%2C+K">Klaus Friesenbichler</a>, 
<a href="/search/cs?searchtype=author&query=Gerschberger%2C+M">Markus Gerschberger</a>, 
<a href="/search/cs?searchtype=author&query=Thurner%2C+S">Stefan Thurner</a>, 
<a href="/search/cs?searchtype=author&query=Klimek%2C+P">Peter Klimek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Globalization has had undesirable effects on the labor standards embedded in
the products we consume. This paper proposes an ex-ante evaluation of supply
chain due diligence regulations, such as the EU Corporate Sustainable Due
Diligence Directive (CSDDD). We construct a full-scale network model derived
from structural business statistics of 30 million EU firms to quantify the
likelihood of links to firms potentially involved in human rights abuses in the
European supply chain. The 900 million supply links of these firms are modeled
in a way that is consistent with multiregional input-output data, EU import
data, and stylized facts of firm-level production networks. We find that this
network exhibits a small world effect with three degrees of separation, meaning
that most firms are no more than three steps away from each other in the
network. Consequently we find that about 8.5% of EU companies are at risk of
having child or forced labor in the first tier of their supply chains, about
82.4% are likely to have such offenders at the second tier and more than 99.1%
have such offenders at the third tier. We also profile companies by country,
sector, and size for the likelihood of having human rights violations or child
and forced labor violations at a given tier in their supply chain, revealing
considerable heterogeneity across EU companies. Our results show that supply
chain due diligence regulations that focus on monitoring individual
buyer-supplier links, as currently proposed in the CSDDD, are likely to be
ineffective due to a high degree of redundancy and the fact that individual
company value chains cannot be properly isolated from the global supply
network. Rather, to maximize cost-effectiveness without compromising due
diligence coverage, we suggest that regulations should focus on monitoring
individual suppliers.
</p>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15977" title="Abstract">arXiv:2311.15977</a> [<a href="/pdf/2311.15977" title="Download PDF">pdf</a>, <a href="/format/2311.15977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text2Loc: 3D Point Cloud Localization from Natural Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Letian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zifeng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Henriques%2C+J+F">Jo&#xe3;o F. Henriques</a>, 
<a href="/search/cs?searchtype=author&query=Cremers%2C+D">Daniel Cremers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We tackle the problem of 3D point cloud localization based on a few natural
linguistic descriptions and introduce a novel neural network, Text2Loc, that
fully interprets the semantic relationship between points and text. Text2Loc
follows a coarse-to-fine localization pipeline: text-submap global place
recognition, followed by fine localization. In global place recognition,
relational dynamics among each textual hint are captured in a hierarchical
transformer with max-pooling (HTM), whereas a balance between positive and
negative pairs is maintained using text-submap contrastive learning. Moreover,
we propose a novel matching-free fine localization method to further refine the
location predictions, which completely removes the need for complicated
text-instance matching and is lighter, faster, and more accurate than previous
methods. Extensive experiments show that Text2Loc improves the localization
accuracy by up to $2\times$ over the state-of-the-art on the KITTI360Pose
dataset. We will make the code publicly available.
</p>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15979" title="Abstract">arXiv:2311.15979</a> [<a href="/pdf/2311.15979" title="Download PDF">pdf</a>, <a href="/format/2311.15979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Soil Organic Carbon Estimation from Climate-related Features with Graph  Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Weiying Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Efremova%2C+N">Natalia Efremova</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Tackling Climate Change with Machine Learning: workshop at NeurIPS
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Soil organic carbon (SOC) plays a pivotal role in the global carbon cycle,
impacting climate dynamics and necessitating accurate estimation for
sustainable land and agricultural management. While traditional methods of SOC
estimation face resolution and accuracy challenges, recent technological
solutions harness remote sensing, machine learning, and high-resolution
satellite mapping. Graph Neural Networks (GNNs), especially when integrated
with positional encoders, can capture complex relationships between soil and
climate. Using the LUCAS database, this study compared four GNN operators in
the positional encoder framework. Results revealed that the PESAGE and
PETransformer models outperformed others in SOC estimation, indicating their
potential in capturing the complex relationship between SOC and climate
features. Our findings confirm the feasibility of applications of GNN
architectures in SOC prediction, establishing a framework for future
explorations of this topic with more advanced GNN models.
</p>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15980" title="Abstract">arXiv:2311.15980</a> [<a href="/pdf/2311.15980" title="Download PDF">pdf</a>, <a href="/format/2311.15980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Direct2.5: Diverse Text-to-3D Generation via Multi-view 2.5D Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yuanxun Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+T">Tian Fang</a>, 
<a href="/search/cs?searchtype=author&query=McKinnon%2C+D">David McKinnon</a>, 
<a href="/search/cs?searchtype=author&query=Tsin%2C+Y">Yanghai Tsin</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+L">Long Quan</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xun Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yao Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project webpage: <a href="https://nju-3dv.github.io/projects/direct25">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advances in generative AI have unveiled significant potential for the
creation of 3D content. However, current methods either apply a pre-trained 2D
diffusion model with the time-consuming score distillation sampling (SDS), or a
direct 3D diffusion model trained on limited 3D data losing generation
diversity. In this work, we approach the problem by employing a multi-view 2.5D
diffusion fine-tuned from a pre-trained 2D diffusion model. The multi-view 2.5D
diffusion directly models the structural distribution of 3D data, while still
maintaining the strong generalization ability of the original 2D diffusion
model, filling the gap between 2D diffusion-based and direct 3D diffusion-based
methods for 3D content generation. During inference, multi-view normal maps are
generated using the 2.5D diffusion, and a novel differentiable rasterization
scheme is introduced to fuse the almost consistent multi-view normal maps into
a consistent 3D model. We further design a normal-conditioned multi-view image
generation module for fast appearance generation given the 3D geometry. Our
method is a one-pass diffusion process and does not require any SDS
optimization as post-processing. We demonstrate through extensive experiments
that, our direct 2.5D generation with the specially-designed fusion scheme can
achieve diverse, mode-seeking-free, and high-fidelity 3D content generation in
only 10 seconds. Project page: https://nju-3dv.github.io/projects/direct25.
</p>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15983" title="Abstract">arXiv:2311.15983</a> [<a href="/pdf/2311.15983" title="Download PDF">pdf</a>, <a href="/format/2311.15983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparsify-then-Classify: From Internal Neurons of Large Language Models  To Efficient Text Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yilun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+D">Difan Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+A">Ashton Anderson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 5 figures, 8 tables Code available at <a href="https://github.com/difanj0713/Sparsify-then-Classify">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Among the many tasks that Large Language Models (LLMs) have revolutionized is
text classification. However, existing approaches for applying pretrained LLMs
to text classification predominantly rely on using single token outputs from
only the last layer of hidden states. As a result, they suffer from limitations
in efficiency, task-specificity, and interpretability. In our work, we
contribute an approach that uses all internal representations by employing
multiple pooling strategies on all activation and hidden states. Our novel
lightweight strategy, Sparsify-then-Classify (STC) first sparsifies
task-specific features layer-by-layer, then aggregates across layers for text
classification. STC can be applied as a seamless plug-and-play module on top of
existing LLMs. Our experiments on a comprehensive set of models and datasets
demonstrate that STC not only consistently improves the classification
performance of pretrained and fine-tuned models, but is also more efficient for
both training and inference, and is more intrinsically interpretable.
</p>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15990" title="Abstract">arXiv:2311.15990</a> [<a href="/pdf/2311.15990" title="Download PDF">pdf</a>, <a href="/format/2311.15990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Should We Learn Most Likely Functions or Parameters?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+S">Shikai Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Rudner%2C+T+G+J">Tim G. J. Rudner</a>, 
<a href="/search/cs?searchtype=author&query=Kapoor%2C+S">Sanyam Kapoor</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+A+G">Andrew Gordon Wilson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. Code available at <a href="https://github.com/activatedgeek/function-space-map">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Standard regularized training procedures correspond to maximizing a posterior
distribution over parameters, known as maximum a posteriori (MAP) estimation.
However, model parameters are of interest only insomuch as they combine with
the functional form of a model to provide a function that can make good
predictions. Moreover, the most likely parameters under the parameter posterior
do not generally correspond to the most likely function induced by the
parameter posterior. In fact, we can re-parametrize a model such that any
setting of parameters can maximize the parameter posterior. As an alternative,
we investigate the benefits and drawbacks of directly estimating the most
likely function implied by the model and the data. We show that this procedure
leads to pathological solutions when using neural networks and prove conditions
under which the procedure is well-behaved, as well as a scalable approximation.
Under these conditions, we find that function-space MAP estimation can lead to
flatter minima, better generalization, and improved robustness to overfitting.
</p>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15991" title="Abstract">arXiv:2311.15991</a> [<a href="/pdf/2311.15991" title="Download PDF">pdf</a>, <a href="/format/2311.15991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffAnt: Diffusion Models for Action Anticipation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zeyun Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chengzhi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+M">Manuel Martin</a>, 
<a href="/search/cs?searchtype=author&query=Voit%2C+M">Michael Voit</a>, 
<a href="/search/cs?searchtype=author&query=Gall%2C+J">Juergen Gall</a>, 
<a href="/search/cs?searchtype=author&query=Beyerer%2C+J">J&#xfc;rgen Beyerer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Anticipating future actions is inherently uncertain. Given an observed video
segment containing ongoing actions, multiple subsequent actions can plausibly
follow. This uncertainty becomes even larger when predicting far into the
future. However, the majority of existing action anticipation models adhere to
a deterministic approach, neglecting to account for future uncertainties. In
this work, we rethink action anticipation from a generative view, employing
diffusion models to capture different possible future actions. In this
framework, future actions are iteratively generated from standard Gaussian
noise in the latent space, conditioned on the observed video, and subsequently
transitioned into the action space. Extensive experiments on four benchmark
datasets, i.e., Breakfast, 50Salads, EpicKitchens, and EGTEA Gaze+, are
performed and the proposed method achieves superior or comparable results to
state-of-the-art methods, showing the effectiveness of a generative approach
for action anticipation. Our code and trained models will be published on
GitHub.
</p>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15993" title="Abstract">arXiv:2311.15993</a> [<a href="/pdf/2311.15993" title="Download PDF">pdf</a>, <a href="/format/2311.15993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified Batch Normalization: Identifying and Alleviating the Feature  Condensation in Batch Normalization and a Unified Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shaobo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangdong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Batch Normalization (BN) has become an essential technique in contemporary
neural network design, enhancing training stability. Specifically, BN employs
centering and scaling operations to standardize features along the batch
dimension and uses an affine transformation to recover features. Although
standard BN has shown its capability to improve deep neural network training
and convergence, it still exhibits inherent limitations in certain cases. Most
existing techniques that enhance BN consider a single or a few aspects of BN.
In this paper, we first identify problems with BN from a feature perspective
and explore that feature condensation exists in the learning when employing BN,
which negatively affects testing performance. To tackle this problem, we
propose a two-stage unified framework called Unified Batch Normalization (UBN).
In the first stage, we utilize a simple feature condensation threshold to
alleviate the feature condensation, which hinders inappropriate statistic
updates in normalization. In the second stage, we unify various normalization
variants to boost each component of BN. Our experimental results reveal that
UBN significantly enhances performance across different visual backbones and
notably expedites network training convergence, particularly in early training
stages. Notably, our method improved about 3% in top-1 accuracy on ImageNet
classification with large batch sizes, showing the effectiveness of our
approach in real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15994" title="Abstract">arXiv:2311.15994</a> [<a href="/pdf/2311.15994" title="Download PDF">pdf</a>, <a href="/format/2311.15994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversaral Doodles: Interpretable and Human-drawable Attacks Provide  Describable Insights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nara%2C+R">Ryoya Nara</a>, 
<a href="/search/cs?searchtype=author&query=Matsui%2C+Y">Yusuke Matsui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">DNN-based image classification models are susceptible to adversarial attacks.
Most previous adversarial attacks do not focus on the interpretability of the
generated adversarial examples, and we cannot gain insights into the mechanism
of the target classifier from the attacks. Therefore, we propose Adversarial
Doodles, which have interpretable shapes. We optimize black b\'ezier curves to
fool the target classifier by overlaying them onto the input image. By
introducing random perspective transformation and regularizing the doodled
area, we obtain compact attacks that cause misclassification even when humans
replicate them by hand. Adversarial doodles provide describable and intriguing
insights into the relationship between our attacks and the classifier's output.
We utilize adversarial doodles and discover the bias inherent in the target
classifier, such as "We add two strokes on its head, a triangle onto its body,
and two lines inside the triangle on a bird image. Then, the classifier
misclassifies the image as a butterfly."
</p>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15995" title="Abstract">arXiv:2311.15995</a> [<a href="/pdf/2311.15995" title="Download PDF">pdf</a>, <a href="/format/2311.15995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sensitivity-Based Layer Insertion for Residual and Feedforward Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herberg%2C+E">Evelyn Herberg</a>, 
<a href="/search/cs?searchtype=author&query=Herzog%2C+R">Roland Herzog</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6hne%2C+F">Frederik K&#xf6;hne</a>, 
<a href="/search/cs?searchtype=author&query=Kreis%2C+L">Leonie Kreis</a>, 
<a href="/search/cs?searchtype=author&query=Schiela%2C+A">Anton Schiela</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">The training of neural networks requires tedious and often manual tuning of
the network architecture. We propose a systematic method to insert new layers
during the training process, which eliminates the need to choose a fixed
network size before training. Our technique borrows techniques from constrained
optimization and is based on first-order sensitivity information of the
objective with respect to the virtual parameters that additional layers, if
inserted, would offer. We consider fully connected feedforward networks with
selected activation functions as well as residual neural networks. In numerical
experiments, the proposed sensitivity-based layer insertion technique exhibits
improved training decay, compared to not inserting the layer. Furthermore, the
computational effort is reduced in comparison to inserting the layer from the
beginning. The code is available at
\url{https://github.com/LeonieKreis/layer_insertion_sensitivity_based}.
</p>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15996" title="Abstract">arXiv:2311.15996</a> [<a href="/pdf/2311.15996" title="Download PDF">pdf</a>, <a href="/format/2311.15996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Closing the ODE-SDE gap in score-based diffusion models through the  Fokker-Planck equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deveney%2C+T">Teo Deveney</a>, 
<a href="/search/cs?searchtype=author&query=Stanczuk%2C+J">Jan Stanczuk</a>, 
<a href="/search/cs?searchtype=author&query=Kreusser%2C+L+M">Lisa Maria Kreusser</a>, 
<a href="/search/cs?searchtype=author&query=Budd%2C+C">Chris Budd</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6nlieb%2C+C">Carola-Bibiane Sch&#xf6;nlieb</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
<p class="mathjax">Score-based diffusion models have emerged as one of the most promising
frameworks for deep generative modelling, due to their state-of-the art
performance in many generation tasks while relying on mathematical foundations
such as stochastic differential equations (SDEs) and ordinary differential
equations (ODEs). Empirically, it has been reported that ODE based samples are
inferior to SDE based samples. In this paper we rigorously describe the range
of dynamics and approximations that arise when training score-based diffusion
models, including the true SDE dynamics, the neural approximations, the various
approximate particle dynamics that result, as well as their associated
Fokker--Planck equations and the neural network approximations of these
Fokker--Planck equations. We systematically analyse the difference between the
ODE and SDE dynamics of score-based diffusion models, and link it to an
associated Fokker--Planck equation. We derive a theoretical upper bound on the
Wasserstein 2-distance between the ODE- and SDE-induced distributions in terms
of a Fokker--Planck residual. We also show numerically that conventional
score-based diffusion models can exhibit significant differences between ODE-
and SDE-induced distributions which we demonstrate using explicit comparisons.
Moreover, we show numerically that reducing the Fokker--Planck residual by
adding it as an additional regularisation term leads to closing the gap between
ODE- and SDE-induced distributions. Our experiments suggest that this
regularisation can improve the distribution generated by the ODE, however that
this can come at the cost of degraded SDE sample quality.
</p>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15999" title="Abstract">arXiv:2311.15999</a> [<a href="/pdf/2311.15999" title="Download PDF">pdf</a>, <a href="/format/2311.15999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Microarchitectural Security of AWS Firecracker VMM for Serverless Cloud  Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weissman%2C+Z">Zane Weissman</a> (1), 
<a href="/search/cs?searchtype=author&query=Tiemann%2C+T">Thore Tiemann</a> (2), 
<a href="/search/cs?searchtype=author&query=Eisenbarth%2C+T">Thomas Eisenbarth</a> (2), 
<a href="/search/cs?searchtype=author&query=Sunar%2C+B">Berk Sunar</a> (1) ((1) Worcester Polytechnic Institute, (2) University of L&#xfc;beck)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Firecracker is a virtual machine manager (VMM) built by Amazon Web Services
(AWS) for serverless cloud platforms, services that run code for end users on a
per-task basis, automatically managing server infrastructure. Firecracker
provides fast and lightweight VMs and promises a combination of the speed of
containers, typically used to isolate small tasks, and the security of VMs,
which tend to provide greater isolation at the cost of performance. This
combination of security and efficiency, AWS claims, makes it not only possible
but safe to run thousands of user tasks from different users on the same
hardware, with the host system frequently switching between active tasks.
Though AWS states that microarchitectural attacks are included in their threat
model, this class of attacks directly relies on shared hardware, just as the
scalability of serverless computing relies on sharing hardware between
unprecedented numbers of users. In this work, we investigate how secure
Firecracker is against microarchitectural attacks. First, we review
Firecracker's stated isolation model and recommended best practices for
deployment, identify potential threat models for serverless platforms, and
analyze potential weak points. Then, we use microarchitectural attack
proof-of-concepts to test the isolation provided by Firecracker and find that
it offers little protection against Spectre or MDS attacks. We discover two
particularly concerning cases: 1) a Medusa variant that threatens Firecracker
VMs but not processes running outside them, and is not mitigated by defenses
recommended by AWS, and 2) a Spectre-PHT variant that remains exploitable even
if recommended countermeasures are in place and SMT is disabled in the system.
In summary, we show that AWS overstates the security inherent to the
Firecracker VMM and provides incomplete guidance for properly securing cloud
systems that use Firecracker.
</p>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16003" title="Abstract">arXiv:2311.16003</a> [<a href="/pdf/2311.16003" title="Download PDF">pdf</a>, <a href="/format/2311.16003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forecasting Auxiliary Energy Consumption for Electric Heavy-Duty  Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yuantao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhenkan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pashami%2C+S">Sepideh Pashami</a>, 
<a href="/search/cs?searchtype=author&query=Nowaczyk%2C+S">Slawomir Nowaczyk</a>, 
<a href="/search/cs?searchtype=author&query=Ydreskog%2C+H">Henrik Ydreskog</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Accurate energy consumption prediction is crucial for optimizing the
operation of electric commercial heavy-duty vehicles, e.g., route planning for
charging. Moreover, understanding why certain predictions are cast is paramount
for such a predictive model to gain user trust and be deployed in practice.
Since commercial vehicles operate differently as transportation tasks, ambient,
and drivers vary, a heterogeneous population is expected when building an AI
system for forecasting energy consumption. The dependencies between the input
features and the target values are expected to also differ across
sub-populations. One well-known example of such a statistical phenomenon is the
Simpson paradox. In this paper, we illustrate that such a setting poses a
challenge for existing XAI methods that produce global feature statistics, e.g.
LIME or SHAP, causing them to yield misleading results. We demonstrate a
potential solution by training multiple regression models on subsets of data.
It not only leads to superior regression performance but also more relevant and
consistent LIME explanations. Given that the employed groupings correspond to
relevant sub-populations, the associations between the input features and the
target values are consistent within each cluster but different across clusters.
Experiments on both synthetic and real-world datasets show that such splitting
of a complex problem into simpler ones yields better regression performance and
interpretability.
</p>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16008" title="Abstract">arXiv:2311.16008</a> [<a href="/pdf/2311.16008" title="Download PDF">pdf</a>, <a href="/format/2311.16008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Decentralized Aggregation for Federated Learning with Differential  Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=El-Kareem%2C+H+A">Hadeel Abd El-Kareem</a>, 
<a href="/search/cs?searchtype=author&query=Saleh%2C+A+E">Abd El-Moaty Saleh</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Vilas%2C+A">Ana Fern&#xe1;ndez-Vilas</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Veiga%2C+M">Manuel Fern&#xe1;ndez-Veiga</a>, 
<a href="/search/cs?searchtype=author&query=El-Sonbaty%2C+a">asser El-Sonbaty</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> PE-WASUN '22: Proceedings of the 19th ACM International Symposium
  on Performance Evaluation of Wireless Ad Hoc, Sensor, &amp; Ubiquitous
  NetworksOctober 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Nowadays, the ubiquitous usage of mobile devices and networks have raised
concerns about the loss of control over personal data and research advance
towards the trade-off between privacy and utility in scenarios that combine
exchange communications, big databases and distributed and collaborative (P2P)
Machine Learning techniques. On the other hand, although Federated Learning
(FL) provides some level of privacy by retaining the data at the local node,
which executes a local training to enrich a global model, this scenario is
still susceptible to privacy breaches as membership inference attacks. To
provide a stronger level of privacy, this research deploys an experimental
environment for FL with Differential Privacy (DP) using benchmark datasets. The
obtained results show that the election of parameters and techniques of DP is
central in the aforementioned trade-off between privacy and utility by means of
a classification example.
</p>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16017" title="Abstract">arXiv:2311.16017</a> [<a href="/pdf/2311.16017" title="Download PDF">pdf</a>, <a href="/format/2311.16017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoding Logic Errors: A Comparative Study on Bug Detection by Students  and Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=MacNeil%2C+S">Stephen MacNeil</a>, 
<a href="/search/cs?searchtype=author&query=Denny%2C+P">Paul Denny</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+A">Andrew Tran</a>, 
<a href="/search/cs?searchtype=author&query=Leinonen%2C+J">Juho Leinonen</a>, 
<a href="/search/cs?searchtype=author&query=Bernstein%2C+S">Seth Bernstein</a>, 
<a href="/search/cs?searchtype=author&query=Hellas%2C+A">Arto Hellas</a>, 
<a href="/search/cs?searchtype=author&query=Sarsa%2C+S">Sami Sarsa</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Joanne Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Identifying and resolving logic errors can be one of the most frustrating
challenges for novices programmers. Unlike syntax errors, for which a compiler
or interpreter can issue a message, logic errors can be subtle. In certain
conditions, buggy code may even exhibit correct behavior -- in other cases, the
issue might be about how a problem statement has been interpreted. Such errors
can be hard to spot when reading the code, and they can also at times be missed
by automated tests. There is great educational potential in automatically
detecting logic errors, especially when paired with suitable feedback for
novices. Large language models (LLMs) have recently demonstrated surprising
performance for a range of computing tasks, including generating and explaining
code. These capabilities are closely linked to code syntax, which aligns with
the next token prediction behavior of LLMs. On the other hand, logic errors
relate to the runtime performance of code and thus may not be as well suited to
analysis by LLMs. To explore this, we investigate the performance of two
popular LLMs, GPT-3 and GPT-4, for detecting and providing a novice-friendly
explanation of logic errors. We compare LLM performance with a large cohort of
introductory computing students $(n=964)$ solving the same error detection
task. Through a mixed-methods analysis of student and model responses, we
observe significant improvement in logic error identification between the
previous and current generation of LLMs, and find that both LLM generations
significantly outperform students. We outline how such models could be
integrated into computing education tools, and discuss their potential for
supporting students when learning programming.
</p>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16018" title="Abstract">arXiv:2311.16018</a> [<a href="/pdf/2311.16018" title="Download PDF">pdf</a>, <a href="/format/2311.16018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RIDE: Real-time Intrusion Detection via Explainable Machine Learning  Implemented in a Memristor Hardware Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingdi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Riem%2C+J">Joseph Riem</a>, 
<a href="/search/cs?searchtype=author&query=Adam%2C+G">Gina Adam</a>, 
<a href="/search/cs?searchtype=author&query=Bastian%2C+N+D">Nathaniel D. Bastian</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+T">Tian Lan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep Learning (DL) based methods have shown great promise in network
intrusion detection by identifying malicious network traffic behavior patterns
with high accuracy, but their applications to real-time, packet-level
detections in high-speed communication networks are challenging due to the high
computation time and resource requirements of Deep Neural Networks (DNNs), as
well as lack of explainability. To this end, we propose a packet-level network
intrusion detection solution that makes novel use of Recurrent Autoencoders to
integrate an arbitrary-length sequence of packets into a more compact joint
feature embedding, which is fed into a DNN-based classifier. To enable
explainability and support real-time detections at micro-second speed, we
further develop a Software-Hardware Co-Design approach to efficiently realize
the proposed solution by converting the learned detection policies into
decision trees and implementing them using an emerging architecture based on
memristor devices. By jointly optimizing associated software and hardware
constraints, we show that our approach leads to an extremely efficient,
real-time solution with high detection accuracy at the packet level. Evaluation
results on real-world datasets (e.g., UNSW and CIC-IDS datasets) demonstrate
nearly three-nines detection accuracy with a substantial speedup of nearly four
orders of magnitude.
</p>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16019" title="Abstract">arXiv:2311.16019</a> [<a href="/pdf/2311.16019" title="Download PDF">pdf</a>, <a href="/format/2311.16019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sketched and Truncated Polynomial Krylov Subspace Methods: Matrix  Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Palitta%2C+D">Davide Palitta</a>, 
<a href="/search/math?searchtype=author&query=Schweitzer%2C+M">Marcel Schweitzer</a>, 
<a href="/search/math?searchtype=author&query=Simoncini%2C+V">Valeria Simoncini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Thanks to its great potential in reducing both computational cost and memory
requirements, combining sketching and Krylov subspace techniques has attracted
a lot of attention in the recent literature on projection methods for linear
systems, matrix function approximations, and eigenvalue problems. Applying this
appealing strategy in the context of linear matrix equations turns out to be
far more involved than a straightforward generalization. These difficulties
include establishing well-posedness of the projected problem and deriving
possible error estimates depending on the sketching properties. Further
computational complications include the lack of a natural residual norm
estimate and of an explicit basis for the generated subspace. In this paper we
propose a new sketched-and-truncated polynomial Krylov subspace method for
Sylvester equations that aims to address all these issues. The potential of our
novel approach, in terms of both computational time and storage demand, is
illustrated with numerical experiments. Comparisons with a state-of-the-art
projection scheme based on rational Krylov subspaces are also included.
</p>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16021" title="Abstract">arXiv:2311.16021</a> [<a href="/pdf/2311.16021" title="Download PDF">pdf</a>, <a href="/format/2311.16021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scheduling and Communication Schemes for Decentralized Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdelghany%2C+B+A">Bahaa-Eldin Ali Abdelghany</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Vilas%2C+A">Ana Fern&#xe1;ndez-Vilas</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Veiga%2C+M">Manuel Fern&#xe1;ndez-Veiga</a>, 
<a href="/search/cs?searchtype=author&query=El-Bendary%2C+N">Nashwa El-Bendary</a>, 
<a href="/search/cs?searchtype=author&query=Hassan%2C+A+M">Ammar M. Hassan</a>, 
<a href="/search/cs?searchtype=author&query=Abdelmoez%2C+W+M">Walid M. Abdelmoez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32nd International Conference on Computer Theory and Applications (ICCTA), Alexandria, Egypt, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated learning (FL) is a distributed machine learning paradigm in which a
large number of clients coordinate with a central server to learn a model
without sharing their own training data. One central server is not enough, due
to problems of connectivity with clients. In this paper, a decentralized
federated learning (DFL) model with the stochastic gradient descent (SGD)
algorithm has been introduced, as a more scalable approach to improve the
learning performance in a network of agents with arbitrary topology. Three
scheduling policies for DFL have been proposed for communications between the
clients and the parallel servers, and the convergence, accuracy, and loss have
been tested in a totally decentralized mplementation of SGD. The experimental
results show that the proposed scheduling polices have an impact both on the
speed of convergence and in the final global model.
</p>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16023" title="Abstract">arXiv:2311.16023</a> [<a href="/pdf/2311.16023" title="Download PDF">pdf</a>, <a href="/format/2311.16023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative AI and US Intellectual Property Law
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poland%2C+C+M">Cherie M Poland</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The rapidity with which generative AI has been adopted and advanced has
raised legal and ethical questions related to the impact on artists rights,
content production, data collection, privacy, accuracy of information, and
intellectual property rights. Recent administrative and case law challenges
have shown that generative AI software systems do not have independent
intellectual property rights in the content that they generate. It remains to
be seen whether human content creators can retain their intellectual property
rights against generative AI software, its developers, operators, and owners
for the misappropriation of the work of human creatives, given the metes and
bounds of existing law. Early signs from various courts are mixed as to whether
and to what degree the results generated by AI models meet the legal standards
of infringement under existing law.
</p>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16026" title="Abstract">arXiv:2311.16026</a> [<a href="/pdf/2311.16026" title="Download PDF">pdf</a>, <a href="/format/2311.16026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Neural Framework for Generalized Causal Sensitivity Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frauen%2C+D">Dennis Frauen</a>, 
<a href="/search/cs?searchtype=author&query=Imrie%2C+F">Fergus Imrie</a>, 
<a href="/search/cs?searchtype=author&query=Curth%2C+A">Alicia Curth</a>, 
<a href="/search/cs?searchtype=author&query=Melnychuk%2C+V">Valentyn Melnychuk</a>, 
<a href="/search/cs?searchtype=author&query=Feuerriegel%2C+S">Stefan Feuerriegel</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Schaar%2C+M">Mihaela van der Schaar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Unobserved confounding is common in many applications, making causal
inference from observational data challenging. As a remedy, causal sensitivity
analysis is an important tool to draw causal conclusions under unobserved
confounding with mathematical guarantees. In this paper, we propose NeuralCSA,
a neural framework for generalized causal sensitivity analysis. Unlike previous
work, our framework is compatible with (i) a large class of sensitivity models,
including the marginal sensitivity model, f-sensitivity models, and Rosenbaum's
sensitivity model; (ii) different treatment types (i.e., binary and
continuous); and (iii) different causal queries, including (conditional)
average treatment effects and simultaneous effects on multiple outcomes. The
generality of \frameworkname is achieved by learning a latent distribution
shift that corresponds to a treatment intervention using two conditional
normalizing flows. We provide theoretical guarantees that NeuralCSA is able to
infer valid bounds on the causal query of interest and also demonstrate this
empirically using both simulated and real-world data.
</p>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16027" title="Abstract">arXiv:2311.16027</a> [<a href="/pdf/2311.16027" title="Download PDF">pdf</a>, <a href="/ps/2311.16027" title="Download PostScript">ps</a>, <a href="/format/2311.16027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An HCAI Methodological Framework: Putting It Into Action to Enable  Human-Centered AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zaifeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Dainoff%2C+M">Marvin Dainoff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Human-centered AI (HCAI), as a design philosophy, advocates prioritizing
humans in designing, developing, and deploying intelligent systems, aiming to
maximize the benefits of AI technology to humans and avoid its potential
adverse effects. While HCAI has gained momentum, the lack of guidance on
methodology in its implementation makes its adoption challenging. After
assessing the needs for a methodological framework for HCAI, this paper first
proposes a comprehensive and interdisciplinary HCAI methodological framework
integrated with seven components, including design goals, design principles,
implementation approaches, design paradigms, interdisciplinary teams, methods,
and processes. THe implications of the framework are also discussed. This paper
also presents a "three-layer" approach to facilitate the implementation of the
framework. We believe the proposed framework is systematic and executable,
which can overcome the weaknesses in current frameworks and the challenges
currently faced in implementing HCAI. Thus, the framework can help put it into
action to develop, transfer, and implement HCAI in practice, eventually
enabling the design, development, and deployment of HCAI-based intelligent
systems.
</p>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16030" title="Abstract">arXiv:2311.16030</a> [<a href="/pdf/2311.16030" title="Download PDF">pdf</a>, <a href="/format/2311.16030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning-Enhanced Aircraft Landing Scheduling under  Uncertainties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pang%2C+Y">Yutian Pang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Peng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jueming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yongming Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper addresses aircraft delays, emphasizing their impact on safety and
financial losses. To mitigate these issues, an innovative machine learning
(ML)-enhanced landing scheduling methodology is proposed, aiming to improve
automation and safety. Analyzing flight arrival delay scenarios reveals strong
multimodal distributions and clusters in arrival flight time durations. A
multi-stage conditional ML predictor enhances separation time prediction based
on flight events. ML predictions are then integrated as safety constraints in a
time-constrained traveling salesman problem formulation, solved using
mixed-integer linear programming (MILP). Historical flight recordings and model
predictions address uncertainties between successive flights, ensuring
reliability. The proposed method is validated using real-world data from the
Atlanta Air Route Traffic Control Center (ARTCC ZTL). Case studies demonstrate
an average 17.2% reduction in total landing time compared to the
First-Come-First-Served (FCFS) rule. Unlike FCFS, the proposed methodology
considers uncertainties, instilling confidence in scheduling. The study
concludes with remarks and outlines future research directions.
</p>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16034" title="Abstract">arXiv:2311.16034</a> [<a href="/pdf/2311.16034" title="Download PDF">pdf</a>, <a href="/ps/2311.16034" title="Download PostScript">ps</a>, <a href="/format/2311.16034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Application of Diagnostic Test Methods To The Classification Of Time  Series With Discrete Values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gevorgyan%2C+A">Artyom Gevorgyan</a>, 
<a href="/search/cs?searchtype=author&query=Gevorgyan%2C+A">Albert Gevorgyan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">Discrete-value time series are sequences of measurements where each
measurement is a discrete (categorical or integer) value. These time series are
widely used in various fields, and their classification and clustering are
essential for data analysis. This article presents the possibility of applying
diagnostic test methods to such time series and estimates the probability of
finding ``matching tests''.
</p>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16037" title="Abstract">arXiv:2311.16037</a> [<a href="/pdf/2311.16037" title="Download PDF">pdf</a>, <a href="/format/2311.16037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GaussianEditor: Editing 3D Gaussians Delicately with Text Instructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Jiemin Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaopeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lingxi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qi Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://GaussianEditor.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Recently, impressive results have been achieved in 3D scene editing with text
instructions based on a 2D diffusion model. However, current diffusion models
primarily generate images by predicting noise in the latent space, and the
editing is usually applied to the whole image, which makes it challenging to
perform delicate, especially localized, editing for 3D scenes. Inspired by
recent 3D Gaussian splatting, we propose a systematic framework, named
GaussianEditor, to edit 3D scenes delicately via 3D Gaussians with text
instructions. Benefiting from the explicit property of 3D Gaussians, we design
a series of techniques to achieve delicate editing. Specifically, we first
extract the region of interest (RoI) corresponding to the text instruction,
aligning it to 3D Gaussians. The Gaussian RoI is further used to control the
editing process. Our framework can achieve more delicate and precise editing of
3D scenes than previous methods while enjoying much faster training speed, i.e.
within 20 minutes on a single V100 GPU, more than twice as fast as
Instruct-NeRF2NeRF (45 minutes -- 2 hours).
</p>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16038" title="Abstract">arXiv:2311.16038</a> [<a href="/pdf/2311.16038" title="Download PDF">pdf</a>, <a href="/format/2311.16038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OccWorld: Learning a 3D Occupancy World Model for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Wenzhao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weiliang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuanhui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Borui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yueqi Duan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiwen Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at: <a href="https://github.com/wzzheng/OccWorld">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Understanding how the 3D scene evolves is vital for making decisions in
autonomous driving. Most existing methods achieve this by predicting the
movements of object boxes, which cannot capture more fine-grained scene
information. In this paper, we explore a new framework of learning a world
model, OccWorld, in the 3D Occupancy space to simultaneously predict the
movement of the ego car and the evolution of the surrounding scenes. We propose
to learn a world model based on 3D occupancy rather than 3D bounding boxes and
segmentation maps for three reasons: 1) expressiveness. 3D occupancy can
describe the more fine-grained 3D structure of the scene; 2) efficiency. 3D
occupancy is more economical to obtain (e.g., from sparse LiDAR points). 3)
versatility. 3D occupancy can adapt to both vision and LiDAR. To facilitate the
modeling of the world evolution, we learn a reconstruction-based scene
tokenizer on the 3D occupancy to obtain discrete scene tokens to describe the
surrounding scenes. We then adopt a GPT-like spatial-temporal generative
transformer to generate subsequent scene and ego tokens to decode the future
occupancy and ego trajectory. Extensive experiments on the widely used nuScenes
benchmark demonstrate the ability of OccWorld to effectively model the
evolution of the driving scenes. OccWorld also produces competitive planning
results without using instance and map supervision. Code:
https://github.com/wzzheng/OccWorld.
</p>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16042" title="Abstract">arXiv:2311.16042</a> [<a href="/pdf/2311.16042" title="Download PDF">pdf</a>, <a href="/format/2311.16042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly-Supervised 3D Reconstruction of Clothed Humans via Normal Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jane Wu</a>, 
<a href="/search/cs?searchtype=author&query=Thomas%2C+D">Diego Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Fedkiw%2C+R">Ronald Fedkiw</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a novel deep learning-based approach to the 3D reconstruction of
clothed humans using weak supervision via 2D normal maps. Given a single RGB
image or multiview images, our network infers a signed distance function (SDF)
discretized on a tetrahedral mesh surrounding the body in a rest pose.
Subsequently, inferred pose and camera parameters are used to generate a normal
map from the SDF. A key aspect of our approach is the use of Marching
Tetrahedra to (uniquely) compute a triangulated surface from the SDF on the
tetrahedral mesh, facilitating straightforward differentiation (and thus
backpropagation). Thus, given only ground truth normal maps (with no volumetric
information ground truth information), we can train the network to produce SDF
values from corresponding RGB images. Optionally, an additional multiview loss
leads to improved results. We demonstrate the efficacy of our approach for both
network inference and 3D reconstruction.
</p>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16043" title="Abstract">arXiv:2311.16043</a> [<a href="/pdf/2311.16043" title="Download PDF">pdf</a>, <a href="/format/2311.16043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relightable 3D Gaussian: Real-time Point Cloud Relighting with BRDF  Decomposition and Ray Tracing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jian Gao</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+C">Chun Gu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Youtian Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xun Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yao Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We present a novel differentiable point-based rendering framework for
material and lighting decomposition from multi-view images, enabling editing,
ray-tracing, and real-time relighting of the 3D point cloud. Specifically, a 3D
scene is represented as a set of relightable 3D Gaussian points, where each
point is additionally associated with a normal direction, BRDF parameters, and
incident lights from different directions. To achieve robust lighting
estimation, we further divide incident lights of each point into global and
local components, as well as view-dependent visibilities. The 3D scene is
optimized through the 3D Gaussian Splatting technique while BRDF and lighting
are decomposed by physically-based differentiable rendering. Moreover, we
introduce an innovative point-based ray-tracing approach based on the bounding
volume hierarchy for efficient visibility baking, enabling real-time rendering
and relighting of 3D Gaussian points with accurate shadow effects. Extensive
experiments demonstrate improved BRDF estimation and novel view rendering
results compared to state-of-the-art material estimation approaches. Our
framework showcases the potential to revolutionize the mesh-based graphics
pipeline with a relightable, traceable, and editable rendering pipeline solely
based on point cloud. Project
page:https://nju-3dv.github.io/projects/Relightable3DGaussian/.
</p>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16045" title="Abstract">arXiv:2311.16045</a> [<a href="/pdf/2311.16045" title="Download PDF">pdf</a>, <a href="/format/2311.16045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatio-temporal Lie-Poisson discretization for incompressible  magnetohydrodynamics on the sphere
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Modin%2C+K">Klas Modin</a>, 
<a href="/search/math?searchtype=author&query=Roop%2C+M">Michael Roop</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph); Differential Geometry (math.DG)

</div>
<p class="mathjax">We give a structure preserving spatio-temporal discretization for
incompressible magnetohydrodynamics (MHD) on the sphere. Discretization in
space is based on the theory of geometric quantization, which yields a
spatially discretized analogue of the MHD equations as a finite-dimensional
Lie--Poisson system on the dual of the magnetic extension Lie algebra
$\mathfrak{f}=\mathfrak{su}(N)\ltimes\mathfrak{su}(N)^{*}$. We also give
accompanying structure preserving time discretizations for Lie--Poisson systems
on the dual of semidirect product Lie algebras of the form
$\mathfrak{f}=\mathfrak{g}\ltimes\mathfrak{g^{*}}$, where $\mathfrak{g}$ is a
$J$-quadratic Lie algebra. Critically, the time integration method is free of
computationally costly matrix exponentials. The full method preserves the
underlying geometry, namely the Lie--Poisson structure and all the Casimirs,
and nearly preserves the Hamiltonian function in the sense of backward error
analysis. To showcase the method, we apply it to two models for magnetic
fluids: incompressible magnetohydrodynamics and Hazeltine's model. For the
latter, our simulations reveal the formation of large scale vortex condensates,
indicating a backward energy cascade analogous to two-dimensional turbulence.
</p>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16051" title="Abstract">arXiv:2311.16051</a> [<a href="/pdf/2311.16051" title="Download PDF">pdf</a>, <a href="/format/2311.16051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Impact of Personalized Value Alignment in Human-Robot  Interaction: Insights into Trust and Team Performance Outcomes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhat%2C+S">Shreyas Bhat</a>, 
<a href="/search/cs?searchtype=author&query=Lyons%2C+J+B">Joseph B. Lyons</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Cong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X+J">X. Jessie Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures, to be published in ACM/IEEE International Conference on Human Robot Interaction. arXiv admin note: text overlap with <a href="/abs/2309.05179">arXiv:2309.05179</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper examines the effect of real-time, personalized alignment of a
robot's reward function to the human's values on trust and team performance. We
present and compare three distinct robot interaction strategies: a non-learner
strategy where the robot presumes the human's reward function mirrors its own,
a non-adaptive-learner strategy in which the robot learns the human's reward
function for trust estimation and human behavior modeling, but still optimizes
its own reward function, and an adaptive-learner strategy in which the robot
learns the human's reward function and adopts it as its own. Two human-subject
experiments with a total number of 54 participants were conducted. In both
experiments, the human-robot team searches for potential threats in a town. The
team sequentially goes through search sites to look for threats. We model the
interaction between the human and the robot as a trust-aware Markov Decision
Process (trust-aware MDP) and use Bayesian Inverse Reinforcement Learning (IRL)
to estimate the reward weights of the human as they interact with the robot. In
Experiment 1, we start our learning algorithm with an informed prior of the
human's values/goals. In Experiment 2, we start the learning algorithm with an
uninformed prior. Results indicate that when starting with a good informed
prior, personalized value alignment does not seem to benefit trust or team
performance. On the other hand, when an informed prior is unavailable,
alignment to the human's values leads to high trust and higher perceived
performance while maintaining the same objective team performance.
</p>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16052" title="Abstract">arXiv:2311.16052</a> [<a href="/pdf/2311.16052" title="Download PDF">pdf</a>, <a href="/format/2311.16052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Attribute Variations in Style-based GANs using Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parihar%2C+R">Rishubh Parihar</a>, 
<a href="/search/cs?searchtype=author&query=Balaji%2C+P">Prasanna Balaji</a>, 
<a href="/search/cs?searchtype=author&query=Magazine%2C+R">Raghav Magazine</a>, 
<a href="/search/cs?searchtype=author&query=Vora%2C+S">Sarthak Vora</a>, 
<a href="/search/cs?searchtype=author&query=Karmali%2C+T">Tejan Karmali</a>, 
<a href="/search/cs?searchtype=author&query=Jampani%2C+V">Varun Jampani</a>, 
<a href="/search/cs?searchtype=author&query=Babu%2C+R+V">R. Venkatesh Babu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Neurips Workshop on Diffusion Models 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing attribute editing methods treat semantic attributes as binary,
resulting in a single edit per attribute. However, attributes such as
eyeglasses, smiles, or hairstyles exhibit a vast range of diversity. In this
work, we formulate the task of \textit{diverse attribute editing} by modeling
the multidimensional nature of attribute edits. This enables users to generate
multiple plausible edits per attribute. We capitalize on disentangled latent
spaces of pretrained GANs and train a Denoising Diffusion Probabilistic Model
(DDPM) to learn the latent distribution for diverse edits. Specifically, we
train DDPM over a dataset of edit latent directions obtained by embedding image
pairs with a single attribute change. This leads to latent subspaces that
enable diverse attribute editing. Applying diffusion in the highly compressed
latent space allows us to model rich distributions of edits within limited
computational resources. Through extensive qualitative and quantitative
experiments conducted across a range of datasets, we demonstrate the
effectiveness of our approach for diverse attribute editing. We also showcase
the results of our method applied for 3D editing of various face attributes.
</p>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16054" title="Abstract">arXiv:2311.16054</a> [<a href="/pdf/2311.16054" title="Download PDF">pdf</a>, <a href="/format/2311.16054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metric Space Magnitude for Evaluating Unsupervised Representation  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Limbeck%2C+K">Katharina Limbeck</a>, 
<a href="/search/cs?searchtype=author&query=Andreeva%2C+R">Rayna Andreeva</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+R">Rik Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Rieck%2C+B">Bastian Rieck</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Geometric Topology (math.GT); Machine Learning (stat.ML)

</div>
<p class="mathjax">The magnitude of a metric space was recently established as a novel
invariant, providing a measure of the `effective size' of a space across
multiple scales. By capturing both geometrical and topological properties of
data, magnitude is poised to address challenges in unsupervised representation
learning tasks. We formalise a novel notion of dissimilarity between magnitude
functions of finite metric spaces and use them to derive a quality measure for
dimensionality reduction tasks. Our measure is provably stable under
perturbations of the data, can be efficiently calculated, and enables a
rigorous multi-scale comparison of embeddings. We show the utility of our
measure in an experimental suite that comprises different domains and tasks,
including the comparison of data visualisations.
</p>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16060" title="Abstract">arXiv:2311.16060</a> [<a href="/pdf/2311.16060" title="Download PDF">pdf</a>, <a href="/format/2311.16060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffSLVA: Harnessing Diffusion Models for Sign Language Video  Anonymization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+Z">Zhaoyang Xia</a>, 
<a href="/search/cs?searchtype=author&query=Neidle%2C+C">Carol Neidle</a>, 
<a href="/search/cs?searchtype=author&query=Metaxas%2C+D+N">Dimitris N. Metaxas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project webpage: <a href="https://github.com/Jeffery9707/DiffSLVA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Since American Sign Language (ASL) has no standard written form, Deaf signers
frequently share videos in order to communicate in their native language.
However, since both hands and face convey critical linguistic information in
signed languages, sign language videos cannot preserve signer privacy. While
signers have expressed interest, for a variety of applications, in sign
language video anonymization that would effectively preserve linguistic
content, attempts to develop such technology have had limited success, given
the complexity of hand movements and facial expressions. Existing approaches
rely predominantly on precise pose estimations of the signer in video footage
and often require sign language video datasets for training. These requirements
prevent them from processing videos 'in the wild,' in part because of the
limited diversity present in current sign language video datasets. To address
these limitations, our research introduces DiffSLVA, a novel methodology that
utilizes pre-trained large-scale diffusion models for zero-shot text-guided
sign language video anonymization. We incorporate ControlNet, which leverages
low-level image features such as HED (Holistically-Nested Edge Detection)
edges, to circumvent the need for pose estimation. Additionally, we develop a
specialized module dedicated to capturing facial expressions, which are
critical for conveying essential linguistic information in signed languages. We
then combine the above methods to achieve anonymization that better preserves
the essential linguistic content of the original signer. This innovative
methodology makes possible, for the first time, sign language video
anonymization that could be used for real-world applications, which would offer
significant benefits to the Deaf and Hard-of-Hearing communities. We
demonstrate the effectiveness of our approach with a series of signer
anonymization experiments.
</p>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16062" title="Abstract">arXiv:2311.16062</a> [<a href="/pdf/2311.16062" title="Download PDF">pdf</a>, <a href="/format/2311.16062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local Differentially Private Heavy Hitter Detection in Data Streams with  Bounded Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaochen Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiran Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+J">Jian Lou</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yuan Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+K">Kui Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Top-$k$ frequent items detection is a fundamental task in data stream mining.
Many promising solutions are proposed to improve memory efficiency while still
maintaining high accuracy for detecting the Top-$k$ items. Despite the memory
efficiency concern, the users could suffer from privacy loss if participating
in the task without proper protection, since their contributed local data
streams may continually leak sensitive individual information. However, most
existing works solely focus on addressing either the memory-efficiency problem
or the privacy concerns but seldom jointly, which cannot achieve a satisfactory
tradeoff between memory efficiency, privacy protection, and detection accuracy.
<br />In this paper, we present a novel framework HG-LDP to achieve accurate
Top-$k$ item detection at bounded memory expense, while providing rigorous
local differential privacy (LDP) protection. Specifically, we identify two key
challenges naturally arising in the task, which reveal that directly applying
existing LDP techniques will lead to an inferior ``accuracy-privacy-memory
efficiency'' tradeoff. Therefore, we instantiate three advanced schemes under
the framework by designing novel LDP randomization methods, which address the
hurdles caused by the large size of the item domain and by the limited space of
the memory. We conduct comprehensive experiments on both synthetic and
real-world datasets to show that the proposed advanced schemes achieve a
superior ``accuracy-privacy-memory efficiency'' tradeoff, saving $2300\times$
memory over baseline methods when the item domain size is $41,270$. Our code is
open-sourced via the link.
</p>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16065" title="Abstract">arXiv:2311.16065</a> [<a href="/pdf/2311.16065" title="Download PDF">pdf</a>, <a href="/format/2311.16065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Vulnerability of Federated Learning: A Learning Algorithm  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xianghua Xie</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Hanchi Ren</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jingjing Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://github.com/Rand2AI/Awesome-Vulnerability-of-Federated-Learning">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This review paper takes a comprehensive look at malicious attacks against FL,
categorizing them from new perspectives on attack origins and targets, and
providing insights into their methodology and impact. In this survey, we focus
on threat models targeting the learning process of FL systems. Based on the
source and target of the attack, we categorize existing threat models into four
types, Data to Model (D2M), Model to Data (M2D), Model to Model (M2M) and
composite attacks. For each attack type, we discuss the defense strategies
proposed, highlighting their effectiveness, assumptions and potential areas for
improvement. Defense strategies have evolved from using a singular metric to
excluding malicious clients, to employing a multifaceted approach examining
client models at various phases. In this survey paper, our research indicates
that the to-learn data, the learning gradients, and the learned model at
different stages all can be manipulated to initiate malicious attacks that
range from undermining model performance, reconstructing private local data,
and to inserting backdoors. We have also seen these threat are becoming more
insidious. While earlier studies typically amplified malicious gradients,
recent endeavors subtly alter the least significant weights in local models to
bypass defense measures. This literature review provides a holistic
understanding of the current FL threat landscape and highlights the importance
of developing robust, efficient, and privacy-preserving defenses to ensure the
safe and trusted adoption of FL in real-world applications.
</p>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16075" title="Abstract">arXiv:2311.16075</a> [<a href="/pdf/2311.16075" title="Download PDF">pdf</a>, <a href="/ps/2311.16075" title="Download PostScript">ps</a>, <a href="/format/2311.16075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BioLORD-2023: Semantic Textual Representations Fusing LLM and Clinical  Knowledge Graph Insights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Remy%2C+F">Fran&#xe7;ois Remy</a>, 
<a href="/search/cs?searchtype=author&query=Demuynck%2C+K">Kris Demuynck</a>, 
<a href="/search/cs?searchtype=author&query=Demeester%2C+T">Thomas Demeester</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint of upcoming journal article
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">In this study, we investigate the potential of Large Language Models to
complement biomedical knowledge graphs in the training of semantic models for
the biomedical and clinical domains. Drawing on the wealth of the UMLS
knowledge graph and harnessing cutting-edge Large Language Models, we propose a
new state-of-the-art approach for obtaining high-fidelity representations of
biomedical concepts and sentences, consisting of three steps: an improved
contrastive learning phase, a novel self-distillation phase, and a weight
averaging phase. Through rigorous evaluations via the extensive BioLORD testing
suite and diverse downstream tasks, we demonstrate consistent and substantial
performance improvements over the previous state of the art (e.g. +2pts on
MedSTS, +2.5pts on MedNLI-S, +6.1pts on EHR-Rel-B). Besides our new
state-of-the-art biomedical model for English, we also distill and release a
multilingual model compatible with 50+ languages and finetuned on 7 European
languages. Many clinical pipelines can benefit from our latest models. Our new
multilingual model enables a range of languages to benefit from our
advancements in biomedical semantic representation learning, opening a new
avenue for bioinformatics researchers around the world. As a result, we hope to
see BioLORD-2023 becoming a precious tool for future biomedical applications.
</p>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16077" title="Abstract">arXiv:2311.16077</a> [<a href="/pdf/2311.16077" title="Download PDF">pdf</a>, <a href="/ps/2311.16077" title="Download PostScript">ps</a>, <a href="/format/2311.16077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finite elements for symmetric and traceless tensors in three dimensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hu%2C+K">Kaibo Hu</a>, 
<a href="/search/math?searchtype=author&query=Lin%2C+T">Ting Lin</a>, 
<a href="/search/math?searchtype=author&query=Shi%2C+B">Bowen Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We construct a family of finite element sub-complexes of the conformal
complex on tetrahedral meshes. This complex includes vector fields and
symmetric and traceless tensor fields, interlinked through the conformal
Killing operator, the linearized Cotton-York operator, and the divergence
operator, respectively. This leads to discrete versions of transverse traceless
(TT) tensors and York splits in general relativity. We provide bubble complexes
and investigate supersmoothness to facilitate the construction. We show the
exactness of the finite element complex on contractible domains.
</p>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16079" title="Abstract">arXiv:2311.16079</a> [<a href="/pdf/2311.16079" title="Download PDF">pdf</a>, <a href="/format/2311.16079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MEDITRON-70B: Scaling Medical Pretraining for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zeming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cano%2C+A+H">Alejandro Hern&#xe1;ndez Cano</a>, 
<a href="/search/cs?searchtype=author&query=Romanou%2C+A">Angelika Romanou</a>, 
<a href="/search/cs?searchtype=author&query=Bonnet%2C+A">Antoine Bonnet</a>, 
<a href="/search/cs?searchtype=author&query=Matoba%2C+K">Kyle Matoba</a>, 
<a href="/search/cs?searchtype=author&query=Salvi%2C+F">Francesco Salvi</a>, 
<a href="/search/cs?searchtype=author&query=Pagliardini%2C+M">Matteo Pagliardini</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Simin Fan</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6pf%2C+A">Andreas K&#xf6;pf</a>, 
<a href="/search/cs?searchtype=author&query=Mohtashami%2C+A">Amirkeivan Mohtashami</a>, 
<a href="/search/cs?searchtype=author&query=Sallinen%2C+A">Alexandre Sallinen</a>, 
<a href="/search/cs?searchtype=author&query=Sakhaeirad%2C+A">Alireza Sakhaeirad</a>, 
<a href="/search/cs?searchtype=author&query=Swamy%2C+V">Vinitra Swamy</a>, 
<a href="/search/cs?searchtype=author&query=Krawczuk%2C+I">Igor Krawczuk</a>, 
<a href="/search/cs?searchtype=author&query=Bayazit%2C+D">Deniz Bayazit</a>, 
<a href="/search/cs?searchtype=author&query=Marmet%2C+A">Axel Marmet</a>, 
<a href="/search/cs?searchtype=author&query=Montariol%2C+S">Syrielle Montariol</a>, 
<a href="/search/cs?searchtype=author&query=Hartley%2C+M">Mary-Anne Hartley</a>, 
<a href="/search/cs?searchtype=author&query=Jaggi%2C+M">Martin Jaggi</a>, 
<a href="/search/cs?searchtype=author&query=Bosselut%2C+A">Antoine Bosselut</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) can potentially democratize access to medical
knowledge. While many efforts have been made to harness and improve LLMs'
medical knowledge and reasoning capacities, the resulting models are either
closed-source (e.g., PaLM, GPT-4) or limited in scale (&lt;= 13B parameters),
which restricts their abilities. In this work, we improve access to large-scale
medical LLMs by releasing MEDITRON: a suite of open-source LLMs with 7B and 70B
parameters adapted to the medical domain. MEDITRON builds on Llama-2 (through
our adaptation of Nvidia's Megatron-LM distributed trainer), and extends
pretraining on a comprehensively curated medical corpus, including selected
PubMed articles, abstracts, and internationally-recognized medical guidelines.
Evaluations using four major medical benchmarks show significant performance
gains over several state-of-the-art baselines before and after task-specific
finetuning. Overall, MEDITRON achieves a 6% absolute performance gain over the
best public baseline in its parameter class and 3% over the strongest baseline
we finetuned from Llama-2. Compared to closed-source LLMs, MEDITRON-70B
outperforms GPT-3.5 and Med-PaLM and is within 5% of GPT-4 and 10% of
Med-PaLM-2. We release our code for curating the medical pretraining corpus and
the MEDITRON model weights to drive open-source development of more capable
medical LLMs.
</p>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16081" title="Abstract">arXiv:2311.16081</a> [<a href="/pdf/2311.16081" title="Download PDF">pdf</a>, <a href="/format/2311.16081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViT-Lens-2: Gateway to Omni-modal Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+W">Weixian Lei</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yixiao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+K">Kun Yi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+D">Difei Gao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Dylan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yuying Ge</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is a follow-up of "ViT-Lens: Towards Omni-modal Representations". arXiv admin note: text overlap with <a href="/abs/2308.10185">arXiv:2308.10185</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Aiming to advance AI agents, large foundation models significantly improve
reasoning and instruction execution, yet the current focus on vision and
language neglects the potential of perceiving diverse modalities in open-world
environments. However, the success of data-driven vision and language models is
costly or even infeasible to be reproduced for rare modalities. In this paper,
we present ViT-Lens-2 that facilitates efficient omni-modal representation
learning by perceiving novel modalities with a pretrained ViT and aligning them
to a pre-defined space. Specifically, the modality-specific lens is tuned to
project any-modal signals to an intermediate embedding space, which are then
processed by a strong ViT with pre-trained visual knowledge. The encoded
representations are optimized toward aligning with the modal-independent space,
pre-defined by off-the-shelf foundation models. ViT-Lens-2 provides a unified
solution for representation learning of increasing modalities with two
appealing advantages: (i) Unlocking the great potential of pretrained ViTs to
novel modalities effectively with efficient data regime; (ii) Enabling emergent
downstream capabilities through modality alignment and shared ViT parameters.
We tailor ViT-Lens-2 to learn representations for 3D point cloud, depth, audio,
tactile and EEG, and set new state-of-the-art results across various
understanding tasks, such as zero-shot classification. By seamlessly
integrating ViT-Lens-2 into Multimodal Foundation Models, we enable
Any-modality to Text and Image Generation in a zero-shot manner. Code and
models are available at https://github.com/TencentARC/ViT-Lens.
</p>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16083" title="Abstract">arXiv:2311.16083</a> [<a href="/pdf/2311.16083" title="Download PDF">pdf</a>, <a href="/format/2311.16083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BERT Goes Off-Topic: Investigating the Domain Transfer Challenge using  Genre Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roussinov%2C+D">Dmitri Roussinov</a>, 
<a href="/search/cs?searchtype=author&query=Sharoff%2C+S">Serge Sharoff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at EMNLP'2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">While performance of many text classification tasks has been recently
improved due to Pre-trained Language Models (PLMs), in this paper we show that
they still suffer from a performance gap when the underlying distribution of
topics changes. For example, a genre classifier trained on \textit{political}
topics often fails when tested on documents about \textit{sport} or
\textit{medicine}. In this work, we quantify this phenomenon empirically with a
large corpus and a large set of topics. Consequently, we verify that domain
transfer remains challenging both for classic PLMs, such as BERT, and for
modern large models, such as GPT-3. We also suggest and successfully test a
possible remedy: after augmenting the training dataset with
topically-controlled synthetic texts, the F1 score improves by up to 50\% for
some topics, nearing on-topic training results, while others show little to no
improvement. While our empirical results focus on genre classification, our
methodology is applicable to other classification tasks such as gender,
authorship, or sentiment classification. The code and data to replicate the
experiments are available at https://github.com/dminus1/genre
</p>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16086" title="Abstract">arXiv:2311.16086</a> [<a href="/pdf/2311.16086" title="Download PDF">pdf</a>, <a href="/format/2311.16086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAST: Model-Agnostic Sparsified Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Demidovich%2C+Y">Yury Demidovich</a>, 
<a href="/search/cs?searchtype=author&query=Malinovsky%2C+G">Grigory Malinovsky</a>, 
<a href="/search/cs?searchtype=author&query=Shulgin%2C+E">Egor Shulgin</a>, 
<a href="/search/cs?searchtype=author&query=Richt%C3%A1rik%2C+P">Peter Richt&#xe1;rik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 58 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC)

</div>
<p class="mathjax">We introduce a novel optimization problem formulation that departs from the
conventional way of minimizing machine learning model loss as a black-box
function. Unlike traditional formulations, the proposed approach explicitly
incorporates an initially pre-trained model and random sketch operators,
allowing for sparsification of both the model and gradient during training. We
establish insightful properties of the proposed objective function and
highlight its connections to the standard formulation. Furthermore, we present
several variants of the Stochastic Gradient Descent (SGD) method adapted to the
new problem formulation, including SGD with general sampling, a distributed
version, and SGD with variance reduction techniques. We achieve tighter
convergence rates and relax assumptions, bridging the gap between theoretical
principles and practical applications, covering several important techniques
such as Dropout and Sparse training. This work presents promising opportunities
to enhance the theoretical understanding of model training through a
sparsification-aware optimization approach.
</p>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16087" title="Abstract">arXiv:2311.16087</a> [<a href="/pdf/2311.16087" title="Download PDF">pdf</a>, <a href="/format/2311.16087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DUnE: Dataset for Unified Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aky%C3%BCrek%2C+A+F">Afra Feyza Aky&#xfc;rek</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+E">Eric Pan</a>, 
<a href="/search/cs?searchtype=author&query=Kuwanto%2C+G">Garry Kuwanto</a>, 
<a href="/search/cs?searchtype=author&query=Wijaya%2C+D">Derry Wijaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Even the most advanced language models remain susceptible to errors
necessitating to modify these models without initiating a comprehensive
retraining process. Model editing refers to the modification of a model's
knowledge or representations in a manner that produces the desired outcomes.
Prior research primarily centered around editing factual data e.g. "Messi plays
for Inter Miami" confining the definition of an edit to a knowledge triplet
i.e. (subject, object, relation). However, as the applications of language
models expand, so do the diverse ways in which we wish to edit and refine their
outputs. In this study, we broaden the scope of the editing problem to include
an array of editing cases such as debiasing and rectifying reasoning errors and
define an edit as any natural language expression that solicits a change in the
model's outputs. We are introducing DUnE-an editing benchmark where edits are
natural language sentences and propose that DUnE presents a challenging yet
relevant task. To substantiate this claim, we conduct an extensive series of
experiments testing various editing approaches to address DUnE, demonstrating
their respective strengths and weaknesses. We show that retrieval-augmented
language modeling can outperform specialized editing techniques and neither set
of approaches has fully solved the generalized editing problem covered by our
benchmark.
</p>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16090" title="Abstract">arXiv:2311.16090</a> [<a href="/pdf/2311.16090" title="Download PDF">pdf</a>, <a href="/format/2311.16090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-correcting LLM-controlled Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tsung-Han Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+L">Long Lian</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+J+E">Joseph E. Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Darrell%2C+T">Trevor Darrell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-to-image generation has witnessed significant progress with the advent
of diffusion models. Despite the ability to generate photorealistic images,
current text-to-image diffusion models still often struggle to accurately
interpret and follow complex input text prompts. In contrast to existing models
that aim to generate images only with their best effort, we introduce
Self-correcting LLM-controlled Diffusion (SLD). SLD is a framework that
generates an image from the input prompt, assesses its alignment with the
prompt, and performs self-corrections on the inaccuracies in the generated
image. Steered by an LLM controller, SLD turns text-to-image generation into an
iterative closed-loop process, ensuring correctness in the resulting image. SLD
is not only training-free but can also be seamlessly integrated with diffusion
models behind API access, such as DALL-E 3, to further boost the performance of
state-of-the-art diffusion models. Experimental results show that our approach
can rectify a majority of incorrect generations, particularly in generative
numeracy, attribute binding, and spatial relationships. Furthermore, by simply
adjusting the instructions to the LLM, SLD can perform image editing tasks,
bridging the gap between text-to-image generation and image editing pipelines.
We will make our code available for future research and applications.
</p>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16091" title="Abstract">arXiv:2311.16091</a> [<a href="/pdf/2311.16091" title="Download PDF">pdf</a>, <a href="/format/2311.16091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Autonomous Navigation with Internal State Inference and  Interactivity Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiachen Li</a>, 
<a href="/search/cs?searchtype=author&query=Isele%2C+D">David Isele</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kanghoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jinkyoo Park</a>, 
<a href="/search/cs?searchtype=author&query=Fujimura%2C+K">Kikuo Fujimura</a>, 
<a href="/search/cs?searchtype=author&query=Kochenderfer%2C+M+J">Mykel J. Kochenderfer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Deep reinforcement learning (DRL) provides a promising way for intelligent
agents (e.g., autonomous vehicles) to learn to navigate complex scenarios.
However, DRL with neural networks as function approximators is typically
considered a black box with little explainability and often suffers from
suboptimal performance, especially for autonomous navigation in highly
interactive multi-agent environments. To address these issues, we propose three
auxiliary tasks with spatio-temporal relational reasoning and integrate them
into the standard DRL framework, which improves the decision making performance
and provides explainable intermediate indicators. We propose to explicitly
infer the internal states (i.e., traits and intentions) of surrounding agents
(e.g., human drivers) as well as to predict their future trajectories in the
situations with and without the ego agent through counterfactual reasoning.
These auxiliary tasks provide additional supervision signals to infer the
behavior patterns of other interactive agents. Multiple variants of framework
integration strategies are compared. We also employ a spatio-temporal graph
neural network to encode relations between dynamic entities, which enhances
both internal state inference and decision making of the ego agent. Moreover,
we propose an interactivity estimation mechanism based on the difference
between predicted trajectories in these two situations, which indicates the
degree of influence of the ego agent on other agents. To validate the proposed
method, we design an intersection driving simulator based on the Intelligent
Intersection Driver Model (IIDM) that simulates vehicles and pedestrians. Our
approach achieves robust and state-of-the-art performance in terms of standard
evaluation metrics and provides explainable intermediate indicators (i.e.,
internal states, and interactivity scores) for decision making.
</p>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16093" title="Abstract">arXiv:2311.16093</a> [<a href="/pdf/2311.16093" title="Download PDF">pdf</a>, <a href="/format/2311.16093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Have we built machines that think like people?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Buschoff%2C+L+M+S">Luca M. Schulze Buschoff</a>, 
<a href="/search/cs?searchtype=author&query=Akata%2C+E">Elif Akata</a>, 
<a href="/search/cs?searchtype=author&query=Bethge%2C+M">Matthias Bethge</a>, 
<a href="/search/cs?searchtype=author&query=Schulz%2C+E">Eric Schulz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">A chief goal of artificial intelligence is to build machines that think like
people. Yet it has been argued that deep neural network architectures fail to
accomplish this. Researchers have asserted these models' limitations in the
domains of causal reasoning, intuitive physics, and intuitive psychology. Yet
recent advancements, namely the rise of large language models, particularly
those designed for visual processing, have rekindled interest in the potential
to emulate human-like cognitive abilities. This paper evaluates the current
state of vision-based large language models in the domains of intuitive
physics, causal reasoning, and intuitive psychology. Through a series of
controlled experiments, we investigate the extent to which these modern models
grasp complex physical interactions, causal relationships, and intuitive
understanding of others' preferences. Our findings reveal that, while these
models demonstrate a notable proficiency in processing and interpreting visual
data, they still fall short of human capabilities in these areas. The models
exhibit a rudimentary understanding of physical laws and causal relationships,
but their performance is hindered by a lack of deeper insights-a key aspect of
human cognition. Furthermore, in tasks requiring an intuitive theory of mind,
the models fail altogether. Our results emphasize the need for integrating more
robust mechanisms for understanding causality, physical dynamics, and social
cognition into modern-day, vision-based language models, and point out the
importance of cognitively-inspired benchmarks.
</p>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16094" title="Abstract">arXiv:2311.16094</a> [<a href="/pdf/2311.16094" title="Download PDF">pdf</a>, <a href="/format/2311.16094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Street TryOn: Learning In-the-Wild Virtual Try-On from Unpaired Person  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+A">Aiyu Cui</a>, 
<a href="/search/cs?searchtype=author&query=Mahajan%2C+J">Jay Mahajan</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+V">Viraj Shah</a>, 
<a href="/search/cs?searchtype=author&query=Gomathinayagam%2C+P">Preeti Gomathinayagam</a>, 
<a href="/search/cs?searchtype=author&query=Lazebnik%2C+S">Svetlana Lazebnik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Virtual try-on has become a popular research topic, but most existing methods
focus on studio images with a clean background. They can achieve plausible
results for this studio try-on setting by learning to warp a garment image to
fit a person's body from paired training data, i.e., garment images paired with
images of people wearing the same garment. Such data is often collected from
commercial websites, where each garment is demonstrated both by itself and on
several models. By contrast, it is hard to collect paired data for in-the-wild
scenes, and therefore, virtual try-on for casual images of people against
cluttered backgrounds is rarely studied.
<br />In this work, we fill the gap in the current virtual try-on research by (1)
introducing a Street TryOn benchmark to evaluate performance on street scenes
and (2) proposing a novel method that can learn without paired data, from a set
of in-the-wild person images directly. Our method can achieve robust
performance across shop and street domains using a novel DensePose warping
correction method combined with diffusion-based inpainting controlled by pose
and semantic segmentation. Our experiments demonstrate competitive performance
for standard studio try-on tasks and SOTA performance for street try-on and
cross-domain try-on tasks.
</p>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16096" title="Abstract">arXiv:2311.16096</a> [<a href="/pdf/2311.16096" title="Download PDF">pdf</a>, <a href="/format/2311.16096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Animatable Gaussians: Learning Pose-dependent Gaussian Maps for  High-fidelity Human Avatar Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zerong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lizhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yebin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Projectpage: <a href="https://animatable-gaussians.github.io/">this https URL</a>, Code: <a href="https://github.com/lizhe00/AnimatableGaussians">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Modeling animatable human avatars from RGB videos is a long-standing and
challenging problem. Recent works usually adopt MLP-based neural radiance
fields (NeRF) to represent 3D humans, but it remains difficult for pure MLPs to
regress pose-dependent garment details. To this end, we introduce Animatable
Gaussians, a new avatar representation that leverages powerful 2D CNNs and 3D
Gaussian splatting to create high-fidelity avatars. To associate 3D Gaussians
with the animatable avatar, we learn a parametric template from the input
videos, and then parameterize the template on two front \&amp; back canonical
Gaussian maps where each pixel represents a 3D Gaussian. The learned template
is adaptive to the wearing garments for modeling looser clothes like dresses.
Such template-guided 2D parameterization enables us to employ a powerful
StyleGAN-based CNN to learn the pose-dependent Gaussian maps for modeling
detailed dynamic appearances. Furthermore, we introduce a pose projection
strategy for better generalization given novel poses. Overall, our method can
create lifelike avatars with dynamic, realistic and generalized appearances.
Experiments show that our method outperforms other state-of-the-art approaches.
Code: https://github.com/lizhe00/AnimatableGaussians
</p>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16097" title="Abstract">arXiv:2311.16097</a> [<a href="/pdf/2311.16097" title="Download PDF">pdf</a>, <a href="/format/2311.16097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CG-HOI: Contact-Guided 3D Human-Object Interaction Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diller%2C+C">Christian Diller</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+A">Angela Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://cg-hoi.christian-diller.de">this https URL</a> Video: <a href="https://www.youtube.com/watch?v=GNyQwTwZ15s">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose CG-HOI, the first method to address the task of generating dynamic
3D human-object interactions (HOIs) from text. We model the motion of both
human and object in an interdependent fashion, as semantically rich human
motion rarely happens in isolation without any interactions. Our key insight is
that explicitly modeling contact between the human body surface and object
geometry can be used as strong proxy guidance, both during training and
inference. Using this guidance to bridge human and object motion enables
generating more realistic and physically plausible interaction sequences, where
the human body and corresponding object move in a coherent manner. Our method
first learns to model human motion, object motion, and contact in a joint
diffusion process, inter-correlated through cross-attention. We then leverage
this learned contact for guidance during inference synthesis of realistic,
coherent HOIs. Extensive evaluation shows that our joint contact-based
human-object interaction approach generates realistic and physically plausible
sequences, and we show two applications highlighting the capabilities of our
method. Conditioned on a given object trajectory, we can generate the
corresponding human motion without re-training, demonstrating strong
human-object interdependency learning. Our approach is also flexible, and can
be applied to static real-world 3D scene scans.
</p>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16098" title="Abstract">arXiv:2311.16098</a> [<a href="/pdf/2311.16098" title="Download PDF">pdf</a>, <a href="/format/2311.16098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Bringing Robots Home
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shafiullah%2C+N+M+M">Nur Muhammad Mahi Shafiullah</a>, 
<a href="/search/cs?searchtype=author&query=Rai%2C+A">Anant Rai</a>, 
<a href="/search/cs?searchtype=author&query=Etukuru%2C+H">Haritheja Etukuru</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiqian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Misra%2C+I">Ishan Misra</a>, 
<a href="/search/cs?searchtype=author&query=Chintala%2C+S">Soumith Chintala</a>, 
<a href="/search/cs?searchtype=author&query=Pinto%2C+L">Lerrel Pinto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website and videos are available at <a href="https://dobb-e.com">this https URL</a>, technical documentation for getting started is available at <a href="https://docs.dobb-e.com">this https URL</a>, and code is released at <a href="https://github.com/notmahi/dobb-e">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Throughout history, we have successfully integrated various machines into our
homes. Dishwashers, laundry machines, stand mixers, and robot vacuums are a few
recent examples. However, these machines excel at performing only a single task
effectively. The concept of a "generalist machine" in homes - a domestic
assistant that can adapt and learn from our needs, all while remaining
cost-effective - has long been a goal in robotics that has been steadily
pursued for decades. In this work, we initiate a large-scale effort towards
this goal by introducing Dobb-E, an affordable yet versatile general-purpose
system for learning robotic manipulation within household settings. Dobb-E can
learn a new task with only five minutes of a user showing it how to do it,
thanks to a demonstration collection tool ("The Stick") we built out of cheap
parts and iPhones. We use the Stick to collect 13 hours of data in 22 homes of
New York City, and train Home Pretrained Representations (HPR). Then, in a
novel home environment, with five minutes of demonstrations and fifteen minutes
of adapting the HPR model, we show that Dobb-E can reliably solve the task on
the Stretch, a mobile robot readily available on the market. Across roughly 30
days of experimentation in homes of New York City and surrounding areas, we
test our system in 10 homes, with a total of 109 tasks in different
environments, and finally achieve a success rate of 81%. Beyond success
percentages, our experiments reveal a plethora of unique challenges absent or
ignored in lab robotics. These range from effects of strong shadows, to
variable demonstration quality by non-expert users. With the hope of
accelerating research on home robots, and eventually seeing robot butlers in
every home, we open-source Dobb-E software stack and models, our data, and our
hardware designs at https://dobb-e.com
</p>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16099" title="Abstract">arXiv:2311.16099</a> [<a href="/pdf/2311.16099" title="Download PDF">pdf</a>, <a href="/format/2311.16099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GART: Gaussian Articulated Template Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+J">Jiahui Lei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yufu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pavlakos%2C+G">Georgios Pavlakos</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Daniilidis%2C+K">Kostas Daniilidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, code available at <a href="https://www.cis.upenn.edu/~leijh/projects/gart/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We introduce Gaussian Articulated Template Model GART, an explicit,
efficient, and expressive representation for non-rigid articulated subject
capturing and rendering from monocular videos. GART utilizes a mixture of
moving 3D Gaussians to explicitly approximate a deformable subject's geometry
and appearance. It takes advantage of a categorical template model prior (SMPL,
SMAL, etc.) with learnable forward skinning while further generalizing to more
complex non-rigid deformations with novel latent bones. GART can be
reconstructed via differentiable rendering from monocular videos in seconds or
minutes and rendered in novel poses faster than 150fps.
</p>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16100" title="Abstract">arXiv:2311.16100</a> [<a href="/pdf/2311.16100" title="Download PDF">pdf</a>, <a href="/format/2311.16100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient high-resolution refinement in cryo-EM with stochastic gradient  descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Toader%2C+B">Bogdan Toader</a>, 
<a href="/search/math?searchtype=author&query=Brubaker%2C+M+A">Marcus A. Brubaker</a>, 
<a href="/search/math?searchtype=author&query=Lederman%2C+R+R">Roy R. Lederman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Biomolecules (q-bio.BM)

</div>
<p class="mathjax">Electron cryomicroscopy (cryo-EM) is an imaging technique widely used in
structural biology to determine the three-dimensional structure of biological
molecules from noisy two-dimensional projections with unknown orientations. As
the typical pipeline involves processing large amounts of data, efficient
algorithms are crucial for fast and reliable results. The stochastic gradient
descent (SGD) algorithm has been used to improve the speed of ab initio
reconstruction, which results in a first, low-resolution estimation of the
volume representing the molecule of interest, but has yet to be applied
successfully in the high-resolution regime, where expectation-maximization
algorithms achieve state-of-the-art results, at a high computational cost. In
this article, we investigate the conditioning of the optimization problem and
show that the large condition number prevents the successful application of
gradient descent-based methods at high resolution. Our results include a
theoretical analysis of the condition number of the optimization problem in a
simplified setting where the individual projection directions are known, an
algorithm based on computing a diagonal preconditioner using Hutchinson's
diagonal estimator, and numerical experiments showing the improvement in the
convergence speed when using the estimated preconditioner with SGD. The
preconditioned SGD approach can potentially enable a simple and unified
approach to ab initio reconstruction and high-resolution refinement with faster
convergence speed and higher flexibility, and our results are a promising step
in this direction.
</p>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16101" title="Abstract">arXiv:2311.16101</a> [<a href="/pdf/2311.16101" title="Download PDF">pdf</a>, <a href="/format/2311.16101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Many Unicorns Are in This Image? A Safety Evaluation Benchmark for  Vision LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tu%2C+H">Haoqin Tu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+C">Chenhang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zijun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yiyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bingchen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Junlin Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wangchunshu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Huaxiu Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Cihang Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> H.T., C.C., and Z.W. contribute equally. Work done during H.T. and Z.W.'s internship at UCSC, and C.C. and Y.Z.'s internship at UNC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">This work focuses on the potential of Vision LLMs (VLLMs) in visual
reasoning. Different from prior studies, we shift our focus from evaluating
standard performance to introducing a comprehensive safety evaluation suite,
covering both out-of-distribution (OOD) generalization and adversarial
robustness. For the OOD evaluation, we present two novel VQA datasets, each
with one variant, designed to test model performance under challenging
conditions. In exploring adversarial robustness, we propose a straightforward
attack strategy for misleading VLLMs to produce visual-unrelated responses.
Moreover, we assess the efficacy of two jailbreaking strategies, targeting
either the vision or language component of VLLMs. Our evaluation of 21 diverse
models, ranging from open-source VLLMs to GPT-4V, yields interesting
observations: 1) Current VLLMs struggle with OOD texts but not images, unless
the visual information is limited; and 2) These VLLMs can be easily misled by
deceiving vision encoders only, and their vision-language training often
compromise safety protocols. We release this safety evaluation suite at
https://github.com/UCSC-VLAA/vllm-safety-benchmark.
</p>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16102" title="Abstract">arXiv:2311.16102</a> [<a href="/pdf/2311.16102" title="Download PDF">pdf</a>, <a href="/format/2311.16102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Test-time Adaptation of Discriminative Models via Diffusion Generative  Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prabhudesai%2C+M">Mihir Prabhudesai</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+T">Tsung-Wei Ke</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A+C">Alexander C. Li</a>, 
<a href="/search/cs?searchtype=author&query=Pathak%2C+D">Deepak Pathak</a>, 
<a href="/search/cs?searchtype=author&query=Fragkiadaki%2C+K">Katerina Fragkiadaki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023 Webpage with Code: <a href="https://diffusion-tta.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">The advancements in generative modeling, particularly the advent of diffusion
models, have sparked a fundamental question: how can these models be
effectively used for discriminative tasks? In this work, we find that
generative models can be great test-time adapters for discriminative models.
Our method, Diffusion-TTA, adapts pre-trained discriminative models such as
image classifiers, segmenters and depth predictors, to each unlabelled example
in the test set using generative feedback from a diffusion model. We achieve
this by modulating the conditioning of the diffusion model using the output of
the discriminative model. We then maximize the image likelihood objective by
backpropagating the gradients to discriminative model's parameters. We show
Diffusion-TTA significantly enhances the accuracy of various large-scale
pre-trained discriminative models, such as, ImageNet classifiers, CLIP models,
image pixel labellers and image depth predictors. Diffusion-TTA outperforms
existing test-time adaptation methods, including TTT-MAE and TENT, and
particularly shines in online adaptation setups, where the discriminative model
is continually adapted to each example in the test set. We provide access to
code, results, and visualizations on our website:
https://diffusion-tta.github.io/.
</p>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16103" title="Abstract">arXiv:2311.16103</a> [<a href="/pdf/2311.16103" title="Download PDF">pdf</a>, <a href="/format/2311.16103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video-Bench: A Comprehensive Benchmark and Toolkit for Evaluating  Video-based Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ning%2C+M">Munan Ning</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Bin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yujia Xie</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Bin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jiaxi Cui</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Lu Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dongdong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Li Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Benchmark is available at <a href="https://github.com/PKU-YuanGroup/Video-Bench">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Video-based large language models (Video-LLMs) have been recently introduced,
targeting both fundamental improvements in perception and comprehension, and a
diverse range of user inquiries. In pursuit of the ultimate goal of achieving
artificial general intelligence, a truly intelligent Video-LLM model should not
only see and understand the surroundings, but also possess human-level
commonsense, and make well-informed decisions for the users. To guide the
development of such a model, the establishment of a robust and comprehensive
evaluation system becomes crucial. To this end, this paper proposes
\textit{Video-Bench}, a new comprehensive benchmark along with a toolkit
specifically designed for evaluating Video-LLMs. The benchmark comprises 10
meticulously crafted tasks, evaluating the capabilities of Video-LLMs across
three distinct levels: Video-exclusive Understanding, Prior Knowledge-based
Question-Answering, and Comprehension and Decision-making. In addition, we
introduce an automatic toolkit tailored to process model outputs for various
tasks, facilitating the calculation of metrics and generating convenient final
scores. We evaluate 8 representative Video-LLMs using \textit{Video-Bench}. The
findings reveal that current Video-LLMs still fall considerably short of
achieving human-like comprehension and analysis of real-world videos, offering
valuable insights for future research directions. The benchmark and toolkit are
available at: \url{https://github.com/PKU-YuanGroup/Video-Bench}.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Tue, 28 Nov 23</h3>
<dl>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14698" title="Abstract">arXiv:2311.14698</a> (cross-list from stat.ME) [<a href="/pdf/2311.14698" title="Download PDF">pdf</a>, <a href="/format/2311.14698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Business Policy Experiments using Fractional Factorial Designs: Consumer  Retention on DoorDash
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Tang%2C+Y">Yixin Tang</a>, 
<a href="/search/stat?searchtype=author&query=Yicong">Yicong</a> (Nicole)Lin, 
<a href="/search/stat?searchtype=author&query=Sahni%2C+N+S">Navdeep S. Sahni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Econometrics (econ.EM)

</div>
<p class="mathjax">This paper investigates an approach to both speed up business decision-making
and lower the cost of learning through experimentation by factorizing business
policies and employing fractional factorial experimental designs for their
evaluation. We illustrate how this method integrates with advances in the
estimation of heterogeneous treatment effects, elaborating on its advantages
and foundational assumptions. We empirically demonstrate the implementation and
benefits of our approach and assess its validity in evaluating consumer
promotion policies at DoorDash, which is one of the largest delivery platforms
in the US. Our approach discovers a policy with 5% incremental profit at 67%
lower implementation cost.
</p>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14725" title="Abstract">arXiv:2311.14725</a> (cross-list from cond-mat.stat-mech) [<a href="/pdf/2311.14725" title="Download PDF">pdf</a>, <a href="/format/2311.14725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised learning of site percolation based on shuffled  configurations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Xu%2C+D">Dian Xu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wang%2C+S">Shanshan Wang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Gao%2C+F">Feng Gao</a>, 
<a href="/search/cond-mat?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cond-mat?searchtype=author&query=Shen%2C+J">Jianmin Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages,8 figures,41 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Mechanics (cond-mat.stat-mech)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the field of statistical physics, machine learning has gained significant
popularity and has achieved remarkable results in recent studies on phase
transitions.In this paper, we apply Principal Component Analysis (PCA) and
Autoencoder(AE) based on Unsupervised learning to study the various
configurations of the percolation model in equilibrium phase transition. In
certain phase transition models, such as the DP model in non-equilibrium phase
transitions, the order parameter is particle density. However, in some other
phase transition models, such as the percolation model, it is not. This study
involved randomizing and selecting percolation graphs to be used as input for a
neural network, and analyzed the obtained results, indicating that the outputs
of the single latent variable of AE and the first principal component of PCA
are signals related to particle density.
</p>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14731" title="Abstract">arXiv:2311.14731</a> (cross-list from q-fin.ST) [<a href="/pdf/2311.14731" title="Download PDF">pdf</a>, <a href="/ps/2311.14731" title="Download PostScript">ps</a>, <a href="/format/2311.14731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep State-Space Model for Predicting Cryptocurrency Price
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Sharma%2C+S">Shalini Sharma</a>, 
<a href="/search/q-fin?searchtype=author&query=Majumdar%2C+A">Angshul Majumdar</a>, 
<a href="/search/q-fin?searchtype=author&query=Chouzenoux%2C+E">Emilie Chouzenoux</a>, 
<a href="/search/q-fin?searchtype=author&query=Elvira%2C+V">Victor Elvira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">Our work presents two fundamental contributions. On the application side, we
tackle the challenging problem of predicting day-ahead crypto-currency prices.
On the methodological side, a new dynamical modeling approach is proposed. Our
approach keeps the probabilistic formulation of the state-space model, which
provides uncertainty quantification on the estimates, and the function
approximation ability of deep neural networks. We call the proposed approach
the deep state-space model. The experiments are carried out on established
cryptocurrencies (obtained from Yahoo Finance). The goal of the work has been
to predict the price for the next day. Benchmarking has been done with both
state-of-the-art and classical dynamical modeling techniques. Results show that
the proposed approach yields the best overall results in terms of accuracy.
</p>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14735" title="Abstract">arXiv:2311.14735</a> (cross-list from q-fin.ST) [<a href="/pdf/2311.14735" title="Download PDF">pdf</a>, <a href="/format/2311.14735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Machine Learning for Multivariate Equity Returns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Tepelyan%2C+R">Ruslan Tepelyan</a>, 
<a href="/search/q-fin?searchtype=author&query=Gopal%2C+A">Achintya Gopal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 2-column format, presented at ICAIF'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The use of machine learning to generate synthetic data has grown in
popularity with the proliferation of text-to-image models and especially large
language models. The core methodology these models use is to learn the
distribution of the underlying data, similar to the classical methods common in
finance of fitting statistical models to data. In this work, we explore the
efficacy of using modern machine learning methods, specifically conditional
importance weighted autoencoders (a variant of variational autoencoders) and
conditional normalizing flows, for the task of modeling the returns of
equities. The main problem we work to address is modeling the joint
distribution of all the members of the S&amp;P 500, or, in other words, learning a
500-dimensional joint distribution. We show that this generative model has a
broad range of applications in finance, including generating realistic
synthetic data, volatility and correlation estimation, risk analysis (e.g.,
value at risk, or VaR, of portfolios), and portfolio optimization.
</p>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14744" title="Abstract">arXiv:2311.14744</a> (cross-list from physics.chem-ph) [<a href="/pdf/2311.14744" title="Download PDF">pdf</a>, <a href="/ps/2311.14744" title="Download PostScript">ps</a>, <a href="/format/2311.14744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coarse-Grained Configurational Polymer Fingerprints for Property  Prediction using Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kumar%2C+I">Ishan Kumar</a>, 
<a href="/search/physics?searchtype=author&query=Jha%2C+P+K">Prateek K Jha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this work, we present a method to generate a configurational level
fingerprint for polymers using the Bead-Spring-Model. Unlike some of the
previous fingerprinting approaches that employ monomer-level information where
atomistic descriptors are computed using quantum chemistry calculations, this
approach incorporates configurational information from a coarse-grained model
of a long polymer chain. The proposed approach may be advantageous for the
study of behavior resulting from large molecular weights. To create this
fingerprint, we make use of two kinds of descriptors. First, we calculate
certain geometric descriptors like Re2, Rg2 etc. and label them as Calculated
Descriptors. Second, we generate a set of data-driven descriptors using an
unsupervised autoencoder model and call them Learnt Descriptors. Using a
combination of both of them, we are able to learn mappings from the structure
to various properties of the polymer chain by training ML models. We test our
fingerprint to predict the probability of occurrence of a configuration at
equilibrium, which is approximated by a simple linear relationship between the
instantaneous internal energy and equilibrium average internal energy.
</p>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14759" title="Abstract">arXiv:2311.14759</a> (cross-list from q-fin.ST) [<a href="/pdf/2311.14759" title="Download PDF">pdf</a>, <a href="/format/2311.14759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forecasting Cryptocurrency Prices Using Deep Learning: Integrating  Financial, Blockchain, and Text Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Gurgul%2C+V">Vincent Gurgul</a>, 
<a href="/search/q-fin?searchtype=author&query=Lessmann%2C+S">Stefan Lessmann</a>, 
<a href="/search/q-fin?searchtype=author&query=H%C3%A4rdle%2C+W+K">Wolfgang Karl H&#xe4;rdle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper explores the application of Machine Learning (ML) and Natural
Language Processing (NLP) techniques in cryptocurrency price forecasting,
specifically Bitcoin (BTC) and Ethereum (ETH). Focusing on news and social
media data, primarily from Twitter and Reddit, we analyse the influence of
public sentiment on cryptocurrency valuations using advanced deep learning NLP
methods. Alongside conventional price regression, we treat cryptocurrency price
forecasting as a classification problem. This includes both the prediction of
price movements (up or down) and the identification of local extrema. We
compare the performance of various ML models, both with and without NLP data
integration. Our findings reveal that incorporating NLP data significantly
enhances the forecasting performance of our models. We discover that
pre-trained models, such as Twitter-RoBERTa and BART MNLI, are highly effective
in capturing market sentiment, and that fine-tuning Large Language Models
(LLMs) also yields substantial forecasting improvements. Notably, the BART MNLI
zero-shot classification model shows considerable proficiency in extracting
bullish and bearish signals from textual data. All of our models consistently
generate profit across different validation scenarios, with no observed decline
in profits or reduction in the impact of NLP data over time. The study
highlights the potential of text analysis in improving financial forecasts and
demonstrates the effectiveness of various NLP techniques in capturing nuanced
market sentiment.
</p>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14761" title="Abstract">arXiv:2311.14761</a> (cross-list from physics.soc-ph) [<a href="/pdf/2311.14761" title="Download PDF">pdf</a>, <a href="/ps/2311.14761" title="Download PostScript">ps</a>, <a href="/format/2311.14761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Spin States to Social Consensus: Ising Approach to Dimer  Configurations in Opinion Formation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kawahata%2C+Y">Yasuko Kawahata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Discussion Paper:Theory of opinion distribution in human relations where trust and distrust mixed(2020)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">The field of opinion dynamics has evolved steadily since the earliest studies
applying magnetic physics methods to better understand social opinion
formation. However, in the real world, complete agreement of opinions is rare,
and biaxial consensus, especially on social issues, is rare. To address this
challenge, Ishii and Kawabata (2018) proposed an extended version of the
Bounded Confidence Model that introduces new parameters indicating dissent and
distrust, as well as the influence of mass media. Their model aimed to capture
more realistic social opinion dynamics by introducing coefficients representing
the degree of trust and distrust, rather than assuming convergence of opinions.
In this paper, we propose a new approach to opinion dynamics based on this
Trust-Distrust Model (TDM), applying the dimer allocation and Ising model. Our
goal is to explore how the interaction between trust and distrust affects
social opinion formation. In particular, we analyze through mathematical models
how various external stimuli, such as mass media, third-party opinions, and
economic and political factors, affect people's opinions. Our approach is to
mathematically represent the dynamics of trust and distrust, which traditional
models have not addressed. This theoretical framework provides new insights
into the polarization of opinions, the process of consensus building, and how
these are reflected in social behavior. In addition to developing the
theoretical framework by applying the dimer configuration, the dimer model and
the Ising model, this paper uses numerical simulations to show how the proposed
model applies to actual social opinion formation. This research aims to
contribute to a deeper understanding of social opinion formation by providing
new perspectives in the fields of social science, physics, and computational
modeling.
</p>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14777" title="Abstract">arXiv:2311.14777</a> (cross-list from eess.IV) [<a href="/pdf/2311.14777" title="Download PDF">pdf</a>, <a href="/format/2311.14777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Text to Image: Exploring GPT-4Vision&#x27;s Potential in Advanced  Radiological Analysis across Subspecialties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Busch%2C+F">Felix Busch</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+T">Tianyu Han</a>, 
<a href="/search/eess?searchtype=author&query=Makowski%2C+M">Marcus Makowski</a>, 
<a href="/search/eess?searchtype=author&query=Truhn%2C+D">Daniel Truhn</a>, 
<a href="/search/eess?searchtype=author&query=Bressem%2C+K">Keno Bressem</a>, 
<a href="/search/eess?searchtype=author&query=Adams%2C+L">Lisa Adams</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The study evaluates and compares GPT-4 and GPT-4Vision for radiological
tasks, suggesting GPT-4Vision may recognize radiological features from images,
thereby enhancing its diagnostic potential over text-based descriptions.
</p>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14817" title="Abstract">arXiv:2311.14817</a> (cross-list from physics.soc-ph) [<a href="/pdf/2311.14817" title="Download PDF">pdf</a>, <a href="/format/2311.14817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-metric topology characterizes epidemic spreading on complex  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Pa%C3%B1os%2C+D+S">David Soriano Pa&#xf1;os</a>, 
<a href="/search/physics?searchtype=author&query=Costa%2C+F+X">Felipe Xavier Costa</a>, 
<a href="/search/physics?searchtype=author&query=Rocha%2C+L+M">Luis M. Rocha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures. Supplementary Text: 6 pages, 1 table, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Network sparsification represents an essential tool to extract the core of
interactions sustaining both networks dynamics and their connectedness. In the
case of infectious diseases, network sparsification methods remove irrelevant
connections to unveil the primary subgraph driving the unfolding of epidemic
outbreaks in real networks. In this paper, we explore the features determining
whether the metric backbone, a subgraph capturing the structure of shortest
paths across a network, allows reconstructing epidemic outbreaks. We find that
both the relative size of the metric backbone, capturing the fraction of edges
kept in such structure, and the distortion of semi-metric edges, quantifying
how far those edges not included in the metric backbone are from their
associated shortest path, shape the retrieval of Susceptible-Infected (SI)
dynamics. We propose a new method to progressively dismantle networks relying
on the semi-metric edge distortion, removing first those connections farther
from those included in the metric backbone, i.e. those with highest semi-metric
distortion values. We apply our method in both synthetic and real networks,
finding that semi-metric distortion provides solid ground to preserve spreading
dynamics and connectedness while sparsifying networks.
</p>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14823" title="Abstract">arXiv:2311.14823</a> (cross-list from quant-ph) [<a href="/pdf/2311.14823" title="Download PDF">pdf</a>, <a href="/ps/2311.14823" title="Download PostScript">ps</a>, <a href="/format/2311.14823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Quantum Algorithms for Linear Regressions: Quadratic Speedups  without Data-Dependent Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Song%2C+Z">Zhao Song</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yin%2C+J">Junze Yin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+R">Ruizhe Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG)

</div>
<p class="mathjax">Linear regression is one of the most fundamental linear algebra problems.
Given a dense matrix $A \in \mathbb{R}^{n \times d}$ and a vector $b$, the goal
is to find $x'$ such that
<br />$ \| Ax' - b \|_2^2 \leq (1+\epsilon) \min_{x} \| A x - b \|_2^2 $. The best
classical algorithm takes $O(nd) + \mathrm{poly}(d/\epsilon)$ time [Clarkson
and Woodruff STOC 2013, Nelson and Nguyen FOCS 2013]. On the other hand,
quantum linear regression algorithms can achieve exponential quantum speedups,
as shown in [Wang Phys. Rev. A 96, 012335, Kerenidis and Prakash ITCS 2017,
Chakraborty, Gily{\'e}n and Jeffery ICALP 2019]. However, the running times of
these algorithms depend on some quantum linear algebra-related parameters, such
as $\kappa(A)$, the condition number of $A$. In this work, we develop a quantum
algorithm that runs in $\widetilde{O}(\epsilon^{-1}\sqrt{n}d^{1.5}) +
\mathrm{poly}(d/\epsilon)$ time. It provides a quadratic quantum speedup in $n$
over the classical lower bound without any dependence on data-dependent
parameters. In addition, we also show our result can be generalized to multiple
regression and ridge linear regression.
</p>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14828" title="Abstract">arXiv:2311.14828</a> (cross-list from stat.ML) [<a href="/pdf/2311.14828" title="Download PDF">pdf</a>, <a href="/format/2311.14828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Latent Force Models: ODE-based Process Convolutions for Bayesian  Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Baldwin-McDonald%2C+T">Thomas Baldwin-McDonald</a>, 
<a href="/search/stat?searchtype=author&query=%C3%81lvarez%2C+M+A">Mauricio A. &#xc1;lvarez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 6 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. arXiv admin note: text overlap with <a href="/abs/2106.05960">arXiv:2106.05960</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Effectively modeling phenomena present in highly nonlinear dynamical systems
whilst also accurately quantifying uncertainty is a challenging task, which
often requires problem-specific techniques. We outline the deep latent force
model (DLFM), a domain-agnostic approach to tackling this problem, which
consists of a deep Gaussian process architecture where the kernel at each layer
is derived from an ordinary differential equation using the framework of
process convolutions. Two distinct formulations of the DLFM are presented which
utilise weight-space and variational inducing points-based Gaussian process
approximations, both of which are amenable to doubly stochastic variational
inference. We provide evidence that our model is capable of capturing highly
nonlinear behaviour in real-world multivariate time series data. In addition,
we find that our approach achieves comparable performance to a number of other
probabilistic models on benchmark regression tasks. We also empirically assess
the negative impact of the inducing points framework on the extrapolation
capabilities of LFM-based models.
</p>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14856" title="Abstract">arXiv:2311.14856</a> (cross-list from physics.plasm-ph) [<a href="/pdf/2311.14856" title="Download PDF">pdf</a>, <a href="/format/2311.14856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disruption Prediction in Fusion Devices through Feature Extraction and  Logistic Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Ferreira%2C+D+R">Diogo R. Ferreira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Plasma Physics (physics.plasm-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This document describes an approach used in the Multi-Machine Disruption
Prediction Challenge for Fusion Energy by ITU, a data science competition which
ran from September to November 2023, on the online platform Zindi. The
competition involved data from three fusion devices - C-Mod, HL-2A, and J-TEXT
- with most of the training data coming from the last two, and the test data
coming from the first one. Each device has multiple diagnostics and signals,
and it turns out that a critical issue in this competition was to identify
which signals, and especially which features from those signals, were most
relevant to achieve accurate predictions. The approach described here is based
on extracting features from signals, and then applying logistic regression on
top of those features. Each signal is treated as a separate predictor and, in
the end, a combination of such predictors achieved the first place on the
leaderboard.
</p>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14875" title="Abstract">arXiv:2311.14875</a> (cross-list from eess.IV) [<a href="/pdf/2311.14875" title="Download PDF">pdf</a>, <a href="/format/2311.14875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Aware AI for MRI Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Konathala%2C+L">Lohith Konathala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 Pages, 9 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Robust uncertainty estimations are necessary in safety-critical applications
of Deep Learning. One such example is the semantic segmentation of medical
images, whilst deep-learning approaches have high-performance in such tasks
they lack interpretability as they give no indication of their confidence when
making classification decisions. Robust and interpretable segmentation is a
critical first stage in automatically screening for pathologies hence the
optimal solution is one which can provide highly accuracy but also capture the
underlying uncertainty. In this work we present an uncertainty-aware
segmentation model, BA U-Net, for use on MRI data that incorporates Bayesian
Neural Networks and Attention Mechanisms to provide accurate and interpretable
segmentations. We evaluated our model on the publicly available BraTS 2020
dataset using F1 Score and Intersection Over Union (IoU) as evaluation metrics.
</p>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14890" title="Abstract">arXiv:2311.14890</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2311.14890" title="Download PDF">pdf</a>, <a href="/format/2311.14890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment-Based Wall Treatment Model for Heat Transfer Rate in Smoothed  Particle Hydrodynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Park%2C+H">Hyung-Jun Park</a>, 
<a href="/search/physics?searchtype=author&query=Kim%2C+J">Jaekwang Kim</a>, 
<a href="/search/physics?searchtype=author&query=Kim%2C+H">Hyojin Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Numerical Analysis (math.NA); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">In this study, a smoothed particle hydrodynamics (SPH) model that applies a
segment-based boundary treatment is used to simulate natural convection. In a
natural convection simulated using an SPH model, the wall boundary treatment is
a major issue because accurate heat transfer from boundaries should be
calculated. The boundary particle method, which models the boundary by placing
multiple layers of particles on and behind the wall boundary, is the most
widely used boundary treatment method. Although this method can impose accurate
boundary conditions, boundary modeling for complex shapes is challenging and
requires excessive computational costs depending on the boundary shape. In this
study, we utilize a segment-based boundary treatment method to model the wall
boundary and apply this method to the energy conservation equation for the wall
heat transfer model. The proposed method solves the problems arising from the
use of boundary particles and simultaneously provides accurate heat transfer
calculation results for the wall. In various numerical examples, the proposed
method is verified through a comparison with available experimental results,
SPH results using the boundary particle method, and finite volume method (FVM)
results.
</p>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14910" title="Abstract">arXiv:2311.14910</a> (cross-list from math.DS) [<a href="/pdf/2311.14910" title="Download PDF">pdf</a>, <a href="/format/2311.14910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A latent linear model for nonlinear coupled oscillators on graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Goyal%2C+A">Agam Goyal</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+Z">Zhaoxing Wu</a>, 
<a href="/search/math?searchtype=author&query=Yim%2C+R+P">Richard P. Yim</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+B">Binhao Chen</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+Z">Zihong Xu</a>, 
<a href="/search/math?searchtype=author&query=Lyu%2C+H">Hanbaek Lyu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">A system of coupled oscillators on an arbitrary graph is locally driven by
the tendency to mutual synchronization between nearby oscillators, but can and
often exhibit nonlinear behavior on the whole graph. Understanding such
nonlinear behavior has been a key challenge in predicting whether all
oscillators in such a system will eventually synchronize. In this paper, we
demonstrate that, surprisingly, such nonlinear behavior of coupled oscillators
can be effectively linearized in certain latent dynamic spaces. The key insight
is that there is a small number of `latent dynamics filters', each with a
specific association with synchronizing and non-synchronizing dynamics on
subgraphs so that any observed dynamics on subgraphs can be approximated by a
suitable linear combination of such elementary dynamic patterns. Taking an
ensemble of subgraph-level predictions provides an interpretable predictor for
whether the system on the whole graph reaches global synchronization. We
propose algorithms based on supervised matrix factorization to learn such
latent dynamics filters. We demonstrate that our method performs competitively
in synchronization prediction tasks against baselines and black-box
classification algorithms, despite its simple and interpretable architecture.
</p>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14918" title="Abstract">arXiv:2311.14918</a> (cross-list from eess.IV) [<a href="/pdf/2311.14918" title="Download PDF">pdf</a>, <a href="/format/2311.14918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resolution- and Stimulus-agnostic Super-Resolution of Ultra-High-Field  Functional MRI: Application to Visual Studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+H+B">Hongwei Bran Li</a>, 
<a href="/search/eess?searchtype=author&query=Rosen%2C+M+S">Matthew S. Rosen</a>, 
<a href="/search/eess?searchtype=author&query=Nasr%2C+S">Shahin Nasr</a>, 
<a href="/search/eess?searchtype=author&query=Iglesias%2C+J+E">Juan Eugenio Iglesias</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">High-resolution fMRI provides a window into the brain's mesoscale
organization. Yet, higher spatial resolution increases scan times, to
compensate for the low signal and contrast-to-noise ratio. This work introduces
a deep learning-based 3D super-resolution (SR) method for fMRI. By
incorporating a resolution-agnostic image augmentation framework, our method
adapts to varying voxel sizes without retraining. We apply this innovative
technique to localize fine-scale motion-selective sites in the early visual
areas. Detection of these sites typically requires a resolution higher than 1
mm isotropic, whereas here, we visualize them based on lower resolution (2-3mm
isotropic) fMRI data. Remarkably, the super-resolved fMRI is able to recover
high-frequency detail of the interdigitated organization of these sites
(relative to the color-selective sites), even with training data sourced from
different subjects and experimental paradigms -- including non-visual
resting-state fMRI, underscoring its robustness and versatility. Quantitative
and qualitative results indicate that our method has the potential to enhance
the spatial resolution of fMRI, leading to a drastic reduction in acquisition
time.
</p>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14941" title="Abstract">arXiv:2311.14941</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2311.14941" title="Download PDF">pdf</a>, <a href="/ps/2311.14941" title="Download PostScript">ps</a>, <a href="/format/2311.14941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Development of a Chemistry Dynamic Load Balancing Solver with Sparse  Analytical Jacobian Approach for Rapid and Accurate Reactive Flow Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Yang%2C+Y">Yinan Yang</a>, 
<a href="/search/physics?searchtype=author&query=Hori%2C+T">Tsukasa Hori</a>, 
<a href="/search/physics?searchtype=author&query=Sawada%2C+S">Shinya Sawada</a>, 
<a href="/search/physics?searchtype=author&query=Akamatsu%2C+F">Fumiteru Akamatsu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">In addressing the demands of industrial high-fidelity computation, the
present study introduces a rapid and accurate customized solver developed on
the OpenFOAM platform. To enhance computational efficiency, a novel integrated
acceleration strategy is introduced. Initially, a sparse analytical Jacobian
approach utilizing the SpeedCHEM chemistry library was implemented to increase
the efficiency of the ODE solver. Subsequently, the Dynamic Load Balancing
(DLB) code was employed to uniformly distribute the computational workload for
chemistry among multiple processes. Further optimization was achieved through
the introduction of the Open Multi-Processing (OpenMP) method to enhance
parallel computing efficiency. Lastly, the Local Time Stepping (LTS) scheme was
integrated to maximize the individual time step for each computational cell,
resulting in a noteworthy minimum speed-up of over 31 times. The effectiveness
and robustness of this customized solver were systematically validated against
three distinct partially turbulent premixed flames, Sandia Flames D, E, and F.
Additionally, a comparative analysis was conducted, encompassing different
turbulence models, turbulent Prandtl numbers, and model constants, resulting in
the recommendation of optimal numerical parameters for various conditions. The
present study offers one viable solution for rapid and accurate calculations in
the OpenFOAM platform, while also providing insights into the selection of
turbulence models and parameters for industrial numerical simulation.
</p>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14942" title="Abstract">arXiv:2311.14942</a> (cross-list from eess.SP) [<a href="/pdf/2311.14942" title="Download PDF">pdf</a>, <a href="/format/2311.14942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Precoding and Combining for mmWave Full-Duplex Joint Radar and  Communication Systems under Self-Interference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bayraktar%2C+M">Murat Bayraktar</a>, 
<a href="/search/eess?searchtype=author&query=Gonz%C3%A1lez-Prelcic%2C+N">Nuria Gonz&#xe1;lez-Prelcic</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to 2024 IEEE International Conference on Communications for possible publication. 6 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In the context of integrated sensing and communication (ISAC), a full-duplex
(FD) transceiver can operate as a monostatic radar while maintaining
communication capabilities. This paper investigates the design of precoders and
combiners for a joint radar and communication (JRC) system at mmWave
frequencies. The primary goals of the design are to minimize self-interference
(SI) caused by FD operation, while guaranteeing certain performance in terms of
some sensing and communication metrics, as well as taking into account the
hardware limitations coming from a hybrid MIMO architecture. Specifically, we
introduce a generalized eigenvalue-based precoder that takes into account
downlink user rate, radar gain, and SI suppression. Since the hybrid
analog/digital architecture degrades the SI suppression capability of the
precoder, we further enhance SI suppression with the analog combiner. Our
numerical results demonstrate that the proposed architecture achieves the
required radar gain and SI mitigation while incurring a small loss in downlink
spectral efficiency. Additionally, the numerical experiments also show that the
use of orthogonal frequency division multiplexing (OFDM) for radar processing
with the proposed beamforming architecture results in highly accurate range and
velocity estimates for detected targets.
</p>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14944" title="Abstract">arXiv:2311.14944</a> (cross-list from math.OC) [<a href="/pdf/2311.14944" title="Download PDF">pdf</a>, <a href="/ps/2311.14944" title="Download PostScript">ps</a>, <a href="/format/2311.14944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamical State Feedback Control for Linear Input Delay Systems, Part I:  Dissipative Stabilization via Semidefinite Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Feng%2C+Q">Qian Feng</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+C">Cong Zhang</a>, 
<a href="/search/math?searchtype=author&query=Wei%2C+B">Bo Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">It is well known that predictor controllers can completely eliminate the
destabilizing effects of input delays. However, their design is typically based
on direct constructions that leave little room for incorporating closed-loop
performance objectives. To address this issue, we introduce the concept of
parameterized linear dynamical state feedbacks (LDSFs) that can achieve both
input delay compensation and stabilization for linear input delay systems with
dissipative constraints. This control construct draws inspiration from recent
developments in the mathematical treatment of distributed delays, and
generalizes conventional predictor controllers, where the degree of
parameterization can be increased by adjusting the integral term. A sufficient
condition for the existence of the LDSF is formulated as matrix inequalities by
constructing a complete type Krasovskii functional. To solve the bilinear
matrix inequality in the synthesis condition, we employ an inner convex
approximation algorithm that can be initialized using the gains of a predictor
controller obtained via explicit construction. Unlike traditional predictor
controllers, the parameters of our LTDS can be directly tuned via the proposed
optimization framework. Numerical examples and simulation have been
experimented to demonstrate the validity and effectiveness of our methodology.
</p>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14964" title="Abstract">arXiv:2311.14964</a> (cross-list from stat.ML) [<a href="/pdf/2311.14964" title="Download PDF">pdf</a>, <a href="/format/2311.14964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Selective Inference for Changepoint detection by Recurrent Neural  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Shiraishi%2C+T">Tomohiro Shiraishi</a>, 
<a href="/search/stat?searchtype=author&query=Miwa%2C+D">Daiki Miwa</a>, 
<a href="/search/stat?searchtype=author&query=Duy%2C+V+N+L">Vo Nguyen Le Duy</a>, 
<a href="/search/stat?searchtype=author&query=Takeuchi%2C+I">Ichiro Takeuchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41pages, 16figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this study, we investigate the quantification of the statistical
reliability of detected change points (CPs) in time series using a Recurrent
Neural Network (RNN). Thanks to its flexibility, RNN holds the potential to
effectively identify CPs in time series characterized by complex dynamics.
However, there is an increased risk of erroneously detecting random noise
fluctuations as CPs. The primary goal of this study is to rigorously control
the risk of false detections by providing theoretically valid p-values to the
CPs detected by RNN. To achieve this, we introduce a novel method based on the
framework of Selective Inference (SI). SI enables valid inferences by
conditioning on the event of hypothesis selection, thus mitigating selection
bias. In this study, we apply SI framework to RNN-based CP detection, where
characterizing the complex process of RNN selecting CPs is our main technical
challenge. We demonstrate the validity and effectiveness of the proposed method
through artificial and real data experiments.
</p>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14983" title="Abstract">arXiv:2311.14983</a> (cross-list from astro-ph.IM) [<a href="/pdf/2311.14983" title="Download PDF">pdf</a>, <a href="/format/2311.14983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Network Based Approach to Recognition of Meteor Tracks in the  Mini-EUSO Telescope Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Zotov%2C+M">Mikhail Zotov</a>, 
<a href="/search/astro-ph?searchtype=author&query=Anzhiganov%2C+D">Dmitry Anzhiganov</a>, 
<a href="/search/astro-ph?searchtype=author&query=Kryazhenkov%2C+A">Aleksandr Kryazhenkov</a>, 
<a href="/search/astro-ph?searchtype=author&query=Barghini%2C+D">Dario Barghini</a>, 
<a href="/search/astro-ph?searchtype=author&query=Battisti%2C+M">Matteo Battisti</a>, 
<a href="/search/astro-ph?searchtype=author&query=Belov%2C+A">Alexander Belov</a>, 
<a href="/search/astro-ph?searchtype=author&query=Bertaina%2C+M">Mario Bertaina</a>, 
<a href="/search/astro-ph?searchtype=author&query=Bianciotto%2C+M">Marta Bianciotto</a>, 
<a href="/search/astro-ph?searchtype=author&query=Bisconti%2C+F">Francesca Bisconti</a>, 
<a href="/search/astro-ph?searchtype=author&query=Blaksley%2C+C">Carl Blaksley</a>, 
<a href="/search/astro-ph?searchtype=author&query=Blin%2C+S">Sylvie Blin</a>, 
<a href="/search/astro-ph?searchtype=author&query=Cambi%C3%A8%2C+G">Giorgio Cambi&#xe8;</a>, 
<a href="/search/astro-ph?searchtype=author&query=Capel%2C+F">Francesca Capel</a>, 
<a href="/search/astro-ph?searchtype=author&query=Casolino%2C+M">Marco Casolino</a>, 
<a href="/search/astro-ph?searchtype=author&query=Ebisuzaki%2C+T">Toshikazu Ebisuzaki</a>, 
<a href="/search/astro-ph?searchtype=author&query=Eser%2C+J">Johannes Eser</a>, 
<a href="/search/astro-ph?searchtype=author&query=Fenu%2C+F">Francesco Fenu</a>, 
<a href="/search/astro-ph?searchtype=author&query=Franceschi%2C+M+A">Massimo Alberto Franceschi</a>, 
<a href="/search/astro-ph?searchtype=author&query=Golzio%2C+A">Alessio Golzio</a>, 
<a href="/search/astro-ph?searchtype=author&query=Gorodetzky%2C+P">Philippe Gorodetzky</a>, 
<a href="/search/astro-ph?searchtype=author&query=Kajino%2C+F">Fumiyoshi Kajino</a>, 
<a href="/search/astro-ph?searchtype=author&query=Kasuga%2C+H">Hiroshi Kasuga</a>, 
<a href="/search/astro-ph?searchtype=author&query=Klimov%2C+P">Pavel Klimov</a>, 
<a href="/search/astro-ph?searchtype=author&query=Manfrin%2C+M">Massimiliano Manfrin</a>, 
<a href="/search/astro-ph?searchtype=author&query=Marcelli%2C+L">Laura Marcelli</a>, 
<a href="/search/astro-ph?searchtype=author&query=Miyamoto%2C+H">Hiroko Miyamoto</a>, 
<a href="/search/astro-ph?searchtype=author&query=Murashov%2C+A">Alexey Murashov</a>, 
<a href="/search/astro-ph?searchtype=author&query=Napolitano%2C+T">Tommaso Napolitano</a>, 
<a href="/search/astro-ph?searchtype=author&query=Ohmori%2C+H">Hiroshi Ohmori</a>, 
<a href="/search/astro-ph?searchtype=author&query=Olinto%2C+A">Angela Olinto</a>, 
<a href="/search/astro-ph?searchtype=author&query=Parizot%2C+E">Etienne Parizot</a>, 
<a href="/search/astro-ph?searchtype=author&query=Picozza%2C+P">Piergiorgio Picozza</a>, 
<a href="/search/astro-ph?searchtype=author&query=Piotrowski%2C+L+W">Lech Wiktor Piotrowski</a>, 
<a href="/search/astro-ph?searchtype=author&query=Plebaniak%2C+Z">Zbigniew Plebaniak</a>, 
<a href="/search/astro-ph?searchtype=author&query=Pr%C3%A9v%C3%B4t%2C+G">Guillaume Pr&#xe9;v&#xf4;t</a>, 
<a href="/search/astro-ph?searchtype=author&query=Reali%2C+E">Enzo Reali</a>, 
<a href="/search/astro-ph?searchtype=author&query=Ricci%2C+M">Marco Ricci</a>, 
<a href="/search/astro-ph?searchtype=author&query=Romoli%2C+G">Giulia Romoli</a>, 
<a href="/search/astro-ph?searchtype=author&query=Sakaki%2C+N">Naoto Sakaki</a>, 
<a href="/search/astro-ph?searchtype=author&query=Shinozaki%2C+K">Kenji Shinozaki</a>, 
<a href="/search/astro-ph?searchtype=author&query=De+La+Taille%2C+C">Christophe De La Taille</a>, 
<a href="/search/astro-ph?searchtype=author&query=Takizawa%2C+Y">Yoshiyuki Takizawa</a>, 
<a href="/search/astro-ph?searchtype=author&query=Vr%C3%A1bel%2C+M">Michal Vr&#xe1;bel</a>, 
<a href="/search/astro-ph?searchtype=author&query=Wiencke%2C+L">Lawrence Wiencke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Algorithms 2023, 16(9), 448
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Mini-EUSO is a wide-angle fluorescence telescope that registers ultraviolet
(UV) radiation in the nocturnal atmosphere of Earth from the International
Space Station. Meteors are among multiple phenomena that manifest themselves
not only in the visible range but also in the UV. We present two simple
artificial neural networks that allow for recognizing meteor signals in the
Mini-EUSO data with high accuracy in terms of a binary classification problem.
We expect that similar architectures can be effectively used for signal
recognition in other fluorescence telescopes, regardless of the nature of the
signal. Due to their simplicity, the networks can be implemented in onboard
electronics of future orbital or balloon experiments.
</p>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14990" title="Abstract">arXiv:2311.14990</a> (cross-list from eess.IV) [<a href="/pdf/2311.14990" title="Download PDF">pdf</a>, <a href="/format/2311.14990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> View it like a radiologist: Shifted windows for deep learning  augmentation of CT images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=%C3%98stmo%2C+E+A">Eirik A. &#xd8;stmo</a>, 
<a href="/search/eess?searchtype=author&query=Wickstr%C3%B8m%2C+K+K">Kristoffer K. Wickstr&#xf8;m</a>, 
<a href="/search/eess?searchtype=author&query=Radiya%2C+K">Keyur Radiya</a>, 
<a href="/search/eess?searchtype=author&query=Kampffmeyer%2C+M+C">Michael C. Kampffmeyer</a>, 
<a href="/search/eess?searchtype=author&query=Jenssen%2C+R">Robert Jenssen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, accepted to MLSP 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE 33rd International Workshop on Machine Learning for
  Signal Processing (MLSP), 1-6
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning has the potential to revolutionize medical practice by
automating and performing important tasks like detecting and delineating the
size and locations of cancers in medical images. However, most deep learning
models rely on augmentation techniques that treat medical images as natural
images. For contrast-enhanced Computed Tomography (CT) images in particular,
the signals producing the voxel intensities have physical meaning, which is
lost during preprocessing and augmentation when treating such images as natural
images. To address this, we propose a novel preprocessing and intensity
augmentation scheme inspired by how radiologists leverage multiple viewing
windows when evaluating CT images. Our proposed method, window shifting,
randomly places the viewing windows around the region of interest during
training. This approach improves liver lesion segmentation performance and
robustness on images with poorly timed contrast agent. Our method outperforms
classical intensity augmentations as well as the intensity augmentation
pipeline of the popular nn-UNet on multiple datasets.
</p>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14997" title="Abstract">arXiv:2311.14997</a> (cross-list from math.CO) [<a href="/pdf/2311.14997" title="Download PDF">pdf</a>, <a href="/ps/2311.14997" title="Download PostScript">ps</a>, <a href="/format/2311.14997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Every latin hypercube of order 5 has transversals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Perezhogin%2C+A+L">A. L. Perezhogin</a>, 
<a href="/search/math?searchtype=author&query=Potapov%2C+V+N">V. N. Potapov</a>, 
<a href="/search/math?searchtype=author&query=Vladimirov%2C+S+Y">S. Yu. Vladimirov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Supplementary data <a href="https://zenodo.org/records/10204026">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">We prove that for all n&gt;1 every latin n-dimensional cube of order 5 has
transversals. We find all 123 paratopy classes of layer-latin cubes of order 5
with no transversals. For each $n\geq 3$ and $q\geq 3$ we construct a
(2q-2)-layer latin n-dimensional cuboid with no transversals. Moreover, we find
all paratopy classes of nonextendible and noncompletable latin cuboids of order
5.
</p>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15028" title="Abstract">arXiv:2311.15028</a> (cross-list from astro-ph.EP) [<a href="/pdf/2311.15028" title="Download PDF">pdf</a>, <a href="/format/2311.15028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mathematical Modelling and a Numerical Solution for High Precision  Satellite Ephemeris Determination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Gundakaram%2C+A">Aravind Gundakaram</a>, 
<a href="/search/astro-ph?searchtype=author&query=Sangala%2C+A">Abhirath Sangala</a>, 
<a href="/search/astro-ph?searchtype=author&query=Ellendula%2C+A+S">Aditya Sai Ellendula</a>, 
<a href="/search/astro-ph?searchtype=author&query=Kansal%2C+P">Prachi Kansal</a>, 
<a href="/search/astro-ph?searchtype=author&query=Lakshitaa%2C+L">Lanii Lakshitaa</a>, 
<a href="/search/astro-ph?searchtype=author&query=Punuru%2C+S+R">Suchir Reddy Punuru</a>, 
<a href="/search/astro-ph?searchtype=author&query=Naveen%2C+N">Nethra Naveen</a>, 
<a href="/search/astro-ph?searchtype=author&query=Jaggumantri%2C+S">Sanjitha Jaggumantri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted and Presented at 9th International Conference and Exhibition on Satellite and Space Missions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Earth and Planetary Astrophysics (astro-ph.EP)</span>; Mathematical Software (cs.MS); Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this paper, we develop a high-precision satellite orbit determination
model for satellites orbiting the Earth. Solving this model entails numerically
integrating the differential equation of motion governing a two-body system,
employing Fehlberg's formulation and the Runge-Kutta class of embedded
integrators with adaptive stepsize control. Relevant primary perturbing forces
included in this mathematical model are the full force gravitational field
model, Earth's atmospheric drag, third body gravitational effects and solar
radiation pressure. Development of the high-precision model required accounting
for the perturbing influences of Earth radiation pressure, Earth tides and
relativistic effects. The model is then implemented to obtain a high-fidelity
Earth orbiting satellite propagator, namely the Satellite Ephemeris Determiner
(SED), which is comparable to the popular High Precision Orbit Propagator
(HPOP). The architecture of SED, the methodology employed, and the numerical
results obtained are presented.
</p>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15039" title="Abstract">arXiv:2311.15039</a> (cross-list from math.GR) [<a href="/pdf/2311.15039" title="Download PDF">pdf</a>, <a href="/ps/2311.15039" title="Download PostScript">ps</a>, <a href="/format/2311.15039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subsets of groups in public-key cryptography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Carvalho%2C+A">Andr&#xe9; Carvalho</a>, 
<a href="/search/math?searchtype=author&query=Malheiro%2C+A">Ant&#xf3;nio Malheiro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, comments welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Group Theory (math.GR)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">We suggest the usage of algebraic subsets instead of subgroups in public-key
cryptography. In particular, we present the subset version of two protocols
introduced by Shpilrain and Ushakov with some examples in ascending
HNN-extensions of free-abelian groups and discuss their resistance to length
and distance based attacks. We also introduce several new group theoretic
problems arising from this work.
</p>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15060" title="Abstract">arXiv:2311.15060</a> (cross-list from eess.SP) [<a href="/pdf/2311.15060" title="Download PDF">pdf</a>, <a href="/ps/2311.15060" title="Download PostScript">ps</a>, <a href="/format/2311.15060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Key Issues in Wireless Transmission for NTN-Assisted Internet of Things
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Qi%2C+C">Chenhao Qi</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jing Wang</a>, 
<a href="/search/eess?searchtype=author&query=Lyu%2C+L">Leyi Lyu</a>, 
<a href="/search/eess?searchtype=author&query=Tan%2C+L">Lei Tan</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jinming Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+G+Y">Geoffrey Ye Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Non-terrestrial networks (NTNs) have become appealing resolutions for
seamless coverage in the next-generation wireless transmission, where a large
number of Internet of Things (IoT) devices diversely distributed can be
efficiently served. The explosively growing number of IoT devices brings a new
challenge for massive connection. The long-distance wireless signal propagation
in NTNs leads to severe path loss and large latency, where the accurate
acquisition of channel state information (CSI) is another challenge, especially
for fast-moving non-terrestrial base stations (NTBSs). Moreover, the scarcity
of on-board resources of NTBSs is also a challenge for resource allocation. To
this end, we investigate three key issues, where the existing schemes and
emerging resolutions for these three key issues have been comprehensively
presented. The first issue is to enable the massive connection by designing
random access to establish the wireless link and multiple access to transmit
data streams. The second issue is to accurately acquire CSI in various channel
conditions by channel estimation and beam training, where orthogonal time
frequency space modulation and dynamic codebooks are on focus. The third issue
is to efficiently allocate the wireless resources, including power allocation,
spectrum sharing, beam hopping, and beamforming. At the end of this article,
some future research topics are identified.
</p>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15062" title="Abstract">arXiv:2311.15062</a> (cross-list from eess.SP) [<a href="/pdf/2311.15062" title="Download PDF">pdf</a>, <a href="/format/2311.15062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simultaneous Beam Training and Target Sensing in ISAC Systems with RIS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+K">Kangjian Chen</a>, 
<a href="/search/eess?searchtype=author&query=Qi%2C+C">Chenhao Qi</a>, 
<a href="/search/eess?searchtype=author&query=Dobre%2C+O+A">Octavia A. Dobre</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+G+Y">Geoffrey Ye Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">This paper investigates an integrated sensing and communication (ISAC) system
with reconfigurable intelligent surface (RIS). Our simultaneous beam training
and target sensing (SBTTS) scheme enables the base station to perform beam
training with the user terminals (UTs) and the RIS, and simultaneously to sense
the targets. Based on our findings, the energy of the echoes from the RIS is
accumulated in the angle-delay domain while that from the targets is
accumulated in the Doppler-delay domain. The SBTTS scheme can distinguish the
RIS from the targets with the mixed echoes from the RIS and the targets. Then
we propose a positioning and array orientation estimation (PAOE) scheme for
both the line-of-sight channels and the non-line-of-sight channels based on the
beam training results of SBTTS by developing a low-complexity two-dimensional
fast search algorithm. Based on the SBTTS and PAOE schemes, we further compute
the angle-of-arrival and angle-of-departure for the channels between the RIS
and the UTs by exploiting the geometry relationship to accomplish the beam
alignment of the ISAC system. Simulation results verify the effectiveness of
the proposed schemes.
</p>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15088" title="Abstract">arXiv:2311.15088</a> (cross-list from physics.comp-ph) [<a href="/pdf/2311.15088" title="Download PDF">pdf</a>, <a href="/format/2311.15088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A GPU-based Hydrodynamic Simulator with Boid Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Liu%2C+X">Xi Liu</a>, 
<a href="/search/physics?searchtype=author&query=Kayar%2C+G">Gizem Kayar</a>, 
<a href="/search/physics?searchtype=author&query=Perlin%2C+K">Ken Perlin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Hardware Architecture (cs.AR); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a hydrodynamic simulation system using the GPU compute shaders of
DirectX for simulating virtual agent behaviors and navigation inside a smoothed
particle hydrodynamical (SPH) fluid environment with real-time water mesh
surface reconstruction. The current SPH literature includes interactions
between SPH and heterogeneous meshes but seldom involves interactions between
SPH and virtual boid agents. The contribution of the system lies in the
combination of the parallel smoothed particle hydrodynamics model with the
distributed boid model of virtual agents to enable agents to interact with
fluids. The agents based on the boid algorithm influence the motion of SPH
fluid particles, and the forces from the SPH algorithm affect the movement of
the boids. To enable realistic fluid rendering and simulation in a
particle-based system, it is essential to construct a mesh from the particle
attributes. Our system also contributes to the surface reconstruction aspect of
the pipeline, in which we performed a set of experiments with the parallel
marching cubes algorithm per frame for constructing the mesh from the fluid
particles in a real-time compute and memory-intensive application, producing a
wide range of triangle configurations. We also demonstrate that our system is
versatile enough for reinforced robotic agents instead of boid agents to
interact with the fluid environment for underwater navigation and remote
control engineering purposes.
</p>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15090" title="Abstract">arXiv:2311.15090</a> (cross-list from eess.IV) [<a href="/pdf/2311.15090" title="Download PDF">pdf</a>, <a href="/format/2311.15090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Grained Unsupervised Cross-Modality Domain Adaptation for  Vestibular Schwannoma Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Han%2C+L">Luyi Han</a>, 
<a href="/search/eess?searchtype=author&query=Tan%2C+T">Tao Tan</a>, 
<a href="/search/eess?searchtype=author&query=Mann%2C+R">Ritse Mann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The domain adaptation approach has gained significant acceptance in
transferring styles across various vendors and centers, along with filling the
gaps in modalities. However, multi-center application faces the challenge of
the difficulty of domain adaptation due to their intra-domain differences. We
focus on introducing a fine-grained unsupervised framework for domain
adaptation to facilitate cross-modality segmentation of vestibular schwannoma
(VS) and cochlea. We propose to use a vector to control the generator to
synthesize a fake image with given features. And then, we can apply various
augmentations to the dataset by searching the feature dictionary. The diversity
augmentation can increase the performance and robustness of the segmentation
model. On the CrossMoDA validation phase Leaderboard, our method received a
mean Dice score of 0.765 and 0.836 on VS and cochlea, respectively.
</p>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15109" title="Abstract">arXiv:2311.15109</a> (cross-list from math.OC) [<a href="/pdf/2311.15109" title="Download PDF">pdf</a>, <a href="/format/2311.15109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Stability of Neural Feedback Systems with Interval Matrix  Uncertainties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+Y">Yuhao Zhang</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+X">Xiangru Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Neural networks have gained popularity in controller design due to their
versatility and efficiency, but their integration into feedback systems can
compromise stability, especially in the presence of uncertainties. This paper
addresses the challenge of certifying robust stability in neural feedback
systems with interval matrix uncertainties. By leveraging classic robust
stability techniques and the recent quadratic constraint-based method to
abstract the input-output relationship imposed by neural networks, we present
novel robust stability certificates that are formulated in the form of linear
matrix inequalities. Three relaxed sufficient conditions are introduced to
mitigate computational complexity. The equivalence of these conditions in terms
of feasibility, as well as their connections with existing robust stability
results, are also established. The proposed method is demonstrated by two
numerical examples.
</p>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15123" title="Abstract">arXiv:2311.15123</a> (cross-list from quant-ph) [<a href="/pdf/2311.15123" title="Download PDF">pdf</a>, <a href="/format/2311.15123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FPQA-C: A Compilation Framework for Field Programmable Qubit Array
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+H">Hanrui Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+P">Pengyu Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tan%2C+B">Bochen Tan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+Y">Yilian Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gu%2C+J">Jiaqi Gu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pan%2C+D+Z">David Z. Pan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cong%2C+J">Jason Cong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Acar%2C+U">Umut Acar</a>, 
<a href="/search/quant-ph?searchtype=author&query=Han%2C+S">Song Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 24 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Hardware Architecture (cs.AR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">The neutral atom array has gained prominence in quantum computing for its
scalability and operation fidelity. Previous works focus on \textit{fixed} atom
arrays (FAA) that necessitate extensive SWAP operations for long-range
interactions. This work explores a novel architecture known as \textit{field
programmable qubit array (FPQA)}, which uniquely allows for coherent atom
movements during circuit execution and significantly \textit{reduces the cost
of long-range interactions}. However, the atom movements have multiple hardware
constraints, making movement scheduling very challenging.
<br />In this work, we introduce FPQA-C, a compilation framework tailored for qubit
mapping, atom movement, and gate scheduling of FPQA. It contains a qubit-array
mapper to decide the coarse-grained mapping of qubit to arrays, leveraging MAX
k-Cut on a constructed gate frequency graph to minimize SWAP overhead.
Subsequently, a qubit-atom mapper determines the fine-grained mapping of qubits
to specific atoms in the array, and considers load balance to prevent hardware
constraint violations. We further propose a high-parallelism router that
iteratively identifies parallelizable 2Q gates and decide the atom movements
and gate executions, thus improving the parallelism. Besides, for
fault-tolerant computing with FPQA, we provide comprehensive simulations
evaluating logical error rates, execution times, physical qubit requirements,
code distances, and bandwidth.
<br />We rigorously assess FPQA-C across 20+ diverse benchmarks, including generic
circuits (arbitrary, QASMBench, SupermarQ), Quantum Simulation, and QAOA
circuits. FPQA-C consistently outperforms the IBM Superconducting, FAA with
long-range gates, FAA with rectangular and triangular topologies, achieving 2Q
gate reductions by factors of 5.3x, 3.2x, 3.4x, and 2.6x, and circuit depth
reductions by factors of 3.6x, 3.2x, 3.1x, and 2.2x, respectively.
</p>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15137" title="Abstract">arXiv:2311.15137</a> (cross-list from math.OC) [<a href="/pdf/2311.15137" title="Download PDF">pdf</a>, <a href="/format/2311.15137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-fidelity Constrained Optimization for Stochastic Black Box  Simulators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Agrawal%2C+A">Atul Agrawal</a>, 
<a href="/search/math?searchtype=author&query=Ravi%2C+K">Kislaya Ravi</a>, 
<a href="/search/math?searchtype=author&query=Koutsourelakis%2C+P">Phaedon-Stelios Koutsourelakis</a>, 
<a href="/search/math?searchtype=author&query=Bungartz%2C+H">Hans-Joachim Bungartz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Constrained optimization of the parameters of a simulator plays a crucial
role in a design process. These problems become challenging when the simulator
is stochastic, computationally expensive, and the parameter space is
high-dimensional. One can efficiently perform optimization only by utilizing
the gradient with respect to the parameters, but these gradients are
unavailable in many legacy, black-box codes. We introduce the algorithm
Scout-Nd (Stochastic Constrained Optimization for N dimensions) to tackle the
issues mentioned earlier by efficiently estimating the gradient, reducing the
noise of the gradient estimator, and applying multi-fidelity schemes to further
reduce computational effort. We validate our approach on standard benchmarks,
demonstrating its effectiveness in optimizing parameters highlighting better
performance compared to existing methods.
</p>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15167" title="Abstract">arXiv:2311.15167</a> (cross-list from eess.IV) [<a href="/pdf/2311.15167" title="Download PDF">pdf</a>, <a href="/format/2311.15167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised OCT Image Denoising with Slice-to-Slice Registration and  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Shijie Li</a>, 
<a href="/search/eess?searchtype=author&query=Alexopoulos%2C+P">Palaiologos Alexopoulos</a>, 
<a href="/search/eess?searchtype=author&query=Vellappally%2C+A">Anse Vellappally</a>, 
<a href="/search/eess?searchtype=author&query=Zambrano%2C+R">Ronald Zambrano</a>, 
<a href="/search/eess?searchtype=author&query=Gadi%2C+W">Wollstein Gadi</a>, 
<a href="/search/eess?searchtype=author&query=Gerig%2C+G">Guido Gerig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, 1 table, submitted to International Symposium on Biomedical Imaging 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Strong speckle noise is inherent to optical coherence tomography (OCT)
imaging and represents a significant obstacle for accurate quantitative
analysis of retinal structures which is key for advances in clinical diagnosis
and monitoring of disease. Learning-based self-supervised methods for
structure-preserving noise reduction have demonstrated superior performance
over traditional methods but face unique challenges in OCT imaging. The high
correlation of voxels generated by coherent A-scan beams undermines the
efficacy of self-supervised learning methods as it violates the assumption of
independent pixel noise. We conduct experiments demonstrating limitations of
existing models due to this independence assumption. We then introduce a new
end-to-end self-supervised learning framework specifically tailored for OCT
image denoising, integrating slice-by-slice training and registration modules
into one network. An extensive ablation study is conducted for the proposed
approach. Comparison to previously published self-supervised denoising models
demonstrates improved performance of the proposed framework, potentially
serving as a preprocessing step towards superior segmentation performance and
quantitative analysis.
</p>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15175" title="Abstract">arXiv:2311.15175</a> (cross-list from math.OC) [<a href="/pdf/2311.15175" title="Download PDF">pdf</a>, <a href="/format/2311.15175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Multi-Timestep Security-Constrained Optimal Power Flow for  Large Power Grids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sharadga%2C+H">Hussein Sharadga</a>, 
<a href="/search/math?searchtype=author&query=Mohammadi%2C+J">Javad Mohammadi</a>, 
<a href="/search/math?searchtype=author&query=Crozier%2C+C">Constance Crozier</a>, 
<a href="/search/math?searchtype=author&query=Baker%2C+K">Kyri Baker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This work proposes a novel method for scaling multi-timestep
security-constrained optimal power flow in large power grids. The challenge
arises from dealing with millions of variables and constraints, including
binary variables and nonconvex, nonlinear characteristics. To navigate these
complexities, techniques such as constraint relaxation, linearization,
sequential optimization, and problem reformulation are employed. By leveraging
these methods, complex power grid problems are solved while achieving
high-quality solutions and meeting time constraints. The innovative solution
approach showcases great robustness and consistently outperforms benchmark
standards.
</p>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15180" title="Abstract">arXiv:2311.15180</a> (cross-list from q-fin.TR) [<a href="/pdf/2311.15180" title="Download PDF">pdf</a>, <a href="/format/2311.15180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Large Language Model Volatility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Yu%2C+B">Boyang Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures, Workshop on AI Safety and Robustness In Finance, ICAIF 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Trading and Market Microstructure (q-fin.TR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The impact of non-deterministic outputs from Large Language Models (LLMs) is
not well examined for financial text understanding tasks. Through a compelling
case study on investing in the US equity market via news sentiment analysis, we
uncover substantial variability in sentence-level sentiment classification
results, underscoring the innate volatility of LLM outputs. These uncertainties
cascade downstream, leading to more significant variations in portfolio
construction and return. While tweaking the temperature parameter in the
language model decoder presents a potential remedy, it comes at the expense of
stifled creativity. Similarly, while ensembling multiple outputs mitigates the
effect of volatile outputs, it demands a notable computational investment. This
work furnishes practitioners with invaluable insights for adeptly navigating
uncertainty in the integration of LLMs into financial decision-making,
particularly in scenarios dictated by non-deterministic information.
</p>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15207" title="Abstract">arXiv:2311.15207</a> (cross-list from physics.chem-ph) [<a href="/pdf/2311.15207" title="Download PDF">pdf</a>, <a href="/format/2311.15207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient interpolation of molecular properties across chemical compound  space with low-dimensional descriptors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Mao%2C+Y">Yun-Wen Mao</a>, 
<a href="/search/physics?searchtype=author&query=Krems%2C+R+V">Roman V. Krems</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 12 figures, submitted to Machine Learning: Science and Technology November 22nd, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We demonstrate accurate data-starved models of molecular properties for
interpolation in chemical compound spaces with low-dimensional descriptors.
<br />Our starting point is based on three-dimensional, universal, physical
descriptors derived from the properties of the distributions of the eigenvalues
of Coulomb matrices. To account for the shape and composition of molecules, we
combine these descriptors with six-dimensional features informed by the
Gershgorin circle theorem. We use the nine-dimensional descriptors thus
obtained for Gaussian process regression based on kernels with variable
functional form, leading to extremely efficient, low-dimensional interpolation
models. The resulting models trained with 100 molecules are able to predict the
product of entropy and temperature ($S \times T$) and zero point vibrational
energy (ZPVE) with the absolute error under 1 kcal mol$^{-1}$ for $&gt; 78$ \% and
under 1.3 kcal mol$^{-1}$ for $&gt; 92$ \% of molecules in the test data. The test
data comprises 20,000 molecules with complexity varying from three atoms to 29
atoms and the ranges of $S \times T$ and ZPVE covering 36 kcal mol$^{-1}$ and
161 kcal mol$^{-1}$, respectively. We also illustrate that the descriptors
based on the Gershgorin circle theorem yield more accurate models of molecular
entropy than those based on graph neural networks that explicitly account for
the atomic connectivity of molecules.
</p>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15213" title="Abstract">arXiv:2311.15213</a> (cross-list from eess.IV) [<a href="/pdf/2311.15213" title="Download PDF">pdf</a>, <a href="/ps/2311.15213" title="Download PostScript">ps</a>, <a href="/format/2311.15213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Anatomical Constraints with Uncertainty for Pneumothorax  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yuan%2C+H">Han Yuan</a>, 
<a href="/search/eess?searchtype=author&query=Hong%2C+C">Chuan Hong</a>, 
<a href="/search/eess?searchtype=author&query=Tran%2C+N+T+A">Nguyen Tuan Anh Tran</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+X">Xinxing Xu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+N">Nan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Pneumothorax is a medical emergency caused by abnormal accumulation of air in
the pleural space - the potential space between the lungs and chest wall. On 2D
chest radiographs, pneumothorax occurs within the thoracic cavity and outside
of the mediastinum and we refer to this area as "lung+ space". While deep
learning (DL) has increasingly been utilized to segment pneumothorax lesions in
chest radiographs, many existing DL models employ an end-to-end approach. These
models directly map chest radiographs to clinician-annotated lesion areas,
often neglecting the vital domain knowledge that pneumothorax is inherently
location-sensitive.
<br />We propose a novel approach that incorporates the lung+ space as a constraint
during DL model training for pneumothorax segmentation on 2D chest radiographs.
To circumvent the need for additional annotations and to prevent potential
label leakage on the target task, our method utilizes external datasets and an
auxiliary task of lung segmentation. This approach generates a specific
constraint of lung+ space for each chest radiograph. Furthermore, we have
incorporated a discriminator to eliminate unreliable constraints caused by the
domain shift between the auxiliary and target datasets.
<br />Our results demonstrated significant improvements, with average performance
gains of 4.6%, 3.6%, and 3.3% regarding Intersection over Union (IoU), Dice
Similarity Coefficient (DSC), and Hausdorff Distance (HD). Our research
underscores the significance of incorporating medical domain knowledge about
the location-specific nature of pneumothorax to enhance DL-based lesion
segmentation.
</p>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15215" title="Abstract">arXiv:2311.15215</a> (cross-list from eess.SP) [<a href="/pdf/2311.15215" title="Download PDF">pdf</a>, <a href="/format/2311.15215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From OTFS to DD-ISAC: Integrating Sensing and Communications in the  Delay Doppler Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yuan%2C+W">Weijie Yuan</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+L">Lin Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Dehkordi%2C+S+K">Saeid K. Dehkordi</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Shuangyang Li</a>, 
<a href="/search/eess?searchtype=author&query=Fan%2C+P">Pingzhi Fan</a>, 
<a href="/search/eess?searchtype=author&query=Caire%2C+G">Giuseppe Caire</a>, 
<a href="/search/eess?searchtype=author&query=Poor%2C+H+V">H. Vincent Poor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Magazine paper submitted to IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Next-generation vehicular networks are expected to provide the capability of
robust environmental sensing in addition to reliable communications to meet
intelligence requirements. A promising solution is the integrated sensing and
communication (ISAC) technology, which performs both functionalities using the
same spectrum and hardware resources. Most existing works on ISAC consider the
Orthogonal Frequency Division Multiplexing (OFDM) waveform. Nevertheless,
vehicle motion introduces Doppler shift, which breaks the subcarrier
orthogonality and leads to performance degradation. The recently proposed
Orthogonal Time Frequency Space (OTFS) modulation, which exploits various
advantages of Delay Doppler (DD) channels, has been shown to support reliable
communication in high-mobility scenarios. Moreover, the DD waveform can
directly interact with radar sensing parameters, which are actually delay and
Doppler shifts. This paper investigates the advantages of applying the DD
communication waveform to ISAC. Specifically, we first provide a comprehensive
overview of implementing DD communications, based on which several advantages
of DD-ISAC over OFDM-based ISAC are revealed, including transceiver designs and
the ambiguity function. Furthermore, a detailed performance comparison are
presented, where the target detection probability and the mean squared error
(MSE) performance are also studied. Finally, some challenges and opportunities
of DD-ISAC are also provided.
</p>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15234" title="Abstract">arXiv:2311.15234</a> (cross-list from math.DS) [<a href="/pdf/2311.15234" title="Download PDF">pdf</a>, <a href="/ps/2311.15234" title="Download PostScript">ps</a>, <a href="/format/2311.15234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the algorithmic descriptive complexity of attractors in topological  dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Rojas%2C+C">Cristobal Rojas</a>, 
<a href="/search/math?searchtype=author&query=Sablik%2C+M">Mathieu Sablik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">We study the computational problem of rigorously describing the asymptotic
behaviour of topological dynamical systems up to a finite but arbitrarily small
pre-specified error. More precisely, we consider the limit set of a typical
orbit, both as a spatial object (attractor set) and as a statistical
distribution (physical measure), and prove upper bounds on the computational
resources of computing descriptions of these objects with arbitrary accuracy.
We also study how these bounds are affected by different dynamical constrains
and provide several examples showing that our bounds are sharp in general. In
particular, we exhibit a computable interval map having a unique transitive
attractor with Cantor set structure supporting a unique physical measure such
that both the attractor and the measure are non computable.
</p>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15237" title="Abstract">arXiv:2311.15237</a> (cross-list from math.OC) [<a href="/pdf/2311.15237" title="Download PDF">pdf</a>, <a href="/format/2311.15237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the sensing power of mixed vehicle fleets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Han%2C+K">Ke Han</a>, 
<a href="/search/math?searchtype=author&query=Ji%2C+W">Wen Ji</a>, Yu (Marco)Nie, 
<a href="/search/math?searchtype=author&query=Li%2C+Z">Zhexian Li</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+S">Shenglin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Vehicle-based mobile sensing (a.k.a. drive-by sensing) has become an
important means to survey urban environment at low costs by leveraging the
mobility of urban vehicles. Recent studies have focused on characterizing and
optimizing the power of drive-by sensing, but restricted to fleets of a single
type. In this work, we explore the sensing power and cost effectiveness of
fleets comprised of taxis, buses and dedicated vehicles (DVs), each
characterized by unique mobility patterns and operational characteristics. This
is achieved by solving the drive-by sensing coverage (DSC) problem, which
includes (1) a method to quantify the sensing utility of spatial-temporal
vehicle coverage, followed by a first-order optimality analysis leading to
target sensing distributions; (2) an optimization procedure that simultaneously
determines fleet composition, sensor allocation and vehicle routing for a given
budget. Such a procedure includes a convex program for the taxi-bus fleet, and
a dual-spatial-scale routing problem for the DVs. An air quality sensing case
study in Longquanyi District (Chengdu, China) shows that (1) mixed fleets
considerably increase the sensing utilities and yields close approximation to
the target sensing distribution even with low budgets; (2) mixed fleet can save
at least 30% budget while achieving sensing quality no worse than homogenous
fleets. These insights are generalized to two additional real-world networks,
with a regression analysis that further uncover the key factors underlying the
sensing power of mixed fleets. This work offers quantitative and managerial
insights into drive-by sensing, which represents a positive externality of
urban transport activities.
</p>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15301" title="Abstract">arXiv:2311.15301</a> (cross-list from eess.IV) [<a href="/pdf/2311.15301" title="Download PDF">pdf</a>, <a href="/ps/2311.15301" title="Download PostScript">ps</a>, <a href="/format/2311.15301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eye Disease Prediction using Ensemble Learning and Attention on OCT  Scans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Naik%2C+G">Gauri Naik</a>, 
<a href="/search/eess?searchtype=author&query=Narvekar%2C+N">Nandini Narvekar</a>, 
<a href="/search/eess?searchtype=author&query=Agarwal%2C+D">Dimple Agarwal</a>, 
<a href="/search/eess?searchtype=author&query=Nandanwar%2C+N">Nishita Nandanwar</a>, 
<a href="/search/eess?searchtype=author&query=Pande%2C+H">Himangi Pande</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full paper accepted at FICC (Springer) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Eye diseases have posed significant challenges for decades, but advancements
in technology have opened new avenues for their detection and treatment.
Machine learning and deep learning algorithms have become instrumental in this
domain, particularly when combined with Optical Coherent Technology (OCT)
imaging. We propose a novel method for efficient detection of eye diseases from
OCT images. Our technique enables the classification of patients into disease
free (normal eyes) or affected by specific conditions such as Choroidal
Neovascularization (CNV), Diabetic Macular Edema (DME), or Drusen. In this
work, we introduce an end to end web application that utilizes machine learning
and deep learning techniques for efficient eye disease prediction. The
application allows patients to submit their raw OCT scanned images, which
undergo segmentation using a trained custom UNet model. The segmented images
are then fed into an ensemble model, comprising InceptionV3 and Xception
networks, enhanced with a self attention layer. This self attention approach
leverages the feature maps of individual models to achieve improved
classification accuracy. The ensemble model's output is aggregated to predict
and classify various eye diseases. Extensive experimentation and optimization
have been conducted to ensure the application's efficiency and optimal
performance. Our results demonstrate the effectiveness of the proposed approach
in accurate eye disease prediction. The developed web application holds
significant potential for early detection and timely intervention, thereby
contributing to improved eye healthcare outcomes.
</p>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15302" title="Abstract">arXiv:2311.15302</a> (cross-list from math.OC) [<a href="/pdf/2311.15302" title="Download PDF">pdf</a>, <a href="/ps/2311.15302" title="Download PostScript">ps</a>, <a href="/format/2311.15302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Quick Response Algorithm for Dynamic Autonomous Mobile Robot Routing  Problem with Time Windows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cheng%2C+L">Lulu Cheng</a>, 
<a href="/search/math?searchtype=author&query=Zhao%2C+N">Ning Zhao</a>, 
<a href="/search/math?searchtype=author&query=Yuan%2C+M">Mengge Yuan</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+K">Kan Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This paper investigates the optimization problem of scheduling autonomous
mobile robots (AMRs) in hospital settings, considering dynamic requests with
different priorities. The primary objective is to minimize the daily service
cost by dynamically planning routes for the limited number of available AMRs.
The total cost consists of AMR's purchase cost, transportation cost, delay
penalty cost, and loss of denial of service. To address this problem, we have
established a two-stage mathematical programming model. In the first stage, a
tabu search algorithm is employed to plan prior routes for all known medical
requests. The second stage involves planning for real-time received dynamic
requests using the efficient insertion algorithm with decision rules, which
enables quick response based on the time window and demand constraints of the
dynamic requests. One of the main contributions of this study is to make
resource allocation decisions based on the present number of service AMRs for
dynamic requests with different priorities. Computational experiments using
Lackner instances demonstrate the efficient insertion algorithm with decision
rules is very fast and robust in solving the dynamic AMR routing problem with
time windows and request priority. Additionally, we provide managerial insights
concerning the AMR's safety stock settings, which can aid in decision-making
processes.
</p>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15313" title="Abstract">arXiv:2311.15313</a> (cross-list from eess.SP) [<a href="/pdf/2311.15313" title="Download PDF">pdf</a>, <a href="/ps/2311.15313" title="Download PostScript">ps</a>, <a href="/format/2311.15313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Complexity Joint Beamforming for RIS-Assisted MU-MISO Systems Based  on Model-Driven Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jin%2C+W">Weijie Jin</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wen%2C+C">Chao-Kai Wen</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+S">Shi Jin</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiao Li</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+S">Shuangfeng Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures, 2 tables. This paper has been accepted for publication by the IEEE Transactions on Wireless Communications. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Reconfigurable intelligent surfaces (RIS) can improve signal propagation
environments by adjusting the phase of the incident signal. However, optimizing
the phase shifts jointly with the beamforming vector at the access point is
challenging due to the non-convex objective function and constraints. In this
study, we propose an algorithm based on weighted minimum mean square error
optimization and power iteration to maximize the weighted sum rate (WSR) of a
RIS-assisted downlink multi-user multiple-input single-output system. To
further improve performance, a model-driven deep learning (DL) approach is
designed, where trainable variables and graph neural networks are introduced to
accelerate the convergence of the proposed algorithm. We also extend the
proposed method to include beamforming with imperfect channel state information
and derive a two-timescale stochastic optimization algorithm. Simulation
results show that the proposed algorithm outperforms state-of-the-art
algorithms in terms of complexity and WSR. Specifically, the model-driven DL
approach has a runtime that is approximately 3% of the state-of-the-art
algorithm to achieve the same performance. Additionally, the proposed algorithm
with 2-bit phase shifters outperforms the compared algorithm with continuous
phase shift.
</p>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15318" title="Abstract">arXiv:2311.15318</a> (cross-list from physics.soc-ph) [<a href="/pdf/2311.15318" title="Download PDF">pdf</a>, <a href="/ps/2311.15318" title="Download PostScript">ps</a>, <a href="/format/2311.15318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perspective in Opinion Dynamics on Complex Convex Domains of Time  Networks for Addiction, Forgetting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kawahata%2C+Y">Yasuko Kawahata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Discussion Paper:Convex Regions of Opinion Dynamics, Approaches to the Complexity of Binary Consensus with Reference to Addiction and Obliviousness:Integrated Dimer Model Perspective(2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper revises previous work and introduces changes in spatio-temporal
scales. The paper presents a model that includes layers A and B with varying
degrees of forgetting and dependence over time. We also model changes in
dependence and forgetting in layers A, A', B, and B' under certain conditions.
In addition, to discuss the formation of opinion clusters that have reinforcing
or obstructive behaviors of forgetting and dependence and are conservative or
brainwashing or detoxifying and less prone to filter bubbling, new clusters C
and D that recommend, obstruct, block, or incite forgetting and dependence over
time are Introduction. This introduction allows us to test hypotheses regarding
the expansion of opinions in two dimensions over time and space, the state of
development of opinion space, and the expansion of public opinion. Challenges
in consensus building will be highlighted, emphasizing the dynamic nature of
opinions and the need to consider factors such as dissent, distrust, and media
influence. The paper proposes an extended framework that incorporates trust,
distrust, and media influence into the consensus building model. We introduce
network analysis using dimerizing as a method to gain deeper insights. In this
context, we discuss network clustering, media influence, and consensus
building. The location and distribution of dimers will be analyzed to gain
insight into the structure and dynamics of the network. Dimertiling has been
applied in various fields other than network analysis, such as physics and
sociology. The paper concludes by emphasizing the importance of diverse
perspectives, network analysis, and influential entities in consensus building.
It also introduces torus-based visualizations that aid in understanding complex
network structures.
</p>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15328" title="Abstract">arXiv:2311.15328</a> (cross-list from eess.IV) [<a href="/pdf/2311.15328" title="Download PDF">pdf</a>, <a href="/format/2311.15328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BS-Diff: Effective Bone Suppression Using Conditional Diffusion Models  from Chest X-Ray Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+Z">Zhanghao Chen</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+Y">Yifei Sun</a>, 
<a href="/search/eess?searchtype=author&query=Qin%2C+W">Wenjian Qin</a>, 
<a href="/search/eess?searchtype=author&query=Ge%2C+R">Ruiquan Ge</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+C">Cheng Pan</a>, 
<a href="/search/eess?searchtype=author&query=Deng%2C+W">Wenming Deng</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Zhou Liu</a>, 
<a href="/search/eess?searchtype=author&query=Min%2C+W">Wenwen Min</a>, 
<a href="/search/eess?searchtype=author&query=Elazab%2C+A">Ahmed Elazab</a>, 
<a href="/search/eess?searchtype=author&query=Wan%2C+X">Xiang Wan</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Changmiao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Chest X-rays (CXRs) are commonly utilized as a low-dose modality for lung
screening. Nonetheless, the efficacy of CXRs is somewhat impeded, given that
approximately 75% of the lung area overlaps with bone, which in turn hampers
the detection and diagnosis of diseases. As a remedial measure, bone
suppression techniques have been introduced. The current dual-energy
subtraction imaging technique in the clinic requires costly equipment and
subjects being exposed to high radiation. To circumvent these issues, deep
learning-based image generation algorithms have been proposed. However,
existing methods fall short in terms of producing high-quality images and
capturing texture details, particularly with pulmonary vessels. To address
these issues, this paper proposes a new bone suppression framework, termed
BS-Diff, that comprises a conditional diffusion model equipped with a U-Net
architecture and a simple enhancement module to incorporate an autoencoder. Our
proposed network cannot only generate soft tissue images with a high bone
suppression rate but also possesses the capability to capture fine image
details. Additionally, we compiled the largest dataset since 2010, including
data from 120 patients with high-definition, high-resolution paired CXRs and
soft tissue images collected by our affiliated hospital. Extensive experiments,
comparative analyses, ablation studies, and clinical evaluations indicate that
the proposed BS-Diff outperforms several bone-suppression models across
multiple metrics.
</p>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15346" title="Abstract">arXiv:2311.15346</a> (cross-list from math.OC) [<a href="/pdf/2311.15346" title="Download PDF">pdf</a>, <a href="/format/2311.15346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Primal-Dual Extension of the Goemans--Williamson Algorithm for the  Weighted Fractional Cut-Covering Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Proen%C3%A7a%2C+N+B">Nathan Benedetto Proen&#xe7;a</a>, 
<a href="/search/math?searchtype=author&query=de+Carli+Silva%2C+M+K">Marcel K. de Carli Silva</a>, 
<a href="/search/math?searchtype=author&query=Sato%2C+C+M">Cristiane M. Sato</a>, 
<a href="/search/math?searchtype=author&query=Tun%C3%A7el%2C+L">Levent Tun&#xe7;el</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We study a weighted generalization of the fractional cut-covering problem,
which we relate to the maximum cut problem via antiblocker and gauge duality.
This relationship allows us to introduce a semidefinite programming (SDP)
relaxation whose solutions may be rounded into fractional cut covers by
sampling via the random hyperplane technique. We then provide a
$1/\alpha_{\scriptscriptstyle \mathrm{GW}}$-approximation algorithm for the
weighted fractional cut-covering problem, where $\alpha_{\scriptscriptstyle
\mathrm{GW}} \approx 0.878$ is the approximation factor of the celebrated
Goemans--Williamson algorithm for the maximum cut problem. Nearly optimal
solutions of the SDPs in our duality framework allow one to consider instances
of the maximum cut and the fractional cut-covering problems as primal-dual
pairs, where cuts and fractional cut covers simultaneously certify each other's
approximation quality. We exploit this relationship to introduce new
combinatorial certificates for both problems, as well as a randomized
polynomial-time algorithm for producing such certificates. In~particular,
we~show how the Goemans--Williamson algorithm implicitly approximates a
weighted instance of the fractional cut-covering problem, and how our new
algorithm explicitly approximates a weighted instance of the maximum cut
problem. We conclude by discussing the role played by geometric representations
of graphs in our results, and by proving our algorithms and analyses to be
optimal in several aspects.
</p>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15369" title="Abstract">arXiv:2311.15369</a> (cross-list from eess.IV) [<a href="/pdf/2311.15369" title="Download PDF">pdf</a>, <a href="/format/2311.15369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TD-Net: A Tri-domain network for sparse-view CT reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xinyuan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Su%2C+C">Changqing Su</a>, 
<a href="/search/eess?searchtype=author&query=Xiong%2C+B">Bo Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Sparse-view CT reconstruction, aimed at reducing X-ray radiation risks,
frequently suffers from image quality degradation, manifested as noise and
artifacts. Existing post-processing and dual-domain techniques, although
effective in radiation reduction, often lead to over-smoothed results,
compromising diagnostic clarity. Addressing this, we introduce TD-Net, a
pioneering tri-domain approach that unifies sinogram, image, and frequency
domain optimizations. By incorporating Frequency Supervision Module(FSM),
TD-Net adeptly preserves intricate details, overcoming the prevalent
over-smoothing issue. Extensive evaluations demonstrate TD-Net's superior
performance in reconstructing high-quality CT images from sparse views,
efficiently balancing radiation safety and image fidelity. The enhanced
capabilities of TD-Net in varied noise scenarios highlight its potential as a
breakthrough in medical imaging.
</p>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15384" title="Abstract">arXiv:2311.15384</a> (cross-list from stat.ML) [<a href="/pdf/2311.15384" title="Download PDF">pdf</a>, <a href="/format/2311.15384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust and Automatic Data Clustering: Dirichlet Process meets  Median-of-Means
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Basu%2C+S">Supratik Basu</a>, 
<a href="/search/stat?searchtype=author&query=Choudhury%2C+J+R">Jyotishka Ray Choudhury</a>, 
<a href="/search/stat?searchtype=author&query=Paul%2C+D">Debolina Paul</a>, 
<a href="/search/stat?searchtype=author&query=Das%2C+S">Swagatam Das</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Clustering stands as one of the most prominent challenges within the realm of
unsupervised machine learning. Among the array of centroid-based clustering
algorithms, the classic $k$-means algorithm, rooted in Lloyd's heuristic, takes
center stage as one of the extensively employed techniques in the literature.
Nonetheless, both $k$-means and its variants grapple with noteworthy
limitations. These encompass a heavy reliance on initial cluster centroids,
susceptibility to converging into local minima of the objective function, and
sensitivity to outliers and noise in the data. When confronted with data
containing noisy or outlier-laden observations, the Median-of-Means (MoM)
estimator emerges as a stabilizing force for any centroid-based clustering
framework. On a different note, a prevalent constraint among existing
clustering methodologies resides in the prerequisite knowledge of the number of
clusters prior to analysis. Utilizing model-based methodologies, such as
Bayesian nonparametric models, offers the advantage of infinite mixture models,
thereby circumventing the need for such requirements. Motivated by these facts,
in this article, we present an efficient and automatic clustering technique by
integrating the principles of model-based and centroid-based methodologies that
mitigates the effect of noise on the quality of clustering while ensuring that
the number of clusters need not be specified in advance. Statistical guarantees
on the upper bound of clustering error, and rigorous assessment through
simulated and real datasets suggest the advantages of our proposed method over
existing state-of-the-art clustering algorithms.
</p>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15386" title="Abstract">arXiv:2311.15386</a> (cross-list from eess.IV) [<a href="/pdf/2311.15386" title="Download PDF">pdf</a>, <a href="/format/2311.15386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectro-ViT: A Vision Transformer Model for GABA-edited MRS  Reconstruction Using Spectrograms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dias%2C+G">Gabriel Dias</a>, 
<a href="/search/eess?searchtype=author&query=Berto%2C+R+P">Rodrigo Pommot Berto</a>, 
<a href="/search/eess?searchtype=author&query=Oliveira%2C+M">Mateus Oliveira</a>, 
<a href="/search/eess?searchtype=author&query=Ueda%2C+L">Lucas Ueda</a>, 
<a href="/search/eess?searchtype=author&query=Dertkigil%2C+S">Sergio Dertkigil</a>, 
<a href="/search/eess?searchtype=author&query=Costa%2C+P+D+P">Paula D. P. Costa</a>, 
<a href="/search/eess?searchtype=author&query=Shamaei%2C+A">Amirmohammad Shamaei</a>, 
<a href="/search/eess?searchtype=author&query=Souza%2C+R">Roberto Souza</a>, 
<a href="/search/eess?searchtype=author&query=Harris%2C+A">Ashley Harris</a>, 
<a href="/search/eess?searchtype=author&query=Rittner%2C+L">Leticia Rittner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Purpose: To investigate the use of a Vision Transformer (ViT) to
reconstruct/denoise GABA-edited magnetic resonance spectroscopy (MRS) from a
quarter of the typically acquired number of transients using spectrograms.
<br />Theory and Methods: A quarter of the typically acquired number of transients
collected in GABA-edited MRS scans are pre-processed and converted to a
spectrogram image representation using the Short-Time Fourier Transform (STFT).
The image representation of the data allows the adaptation of a pre-trained ViT
for reconstructing GABA-edited MRS spectra (Spectro-ViT). The Spectro-ViT is
fine-tuned and then tested using \textit{in vivo} GABA-edited MRS data. The
Spectro-ViT performance is compared against other models in the literature
using spectral quality metrics and estimated metabolite concentration values.
<br />Results: The Spectro-ViT model significantly outperformed all other models in
four out of five quantitative metrics (mean squared error, shape score,
GABA+/water fit error, and full width at half maximum). The metabolite
concentrations estimated (GABA+/water, GABA+/Cr, and Glx/water) were consistent
with the metabolite concentrations estimated using typical GABA-edited MRS
scans reconstructed with the full amount of typically collected transients.
<br />Conclusion: The proposed Spectro-ViT model achieved state-of-the-art results
in reconstructing GABA-edited MRS, and the results indicate these scans could
be up to four times faster.
</p>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15437" title="Abstract">arXiv:2311.15437</a> (cross-list from eess.IV) [<a href="/pdf/2311.15437" title="Download PDF">pdf</a>, <a href="/ps/2311.15437" title="Download PostScript">ps</a>, <a href="/format/2311.15437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quality Modeling Under A Relaxed Natural Scene Statistics Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Venkataramanan%2C+A+K">Abhinau K. Venkataramanan</a>, 
<a href="/search/eess?searchtype=author&query=Bovik%2C+A+C">Alan C. Bovik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Statistics Theory (math.ST)

</div>
<p class="mathjax">Information-theoretic image quality assessment (IQA) models such as Visual
Information Fidelity (VIF) and Spatio-temporal Reduced Reference Entropic
Differences (ST-RRED) have enjoyed great success by seamlessly integrating
natural scene statistics (NSS) with information theory. The Gaussian Scale
Mixture (GSM) model that governs the wavelet subband coefficients of natural
images forms the foundation for these algorithms. However, the explosion of
user-generated content on social media, which is typically distorted by one or
more of many possible unknown impairments, has revealed the limitations of
NSS-based IQA models that rely on the simple GSM model. Here, we seek to
elaborate the VIF index by deriving useful properties of the Multivariate
Generalized Gaussian Distribution (MGGD), and using them to study the behavior
of VIF under a Generalized GSM (GGSM) model.
</p>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15511" title="Abstract">arXiv:2311.15511</a> (cross-list from math.CO) [<a href="/pdf/2311.15511" title="Download PDF">pdf</a>, <a href="/format/2311.15511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Compact Representation for AVL Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chizewer%2C+J">Jeremy Chizewer</a>, 
<a href="/search/math?searchtype=author&query=Melczer%2C+S">Stephen Melczer</a>, 
<a href="/search/math?searchtype=author&query=Munro%2C+J+I">J. Ian Munro</a>, 
<a href="/search/math?searchtype=author&query=Pun%2C+A">Ava Pun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We use arithmetic codes to create a static representation of AVL trees -- a
class of self-balancing binary search trees -- using less than $0.99933$ bits
per node. Our encoding supports efficient full traversal of the tree. To
evaluate how close to optimal our encoding is, we derive asymptotics for the
information theoretic lower-bound on the number of bits needed to store AVL
trees. Specifically, we show that at least $0.938$ bits per node are necessary
to encode AVL trees. Our method characterizes the exponential growth for the
counting sequence of combinatorial classes whose generating functions satisfy
certain functional equations, and may be of independent interest.
</p>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15517" title="Abstract">arXiv:2311.15517</a> (cross-list from math.OC) [<a href="/pdf/2311.15517" title="Download PDF">pdf</a>, <a href="/ps/2311.15517" title="Download PostScript">ps</a>, <a href="/format/2311.15517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bi-level Mixed-Integer Nonlinear Optimization for Pelagic Island  Microgrid Group Energy Management Considering Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+J">Jichen Zhang</a>, 
<a href="/search/math?searchtype=author&query=Wei%2C+X">Xuan Wei</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+Y">Yinliang Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CSEE Journal of Power and Energy Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">To realize the safe, economical and low-carbon operation of the pelagic
island microgrid group, this paper develops a bi-level energy management
framework in a joint energy-reserve market where the microgrid group (MG)
operator and renewable and storage aggregators (RSA) are independent
stakeholders with their own interests. In the upper level, MG operator
determines the optimal transaction prices with aggregators to minimize MG
operation cost while ensuring all safety constraints are satisfied under
uncertainty. In the lower level, aggregators utilize vessels for batteries
swapping and transmission among islands in addition to energy arbitrage by
participating in energy and reserve market to maximize their own revenue. An
upper bound tightening iterative algorithm is proposed for the formulated
problem with nonlinear terms and integer variables in the lower level to
improve the efficiency and reduce the gap between upper bound and lower bound
compared with existing reformulation and decomposition algorithm. Case studies
validate the effectiveness of the proposed approach and demonstrate its
advantage of the proposed approach in terms of optimality and computation
efficiency, compared with other methods.
</p>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15538" title="Abstract">arXiv:2311.15538</a> (cross-list from physics.ins-det) [<a href="/pdf/2311.15538" title="Download PDF">pdf</a>, <a href="/format/2311.15538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noise Analysis for Performance Evaluation of Biopotential Recording  Front-Ends
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Lee%2C+T">Taeju Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Detectors (physics.ins-det)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Noise efficiency factor (NEF) and power efficiency factor (PEF) are widely
used as the figure of merit to quantify the performance of biopotential
recording front-ends. NEF and PEF are discussed from the noise analysis to the
trend survey. To provide a comprehensive performance comparison of the
front-ends, the performance mapping is developed using the design parameters of
the technology node, NEF, PEF, |PEF - NEF|, and supply voltage. Using |PEF -
NEF| provides how well a front-end balances between current-noise efficiency
and power-noise efficiency, in other words, how biased a front-end is between
current- and power-noise efficiencies. Also, the performance mappings of
different front-end architectures are presented.
</p>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15549" title="Abstract">arXiv:2311.15549</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2311.15549" title="Download PDF">pdf</a>, <a href="/ps/2311.15549" title="Download PostScript">ps</a>, <a href="/format/2311.15549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Prediction to Action: The Critical Role of Proper Performance  Estimation for Machine-Learning-Driven Materials Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Boley%2C+M">Mario Boley</a>, 
<a href="/search/cond-mat?searchtype=author&query=Luong%2C+F">Felix Luong</a>, 
<a href="/search/cond-mat?searchtype=author&query=Teshuva%2C+S">Simon Teshuva</a>, 
<a href="/search/cond-mat?searchtype=author&query=Schmidt%2C+D+F">Daniel F Schmidt</a>, 
<a href="/search/cond-mat?searchtype=author&query=Foppa%2C+L">Lucas Foppa</a>, 
<a href="/search/cond-mat?searchtype=author&query=Scheffler%2C+M">Matthias Scheffler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Materials discovery driven by statistical property models is an iterative
decision process, during which an initial data collection is extended with new
data proposed by a model-informed acquisition function--with the goal to
maximize a certain "reward" over time, such as the maximum property value
discovered so far. While the materials science community achieved much progress
in developing property models that predict well on average with respect to the
training distribution, this form of in-distribution performance measurement is
not directly coupled with the discovery reward. This is because an iterative
discovery process has a shifting reward distribution that is
over-proportionally determined by the model performance for exceptional
materials. We demonstrate this problem using the example of bulk modulus
maximization among double perovskite oxides. We find that the in-distribution
predictive performance suggests random forests as superior to Gaussian process
regression, while the results are inverse in terms of the discovery rewards. We
argue that the lack of proper performance estimation methods from pre-computed
data collections is a fundamental problem for improving data-driven materials
discovery, and we propose a novel such estimator that, in contrast to na\"ive
reward estimation, successfully predicts Gaussian processes with the "expected
improvement" acquisition function as the best out of four options in our
demonstrational study for double perovskites. Importantly, it does so without
requiring the over thousand ab initio computations that were needed to confirm
this prediction.
</p>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15584" title="Abstract">arXiv:2311.15584</a> (cross-list from eess.IV) [<a href="/pdf/2311.15584" title="Download PDF">pdf</a>, <a href="/format/2311.15584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A deep learning approach for marine snow synthesis and removal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Galetto%2C+F">Fernando Galetto</a>, 
<a href="/search/eess?searchtype=author&query=Deng%2C+G">Guang Deng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Marine snow, the floating particles in underwater images, severely degrades
the visibility and performance of human and machine vision systems. This paper
proposes a novel method to reduce the marine snow interference using deep
learning techniques. We first synthesize realistic marine snow samples by
training a Generative Adversarial Network (GAN) model and combine them with
natural underwater images to create a paired dataset. We then train a U-Net
model to perform marine snow removal as an image to image translation task. Our
experiments show that the U-Net model can effectively remove both synthetic and
natural marine snow with high accuracy, outperforming state-of-the-art methods
such as the Median filter and its adaptive variant. We also demonstrate the
robustness of our method by testing it on the MSRB dataset, which contains
synthetic artifacts that our model has not seen during training. Our method is
a practical and efficient solution for enhancing underwater images affected by
marine snow.
</p>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15586" title="Abstract">arXiv:2311.15586</a> (cross-list from eess.IV) [<a href="/pdf/2311.15586" title="Download PDF">pdf</a>, <a href="/format/2311.15586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Ensemble of 2.5D ResUnet Based Models for Segmentation for Kidney and  Masses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+C">Cancan Chen</a>, 
<a href="/search/eess?searchtype=author&query=RongguoZhang">RongguoZhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The automatic segmentation of kidney, kidney tumor and kidney cyst on
Computed Tomography (CT) scans is a challenging task due to the indistinct
lesion boundaries and fuzzy texture. Considering the large range and unbalanced
distribution of CT scans' thickness, 2.5D ResUnet are adopted to build an
efficient coarse-to-fine semantic segmentation framework in this work. A set of
489 CT scans are used for training and validation, and an independent
never-before-used CT scans for testing. Finally, we demonstrate the
effectiveness of our proposed method. The dice values on test set are 0.954,
0.792, 0.691, the surface dice values are 0.897, 0.591, 0.541 for kidney, tumor
and cyst, respectively. The average inference time of each CT scan is 20.65s
and the max GPU memory is 3525MB. The results suggest that a better trade-off
between model performance and efficiency.
</p>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15587" title="Abstract">arXiv:2311.15587</a> (cross-list from quant-ph) [<a href="/pdf/2311.15587" title="Download PDF">pdf</a>, <a href="/format/2311.15587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Langevin Dynamics for Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+Z">Zherui Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lu%2C+Y">Yuchen Lu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+Y">Yizhou Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+T">Tongyang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 1 table, 26 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">We initiate the study of utilizing Quantum Langevin Dynamics (QLD) to solve
optimization problems, particularly those non-convex objective functions that
present substantial obstacles for traditional gradient descent algorithms.
Specifically, we examine the dynamics of a system coupled with an infinite heat
bath. This interaction induces both random quantum noise and a deterministic
damping effect to the system, which nudge the system towards a steady state
that hovers near the global minimum of objective functions. We theoretically
prove the convergence of QLD in convex landscapes, demonstrating that the
average energy of the system can approach zero in the low temperature limit
with an exponential decay rate correlated with the evolution time. Numerically,
we first show the energy dissipation capability of QLD by retracing its origins
to spontaneous emission. Furthermore, we conduct detailed discussion of the
impact of each parameter. Finally, based on the observations when comparing QLD
with classical Fokker-Plank-Smoluchowski equation, we propose a time-dependent
QLD by making temperature and $\hbar$ time-dependent parameters, which can be
theoretically proven to converge better than the time-independent case and also
outperforms a series of state-of-the-art quantum and classical optimization
algorithms in many non-convex landscapes.
</p>
</div>
</dd>
<dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15597" title="Abstract">arXiv:2311.15597</a> (cross-list from eess.AS) [<a href="/pdf/2311.15597" title="Download PDF">pdf</a>, <a href="/ps/2311.15597" title="Download PostScript">ps</a>, <a href="/format/2311.15597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial Diarization for Meeting Transcription with Ad-Hoc Acoustic  Sensor Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gburrek%2C+T">Tobias Gburrek</a>, 
<a href="/search/eess?searchtype=author&query=Schmalenstroeer%2C+J">Joerg Schmalenstroeer</a>, 
<a href="/search/eess?searchtype=author&query=Haeb-Umbach%2C+R">Reinhold Haeb-Umbach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Asilomar Conference on Signals, Systems, and Computers 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">We propose a diarization system, that estimates "who spoke when" based on
spatial information, to be used as a front-end of a meeting transcription
system running on the signals gathered from an acoustic sensor network (ASN).
Although the spatial distribution of the microphones is advantageous,
exploiting the spatial diversity for diarization and signal enhancement is
challenging, because the microphones' positions are typically unknown, and the
recorded signals are initially unsynchronized in general. Here, we approach
these issues by first blindly synchronizing the signals and then estimating
time differences of arrival (TDOAs). The TDOA information is exploited to
estimate the speakers' activity, even in the presence of multiple speakers
being simultaneously active. This speaker activity information serves as a
guide for a spatial mixture model, on which basis the individual speaker's
signals are extracted via beamforming. Finally, the extracted signals are
forwarded to a speech recognizer. Additionally, a novel initialization scheme
for spatial mixture models based on the TDOA estimates is proposed. Experiments
conducted on real recordings from the LibriWASN data set have shown that our
proposed system is advantageous compared to a system using a spatial mixture
model, which does not make use of external diarization information.
</p>
</div>
</dd>
<dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15598" title="Abstract">arXiv:2311.15598</a> (cross-list from math.ST) [<a href="/pdf/2311.15598" title="Download PDF">pdf</a>, <a href="/format/2311.15598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Clustering of Discrete Mixtures: Binomial, Poisson, Block  Models, and Multi-layer Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lyu%2C+Z">Zhongyuan Lyu</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+T">Ting Li</a>, 
<a href="/search/math?searchtype=author&query=Xia%2C+D">Dong Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">In this paper, we first study the fundamental limit of clustering networks
when a multi-layer network is present. Under the mixture multi-layer stochastic
block model (MMSBM), we show that the minimax optimal network clustering error
rate, which takes an exponential form and is characterized by the Renyi
divergence between the edge probability distributions of the component
networks. We propose a novel two-stage network clustering method including a
tensor-based initialization algorithm involving both node and sample splitting
and a refinement procedure by likelihood-based Lloyd algorithm. Network
clustering must be accompanied by node community detection. Our proposed
algorithm achieves the minimax optimal network clustering error rate and allows
extreme network sparsity under MMSBM. Numerical simulations and real data
experiments both validate that our method outperforms existing methods.
Oftentimes, the edges of networks carry count-type weights. We then extend our
methodology and analysis framework to study the minimax optimal clustering
error rate for mixture of discrete distributions including Binomial, Poisson,
and multi-layer Poisson networks. The minimax optimal clustering error rates in
these discrete mixtures all take the same exponential form characterized by the
Renyi divergences. These optimal clustering error rates in discrete mixtures
can also be achieved by our proposed two-stage clustering algorithm.
</p>
</div>
</dd>
<dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15607" title="Abstract">arXiv:2311.15607</a> (cross-list from eess.IV) [<a href="/pdf/2311.15607" title="Download PDF">pdf</a>, <a href="/format/2311.15607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatially Covariant Image Registration with Text Prompts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+H">Hang Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xiang Chen</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+R">Rongguang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+R">Renjiu Hu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+D">Dongdong Liu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+G">Gaolei Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 8 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Medical images are often characterized by their structured anatomical
representations and spatially inhomogeneous contrasts. Leveraging anatomical
priors in neural networks can greatly enhance their utility in
resource-constrained clinical settings. Prior research has harnessed such
information for image segmentation, yet progress in deformable image
registration has been modest. Our work introduces textSCF, a novel method that
integrates spatially covariant filters and textual anatomical prompts encoded
by visual-language models, to fill this gap. This approach optimizes an
implicit function that correlates text embeddings of anatomical regions to
filter weights, relaxing the typical translation-invariance constraint of
convolutional operations. TextSCF not only boosts computational efficiency but
can also retain or improve registration accuracy. By capturing the contextual
interplay between anatomical regions, it offers impressive inter-regional
transferability and the ability to preserve structural discontinuities during
registration. TextSCF's performance has been rigorously tested on inter-subject
brain MRI and abdominal CT registration tasks, outperforming existing
state-of-the-art models in the MICCAI Learn2Reg 2021 challenge and leading the
leaderboard. In abdominal registrations, textSCF's larger model variant
improved the Dice score by 11.3% over the second-best model, while its smaller
variant maintained similar accuracy but with an 89.13% reduction in network
parameters and a 98.34\% decrease in computational operations.
</p>
</div>
</dd>
<dt><a name="item671">[671]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15610" title="Abstract">arXiv:2311.15610</a> (cross-list from stat.ML) [<a href="/pdf/2311.15610" title="Download PDF">pdf</a>, <a href="/format/2311.15610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Approach to Linear Bayesian Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hwang%2C+S">Seyong Hwang</a>, 
<a href="/search/stat?searchtype=author&query=Lee%2C+K">Kyoungjae Lee</a>, 
<a href="/search/stat?searchtype=author&query=Oh%2C+S">Sunmin Oh</a>, 
<a href="/search/stat?searchtype=author&query=Park%2C+G">Gunwoong Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST); Methodology (stat.ME)

</div>
<p class="mathjax">This study proposes the first Bayesian approach for learning high-dimensional
linear Bayesian networks. The proposed approach iteratively estimates each
element of the topological ordering from backward and its parent using the
inverse of a partial covariance matrix. The proposed method successfully
recovers the underlying structure when Bayesian regularization for the inverse
covariance matrix with unequal shrinkage is applied. Specifically, it shows
that the number of samples $n = \Omega( d_M^2 \log p)$ and $n = \Omega(d_M^2
p^{2/m})$ are sufficient for the proposed algorithm to learn linear Bayesian
networks with sub-Gaussian and 4m-th bounded-moment error distributions,
respectively, where $p$ is the number of nodes and $d_M$ is the maximum degree
of the moralized graph. The theoretical findings are supported by extensive
simulation studies including real data analysis. Furthermore the proposed
method is demonstrated to outperform state-of-the-art frequentist approaches,
such as the BHLSM, LISTEN, and TD algorithms in synthetic data.
</p>
</div>
</dd>
<dt><a name="item672">[672]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15646" title="Abstract">arXiv:2311.15646</a> (cross-list from math.CO) [<a href="/pdf/2311.15646" title="Download PDF">pdf</a>, <a href="/ps/2311.15646" title="Download PostScript">ps</a>, <a href="/format/2311.15646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> k-dimensional transversals for balls
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jung%2C+A">Attila Jung</a>, 
<a href="/search/math?searchtype=author&query=P%C3%A1lv%C3%B6lgyi%2C+D">D&#xf6;m&#xf6;t&#xf6;r P&#xe1;lv&#xf6;lgyi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">We prove fractional Helly and $(p,k+2)$-theorems for $k$-flats intersecting
Euclidean balls. For example, we show that if for a collection of balls from
$\mathbb R^d$ any $p$ balls have a $k$-flat that intersects at least $k+2$ of
them, then the whole collection can be intersected by bounded many $k$-flats.
We prove colorful, spherical, and infinite variants as well. In fact, we prove
that fractional Helly and $(p,q)$-theorems imply $(\aleph_0,q)$-theorems in an
entirely abstract setting. The fractional Helly theorems generalize to other
fat objects as well.
</p>
</div>
</dd>
<dt><a name="item673">[673]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15654" title="Abstract">arXiv:2311.15654</a> (cross-list from stat.ML) [<a href="/pdf/2311.15654" title="Download PDF">pdf</a>, <a href="/format/2311.15654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Event Detection in Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Azib%2C+M">Menouar Azib</a>, 
<a href="/search/stat?searchtype=author&query=Renard%2C+B">Benjamin Renard</a>, 
<a href="/search/stat?searchtype=author&query=Garnier%2C+P">Philippe Garnier</a>, 
<a href="/search/stat?searchtype=author&query=G%C3%A9not%2C+V">Vincent G&#xe9;not</a>, 
<a href="/search/stat?searchtype=author&query=Andr%C3%A9%2C+N">Nicolas Andr&#xe9;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be submitted to IEEE Transactions on Neural Networks and Learning Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In our previously published work, we introduced a supervised deep learning
method for event detection in multivariate time series data, employing
regression instead of binary classification. This simplification avoids the
need for point-wise labels throughout the entire dataset, relying solely on
ground truth events defined as time points or intervals. In this paper, we
establish mathematically that our method is universal, and capable of detecting
any type of event with arbitrary precision under mild continuity assumptions on
the time series. These events may encompass change points, frauds, anomalies,
physical occurrences, and more. We substantiate our theoretical results using
the universal approximation theorem for feed-forward neural networks (FFN).
Additionally, we provide empirical validations that confirm our claims,
demonstrating that our method, with a limited number of parameters, outperforms
other deep learning approaches, particularly for rare events and imbalanced
datasets from different domains.
</p>
</div>
</dd>
<dt><a name="item674">[674]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15683" title="Abstract">arXiv:2311.15683</a> (cross-list from eess.AS) [<a href="/pdf/2311.15683" title="Download PDF">pdf</a>, <a href="/ps/2311.15683" title="Download PostScript">ps</a>, <a href="/format/2311.15683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultrasensitive Textile Strain Sensors Redefine Wearable Silent Speech  Interfaces with High Machine Learning Efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tang%2C+C">Chenyu Tang</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+M">Muzi Xu</a>, 
<a href="/search/eess?searchtype=author&query=Yi%2C+W">Wentian Yi</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Zibo Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Occhipinti%2C+E">Edoardo Occhipinti</a>, 
<a href="/search/eess?searchtype=author&query=Dong%2C+C">Chaoqun Dong</a>, 
<a href="/search/eess?searchtype=author&query=Ravenscroft%2C+D">Dafydd Ravenscroft</a>, 
<a href="/search/eess?searchtype=author&query=Jung%2C+S">Sung-Min Jung</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+S">Sanghyo Lee</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+S">Shuo Gao</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+J+M">Jong Min Kim</a>, 
<a href="/search/eess?searchtype=author&query=Occhipinti%2C+L+G">Luigi G. Occhipinti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 figures in the article; 11 figures and 4 tables in supplementary information
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Signal Processing (eess.SP)

</div>
<p class="mathjax">Our research presents a wearable Silent Speech Interface (SSI) technology
that excels in device comfort, time-energy efficiency, and speech decoding
accuracy for real-world use. We developed a biocompatible, durable textile
choker with an embedded graphene-based strain sensor, capable of accurately
detecting subtle throat movements. This sensor, surpassing other strain sensors
in sensitivity by 420%, simplifies signal processing compared to traditional
voice recognition methods. Our system uses a computationally efficient neural
network, specifically a one-dimensional convolutional neural network with
residual structures, to decode speech signals. This network is energy and
time-efficient, reducing computational load by 90% while achieving 95.25%
accuracy for a 20-word lexicon and swiftly adapting to new users and words with
minimal samples. This innovation demonstrates a practical, sensitive, and
precise wearable SSI suitable for daily communication applications.
</p>
</div>
</dd>
<dt><a name="item675">[675]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15696" title="Abstract">arXiv:2311.15696</a> (cross-list from quant-ph) [<a href="/pdf/2311.15696" title="Download PDF">pdf</a>, <a href="/format/2311.15696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Peptide Binding Classification on Quantum Computers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=London%2C+C">Charles London</a>, 
<a href="/search/quant-ph?searchtype=author&query=Brown%2C+D">Douglas Brown</a>, 
<a href="/search/quant-ph?searchtype=author&query=Xu%2C+W">Wenduan Xu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Vatansever%2C+S">Sezen Vatansever</a>, 
<a href="/search/quant-ph?searchtype=author&query=Langmead%2C+C+J">Christopher James Langmead</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kartsaklis%2C+D">Dimitri Kartsaklis</a>, 
<a href="/search/quant-ph?searchtype=author&query=Clark%2C+S">Stephen Clark</a>, 
<a href="/search/quant-ph?searchtype=author&query=Meichanetzidis%2C+K">Konstantinos Meichanetzidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We conduct an extensive study on using near-term quantum computers for a task
in the domain of computational biology. By constructing quantum models based on
parameterised quantum circuits we perform sequence classification on a task
relevant to the design of therapeutic proteins, and find competitive
performance with classical baselines of similar scale. To study the effect of
noise, we run some of the best-performing quantum models with favourable
resource requirements on emulators of state-of-the-art noisy quantum
processors. We then apply error mitigation methods to improve the signal. We
further execute these quantum models on the Quantinuum H1-1 trapped-ion quantum
processor and observe very close agreement with noiseless exact simulation.
Finally, we perform feature attribution methods and find that the quantum
models indeed identify sensible relationships, at least as well as the
classical baselines. This work constitutes the first proof-of-concept
application of near-term quantum computing to a task critical to the design of
therapeutic proteins, opening the route toward larger-scale applications in
this and related fields, in line with the hardware development roadmaps of
near-term quantum technologies.
</p>
</div>
</dd>
<dt><a name="item676">[676]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15703" title="Abstract">arXiv:2311.15703</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2311.15703" title="Download PDF">pdf</a>, <a href="/ps/2311.15703" title="Download PostScript">ps</a>, <a href="/format/2311.15703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tabular Two-Dimensional Correlation Analysis for Multifaceted  Characterization Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Muroga%2C+S">Shun Muroga</a>, 
<a href="/search/cond-mat?searchtype=author&query=Yamazaki%2C+S">Satoshi Yamazaki</a>, 
<a href="/search/cond-mat?searchtype=author&query=Michishio%2C+K">Koji Michishio</a>, 
<a href="/search/cond-mat?searchtype=author&query=Nakajima%2C+H">Hideaki Nakajima</a>, 
<a href="/search/cond-mat?searchtype=author&query=Morimoto%2C+T">Takahiro Morimoto</a>, 
<a href="/search/cond-mat?searchtype=author&query=Oshima%2C+N">Nagayasu Oshima</a>, 
<a href="/search/cond-mat?searchtype=author&query=Kobashi%2C+K">Kazufumi Kobashi</a>, 
<a href="/search/cond-mat?searchtype=author&query=Okazaki%2C+T">Toshiya Okazaki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Soft Condensed Matter (cond-mat.soft); Machine Learning (cs.LG); Applied Physics (physics.app-ph); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">We propose tabular two-dimensional correlation analysis for extracting
features from multifaceted characterization data, essential for understanding
material properties. This method visualizes similarities and phase lags in
structural parameter changes through heatmaps, combining hierarchical
clustering and asynchronous correlations. We applied the proposed method to
datasets of carbon nanotube (CNTs) films annealed at various temperatures and
revealed the complexity of their hierarchical structures, which include
elements like voids, bundles, and amorphous carbon. Our analysis addresses the
challenge of attempting to understand the sequence of structural changes,
especially in multifaceted characterization data where 11 structural parameters
derived from 8 characterization methods interact with complex behavior. The
results show how phase lags (asynchronous changes from stimuli) and parameter
similarities can illuminate the sequence of structural changes in materials,
providing insights into phenomena like the removal of amorphous carbon and
graphitization in annealed CNTs. This approach is beneficial even with limited
data and holds promise for a wide range of material analyses, demonstrating its
potential in elucidating complex material behaviors and properties.
</p>
</div>
</dd>
<dt><a name="item677">[677]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15735" title="Abstract">arXiv:2311.15735</a> (cross-list from physics.med-ph) [<a href="/pdf/2311.15735" title="Download PDF">pdf</a>, <a href="/format/2311.15735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-based reconstructions for quantitative imaging in photoacoustic  tomography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Hauptmann%2C+A">Andreas Hauptmann</a>, 
<a href="/search/physics?searchtype=author&query=Tarvainen%2C+T">Tanja Tarvainen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Image and Video Processing (eess.IV); Numerical Analysis (math.NA)

</div>
<p class="mathjax">The reconstruction task in photoacoustic tomography can vary a lot depending
on measured targets, geometry, and especially the quantity we want to recover.
Specifically, as the signal is generated due to the coupling of light and sound
by the photoacoustic effect, we have the possibility to recover acoustic as
well as optical tissue parameters. This is referred to as quantitative imaging,
i.e, correct recovery of physical parameters and not just a qualitative image.
In this chapter, we aim to give an overview on established reconstruction
techniques in photoacoustic tomography. We start with modelling of the optical
and acoustic phenomena, necessary for a reliable recovery of quantitative
values. Furthermore, we give an overview of approaches for the tomographic
reconstruction problem with an emphasis on the recovery of quantitative values,
from direct and fast analytic approaches to computationally involved
optimisation based techniques and recent data-driven approaches.
</p>
</div>
</dd>
<dt><a name="item678">[678]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15751" title="Abstract">arXiv:2311.15751</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2311.15751" title="Download PDF">pdf</a>, <a href="/ps/2311.15751" title="Download PostScript">ps</a>, <a href="/format/2311.15751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PyNanospacing: TEM image processing tool for strain analysis and  visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Sarsil%2C+M+A">Mehmet Ali Sarsil</a>, 
<a href="/search/cond-mat?searchtype=author&query=Mansoor%2C+M">Mubashir Mansoor</a>, 
<a href="/search/cond-mat?searchtype=author&query=Saracoglu%2C+M">Mert Saracoglu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Timur%2C+S">Servet Timur</a>, 
<a href="/search/cond-mat?searchtype=author&query=Urgen%2C+M">Mustafa Urgen</a>, 
<a href="/search/cond-mat?searchtype=author&query=Ergen%2C+O">Onur Ergen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint, 13 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The diverse spectrum of material characteristics including band gap,
mechanical moduli, color, phonon and electronic density of states, along with
catalytic and surface properties are intricately intertwined with the atomic
structure and the corresponding interatomic bond-lengths. This interconnection
extends to the manifestation of interplanar spacings within a crystalline
lattice. Analysis of these interplanar spacings and the comprehension of any
deviations, whether it be lattice compression or expansion, commonly referred
to as strain, hold paramount significance in unraveling various unknowns within
the field. Transmission Electron Microscopy (TEM) is widely used to capture
atomic-scale ordering, facilitating direct investigation of interplanar
spacings. However, creating critical contour maps for visualizing and
interpreting lattice stresses in TEM images remains a challenging task. Here we
developed a Python code for TEM image processing that can handle a wide range
of materials including nanoparticles, 2D materials, pure crystals and solid
solutions. This algorithm converts local differences in interplanar spacings
into contour maps allowing for a visual representation of lattice expansion and
compression. The tool is very generic and can significantly aid in analyzing
material properties using TEM images, allowing for a more in-depth exploration
of the underlying science behind strain engineering via strain contour maps at
the atomic level.
</p>
</div>
</dd>
<dt><a name="item679">[679]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15804" title="Abstract">arXiv:2311.15804</a> (cross-list from eess.AS) [<a href="/pdf/2311.15804" title="Download PDF">pdf</a>, <a href="/ps/2311.15804" title="Download PostScript">ps</a>, <a href="/format/2311.15804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Voice Anonymization for All -- Bias Evaluation of the Voice Privacy  Challenge Baseline System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Leschanowsky%2C+A">Anna Leschanowsky</a>, 
<a href="/search/eess?searchtype=author&query=Gaznepoglu%2C+%C3%9C+E">&#xdc;nal Ege Gaznepoglu</a>, 
<a href="/search/eess?searchtype=author&query=Peters%2C+N">Nils Peters</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">In an age of voice-enabled technology, voice anonymization offers a solution
to protect people's privacy, provided these systems work equally well across
subgroups. This study investigates bias in voice anonymization systems within
the context of the Voice Privacy Challenge. We curate a novel benchmark dataset
to assess performance disparities among speaker subgroups based on sex and
dialect. We analyze the impact of three anonymization systems and attack models
on speaker subgroup bias and reveal significant performance variations.
Notably, subgroup bias intensifies with advanced attacker capabilities,
emphasizing the challenge of achieving equal performance across all subgroups.
Our study highlights the need for inclusive benchmark datasets and
comprehensive evaluation strategies that address subgroup bias in voice
anonymization.
</p>
</div>
</dd>
<dt><a name="item680">[680]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15828" title="Abstract">arXiv:2311.15828</a> (cross-list from eess.SP) [<a href="/pdf/2311.15828" title="Download PDF">pdf</a>, <a href="/ps/2311.15828" title="Download PostScript">ps</a>, <a href="/format/2311.15828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Polar-Domain Dictionary Design for the Near-field Region of  Extremely Large Aperture Arrays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Demir%2C+%C3%96+T">&#xd6;zlem Tu&#x11f;fe Demir</a>, 
<a href="/search/eess?searchtype=author&query=Bj%C3%B6rnson%2C+E">Emil Bj&#xf6;rnson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, to appear in the proceedings of the IEEE CAMSAP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">A grid of orthogonal beams with zero column coherence can be easily
constructed to cover all prospective user equipments (UEs) in the far-field
region of a multiple-antenna base station (BS). However, when the BS is
equipped with an extremely large aperture array, the Fraunhofer distance is
huge, causing the UEs to be located in the radiative near-field region. This
calls for designing a grid of beams based on a near-field dictionary. In the
previous work, a polar-domain grid design was proposed to maintain control over
the column coherence. A limitation of this approach is identified in this
paper, and we propose an enhanced methodology for the design of a polar-domain
dictionary specifically tailored for the near-field of an extremely large
aperture uniform planar array. Through simulation results, it is demonstrated
that the proposed dictionary, employing a non-uniform distance sampling
approach, achieves lower column coherence than the benchmark and significantly
improves the localization of UEs compared to uniform distance sampling.
</p>
</div>
</dd>
<dt><a name="item681">[681]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15847" title="Abstract">arXiv:2311.15847</a> (cross-list from eess.IV) [<a href="/pdf/2311.15847" title="Download PDF">pdf</a>, <a href="/format/2311.15847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cell Maps Representation For Lung Adenocarcinoma Growth Patterns  Classification In Whole Slide Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Al-Rubaian%2C+A">Arwa Al-Rubaian</a>, 
<a href="/search/eess?searchtype=author&query=Gunesli%2C+G+N">Gozde N. Gunesli</a>, 
<a href="/search/eess?searchtype=author&query=Althakfi%2C+W+A">Wajd A. Althakfi</a>, 
<a href="/search/eess?searchtype=author&query=Azam%2C+A">Ayesha Azam</a>, 
<a href="/search/eess?searchtype=author&query=Rajpoot%2C+N">Nasir Rajpoot</a>, 
<a href="/search/eess?searchtype=author&query=Raza%2C+S+E+A">Shan E Ahmed Raza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Lung adenocarcinoma is a morphologically heterogeneous disease, characterized
by five primary histologic growth patterns. The quantity of these patterns can
be related to tumor behavior and has a significant impact on patient prognosis.
In this work, we propose a novel machine learning pipeline capable of
classifying tissue tiles into one of the five patterns or as non-tumor, with an
Area Under the Receiver Operating Characteristic Curve (AUCROC) score of 0.97.
Our model's strength lies in its comprehensive consideration of cellular
spatial patterns, where it first generates cell maps from Hematoxylin and Eosin
(H&amp;E) whole slide images (WSIs), which are then fed into a convolutional neural
network classification model. Exploiting these cell maps provides the model
with robust generalizability to new data, achieving approximately 30% higher
accuracy on unseen test-sets compared to current state of the art approaches.
The insights derived from our model can be used to predict prognosis, enhancing
patient outcomes.
</p>
</div>
</dd>
<dt><a name="item682">[682]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15856" title="Abstract">arXiv:2311.15856</a> (cross-list from eess.IV) [<a href="/pdf/2311.15856" title="Download PDF">pdf</a>, <a href="/format/2311.15856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JSSL: Joint Supervised and Self-supervised Learning for MRI  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yiasemis%2C+G">George Yiasemis</a>, 
<a href="/search/eess?searchtype=author&query=Moriakov%2C+N">Nikita Moriakov</a>, 
<a href="/search/eess?searchtype=author&query=S%C3%A1nchez%2C+C+I">Clara I. S&#xe1;nchez</a>, 
<a href="/search/eess?searchtype=author&query=Sonke%2C+J">Jan-Jakob Sonke</a>, 
<a href="/search/eess?searchtype=author&query=Teuwen%2C+J">Jonas Teuwen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 11 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Magnetic Resonance Imaging represents an important diagnostic modality;
however, its inherently slow acquisition process poses challenges in obtaining
fully sampled k-space data under motion in clinical scenarios such as
abdominal, cardiac, and prostate imaging. In the absence of fully sampled
acquisitions, which can serve as ground truth data, training deep learning
algorithms in a supervised manner to predict the underlying ground truth image
becomes an impossible task. To address this limitation, self-supervised methods
have emerged as a viable alternative, leveraging available subsampled k-space
data to train deep learning networks for MRI reconstruction. Nevertheless,
these self-supervised approaches often fall short when compared to supervised
methodologies. In this paper, we introduce JSSL (Joint Supervised and
Self-supervised Learning), a novel training approach for deep learning-based
MRI reconstruction algorithms aimed at enhancing reconstruction quality in
scenarios where target dataset(s) containing fully sampled k-space measurements
are unavailable. Our proposed method operates by simultaneously training a
model in a self-supervised learning setting, using subsampled data from the
target dataset(s), and in a supervised learning manner, utilizing data from
other datasets, referred to as proxy datasets, where fully sampled k-space data
is accessible. To demonstrate the efficacy of JSSL, we utilized subsampled
prostate parallel MRI measurements as the target dataset, while employing fully
sampled brain and knee k-space acquisitions as proxy datasets. Our results
showcase a substantial improvement over conventional self-supervised training
methods, thereby underscoring the effectiveness of our joint approach. We
provide a theoretical motivation for JSSL and establish a practical
"rule-of-thumb" for selecting the most appropriate training approach for deep
MRI reconstruction.
</p>
</div>
</dd>
<dt><a name="item683">[683]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15865" title="Abstract">arXiv:2311.15865</a> (cross-list from astro-ph.CO) [<a href="/pdf/2311.15865" title="Download PDF">pdf</a>, <a href="/format/2311.15865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A precise symbolic emulator of the linear matter power spectrum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Bartlett%2C+D+J">Deaglan J. Bartlett</a>, 
<a href="/search/astro-ph?searchtype=author&query=Kammerer%2C+L">Lukas Kammerer</a>, 
<a href="/search/astro-ph?searchtype=author&query=Kronberger%2C+G">Gabriel Kronberger</a>, 
<a href="/search/astro-ph?searchtype=author&query=Desmond%2C+H">Harry Desmond</a>, 
<a href="/search/astro-ph?searchtype=author&query=Ferreira%2C+P+G">Pedro G. Ferreira</a>, 
<a href="/search/astro-ph?searchtype=author&query=Wandelt%2C+B+D">Benjamin D. Wandelt</a>, 
<a href="/search/astro-ph?searchtype=author&query=Burlacu%2C+B">Bogdan Burlacu</a>, 
<a href="/search/astro-ph?searchtype=author&query=Alonso%2C+D">David Alonso</a>, 
<a href="/search/astro-ph?searchtype=author&query=Zennaro%2C+M">Matteo Zennaro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures. Submitted to A&amp;A
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cosmology and Nongalactic Astrophysics (astro-ph.CO)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Computing the matter power spectrum, $P(k)$, as a function of cosmological
parameters can be prohibitively slow in cosmological analyses, hence emulating
this calculation is desirable. Previous analytic approximations are
insufficiently accurate for modern applications, so black-box, uninterpretable
emulators are often used. We utilise an efficient genetic programming based
symbolic regression framework to explore the space of potential mathematical
expressions which can approximate the power spectrum and $\sigma_8$. We learn
the ratio between an existing low-accuracy fitting function for $P(k)$ and that
obtained by solving the Boltzmann equations and thus still incorporate the
physics which motivated this earlier approximation. We obtain an analytic
approximation to the linear power spectrum with a root mean squared fractional
error of 0.2% between $k = 9\times10^{-3} - 9 \, h{\rm \, Mpc^{-1}}$ and across
a wide range of cosmological parameters, and we provide physical
interpretations for various terms in the expression. We also provide a simple
analytic approximation for $\sigma_8$ with a similar accuracy, with a root mean
squared fractional error of just 0.4% when evaluated across the same range of
cosmologies. This function is easily invertible to obtain $A_{\rm s}$ as a
function of $\sigma_8$ and the other cosmological parameters, if preferred. It
is possible to obtain symbolic approximations to a seemingly complex function
at a precision required for current and future cosmological analyses without
resorting to deep-learning techniques, thus avoiding their black-box nature and
large number of parameters. Our emulator will be usable long after the codes on
which numerical approximations are built become outdated.
</p>
</div>
</dd>
<dt><a name="item684">[684]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15961" title="Abstract">arXiv:2311.15961</a> (cross-list from stat.ML) [<a href="/pdf/2311.15961" title="Download PDF">pdf</a>, <a href="/ps/2311.15961" title="Download PostScript">ps</a>, <a href="/format/2311.15961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximum Likelihood Estimation is All You Need for Well-Specified  Covariate Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ge%2C+J">Jiawei Ge</a>, 
<a href="/search/stat?searchtype=author&query=Tang%2C+S">Shange Tang</a>, 
<a href="/search/stat?searchtype=author&query=Fan%2C+J">Jianqing Fan</a>, 
<a href="/search/stat?searchtype=author&query=Ma%2C+C">Cong Ma</a>, 
<a href="/search/stat?searchtype=author&query=Jin%2C+C">Chi Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
<p class="mathjax">A key challenge of modern machine learning systems is to achieve
Out-of-Distribution (OOD) generalization -- generalizing to target data whose
distribution differs from that of source data. Despite its significant
importance, the fundamental question of ``what are the most effective
algorithms for OOD generalization'' remains open even under the standard
setting of covariate shift. This paper addresses this fundamental question by
proving that, surprisingly, classical Maximum Likelihood Estimation (MLE)
purely using source data (without any modification) achieves the minimax
optimality for covariate shift under the well-specified setting. That is, no
algorithm performs better than MLE in this setting (up to a constant factor),
justifying MLE is all you need. Our result holds for a very rich class of
parametric models, and does not require any boundedness condition on the
density ratio. We illustrate the wide applicability of our framework by
instantiating it to three concrete examples -- linear regression, logistic
regression, and phase retrieval. This paper further complement the study by
proving that, under the misspecified setting, MLE is no longer the optimal
choice, whereas Maximum Weighted Likelihood Estimator (MWLE) emerges as minimax
optimal in certain scenarios.
</p>
</div>
</dd>
<dt><a name="item685">[685]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15962" title="Abstract">arXiv:2311.15962</a> (cross-list from math.OC) [<a href="/pdf/2311.15962" title="Download PDF">pdf</a>, <a href="/format/2311.15962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Quantification of Set-Membership Estimation in Control and  Perception: Revisiting the Minimum Enclosing Ellipsoid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tang%2C+Y">Yukai Tang</a>, 
<a href="/search/math?searchtype=author&query=Lasserre%2C+J">Jean-Bernard Lasserre</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+H">Heng Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to 6th Learning for Dynamics and Control (L4DC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Set-membership estimation (SME) outputs a set estimator that guarantees to
cover the groundtruth. Such sets are, however, defined by (many) abstract (and
potentially nonconvex) constraints and therefore difficult to manipulate. We
present tractable algorithms to compute simple and tight overapproximations of
SME in the form of minimum enclosing ellipsoids (MEE). We first introduce the
hierarchy of enclosing ellipsoids proposed by Nie and Demmel (2005), based on
sums-ofsquares relaxations, that asymptotically converge to the MEE of a basic
semialgebraic set. This framework, however, struggles in modern control and
perception problems due to computational challenges. We contribute three
computational enhancements to make this framework practical, namely constraints
pruning, generalized relaxed Chebyshev center, and handling non-Euclidean
geometry. We showcase numerical examples on system identification and object
pose estimation.
</p>
</div>
</dd>
<dt><a name="item686">[686]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15966" title="Abstract">arXiv:2311.15966</a> (cross-list from quant-ph) [<a href="/pdf/2311.15966" title="Download PDF">pdf</a>, <a href="/format/2311.15966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Transfer Learning for Large-Scale Image Classification Using  Annealing-based Quantum Boltzmann Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Schuman%2C+D">Dani&#xeb;lle Schuman</a>, 
<a href="/search/quant-ph?searchtype=author&query=S%C3%BCnkel%2C+L">Leo S&#xfc;nkel</a>, 
<a href="/search/quant-ph?searchtype=author&query=Altmann%2C+P">Philipp Altmann</a>, 
<a href="/search/quant-ph?searchtype=author&query=Stein%2C+J">Jonas Stein</a>, 
<a href="/search/quant-ph?searchtype=author&query=Roch%2C+C">Christoph Roch</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gabor%2C+T">Thomas Gabor</a>, 
<a href="/search/quant-ph?searchtype=author&query=Linnhoff-Popien%2C+C">Claudia Linnhoff-Popien</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures (5 if counting subfigures), 1 table. To be published in the proceedings of the 2023 IEEE International Conference on Quantum Computing and Engineering (QCE)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Quantum Transfer Learning (QTL) recently gained popularity as a hybrid
quantum-classical approach for image classification tasks by efficiently
combining the feature extraction capabilities of large Convolutional Neural
Networks with the potential benefits of Quantum Machine Learning (QML).
Existing approaches, however, only utilize gate-based Variational Quantum
Circuits for the quantum part of these procedures. In this work we present an
approach to employ Quantum Annealing (QA) in QTL-based image classification.
Specifically, we propose using annealing-based Quantum Boltzmann Machines as
part of a hybrid quantum-classical pipeline to learn the classification of
real-world, large-scale data such as medical images through supervised
training. We demonstrate our approach by applying it to the three-class
COVID-CT-MD dataset, a collection of lung Computed Tomography (CT) scan slices.
Using Simulated Annealing as a stand-in for actual QA, we compare our method to
classical transfer learning, using a neural network of the same order of
magnitude, to display its improved classification performance. We find that our
approach consistently outperforms its classical baseline in terms of test
accuracy and AUC-ROC-Score and needs less training epochs to do this.
</p>
</div>
</dd>
<dt><a name="item687">[687]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16001" title="Abstract">arXiv:2311.16001</a> (cross-list from eess.IV) [<a href="/pdf/2311.16001" title="Download PDF">pdf</a>, <a href="/ps/2311.16001" title="Download PostScript">ps</a>, <a href="/format/2311.16001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Measurement of Vascular Calcification in Femoral  Endarterectomy Patients Using Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rajeoni%2C+A+B">Alireza Bagheri Rajeoni</a>, 
<a href="/search/eess?searchtype=author&query=Pederson%2C+B">Breanna Pederson</a>, 
<a href="/search/eess?searchtype=author&query=Clair%2C+D+G">Daniel G. Clair</a>, 
<a href="/search/eess?searchtype=author&query=Lessner%2C+S+M">Susan M. Lessner</a>, 
<a href="/search/eess?searchtype=author&query=Valafar%2C+H">Homayoun Valafar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in MDPI Diagnostic journal, the code can be accessed via the GitHub link in the paper
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Diagnostics 2023, 13, 3363
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Atherosclerosis, a chronic inflammatory disease affecting the large arteries,
presents a global health risk. Accurate analysis of diagnostic images, like
computed tomographic angiograms (CTAs), is essential for staging and monitoring
the progression of atherosclerosis-related conditions, including peripheral
arterial disease (PAD). However, manual analysis of CTA images is
time-consuming and tedious. To address this limitation, we employed a deep
learning model to segment the vascular system in CTA images of PAD patients
undergoing femoral endarterectomy surgery and to measure vascular calcification
from the left renal artery to the patella. Utilizing proprietary CTA images of
27 patients undergoing femoral endarterectomy surgery provided by Prisma Health
Midlands, we developed a Deep Neural Network (DNN) model to first segment the
arterial system, starting from the descending aorta to the patella, and second,
to provide a metric of arterial calcification. Our designed DNN achieved 83.4%
average Dice accuracy in segmenting arteries from aorta to patella, advancing
the state-of-the-art by 0.8%. Furthermore, our work is the first to present a
robust statistical analysis of automated calcification measurement in the lower
extremities using deep learning, attaining a Mean Absolute Percentage Error
(MAPE) of 9.5% and a correlation coefficient of 0.978 between automated and
manual calcification scores. These findings underscore the potential of deep
learning techniques as a rapid and accurate tool for medical professionals to
assess calcification in the abdominal aorta and its branches above the patella.
The developed DNN model and related documentation in this project are available
at GitHub page at https://github.com/pip-alireza/DeepCalcScoring.
</p>
</div>
</dd>
<dt><a name="item688">[688]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16004" title="Abstract">arXiv:2311.16004</a> (cross-list from q-fin.ST) [<a href="/pdf/2311.16004" title="Download PDF">pdf</a>, <a href="/format/2311.16004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Data Generation for Enhanced Asset Allocation: A Synthetic  Dataset Approach for the Fixed Income Universe
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Kubiak%2C+S">Szymon Kubiak</a>, 
<a href="/search/q-fin?searchtype=author&query=Weyde%2C+T">Tillman Weyde</a>, 
<a href="/search/q-fin?searchtype=author&query=Galkin%2C+O">Oleksandr Galkin</a>, 
<a href="/search/q-fin?searchtype=author&query=Philps%2C+D">Dan Philps</a>, 
<a href="/search/q-fin?searchtype=author&query=Gopal%2C+R">Ram Gopal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a novel process for generating synthetic datasets tailored to
assess asset allocation methods and construct portfolios within the fixed
income universe. Our approach begins by enhancing the CorrGAN model to generate
synthetic correlation matrices. Subsequently, we propose an Encoder-Decoder
model that samples additional data conditioned on a given correlation matrix.
The resulting synthetic dataset facilitates in-depth analyses of asset
allocation methods across diverse asset universes. Additionally, we provide a
case study that exemplifies the use of the synthetic dataset to improve
portfolios constructed within a simulation-based asset allocation process.
</p>
</div>
</dd>
<dt><a name="item689">[689]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16035" title="Abstract">arXiv:2311.16035</a> (cross-list from quant-ph) [<a href="/pdf/2311.16035" title="Download PDF">pdf</a>, <a href="/format/2311.16035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RobustState: Boosting Fidelity of Quantum State Preparation via  Noise-Aware Variational Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+H">Hanrui Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+Y">Yilian Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+P">Pengyu Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gu%2C+J">Jiaqi Gu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+Z">Zirui Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liang%2C+Z">Zhiding Liang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cheng%2C+J">Jinglei Cheng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ding%2C+Y">Yongshan Ding</a>, 
<a href="/search/quant-ph?searchtype=author&query=Qian%2C+X">Xuehai Qian</a>, 
<a href="/search/quant-ph?searchtype=author&query=Shi%2C+Y">Yiyu Shi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pan%2C+D+Z">David Z. Pan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chong%2C+F+T">Frederic T. Chong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Han%2C+S">Song Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to FASTML @ ICCAD 2023. 14 pages, 20 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Quantum state preparation, a crucial subroutine in quantum computing,
involves generating a target quantum state from initialized qubits. Arbitrary
state preparation algorithms can be broadly categorized into arithmetic
decomposition (AD) and variational quantum state preparation (VQSP). AD employs
a predefined procedure to decompose the target state into a series of gates,
whereas VQSP iteratively tunes ansatz parameters to approximate target state.
VQSP is particularly apt for Noisy-Intermediate Scale Quantum (NISQ) machines
due to its shorter circuits. However, achieving noise-robust parameter
optimization still remains challenging.
<br />We present RobustState, a novel VQSP training methodology that combines high
robustness with high training efficiency. The core idea involves utilizing
measurement outcomes from real machines to perform back-propagation through
classical simulators, thus incorporating real quantum noise into gradient
calculations. RobustState serves as a versatile, plug-and-play technique
applicable for training parameters from scratch or fine-tuning existing
parameters to enhance fidelity on target machines. It is adaptable to various
ansatzes at both gate and pulse levels and can even benefit other variational
algorithms, such as variational unitary synthesis.
<br />Comprehensive evaluation of RobustState on state preparation tasks for 4
distinct quantum algorithms using 10 real quantum machines demonstrates a
coherent error reduction of up to 7.1 $\times$ and state fidelity improvement
of up to 96\% and 81\% for 4-Q and 5-Q states, respectively. On average,
RobustState improves fidelity by 50\% and 72\% for 4-Q and 5-Q states compared
to baseline approaches.
</p>
</div>
</dd>
<dt><a name="item690">[690]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16057" title="Abstract">arXiv:2311.16057</a> (cross-list from quant-ph) [<a href="/pdf/2311.16057" title="Download PDF">pdf</a>, <a href="/ps/2311.16057" title="Download PostScript">ps</a>, <a href="/format/2311.16057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Power of Adaptivity in Quantum Query Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Girish%2C+U">Uma Girish</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sinha%2C+M">Makrand Sinha</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ta%2C+A">Avishay Ta</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wu%2C+K">Kewen Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Motivated by limitations on the depth of near-term quantum devices, we study
the depth-computation trade-off in the query model, where the depth corresponds
to the number of adaptive query rounds and the computation per layer
corresponds to the number of parallel queries per round. We achieve the
strongest known separation between quantum algorithms with $r$ versus $r-1$
rounds of adaptivity. We do so by using the $k$-fold Forrelation problem
introduced by Aaronson and Ambainis (SICOMP'18). For $k=2r$, this problem can
be solved using an $r$ round quantum algorithm with only one query per round,
yet we show that any $r-1$ round quantum algorithm needs an exponential (in the
number of qubits) number of parallel queries per round.
<br />Our results are proven following the Fourier analytic machinery developed in
recent works on quantum-classical separations. The key new component in our
result are bounds on the Fourier weights of quantum query algorithms with
bounded number of rounds of adaptivity. These may be of independent interest as
they distinguish the polynomials that arise from such algorithms from arbitrary
bounded polynomials of the same degree.
</p>
</div>
</dd>
<dt><a name="item691">[691]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16080" title="Abstract">arXiv:2311.16080</a> (cross-list from physics.comp-ph) [<a href="/pdf/2311.16080" title="Download PDF">pdf</a>, <a href="/format/2311.16080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XLB: Distributed Multi-GPU Lattice Boltzmann Simulation Framework for  Differentiable Scientific Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Ataei%2C+M">Mohammadmehdi Ataei</a>, 
<a href="/search/physics?searchtype=author&query=Salehipour%2C+H">Hesam Salehipour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
<p class="mathjax">The lattice Boltzmann method (LBM) has emerged as a prominent technique for
solving fluid dynamics problems due to its algorithmic potential for
computational scalability. We introduce XLB framework, a Python-based
differentiable LBM library which harnesses the capabilities of the JAX
framework. The architecture of XLB is predicated upon ensuring accessibility,
extensibility, and computational performance, enabling scaling effectively
across CPU, multi-GPU, and distributed multi-GPU systems. The framework can be
readily augmented with novel boundary conditions, collision models, or
simulation capabilities. XLB offers the unique advantage of integration with
JAX's extensive machine learning echosystem, and the ability to utilize
automatic differentiation for tackling physics-based machine learning,
optimization, and inverse problems. XLB has been successfully scaled to handle
simulations with billions of cells, achieving giga-scale lattice updates per
second. XLB is released under the permissive Apache-2.0 license and is
available on GitHub at https://github.com/Autodesk/XLB.
</p>
</div>
</dd>
<dt><a name="item692">[692]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16082" title="Abstract">arXiv:2311.16082</a> (cross-list from quant-ph) [<a href="/pdf/2311.16082" title="Download PDF">pdf</a>, <a href="/format/2311.16082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer-QEC: Quantum Error Correction Code Decoding with  Transferable Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+H">Hanrui Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+P">Pengyu Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Shao%2C+K">Kevin Shao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+D">Dantong Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gu%2C+J">Jiaqi Gu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pan%2C+D+Z">David Z. Pan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ding%2C+Y">Yongshan Ding</a>, 
<a href="/search/quant-ph?searchtype=author&query=Han%2C+S">Song Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCAD 2023, FAST ML for Science Workshop; 7 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR); Emerging Technologies (cs.ET); Machine Learning (cs.LG)

</div>
<p class="mathjax">Quantum computing has the potential to solve problems that are intractable
for classical systems, yet the high error rates in contemporary quantum devices
often exceed tolerable limits for useful algorithm execution. Quantum Error
Correction (QEC) mitigates this by employing redundancy, distributing quantum
information across multiple data qubits and utilizing syndrome qubits to
monitor their states for errors. The syndromes are subsequently interpreted by
a decoding algorithm to identify and correct errors in the data qubits. This
task is complex due to the multiplicity of error sources affecting both data
and syndrome qubits as well as syndrome extraction operations. Additionally,
identical syndromes can emanate from different error sources, necessitating a
decoding algorithm that evaluates syndromes collectively. Although machine
learning (ML) decoders such as multi-layer perceptrons (MLPs) and convolutional
neural networks (CNNs) have been proposed, they often focus on local syndrome
regions and require retraining when adjusting for different code distances. We
introduce a transformer-based QEC decoder which employs self-attention to
achieve a global receptive field across all input syndromes. It incorporates a
mixed loss training approach, combining both local physical error and global
parity label losses. Moreover, the transformer architecture's inherent
adaptability to variable-length inputs allows for efficient transfer learning,
enabling the decoder to adapt to varying code distances without retraining.
<br />Evaluation on six code distances and ten different error configurations
demonstrates that our model consistently outperforms non-ML decoders, such as
Union Find (UF) and Minimum Weight Perfect Matching (MWPM), and other ML
decoders, thereby achieving best logical error rates. Moreover, the transfer
learning can save over 10x of training cost.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Tue, 28 Nov 23</h3>
<dl>
<dt><a name="item693">[693]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1110.6749" title="Abstract">arXiv:1110.6749</a> (replaced) [<a href="/pdf/1110.6749" title="Download PDF">pdf</a>, <a href="/ps/1110.6749" title="Download PostScript">ps</a>, <a href="/format/1110.6749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nystrom Methods in the RKQ Algorithm for Initial-value Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Prentice%2C+J+S+C">J. S. C. Prentice</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an extension of ideas published in J. Math. Res. (open access); see refs [1] and [2]
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item694">[694]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1807.03418" title="Abstract">arXiv:1807.03418</a> (replaced) [<a href="/pdf/1807.03418" title="Download PDF">pdf</a>, <a href="/format/1807.03418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AudioMNIST: Exploring Explainable Artificial Intelligence for Audio  Analysis on a Simple Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Becker%2C+S">S&#xf6;ren Becker</a>, 
<a href="/search/cs?searchtype=author&query=Vielhaben%2C+J">Johanna Vielhaben</a>, 
<a href="/search/cs?searchtype=author&query=Ackermann%2C+M">Marcel Ackermann</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+K">Klaus-Robert M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Lapuschkin%2C+S">Sebastian Lapuschkin</a>, 
<a href="/search/cs?searchtype=author&query=Samek%2C+W">Wojciech Samek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item695">[695]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1909.10199" title="Abstract">arXiv:1909.10199</a> (replaced) [<a href="/pdf/1909.10199" title="Download PDF">pdf</a>, <a href="/format/1909.10199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scheduling Games with Machine-Dependent Priority Lists
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vijayalakshmi%2C+V+R">Vipin Ravindran Vijayalakshmi</a>, 
<a href="/search/cs?searchtype=author&query=Schr%C3%B6der%2C+M">Marc Schr&#xf6;der</a>, 
<a href="/search/cs?searchtype=author&query=Tamir%2C+T">Tami Tamir</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item696">[696]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1910.14389" title="Abstract">arXiv:1910.14389</a> (replaced) [<a href="/pdf/1910.14389" title="Download PDF">pdf</a>, <a href="/ps/1910.14389" title="Download PostScript">ps</a>, <a href="/format/1910.14389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sharp Bounds for Genetic Drift in Estimation of Distribution Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doerr%2C+B">Benjamin Doerr</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Weijie Zheng</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Evolutionary Computation, vol. 24, no. 6, pp.
  1140-1149, Dec. 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item697">[697]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2003.11795" title="Abstract">arXiv:2003.11795</a> (replaced) [<a href="/pdf/2003.11795" title="Download PDF">pdf</a>, <a href="/format/2003.11795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Primal-Dual Weak Galerkin Method for Div-Curl Systems with  low-regularity solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+Y">Yujie Liu</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+J">Junping Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item698">[698]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2003.13605" title="Abstract">arXiv:2003.13605</a> (replaced) [<a href="/pdf/2003.13605" title="Download PDF">pdf</a>, <a href="/ps/2003.13605" title="Download PostScript">ps</a>, <a href="/format/2003.13605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On different Versions of the Exact Subgraph Hierarchy for the Stable Set  Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gaar%2C+E">Elisabeth Gaar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item699">[699]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2007.14660" title="Abstract">arXiv:2007.14660</a> (replaced) [<a href="/pdf/2007.14660" title="Download PDF">pdf</a>, <a href="/format/2007.14660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ergodicity of the underdamped mean-field Langevin dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kazeykina%2C+A">Anna Kazeykina</a>, 
<a href="/search/math?searchtype=author&query=Ren%2C+Z">Zhenjie Ren</a>, 
<a href="/search/math?searchtype=author&query=Tan%2C+X">Xiaolu Tan</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+J">Junjian Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item700">[700]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.12920" title="Abstract">arXiv:2102.12920</a> (replaced) [<a href="/pdf/2102.12920" title="Download PDF">pdf</a>, <a href="/ps/2102.12920" title="Download PostScript">ps</a>, <a href="/format/2102.12920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emerging Trends in Federated Learning: From Model Fusion to Federated X  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shaoxiong Ji</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yue Tan</a>, 
<a href="/search/cs?searchtype=author&query=Saravirta%2C+T">Teemu Saravirta</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhiqin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Vasankari%2C+L">Lauri Vasankari</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shirui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+G">Guodong Long</a>, 
<a href="/search/cs?searchtype=author&query=Walid%2C+A">Anwar Walid</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item701">[701]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.03543" title="Abstract">arXiv:2103.03543</a> (replaced) [<a href="/pdf/2103.03543" title="Download PDF">pdf</a>, <a href="/format/2103.03543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Artificial Neural Networks generated by Low Discrepancy Sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Keller%2C+A">Alexander Keller</a>, 
<a href="/search/cs?searchtype=author&query=Van+keirsbilck%2C+M">Matthijs Van keirsbilck</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item702">[702]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.00867" title="Abstract">arXiv:2104.00867</a> (replaced) [<a href="/pdf/2104.00867" title="Download PDF">pdf</a>, <a href="/format/2104.00867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curl-Flow: Boundary-Respecting Pointwise Incompressible Velocity  Interpolation for Grid-Based Fluids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+J">Jumyung Chang</a>, 
<a href="/search/cs?searchtype=author&query=Partono%2C+R">Ruben Partono</a>, 
<a href="/search/cs?searchtype=author&query=Azevedo%2C+V+C">Vinicius C. Azevedo</a>, 
<a href="/search/cs?searchtype=author&query=Batty%2C+C">Christopher Batty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
</div>
</dd>
<dt><a name="item703">[703]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.10926" title="Abstract">arXiv:2105.10926</a> (replaced) [<a href="/pdf/2105.10926" title="Download PDF">pdf</a>, <a href="/format/2105.10926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Global Context in Crowd Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Guolei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Probst%2C+T">Thomas Probst</a>, 
<a href="/search/cs?searchtype=author&query=Paudel%2C+D+P">Danda Pani Paudel</a>, 
<a href="/search/cs?searchtype=author&query=Popovic%2C+N">Nikola Popovic</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Machine Intelligence Research (MIR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item704">[704]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.10021" title="Abstract">arXiv:2107.10021</a> (replaced) [<a href="/pdf/2107.10021" title="Download PDF">pdf</a>, <a href="/format/2107.10021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuradicon: operational representation learning of neuroimaging reports
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Watkins%2C+H">Henry Watkins</a>, 
<a href="/search/cs?searchtype=author&query=Gray%2C+R">Robert Gray</a>, 
<a href="/search/cs?searchtype=author&query=Julius%2C+A">Adam Julius</a>, 
<a href="/search/cs?searchtype=author&query=Mah%2C+Y">Yee-Haur Mah</a>, 
<a href="/search/cs?searchtype=author&query=Pinaya%2C+W+H+L">Walter H.L. Pinaya</a>, 
<a href="/search/cs?searchtype=author&query=Wright%2C+P">Paul Wright</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+A">Ashwani Jha</a>, 
<a href="/search/cs?searchtype=author&query=Engleitner%2C+H">Holger Engleitner</a>, 
<a href="/search/cs?searchtype=author&query=Cardoso%2C+J">Jorge Cardoso</a>, 
<a href="/search/cs?searchtype=author&query=Ourselin%2C+S">Sebastien Ourselin</a>, 
<a href="/search/cs?searchtype=author&query=Rees%2C+G">Geraint Rees</a>, 
<a href="/search/cs?searchtype=author&query=Jaeger%2C+R">Rolf Jaeger</a>, 
<a href="/search/cs?searchtype=author&query=Nachev%2C+P">Parashkev Nachev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item705">[705]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.06584" title="Abstract">arXiv:2109.06584</a> (replaced) [<a href="/pdf/2109.06584" title="Download PDF">pdf</a>, <a href="/ps/2109.06584" title="Download PostScript">ps</a>, <a href="/format/2109.06584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Choosing the Right Algorithm With Hints From Complexity Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shouda Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Weijie Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Doerr%2C+B">Benjamin Doerr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 1 Figure. Journal version of a paper appearing at IJCAI 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item706">[706]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.08693" title="Abstract">arXiv:2110.08693</a> (replaced) [<a href="/pdf/2110.08693" title="Download PDF">pdf</a>, <a href="/format/2110.08693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Elastic Shape Analysis of Tree-like 3D Objects using Extended SRVF  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Laga%2C+H">Hamid Laga</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+A">Anuj Srivastava</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Geometry (cs.CG); Graphics (cs.GR); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item707">[707]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.08239" title="Abstract">arXiv:2111.08239</a> (replaced) [<a href="/pdf/2111.08239" title="Download PDF">pdf</a>, <a href="/format/2111.08239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing Deep Neural Networks as Probability Estimators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Kuo%2C+K">Kwo-Sen Kuo</a>, 
<a href="/search/cs?searchtype=author&query=Rilee%2C+M+L">Michael L. Rilee</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hongfeng Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Y. Pan, K. Kuo, M. Rilee and H. Yu, "Assessing Deep Neural Networks as Probability Estimators," in 2021 IEEE International Conference on Big Data (Big Data), Orlando, FL, USA, 2021 pp. 1083-1091. doi: 10.1109/BigData52589.2021.9671328
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item708">[708]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.08805" title="Abstract">arXiv:2111.08805</a> (replaced) [<a href="/pdf/2111.08805" title="Download PDF">pdf</a>, <a href="/ps/2111.08805" title="Download PostScript">ps</a>, <a href="/format/2111.08805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Estimation and Optimization of Utility-Based Shortfall Risk
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hegde%2C+V">Vishwajit Hegde</a>, 
<a href="/search/stat?searchtype=author&query=Menon%2C+A+S">Arvind S. Menon</a>, 
<a href="/search/stat?searchtype=author&query=Prashanth%2C+L+A">L.A. Prashanth</a>, 
<a href="/search/stat?searchtype=author&query=Jagannathan%2C+K">Krishna Jagannathan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Risk Management (q-fin.RM)

</div>
</div>
</dd>
<dt><a name="item709">[709]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.12589" title="Abstract">arXiv:2112.12589</a> (replaced) [<a href="/pdf/2112.12589" title="Download PDF">pdf</a>, <a href="/ps/2112.12589" title="Download PostScript">ps</a>, <a href="/format/2112.12589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A deep reinforcement learning model for predictive maintenance planning  of road assets: Integrating LCA and LCCA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Latifi%2C+M">Moein Latifi</a>, 
<a href="/search/cs?searchtype=author&query=Darvishvand%2C+F+G">Fateme Golivand Darvishvand</a>, 
<a href="/search/cs?searchtype=author&query=Khandel%2C+O">Omid Khandel</a>, 
<a href="/search/cs?searchtype=author&query=Nowsoud%2C+M+L">Mobin Latifi Nowsoud</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item710">[710]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.14019" title="Abstract">arXiv:2112.14019</a> (replaced) [<a href="/pdf/2112.14019" title="Download PDF">pdf</a>, <a href="/format/2112.14019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-supervised Salient Object Detection with Effective Confidence  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiawei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Barnes%2C+N">Nick Barnes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item711">[711]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.01628" title="Abstract">arXiv:2201.01628</a> (replaced) [<a href="/pdf/2201.01628" title="Download PDF">pdf</a>, <a href="/format/2201.01628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Adversarial and Nonstationary Multi-armed Bandit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Ningyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuoguang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hailun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item712">[712]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.03005" title="Abstract">arXiv:2203.03005</a> (replaced) [<a href="/pdf/2203.03005" title="Download PDF">pdf</a>, <a href="/format/2203.03005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Face Image Restoration with a One-Shot Reference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yanhui Guo</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+F">Fangzhou Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shaoyuan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item713">[713]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.05400" title="Abstract">arXiv:2203.05400</a> (replaced) [<a href="/pdf/2203.05400" title="Download PDF">pdf</a>, <a href="/format/2203.05400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymptotic Bounds for Smoothness Parameter Estimates in Gaussian Process  Interpolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Karvonen%2C+T">Toni Karvonen</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> TSIAM/ASA Journal on Uncertainty Quantification, 11(4):1225-1257
  (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item714">[714]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.09347" title="Abstract">arXiv:2203.09347</a> (replaced) [<a href="/pdf/2203.09347" title="Download PDF">pdf</a>, <a href="/format/2203.09347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dimensionality Reduction and Wasserstein Stability for Kernel Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Eckstein%2C+S">Stephan Eckstein</a>, 
<a href="/search/stat?searchtype=author&query=Iske%2C+A">Armin Iske</a>, 
<a href="/search/stat?searchtype=author&query=Trabs%2C+M">Mathias Trabs</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Forthcoming in JMLR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item715">[715]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.09659" title="Abstract">arXiv:2203.09659</a> (replaced) [<a href="/pdf/2203.09659" title="Download PDF">pdf</a>, <a href="/format/2203.09659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-degree learning and the metric entropy of polynomials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eskenazis%2C+A">Alexandros Eskenazis</a>, 
<a href="/search/cs?searchtype=author&query=Ivanisvili%2C+P">Paata Ivanisvili</a>, 
<a href="/search/cs?searchtype=author&query=Streck%2C+L">Lauritz Streck</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Complexity (cs.CC); Combinatorics (math.CO); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item716">[716]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.05859" title="Abstract">arXiv:2204.05859</a> (replaced) [<a href="/pdf/2204.05859" title="Download PDF">pdf</a>, <a href="/format/2204.05859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bootstrap Motion Forecasting With Self-Consistent Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+M">Maosheng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiamiao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xunnong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tengfei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+T">Tongyi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qifeng Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item717">[717]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.12181" title="Abstract">arXiv:2204.12181</a> (replaced) [<a href="/pdf/2204.12181" title="Download PDF">pdf</a>, <a href="/format/2204.12181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Target Search with a Visual Drone Swarm: An Adaptive  Curriculum Embedded Multistage Reinforcement Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jiaping Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Pisutsin%2C+P">Phumrapee Pisutsin</a>, 
<a href="/search/cs?searchtype=author&query=Feroskhan%2C+M">Mir Feroskhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Neural Networks and Learning Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item718">[718]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.08253" title="Abstract">arXiv:2205.08253</a> (replaced) [<a href="/pdf/2205.08253" title="Download PDF">pdf</a>, <a href="/format/2205.08253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Momentum-Based Policy Gradient with Second-Order Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salehkaleybar%2C+S">Saber Salehkaleybar</a>, 
<a href="/search/cs?searchtype=author&query=Khorasani%2C+S">Sadegh Khorasani</a>, 
<a href="/search/cs?searchtype=author&query=Kiyavash%2C+N">Negar Kiyavash</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+N">Niao He</a>, 
<a href="/search/cs?searchtype=author&query=Thiran%2C+P">Patrick Thiran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item719">[719]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.10089" title="Abstract">arXiv:2205.10089</a> (replaced) [<a href="/pdf/2205.10089" title="Download PDF">pdf</a>, <a href="/format/2205.10089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kernel Normalized Convolutional Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nasirigerdeh%2C+R">Reza Nasirigerdeh</a>, 
<a href="/search/cs?searchtype=author&query=Torkzadehmahani%2C+R">Reihaneh Torkzadehmahani</a>, 
<a href="/search/cs?searchtype=author&query=Rueckert%2C+D">Daniel Rueckert</a>, 
<a href="/search/cs?searchtype=author&query=Kaissis%2C+G">Georgios Kaissis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item720">[720]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.10952" title="Abstract">arXiv:2205.10952</a> (replaced) [<a href="/pdf/2205.10952" title="Download PDF">pdf</a>, <a href="/format/2205.10952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of functional neural codes of deep learning models: Functional  Telescope Hypothesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+H">Jung Hoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Vijayan%2C+S">Sujith Vijayan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 12 main figures, 3 supplemental figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item721">[721]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.13748" title="Abstract">arXiv:2205.13748</a> (replaced) [<a href="/pdf/2205.13748" title="Download PDF">pdf</a>, <a href="/format/2205.13748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auto-PINN: Understanding and Optimizing Physics-Informed Neural  Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yicheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaotian Han</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Chia-Yuan Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+D">Daochen Zha</a>, 
<a href="/search/cs?searchtype=author&query=Braga-Neto%2C+U">Ulisses Braga-Neto</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xia Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item722">[722]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.15580" title="Abstract">arXiv:2205.15580</a> (replaced) [<a href="/pdf/2205.15580" title="Download PDF">pdf</a>, <a href="/format/2205.15580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Computation and Communication Efficient Method for Distributed  Nonconvex Problems in the Partial Participation Setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tyurin%2C+A">Alexander Tyurin</a>, 
<a href="/search/cs?searchtype=author&query=Richt%C3%A1rik%2C+P">Peter Richt&#xe1;rik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item723">[723]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.06817" title="Abstract">arXiv:2206.06817</a> (replaced) [<a href="/pdf/2206.06817" title="Download PDF">pdf</a>, <a href="/ps/2206.06817" title="Download PostScript">ps</a>, <a href="/format/2206.06817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Residual-based physics-informed transfer learning: A hybrid method for  accelerating long-term CFD simulations via deep learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Jeon%2C+J">Joongoo Jeon</a>, 
<a href="/search/physics?searchtype=author&query=Lee%2C+J">Juhyeong Lee</a>, 
<a href="/search/physics?searchtype=author&query=Vinuesa%2C+R">Ricardo Vinuesa</a>, 
<a href="/search/physics?searchtype=author&query=Kim%2C+S+J">Sung Joong Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 10 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Heat and Mass Transfer 220 (2024) 124900
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item724">[724]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.10498" title="Abstract">arXiv:2206.10498</a> (replaced) [<a href="/pdf/2206.10498" title="Download PDF">pdf</a>, <a href="/format/2206.10498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PlanBench: An Extensible Benchmark for Evaluating Large Language Models  on Planning and Reasoning about Change
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valmeekam%2C+K">Karthik Valmeekam</a>, 
<a href="/search/cs?searchtype=author&query=Marquez%2C+M">Matthew Marquez</a>, 
<a href="/search/cs?searchtype=author&query=Olmo%2C+A">Alberto Olmo</a>, 
<a href="/search/cs?searchtype=author&query=Sreedharan%2C+S">Sarath Sreedharan</a>, 
<a href="/search/cs?searchtype=author&query=Kambhampati%2C+S">Subbarao Kambhampati</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Track on Datasets and Benchmarks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item725">[725]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.13765" title="Abstract">arXiv:2206.13765</a> (replaced) [<a href="/pdf/2206.13765" title="Download PDF">pdf</a>, <a href="/format/2206.13765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Indiscernibles and Flatness in Monadically Stable and Monadically NIP  Classes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dreier%2C+J">Jan Dreier</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%A4hlmann%2C+N">Nikolas M&#xe4;hlmann</a>, 
<a href="/search/cs?searchtype=author&query=Siebertz%2C+S">Sebastian Siebertz</a>, 
<a href="/search/cs?searchtype=author&query=Toru%C5%84czyk%2C+S">Szymon Toru&#x144;czyk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v2: revised presentation; renamed flip-wideness to flip-flatness; changed the title from "Indiscernibles and Wideness [...]" to "Indiscernibles and Flatness [...]"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO); Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item726">[726]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.07417" title="Abstract">arXiv:2207.07417</a> (replaced) [<a href="/pdf/2207.07417" title="Download PDF">pdf</a>, <a href="/format/2207.07417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-Linear Time and Fixed-Parameter Tractable Algorithms for Tensor  Decompositions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahankali%2C+A+V">Arvind V. Mahankali</a>, 
<a href="/search/cs?searchtype=author&query=Woodruff%2C+D+P">David P. Woodruff</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziyu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item727">[727]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.08913" title="Abstract">arXiv:2207.08913</a> (replaced) [<a href="/pdf/2207.08913" title="Download PDF">pdf</a>, <a href="/format/2207.08913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Factorizations and Colorings of Tensor Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brakensiek%2C+J">Joshua Brakensiek</a>, 
<a href="/search/cs?searchtype=author&query=Davies%2C+S">Sami Davies</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 3 figures; accepted to SIAM Journal on Discrete Mathematics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Data Structures and Algorithms (cs.DS); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item728">[728]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.04568" title="Abstract">arXiv:2208.04568</a> (replaced) [<a href="/pdf/2208.04568" title="Download PDF">pdf</a>, <a href="/format/2208.04568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Data Corruption on Named Entity Recognition for  Low-resourced Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fokam%2C+M">Manuel Fokam</a>, 
<a href="/search/cs?searchtype=author&query=Beukman%2C+M">Michael Beukman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item729">[729]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.06991" title="Abstract">arXiv:2208.06991</a> (replaced) [<a href="/pdf/2208.06991" title="Download PDF">pdf</a>, <a href="/format/2208.06991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Interpretable Sleep Stage Classification Using Cross-Modal  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pradeepkumar%2C+J">Jathurshan Pradeepkumar</a>, 
<a href="/search/cs?searchtype=author&query=Anandakumar%2C+M">Mithunjha Anandakumar</a>, 
<a href="/search/cs?searchtype=author&query=Kugathasan%2C+V">Vinith Kugathasan</a>, 
<a href="/search/cs?searchtype=author&query=Suntharalingham%2C+D">Dhinesh Suntharalingham</a>, 
<a href="/search/cs?searchtype=author&query=Kappel%2C+S+L">Simon L. Kappel</a>, 
<a href="/search/cs?searchtype=author&query=De+Silva%2C+A+C">Anjula C. De Silva</a>, 
<a href="/search/cs?searchtype=author&query=Edussooriya%2C+C+U+S">Chamira U. S. Edussooriya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item730">[730]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.12370" title="Abstract">arXiv:2208.12370</a> (replaced) [<a href="/pdf/2208.12370" title="Download PDF">pdf</a>, <a href="/format/2208.12370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COOKIEGRAPH: Understanding and Detecting First-Party Tracking Cookies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Munir%2C+S">Shaoor Munir</a>, 
<a href="/search/cs?searchtype=author&query=Siby%2C+S">Sandra Siby</a>, 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+U">Umar Iqbal</a>, 
<a href="/search/cs?searchtype=author&query=Englehardt%2C+S">Steven Englehardt</a>, 
<a href="/search/cs?searchtype=author&query=Shafiq%2C+Z">Zubair Shafiq</a>, 
<a href="/search/cs?searchtype=author&query=Troncoso%2C+C">Carmela Troncoso</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item731">[731]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.12854" title="Abstract">arXiv:2208.12854</a> (replaced) [<a href="/pdf/2208.12854" title="Download PDF">pdf</a>, <a href="/ps/2208.12854" title="Download PostScript">ps</a>, <a href="/format/2208.12854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving large-scale MEG/EEG source localization and functional  connectivity problems simultaneously using state-space models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sanchez-Bornot%2C+J+M">Jose M. Sanchez-Bornot</a>, 
<a href="/search/stat?searchtype=author&query=Sotero%2C+R+C">Roberto C. Sotero</a>, 
<a href="/search/stat?searchtype=author&query=Kelso%2C+S">Scott Kelso</a>, 
<a href="/search/stat?searchtype=author&query=Coyle%2C+D">Damien Coyle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neuroimage 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation (stat.CO)</span>; Signal Processing (eess.SP); Dynamical Systems (math.DS); Numerical Analysis (math.NA); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item732">[732]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.14362" title="Abstract">arXiv:2208.14362</a> (replaced) [<a href="/pdf/2208.14362" title="Download PDF">pdf</a>, <a href="/format/2208.14362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoWS-Bench-101: Benchmarking Automated Weak Supervision with 100  Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roberts%2C+N">Nicholas Roberts</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xintong Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tzu-Heng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Adila%2C+D">Dyah Adila</a>, 
<a href="/search/cs?searchtype=author&query=Schoenberg%2C+S">Spencer Schoenberg</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cheng-Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pick%2C+L">Lauren Pick</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Haotian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Albarghouthi%2C+A">Aws Albarghouthi</a>, 
<a href="/search/cs?searchtype=author&query=Sala%2C+F">Frederic Sala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2022 Datasets and Benchmarks Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item733">[733]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.00462" title="Abstract">arXiv:2209.00462</a> (replaced) [<a href="/pdf/2209.00462" title="Download PDF">pdf</a>, <a href="/format/2209.00462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MA-RECON: Mask-aware deep-neural-network for robust fast MRI k-space  interpolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Avidan%2C+N">Nitzan Avidan</a>, 
<a href="/search/eess?searchtype=author&query=Freiman%2C+M">Moti Freiman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Computer Methods and Programs in Biomedicine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item734">[734]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.04567" title="Abstract">arXiv:2209.04567</a> (replaced) [<a href="/pdf/2209.04567" title="Download PDF">pdf</a>, <a href="/format/2209.04567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A general class of combinatorial filters that can be minimized  efficiently
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yulin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shell%2C+D+A">Dylan A. Shell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item735">[735]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.07042" title="Abstract">arXiv:2209.07042</a> (replaced) [<a href="/pdf/2209.07042" title="Download PDF">pdf</a>, <a href="/format/2209.07042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Perception, Planning, and Control Algorithms for Vision-Based  Automated Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Der-Hau Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 figures, 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item736">[736]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.13204" title="Abstract">arXiv:2209.13204</a> (replaced) [<a href="/pdf/2209.13204" title="Download PDF">pdf</a>, <a href="/format/2209.13204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NEURAL MARIONETTE: A Transformer-based Multi-action Human Motion  Synthesis System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhe%2C+X">Xuefei Zhe</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+Q">Qiuhong Ke</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+D">Di Kang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tingguang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruizhi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+L">Linchao Bao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item737">[737]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.14634" title="Abstract">arXiv:2209.14634</a> (replaced) [<a href="/pdf/2209.14634" title="Download PDF">pdf</a>, <a href="/format/2209.14634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hard thresholding hyperinterpolation over general regions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=An%2C+C">Congpei An</a>, 
<a href="/search/math?searchtype=author&query=Ran%2C+J">Jia-Shu Ran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item738">[738]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.00716" title="Abstract">arXiv:2210.00716</a> (replaced) [<a href="/pdf/2210.00716" title="Download PDF">pdf</a>, <a href="/format/2210.00716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> rPPG-Toolbox: Deep Remote PPG Toolbox
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Narayanswamy%2C+G">Girish Narayanswamy</a>, 
<a href="/search/cs?searchtype=author&query=Paruchuri%2C+A">Akshay Paruchuri</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiankai Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuzhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+S">Soumyadip Sengupta</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+S">Shwetak Patel</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuntao Wang</a>, 
<a href="/search/cs?searchtype=author&query=McDuff%2C+D">Daniel McDuff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item739">[739]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.01694" title="Abstract">arXiv:2210.01694</a> (replaced) [<a href="/pdf/2210.01694" title="Download PDF">pdf</a>, <a href="/format/2210.01694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Complexity of Online Graph Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fuchs%2C+J">Janosch Fuchs</a>, 
<a href="/search/cs?searchtype=author&query=Gr%C3%BCne%2C+C">Christoph Gr&#xfc;ne</a>, 
<a href="/search/cs?searchtype=author&query=Jan%C3%9Fen%2C+T">Tom Jan&#xdf;en</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item740">[740]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.02054" title="Abstract">arXiv:2210.02054</a> (replaced) [<a href="/pdf/2210.02054" title="Download PDF">pdf</a>, <a href="/format/2210.02054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Placing by Touching: An empirical study on the importance of tactile  sensing for precise object placing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lach%2C+L">Luca Lach</a>, 
<a href="/search/cs?searchtype=author&query=Funk%2C+N">Niklas Funk</a>, 
<a href="/search/cs?searchtype=author&query=Haschke%2C+R">Robert Haschke</a>, 
<a href="/search/cs?searchtype=author&query=Lemaignan%2C+S">Severin Lemaignan</a>, 
<a href="/search/cs?searchtype=author&query=Ritter%2C+H+J">Helge Joachim Ritter</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Jan Peters</a>, 
<a href="/search/cs?searchtype=author&query=Chalvatzaki%2C+G">Georgia Chalvatzaki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item741">[741]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.02341" title="Abstract">arXiv:2210.02341</a> (replaced) [<a href="/pdf/2210.02341" title="Download PDF">pdf</a>, <a href="/format/2210.02341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Distributed Block-Split Gibbs Sampler with Hypergraph Structure for  High-Dimensional Inverse Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Thouvenin%2C+P">Pierre-Antoine Thouvenin</a>, 
<a href="/search/stat?searchtype=author&query=Repetti%2C+A">Audrey Repetti</a>, 
<a href="/search/stat?searchtype=author&query=Chainais%2C+P">Pierre Chainais</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item742">[742]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.03829" title="Abstract">arXiv:2210.03829</a> (replaced) [<a href="/pdf/2210.03829" title="Download PDF">pdf</a>, <a href="/format/2210.03829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Early Detection of Bark Beetle Attack Using Remote Sensing and Machine  Learning: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marvasti-Zadeh%2C+S+M">Seyed Mojtaba Marvasti-Zadeh</a>, 
<a href="/search/cs?searchtype=author&query=Goodsman%2C+D">Devin Goodsman</a>, 
<a href="/search/cs?searchtype=author&query=Ray%2C+N">Nilanjan Ray</a>, 
<a href="/search/cs?searchtype=author&query=Erbilgin%2C+N">Nadir Erbilgin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM Computing Surveys, 56, 4, Article 97, April 2024. <a href="https://doi.org/10.1145/3625387">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item743">[743]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.04022" title="Abstract">arXiv:2210.04022</a> (replaced) [<a href="/pdf/2210.04022" title="Download PDF">pdf</a>, <a href="/format/2210.04022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speeding up the solution of the Site and Power Assignment Problem in  Wireless Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Avella%2C+P">Pasquale Avella</a>, 
<a href="/search/cs?searchtype=author&query=Calamita%2C+A">Alice Calamita</a>, 
<a href="/search/cs?searchtype=author&query=Palagi%2C+L">Laura Palagi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
</div>
</dd>
<dt><a name="item744">[744]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.06462" title="Abstract">arXiv:2210.06462</a> (replaced) [<a href="/pdf/2210.06462" title="Download PDF">pdf</a>, <a href="/format/2210.06462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Guided Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+V+T">Vincent Tao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D+W">David W Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Asano%2C+Y+M">Yuki M. Asano</a>, 
<a href="/search/cs?searchtype=author&query=Burghouts%2C+G+J">Gertjan J. Burghouts</a>, 
<a href="/search/cs?searchtype=author&query=Snoek%2C+C+G+M">Cees G. M. Snoek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item745">[745]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.08728" title="Abstract">arXiv:2210.08728</a> (replaced) [<a href="/pdf/2210.08728" title="Download PDF">pdf</a>, <a href="/format/2210.08728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fault Injection based Failure Analysis of three CentOS-like Operating  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hao Xu</a> (1), 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yuxi Hu</a> (2), 
<a href="/search/cs?searchtype=author&query=Tan%2C+B">Bolong Tan</a> (2), 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xiaohai Shi</a> (2), 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhangjun Lu</a> (1), 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a> (1), 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jianhui Jiang</a> (1) ((1) Tongji University, (2) Alibaba Inc.)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item746">[746]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.09846" title="Abstract">arXiv:2210.09846</a> (replaced) [<a href="/pdf/2210.09846" title="Download PDF">pdf</a>, <a href="/format/2210.09846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> G-PECNet: Towards a Generalizable Pedestrian Trajectory Prediction  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garg%2C+A">Aryan Garg</a>, 
<a href="/search/cs?searchtype=author&query=Rameshan%2C+R+M">Renu M. Rameshan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item747">[747]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.00460" title="Abstract">arXiv:2211.00460</a> (replaced) [<a href="/pdf/2211.00460" title="Download PDF">pdf</a>, <a href="/format/2211.00460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmentation Invariant Manifold Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wang%2C+S">Shulei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item748">[748]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.04385" title="Abstract">arXiv:2211.04385</a> (replaced) [<a href="/pdf/2211.04385" title="Download PDF">pdf</a>, <a href="/format/2211.04385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why we couldn&#x27;t prove SETH hardness of the Closest Vector Problem for  even norms!
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+D">Divesh Aggarwal</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+R">Rajendra Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added: Instance compression of exact-CVP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Cryptography and Security (cs.CR); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item749">[749]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.04686" title="Abstract">arXiv:2211.04686</a> (replaced) [<a href="/pdf/2211.04686" title="Download PDF">pdf</a>, <a href="/format/2211.04686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Directional Privacy for Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Faustini%2C+P">Pedro Faustini</a>, 
<a href="/search/cs?searchtype=author&query=Fernandes%2C+N">Natasha Fernandes</a>, 
<a href="/search/cs?searchtype=author&query=Tonni%2C+S">Shakila Tonni</a>, 
<a href="/search/cs?searchtype=author&query=McIver%2C+A">Annabelle McIver</a>, 
<a href="/search/cs?searchtype=author&query=Dras%2C+M">Mark Dras</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item750">[750]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.10413" title="Abstract">arXiv:2211.10413</a> (replaced) [<a href="/pdf/2211.10413" title="Download PDF">pdf</a>, <a href="/format/2211.10413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TSN-FlexTest: Flexible TSN Measurement Testbed (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ulbricht%2C+M">Marian Ulbricht</a>, 
<a href="/search/cs?searchtype=author&query=Senk%2C+S">Stefan Senk</a>, 
<a href="/search/cs?searchtype=author&query=Nazari%2C+H+K">Hosein K. Nazari</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">How-Hang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Reisslein%2C+M">Martin Reisslein</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+G+T">Giang T. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Fitzek%2C+F+H+P">Frank H. P. Fitzek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 18 figures, 6 tables, IEEE TNSM, in print, 2024. Shorter version in print in IEEE Trans. on Network and Service Management (see related DOI below)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item751">[751]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14309" title="Abstract">arXiv:2211.14309</a> (replaced) [<a href="/pdf/2211.14309" title="Download PDF">pdf</a>, <a href="/format/2211.14309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FutureHuman3D: Forecasting Complex Long-Term 3D Human Behavior from  Video Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diller%2C+C">Christian Diller</a>, 
<a href="/search/cs?searchtype=author&query=Funkhouser%2C+T">Thomas Funkhouser</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+A">Angela Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://future-human-3d.christian-diller.de/">this https URL</a> Video: <a href="https://www.youtube.com/watch?v=18du85YFXL0">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item752">[752]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14400" title="Abstract">arXiv:2211.14400</a> (replaced) [<a href="/pdf/2211.14400" title="Download PDF">pdf</a>, <a href="/ps/2211.14400" title="Download PostScript">ps</a>, <a href="/format/2211.14400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Approximation Rates for Deep ReLU Neural Networks on Sobolev and  Besov Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Siegel%2C+J+W">Jonathan W. Siegel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item753">[753]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14456" title="Abstract">arXiv:2211.14456</a> (replaced) [<a href="/pdf/2211.14456" title="Download PDF">pdf</a>, <a href="/format/2211.14456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TetraSphere: A Neural Descriptor for O(3)-Invariant Point Cloud Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Melnyk%2C+P">Pavlo Melnyk</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+A">Andreas Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Felsberg%2C+M">Michael Felsberg</a>, 
<a href="/search/cs?searchtype=author&query=Wadenb%C3%A4ck%2C+M">M&#xe5;rten Wadenb&#xe4;ck</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item754">[754]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.16587" title="Abstract">arXiv:2211.16587</a> (replaced) [<a href="/pdf/2211.16587" title="Download PDF">pdf</a>, <a href="/format/2211.16587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rigorous Assessment of Model Inference Accuracy using Language  Cardinality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Clun%2C+D">Donato Clun</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+D">Donghwan Shin</a>, 
<a href="/search/cs?searchtype=author&query=Filieri%2C+A">Antonio Filieri</a>, 
<a href="/search/cs?searchtype=author&query=Bianculli%2C+D">Domenico Bianculli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item755">[755]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09068" title="Abstract">arXiv:2212.09068</a> (replaced) [<a href="/pdf/2212.09068" title="Download PDF">pdf</a>, <a href="/format/2212.09068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Style-Hallucinated Dual Consistency Learning: A Unified Framework for  Visual Domain Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zhun Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+N">Na Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sebe%2C+N">Nicu Sebe</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+G+H">Gim Hee Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IJCV. Journal extension of <a href="/abs/2204.02548">arXiv:2204.02548</a>. Code is available at <a href="https://github.com/HeliosZhao/SHADE-VisualDG">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item756">[756]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.10013" title="Abstract">arXiv:2212.10013</a> (replaced) [<a href="/pdf/2212.10013" title="Download PDF">pdf</a>, <a href="/format/2212.10013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DocAsRef: An Empirical Study on Repurposing Reference-Based Summary  Quality Metrics Reference-Freely
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+F+S">Forrest Sheng Bao</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+R">Ruixuan Tu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+G">Ge Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yinfei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hebi Li</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+M">Minghui Qiu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Youbiao He</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cen Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted into Findings of EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item757">[757]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.12015" title="Abstract">arXiv:2212.12015</a> (replaced) [<a href="/pdf/2212.12015" title="Download PDF">pdf</a>, <a href="/format/2212.12015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic analysis of the Elo rating algorithm in round-robin  tournaments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Pinho+Zanco%2C+D+G">Daniel Gomes de Pinho Zanco</a>, 
<a href="/search/cs?searchtype=author&query=Szczecinski%2C+L">Leszek Szczecinski</a>, 
<a href="/search/cs?searchtype=author&query=Kuhn%2C+E+V">Eduardo Vinicius Kuhn</a>, 
<a href="/search/cs?searchtype=author&query=Seara%2C+R">Rui Seara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item758">[758]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00387" title="Abstract">arXiv:2301.00387</a> (replaced) [<a href="/pdf/2301.00387" title="Download PDF">pdf</a>, <a href="/ps/2301.00387" title="Download PostScript">ps</a>, <a href="/format/2301.00387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exactly Hittable Interval Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhannya%2C+S+M">S.M. Dhannya</a>, 
<a href="/search/cs?searchtype=author&query=Narayanaswamy%2C+N+S">N.S. Narayanaswamy</a>, 
<a href="/search/cs?searchtype=author&query=Nisha%2C+K+K">K.K. Nisha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages. arXiv admin note: text overlap with <a href="/abs/1707.05071">arXiv:1707.05071</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item759">[759]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.01095" title="Abstract">arXiv:2301.01095</a> (replaced) [<a href="/pdf/2301.01095" title="Download PDF">pdf</a>, <a href="/format/2301.01095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Database management system performance comparisons: A systematic  literature review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taipalus%2C+T">Toni Taipalus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Systems and Software, Volume 208, Article 111872,
  February 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>; Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item760">[760]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.06530" title="Abstract">arXiv:2301.06530</a> (replaced) [<a href="/pdf/2301.06530" title="Download PDF">pdf</a>, <a href="/format/2301.06530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KEWS: A KPIs-Based Evaluation Framework of Workload Simulation On  Microservice System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pengsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Q">Qingfeng Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shengjie Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item761">[761]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00659" title="Abstract">arXiv:2302.00659</a> (replaced) [<a href="/pdf/2302.00659" title="Download PDF">pdf</a>, <a href="/ps/2302.00659" title="Download PostScript">ps</a>, <a href="/format/2302.00659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geodiversity of Research: A Comparison of Geographical Topic Focus and  Author Location using SDG 2: Zero Hunger as a Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Purnell%2C+P+J">Philip James Purnell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
</div>
</dd>
<dt><a name="item762">[762]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04475" title="Abstract">arXiv:2302.04475</a> (replaced) [<a href="/pdf/2302.04475" title="Download PDF">pdf</a>, <a href="/format/2302.04475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Locally consistent decomposition of strings with applications to edit  distance sketching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+S">Sudatta Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Kouck%C3%BD%2C+M">Michal Kouck&#xfd;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item763">[763]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05447" title="Abstract">arXiv:2302.05447</a> (replaced) [<a href="/pdf/2302.05447" title="Download PDF">pdf</a>, <a href="/format/2302.05447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Ensemble Analysis of Fluid Flow in Porous Media across Simulation  Codes and Experiment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bauer%2C+R">Ruben Bauer</a>, 
<a href="/search/cs?searchtype=author&query=Ngo%2C+Q+Q">Quynh Quang Ngo</a>, 
<a href="/search/cs?searchtype=author&query=Reina%2C+G">Guido Reina</a>, 
<a href="/search/cs?searchtype=author&query=Frey%2C+S">Steffen Frey</a>, 
<a href="/search/cs?searchtype=author&query=Flemisch%2C+B">Bernd Flemisch</a>, 
<a href="/search/cs?searchtype=author&query=Hauser%2C+H">Helwig Hauser</a>, 
<a href="/search/cs?searchtype=author&query=Ertl%2C+T">Thomas Ertl</a>, 
<a href="/search/cs?searchtype=author&query=Sedlmair%2C+M">Michael Sedlmair</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a non-peer-reviewed pre-print version of the manuscript submitted to Transport in Porous Media. Please refer to the peer-reviewed and accepted version at <a href="https://link.springer.com/article/10.1007/s11242-023-02019-y">this https URL</a> when referencing this article
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transp Porous Med (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item764">[764]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05543" title="Abstract">arXiv:2302.05543</a> (replaced) [<a href="/pdf/2302.05543" title="Download PDF">pdf</a>, <a href="/format/2302.05543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adding Conditional Control to Text-to-Image Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lvmin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+A">Anyi Rao</a>, 
<a href="/search/cs?searchtype=author&query=Agrawala%2C+M">Maneesh Agrawala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Codes and Supplementary Material: <a href="https://github.com/lllyasviel/ControlNet">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Human-Computer Interaction (cs.HC); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item765">[765]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12931" title="Abstract">arXiv:2302.12931</a> (replaced) [<a href="/pdf/2302.12931" title="Download PDF">pdf</a>, <a href="/format/2302.12931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CATNIPS: Collision Avoidance Through Neural Implicit Probabilistic  Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Timothy Chen</a>, 
<a href="/search/cs?searchtype=author&query=Culbertson%2C+P">Preston Culbertson</a>, 
<a href="/search/cs?searchtype=author&query=Schwager%2C+M">Mac Schwager</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review in IEEE Transactions on Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item766">[766]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01002" title="Abstract">arXiv:2303.01002</a> (replaced) [<a href="/pdf/2303.01002" title="Download PDF">pdf</a>, <a href="/format/2303.01002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nearest-neighbour directed random hyperbolic graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kasyanov%2C+I+A">I.A. Kasyanov</a>, 
<a href="/search/physics?searchtype=author&query=van+der+Hoorn%2C+P">P. van der Hoorn</a>, 
<a href="/search/physics?searchtype=author&query=Krioukov%2C+D">D. Krioukov</a>, 
<a href="/search/physics?searchtype=author&query=Tamm%2C+M+V">M.V. Tamm</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 papers, 12 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Phys.Rev. E 108, 054310 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI); Probability (math.PR); Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item767">[767]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01486" title="Abstract">arXiv:2303.01486</a> (replaced) [<a href="/pdf/2303.01486" title="Download PDF">pdf</a>, <a href="/format/2303.01486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding plasticity in neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyle%2C+C">Clare Lyle</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zeyu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Nikishin%2C+E">Evgenii Nikishin</a>, 
<a href="/search/cs?searchtype=author&query=Pires%2C+B+A">Bernardo Avila Pires</a>, 
<a href="/search/cs?searchtype=author&query=Pascanu%2C+R">Razvan Pascanu</a>, 
<a href="/search/cs?searchtype=author&query=Dabney%2C+W">Will Dabney</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICML 2023 (oral presentation)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item768">[768]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03092" title="Abstract">arXiv:2303.03092</a> (replaced) [<a href="/pdf/2303.03092" title="Download PDF">pdf</a>, <a href="/format/2303.03092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Environment Invariant Linear Least Squares
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fan%2C+J">Jianqing Fan</a>, 
<a href="/search/math?searchtype=author&query=Fang%2C+C">Cong Fang</a>, 
<a href="/search/math?searchtype=author&query=Gu%2C+Y">Yihong Gu</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 62 pages,6 figures. Reorganize the main text part; Improve theoretical analysis with less technical conditions; Add numerical comparisons
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item769">[769]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03731" title="Abstract">arXiv:2303.03731</a> (replaced) [<a href="/pdf/2303.03731" title="Download PDF">pdf</a>, <a href="/ps/2303.03731" title="Download PostScript">ps</a>, <a href="/format/2303.03731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Completion of Matrices with Low Description Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Riegler%2C+E">Erwin Riegler</a>, 
<a href="/search/cs?searchtype=author&query=Koliander%2C+G">G&#xfc;nther Koliander</a>, 
<a href="/search/cs?searchtype=author&query=Stotz%2C+D">David Stotz</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%B6lcskei%2C+H">Helmut B&#xf6;lcskei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item770">[770]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03945" title="Abstract">arXiv:2303.03945</a> (replaced) [<a href="/pdf/2303.03945" title="Download PDF">pdf</a>, <a href="/ps/2303.03945" title="Download PostScript">ps</a>, <a href="/format/2303.03945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Computation of Redundancy Matrices for Moderately Redundant  Truss and Frame Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tkachuk%2C+A">Anton Tkachuk</a>, 
<a href="/search/cs?searchtype=author&query=Krake%2C+T">Tim Krake</a>, 
<a href="/search/cs?searchtype=author&query=Gade%2C+J">Jan Gade</a>, 
<a href="/search/cs?searchtype=author&query=von+Scheven%2C+M">Malte von Scheven</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item771">[771]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04190" title="Abstract">arXiv:2303.04190</a> (replaced) [<a href="/pdf/2303.04190" title="Download PDF">pdf</a>, <a href="/format/2303.04190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multivariate growth and cogrowth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Grigorchuk%2C+R">Rostislav Grigorchuk</a>, 
<a href="/search/math?searchtype=author&query=Quint%2C+J">Jean-Francois Quint</a>, 
<a href="/search/math?searchtype=author&query=Shaikh%2C+A">Asif Shaikh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 10 figures, the revised version include the correction of definition 4.1 and the replacement of an incorrect figure 6a
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Group Theory (math.GR)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item772">[772]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06226" title="Abstract">arXiv:2303.06226</a> (replaced) [<a href="/pdf/2303.06226" title="Download PDF">pdf</a>, <a href="/format/2303.06226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeRFlame: FLAME-based conditioning of NeRF for 3D face rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zaj%C4%85c%2C+W">Wojciech Zaj&#x105;c</a>, 
<a href="/search/cs?searchtype=author&query=Waczy%C5%84ska%2C+J">Joanna Waczy&#x144;ska</a>, 
<a href="/search/cs?searchtype=author&query=Borycki%2C+P">Piotr Borycki</a>, 
<a href="/search/cs?searchtype=author&query=Tabor%2C+J">Jacek Tabor</a>, 
<a href="/search/cs?searchtype=author&query=Zi%C4%99ba%2C+M">Maciej Zi&#x119;ba</a>, 
<a href="/search/cs?searchtype=author&query=Spurek%2C+P">Przemys&#x142;aw Spurek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item773">[773]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08112" title="Abstract">arXiv:2303.08112</a> (replaced) [<a href="/pdf/2303.08112" title="Download PDF">pdf</a>, <a href="/format/2303.08112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eliciting Latent Predictions from Transformers with the Tuned Lens
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belrose%2C+N">Nora Belrose</a>, 
<a href="/search/cs?searchtype=author&query=Furman%2C+Z">Zach Furman</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+L">Logan Smith</a>, 
<a href="/search/cs?searchtype=author&query=Halawi%2C+D">Danny Halawi</a>, 
<a href="/search/cs?searchtype=author&query=Ostrovsky%2C+I">Igor Ostrovsky</a>, 
<a href="/search/cs?searchtype=author&query=McKinney%2C+L">Lev McKinney</a>, 
<a href="/search/cs?searchtype=author&query=Biderman%2C+S">Stella Biderman</a>, 
<a href="/search/cs?searchtype=author&query=Steinhardt%2C+J">Jacob Steinhardt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item774">[774]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08730" title="Abstract">arXiv:2303.08730</a> (replaced) [<a href="/pdf/2303.08730" title="Download PDF">pdf</a>, <a href="/format/2303.08730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffusionAD: Norm-guided One-step Denoising Diffusion for Anomaly  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zuxuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu-Gang Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item775">[775]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10594" title="Abstract">arXiv:2303.10594</a> (replaced) [<a href="/pdf/2303.10594" title="Download PDF">pdf</a>, <a href="/format/2303.10594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaptGuard: Defending Against Universal Attacks for Model Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sheng%2C+L">Lijun Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jian Liang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ran He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zilei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+T">Tieniu Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item776">[776]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10622" title="Abstract">arXiv:2303.10622</a> (replaced) [<a href="/pdf/2303.10622" title="Download PDF">pdf</a>, <a href="/ps/2303.10622" title="Download PostScript">ps</a>, <a href="/format/2303.10622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A search for short-period Tausworthe generators over $\mathbb{F}_b$ with  application to Markov chain quasi-Monte Carlo
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Harase%2C+S">Shin Harase</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation (stat.CO)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item777">[777]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12153" title="Abstract">arXiv:2303.12153</a> (replaced) [<a href="/pdf/2303.12153" title="Download PDF">pdf</a>, <a href="/format/2303.12153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text2Motion: From Natural Language Instructions to Feasible Plans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kevin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Agia%2C+C">Christopher Agia</a>, 
<a href="/search/cs?searchtype=author&query=Migimatsu%2C+T">Toki Migimatsu</a>, 
<a href="/search/cs?searchtype=author&query=Pavone%2C+M">Marco Pavone</a>, 
<a href="/search/cs?searchtype=author&query=Bohg%2C+J">Jeannette Bohg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Autonomous Robots, Special Issue: Large Language Models in Robotics 2023. Project page: <a href="https://sites.google.com/stanford.edu/text2motion.">this https URL</a> First two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item778">[778]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13997" title="Abstract">arXiv:2303.13997</a> (replaced) [<a href="/pdf/2303.13997" title="Download PDF">pdf</a>, <a href="/format/2303.13997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PowerPruning: Selecting Weights and Activations for Power-Efficient  Neural Network Acceleration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Petri%2C+R">Richard Petri</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G+L">Grace Li Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiran Chen</a>, 
<a href="/search/cs?searchtype=author&query=Schlichtmann%2C+U">Ulf Schlichtmann</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bing Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by Design Automation Conference (DAC) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item779">[779]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15445" title="Abstract">arXiv:2303.15445</a> (replaced) [<a href="/pdf/2303.15445" title="Download PDF">pdf</a>, <a href="/format/2303.15445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IRFL: Image Recognition of Figurative Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yosef%2C+R">Ron Yosef</a>, 
<a href="/search/cs?searchtype=author&query=Bitton%2C+Y">Yonatan Bitton</a>, 
<a href="/search/cs?searchtype=author&query=Shahaf%2C+D">Dafna Shahaf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item780">[780]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16195" title="Abstract">arXiv:2303.16195</a> (replaced) [<a href="/pdf/2303.16195" title="Download PDF">pdf</a>, <a href="/format/2303.16195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When to be critical? Performance and evolvability in different regimes  of neural Ising agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khajehabdollahi%2C+S">Sina Khajehabdollahi</a>, 
<a href="/search/cs?searchtype=author&query=Prosi%2C+J">Jan Prosi</a>, 
<a href="/search/cs?searchtype=author&query=Giannakakis%2C+E">Emmanouil Giannakakis</a>, 
<a href="/search/cs?searchtype=author&query=Martius%2C+G">Georg Martius</a>, 
<a href="/search/cs?searchtype=author&query=Levina%2C+A">Anna Levina</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2103.12184">arXiv:2103.12184</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Artificial Life (2022) 28 (4): 458-478
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item781">[781]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16585" title="Abstract">arXiv:2303.16585</a> (replaced) [<a href="/pdf/2303.16585" title="Download PDF">pdf</a>, <a href="/format/2303.16585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Deep Hedging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Cherrat%2C+E+A">El Amine Cherrat</a>, 
<a href="/search/quant-ph?searchtype=author&query=Raj%2C+S">Snehal Raj</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kerenidis%2C+I">Iordanis Kerenidis</a>, 
<a href="/search/quant-ph?searchtype=author&query=Shekhar%2C+A">Abhishek Shekhar</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wood%2C+B">Ben Wood</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dee%2C+J">Jon Dee</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chakrabarti%2C+S">Shouvanik Chakrabarti</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+R">Richard Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Herman%2C+D">Dylan Herman</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hu%2C+S">Shaohan Hu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Minssen%2C+P">Pierre Minssen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Shaydulin%2C+R">Ruslan Shaydulin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sun%2C+Y">Yue Sun</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yalovetzky%2C+R">Romina Yalovetzky</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pistoia%2C+M">Marco Pistoia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); Computational Finance (q-fin.CP)

</div>
</div>
</dd>
<dt><a name="item782">[782]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00553" title="Abstract">arXiv:2304.00553</a> (replaced) [<a href="/pdf/2304.00553" title="Download PDF">pdf</a>, <a href="/format/2304.00553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Isolated Islands to Pangea: Unifying Semantic Space for Human  Action Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong-Lu Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaoqian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinpeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zehao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Y">Yiming Dou</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Y">Yikun Ji</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yixing Li</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+J">Jingru Tan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xudong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Webpage: <a href="https://mvig-rhos.com/pangea">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item783">[783]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01664" title="Abstract">arXiv:2304.01664</a> (replaced) [<a href="/pdf/2304.01664" title="Download PDF">pdf</a>, <a href="/format/2304.01664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Embedding-based Approach to Inconsistency-tolerant Reasoning with  Inconsistent Ontologies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Keyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Site Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaye Li</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+G">Guilin Qi</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Q">Qiu Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages,1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item784">[784]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02833" title="Abstract">arXiv:2304.02833</a> (replaced) [<a href="/pdf/2304.02833" title="Download PDF">pdf</a>, <a href="/format/2304.02833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DoUnseen: Tuning-Free Class-Adaptive Object Detection of Unseen Objects  for Robotic Grasping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gouda%2C+A">Anas Gouda</a>, 
<a href="/search/cs?searchtype=author&query=Roidl%2C+M">Moritz Roidl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> presented at RSS 2023 Workshop on Perception and Manipulation Challenges for Warehouse Automation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item785">[785]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02858" title="Abstract">arXiv:2304.02858</a> (replaced) [<a href="/pdf/2304.02858" title="Download PDF">pdf</a>, <a href="/format/2304.02858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A review of ensemble learning and data augmentation models for class  imbalanced problems: combination, implementation and evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+A+A">Azal Ahmad Khan</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhari%2C+O">Omkar Chaudhari</a>, 
<a href="/search/cs?searchtype=author&query=Chandra%2C+R">Rohitash Chandra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item786">[786]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02970" title="Abstract">arXiv:2304.02970</a> (replaced) [<a href="/pdf/2304.02970" title="Download PDF">pdf</a>, <a href="/format/2304.02970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Closer Look at Audio-Visual Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuanhong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fengbei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Carneiro%2C+G">Gustavo Carneiro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item787">[787]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04258" title="Abstract">arXiv:2304.04258</a> (replaced) [<a href="/pdf/2304.04258" title="Download PDF">pdf</a>, <a href="/ps/2304.04258" title="Download PostScript">ps</a>, <a href="/format/2304.04258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Note on &quot;Efficient Task-Specific Data Valuation for Nearest Neighbor  Algorithms&quot;
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wang%2C+J+T">Jiachen T. Wang</a>, 
<a href="/search/stat?searchtype=author&query=Jia%2C+R">Ruoxi Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Note
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item788">[788]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04667" title="Abstract">arXiv:2304.04667</a> (replaced) [<a href="/pdf/2304.04667" title="Download PDF">pdf</a>, <a href="/format/2304.04667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> (Almost) Ruling Out SETH Lower Bounds for All-Pairs Max-Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Trabelsi%2C+O">Ohad Trabelsi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item789">[789]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04941" title="Abstract">arXiv:2304.04941</a> (replaced) [<a href="/pdf/2304.04941" title="Download PDF">pdf</a>, <a href="/format/2304.04941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stress-hybrid virtual element method on quadrilateral meshes for  compressible and nearly-incompressible linear elasticity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+A">Alvin Chen</a>, 
<a href="/search/math?searchtype=author&query=Sukumar%2C+N">N. Sukumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 37 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item790">[790]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04947" title="Abstract">arXiv:2304.04947</a> (replaced) [<a href="/pdf/2304.04947" title="Download PDF">pdf</a>, <a href="/format/2304.04947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditional Adapters: Parameter-efficient Transfer Learning with Fast  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+T">Tao Lei</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Junwen Bai</a>, 
<a href="/search/cs?searchtype=author&query=Brahma%2C+S">Siddhartha Brahma</a>, 
<a href="/search/cs?searchtype=author&query=Ainslie%2C+J">Joshua Ainslie</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kenton Lee</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yanqi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+N">Nan Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+V+Y">Vincent Y. Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuexin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+M">Ming-Wei Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS camera ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item791">[791]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05646" title="Abstract">arXiv:2304.05646</a> (replaced) [<a href="/pdf/2304.05646" title="Download PDF">pdf</a>, <a href="/format/2304.05646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breaking Modality Disparity: Harmonized Representation for Infrared and  Visible Image Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhiying Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zengxi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Risheng Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item792">[792]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07143" title="Abstract">arXiv:2304.07143</a> (replaced) [<a href="/pdf/2304.07143" title="Download PDF">pdf</a>, <a href="/format/2304.07143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Car-Following Models: A Multidisciplinary Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+T">Tianya Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+P+J">Peter J. Jin</a>, 
<a href="/search/eess?searchtype=author&query=Bayen%2C+A">Alexandre Bayen</a>, 
<a href="/search/eess?searchtype=author&query=D.%2C+P">Ph.D.</a>, 
<a href="/search/eess?searchtype=author&query=Piccoli%2C+B">Benedetto Piccoli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item793">[793]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07403" title="Abstract">arXiv:2304.07403</a> (replaced) [<a href="/pdf/2304.07403" title="Download PDF">pdf</a>, <a href="/ps/2304.07403" title="Download PostScript">ps</a>, <a href="/format/2304.07403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fully Dynamic Shortest Path Reporting Against an Adaptive Adversary
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alokhina%2C+A">Anastasiia Alokhina</a>, 
<a href="/search/cs?searchtype=author&query=van+den+Brand%2C+J">Jan van den Brand</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item794">[794]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08138" title="Abstract">arXiv:2304.08138</a> (replaced) [<a href="/pdf/2304.08138" title="Download PDF">pdf</a>, <a href="/format/2304.08138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Typos-aware Bottlenecked Pre-Training for Robust Dense Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+S">Shengyao Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+L">Linjun Shou</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+J">Jian Pei</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+M">Ming Gong</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Houxing Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zuccon%2C+G">Guido Zuccon</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Daxin Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, accepted at SIGIR-AP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item795">[795]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09444" title="Abstract">arXiv:2304.09444</a> (replaced) [<a href="/pdf/2304.09444" title="Download PDF">pdf</a>, <a href="/ps/2304.09444" title="Download PostScript">ps</a>, <a href="/format/2304.09444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rank-Based Learning and Local Model Based Evolutionary Algorithm for  High-Dimensional Expensive Multi-Objective Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guodong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+J+J">Jiu Jimmy Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+X">Xiaoming Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongzheng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item796">[796]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10001" title="Abstract">arXiv:2304.10001</a> (replaced) [<a href="/pdf/2304.10001" title="Download PDF">pdf</a>, <a href="/format/2304.10001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly Supervised Detection of Baby Cry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+W">Weijun Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Q">Qi Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingfeng Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item797">[797]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14061" title="Abstract">arXiv:2304.14061</a> (replaced) [<a href="/pdf/2304.14061" title="Download PDF">pdf</a>, <a href="/ps/2304.14061" title="Download PostScript">ps</a>, <a href="/format/2304.14061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fourier-Gegenbauer Pseudospectral Method for Solving Time-Dependent  One-Dimensional Fractional Partial Differential Equations with Variable  Coefficients and Periodic Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Elgindy%2C+K+T">Kareem T. Elgindy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item798">[798]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02800" title="Abstract">arXiv:2305.02800</a> (replaced) [<a href="/pdf/2305.02800" title="Download PDF">pdf</a>, <a href="/ps/2305.02800" title="Download PostScript">ps</a>, <a href="/format/2305.02800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Parameterized Complexity of the Perfect Phylogeny Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Vlas%2C+J+M">Jorke M. de Vlas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
</div>
</dd>
<dt><a name="item799">[799]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03310" title="Abstract">arXiv:2305.03310</a> (replaced) [<a href="/pdf/2305.03310" title="Download PDF">pdf</a>, <a href="/format/2305.03310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Design of Sampler and Compressor for Timely Status Updates:  Age-Distortion Tradeoff
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenyi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item800">[800]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03428" title="Abstract">arXiv:2305.03428</a> (replaced) [<a href="/pdf/2305.03428" title="Download PDF">pdf</a>, <a href="/format/2305.03428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supporting single responsibility through automated extract method  refactoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ardalani%2C+A">Alireza Ardalani</a>, 
<a href="/search/cs?searchtype=author&query=Parsa%2C+S">Saeed Parsa</a>, 
<a href="/search/cs?searchtype=author&query=Zakeri-Nasrabadi%2C+M">Morteza Zakeri-Nasrabadi</a>, 
<a href="/search/cs?searchtype=author&query=Chatzigeorgiou%2C+A">Alexander Chatzigeorgiou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item801">[801]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06026" title="Abstract">arXiv:2305.06026</a> (replaced) [<a href="/pdf/2305.06026" title="Download PDF">pdf</a>, <a href="/ps/2305.06026" title="Download PostScript">ps</a>, <a href="/format/2305.06026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty in GNN Learning Evaluations: The Importance of a Consistent  Benchmark for Community Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leeney%2C+W">William Leeney</a>, 
<a href="/search/cs?searchtype=author&query=McConville%2C+R">Ryan McConville</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Twelfth International Conference on Complex Networks &amp; Their Applications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item802">[802]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06151" title="Abstract">arXiv:2305.06151</a> (replaced) [<a href="/pdf/2305.06151" title="Download PDF">pdf</a>, <a href="/format/2305.06151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speeding up Monte Carlo Integration: Control Neighbors for Optimal  Convergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Leluc%2C+R">R&#xe9;mi Leluc</a>, 
<a href="/search/math?searchtype=author&query=Portier%2C+F">Fran&#xe7;ois Portier</a>, 
<a href="/search/math?searchtype=author&query=Segers%2C+J">Johan Segers</a>, 
<a href="/search/math?searchtype=author&query=Zhuman%2C+A">Aigerim Zhuman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Statistics Theory (math.ST); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item803">[803]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06226" title="Abstract">arXiv:2305.06226</a> (replaced) [<a href="/pdf/2305.06226" title="Download PDF">pdf</a>, <a href="/format/2305.06226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RiverBench: an Open RDF Streaming Benchmark Suite
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sowinski%2C+P">Piotr Sowinski</a>, 
<a href="/search/cs?searchtype=author&query=Ganzha%2C+M">Maria Ganzha</a>, 
<a href="/search/cs?searchtype=author&query=Paprzycki%2C+M">Marcin Paprzycki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> RiverBench is available online here: <a href="https://w3id.org/riverbench">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item804">[804]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06898" title="Abstract">arXiv:2305.06898</a> (replaced) [<a href="/pdf/2305.06898" title="Download PDF">pdf</a>, <a href="/format/2305.06898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying vital nodes through augmented random walks on higher-order  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yujie Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yiming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiao-Long Ren</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%BC%2C+L">Linyuan L&#xfc;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item805">[805]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07097" title="Abstract">arXiv:2305.07097</a> (replaced) [<a href="/pdf/2305.07097" title="Download PDF">pdf</a>, <a href="/format/2305.07097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Smell Detection and Recommendation in Natural Language  Requirements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Veizaga%2C+A">Alvaro Veizaga</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+S+Y">Seung Yeob Shin</a>, 
<a href="/search/cs?searchtype=author&query=Briand%2C+L+C">Lionel C. Briand</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item806">[806]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07637" title="Abstract">arXiv:2305.07637</a> (replaced) [<a href="/pdf/2305.07637" title="Download PDF">pdf</a>, <a href="/format/2305.07637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text2Cohort: Facilitating Intuitive Access to Biomedical Data with  Natural Language Cohort Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+P">Pranav Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Kanhere%2C+A">Adway Kanhere</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+P+H">Paul H. Yi</a>, 
<a href="/search/cs?searchtype=author&query=Parekh%2C+V+S">Vishwa S. Parekh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item807">[807]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07721" title="Abstract">arXiv:2305.07721</a> (replaced) [<a href="/pdf/2305.07721" title="Download PDF">pdf</a>, <a href="/format/2305.07721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing Optimal Behavioral Experiments Using Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valentin%2C+S">Simon Valentin</a>, 
<a href="/search/cs?searchtype=author&query=Kleinegesse%2C+S">Steven Kleinegesse</a>, 
<a href="/search/cs?searchtype=author&query=Bramley%2C+N+R">Neil R. Bramley</a>, 
<a href="/search/cs?searchtype=author&query=Seri%C3%A8s%2C+P">Peggy Seri&#xe8;s</a>, 
<a href="/search/cs?searchtype=author&query=Gutmann%2C+M+U">Michael U. Gutmann</a>, 
<a href="/search/cs?searchtype=author&query=Lucas%2C+C+G">Christopher G. Lucas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in eLife
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item808">[808]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07940" title="Abstract">arXiv:2305.07940</a> (replaced) [<a href="/pdf/2305.07940" title="Download PDF">pdf</a>, <a href="/format/2305.07940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MHDnet: Physics-preserving learning for solving magnetohydrodynamics  problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Guan%2C+X">Xiaofei Guan</a>, 
<a href="/search/math?searchtype=author&query=Hu%2C+B">Boya Hu</a>, 
<a href="/search/math?searchtype=author&query=Mao%2C+S">Shipeng Mao</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+X">Xintong Wang</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+Z">Zihao Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item809">[809]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08051" title="Abstract">arXiv:2305.08051</a> (replaced) [<a href="/pdf/2305.08051" title="Download PDF">pdf</a>, <a href="/format/2305.08051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prox-DBRO-VR: A Unified Analysis on Decentralized Byzantine-Resilient  Composite Stochastic Optimization with Variance Reduction and Non-Asymptotic  Convergence Rates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hu%2C+J">Jinhui Hu</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+G">Guo Chen</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+H">Huaqing Li</a>, 
<a href="/search/math?searchtype=author&query=Huang%2C+T">Tingwen Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item810">[810]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08946" title="Abstract">arXiv:2305.08946</a> (replaced) [<a href="/pdf/2305.08946" title="Download PDF">pdf</a>, <a href="/format/2305.08946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Matching by Bare Homography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bellavia%2C+F">Fabio Bellavia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> major revision update - added results on EVD and WxBS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item811">[811]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09620" title="Abstract">arXiv:2305.09620</a> (replaced) [<a href="/pdf/2305.09620" title="Download PDF">pdf</a>, <a href="/format/2305.09620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-Augmented Surveys: Leveraging Large Language Models and Surveys for  Opinion Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Junsol Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B">Byungkyu Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item812">[812]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09987" title="Abstract">arXiv:2305.09987</a> (replaced) [<a href="/pdf/2305.09987" title="Download PDF">pdf</a>, <a href="/format/2305.09987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convex Hulls, Triangulations, and Voronoi Diagrams of Planar Point Sets  on the Congested Clique
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jansson%2C+J">Jesper Jansson</a>, 
<a href="/search/cs?searchtype=author&query=Levcopoulos%2C+C">Christos Levcopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Lingas%2C+A">Andrzej Lingas</a>, 
<a href="/search/cs?searchtype=author&query=Polishchuk%2C+V">Valentin Polishchuk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item813">[813]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11461" title="Abstract">arXiv:2305.11461</a> (replaced) [<a href="/pdf/2305.11461" title="Download PDF">pdf</a>, <a href="/format/2305.11461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SelfzCoT: a Self-Prompt Zero-shot CoT from Semantic-level to Code-level  for a Better Utilization of LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+I">Ioktong Lei</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhidong Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item814">[814]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11650" title="Abstract">arXiv:2305.11650</a> (replaced) [<a href="/pdf/2305.11650" title="Download PDF">pdf</a>, <a href="/format/2305.11650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Moment Matching Denoising Gibbs Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhang%2C+M">Mingtian Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Hawkins-Hooker%2C+A">Alex Hawkins-Hooker</a>, 
<a href="/search/stat?searchtype=author&query=Paige%2C+B">Brooks Paige</a>, 
<a href="/search/stat?searchtype=author&query=Barber%2C+D">David Barber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item815">[815]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11853" title="Abstract">arXiv:2305.11853</a> (replaced) [<a href="/pdf/2305.11853" title="Download PDF">pdf</a>, <a href="/format/2305.11853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain,  and Cross-domain Settings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+S">Shuaichen Chang</a>, 
<a href="/search/cs?searchtype=author&query=Fosler-Lussier%2C+E">Eric Fosler-Lussier</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023 Table Representation Learning Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item816">[816]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13114" title="Abstract">arXiv:2305.13114</a> (replaced) [<a href="/pdf/2305.13114" title="Download PDF">pdf</a>, <a href="/format/2305.13114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring User Perspectives on ChatGPT: Applications, Perceptions, and  Implications for AI-Integrated Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mogavi%2C+R+H">Reza Hadi Mogavi</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+C">Chao Deng</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J+J">Justin Juho Kim</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pengyuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+Y+D">Young D. Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Metwally%2C+A+H+S">Ahmed Hosny Saleh Metwally</a>, 
<a href="/search/cs?searchtype=author&query=Tlili%2C+A">Ahmed Tlili</a>, 
<a href="/search/cs?searchtype=author&query=Bassanelli%2C+S">Simone Bassanelli</a>, 
<a href="/search/cs?searchtype=author&query=Bucchiarone%2C+A">Antonio Bucchiarone</a>, 
<a href="/search/cs?searchtype=author&query=Gujar%2C+S">Sujit Gujar</a>, 
<a href="/search/cs?searchtype=author&query=Nacke%2C+L+E">Lennart E. Nacke</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+P">Pan Hui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the authors' preprint version of the paper accepted by the Journal of Computers in Human Behavior: Artificial Humans (doi: <a href="https://doi.org/10.1016/j.chbah.2023.100027">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item817">[817]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13547" title="Abstract">arXiv:2305.13547</a> (replaced) [<a href="/pdf/2305.13547" title="Download PDF">pdf</a>, <a href="/format/2305.13547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Evolution Learning for Mixup: Enhance Data Augmentation on Few-Shot  Text Classification Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Haoqi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Q">Qihuang Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Liang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhiliang Tian</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+X">Xin Niu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item818">[818]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14067" title="Abstract">arXiv:2305.14067</a> (replaced) [<a href="/pdf/2305.14067" title="Download PDF">pdf</a>, <a href="/format/2305.14067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DIVA: A Dirichlet Process Mixtures Based Incremental Deep Clustering  Algorithm via Variational Auto-Encoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bing%2C+Z">Zhenshan Bing</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Y">Yuan Meng</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+Y">Yuqi Yun</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hang Su</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+X">Xiaojie Su</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Knoll%2C+A">Alois Knoll</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> static datasets comparision updated
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item819">[819]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14930" title="Abstract">arXiv:2305.14930</a> (replaced) [<a href="/pdf/2305.14930" title="Download PDF">pdf</a>, <a href="/format/2305.14930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Context Impersonation Reveals Large Language Models&#x27; Strengths and  Biases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salewski%2C+L">Leonard Salewski</a>, 
<a href="/search/cs?searchtype=author&query=Alaniz%2C+S">Stephan Alaniz</a>, 
<a href="/search/cs?searchtype=author&query=Rio-Torto%2C+I">Isabel Rio-Torto</a>, 
<a href="/search/cs?searchtype=author&query=Schulz%2C+E">Eric Schulz</a>, 
<a href="/search/cs?searchtype=author&query=Akata%2C+Z">Zeynep Akata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in NeurIPS 2023 (Spotlight)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item820">[820]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15363" title="Abstract">arXiv:2305.15363</a> (replaced) [<a href="/pdf/2305.15363" title="Download PDF">pdf</a>, <a href="/format/2305.15363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inverse Preference Learning: Preference-based RL without a Reward  Function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hejna%2C+J">Joey Hejna</a>, 
<a href="/search/cs?searchtype=author&query=Sadigh%2C+D">Dorsa Sadigh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated for NeurIPS 2023 Acceptance
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item821">[821]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15617" title="Abstract">arXiv:2305.15617</a> (replaced) [<a href="/pdf/2305.15617" title="Download PDF">pdf</a>, <a href="/format/2305.15617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ISLE: An Intelligent Streaming Framework for High-Throughput AI  Inference in Medical Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kulkarni%2C+P">Pranav Kulkarni</a>, 
<a href="/search/eess?searchtype=author&query=Garin%2C+S">Sean Garin</a>, 
<a href="/search/eess?searchtype=author&query=Kanhere%2C+A">Adway Kanhere</a>, 
<a href="/search/eess?searchtype=author&query=Siegel%2C+E">Eliot Siegel</a>, 
<a href="/search/eess?searchtype=author&query=Yi%2C+P+H">Paul H. Yi</a>, 
<a href="/search/eess?searchtype=author&query=Parekh%2C+V+S">Vishwa S. Parekh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item822">[822]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16491" title="Abstract">arXiv:2305.16491</a> (replaced) [<a href="/pdf/2305.16491" title="Download PDF">pdf</a>, <a href="/format/2305.16491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAMoSSA: Multivariate Singular Spectrum Analysis with Stochastic  Autoregressive Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alomar%2C+A">Abdullah Alomar</a>, 
<a href="/search/cs?searchtype=author&query=Dahleh%2C+M">Munther Dahleh</a>, 
<a href="/search/cs?searchtype=author&query=Mann%2C+S">Sean Mann</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+D">Devavrat Shah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item823">[823]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17005" title="Abstract">arXiv:2305.17005</a> (replaced) [<a href="/pdf/2305.17005" title="Download PDF">pdf</a>, <a href="/format/2305.17005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aggregating Capacity in FL through Successive Layer Training for  Computationally-Constrained Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pfeiffer%2C+K">Kilian Pfeiffer</a>, 
<a href="/search/cs?searchtype=author&query=Khalili%2C+R">Ramin Khalili</a>, 
<a href="/search/cs?searchtype=author&query=Henkel%2C+J">J&#xf6;rg Henkel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at NeurIPS'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item824">[824]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18434" title="Abstract">arXiv:2305.18434</a> (replaced) [<a href="/pdf/2305.18434" title="Download PDF">pdf</a>, <a href="/ps/2305.18434" title="Download PostScript">ps</a>, <a href="/format/2305.18434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallel Coordinates for Discovery of Interpretable Machine Learning  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hayes%2C+D">Dustin Hayes</a>, 
<a href="/search/cs?searchtype=author&query=Kovalerchuk%2C+B">Boris Kovalerchuk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 30 figures, 7 tables. arXiv admin note: substantial text overlap with <a href="/abs/2106.07474">arXiv:2106.07474</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item825">[825]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19569" title="Abstract">arXiv:2305.19569</a> (replaced) [<a href="/pdf/2305.19569" title="Download PDF">pdf</a>, <a href="/ps/2305.19569" title="Download PostScript">ps</a>, <a href="/format/2305.19569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain knowledge-informed Synthetic fault sample generation with Health  Data Map for cross-domain Planetary Gearbox Fault Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ha%2C+J+M">Jong Moon Ha</a>, 
<a href="/search/cs?searchtype=author&query=Fink%2C+O">Olga Fink</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review / added arXiv identifier / Updated to revised version
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Published in Mechanical Systems and Signal Processing Volume 202,
  1 November 2023, 110680
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item826">[826]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19575" title="Abstract">arXiv:2305.19575</a> (replaced) [<a href="/pdf/2305.19575" title="Download PDF">pdf</a>, <a href="/format/2305.19575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Linear Convergence of Policy Gradient under Hadamard  Parameterization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+J">Jiacai Liu</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+J">Jinchi Chen</a>, 
<a href="/search/math?searchtype=author&query=Wei%2C+K">Ke Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item827">[827]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19599" title="Abstract">arXiv:2305.19599</a> (replaced) [<a href="/pdf/2305.19599" title="Download PDF">pdf</a>, <a href="/format/2305.19599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RealignDiff: Boosting Text-to-Image Diffusion Model with Coarse-to-fine  Semantic Re-alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+G">Guian Fang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zutao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jianhua Han</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+G">Guansong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+S">Shengcai Liao</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaodan Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item828">[828]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00349" title="Abstract">arXiv:2306.00349</a> (replaced) [<a href="/pdf/2306.00349" title="Download PDF">pdf</a>, <a href="/format/2306.00349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CALICO: Self-Supervised Camera-LiDAR Contrastive Pre-training for BEV  Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiachen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Haizhong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingzhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Prakash%2C+A">Atul Prakash</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Z+M">Z. Morley Mao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chaowei Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item829">[829]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00577" title="Abstract">arXiv:2306.00577</a> (replaced) [<a href="/pdf/2306.00577" title="Download PDF">pdf</a>, <a href="/format/2306.00577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TorchRL: A data-driven decision-making library for PyTorch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bou%2C+A">Albert Bou</a>, 
<a href="/search/cs?searchtype=author&query=Bettini%2C+M">Matteo Bettini</a>, 
<a href="/search/cs?searchtype=author&query=Dittert%2C+S">Sebastian Dittert</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vikash Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Sodhani%2C+S">Shagun Sodhani</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaomeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=De+Fabritiis%2C+G">Gianni De Fabritiis</a>, 
<a href="/search/cs?searchtype=author&query=Moens%2C+V">Vincent Moens</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item830">[830]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01460" title="Abstract">arXiv:2306.01460</a> (replaced) [<a href="/pdf/2306.01460" title="Download PDF">pdf</a>, <a href="/format/2306.01460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReLU to the Rescue: Improve Your On-Policy Actor-Critic with Positive  Advantages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jesson%2C+A">Andrew Jesson</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chris Lu</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+G">Gunshi Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Filos%2C+A">Angelos Filos</a>, 
<a href="/search/cs?searchtype=author&query=Foerster%2C+J+N">Jakob Nicolaus Foerster</a>, 
<a href="/search/cs?searchtype=author&query=Gal%2C+Y">Yarin Gal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item831">[831]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03081" title="Abstract">arXiv:2306.03081</a> (replaced) [<a href="/pdf/2306.03081" title="Download PDF">pdf</a>, <a href="/format/2306.03081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sequential Monte Carlo Steering of Large Language Models using  Probabilistic Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lew%2C+A+K">Alexander K. Lew</a>, 
<a href="/search/cs?searchtype=author&query=Zhi-Xuan%2C+T">Tan Zhi-Xuan</a>, 
<a href="/search/cs?searchtype=author&query=Grand%2C+G">Gabriel Grand</a>, 
<a href="/search/cs?searchtype=author&query=Mansinghka%2C+V+K">Vikash K. Mansinghka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Minor typo fixes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Programming Languages (cs.PL); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item832">[832]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05526" title="Abstract">arXiv:2306.05526</a> (replaced) [<a href="/pdf/2306.05526" title="Download PDF">pdf</a>, <a href="/format/2306.05526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Fine-grained View-Invariant Representations from Unpaired  Ego-Exo Videos via Temporal Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+Z">Zihui Xue</a>, 
<a href="/search/cs?searchtype=author&query=Grauman%2C+K">Kristen Grauman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023, Project website: <a href="https://vision.cs.utexas.edu/projects/AlignEgoExo/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item833">[833]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05734" title="Abstract">arXiv:2306.05734</a> (replaced) [<a href="/pdf/2306.05734" title="Download PDF">pdf</a>, <a href="/format/2306.05734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DP-HyPO: An Adaptive Private Hyperparameter Optimization Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hua Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Sheng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huanyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+W+J">Weijie J. Su</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+M">Milan Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item834">[834]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06517" title="Abstract">arXiv:2306.06517</a> (replaced) [<a href="/pdf/2306.06517" title="Download PDF">pdf</a>, <a href="/format/2306.06517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Multi-Dimensional Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V">Vu-Linh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=de+Campos%2C+C">Cassio de Campos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for the 39th Conference on Uncertainty in Artificial Intelligence (UAI 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item835">[835]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07294" title="Abstract">arXiv:2306.07294</a> (replaced) [<a href="/pdf/2306.07294" title="Download PDF">pdf</a>, <a href="/format/2306.07294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational and Storage Efficient Quadratic Neurons for Deep Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chuangtao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G+L">Grace Li Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xunzhao Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+C">Cheng Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Schlichtmann%2C+U">Ulf Schlichtmann</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bing Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Design Automation and Test in Europe (DATE) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item836">[836]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09478" title="Abstract">arXiv:2306.09478</a> (replaced) [<a href="/pdf/2306.09478" title="Download PDF">pdf</a>, <a href="/format/2306.09478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding and Mitigating Extrapolation Failures in Physics-Informed  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fesser%2C+L">Lukas Fesser</a>, 
<a href="/search/cs?searchtype=author&query=D%27Amico-Wong%2C+L">Luca D&#x27;Amico-Wong</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+R">Richard Qiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item837">[837]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12663" title="Abstract">arXiv:2306.12663</a> (replaced) [<a href="/pdf/2306.12663" title="Download PDF">pdf</a>, <a href="/format/2306.12663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High order entropy stable discontinuous Galerkin spectral element  methods through subcell limiting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lin%2C+Y">Yimin Lin</a>, 
<a href="/search/math?searchtype=author&query=Chan%2C+J">Jesse Chan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item838">[838]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02790" title="Abstract">arXiv:2307.02790</a> (replaced) [<a href="/pdf/2307.02790" title="Download PDF">pdf</a>, <a href="/format/2307.02790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sensor Allocation and Online-Learning-based Path Planning for Maritime  Situational Awareness Enhancement: A Multi-Agent Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+B+L">Bach Long Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Doan%2C+A">Anh-Dzung Doan</a>, 
<a href="/search/cs?searchtype=author&query=Chin%2C+T">Tat-Jun Chin</a>, 
<a href="/search/cs?searchtype=author&query=Guettier%2C+C">Christophe Guettier</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Surabhi Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Parra%2C+E">Estelle Parra</a>, 
<a href="/search/cs?searchtype=author&query=Reid%2C+I">Ian Reid</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+M">Markus Wagner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
</div>
</dd>
<dt><a name="item839">[839]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03017" title="Abstract">arXiv:2307.03017</a> (replaced) [<a href="/pdf/2307.03017" title="Download PDF">pdf</a>, <a href="/format/2307.03017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RealLiFe: Real-Time Light Field Reconstruction via Hierarchical Sparse  Gradient Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yijie Deng</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Lei Han</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+T">Tianpeng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinzhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+L">Lu Fang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE TPAMI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item840">[840]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04819" title="Abstract">arXiv:2307.04819</a> (replaced) [<a href="/pdf/2307.04819" title="Download PDF">pdf</a>, <a href="/ps/2307.04819" title="Download PostScript">ps</a>, <a href="/format/2307.04819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Kalman Filter based Low Complexity Throughput Prediction Algorithm for  5G Cellular Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biswas%2C+M">Mayukh Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+A">Ayan Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Palit%2C+B">Basabdatta Palit</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item841">[841]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06255" title="Abstract">arXiv:2307.06255</a> (replaced) [<a href="/pdf/2307.06255" title="Download PDF">pdf</a>, <a href="/format/2307.06255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine learning and Topological data analysis identify unique features  of human papillae in 3D scans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Andreeva%2C+R">Rayna Andreeva</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+A">Anwesha Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+R">Rik Sarkar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Algebraic Topology (math.AT); Differential Geometry (math.DG)

</div>
</div>
</dd>
<dt><a name="item842">[842]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06431" title="Abstract">arXiv:2307.06431</a> (replaced) [<a href="/pdf/2307.06431" title="Download PDF">pdf</a>, <a href="/format/2307.06431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy Discrepancies: A Score-Independent Loss for Energy-Based Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Schr%C3%B6der%2C+T">Tobias Schr&#xf6;der</a>, 
<a href="/search/stat?searchtype=author&query=Ou%2C+Z">Zijing Ou</a>, 
<a href="/search/stat?searchtype=author&query=Lim%2C+J+N">Jen Ning Lim</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+Y">Yingzhen Li</a>, 
<a href="/search/stat?searchtype=author&query=Vollmer%2C+S+J">Sebastian J. Vollmer</a>, 
<a href="/search/stat?searchtype=author&query=Duncan%2C+A+B">Andrew B. Duncan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera Ready version for the 37th Conference on Neural Information Processing Systems (NeurIPS 2023). Changes in this revision: Appendix A1: Corrected proof of Theorem 1. Appendix D3: Added definition and numerical experiments for energy discrepancy on binary discrete spaces. Minor changes in the main text and correction of typos. Added new references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item843">[843]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07187" title="Abstract">arXiv:2307.07187</a> (replaced) [<a href="/pdf/2307.07187" title="Download PDF">pdf</a>, <a href="/format/2307.07187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Erasing, Transforming, and Noising Defense Network for Occluded Person  Re-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+N">Neng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liyan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shuanglin Yan</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jinhui Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item844">[844]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09608" title="Abstract">arXiv:2307.09608</a> (replaced) [<a href="/pdf/2307.09608" title="Download PDF">pdf</a>, <a href="/ps/2307.09608" title="Download PostScript">ps</a>, <a href="/format/2307.09608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Group Testing in Arbitrary Hypergraphs and Related Combinatorial  Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Bonis%2C+A">Annalisa De Bonis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item845">[845]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09807" title="Abstract">arXiv:2307.09807</a> (replaced) [<a href="/pdf/2307.09807" title="Download PDF">pdf</a>, <a href="/ps/2307.09807" title="Download PostScript">ps</a>, <a href="/format/2307.09807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Low-Complexity Beamforming Design for Beyond-Diagonal RIS aided  Multi-User Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+T">Tianyu Fang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yijie Mao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, journal paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item846">[846]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10230" title="Abstract">arXiv:2307.10230</a> (replaced) [<a href="/pdf/2307.10230" title="Download PDF">pdf</a>, <a href="/format/2307.10230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Tuning on Graph-augmented Low-resource Text Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Z">Zhihao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuan Fang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, journal under review. arXiv admin note: substantial text overlap with <a href="/abs/2305.03324">arXiv:2305.03324</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item847">[847]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11445" title="Abstract">arXiv:2307.11445</a> (replaced) [<a href="/pdf/2307.11445" title="Download PDF">pdf</a>, <a href="/format/2307.11445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Extended Nonlinear Stability Assessment Methodology For Type-4 Wind  Turbines via Time Reversal Trajectory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ghosh%2C+S">Sujay Ghosh</a>, 
<a href="/search/eess?searchtype=author&query=Bakhshizadeh%2C+M+K">Mohammad Kazem Bakhshizadeh</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+G">Guangya Yang</a>, 
<a href="/search/eess?searchtype=author&query=Kocewiak%2C+%C5%81">&#x141;ukasz Kocewiak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item848">[848]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11845" title="Abstract">arXiv:2307.11845</a> (replaced) [<a href="/pdf/2307.11845" title="Download PDF">pdf</a>, <a href="/format/2307.11845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Document Analytics for Banking Process Automation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gerling%2C+C">Christopher Gerling</a>, 
<a href="/search/cs?searchtype=author&query=Lessmann%2C+S">Stefan Lessmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Computational Finance (q-fin.CP)

</div>
</div>
</dd>
<dt><a name="item849">[849]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12664" title="Abstract">arXiv:2307.12664</a> (replaced) [<a href="/pdf/2307.12664" title="Download PDF">pdf</a>, <a href="/format/2307.12664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SafeSteps: Learning Safer Footstep Planning Policies for Legged Robots  via Model-Based Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Omar%2C+S">Shafeef Omar</a>, 
<a href="/search/cs?searchtype=author&query=Amatucci%2C+L">Lorenzo Amatucci</a>, 
<a href="/search/cs?searchtype=author&query=Barasuol%2C+V">Victor Barasuol</a>, 
<a href="/search/cs?searchtype=author&query=Turrisi%2C+G">Giulio Turrisi</a>, 
<a href="/search/cs?searchtype=author&query=Semini%2C+C">Claudio Semini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the 2023 IEEE-RAS International Conference on Humanoid Robots (Humanoids)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item850">[850]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13318" title="Abstract">arXiv:2307.13318</a> (replaced) [<a href="/pdf/2307.13318" title="Download PDF">pdf</a>, <a href="/format/2307.13318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Affine Disjunctive Invariant Generation with Farkas&#x27; Lemma
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ke%2C+J">Jingyu Ke</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Hongfei Fu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liqian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guoqiang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://hal.science/hal-04004595">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item851">[851]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14335" title="Abstract">arXiv:2307.14335</a> (replaced) [<a href="/pdf/2307.14335" title="Download PDF">pdf</a>, <a href="/format/2307.14335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WavJourney: Compositional Audio Creation with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xubo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhongkai Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haohe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+M">Meng Cui</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qiushi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jinhua Liang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Q">Qiuqiang Kong</a>, 
<a href="/search/cs?searchtype=author&query=Plumbley%2C+M+D">Mark D. Plumbley</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenwu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> GitHub: <a href="https://github.com/Audio-AGI/WavJourney">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item852">[852]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15176" title="Abstract">arXiv:2307.15176</a> (replaced) [<a href="/pdf/2307.15176" title="Download PDF">pdf</a>, <a href="/format/2307.15176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RCT Rejection Sampling for Causal Estimation Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Keith%2C+K+A">Katherine A. Keith</a>, 
<a href="/search/cs?searchtype=author&query=Feldman%2C+S">Sergey Feldman</a>, 
<a href="/search/cs?searchtype=author&query=Jurgens%2C+D">David Jurgens</a>, 
<a href="/search/cs?searchtype=author&query=Bragg%2C+J">Jonathan Bragg</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+R">Rohit Bhattacharya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and data at <a href="https://github.com/kakeith/rct_rejection_sampling">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transactions on Machine Learning Research (TMLR) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item853">[853]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15950" title="Abstract">arXiv:2307.15950</a> (replaced) [<a href="/pdf/2307.15950" title="Download PDF">pdf</a>, <a href="/format/2307.15950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teaching Autonomous Vehicles to Express Interaction Intent during  Unprotected Left Turns: A Human-Driving-Prior-Based Trajectory Planning  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xiao Qi</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+Y">Ying Ni</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hang%2C+P">Peng Hang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item854">[854]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15992" title="Abstract">arXiv:2307.15992</a> (replaced) [<a href="/pdf/2307.15992" title="Download PDF">pdf</a>, <a href="/format/2307.15992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Codable Watermarking for Injecting Multi-bit Information to LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lean Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenkai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Deli Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yankai Lin</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fandong Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xu Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item855">[855]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00709" title="Abstract">arXiv:2308.00709</a> (replaced) [<a href="/pdf/2308.00709" title="Download PDF">pdf</a>, <a href="/format/2308.00709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepTSF: Codeless machine learning operations for time series  forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pelekis%2C+S">Sotiris Pelekis</a>, 
<a href="/search/cs?searchtype=author&query=Karakolis%2C+E">Evangelos Karakolis</a>, 
<a href="/search/cs?searchtype=author&query=Pountridis%2C+T">Theodosios Pountridis</a>, 
<a href="/search/cs?searchtype=author&query=Kormpakis%2C+G">George Kormpakis</a>, 
<a href="/search/cs?searchtype=author&query=Lampropoulos%2C+G">George Lampropoulos</a>, 
<a href="/search/cs?searchtype=author&query=Mouzakitis%2C+S">Spiros Mouzakitis</a>, 
<a href="/search/cs?searchtype=author&query=Askounis%2C+D">Dimitris Askounis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item856">[856]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00802" title="Abstract">arXiv:2308.00802</a> (replaced) [<a href="/pdf/2308.00802" title="Download PDF">pdf</a>, <a href="/format/2308.00802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GRDD: A Dataset for Greek Dialectal NLP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chatzikyriakidis%2C+S">Stergios Chatzikyriakidis</a>, 
<a href="/search/cs?searchtype=author&query=Qwaider%2C+C">Chatrine Qwaider</a>, 
<a href="/search/cs?searchtype=author&query=Kolokousis%2C+I">Ilias Kolokousis</a>, 
<a href="/search/cs?searchtype=author&query=Koula%2C+C">Christina Koula</a>, 
<a href="/search/cs?searchtype=author&query=Papadakis%2C+D">Dimitris Papadakis</a>, 
<a href="/search/cs?searchtype=author&query=Sakellariou%2C+E">Efthymia Sakellariou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item857">[857]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03016" title="Abstract">arXiv:2308.03016</a> (replaced) [<a href="/pdf/2308.03016" title="Download PDF">pdf</a>, <a href="/format/2308.03016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shaping a Smarter Electromagnetic Landscape: IAB, NCR, and RIS in 5G  Standard and Future 6G
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+C">Chao-Kai Wen</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+L">Lung-Sheng Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Shojaeifard%2C+A">Arman Shojaeifard</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+P">Pei-Kai Liao</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kai-Kit Wong</a>, 
<a href="/search/cs?searchtype=author&query=Chae%2C+C">Chan-Byoung Chae</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures, 1 table. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item858">[858]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04003" title="Abstract">arXiv:2308.04003</a> (replaced) [<a href="/pdf/2308.04003" title="Download PDF">pdf</a>, <a href="/ps/2308.04003" title="Download PostScript">ps</a>, <a href="/format/2308.04003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-complexity Resource Allocation for Uplink RSMA in Future 6G Wireless  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jiewen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Gang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zheng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Ming Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+P">Pingzhi Fan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item859">[859]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05187" title="Abstract">arXiv:2308.05187</a> (replaced) [<a href="/pdf/2308.05187" title="Download PDF">pdf</a>, <a href="/format/2308.05187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Interplay of Interference and Queues in Unlicensed  Spectrum Bands for UAV Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghazikor%2C+M">Masoud Ghazikor</a>, 
<a href="/search/cs?searchtype=author&query=Roach%2C+K">Keenan Roach</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+K">Kenny Cheung</a>, 
<a href="/search/cs?searchtype=author&query=Hashemi%2C+M">Morteza Hashemi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Asilomar Conference on Signals, Systems, and Computers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item860">[860]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05817" title="Abstract">arXiv:2308.05817</a> (replaced) [<a href="/pdf/2308.05817" title="Download PDF">pdf</a>, <a href="/format/2308.05817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing Width Parameters on Graph Classes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Brettell%2C+N">Nick Brettell</a>, 
<a href="/search/math?searchtype=author&query=Munaro%2C+A">Andrea Munaro</a>, 
<a href="/search/math?searchtype=author&query=Paulusma%2C+D">Dani&#xeb;l Paulusma</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+S">Shizhou Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 4 figures, abstract shortened due to arXiv requirements
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item861">[861]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06513" title="Abstract">arXiv:2308.06513</a> (replaced) [<a href="/pdf/2308.06513" title="Download PDF">pdf</a>, <a href="/format/2308.06513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study of MEV Extraction Techniques on a First-Come-First-Served  Blockchain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%96z%2C+B">Burak &#xd6;z</a>, 
<a href="/search/cs?searchtype=author&query=Rezabek%2C+F">Filip Rezabek</a>, 
<a href="/search/cs?searchtype=author&query=Gebele%2C+J">Jonas Gebele</a>, 
<a href="/search/cs?searchtype=author&query=Hoops%2C+F">Felix Hoops</a>, 
<a href="/search/cs?searchtype=author&query=Matthes%2C+F">Florian Matthes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item862">[862]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07037" title="Abstract">arXiv:2308.07037</a> (replaced) [<a href="/pdf/2308.07037" title="Download PDF">pdf</a>, <a href="/format/2308.07037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Flow Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Graves%2C+A">Alex Graves</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+R+K">Rupesh Kumar Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Atkinson%2C+T">Timothy Atkinson</a>, 
<a href="/search/cs?searchtype=author&query=Gomez%2C+F">Faustino Gomez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item863">[863]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08736" title="Abstract">arXiv:2308.08736</a> (replaced) [<a href="/pdf/2308.08736" title="Download PDF">pdf</a>, <a href="/format/2308.08736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Effectiveness of Log Representation for Log-based Anomaly  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xingfang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Heng Li</a>, 
<a href="/search/cs?searchtype=author&query=Khomh%2C+F">Foutse Khomh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Journal of Empirical Software Engineering (EMSE)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Empirical Software Engineering (2023) 28:137
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item864">[864]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09084" title="Abstract">arXiv:2308.09084</a> (replaced) [<a href="/pdf/2308.09084" title="Download PDF">pdf</a>, <a href="/format/2308.09084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MovePose: A High-performance Human Pose Estimation Algorithm on Mobile  and Edge Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dongyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoyue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhirui Zhou</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+W">Wangpeng An</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yanhong Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item865">[865]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10778" title="Abstract">arXiv:2308.10778</a> (replaced) [<a href="/pdf/2308.10778" title="Download PDF">pdf</a>, <a href="/format/2308.10778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Topology-aware Analysis of Graph Collaborative Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malitesta%2C+D">Daniele Malitesta</a>, 
<a href="/search/cs?searchtype=author&query=Pomo%2C+C">Claudio Pomo</a>, 
<a href="/search/cs?searchtype=author&query=Anelli%2C+V+W">Vito Walter Anelli</a>, 
<a href="/search/cs?searchtype=author&query=Mancino%2C+A+C+M">Alberto Carlo Maria Mancino</a>, 
<a href="/search/cs?searchtype=author&query=Di+Sciascio%2C+E">Eugenio Di Sciascio</a>, 
<a href="/search/cs?searchtype=author&query=Di+Noia%2C+T">Tommaso Di Noia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item866">[866]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10819" title="Abstract">arXiv:2308.10819</a> (replaced) [<a href="/pdf/2308.10819" title="Download PDF">pdf</a>, <a href="/format/2308.10819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Instruction-Following Robustness of Large Language Models  to Prompt Injection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zekun Li</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Baolin Peng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+P">Pengcheng He</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xifeng Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The data and code can be found at <a href="https://github.com/Leezekun/instruction-following-robustness-eval">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item867">[867]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11136" title="Abstract">arXiv:2308.11136</a> (replaced) [<a href="/pdf/2308.11136" title="Download PDF">pdf</a>, <a href="/ps/2308.11136" title="Download PostScript">ps</a>, <a href="/format/2308.11136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is There Any Social Principle for LLM-Based Agents?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jitao Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Simiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhonghao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item868">[868]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11978" title="Abstract">arXiv:2308.11978</a> (replaced) [<a href="/pdf/2308.11978" title="Download PDF">pdf</a>, <a href="/format/2308.11978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Will More Expressive Graph Neural Networks do Better on Generative  Tasks?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+X">Xiandong Zou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yiren Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Biomolecules (q-bio.BM); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item869">[869]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12405" title="Abstract">arXiv:2308.12405</a> (replaced) [<a href="/pdf/2308.12405" title="Download PDF">pdf</a>, <a href="/format/2308.12405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concatenation trees: A framework for efficient universal cycle and de  Bruijn sequence constructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sawada%2C+J">J. Sawada</a>, 
<a href="/search/math?searchtype=author&query=Sears%2C+J">J. Sears</a>, 
<a href="/search/math?searchtype=author&query=Trautrim%2C+A">A. Trautrim</a>, 
<a href="/search/math?searchtype=author&query=Williams%2C+A">A. Williams</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item870">[870]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12532" title="Abstract">arXiv:2308.12532</a> (replaced) [<a href="/pdf/2308.12532" title="Download PDF">pdf</a>, <a href="/format/2308.12532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedSoL: Bridging Global Alignment and Local Generality in Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+G">Gihun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+M">Minchan Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sangmook Kim</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+J">Jaehoon Oh</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+S">Se-Young Yun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item871">[871]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13234" title="Abstract">arXiv:2308.13234</a> (replaced) [<a href="/pdf/2308.13234" title="Download PDF">pdf</a>, <a href="/format/2308.13234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoding Natural Images from EEG for Object Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yonghao Song</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bingchuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+N">Nanlin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yijun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiaorong Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item872">[872]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13510" title="Abstract">arXiv:2308.13510</a> (replaced) [<a href="/pdf/2308.13510" title="Download PDF">pdf</a>, <a href="/format/2308.13510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Hierarchical Queries for the Attribution Reporting API
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dawson%2C+M">Matthew Dawson</a>, 
<a href="/search/cs?searchtype=author&query=Ghazi%2C+B">Badih Ghazi</a>, 
<a href="/search/cs?searchtype=author&query=Kamath%2C+P">Pritish Kamath</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+K">Kapil Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+R">Ravi Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Luan%2C+B">Bo Luan</a>, 
<a href="/search/cs?searchtype=author&query=Manurangsi%2C+P">Pasin Manurangsi</a>, 
<a href="/search/cs?searchtype=author&query=Mundru%2C+N">Nishanth Mundru</a>, 
<a href="/search/cs?searchtype=author&query=Nair%2C+H">Harikesh Nair</a>, 
<a href="/search/cs?searchtype=author&query=Sealfon%2C+A">Adam Sealfon</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shengyu Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appeared at AdKDD 2023 workshop; Final proceedings version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item873">[873]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13890" title="Abstract">arXiv:2308.13890</a> (replaced) [<a href="/pdf/2308.13890" title="Download PDF">pdf</a>, <a href="/ps/2308.13890" title="Download PostScript">ps</a>, <a href="/format/2308.13890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spanning Adjacency Oracles in Sublinear Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bodwin%2C+G">Greg Bodwin</a>, 
<a href="/search/cs?searchtype=author&query=Fleischmann%2C+H">Henry Fleischmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 1 figure. Accepted to ITCS '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item874">[874]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14306" title="Abstract">arXiv:2308.14306</a> (replaced) [<a href="/e-print/2308.14306" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Robustness to Instructions of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+Y">Yuansheng Ni</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Sichao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=wu%2C+X">Xinyu wu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Hui Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuli Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> There were major problems with the experimental data
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item875">[875]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14969" title="Abstract">arXiv:2308.14969</a> (replaced) [<a href="/pdf/2308.14969" title="Download PDF">pdf</a>, <a href="/format/2308.14969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncovering the Hidden Cost of Model Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Misra%2C+D">Diganta Misra</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+A">Agam Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Runwal%2C+B">Bharat Runwal</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P+Y">Pin Yu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item876">[876]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15709" title="Abstract">arXiv:2308.15709</a> (replaced) [<a href="/pdf/2308.15709" title="Download PDF">pdf</a>, <a href="/format/2308.15709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Threshold KNN-Shapley: A Linear-Time and Privacy-Friendly Approach to  Data Valuation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J+T">Jiachen T. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuqing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+R">Ruoxi Jia</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+P">Prateek Mittal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Spotlight
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Science and Game Theory (cs.GT); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item877">[877]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16781" title="Abstract">arXiv:2308.16781</a> (replaced) [<a href="/pdf/2308.16781" title="Download PDF">pdf</a>, <a href="/format/2308.16781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StratMed: Relevance Stratification between Biomedical Entities for  Sparsity on Medication Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Shunpan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yulei Hou</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Tengfei Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item878">[878]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00744" title="Abstract">arXiv:2309.00744</a> (replaced) [<a href="/pdf/2309.00744" title="Download PDF">pdf</a>, <a href="/format/2309.00744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Make Them Change it Every Week!&quot;: A Qualitative Exploration of Online  Developer Advice on Usable and Secure Authentication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klemmer%2C+J+H">Jan H. Klemmer</a> (1), 
<a href="/search/cs?searchtype=author&query=Gutfleisch%2C+M">Marco Gutfleisch</a> (2), 
<a href="/search/cs?searchtype=author&query=Stransky%2C+C">Christian Stransky</a> (3), 
<a href="/search/cs?searchtype=author&query=Acar%2C+Y">Yasemin Acar</a> (4), 
<a href="/search/cs?searchtype=author&query=Sasse%2C+M+A">M. Angela Sasse</a> (2), 
<a href="/search/cs?searchtype=author&query=Fahl%2C+S">Sascha Fahl</a> (3) ((1) Leibniz University Hannover, (2) Ruhr University Bochum, (3) CISPA Helmholtz Center for Information Security, (4) Paderborn University)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of the paper that appeared at ACM CCS 2023. 18 pages (+2 pages artifact appendix), 4 figures, 11 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item879">[879]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01897" title="Abstract">arXiv:2309.01897</a> (replaced) [<a href="/pdf/2309.01897" title="Download PDF">pdf</a>, <a href="/format/2309.01897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring Actual Treatment Pathways from Patient Records
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wilkins-Caruana%2C+A">Adrian Wilkins-Caruana</a>, 
<a href="/search/cs?searchtype=author&query=Bandara%2C+M">Madhushi Bandara</a>, 
<a href="/search/cs?searchtype=author&query=Musial%2C+K">Katarzyna Musial</a>, 
<a href="/search/cs?searchtype=author&query=Catchpoole%2C+D">Daniel Catchpoole</a>, 
<a href="/search/cs?searchtype=author&query=Kennedy%2C+P+J">Paul J. Kennedy</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J Biomed Inform. 2023 Nov 22:104554. Epub ahead of print. PMID:
  38000767
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item880">[880]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01947" title="Abstract">arXiv:2309.01947</a> (replaced) [<a href="/pdf/2309.01947" title="Download PDF">pdf</a>, <a href="/format/2309.01947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TODM: Train Once Deploy Many Efficient Supernet-Based RNN-T Compression  For On-device ASR Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shangguan%2C+Y">Yuan Shangguan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Haichuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Danni Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chunyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Fathullah%2C+Y">Yassir Fathullah</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dilin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dalmia%2C+A">Ayushi Dalmia</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamoorthi%2C+R">Raghuraman Krishnamoorthi</a>, 
<a href="/search/cs?searchtype=author&query=Kalinli%2C+O">Ozlem Kalinli</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Junteng Jia</a>, 
<a href="/search/cs?searchtype=author&query=Mahadeokar%2C+J">Jay Mahadeokar</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+X">Xin Lei</a>, 
<a href="/search/cs?searchtype=author&query=Seltzer%2C+M">Mike Seltzer</a>, 
<a href="/search/cs?searchtype=author&query=Chandra%2C+V">Vikas Chandra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Meta AI; Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item881">[881]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04422" title="Abstract">arXiv:2309.04422</a> (replaced) [<a href="/pdf/2309.04422" title="Download PDF">pdf</a>, <a href="/format/2309.04422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video Task Decathlon: Unifying Image and Video Tasks in Autonomous  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+T+E">Thomas E. Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yifan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Fisher Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023, project page at <a href="https://www.vis.xyz/pub/vtd">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item882">[882]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07176" title="Abstract">arXiv:2309.07176</a> (replaced) [<a href="/pdf/2309.07176" title="Download PDF">pdf</a>, <a href="/format/2309.07176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal and Fair Encouragement Policy Evaluation and Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A">Angela Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item883">[883]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07621" title="Abstract">arXiv:2309.07621</a> (replaced) [<a href="/pdf/2309.07621" title="Download PDF">pdf</a>, <a href="/format/2309.07621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact solution of the full RMSA problem in elastic optical networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=David%2C+F">Fabio David</a>, 
<a href="/search/cs?searchtype=author&query=de+Rezende%2C+J+F">Jos&#xe9; F. de Rezende</a>, 
<a href="/search/cs?searchtype=author&query=Barbosa%2C+V+C">Valmir C. Barbosa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This version updates metadata
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item884">[884]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07983" title="Abstract">arXiv:2309.07983</a> (replaced) [<a href="/pdf/2309.07983" title="Download PDF">pdf</a>, <a href="/format/2309.07983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SLMIA-SR: Speaker-Level Membership Inference Attacks against Speaker  Recognition Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guangke Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yedi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+F">Fu Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of the 31st Network and Distributed System Security (NDSS) Symposium, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item885">[885]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09111" title="Abstract">arXiv:2309.09111</a> (replaced) [<a href="/pdf/2309.09111" title="Download PDF">pdf</a>, <a href="/ps/2309.09111" title="Download PostScript">ps</a>, <a href="/format/2309.09111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing sequential change detection to sequential estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shekhar%2C+S">Shubhanshu Shekhar</a>, 
<a href="/search/math?searchtype=author&query=Ramdas%2C+A">Aaditya Ramdas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item886">[886]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09777" title="Abstract">arXiv:2309.09777</a> (replaced) [<a href="/pdf/2309.09777" title="Download PDF">pdf</a>, <a href="/format/2309.09777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DriveDreamer: Towards Real-world-driven World Models for Autonomous  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaofeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Guan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinze Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiagang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiwen Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://drivedreamer.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item887">[887]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10078" title="Abstract">arXiv:2309.10078</a> (replaced) [<a href="/pdf/2309.10078" title="Download PDF">pdf</a>, <a href="/ps/2309.10078" title="Download PostScript">ps</a>, <a href="/format/2309.10078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simple and Optimal Online Contention Resolution Schemes for $k$-Uniform  Matroids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dinev%2C+A">Atanas Dinev</a>, 
<a href="/search/cs?searchtype=author&query=Weinberg%2C+S+M">S. Matthew Weinberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 15th Innovations in Theoretical Computer Science (ITCS 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item888">[888]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12303" title="Abstract">arXiv:2309.12303</a> (replaced) [<a href="/pdf/2309.12303" title="Download PDF">pdf</a>, <a href="/format/2309.12303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PanoVOS: Bridging Non-panoramic and Panoramic Views with Transformer for  Video Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shilin Yan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaohao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Renrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Lingyi Hong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenchao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenqiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item889">[889]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13593" title="Abstract">arXiv:2309.13593</a> (replaced) [<a href="/pdf/2309.13593" title="Download PDF">pdf</a>, <a href="/format/2309.13593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Tuning Hamiltonian Monte Carlo for Accelerated Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Christiansen%2C+H">Henrik Christiansen</a>, 
<a href="/search/physics?searchtype=author&query=Errica%2C+F">Federico Errica</a>, 
<a href="/search/physics?searchtype=author&query=Alesiani%2C+F">Francesco Alesiani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Soft Condensed Matter (cond-mat.soft); Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item890">[890]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13658" title="Abstract">arXiv:2309.13658</a> (replaced) [<a href="/pdf/2309.13658" title="Download PDF">pdf</a>, <a href="/format/2309.13658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fantastic Generalization Measures are Nowhere to be Found
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gastpar%2C+M">Michael Gastpar</a>, 
<a href="/search/cs?searchtype=author&query=Nachum%2C+I">Ido Nachum</a>, 
<a href="/search/cs?searchtype=author&query=Shafer%2C+J">Jonathan Shafer</a>, 
<a href="/search/cs?searchtype=author&query=Weinberger%2C+T">Thomas Weinberger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item891">[891]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14681" title="Abstract">arXiv:2309.14681</a> (replaced) [<a href="/pdf/2309.14681" title="Download PDF">pdf</a>, <a href="/format/2309.14681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Human-generated Demonstrations Necessary for In-context Learning?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rui Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoyin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiwei Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-print Version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item892">[892]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14809" title="Abstract">arXiv:2309.14809</a> (replaced) [<a href="/pdf/2309.14809" title="Download PDF">pdf</a>, <a href="/format/2309.14809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ENIGMA-51: Towards a Fine-Grained Understanding of Human-Object  Interactions in Industrial Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ragusa%2C+F">Francesco Ragusa</a>, 
<a href="/search/cs?searchtype=author&query=Leonardi%2C+R">Rosario Leonardi</a>, 
<a href="/search/cs?searchtype=author&query=Mazzamuto%2C+M">Michele Mazzamuto</a>, 
<a href="/search/cs?searchtype=author&query=Bonanno%2C+C">Claudia Bonanno</a>, 
<a href="/search/cs?searchtype=author&query=Scavo%2C+R">Rosario Scavo</a>, 
<a href="/search/cs?searchtype=author&query=Furnari%2C+A">Antonino Furnari</a>, 
<a href="/search/cs?searchtype=author&query=Farinella%2C+G+M">Giovanni Maria Farinella</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item893">[893]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16883" title="Abstract">arXiv:2309.16883</a> (replaced) [<a href="/pdf/2309.16883" title="Download PDF">pdf</a>, <a href="/format/2309.16883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Lipschitz-Variance-Margin Tradeoff for Enhanced Randomized Smoothing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delattre%2C+B">Blaise Delattre</a>, 
<a href="/search/cs?searchtype=author&query=Araujo%2C+A">Alexandre Araujo</a>, 
<a href="/search/cs?searchtype=author&query=Barth%C3%A9lemy%2C+Q">Quentin Barth&#xe9;lemy</a>, 
<a href="/search/cs?searchtype=author&query=Allauzen%2C+A">Alexandre Allauzen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item894">[894]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16899" title="Abstract">arXiv:2309.16899</a> (replaced) [<a href="/pdf/2309.16899" title="Download PDF">pdf</a>, <a href="/format/2309.16899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Contractivity of Plug-and-Play Operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Athalye%2C+C+D">Chirayu D. Athalye</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhury%2C+K+N">Kunal N. Chaudhury</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+B">Bhartendu Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Errors in the proof of Lemma 1 and the statement of Theorem 2 were identified after the publication; these have been rectified in the revised version (v2)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Signal Processing Letters, vol. 30, pp. 1447-1451, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item895">[895]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17255" title="Abstract">arXiv:2309.17255</a> (replaced) [<a href="/pdf/2309.17255" title="Download PDF">pdf</a>, <a href="/format/2309.17255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Graphs for the Life Sciences: Recent Developments, Challenges  and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaoyan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Hastings%2C+J">Janna Hastings</a>, 
<a href="/search/cs?searchtype=author&query=Jim%C3%A9nez-Ruiz%2C+E">Ernesto Jim&#xe9;nez-Ruiz</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+V">Vanessa L&#xf3;pez</a>, 
<a href="/search/cs?searchtype=author&query=Monnin%2C+P">Pierre Monnin</a>, 
<a href="/search/cs?searchtype=author&query=Pesquita%2C+C">Catia Pesquita</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0koda%2C+P">Petr &#x160;koda</a>, 
<a href="/search/cs?searchtype=author&query=Tamma%2C+V">Valentina Tamma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 1 figure, accepted for Transactions on Graph Data and Knowledge (TGDK)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item896">[896]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17338" title="Abstract">arXiv:2309.17338</a> (replaced) [<a href="/pdf/2309.17338" title="Download PDF">pdf</a>, <a href="/format/2309.17338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Trajectory Prediction in Dynamic Multi-Agent Environment by  Dropping Waypoints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chib%2C+P+S">Pranav Singh Chib</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+P">Pravendra Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item897">[897]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17389" title="Abstract">arXiv:2309.17389</a> (replaced) [<a href="/pdf/2309.17389" title="Download PDF">pdf</a>, <a href="/format/2309.17389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt-based test-time real image dehazing: a novel pipeline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zixuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zewei He</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Ziqian Lu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xuecheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhe-Ming Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> update github link (<a href="https://github.com/cecret3350/PTTD-Dehazing">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item898">[898]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17401" title="Abstract">arXiv:2309.17401</a> (replaced) [<a href="/pdf/2309.17401" title="Download PDF">pdf</a>, <a href="/format/2309.17401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Machine Learning in Latent Representations of Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Milin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Abdi%2C+M">Mohammad Abdi</a>, 
<a href="/search/cs?searchtype=author&query=Restuccia%2C+F">Francesco Restuccia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item899">[899]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00334" title="Abstract">arXiv:2310.00334</a> (replaced) [<a href="/pdf/2310.00334" title="Download PDF">pdf</a>, <a href="/ps/2310.00334" title="Download PostScript">ps</a>, <a href="/format/2310.00334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bounded Simultaneous Messages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bogdanov%2C+A">Andrej Bogdanov</a>, 
<a href="/search/cs?searchtype=author&query=Dinesh%2C+K">Krishnamoorthy Dinesh</a>, 
<a href="/search/cs?searchtype=author&query=Filmus%2C+Y">Yuval Filmus</a>, 
<a href="/search/cs?searchtype=author&query=Ishai%2C+Y">Yuval Ishai</a>, 
<a href="/search/cs?searchtype=author&query=Kaplan%2C+A">Avi Kaplan</a>, 
<a href="/search/cs?searchtype=author&query=Sekar%2C+S">Sruthi Sekar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 1 table, accepted to FSTTCS 2023 (improved exposition)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item900">[900]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00967" title="Abstract">arXiv:2310.00967</a> (replaced) [<a href="/pdf/2310.00967" title="Download PDF">pdf</a>, <a href="/format/2310.00967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MiCRO: Near-Zero Cost Gradient Sparsification for Scaling and  Accelerating Distributed DNN Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoon%2C+D">Daegun Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+S">Sangyoon Oh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30th IEEE International Conference on High Performance Computing, Data, and Analytics (HiPC 2023). Code: <a href="https://github.com/kljp/micro">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item901">[901]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01144" title="Abstract">arXiv:2310.01144</a> (replaced) [<a href="/pdf/2310.01144" title="Download PDF">pdf</a>, <a href="/format/2310.01144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Map Equation Goes Neural
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bl%C3%B6cker%2C+C">Christopher Bl&#xf6;cker</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Chester Tan</a>, 
<a href="/search/cs?searchtype=author&query=Scholtes%2C+I">Ingo Scholtes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item902">[902]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01547" title="Abstract">arXiv:2310.01547</a> (replaced) [<a href="/pdf/2310.01547" title="Download PDF">pdf</a>, <a href="/format/2310.01547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the near-optimality of betting confidence sets for bounded means
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shekhar%2C+S">Shubhanshu Shekhar</a>, 
<a href="/search/math?searchtype=author&query=Ramdas%2C+A">Aaditya Ramdas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 53 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Applications (stat.AP); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item903">[903]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01825" title="Abstract">arXiv:2310.01825</a> (replaced) [<a href="/pdf/2310.01825" title="Download PDF">pdf</a>, <a href="/format/2310.01825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empirical Study of PEFT techniques for Winter Wheat Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zahweh%2C+M+H">Mohamad Hasan Zahweh</a>, 
<a href="/search/cs?searchtype=author&query=Nasrallah%2C+H">Hasan Nasrallah</a>, 
<a href="/search/cs?searchtype=author&query=Shukor%2C+M">Mustafa Shukor</a>, 
<a href="/search/cs?searchtype=author&query=Faour%2C+G">Ghaleb Faour</a>, 
<a href="/search/cs?searchtype=author&query=Ghandour%2C+A+J">Ali J. Ghandour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item904">[904]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01828" title="Abstract">arXiv:2310.01828</a> (replaced) [<a href="/pdf/2310.01828" title="Download PDF">pdf</a>, <a href="/format/2310.01828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trainable Noise Model as an XAI evaluation method: application on Sobol  for remote sensing image segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shreim%2C+H">Hossein Shreim</a>, 
<a href="/search/cs?searchtype=author&query=Gizzini%2C+A+K">Abdul Karim Gizzini</a>, 
<a href="/search/cs?searchtype=author&query=Ghandour%2C+A+J">Ali J. Ghandour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item905">[905]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01889" title="Abstract">arXiv:2310.01889</a> (replaced) [<a href="/pdf/2310.01889" title="Download PDF">pdf</a>, <a href="/format/2310.01889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ring Attention with Blockwise Transformers for Near-Infinite Context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zaharia%2C+M">Matei Zaharia</a>, 
<a href="/search/cs?searchtype=author&query=Abbeel%2C+P">Pieter Abbeel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/lhao499/llm_large_context">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item906">[906]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02573" title="Abstract">arXiv:2310.02573</a> (replaced) [<a href="/pdf/2310.02573" title="Download PDF">pdf</a>, <a href="/format/2310.02573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Collision Detection for Robots with Variable Stiffness Actuation  by Using MAD-CNN: Modularized-Attention-Dilated Convolutional Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+Z">Zhenwei Niu</a>, 
<a href="/search/cs?searchtype=author&query=Saoud%2C+L+S">Lyes Saad Saoud</a>, 
<a href="/search/cs?searchtype=author&query=Hussain%2C+I">Irfan Hussain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item907">[907]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03335" title="Abstract">arXiv:2310.03335</a> (replaced) [<a href="/pdf/2310.03335" title="Download PDF">pdf</a>, <a href="/format/2310.03335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Test-time Domain Adaptation via Dynamic Sample Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanshuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Jie Hong</a>, 
<a href="/search/cs?searchtype=author&query=Cheraghian%2C+A">Ali Cheraghian</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+S">Shafin Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Ahmedt-Aristizabal%2C+D">David Ahmedt-Aristizabal</a>, 
<a href="/search/cs?searchtype=author&query=Petersson%2C+L">Lars Petersson</a>, 
<a href="/search/cs?searchtype=author&query=Harandi%2C+M">Mehrtash Harandi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2024 IEEE/CVF Winter Conference on Applications of Computer Vision
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item908">[908]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03915" title="Abstract">arXiv:2310.03915</a> (replaced) [<a href="/pdf/2310.03915" title="Download PDF">pdf</a>, <a href="/format/2310.03915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Low-Rank and Sparse Recurrent Connectivity for Robust  Closed-Loop Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tumma%2C+N">Neehal Tumma</a>, 
<a href="/search/cs?searchtype=author&query=Lechner%2C+M">Mathias Lechner</a>, 
<a href="/search/cs?searchtype=author&query=Loo%2C+N">Noel Loo</a>, 
<a href="/search/cs?searchtype=author&query=Hasani%2C+R">Ramin Hasani</a>, 
<a href="/search/cs?searchtype=author&query=Rus%2C+D">Daniela Rus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item909">[909]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04366" title="Abstract">arXiv:2310.04366</a> (replaced) [<a href="/pdf/2310.04366" title="Download PDF">pdf</a>, <a href="/format/2310.04366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Swordfish: A Framework for Evaluating Deep Neural Network-based  Basecalling using Computation-In-Memory with Non-Ideal Memristors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shahroodi%2C+T">Taha Shahroodi</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+G">Gagandeep Singh</a>, 
<a href="/search/cs?searchtype=author&query=Zahedi%2C+M">Mahdi Zahedi</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+H">Haiyu Mao</a>, 
<a href="/search/cs?searchtype=author&query=Lindegger%2C+J">Joel Lindegger</a>, 
<a href="/search/cs?searchtype=author&query=Firtina%2C+C">Can Firtina</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+S">Stephan Wong</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>, 
<a href="/search/cs?searchtype=author&query=Hamdioui%2C+S">Said Hamdioui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in 56th IEEE/ACM International Symposium on Microarchitecture (MICRO), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Emerging Technologies (cs.ET); Genomics (q-bio.GN)

</div>
</div>
</dd>
<dt><a name="item910">[910]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04914" title="Abstract">arXiv:2310.04914</a> (replaced) [<a href="/pdf/2310.04914" title="Download PDF">pdf</a>, <a href="/format/2310.04914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Zero-Shot Abilities of Vision-Language Models on Video  Understanding Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madasu%2C+A">Avinash Madasu</a>, 
<a href="/search/cs?searchtype=author&query=Bhiwandiwalla%2C+A">Anahita Bhiwandiwalla</a>, 
<a href="/search/cs?searchtype=author&query=Lal%2C+V">Vasudev Lal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item911">[911]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06422" title="Abstract">arXiv:2310.06422</a> (replaced) [<a href="/pdf/2310.06422" title="Download PDF">pdf</a>, <a href="/format/2310.06422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Propaganda Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sprenkamp%2C+K">Kilian Sprenkamp</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+D+G">Daniel Gordon Jones</a>, 
<a href="/search/cs?searchtype=author&query=Zavolokina%2C+L">Liudmila Zavolokina</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item912">[912]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06627" title="Abstract">arXiv:2310.06627</a> (replaced) [<a href="/pdf/2310.06627" title="Download PDF">pdf</a>, <a href="/format/2310.06627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What If the TV Was Off? Examining Counterfactual Reasoning Abilities of  Multi-modal Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Letian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaotong Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhongkai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+Y">Yongshuo Zong</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+X">Xin Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bingchen Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item913">[913]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06756" title="Abstract">arXiv:2310.06756</a> (replaced) [<a href="/pdf/2310.06756" title="Download PDF">pdf</a>, <a href="/format/2310.06756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Going Beyond Neural Network Feature Similarity: The Network Feature  Complexity and Its Interpretation Using Category Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhanpeng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item914">[914]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07206" title="Abstract">arXiv:2310.07206</a> (replaced) [<a href="/pdf/2310.07206" title="Download PDF">pdf</a>, <a href="/format/2310.07206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepSimHO: Stable Pose Estimation for Hand-Object Interaction via  Physics Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+W">Wei Mao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongdong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item915">[915]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07587" title="Abstract">arXiv:2310.07587</a> (replaced) [<a href="/pdf/2310.07587" title="Download PDF">pdf</a>, <a href="/format/2310.07587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fed-GraB: Federated Long-tailed Learning with Self-Adjusting Gradient  Balancer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zikai Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zihan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Songshang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hualiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jin Hao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J+T">Joey Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H+H">Howard Hao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zuozhu Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item916">[916]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07665" title="Abstract">arXiv:2310.07665</a> (replaced) [<a href="/pdf/2310.07665" title="Download PDF">pdf</a>, <a href="/format/2310.07665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Backtracking Counterfactuals for Causally Compliant Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kladny%2C+K">Klaus-Rudolf Kladny</a>, 
<a href="/search/cs?searchtype=author&query=von+K%C3%BCgelgen%2C+J">Julius von K&#xfc;gelgen</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>, 
<a href="/search/cs?searchtype=author&query=Muehlebach%2C+M">Michael Muehlebach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item917">[917]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07997" title="Abstract">arXiv:2310.07997</a> (replaced) [<a href="/pdf/2310.07997" title="Download PDF">pdf</a>, <a href="/format/2310.07997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PG-NeuS: Robust and Efficient Point Guidance for Multi-View Neural  Surface Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+W">Wanjuan Su</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qingshan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+W">Wenbing Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item918">[918]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08049" title="Abstract">arXiv:2310.08049</a> (replaced) [<a href="/pdf/2310.08049" title="Download PDF">pdf</a>, <a href="/format/2310.08049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Relationship Between Model Architecture and In-Context  Learning Ability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+I">Ivan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+N">Nan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Berg-Kirkpatrick%2C+T">Taylor Berg-Kirkpatrick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item919">[919]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08540" title="Abstract">arXiv:2310.08540</a> (replaced) [<a href="/pdf/2310.08540" title="Download PDF">pdf</a>, <a href="/format/2310.08540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do pretrained Transformers Really Learn In-context by Gradient Descent?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Lingfeng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+A">Aayush Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Khashabi%2C+D">Daniel Khashabi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item920">[920]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08872" title="Abstract">arXiv:2310.08872</a> (replaced) [<a href="/pdf/2310.08872" title="Download PDF">pdf</a>, <a href="/format/2310.08872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> R&amp;B: Region and Boundary Aware Zero-shot Grounded Text-to-image  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jiayu Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+H">Henglei Lv</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuhui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qingming Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint. Under review. Project page: <a href="https://sagileo.github.io/Region-and-Boundary">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item921">[921]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09912" title="Abstract">arXiv:2310.09912</a> (replaced) [<a href="/pdf/2310.09912" title="Download PDF">pdf</a>, <a href="/format/2310.09912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Discovery of Interpretable Directions in h-space of  Pre-trained Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zijian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L+L+Z">Luping Liu. Zhijie Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yichen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhou Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item922">[922]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09926" title="Abstract">arXiv:2310.09926</a> (replaced) [<a href="/pdf/2310.09926" title="Download PDF">pdf</a>, <a href="/format/2310.09926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating Uncertainty in Multimodal Foundation Models using Public  Internet Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dutta%2C+S">Shiladitya Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Hongbo Wei</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Laan%2C+L">Lars van der Laan</a>, 
<a href="/search/cs?searchtype=author&query=Alaa%2C+A+M">Ahmed M. Alaa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item923">[923]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10092" title="Abstract">arXiv:2310.10092</a> (replaced) [<a href="/pdf/2310.10092" title="Download PDF">pdf</a>, <a href="/ps/2310.10092" title="Download PostScript">ps</a>, <a href="/format/2310.10092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Label Differential Privacy via Aggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brahmbhatt%2C+A">Anand Brahmbhatt</a>, 
<a href="/search/cs?searchtype=author&query=Saket%2C+R">Rishi Saket</a>, 
<a href="/search/cs?searchtype=author&query=Havaldar%2C+S">Shreyas Havaldar</a>, 
<a href="/search/cs?searchtype=author&query=Nasery%2C+A">Anshul Nasery</a>, 
<a href="/search/cs?searchtype=author&query=Raghuveer%2C+A">Aravindan Raghuveer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item924">[924]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10520" title="Abstract">arXiv:2310.10520</a> (replaced) [<a href="/pdf/2310.10520" title="Download PDF">pdf</a>, <a href="/format/2310.10520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Parsing by Large Language Models for Intricate Updating  Strategies of Zero-Shot Dialogue State Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuxiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+G">Guanting Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weiran Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the Findings of EMNLP 2023 (Short Paper)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item925">[925]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10541" title="Abstract">arXiv:2310.10541</a> (replaced) [<a href="/pdf/2310.10541" title="Download PDF">pdf</a>, <a href="/format/2310.10541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AST: Effective Dataset Distillation through Alignment with Smooth and  High-Quality Expert Trajectories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jiyuan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenzhuo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+K">Kwok-Yan Lam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item926">[926]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10544" title="Abstract">arXiv:2310.10544</a> (replaced) [<a href="/pdf/2310.10544" title="Download PDF">pdf</a>, <a href="/ps/2310.10544" title="Download PostScript">ps</a>, <a href="/format/2310.10544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Use of probabilistic phrases in a coordination game: human versus GPT-4
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Maloney%2C+L+T">Laurence T Maloney</a>, 
<a href="/search/q-bio?searchtype=author&query=Martello%2C+M+F+D">Maria F Dal Martello</a>, 
<a href="/search/q-bio?searchtype=author&query=Fei%2C+V">Vivian Fei</a>, 
<a href="/search/q-bio?searchtype=author&query=Ma%2C+V">Valerie Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Corrected typos, extended discussion, added references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item927">[927]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11188" title="Abstract">arXiv:2310.11188</a> (replaced) [<a href="/pdf/2310.11188" title="Download PDF">pdf</a>, <a href="/format/2310.11188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Bandits with Multi-User Delayed Feedback: Theory and  Application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yandi Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jianxiong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yupeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+W">Weijia Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an extended version of "A Modified EXP3 in Adversarial Bandits with Multi-User Delayed Feedback" published in COCOON 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item928">[928]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11728" title="Abstract">arXiv:2310.11728</a> (replaced) [<a href="/pdf/2310.11728" title="Download PDF">pdf</a>, <a href="/ps/2310.11728" title="Download PostScript">ps</a>, <a href="/format/2310.11728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Echo-Vision Network: Visualizing the Shape of a Complex Room through  High-order Echoes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeon%2C+I">Inmo Yeon</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+I">Iljoo Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seungchul Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jung-Woo Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item929">[929]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12190" title="Abstract">arXiv:2310.12190</a> (replaced) [<a href="/pdf/2310.12190" title="Download PDF">pdf</a>, <a href="/format/2310.12190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DynamiCrafter: Animating Open-domain Images with Video Diffusion Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+J">Jinbo Xing</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+M">Menghan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haoxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wangbo Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hanyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xintao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+T">Tien-Tsin Wong</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://doubiiu.github.io/projects/DynamiCrafter">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item930">[930]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12877" title="Abstract">arXiv:2310.12877</a> (replaced) [<a href="/pdf/2310.12877" title="Download PDF">pdf</a>, <a href="/format/2310.12877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perceptual Assessment and Optimization of High Dynamic Range Image  Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cao%2C+P">Peibei Cao</a>, 
<a href="/search/eess?searchtype=author&query=Mantiuk%2C+R+K">Rafal K. Mantiuk</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+K">Kede Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item931">[931]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13121" title="Abstract">arXiv:2310.13121</a> (replaced) [<a href="/pdf/2310.13121" title="Download PDF">pdf</a>, <a href="/format/2310.13121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Addition in Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Quirke%2C+P">Philip Quirke</a>, 
<a href="/search/cs?searchtype=author&query=Barez%2C+F">Fazl Barez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures, submitted to ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item932">[932]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13258" title="Abstract">arXiv:2310.13258</a> (replaced) [<a href="/pdf/2310.13258" title="Download PDF">pdf</a>, <a href="/format/2310.13258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ManiCast: Collaborative Manipulation with Cost-Aware Human Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kedia%2C+K">Kushal Kedia</a>, 
<a href="/search/cs?searchtype=author&query=Dan%2C+P">Prithwish Dan</a>, 
<a href="/search/cs?searchtype=author&query=Bhardwaj%2C+A">Atiksh Bhardwaj</a>, 
<a href="/search/cs?searchtype=author&query=Choudhury%2C+S">Sanjiban Choudhury</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CoRL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item933">[933]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13540" title="Abstract">arXiv:2310.13540</a> (replaced) [<a href="/pdf/2310.13540" title="Download PDF">pdf</a>, <a href="/format/2310.13540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Thoroughly Modeling Multi-domain Pre-trained Recommendation as Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+Z">Zekai Qu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+R">Ruobing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chaojun Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+F">Fengzong Lian</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Z">Zhanhui Kang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item934">[934]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14318" title="Abstract">arXiv:2310.14318</a> (replaced) [<a href="/pdf/2310.14318" title="Download PDF">pdf</a>, <a href="/format/2310.14318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intent Contrastive Learning with Cross Subsequences for Sequential  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+X">Xiuyuan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Huanhuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Pengpeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guanfeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+F">Fuzhen Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+V+S">Victor S. Sheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10pages, 5figures, WSDM2024. arXiv admin note: text overlap with <a href="/abs/2304.07763">arXiv:2304.07763</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item935">[935]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14351" title="Abstract">arXiv:2310.14351</a> (replaced) [<a href="/pdf/2310.14351" title="Download PDF">pdf</a>, <a href="/format/2310.14351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonasymptotic Convergence Rate of Quasi-Monte Carlo: Applications to  Linear Elliptic PDEs with Lognormal Coefficients and Importance Samplings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/math?searchtype=author&query=Tempone%2C+R">Ra&#xfa;l Tempone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item936">[936]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14505" title="Abstract">arXiv:2310.14505</a> (replaced) [<a href="/pdf/2310.14505" title="Download PDF">pdf</a>, <a href="/ps/2310.14505" title="Download PostScript">ps</a>, <a href="/format/2310.14505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sentiment analysis with adaptive multi-head attention in Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fanfei Meng</a>, 
<a href="/search/cs?searchtype=author&query=Demeter%2C+D">David Demeter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 4th International Conference on Signal Processing and Machine Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item937">[937]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15848" title="Abstract">arXiv:2310.15848</a> (replaced) [<a href="/pdf/2310.15848" title="Download PDF">pdf</a>, <a href="/format/2310.15848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Responsible Machine Learning Datasets with Fairness, Privacy, and  Regulatory Norms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mittal%2C+S">Surbhi Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Thakral%2C+K">Kartik Thakral</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+R">Richa Singh</a>, 
<a href="/search/cs?searchtype=author&query=Vatsa%2C+M">Mayank Vatsa</a>, 
<a href="/search/cs?searchtype=author&query=Glaser%2C+T">Tamar Glaser</a>, 
<a href="/search/cs?searchtype=author&query=Ferrer%2C+C+C">Cristian Canton Ferrer</a>, 
<a href="/search/cs?searchtype=author&query=Hassner%2C+T">Tal Hassner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> corrected typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item938">[938]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15937" title="Abstract">arXiv:2310.15937</a> (replaced) [<a href="/pdf/2310.15937" title="Download PDF">pdf</a>, <a href="/format/2310.15937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Behavioral Perspective on Models of Linear Dynamical Networks with  Manifest Variables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shi%2C+S">Shengling Shi</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+Z">Zhiyong Sun</a>, 
<a href="/search/eess?searchtype=author&query=De+Schutter%2C+B">Bart De Schutter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item939">[939]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16842" title="Abstract">arXiv:2310.16842</a> (replaced) [<a href="/pdf/2310.16842" title="Download PDF">pdf</a>, <a href="/format/2310.16842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Energy-efficiency by Solving the Throughput Bottleneck of LSTM  Cells for Embedded FPGAs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chao Qian</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+T">Tianheng Ling</a>, 
<a href="/search/cs?searchtype=author&query=Schiele%2C+G">Gregor Schiele</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item940">[940]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17294" title="Abstract">arXiv:2310.17294</a> (replaced) [<a href="/pdf/2310.17294" title="Download PDF">pdf</a>, <a href="/format/2310.17294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scale-Adaptive Feature Aggregation for Efficient Space-Time Video  Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhewei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+A">Ailin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaotao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shuchang Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV2024, 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item941">[941]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17331" title="Abstract">arXiv:2310.17331</a> (replaced) [<a href="/pdf/2310.17331" title="Download PDF">pdf</a>, <a href="/ps/2310.17331" title="Download PostScript">ps</a>, <a href="/format/2310.17331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A novel solution for seepage problems using physics-informed neural  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+T">Tianfu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yelin Feng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qingfu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zongliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+M">Mingjiao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zaihong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">Dawei Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item942">[942]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18285" title="Abstract">arXiv:2310.18285</a> (replaced) [<a href="/pdf/2310.18285" title="Download PDF">pdf</a>, <a href="/format/2310.18285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unlocking the Potential of Prompt-Tuning in Bridging Generalized and  Personalized Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+W">Wenlong Deng</a>, 
<a href="/search/cs?searchtype=author&query=Thrampoulidis%2C+C">Christos Thrampoulidis</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoxiao Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item943">[943]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18332" title="Abstract">arXiv:2310.18332</a> (replaced) [<a href="/pdf/2310.18332" title="Download PDF">pdf</a>, <a href="/format/2310.18332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WordArt Designer: User-Driven Artistic Typography Synthesis using Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jun-Yan He</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhi-Qi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jingdong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+W">Wangmeng Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xianhui Lin</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+X">Xiaoyang Kang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zengke Jin</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yusen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+Y">Yifeng Geng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuansong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by EMNLP 2023, 10 pages, 11 figures, 1 table, the system is at <a href="https://www.modelscope.cn/studios/WordArt/WordArt">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item944">[944]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18387" title="Abstract">arXiv:2310.18387</a> (replaced) [<a href="/pdf/2310.18387" title="Download PDF">pdf</a>, <a href="/format/2310.18387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OffMix-3L: A Novel Code-Mixed Dataset in Bangla-English-Hindi for  Offensive Language Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goswami%2C+D">Dhiman Goswami</a>, 
<a href="/search/cs?searchtype=author&query=Raihan%2C+M+N">Md Nishat Raihan</a>, 
<a href="/search/cs?searchtype=author&query=Mahmud%2C+A">Antara Mahmud</a>, 
<a href="/search/cs?searchtype=author&query=Anastasopoulos%2C+A">Antonios Anastasopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Zampieri%2C+M">Marcos Zampieri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2310.18023">arXiv:2310.18023</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item945">[945]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18446" title="Abstract">arXiv:2310.18446</a> (replaced) [<a href="/pdf/2310.18446" title="Download PDF">pdf</a>, <a href="/format/2310.18446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Skip Orthogonal List for Dynamic Optimal Transport Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaoyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Hu Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI); Computational Geometry (cs.CG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item946">[946]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18493" title="Abstract">arXiv:2310.18493</a> (replaced) [<a href="/pdf/2310.18493" title="Download PDF">pdf</a>, <a href="/format/2310.18493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Kinetic Simulations of Electrostatic Plasmas with  Reduced-Order Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tsai%2C+P">Ping-Hsuan Tsai</a> (1), 
<a href="/search/math?searchtype=author&query=Chung%2C+S+W">Seung Whan Chung</a> (2), 
<a href="/search/math?searchtype=author&query=Ghosh%2C+D">Debojyoti Ghosh</a> (2), 
<a href="/search/math?searchtype=author&query=Loffeld%2C+J">John Loffeld</a> (2), 
<a href="/search/math?searchtype=author&query=Choi%2C+Y">Youngsoo Choi</a> (2), 
<a href="/search/math?searchtype=author&query=Belof%2C+J+L">Jonathan L. Belof</a> (2) ((1) University of Illinois Urbana--Champaign, (2) Lawrence Livermore National Laboratory)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures typos corrected; references added; add one figures for predicted solution fields; fix error in the legend of figure 1.b and caption; add rebox in figure 1.a to indicate training data; add timing for constructing the tensor in offline; add one more paragraph in section 3;
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Plasma Physics (physics.plasm-ph)

</div>
</div>
</dd>
<dt><a name="item947">[947]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19062" title="Abstract">arXiv:2310.19062</a> (replaced) [<a href="/pdf/2310.19062" title="Download PDF">pdf</a>, <a href="/format/2310.19062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A multi-modal table tennis robot system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ziegler%2C+A">Andreas Ziegler</a>, 
<a href="/search/cs?searchtype=author&query=Gossard%2C+T">Thomas Gossard</a>, 
<a href="/search/cs?searchtype=author&query=Vetter%2C+K">Karl Vetter</a>, 
<a href="/search/cs?searchtype=author&query=Tebbe%2C+J">Jonas Tebbe</a>, 
<a href="/search/cs?searchtype=author&query=Zell%2C+A">Andreas Zell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for RoboLetics: Workshop on Robot Learning in Athletics @CoRL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item948">[948]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19106" title="Abstract">arXiv:2310.19106</a> (replaced) [<a href="/pdf/2310.19106" title="Download PDF">pdf</a>, <a href="/format/2310.19106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PACuna: Automated Fine-Tuning of Language Models for Particle  Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sulc%2C+A">Antonin Sulc</a>, 
<a href="/search/cs?searchtype=author&query=Kammering%2C+R">Raimund Kammering</a>, 
<a href="/search/cs?searchtype=author&query=Eichler%2C+A">Annika Eichler</a>, 
<a href="/search/cs?searchtype=author&query=Wilksen%2C+T">Tim Wilksen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item949">[949]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19453" title="Abstract">arXiv:2310.19453</a> (replaced) [<a href="/pdf/2310.19453" title="Download PDF">pdf</a>, <a href="/format/2310.19453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FLIP: Towards Fine-grained Alignment between ID-based Models and  Pretrained Language Models for CTR Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hangyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jianghao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chenxu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruiming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item950">[950]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19736" title="Abstract">arXiv:2310.19736</a> (replaced) [<a href="/pdf/2310.19736" title="Download PDF">pdf</a>, <a href="/format/2310.19736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Large Language Models: A Comprehensive Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zishan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+R">Renren Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chuang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yufei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+D">Dan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Supryadi">Supryadi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Linhao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+B">Bojian Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+D">Deyi Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 111 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item951">[951]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19806" title="Abstract">arXiv:2310.19806</a> (replaced) [<a href="/pdf/2310.19806" title="Download PDF">pdf</a>, <a href="/format/2310.19806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Verification of Equivalence Properties in Advanced Logic  Programs -- Bachelor Thesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heuer%2C+J">Jan Heuer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Bachelor Thesis at the University of Potsdam
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item952">[952]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20174" title="Abstract">arXiv:2310.20174</a> (replaced) [<a href="/pdf/2310.20174" title="Download PDF">pdf</a>, <a href="/format/2310.20174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphTransformers for Geospatial Forecasting of Hurricane Trajectories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+P">Pallavi Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+S">Satyaki Chakraborty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item953">[953]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20189" title="Abstract">arXiv:2310.20189</a> (replaced) [<a href="/pdf/2310.20189" title="Download PDF">pdf</a>, <a href="/ps/2310.20189" title="Download PostScript">ps</a>, <a href="/format/2310.20189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LFG: A Generative Network for Real-Time Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junyi Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 1 figure, 4 tables. Source code would be uploaded to github soon
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item954">[954]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20192" title="Abstract">arXiv:2310.20192</a> (replaced) [<a href="/pdf/2310.20192" title="Download PDF">pdf</a>, <a href="/format/2310.20192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shaping Opinions in Social Networks with Shadow Banning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yen-Shao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zaman%2C+T">Tauhid Zaman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item955">[955]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20587" title="Abstract">arXiv:2310.20587</a> (replaced) [<a href="/pdf/2310.20587" title="Download PDF">pdf</a>, <a href="/format/2310.20587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unleashing the Power of Pre-trained Language Models for Offline  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+R">Ruizhe Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuyao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ze%2C+Y">Yanjie Ze</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S+S">Simon S. Du</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huazhe Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 16 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item956">[956]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00341" title="Abstract">arXiv:2311.00341</a> (replaced) [<a href="/pdf/2311.00341" title="Download PDF">pdf</a>, <a href="/format/2311.00341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Open DAC 2023 Dataset and Challenges for Sorbent Discovery in Direct  Air Capture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Sriram%2C+A">Anuroop Sriram</a>, 
<a href="/search/cond-mat?searchtype=author&query=Choi%2C+S">Sihoon Choi</a>, 
<a href="/search/cond-mat?searchtype=author&query=Yu%2C+X">Xiaohan Yu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Brabson%2C+L+M">Logan M. Brabson</a>, 
<a href="/search/cond-mat?searchtype=author&query=Das%2C+A">Abhishek Das</a>, 
<a href="/search/cond-mat?searchtype=author&query=Ulissi%2C+Z">Zachary Ulissi</a>, 
<a href="/search/cond-mat?searchtype=author&query=Uyttendaele%2C+M">Matt Uyttendaele</a>, 
<a href="/search/cond-mat?searchtype=author&query=Medford%2C+A+J">Andrew J. Medford</a>, 
<a href="/search/cond-mat?searchtype=author&query=Sholl%2C+D+S">David S. Sholl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item957">[957]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00397" title="Abstract">arXiv:2311.00397</a> (replaced) [<a href="/pdf/2311.00397" title="Download PDF">pdf</a>, <a href="/format/2311.00397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Omni-supervised Referring Expression Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Minglang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yiyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+G">Gen Luo</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+G">Guannan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+W">Weilin Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaoshuai Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item958">[958]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00637" title="Abstract">arXiv:2311.00637</a> (replaced) [<a href="/pdf/2311.00637" title="Download PDF">pdf</a>, <a href="/format/2311.00637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of the Single Reference Coupled Cluster Method for Electronic  Structure Calculations: The Discrete Coupled Cluster Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hassan%2C+M">Muhammad Hassan</a>, 
<a href="/search/math?searchtype=author&query=Maday%2C+Y">Yvon Maday</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+Y">Yipeng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 78 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item959">[959]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01043" title="Abstract">arXiv:2311.01043</a> (replaced) [<a href="/pdf/2311.01043" title="Download PDF">pdf</a>, <a href="/format/2311.01043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM4Drive: A Survey of Large Language Models for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhenjie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiaosong Jia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> GitHub Repo: <a href="https://github.com/Thinklab-SJTU/Awesome-LLM4AD">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item960">[960]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01066" title="Abstract">arXiv:2311.01066</a> (replaced) [<a href="/pdf/2311.01066" title="Download PDF">pdf</a>, <a href="/format/2311.01066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Multimodal Information Bottleneck for Multimodality  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fang%2C+Y">Yingying Fang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+S">Shuang Wu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+S">Sheng Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+C">Chaoyan Huang</a>, 
<a href="/search/eess?searchtype=author&query=Zeng%2C+T">Tieyong Zeng</a>, 
<a href="/search/eess?searchtype=author&query=Xing%2C+X">Xiaodan Xing</a>, 
<a href="/search/eess?searchtype=author&query=Walsh%2C+S">Simon Walsh</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+G">Guang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item961">[961]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01276" title="Abstract">arXiv:2311.01276</a> (replaced) [<a href="/pdf/2311.01276" title="Download PDF">pdf</a>, <a href="/format/2311.01276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long-Range Neural Atom Learning for Molecular Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhanke Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiangchao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+Y">Yu Rong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bo Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item962">[962]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01335" title="Abstract">arXiv:2311.01335</a> (replaced) [<a href="/pdf/2311.01335" title="Download PDF">pdf</a>, <a href="/format/2311.01335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Robot Hand-Eye Calibration Enabled by Learning-Based 3D Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Leihui Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xingyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Riwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuping Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 19 figures, 6 tables, submitted to MSSP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item963">[963]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01703" title="Abstract">arXiv:2311.01703</a> (replaced) [<a href="/pdf/2311.01703" title="Download PDF">pdf</a>, <a href="/format/2311.01703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taking a PEEK into YOLOv5 for Satellite Component Recognition via  Entropy-based Visual Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meni%2C+M+J">Mackenzie J. Meni</a>, 
<a href="/search/cs?searchtype=author&query=Mahendrakar%2C+T">Trupti Mahendrakar</a>, 
<a href="/search/cs?searchtype=author&query=Raney%2C+O+D+M">Olivia D. M. Raney</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+R+T">Ryan T. White</a>, 
<a href="/search/cs?searchtype=author&query=Mayo%2C+M+L">Michael L. Mayo</a>, 
<a href="/search/cs?searchtype=author&query=Pilkiewicz%2C+K">Kevin Pilkiewicz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item964">[964]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01815" title="Abstract">arXiv:2311.01815</a> (replaced) [<a href="/pdf/2311.01815" title="Download PDF">pdf</a>, <a href="/format/2311.01815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating 3D Uncertainty Field: Quantifying Uncertainty for Neural  Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jianxiong Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+R">Ruijie Ren</a>, 
<a href="/search/cs?searchtype=author&query=Ruiz%2C+A">Adria Ruiz</a>, 
<a href="/search/cs?searchtype=author&query=Moreno-Noguer%2C+F">Francesc Moreno-Noguer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item965">[965]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01908" title="Abstract">arXiv:2311.01908</a> (replaced) [<a href="/pdf/2311.01908" title="Download PDF">pdf</a>, <a href="/format/2311.01908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-driven Multimodal Target Volume Contouring in Radiation Oncology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Oh%2C+Y">Yujin Oh</a>, 
<a href="/search/eess?searchtype=author&query=Park%2C+S">Sangjoon Park</a>, 
<a href="/search/eess?searchtype=author&query=Byun%2C+H+K">Hwa Kyung Byun</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+J+S">Jin Sung Kim</a>, 
<a href="/search/eess?searchtype=author&query=Ye%2C+J+C">Jong Chul Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item966">[966]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02668" title="Abstract">arXiv:2311.02668</a> (replaced) [<a href="/pdf/2311.02668" title="Download PDF">pdf</a>, <a href="/format/2311.02668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control of convertible UAV with vectorized thrust
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=de+Oliveira%2C+T+L">Tomas Lopes de Oliveira</a>, 
<a href="/search/eess?searchtype=author&query=Anglade%2C+A">Andre Anglade</a>, 
<a href="/search/eess?searchtype=author&query=Hamel%2C+T">Tarek Hamel</a>, 
<a href="/search/eess?searchtype=author&query=Samson%2C+C">Claude Samson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, to appear in Proceedings of IFAC World Congress 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item967">[967]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03573" title="Abstract">arXiv:2311.03573</a> (replaced) [<a href="/pdf/2311.03573" title="Download PDF">pdf</a>, <a href="/ps/2311.03573" title="Download PostScript">ps</a>, <a href="/format/2311.03573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DonationChain: A New Platform for Blockchain-Based Donation-Tracking  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nairi%2C+C">Chaimaa Nairi</a>, 
<a href="/search/cs?searchtype=author&query=Cicioglu%2C+M">Murtaza Cicioglu</a>, 
<a href="/search/cs?searchtype=author&query=Calhan%2C+A">Ali Calhan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item968">[968]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04014" title="Abstract">arXiv:2311.04014</a> (replaced) [<a href="/pdf/2311.04014" title="Download PDF">pdf</a>, <a href="/format/2311.04014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Method to Improve the Performance of Reinforcement Learning Based on  the Y Operator for a Class of Stochastic Differential Equation-Based  Child-Mother Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+C">Cheng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yi Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item969">[969]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05419" title="Abstract">arXiv:2311.05419</a> (replaced) [<a href="/pdf/2311.05419" title="Download PDF">pdf</a>, <a href="/format/2311.05419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mirror: A Universal Framework for Various Information Extraction Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Tong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Junfei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zijian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Mengsong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guoliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+X">Xiaoye Qu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenliang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhefeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huai%2C+B">Baoxing Huai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP23 main conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item970">[970]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05697" title="Abstract">arXiv:2311.05697</a> (replaced) [<a href="/pdf/2311.05697" title="Download PDF">pdf</a>, <a href="/format/2311.05697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3DGAUnet: 3D generative adversarial networks with a 3D U-Net based  generator to achieve the accurate and effective synthesis of clinical tumor  image data for pancreatic cancer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shi%2C+Y">Yu Shi</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+H">Hannah Tang</a>, 
<a href="/search/eess?searchtype=author&query=Baine%2C+M">Michael Baine</a>, 
<a href="/search/eess?searchtype=author&query=Hollingsworth%2C+M+A">Michael A. Hollingsworth</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+H">Huijing Du</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+D">Dandan Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+H">Hongfeng Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published on Cancers: Shi, Yu, Hannah Tang, Michael J. Baine, Michael A. Hollingsworth, Huijing Du, Dandan Zheng, Chi Zhang, and Hongfeng Yu. 2023. "3DGAUnet: 3D Generative Adversarial Networks with a 3D U-Net Based Generator to Achieve the Accurate and Effective Synthesis of Clinical Tumor Image Data for Pancreatic Cancer" Cancers 15, no. 23: 5496
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item971">[971]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05858" title="Abstract">arXiv:2311.05858</a> (replaced) [<a href="/pdf/2311.05858" title="Download PDF">pdf</a>, <a href="/format/2311.05858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Layer-wise Auto-Weighting for Non-Stationary Test-Time Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Junyoung Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+H">Hyeongjun Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+I">Ilhoon Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Sohn%2C+K">Kwanghoon Sohn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item972">[972]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05913" title="Abstract">arXiv:2311.05913</a> (replaced) [<a href="/pdf/2311.05913" title="Download PDF">pdf</a>, <a href="/ps/2311.05913" title="Download PostScript">ps</a>, <a href="/format/2311.05913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditional lower bounds for sparse parameterized 2-CSP: A streamlined  proof
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S.%2C+K+C">Karthik C. S.</a>, 
<a href="/search/cs?searchtype=author&query=Marx%2C+D">D&#xe1;niel Marx</a>, 
<a href="/search/cs?searchtype=author&query=Pilipczuk%2C+M">Marcin Pilipczuk</a>, 
<a href="/search/cs?searchtype=author&query=Souza%2C+U">U&#xe9;verton Souza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item973">[973]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06401" title="Abstract">arXiv:2311.06401</a> (replaced) [<a href="/pdf/2311.06401" title="Download PDF">pdf</a>, <a href="/format/2311.06401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autoregressive Language Models For Estimating the Entropy of Epic EHR  Audit Logs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Warner%2C+B+C">Benjamin C. Warner</a>, 
<a href="/search/cs?searchtype=author&query=Kannampallil%2C+T">Thomas Kannampallil</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seunghwan Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023, December 10th, 2023, New Orleans, United States, 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item974">[974]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06648" title="Abstract">arXiv:2311.06648</a> (replaced) [<a href="/pdf/2311.06648" title="Download PDF">pdf</a>, <a href="/format/2311.06648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design of Reconfigurable Intelligent Surfaces by Using S-Parameter  Multiport Network Theory -- Optimization and Full-Wave Validation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abrardo%2C+A">Andrea Abrardo</a>, 
<a href="/search/cs?searchtype=author&query=Toccafondi%2C+A">Alberto Toccafondi</a>, 
<a href="/search/cs?searchtype=author&query=Di+Renzo%2C+M">Marco Di Renzo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for journal publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item975">[975]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07113" title="Abstract">arXiv:2311.07113</a> (replaced) [<a href="/pdf/2311.07113" title="Download PDF">pdf</a>, <a href="/format/2311.07113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpectralGPT: Spectral Foundation Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+D">Danfeng Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jing Yao</a>, 
<a href="/search/cs?searchtype=author&query=Yokoya%2C+N">Naoto Yokoya</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Ghamisi%2C+P">Pedram Ghamisi</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiuping Jia</a>, 
<a href="/search/cs?searchtype=author&query=Plaza%2C+A">Antonio Plaza</a>, 
<a href="/search/cs?searchtype=author&query=Paolo%2C+G">Gamba Paolo</a>, 
<a href="/search/cs?searchtype=author&query=Benediktsson%2C+J+A">Jon Atli Benediktsson</a>, 
<a href="/search/cs?searchtype=author&query=Chanussot%2C+J">Jocelyn Chanussot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item976">[976]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07363" title="Abstract">arXiv:2311.07363</a> (replaced) [<a href="/pdf/2311.07363" title="Download PDF">pdf</a>, <a href="/format/2311.07363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient bandwidth extension of musical signals using a differentiable  harmonic plus noise model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grumiaux%2C+P">Pierre-Amaury Grumiaux</a>, 
<a href="/search/cs?searchtype=author&query=Lagrange%2C+M">Mathieu Lagrange</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepting for publication in EURASIP Journal on Audio, Speech, and Music Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item977">[977]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07590" title="Abstract">arXiv:2311.07590</a> (replaced) [<a href="/pdf/2311.07590" title="Download PDF">pdf</a>, <a href="/format/2311.07590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Technical Report: Large Language Models can Strategically Deceive their  Users when Put Under Pressure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scheurer%2C+J">J&#xe9;r&#xe9;my Scheurer</a>, 
<a href="/search/cs?searchtype=author&query=Balesni%2C+M">Mikita Balesni</a>, 
<a href="/search/cs?searchtype=author&query=Hobbhahn%2C+M">Marius Hobbhahn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item978">[978]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08172" title="Abstract">arXiv:2311.08172</a> (replaced) [<a href="/pdf/2311.08172" title="Download PDF">pdf</a>, <a href="/format/2311.08172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision-Language Instruction Tuning: A Review and Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yixiao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dian Li</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item979">[979]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08431" title="Abstract">arXiv:2311.08431</a> (replaced) [<a href="/pdf/2311.08431" title="Download PDF">pdf</a>, <a href="/ps/2311.08431" title="Download PostScript">ps</a>, <a href="/format/2311.08431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assuring the emotional and cultural intelligence of intelligent software  systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belle%2C+A+B">Alvine B. Belle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item980">[980]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09247" title="Abstract">arXiv:2311.09247</a> (replaced) [<a href="/pdf/2311.09247" title="Download PDF">pdf</a>, <a href="/format/2311.09247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing Humans, GPT-4, and GPT-4V On Abstraction and Reasoning Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+M">Melanie Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Palmarini%2C+A+B">Alessandro B. Palmarini</a>, 
<a href="/search/cs?searchtype=author&query=Moskvichev%2C+A">Arseny Moskvichev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Corrected typo in email addresses
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item981">[981]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09257" title="Abstract">arXiv:2311.09257</a> (replaced) [<a href="/pdf/2311.09257" title="Download PDF">pdf</a>, <a href="/format/2311.09257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UFOGen: You Forward Once Large Scale Text-to-Image Generation via  Diffusion GANs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yanwu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zhisheng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+T">Tingbo Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item982">[982]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09459" title="Abstract">arXiv:2311.09459</a> (replaced) [<a href="/pdf/2311.09459" title="Download PDF">pdf</a>, <a href="/format/2311.09459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Convex Optimal Value Functions For POSGs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cunha%2C+R+F">Rafael F. Cunha</a>, 
<a href="/search/cs?searchtype=author&query=Castellini%2C+J">Jacopo Castellini</a>, 
<a href="/search/cs?searchtype=author&query=Peralez%2C+J">Johan Peralez</a>, 
<a href="/search/cs?searchtype=author&query=Dibangoye%2C+J+S">Jilles S. Dibangoye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Currently under review at JAIR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
</div>
</dd>
<dt><a name="item983">[983]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09680" title="Abstract">arXiv:2311.09680</a> (replaced) [<a href="/pdf/2311.09680" title="Download PDF">pdf</a>, <a href="/format/2311.09680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trustworthy Large Models in Vision: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Ziyan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Li Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item984">[984]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09740" title="Abstract">arXiv:2311.09740</a> (replaced) [<a href="/pdf/2311.09740" title="Download PDF">pdf</a>, <a href="/format/2311.09740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Redefining Super-Resolution: Fine-mesh PDE predictions without classical  simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Sarkar%2C+R+K">Rajat Kumar Sarkar</a>, 
<a href="/search/physics?searchtype=author&query=Majumdar%2C+R">Ritam Majumdar</a>, 
<a href="/search/physics?searchtype=author&query=Jadhav%2C+V">Vishal Jadhav</a>, 
<a href="/search/physics?searchtype=author&query=Sakhinana%2C+S+S">Sagar Srinivas Sakhinana</a>, 
<a href="/search/physics?searchtype=author&query=Runkana%2C+V">Venkataramana Runkana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Machine Learning and the Physical Sciences Workshop, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item985">[985]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10093" title="Abstract">arXiv:2311.10093</a> (replaced) [<a href="/pdf/2311.10093" title="Download PDF">pdf</a>, <a href="/format/2311.10093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Chosen One: Consistent Characters in Text-to-Image Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Avrahami%2C+O">Omri Avrahami</a>, 
<a href="/search/cs?searchtype=author&query=Hertz%2C+A">Amir Hertz</a>, 
<a href="/search/cs?searchtype=author&query=Vinker%2C+Y">Yael Vinker</a>, 
<a href="/search/cs?searchtype=author&query=Arar%2C+M">Moab Arar</a>, 
<a href="/search/cs?searchtype=author&query=Fruchter%2C+S">Shlomi Fruchter</a>, 
<a href="/search/cs?searchtype=author&query=Fried%2C+O">Ohad Fried</a>, 
<a href="/search/cs?searchtype=author&query=Cohen-Or%2C+D">Daniel Cohen-Or</a>, 
<a href="/search/cs?searchtype=author&query=Lischinski%2C+D">Dani Lischinski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page is available at <a href="https://omriavrahami.com/the-chosen-one">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item986">[986]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10321" title="Abstract">arXiv:2311.10321</a> (replaced) [<a href="/pdf/2311.10321" title="Download PDF">pdf</a>, <a href="/ps/2311.10321" title="Download PostScript">ps</a>, <a href="/format/2311.10321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Machine Learning-based Quantitative Hyperspectral Image Guidance  for Brain Tumor Resection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Black%2C+D">David Black</a>, 
<a href="/search/q-bio?searchtype=author&query=Byrne%2C+D">Declan Byrne</a>, 
<a href="/search/q-bio?searchtype=author&query=Walke%2C+A">Anna Walke</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+S">Sidong Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Di+leva%2C+A">Antonio Di leva</a>, 
<a href="/search/q-bio?searchtype=author&query=Kaneko%2C+S">Sadahiro Kaneko</a>, 
<a href="/search/q-bio?searchtype=author&query=Stummer%2C+W">Walter Stummer</a>, 
<a href="/search/q-bio?searchtype=author&query=Salcudean%2C+S">Septimiu Salcudean</a>, 
<a href="/search/q-bio?searchtype=author&query=Molina%2C+E+S">Eric Suero Molina</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Tissues and Organs (q-bio.TO)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item987">[987]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10522" title="Abstract">arXiv:2311.10522</a> (replaced) [<a href="/pdf/2311.10522" title="Download PDF">pdf</a>, <a href="/format/2311.10522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Object Coherence in Layout-to-Image Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yibin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weizhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jianwei Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Cheng Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item988">[988]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10727" title="Abstract">arXiv:2311.10727</a> (replaced) [<a href="/pdf/2311.10727" title="Download PDF">pdf</a>, <a href="/ps/2311.10727" title="Download PostScript">ps</a>, <a href="/format/2311.10727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling the Potential of Big Data Analytics for Transforming Higher  Education in Bangladesh; Needs, Prospects, and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+S+A">Sabbir Ahmed Chowdhury</a> (1), 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+A">Md Aminul Islam</a> (2), 
<a href="/search/cs?searchtype=author&query=Kamal%2C+M+A">Mostafa Azad Kamal</a> (3),  ((1) School of Education and Social Sciences, University of the West of Scotland, IER, University of Dhaka (2) School of Engineering, Computing and Mathematics, Oxford Brookes University, School of Computing and Technologies, University of Gloucestershire, UK (3) School of Business, Bangladesh Open University, Gazipur)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item989">[989]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10902" title="Abstract">arXiv:2311.10902</a> (replaced) [<a href="/pdf/2311.10902" title="Download PDF">pdf</a>, <a href="/format/2311.10902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OCT2Confocal: 3D CycleGAN based Translation of Retinal OCT Images to  Confocal Microscopy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tian%2C+X">Xin Tian</a>, 
<a href="/search/eess?searchtype=author&query=Anantrasirichai%2C+N">Nantheera Anantrasirichai</a>, 
<a href="/search/eess?searchtype=author&query=Nicholson%2C+L">Lindsay Nicholson</a>, 
<a href="/search/eess?searchtype=author&query=Achim%2C+A">Alin Achim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item990">[990]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10934" title="Abstract">arXiv:2311.10934</a> (replaced) [<a href="/pdf/2311.10934" title="Download PDF">pdf</a>, <a href="/format/2311.10934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Case Repositories: Towards Case-Based Reasoning for AI Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+K+J+K">K. J. Kevin Feng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q+Z">Quan Ze Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheong%2C+I">Inyoung Cheong</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+K">King Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A+X">Amy X. Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MP2 workshop @ NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item991">[991]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11178" title="Abstract">arXiv:2311.11178</a> (replaced) [<a href="/pdf/2311.11178" title="Download PDF">pdf</a>, <a href="/format/2311.11178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Prompt Learning in Vision Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bang%2C+J">Jihwan Bang</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+S">Sumyeong Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jae-Gil Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> version 1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item992">[992]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11225" title="Abstract">arXiv:2311.11225</a> (replaced) [<a href="/pdf/2311.11225" title="Download PDF">pdf</a>, <a href="/format/2311.11225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TextGuard: Provable Defense against Backdoor Attacks on Text  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pei%2C+H">Hengzhi Pei</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jinyuan Jia</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wenbo Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dawn Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NDSS Symposium 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item993">[993]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11235" title="Abstract">arXiv:2311.11235</a> (replaced) [<a href="/pdf/2311.11235" title="Download PDF">pdf</a>, <a href="/format/2311.11235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unraveling the &quot;Anomaly&quot; in Time Series Anomaly Detection: A  Self-supervised Tri-domain Solution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuting Sun</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+G">Guansong Pang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+G">Guanhua Ye</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xia Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongzhi Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is submitted to IEEE International Conference on Data Engineering (ICDE) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item994">[994]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11317" title="Abstract">arXiv:2311.11317</a> (replaced) [<a href="/pdf/2311.11317" title="Download PDF">pdf</a>, <a href="/format/2311.11317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discrete approximations of Gaussian smoothing and Gaussian derivatives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lindeberg%2C+T">Tony Lindeberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 34 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item995">[995]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11435" title="Abstract">arXiv:2311.11435</a> (replaced) [<a href="/pdf/2311.11435" title="Download PDF">pdf</a>, <a href="/format/2311.11435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling Public Perceptions: Machine Learning-Based Sentiment Analysis  of COVID-19 Vaccines in India
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+M">Milind Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Kaushik%2C+A">Abhishek Kaushik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item996">[996]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11509" title="Abstract">arXiv:2311.11509</a> (replaced) [<a href="/pdf/2311.11509" title="Download PDF">pdf</a>, <a href="/ps/2311.11509" title="Download PostScript">ps</a>, <a href="/format/2311.11509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Token-Level Adversarial Prompt Detection Based on Perplexity Measures  and Contextual Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhengmian Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Gang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+S">Saayan Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruiyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+T">Tong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Heng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Swaminathan%2C+V">Viswanathan Swaminathan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item997">[997]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11587" title="Abstract">arXiv:2311.11587</a> (replaced) [<a href="/pdf/2311.11587" title="Download PDF">pdf</a>, <a href="/ps/2311.11587" title="Download PostScript">ps</a>, <a href="/format/2311.11587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AKConv: Convolutional Kernel with Arbitrary Sampled Shapes and Arbitrary  Number of Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yingze Song</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+T">Tingting Song</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Degang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yichen Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liming Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item998">[998]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11602" title="Abstract">arXiv:2311.11602</a> (replaced) [<a href="/pdf/2311.11602" title="Download PDF">pdf</a>, <a href="/format/2311.11602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-In-Single-Out Network for Video Frame Interpolation without  Optical Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaemin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+M">Minseok Seo</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sangwoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Hyobin Park</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+D">Dong-Geol Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/J911/MISO-VFI">this https URL</a> ; Project Page: <a href="https://j911.github.io/MISO-VFI">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item999">[999]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11810" title="Abstract">arXiv:2311.11810</a> (replaced) [<a href="/pdf/2311.11810" title="Download PDF">pdf</a>, <a href="/format/2311.11810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DocPedia: Unleashing the Power of Large Multimodal Model in the  Frequency Domain for Versatile Document Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+H">Hao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wengang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Houqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Can Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1000">[1000]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11860" title="Abstract">arXiv:2311.11860</a> (replaced) [<a href="/pdf/2311.11860" title="Download PDF">pdf</a>, <a href="/format/2311.11860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LION : Empowering Multimodal Large Language Model with Dual-Level Visual  Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Gongwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Leyang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+R">Rui Shao</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+X">Xiang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+L">Liqiang Nie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report. Project page: <a href="https://rshaojimmy.github.io/Projects/JiuTian-LION">this https URL</a> Code: <a href="https://github.com/rshaojimmy/JiuTian">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1001">[1001]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11913" title="Abstract">arXiv:2311.11913</a> (replaced) [<a href="/pdf/2311.11913" title="Download PDF">pdf</a>, <a href="/format/2311.11913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Calibration of Market Simulations using Neural Density Estimators  and Embedding Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stillman%2C+N+R">Namid R. Stillman</a>, 
<a href="/search/cs?searchtype=author&query=Baggott%2C+R">Rory Baggott</a>, 
<a href="/search/cs?searchtype=author&query=Lyon%2C+J">Justin Lyon</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianfei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Dingqiu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Vytelingum%2C+P">Perukrishnen Vytelingum</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4th ACM International Conference on AI in Finance (ICAIF 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Finance (q-fin.CP); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1002">[1002]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12050" title="Abstract">arXiv:2311.12050</a> (replaced) [<a href="/pdf/2311.12050" title="Download PDF">pdf</a>, <a href="/format/2311.12050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D-GOI: 3D GAN Omni-Inversion for Multifaceted and Multi-object Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoran Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Long Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yong Liao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lechao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yanbin Hao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pengyuan Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1003">[1003]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12092" title="Abstract">arXiv:2311.12092</a> (replaced) [<a href="/pdf/2311.12092" title="Download PDF">pdf</a>, <a href="/format/2311.12092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concept Sliders: LoRA Adaptors for Precise Control in Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gandikota%2C+R">Rohit Gandikota</a>, 
<a href="/search/cs?searchtype=author&query=Materzynska%2C+J">Joanna Materzynska</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tingrui Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Torralba%2C+A">Antonio Torralba</a>, 
<a href="/search/cs?searchtype=author&query=Bau%2C+D">David Bau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1004">[1004]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12144" title="Abstract">arXiv:2311.12144</a> (replaced) [<a href="/pdf/2311.12144" title="Download PDF">pdf</a>, <a href="/ps/2311.12144" title="Download PostScript">ps</a>, <a href="/format/2311.12144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applications of Large Scale Foundation Models for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yue Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhu Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages. arXiv admin note: text overlap with <a href="/abs/2304.03589">arXiv:2304.03589</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1005">[1005]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12386" title="Abstract">arXiv:2311.12386</a> (replaced) [<a href="/pdf/2311.12386" title="Download PDF">pdf</a>, <a href="/format/2311.12386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Point, Segment and Count: A Generalized Framework for Object Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhizhong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+M">Mingliang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+H">Hongming Shan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fix typos
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1006">[1006]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12454" title="Abstract">arXiv:2311.12454</a> (replaced) [<a href="/pdf/2311.12454" title="Download PDF">pdf</a>, <a href="/format/2311.12454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HierSpeech++: Bridging the Gap between Semantic and Acoustic  Representation of Speech by Hierarchical Variational Inference for Zero-shot  Speech Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sang-Hoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+H">Ha-Yeong Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seung-Bin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seong-Whan Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures, 12 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1007">[1007]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12530" title="Abstract">arXiv:2311.12530</a> (replaced) [<a href="/pdf/2311.12530" title="Download PDF">pdf</a>, <a href="/format/2311.12530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An efficient likelihood-free Bayesian inference method based on  sequential neural posterior estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Xiong%2C+Y">Yifei Xiong</a>, 
<a href="/search/stat?searchtype=author&query=Yang%2C+X">Xiliang Yang</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+S">Sanguo Zhang</a>, 
<a href="/search/stat?searchtype=author&query=He%2C+Z">Zhijian He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item1008">[1008]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12570" title="Abstract">arXiv:2311.12570</a> (replaced) [<a href="/pdf/2311.12570" title="Download PDF">pdf</a>, <a href="/format/2311.12570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BEND: Benchmarking DNA Language Models on biologically meaningful tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Marin%2C+F+I">Frederikke Isa Marin</a>, 
<a href="/search/q-bio?searchtype=author&query=Teufel%2C+F">Felix Teufel</a>, 
<a href="/search/q-bio?searchtype=author&query=Horlacher%2C+M">Marc Horlacher</a>, 
<a href="/search/q-bio?searchtype=author&query=Madsen%2C+D">Dennis Madsen</a>, 
<a href="/search/q-bio?searchtype=author&query=Pultz%2C+D">Dennis Pultz</a>, 
<a href="/search/q-bio?searchtype=author&query=Winther%2C+O">Ole Winther</a>, 
<a href="/search/q-bio?searchtype=author&query=Boomsma%2C+W">Wouter Boomsma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 1 figure, 3 tables, code available at <a href="https://github.com/frederikkemarin/BEND">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1009">[1009]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12612" title="Abstract">arXiv:2311.12612</a> (replaced) [<a href="/pdf/2311.12612" title="Download PDF">pdf</a>, <a href="/ps/2311.12612" title="Download PostScript">ps</a>, <a href="/format/2311.12612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Type Of Upper And Lower Bounds On Right-Tail Probabilities Of  Continuous Random Variables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zlatanov%2C+N">Nikola Zlatanov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Minor typos corrected v2
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1010">[1010]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12961" title="Abstract">arXiv:2311.12961</a> (replaced) [<a href="/pdf/2311.12961" title="Download PDF">pdf</a>, <a href="/format/2311.12961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demystifying the buzzword behind Digital Twin: a novel generic  evaluation model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Araghi%2C+S+N">Sina Namaki Araghi</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+A">Arkopaul Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Karray%2C+M+H">Mohamed Hedi Karray</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a draft of the article that subject to future change and correction
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item1011">[1011]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12986" title="Abstract">arXiv:2311.12986</a> (replaced) [<a href="/pdf/2311.12986" title="Download PDF">pdf</a>, <a href="/format/2311.12986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Graph Attention Autoencoder for Attributed Networks using  K-means Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bekkaira%2C+A">Abdelfateh Bekkaira</a>, 
<a href="/search/cs?searchtype=author&query=Bellaouar%2C+S">Slimane Bellaouar</a>, 
<a href="/search/cs?searchtype=author&query=Oulad-Naoui%2C+S">Slimane Oulad-Naoui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1012">[1012]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13057" title="Abstract">arXiv:2311.13057</a> (replaced) [<a href="/pdf/2311.13057" title="Download PDF">pdf</a>, <a href="/format/2311.13057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The HaLLMark Effect: Supporting Provenance and Transparent Use of Large  Language Models in Writing through Interactive Visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoque%2C+M+N">Md Naimul Hoque</a>, 
<a href="/search/cs?searchtype=author&query=Mashiat%2C+T">Tasfia Mashiat</a>, 
<a href="/search/cs?searchtype=author&query=Ghai%2C+B">Bhavya Ghai</a>, 
<a href="/search/cs?searchtype=author&query=Shelton%2C+C">Cecilia Shelton</a>, 
<a href="/search/cs?searchtype=author&query=Chevalier%2C+F">Fanny Chevalier</a>, 
<a href="/search/cs?searchtype=author&query=Kraus%2C+K">Kari Kraus</a>, 
<a href="/search/cs?searchtype=author&query=Elmqvist%2C+N">Niklas Elmqvist</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item1013">[1013]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13063" title="Abstract">arXiv:2311.13063</a> (replaced) [<a href="/pdf/2311.13063" title="Download PDF">pdf</a>, <a href="/format/2311.13063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Classification to Clinical Insights: Towards Analyzing and  Reasoning About Mobile and Behavioral Health Data With Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Englhardt%2C+Z">Zachary Englhardt</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chengqian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Morris%2C+M+E">Margaret E. Morris</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X+%22">Xuhai &quot;Orson&quot; Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Chun-Cheng Chang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+L">Lianhui Qin</a>, 
<a href="/search/cs?searchtype=author&query=McDuff%2C+D">Daniel McDuff</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+S">Shwetak Patel</a>, 
<a href="/search/cs?searchtype=author&query=Iyer%2C+V">Vikram Iyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1014">[1014]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13155" title="Abstract">arXiv:2311.13155</a> (replaced) [<a href="/pdf/2311.13155" title="Download PDF">pdf</a>, <a href="/format/2311.13155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A threshold-type algorithm to the gradient flow of the Canham-Helfrich  functional
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ishi%2C+K">Katsuyuki Ishi</a>, 
<a href="/search/math?searchtype=author&query=Kohsaka%2C+Y">Yoshihito Kohsaka</a>, 
<a href="/search/math?searchtype=author&query=Miyake%2C+N">Nobuhito Miyake</a>, 
<a href="/search/math?searchtype=author&query=Sakakibara%2C+K">Koya Sakakibara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item1015">[1015]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13265" title="Abstract">arXiv:2311.13265</a> (replaced) [<a href="/pdf/2311.13265" title="Download PDF">pdf</a>, <a href="/format/2311.13265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved identification accuracy in equation learning via comprehensive  $\boldsymbol{R^2}$-elimination and Bayesian model selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Nickelsen%2C+D">Daniel Nickelsen</a>, 
<a href="/search/stat?searchtype=author&query=Bah%2C+B">Bubacarr Bah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages main text and 11 pages appendix, Published in TMLR (<a href="https://openreview.net/forum?id=0ck7hJ8EVC">this https URL</a>)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transactions on Machine Learning Research (TMLR), 2835-8856
  (11/2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item1016">[1016]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13372" title="Abstract">arXiv:2311.13372</a> (replaced) [<a href="/pdf/2311.13372" title="Download PDF">pdf</a>, <a href="/ps/2311.13372" title="Download PostScript">ps</a>, <a href="/format/2311.13372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MRGazer: Decoding Eye Gaze Points from Functional Magnetic Resonance  Imaging in Individual Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiuwen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Rongjie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jie Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+B">Bensheng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoxiao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item1017">[1017]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13373" title="Abstract">arXiv:2311.13373</a> (replaced) [<a href="/pdf/2311.13373" title="Download PDF">pdf</a>, <a href="/format/2311.13373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model is a Good Policy Teacher for Training Reinforcement  Learning Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zihao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Bin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chenyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1018">[1018]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13404" title="Abstract">arXiv:2311.13404</a> (replaced) [<a href="/e-print/2311.13404" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Animatable 3D Gaussians for High-fidelity Synthesis of Human Motions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+K">Keyang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+T">Tianjia Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kun Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Some experiment data is wrong. The expression of the paper in introduction and abstract is incorrect. Some graphs have inappropriate descriptions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item1019">[1019]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13534" title="Abstract">arXiv:2311.13534</a> (replaced) [<a href="/pdf/2311.13534" title="Download PDF">pdf</a>, <a href="/format/2311.13534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LM-Cocktail: Resilient Tuning of Language Models via Model Merging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+S">Shitao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peitian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+X">Xingrun Xing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item1020">[1020]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13580" title="Abstract">arXiv:2311.13580</a> (replaced) [<a href="/pdf/2311.13580" title="Download PDF">pdf</a>, <a href="/format/2311.13580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $&#x3c3;$-PCA: a unified neural model for linear and nonlinear principal  component analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kanavati%2C+F">Fahdi Kanavati</a>, 
<a href="/search/cs?searchtype=author&query=Katsnith%2C+L">Lucy Katsnith</a>, 
<a href="/search/cs?searchtype=author&query=Tsuneki%2C+M">Masayuki Tsuneki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fixed typo in equation 38
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1021">[1021]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13721" title="Abstract">arXiv:2311.13721</a> (replaced) [<a href="/pdf/2311.13721" title="Download PDF">pdf</a>, <a href="/format/2311.13721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nova$^+$: Generative Language Models for Binaries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+N">Nan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengxiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kevin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiangzhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+L">Lin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangyu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1022">[1022]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13770" title="Abstract">arXiv:2311.13770</a> (replaced) [<a href="/pdf/2311.13770" title="Download PDF">pdf</a>, <a href="/format/2311.13770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Archiving Body Movements: Collective Generation of Chinese Calligraphy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A+L">Aven Le Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jiayi Ye</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianchen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item1023">[1023]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13811" title="Abstract">arXiv:2311.13811</a> (replaced) [<a href="/pdf/2311.13811" title="Download PDF">pdf</a>, <a href="/ps/2311.13811" title="Download PostScript">ps</a>, <a href="/format/2311.13811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Education distillation:getting student models to learn in shcools
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+L">Ling Feng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Danyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianhao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+X">Xuliang Duan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1024">[1024]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13959" title="Abstract">arXiv:2311.13959</a> (replaced) [<a href="/pdf/2311.13959" title="Download PDF">pdf</a>, <a href="/format/2311.13959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RankFeat&amp;RankWeight: Rank-1 Feature/Weight Removal for  Out-of-distribution Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yue Song</a>, 
<a href="/search/cs?searchtype=author&query=Sebe%2C+N">Nicu Sebe</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to T-PAMI. arXiv admin note: substantial text overlap with <a href="/abs/2209.08590">arXiv:2209.08590</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1025">[1025]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13994" title="Abstract">arXiv:2311.13994</a> (replaced) [<a href="/pdf/2311.13994" title="Download PDF">pdf</a>, <a href="/format/2311.13994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient Distributed Nash Equilibrium Seeking with Compressed and  Event-triggered Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xiaomeng Chen</a>, 
<a href="/search/eess?searchtype=author&query=Huo%2C+W">Wei Huo</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Y">Yuchi Wu</a>, 
<a href="/search/eess?searchtype=author&query=Dey%2C+S">Subhrakanti Dey</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+L">Ling Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item1026">[1026]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14078" title="Abstract">arXiv:2311.14078</a> (replaced) [<a href="/pdf/2311.14078" title="Download PDF">pdf</a>, <a href="/ps/2311.14078" title="Download PostScript">ps</a>, <a href="/format/2311.14078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine learning-based decentralized TDMA for VLC IoT networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Makvandi%2C+A">Armin Makvandi</a>, 
<a href="/search/cs?searchtype=author&query=Kavian%2C+Y+S">Yousef Seifi Kavian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to a journal for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1027">[1027]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14084" title="Abstract">arXiv:2311.14084</a> (replaced) [<a href="/pdf/2311.14084" title="Download PDF">pdf</a>, <a href="/format/2311.14084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-Generated Images Introduce Invisible Relevance Bias to Text-Image  Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shicheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+D">Danyang Hou</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+L">Liang Pang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jingcheng Deng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Huawei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1028">[1028]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14118" title="Abstract">arXiv:2311.14118</a> (replaced) [<a href="/pdf/2311.14118" title="Download PDF">pdf</a>, <a href="/format/2311.14118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On The Impact of Replacing Private Cars with Autonomous Shuttles: An  Agent-Based Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bogdoll%2C+D">Daniel Bogdoll</a>, 
<a href="/search/cs?searchtype=author&query=Karsch%2C+L">Louis Karsch</a>, 
<a href="/search/cs?searchtype=author&query=Amritzer%2C+J">Jennifer Amritzer</a>, 
<a href="/search/cs?searchtype=author&query=Z%C3%B6llner%2C+J+M">J. Marius Z&#xf6;llner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Daniel Bogdoll and Louis Karsch contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1029">[1029]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14327" title="Abstract">arXiv:2311.14327</a> (replaced) [<a href="/pdf/2311.14327" title="Download PDF">pdf</a>, <a href="/format/2311.14327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> C-ITS Environment Modeling and Attack Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jaewoong Choi</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M+G">Min Geun Song</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hyosun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Sagong%2C+C">Chaeyeon Sagong</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sangbeom Park</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaesung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+J+D">Jeong Do Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H+K">Huy Kang Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Korean Language, 14 Figures, 15 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1030">[1030]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14342" title="Abstract">arXiv:2311.14342</a> (replaced) [<a href="/pdf/2311.14342" title="Download PDF">pdf</a>, <a href="/format/2311.14342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-based Attack Graph Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sangbeom Park</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaesung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+J+D">Jeong Do Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M+G">Min Geun Song</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hyosun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jaewoong Choi</a>, 
<a href="/search/cs?searchtype=author&query=Sagong%2C+C">Chaeyeon Sagong</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H+K">Huy Kang Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Korean Language, 8 Figures, 14 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1031">[1031]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14353" title="Abstract">arXiv:2311.14353</a> (replaced) [<a href="/pdf/2311.14353" title="Download PDF">pdf</a>, <a href="/format/2311.14353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Average Token Delay: A Duration-aware Latency Metric for Simultaneous  Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kano%2C+Y">Yasumasa Kano</a>, 
<a href="/search/cs?searchtype=author&query=Sudoh%2C+K">Katsuhito Sudoh</a>, 
<a href="/search/cs?searchtype=author&query=Nakamura%2C+S">Satoshi Nakamura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of the paper (doi: 10.21437/Interspeech.2023-933) which appeared in INTERSPEECH 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1032">[1032]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14412" title="Abstract">arXiv:2311.14412</a> (replaced) [<a href="/pdf/2311.14412" title="Download PDF">pdf</a>, <a href="/ps/2311.14412" title="Download PostScript">ps</a>, <a href="/format/2311.14412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparison of PDF Projection with Normalizing Flows and SurVAE
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baggenstoss%2C+P+M">Paul M. Baggenstoss</a>, 
<a href="/search/cs?searchtype=author&query=Govaers%2C+F">Felix Govaers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item1033">[1033]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14468" title="Abstract">arXiv:2311.14468</a> (replaced) [<a href="/pdf/2311.14468" title="Download PDF">pdf</a>, <a href="/format/2311.14468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Gradient Estimation via Adaptive Sampling and Importance  Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sala%C3%BCn%2C+C">Corentin Sala&#xfc;n</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xingchang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Georgiev%2C+I">Iliyan Georgiev</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+N+J">Niloy J. Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+G">Gurprit Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1034">[1034]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14496" title="Abstract">arXiv:2311.14496</a> (replaced) [<a href="/pdf/2311.14496" title="Download PDF">pdf</a>, <a href="/format/2311.14496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RTPS Attack Dataset Description
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+D+Y">Dong Young Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dongsung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yuchan Song</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+G+M">Gang Min Kim</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M+G">Min Geun Song</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+J+D">Jeong Do Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H+K">Huy Kang Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This manuscript is written in Korean. You can download our dataset in our lab: <a href="https://ocslab.hksecurity.net/Datasets/rtps-attack-dataset">this https URL</a> We welcome your comments or feedback. Contact INFO: Dong Young Kim (klgh1256@korea.ac.kr), Huy Kang Kim (cenda@korea.ac.kr)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1035">[1035]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14650" title="Abstract">arXiv:2311.14650</a> (replaced) [<a href="/pdf/2311.14650" title="Download PDF">pdf</a>, <a href="/format/2311.14650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GVEL: Fast Graph Loading in Edgelist and Compressed Sparse Row (CSR)  formats
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sahu%2C+S">Subhajit Sahu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item611">Cross-lists</a></li>
<li><a href="#item693">Replacements</a></li>
</ul>
<small>[ total of 1035 entries:  <b>1-1035</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2311">2311</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
