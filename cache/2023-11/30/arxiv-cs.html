<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Tue 28 Nov 23  to  Wed 29 Nov 23, announced Thu, 30 Nov 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item358">Cross-lists</a></li>
<li><a href="#item398">Replacements</a></li>
</ul>
<small>[ total of 617 entries:  <b>1-617</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Thu, 30 Nov 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17068" title="Abstract">arXiv:2311.17068</a> [<a href="/pdf/2311.17068" title="Download PDF">pdf</a>, <a href="/format/2311.17068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep convolutional encoder-decoder hierarchical neural networks for  conjugate heat transfer surrogate modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ebbs-Picken%2C+T">Takiah Ebbs-Picken</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+D+A">David A. Romero</a>, 
<a href="/search/cs?searchtype=author&query=Da+Silva%2C+C+M">Carlos M. Da Silva</a>, 
<a href="/search/cs?searchtype=author&query=Amon%2C+C+H">Cristina H. Amon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Conjugate heat transfer (CHT) models are vital for the design of many
engineering systems. However, high-fidelity CHT models are computationally
intensive, which limits their use in applications such as design optimization,
where hundreds to thousands of model evaluations are required. In this work, we
develop a modular deep convolutional encoder-decoder hierarchical (DeepEDH)
neural network, a novel deep-learning-based surrogate modeling methodology for
computationally intensive CHT models. Leveraging convective temperature
dependencies, we propose a two-stage temperature prediction architecture that
couples velocity and temperature models. The proposed DeepEDH methodology is
demonstrated by modeling the pressure, velocity, and temperature fields for a
liquid-cooled cold-plate-based battery thermal management system with variable
channel geometry. A computational model of the cold plate is developed and
solved using the finite element method (FEM), generating a dataset of 1,500
simulations. The FEM results are transformed and scaled from unstructured to
structured, image-like meshes to create training and test datasets. The DeepEDH
methodology's performance is examined in relation to data scaling, training
dataset size, and network depth. Our performance analysis covers the impact of
the novel architecture, separate field models, output geometry masks,
multi-stage temperature models, and optimizations of the hyperparameters and
architecture. Furthermore, we quantify the influence of the CHT thermal
boundary condition on surrogate model performance, highlighting improved
temperature model performance with higher heat fluxes. Compared to other deep
learning neural network surrogate models, such as U-Net and DenseED, the
proposed DeepEDH methodology for CHT models exhibits up to a 65% enhancement in
the coefficient of determination ($R^{2}$).
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17072" title="Abstract">arXiv:2311.17072</a> [<a href="/pdf/2311.17072" title="Download PDF">pdf</a>, <a href="/format/2311.17072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IG Captioner: Information Gain Captioners are Strong Zero-shot  Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chenglin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+S">Siyuan Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yuan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Tao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yuille%2C+A">Alan Yuille</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiahui Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">Generative training has been demonstrated to be powerful for building
visual-language models. However, on zero-shot discriminative benchmarks, there
is still a performance gap between models trained with generative and
discriminative objectives. In this paper, we aim to narrow this gap by
improving the efficacy of generative training on classification tasks, without
any finetuning processes or additional modules.
<br />Specifically, we focus on narrowing the gap between the generative captioner
and the CLIP classifier. We begin by analysing the predictions made by the
captioner and classifier and observe that the caption generation inherits the
distribution bias from the language model trained with pure text modality,
making it less grounded on the visual signal. To tackle this problem, we
redesign the scoring objective for the captioner to alleviate the
distributional bias and focus on measuring the gain of information brought by
the visual inputs. We further design a generative training objective to match
the evaluation objective. We name our model trained and evaluated from the
novel procedures as Information Gain (IG) captioner. We pretrain the models on
the public Laion-5B dataset and perform a series of discriminative evaluations.
For the zero-shot classification on ImageNet, IG captioner achieves $&gt; 18\%$
improvements over the standard captioner, achieving comparable performances
with the CLIP classifier. IG captioner also demonstrated strong performance on
zero-shot image-text retrieval tasks on MSCOCO and Flickr30K. We hope this
paper inspires further research towards unifying generative and discriminative
training procedures for visual-language models.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17073" title="Abstract">arXiv:2311.17073</a> [<a href="/pdf/2311.17073" title="Download PDF">pdf</a>, <a href="/format/2311.17073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Practical Layout-Aware Analog/Mixed-Signal Design Automation with  Bayesian Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Budak%2C+A+F">Ahmet F. Budak</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Keren Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+D+Z">David Z. Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 42nd International Conference on Computer-Aided Design (ICCAD 2023); 8 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">The high simulation cost has been a bottleneck of practical
analog/mixed-signal design automation. Many learning-based algorithms require
thousands of simulated data points, which is impractical for expensive to
simulate circuits. We propose a learning-based algorithm that can be trained
using a small amount of data and, therefore, scalable to tasks with expensive
simulations. Our efficient algorithm solves the post-layout performance
optimization problem where simulations are known to be expensive. Our
comprehensive study also solves the schematic-level sizing problem. For
efficient optimization, we utilize Bayesian Neural Networks as a regression
model to approximate circuit performance. For layout-aware optimization, we
handle the problem as a multi-fidelity optimization problem and improve
efficiency by exploiting the correlations from cheaper evaluations. We present
three test cases to demonstrate the efficiency of our algorithms. Our tests
prove that the proposed approach is more efficient than conventional baselines
and state-of-the-art algorithms.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17074" title="Abstract">arXiv:2311.17074</a> [<a href="/pdf/2311.17074" title="Download PDF">pdf</a>, <a href="/format/2311.17074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Learning of Whole and Component-Based Semantic  Representations for Person Re-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Siyuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yifan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Kathirvel%2C+R+P">Ram Prabhakar Kathirvel</a>, 
<a href="/search/cs?searchtype=author&query=Chellappa%2C+R">Rama Chellappa</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+C+P">Chun Pong Lau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Interactive Segmentation Models (ISMs) like the Segment Anything Model have
significantly improved various computer vision tasks, yet their application to
Person Re-identification (ReID) remains limited. On the other hand, existing
semantic pre-training models for ReID often have limitations like predefined
parsing ranges or coarse semantics. Additionally, ReID and Clothes-Changing
ReID (CC-ReID) are usually treated separately due to their different domains.
This paper investigates whether utilizing precise human-centric semantic
representation can boost the ReID performance and improve the generalization
among various ReID tasks. We propose SemReID, a self-supervised ReID model that
leverages ISMs for adaptive part-based semantic extraction, contributing to the
improvement of ReID performance. SemReID additionally refines its semantic
representation through techniques such as image masking and KoLeo
regularization. Evaluation across three types of ReID datasets -- standard
ReID, CC-ReID, and unconstrained ReID -- demonstrates superior performance
compared to state-of-the-art methods. In addition, recognizing the scarcity of
large person datasets with fine-grained semantics, we introduce the novel
LUPerson-Part dataset to assist ReID methods in acquiring the fine-grained part
semantics for robust performance.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17076" title="Abstract">arXiv:2311.17076</a> [<a href="/pdf/2311.17076" title="Download PDF">pdf</a>, <a href="/format/2311.17076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Chain-of-Thought Prompting for Large Multimodal Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mitra%2C+C">Chancharik Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Brandon Huang</a>, 
<a href="/search/cs?searchtype=author&query=Darrell%2C+T">Trevor Darrell</a>, 
<a href="/search/cs?searchtype=author&query=Herzig%2C+R">Roei Herzig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">The combination of strong visual backbones and Large Language Model (LLM)
reasoning has led to Large Multimodal Models (LMMs) becoming the current
standard for a wide range of vision and language (VL) tasks. However, recent
research has shown that even the most advanced LMMs still struggle to capture
aspects of compositional visual reasoning, such as attributes and relationships
between objects. One solution is to utilize scene graphs (SGs)--a formalization
of objects and their relations and attributes that has been extensively used as
a bridge between the visual and textual domains. Yet, scene graph data requires
scene graph annotations, which are expensive to collect and thus not easily
scalable. Moreover, finetuning an LMM based on SG data can lead to catastrophic
forgetting of the pretraining objective. To overcome this, inspired by
chain-of-thought methods, we propose Compositional Chain-of-Thought (CCoT), a
novel zero-shot Chain-of-Thought prompting method that utilizes SG
representations in order to extract compositional knowledge from an LMM.
Specifically, we first generate an SG using the LMM, and then use that SG in
the prompt to produce a response. Through extensive experiments, we find that
the proposed CCoT approach not only improves LMM performance on several vision
and language VL compositional benchmarks but also improves the performance of
several popular LMMs on general multimodal benchmarks, without the need for
fine-tuning or annotated ground-truth SGs.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17080" title="Abstract">arXiv:2311.17080</a> [<a href="/pdf/2311.17080" title="Download PDF">pdf</a>, <a href="/format/2311.17080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combating the &quot;Sameness&quot; in AI Art: Reflections on the Interactive AI  Installation Fencing Hallucination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+W">Weihao Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Legrady%2C+G">George Legrady</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper for NeurIPS 2023 Workshop, Machine Learning for Creativity and Design
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The article summarizes three types of "sameness" issues in Artificial
Intelligence(AI) art, each occurring at different stages of development in AI
image creation tools. Through the Fencing Hallucination project, the article
reflects on the design of AI art production in alleviating the sense of
uniformity, maintaining the uniqueness of images from an AI image synthesizer,
and enhancing the connection between the artworks and the audience. This paper
endeavors to stimulate the creation of distinctive AI art by recounting the
efforts and insights derived from the Fencing Hallucination project, all
dedicated to addressing the issue of "sameness".
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17081" title="Abstract">arXiv:2311.17081</a> [<a href="/pdf/2311.17081" title="Download PDF">pdf</a>, <a href="/format/2311.17081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> I-MedSAM: Implicit Medical Image Segmentation with Segment Anything
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xiaobao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiajun Cao</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yizhu Jin</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+M">Ming Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guangyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanghang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the development of Deep Neural Networks (DNNs), many efforts have been
made to handle medical image segmentation. Traditional methods such as nnUNet
train specific segmentation models on the individual datasets. Plenty of recent
methods have been proposed to adapt the foundational Segment Anything Model
(SAM) to medical image segmentation. However, they still focus on discrete
representations to generate pixel-wise predictions, which are spatially
inflexible and scale poorly to higher resolution. In contrast, implicit methods
learn continuous representations for segmentation, which is crucial for medical
image segmentation. In this paper, we propose I-MedSAM, which leverages the
benefits of both continuous representations and SAM, to obtain better
cross-domain ability and accurate boundary delineation. Since medical image
segmentation needs to predict detailed segmentation boundaries, we designed a
novel adapter to enhance the SAM features with high-frequency information
during Parameter Efficient Fine Tuning (PEFT). To convert the SAM features and
coordinates into continuous segmentation output, we utilize Implicit Neural
Representation (INR) to learn an implicit segmentation decoder. We also propose
an uncertainty-guided sampling strategy for efficient learning of INR.
Extensive evaluations on 2D medical image segmentation tasks have shown that
our proposed method with only 1.6M trainable parameters outperforms existing
methods including discrete and continuous methods. The code will be released.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17082" title="Abstract">arXiv:2311.17082</a> [<a href="/pdf/2311.17082" title="Download PDF">pdf</a>, <a href="/format/2311.17082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreamPropeller: Supercharge Text-to-3D Generation with Parallel Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Linqi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shih%2C+A">Andy Shih</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+C">Chenlin Meng</a>, 
<a href="/search/cs?searchtype=author&query=Ermon%2C+S">Stefano Ermon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Github repo: <a href="https://github.com/alexzhou907/DreamPropeller">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Recent methods such as Score Distillation Sampling (SDS) and Variational
Score Distillation (VSD) using 2D diffusion models for text-to-3D generation
have demonstrated impressive generation quality. However, the long generation
time of such algorithms significantly degrades the user experience. To tackle
this problem, we propose DreamPropeller, a drop-in acceleration algorithm that
can be wrapped around any existing text-to-3D generation pipeline based on
score distillation. Our framework generalizes Picard iterations, a classical
algorithm for parallel sampling an ODE path, and can account for non-ODE paths
such as momentum-based gradient updates and changes in dimensions during the
optimization process as in many cases of 3D generation. We show that our
algorithm trades parallel compute for wallclock time and empirically achieves
up to 4.7x speedup with a negligible drop in generation quality for all tested
frameworks.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17083" title="Abstract">arXiv:2311.17083</a> [<a href="/pdf/2311.17083" title="Download PDF">pdf</a>, <a href="/format/2311.17083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLiC: Concept Learning in Context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Safaee%2C+M">Mehdi Safaee</a>, 
<a href="/search/cs?searchtype=author&query=Mikaeili%2C+A">Aryan Mikaeili</a>, 
<a href="/search/cs?searchtype=author&query=Patashnik%2C+O">Or Patashnik</a>, 
<a href="/search/cs?searchtype=author&query=Cohen-Or%2C+D">Daniel Cohen-Or</a>, 
<a href="/search/cs?searchtype=author&query=Mahdavi-Amiri%2C+A">Ali Mahdavi-Amiri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper addresses the challenge of learning a local visual pattern of an
object from one image, and generating images depicting objects with that
pattern. Learning a localized concept and placing it on an object in a target
image is a nontrivial task, as the objects may have different orientations and
shapes. Our approach builds upon recent advancements in visual concept
learning. It involves acquiring a visual concept (e.g., an ornament) from a
source image and subsequently applying it to an object (e.g., a chair) in a
target image. Our key idea is to perform in-context concept learning, acquiring
the local visual concept within the broader context of the objects they belong
to. To localize the concept learning, we employ soft masks that contain both
the concept within the mask and the surrounding image area. We demonstrate our
approach through object generation within an image, showcasing plausible
embedding of in-context learned concepts. We also introduce methods for
directing acquired concepts to specific locations within target images,
employing cross-attention mechanisms, and establishing correspondences between
source and target objects. The effectiveness of our method is demonstrated
through quantitative and qualitative experiments, along with comparisons
against baseline techniques.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17084" title="Abstract">arXiv:2311.17084</a> [<a href="/pdf/2311.17084" title="Download PDF">pdf</a>, <a href="/format/2311.17084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DepthSSC: Depth-Spatial Alignment and Dynamic Voxel Resolution for  Monocular 3D Semantic Scene Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiawei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jusheng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The task of 3D semantic scene completion with monocular cameras is gaining
increasing attention in the field of autonomous driving. Its objective is to
predict the occupancy status of each voxel in the 3D scene from partial image
inputs. Despite the existence of numerous methods, many of them overlook the
issue of accurate alignment between spatial and depth information. To address
this, we propose DepthSSC, an advanced method for semantic scene completion
solely based on monocular cameras. DepthSSC combines the ST-GF (Spatial
Transformation Graph Fusion) module with geometric-aware voxelization, enabling
dynamic adjustment of voxel resolution and considering the geometric complexity
of 3D space to ensure precise alignment between spatial and depth information.
This approach successfully mitigates spatial misalignment and distortion issues
observed in prior methods. Through evaluation on the SemanticKITTI dataset,
DepthSSC not only demonstrates its effectiveness in capturing intricate 3D
structural details but also achieves state-of-the-art performance. We believe
DepthSSC provides a fresh perspective on monocular camera-based 3D semantic
scene completion research and anticipate it will inspire further related
studies.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17085" title="Abstract">arXiv:2311.17085</a> [<a href="/pdf/2311.17085" title="Download PDF">pdf</a>, <a href="/format/2311.17085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Visual Cues: Synchronously Exploring Target-Centric Semantics for  Vision-Language Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+J">Jiawei Ge</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiangmei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiuxin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xuelin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weijia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Single object tracking aims to locate one specific target in video sequences,
given its initial state. Classical trackers rely solely on visual cues,
restricting their ability to handle challenges such as appearance variations,
ambiguity, and distractions. Hence, Vision-Language (VL) tracking has emerged
as a promising approach, incorporating language descriptions to directly
provide high-level semantics and enhance tracking performance. However, current
VL trackers have not fully exploited the power of VL learning, as they suffer
from limitations such as heavily relying on off-the-shelf backbones for feature
extraction, ineffective VL fusion designs, and the absence of VL-related loss
functions. Consequently, we present a novel tracker that progressively explores
target-centric semantics for VL tracking. Specifically, we propose the first
Synchronous Learning Backbone (SLB) for VL tracking, which consists of two
novel modules: the Target Enhance Module (TEM) and the Semantic Aware Module
(SAM). These modules enable the tracker to perceive target-related semantics
and comprehend the context of both visual and textual modalities at the same
pace, facilitating VL feature extraction and fusion at different semantic
levels. Moreover, we devise the dense matching loss to further strengthen
multi-modal representation learning. Extensive experiments on VL tracking
datasets demonstrate the superiority and effectiveness of our methods.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17086" title="Abstract">arXiv:2311.17086</a> [<a href="/pdf/2311.17086" title="Download PDF">pdf</a>, <a href="/format/2311.17086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PEA-Diffusion: Parameter-Efficient Adapter with Knowledge Distillation  in non-English Text-to-Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Q">Qingsong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Haonan Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Text-to-image diffusion models are well-known for their ability to generate
realistic images based on textual prompts. However, the existing works have
predominantly focused on English, lacking support for non-English text-to-image
models. The most commonly used translation methods cannot solve the generation
problem related to language culture, while training from scratch on a specific
language dataset is prohibitively expensive. In this paper, we are inspired to
propose a simple plug-and-play language transfer method based on knowledge
distillation. All we need to do is train a lightweight MLP-like
parameter-efficient adapter (PEA) with only 6M parameters under teacher
knowledge distillation along with a small parallel data corpus. We are
surprised to find that freezing the parameters of UNet can still achieve
remarkable performance on the language-specific prompt evaluation set,
demonstrating that PEA can stimulate the potential generation ability of the
original UNet. Additionally, it closely approaches the performance of the
English text-to-image model on a general prompt evaluation set. Furthermore,
our adapter can be used as a plugin to achieve significant results in
downstream tasks in cross-lingual text-to-image generation. Code will be
available at: https://github.com/OPPO-Mente-Lab/PEA-Diffusion
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17087" title="Abstract">arXiv:2311.17087</a> [<a href="/pdf/2311.17087" title="Download PDF">pdf</a>, <a href="/format/2311.17087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Mixup for Improving the Adversarial Transferability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaosen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zeyuan Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Mixup augmentation has been widely integrated to generate adversarial
examples with superior adversarial transferability when immigrating from a
surrogate model to other models. However, the underlying mechanism influencing
the mixup's effect on transferability remains unexplored. In this work, we
posit that the adversarial examples located at the convergence of decision
boundaries across various categories exhibit better transferability and
identify that Admix tends to steer the adversarial examples towards such
regions. However, we find the constraint on the added image in Admix decays its
capability, resulting in limited transferability. To address such an issue, we
propose a new input transformation-based attack called Mixing the Image but
Separating the gradienT (MIST). Specifically, MIST randomly mixes the input
image with a randomly shifted image and separates the gradient of each loss
item for each mixed image. To counteract the imprecise gradient, MIST
calculates the gradient on several mixed images for each input sample.
Extensive experimental results on the ImageNet dataset demonstrate that MIST
outperforms existing SOTA input transformation-based attacks with a clear
margin on both Convolutional Neural Networks (CNNs) and Vision Transformers
(ViTs) w/wo defense mechanisms, supporting MIST's high effectiveness and
generality.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17088" title="Abstract">arXiv:2311.17088</a> [<a href="/pdf/2311.17088" title="Download PDF">pdf</a>, <a href="/format/2311.17088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Multimodal Deepfake Detection Using Intra- and Cross-Modal  Inconsistencies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+M">Mulin Tian</a>, 
<a href="/search/cs?searchtype=author&query=Khayatkhoei%2C+M">Mahyar Khayatkhoei</a>, 
<a href="/search/cs?searchtype=author&query=Mathai%2C+J">Joe Mathai</a>, 
<a href="/search/cs?searchtype=author&query=AbdAlmageed%2C+W">Wael AbdAlmageed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deepfake videos present an increasing threat to society with potentially
negative impact on criminal justice, democracy, and personal safety and
privacy. Meanwhile, detecting deepfakes, at scale, remains a very challenging
tasks that often requires labeled training data from existing deepfake
generation methods. Further, even the most accurate supervised learning,
deepfake detection methods do not generalize to deepfakes generated using new
generation methods. In this paper, we introduce a novel unsupervised approach
for detecting deepfake videos by measuring of intra- and cross-modal
consistency among multimodal features; specifically visual, audio, and identity
features. The fundamental hypothesis behind the proposed detection method is
that since deepfake generation attempts to transfer the facial motion of one
identity to another, these methods will eventually encounter a trade-off
between motion and identity that enviably leads to detectable inconsistencies.
We validate our method through extensive experimentation, demonstrating the
existence of significant intra- and cross- modal inconsistencies in deepfake
videos, which can be effectively utilized to detect them with high accuracy.
Our proposed method is scalable because it does not require pristine samples at
inference, generalizable because it is trained only on real data, and is
explainable since it can pinpoint the exact location of modality
inconsistencies which are then verifiable by a human expert.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17089" title="Abstract">arXiv:2311.17089</a> [<a href="/pdf/2311.17089" title="Download PDF">pdf</a>, <a href="/format/2311.17089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Scale 3D Gaussian Splatting for Anti-Aliased Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhiwen Yan</a>, 
<a href="/search/cs?searchtype=author&query=Low%2C+W+F">Weng Fei Low</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+G+H">Gim Hee Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D Gaussians have recently emerged as a highly efficient representation for
3D reconstruction and rendering. Despite its high rendering quality and speed
at high resolutions, they both deteriorate drastically when rendered at lower
resolutions or from far away camera position. During low resolution or far away
rendering, the pixel size of the image can fall below the Nyquist frequency
compared to the screen size of each splatted 3D Gaussian and leads to aliasing
effect. The rendering is also drastically slowed down by the sequential alpha
blending of more splatted Gaussians per pixel. To address these issues, we
propose a multi-scale 3D Gaussian splatting algorithm, which maintains
Gaussians at different scales to represent the same scene. Higher-resolution
images are rendered with more small Gaussians, and lower-resolution images are
rendered with fewer larger Gaussians. With similar training time, our algorithm
can achieve 13\%-66\% PSNR and 160\%-2400\% rendering speed improvement at
4$\times$-128$\times$ scale rendering on Mip-NeRF360 dataset compared to the
single scale 3D Gaussian splatting.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17091" title="Abstract">arXiv:2311.17091</a> [<a href="/pdf/2311.17091" title="Download PDF">pdf</a>, <a href="/format/2311.17091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Sole Strength: Customized Ensembles for Generalized  Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhihe Lu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jiawang Bai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zeyu Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinchao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Fine-tuning pre-trained vision-language models (VLMs), e.g., CLIP, for the
open-world generalization has gained increasing popularity due to its practical
value. However, performance advancements are limited when relying solely on
intricate algorithmic designs for a single model, even one exhibiting strong
performance, e.g., CLIP-ViT-B/16. This paper, for the first time, explores the
collaborative potential of leveraging much weaker VLMs to enhance the
generalization of a robust single model. The affirmative findings motivate us
to address the generalization problem from a novel perspective, i.e., ensemble
of pre-trained VLMs. We introduce three customized ensemble strategies, each
tailored to one specific scenario. Firstly, we introduce the zero-shot
ensemble, automatically adjusting the logits of different models based on their
confidence when only pre-trained VLMs are available. Furthermore, for scenarios
with extra few-shot samples, we propose the training-free and tuning ensemble,
offering flexibility based on the availability of computing resources. The
proposed ensemble strategies are evaluated on zero-shot, base-to-new, and
cross-dataset generalization, achieving new state-of-the-art performance.
Notably, this work represents an initial stride toward enhancing the
generalization performance of VLMs via ensemble. The code is available at
https://github.com/zhiheLu/Ensemble_VLM.git.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17092" title="Abstract">arXiv:2311.17092</a> [<a href="/pdf/2311.17092" title="Download PDF">pdf</a>, <a href="/format/2311.17092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEED-Bench-2: Benchmarking Multimodal Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bohao Li</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yuying Ge</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yixiao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guangzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruimao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project released at: <a href="https://github.com/AILab-CVC/SEED-Bench.">this https URL</a> arXiv admin note: text overlap with <a href="/abs/2307.16125">arXiv:2307.16125</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multimodal large language models (MLLMs), building upon the foundation of
powerful large language models (LLMs), have recently demonstrated exceptional
capabilities in generating not only texts but also images given interleaved
multimodal inputs (acting like a combination of GPT-4V and DALL-E 3). However,
existing MLLM benchmarks remain limited to assessing only models' comprehension
ability of single image-text inputs, failing to keep up with the strides made
in MLLMs. A comprehensive benchmark is imperative for investigating the
progress and uncovering the limitations of current MLLMs. In this work, we
categorize the capabilities of MLLMs into hierarchical levels from $L_0$ to
$L_4$ based on the modalities they can accept and generate, and propose
SEED-Bench-2, a comprehensive benchmark that evaluates the
\textbf{hierarchical} capabilities of MLLMs. Specifically, SEED-Bench-2
comprises 24K multiple-choice questions with accurate human annotations, which
spans 27 dimensions, including the evaluation of both text and image
generation. Multiple-choice questions with groundtruth options derived from
human annotation enables an objective and efficient assessment of model
performance, eliminating the need for human or GPT intervention during
evaluation. We further evaluate the performance of 23 prominent open-source
MLLMs and summarize valuable observations. By revealing the limitations of
existing MLLMs through extensive evaluations, we aim for SEED-Bench-2 to
provide insights that will motivate future research towards the goal of General
Artificial Intelligence. Dataset and evaluation code are available at
\href{https://github.com/AILab-CVC/SEED-Bench}
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17093" title="Abstract">arXiv:2311.17093</a> [<a href="/pdf/2311.17093" title="Download PDF">pdf</a>, <a href="/format/2311.17093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Prototypical Semi-Supervised Learning with Foundation Models:  Prototype Selection, Parametric vMF-SNE Pretraining and Multi-view  Pseudolabelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mannix%2C+E">Evelyn Mannix</a>, 
<a href="/search/cs?searchtype=author&query=Bondell%2C+H">Howard Bondell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper we present an improved approach to prototypical semi-supervised
learning for computer vision, in the context of leveraging a frozen foundation
model as the backbone of our neural network. As a general tool, we propose
parametric von-Mises Fisher Stochastic Neighbour Embedding (vMF-SNE) to create
mappings with neural networks between high-dimensional latent spaces that
preserve local structure. This enables us to pretrain the projection head of
our network using the high-quality embeddings of the foundation model with
vMF-SNE. We also propose soft multi-view pseudolabels, where predictions across
multiple views are combined to provide a more reliable supervision signal
compared to a consistency or swapped assignment approach. We demonstrate that
these ideas improve upon P}redicting View-Assignments with Support Samples
(PAWS), a current state-of-the-art semi-supervised learning method, as well as
Robust PAWS (RoPAWS), over a range of benchmarking datasets. We also introduce
simple $k$-means prototype selection, a technique that provides superior
performance to other unsupervised label selection approaches in this context.
These changes improve upon PAWS by an average of +2.9% for CIFAR-10 and +5.7%
for CIFAR-100 with four labels per class, and by +15.2% for DeepWeeds, a
particularly challenging dataset for semi-supervised learning. We also achieve
new state-of-the-art results in semi-supervised learning in this small label
regime for CIFAR-10 - 95.8% (+0.7%) and CIFAR-100 - 76.6% (+12.0%).
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17094" title="Abstract">arXiv:2311.17094</a> [<a href="/pdf/2311.17094" title="Download PDF">pdf</a>, <a href="/format/2311.17094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In Search of a Data Transformation That Accelerates Neural Field  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seo%2C+J">Junwon Seo</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sangyoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K+I">Kwang In Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaeho Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Neural field is an emerging paradigm in data representation that trains a
neural network to approximate the given signal. A key obstacle that prevents
its widespread adoption is the encoding speed-generating neural fields requires
an overfitting of a neural network, which can take a significant number of SGD
steps to reach the desired fidelity level. In this paper, we delve into the
impacts of data transformations on the speed of neural field training,
specifically focusing on how permuting pixel locations affect the convergence
speed of SGD. Counterintuitively, we find that randomly permuting the pixel
locations can considerably accelerate the training. To explain this phenomenon,
we examine the neural field training through the lens of PSNR curves, loss
landscapes, and error patterns. Our analyses suggest that the random pixel
permutations remove the easy-to-fit patterns, which facilitate easy
optimization in the early stage but hinder capturing fine details of the
signal.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17095" title="Abstract">arXiv:2311.17095</a> [<a href="/pdf/2311.17095" title="Download PDF">pdf</a>, <a href="/format/2311.17095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Plug-and-Play, Dense-Label-Free Extraction of Open-Vocabulary Semantic  Segmentation from Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiayun%2C+L">Luo Jiayun</a>, 
<a href="/search/cs?searchtype=author&query=Khandelwal%2C+S">Siddhesh Khandelwal</a>, 
<a href="/search/cs?searchtype=author&query=Sigal%2C+L">Leonid Sigal</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boyang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">From an enormous amount of image-text pairs, large-scale vision-language
models (VLMs) learn to implicitly associate image regions with words, which is
vital for tasks such as image captioning and visual question answering.
However, leveraging such pre-trained models for open-vocabulary semantic
segmentation remains a challenge. In this paper, we propose a simple, yet
extremely effective, training-free technique, Plug-and-Play Open-Vocabulary
Semantic Segmentation (PnP-OVSS) for this task. PnP-OVSS leverages a VLM with
direct text-to-image cross-attention and an image-text matching loss to produce
semantic segmentation. However, cross-attention alone tends to over-segment,
whereas cross-attention plus GradCAM tend to under-segment. To alleviate this
issue, we introduce Salience Dropout; by iteratively dropping patches that the
model is most attentive to, we are able to better resolve the entire extent of
the segmentation mask. Compared to existing techniques, the proposed method
does not require any neural network training and performs hyperparameter tuning
without the need for any segmentation annotations, even for a validation set.
PnP-OVSS demonstrates substantial improvements over a comparable baseline
(+29.4% mIoU on Pascal VOC, +13.2% mIoU on Pascal Context, +14.0% mIoU on MS
COCO, +2.4% mIoU on COCO Stuff) and even outperforms most baselines that
conduct additional network training on top of pretrained VLMs.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17096" title="Abstract">arXiv:2311.17096</a> [<a href="/pdf/2311.17096" title="Download PDF">pdf</a>, <a href="/format/2311.17096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Transductive Few-shot Learning via Joint Message Passing and  Prototype-based Soft-label Propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiahui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bin Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Few-shot learning (FSL) aims to develop a learning model with the ability to
generalize to new classes using a few support samples. For transductive FSL
tasks, prototype learning and label propagation methods are commonly employed.
Prototype methods generally first learn the representative prototypes from the
support set and then determine the labels of queries based on the metric
between query samples and prototypes. Label propagation methods try to
propagate the labels of support samples on the constructed graph encoding the
relationships between both support and query samples. This paper aims to
integrate these two principles together and develop an efficient and robust
transductive FSL approach, termed Prototype-based Soft-label Propagation
(PSLP). Specifically, we first estimate the soft-label presentation for each
query sample by leveraging prototypes. Then, we conduct soft-label propagation
on our learned query-support graph. Both steps are conducted progressively to
boost their respective performance. Moreover, to learn effective prototypes for
soft-label estimation as well as the desirable query-support graph for
soft-label propagation, we design a new joint message passing scheme to learn
sample presentation and relational graph jointly. Our PSLP method is
parameter-free and can be implemented very efficiently. On four popular
datasets, our method achieves competitive results on both balanced and
imbalanced settings compared to the state-of-the-art methods. The code will be
released upon acceptance.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17097" title="Abstract">arXiv:2311.17097</a> [<a href="/pdf/2311.17097" title="Download PDF">pdf</a>, <a href="/format/2311.17097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anonymous Jamming Detection in 5G with Bayesian Network Model Based  Inference Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Ying Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jere%2C+S">Shashank Jere</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Soumya Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingjia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shetty%2C+S">Sachin Shetty</a>, 
<a href="/search/cs?searchtype=author&query=Dayekh%2C+S">Shehadi Dayekh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 9 figures, Published in HPSR22. arXiv admin note: text overlap with <a href="/abs/2304.13660">arXiv:2304.13660</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Jamming and intrusion detection are critical in 5G research, aiming to
maintain reliability, prevent user experience degradation, and avoid
infrastructure failure. This paper introduces an anonymous jamming detection
model for 5G based on signal parameters from the protocol stacks. The system
uses supervised and unsupervised learning for real-time, high-accuracy
detection of jamming, including unknown types. Supervised models reach an AUC
of 0.964 to 1, compared to LSTM models with an AUC of 0.923 to 1. However, the
need for data annotation limits the supervised approach. To address this, an
unsupervised auto-encoder-based anomaly detection is presented with an AUC of
0.987. The approach is resistant to adversarial training samples. For
transparency and domain knowledge injection, a Bayesian network-based causation
analysis is introduced.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17098" title="Abstract">arXiv:2311.17098</a> [<a href="/pdf/2311.17098" title="Download PDF">pdf</a>, <a href="/format/2311.17098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DyRA: Dynamic Resolution Adjustment for Scale-robust Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seo%2C+D">Daeun Seo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hoeseok Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyungshin Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In object detection, achieving constant accuracy is challenging due to the
variability of object sizes. One possible solution to this problem is to
optimize the input resolution, known as a multi-resolution strategy. Previous
approaches for optimizing resolution are often based on pre-defined resolutions
or a dynamic neural network, but there is a lack of study for run-time
resolution optimization for existing architecture. In this paper, we propose an
adaptive resolution scaling network called DyRA, which comprises convolutions
and transformer encoder blocks, for existing detectors. Our DyRA returns a
scale factor from an input image, which enables instance-specific scaling. This
network is jointly trained with detectors with specially designed loss
functions, namely ParetoScaleLoss and BalanceLoss. The ParetoScaleLoss produces
an adaptive scale factor from the image, while the BalanceLoss optimizes the
scale factor according to localization power for the dataset. The loss function
is designed to minimize accuracy drop about the contrasting objective of small
and large objects. Our experiments on COCO, RetinaNet, Faster-RCNN, FCOS, and
Mask-RCNN achieved 1.3%, 1.1%, 1.3%, and 0.8% accuracy improvement than a
multi-resolution baseline with solely resolution adjustment. The code is
available at https://github.com/DaEunFullGrace/DyRA.git.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17099" title="Abstract">arXiv:2311.17099</a> [<a href="/pdf/2311.17099" title="Download PDF">pdf</a>, <a href="/format/2311.17099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StreamFlow: Streamlined Multi-Frame Optical Flow Estimation for Video  Sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shangkun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T+H">Thomas H. Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huaxia Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guoqing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Wei Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Occlusions between consecutive frames have long posed a significant challenge
in optical flow estimation. The inherent ambiguity introduced by occlusions
directly violates the brightness constancy constraint and considerably hinders
pixel-to-pixel matching. To address this issue, multi-frame optical flow
methods leverage adjacent frames to mitigate the local ambiguity. Nevertheless,
prior multi-frame methods predominantly adopt recursive flow estimation,
resulting in a considerable computational overlap. In contrast, we propose a
streamlined in-batch framework that eliminates the need for extensive redundant
recursive computations while concurrently developing effective spatio-temporal
modeling approaches under in-batch estimation constraints. Specifically, we
present a Streamlined In-batch Multi-frame (SIM) pipeline tailored to video
input, attaining a similar level of time efficiency to two-frame networks.
Furthermore, we introduce an efficient Integrative Spatio-temporal Coherence
(ISC) modeling method for effective spatio-temporal modeling during the
encoding phase, which introduces no additional parameter overhead.
Additionally, we devise a Global Temporal Regressor (GTR) that effectively
explores temporal relations during decoding. Benefiting from the efficient SIM
pipeline and effective modules, StreamFlow not only excels in terms of
performance on the challenging KITTI and Sintel datasets, with particular
improvement in occluded areas but also attains a remarkable $63.82\%$
enhancement in speed compared with previous multi-frame methods. The code will
be available soon at https://github.com/littlespray/StreamFlow.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17101" title="Abstract">arXiv:2311.17101</a> [<a href="/pdf/2311.17101" title="Download PDF">pdf</a>, <a href="/format/2311.17101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Diffusion GAN using Semi-Unbalanced Optimal Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dao%2C+Q">Quan Dao</a>, 
<a href="/search/cs?searchtype=author&query=Ta%2C+B">Binh Ta</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+T">Tung Pham</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+A">Anh Tran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion models, a type of generative model, have demonstrated great
potential for synthesizing highly detailed images. By integrating with GAN,
advanced diffusion models like DDGAN \citep{xiao2022DDGAN} could approach
real-time performance for expansive practical applications. While DDGAN has
effectively addressed the challenges of generative modeling, namely producing
high-quality samples, covering different data modes, and achieving faster
sampling, it remains susceptible to performance drops caused by datasets that
are corrupted with outlier samples. This work introduces a robust training
technique based on semi-unbalanced optimal transport to mitigate the impact of
outliers effectively. Through comprehensive evaluations, we demonstrate that
our robust diffusion GAN (RDGAN) outperforms vanilla DDGAN in terms of the
aforementioned generative modeling criteria, i.e., image quality, mode coverage
of distribution, and inference speed, and exhibits improved robustness when
dealing with both clean and corrupted datasets.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17104" title="Abstract">arXiv:2311.17104</a> [<a href="/pdf/2311.17104" title="Download PDF">pdf</a>, <a href="/format/2311.17104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-Cell Clustering via Dual-Graph Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+D">Dayu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+K">Ke Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinwang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Molecular Networks (q-bio.MN)

</div>
<p class="mathjax">In recent years, the field of single-cell RNA sequencing has seen a surge in
the development of clustering methods. These methods enable the identification
of cell subpopulations, thereby facilitating the understanding of tumor
microenvironments. Despite their utility, most existing clustering algorithms
primarily focus on the attribute information provided by the cell matrix or the
network structure between cells, often neglecting the network between genes.
This oversight could lead to loss of information and clustering results that
lack clinical significance. To address this limitation, we develop an advanced
single-cell clustering model incorporating dual-graph alignment, which
integrates gene network information into the clustering process based on
self-supervised and unsupervised optimization. Specifically, we designed a
graph-based autoencoder enhanced by an attention mechanism to effectively
capture relationships between cells. Moreover, we performed the node2vec method
on Protein-Protein Interaction (PPI) networks to derive the gene network
structure and maintained this structure throughout the clustering process. Our
proposed method has been demonstrated to be effective through experimental
results, showcasing its ability to optimize clustering outcomes while
preserving the original associations between cells and genes. This research
contributes to obtaining accurate cell subpopulations and generates clustering
results that more closely resemble real-world biological scenarios. It provides
better insights into the characteristics and distribution of diseased cells,
ultimately building a foundation for early disease diagnosis and treatment.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17105" title="Abstract">arXiv:2311.17105</a> [<a href="/pdf/2311.17105" title="Download PDF">pdf</a>, <a href="/format/2311.17105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Calibration of Human Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+K">Kerui Gu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Rongyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+A">Angela Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Most 2D human pose estimation frameworks estimate keypoint confidence in an
ad-hoc manner, using heuristics such as the maximum value of heatmaps. The
confidence is part of the evaluation scheme, e.g., AP for the MSCOCO dataset,
yet has been largely overlooked in the development of state-of-the-art methods.
This paper takes the first steps in addressing miscalibration in pose
estimation. From a calibration point of view, the confidence should be aligned
with the pose accuracy. In practice, existing methods are poorly calibrated. We
show, through theoretical analysis, why a miscalibration gap exists and how to
narrow the gap. Simply predicting the instance size and adjusting the
confidence function gives considerable AP improvements. Given the black-box
nature of deep neural networks, however, it is not possible to fully close this
gap with only closed-form adjustments. As such, we go one step further and
learn network-specific adjustments by enforcing consistency between confidence
and pose accuracy. Our proposed Calibrated ConfidenceNet (CCNet) is a
light-weight post-hoc addition that improves AP by up to 1.4% on off-the-shelf
pose estimation frameworks. Applied to the downstream task of mesh recovery,
CCNet facilitates an additional 1.0mm decrease in 3D keypoint error.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17107" title="Abstract">arXiv:2311.17107</a> [<a href="/pdf/2311.17107" title="Download PDF">pdf</a>, <a href="/format/2311.17107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClimateX: Do LLMs Accurately Assess Human Expert Confidence in Climate  Statements?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lacombe%2C+R">Romain Lacombe</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kerrie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Dilworth%2C+E">Eddie Dilworth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tackling Climate Change with Machine Learning workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Evaluating the accuracy of outputs generated by Large Language Models (LLMs)
is especially important in the climate science and policy domain. We introduce
the Expert Confidence in Climate Statements (ClimateX) dataset, a novel,
curated, expert-labeled dataset consisting of 8094 climate statements collected
from the latest Intergovernmental Panel on Climate Change (IPCC) reports,
labeled with their associated confidence levels. Using this dataset, we show
that recent LLMs can classify human expert confidence in climate-related
statements, especially in a few-shot learning setting, but with limited (up to
47%) accuracy. Overall, models exhibit consistent and significant
over-confidence on low and medium confidence statements. We highlight
implications of our results for climate communication, LLMs evaluation
strategies, and the use of LLMs in information retrieval systems.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17109" title="Abstract">arXiv:2311.17109</a> [<a href="/pdf/2311.17109" title="Download PDF">pdf</a>, <a href="/format/2311.17109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Texture Puppeteer: A Framework for Neural Geometry and Texture  Rendering of Articulated Shapes, Enabling Re-Identification at Interactive  Speed
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Waldmann%2C+U">Urs Waldmann</a>, 
<a href="/search/cs?searchtype=author&query=Johannsen%2C+O">Ole Johannsen</a>, 
<a href="/search/cs?searchtype=author&query=Goldluecke%2C+B">Bastian Goldluecke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we present a neural rendering pipeline for textured
articulated shapes that we call Neural Texture Puppeteer. Our method separates
geometry and texture encoding. The geometry pipeline learns to capture spatial
relationships on the surface of the articulated shape from ground truth data
that provides this geometric information. A texture auto-encoder makes use of
this information to encode textured images into a global latent code. This
global texture embedding can be efficiently trained separately from the
geometry, and used in a downstream task to identify individuals. The neural
texture rendering and the identification of individuals run at interactive
speeds. To the best of our knowledge, we are the first to offer a promising
alternative to CNN- or transformer-based approaches for re-identification of
articulated individuals based on neural rendering. Realistic looking novel view
and pose synthesis for different synthetic cow textures further demonstrate the
quality of our method. Restricted by the availability of ground truth data for
the articulated shape's geometry, the quality for real-world data synthesis is
reduced. We further demonstrate the flexibility of our model for real-world
data by applying a synthetic to real-world texture domain shift where we
reconstruct the texture from a real-world 2D RGB image. Thus, our method can be
applied to endangered species where data is limited. Our novel synthetic
texture dataset NePuMoo is publicly available to inspire further development in
the field of neural rendering-based re-identification.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17110" title="Abstract">arXiv:2311.17110</a> [<a href="/pdf/2311.17110" title="Download PDF">pdf</a>, <a href="/format/2311.17110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XAI for time-series classification leveraging image highlight methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Makridis%2C+G">Georgios Makridis</a>, 
<a href="/search/cs?searchtype=author&query=Fatouros%2C+G">Georgios Fatouros</a>, 
<a href="/search/cs?searchtype=author&query=Koukos%2C+V">Vasileios Koukos</a>, 
<a href="/search/cs?searchtype=author&query=Kotios%2C+D">Dimitrios Kotios</a>, 
<a href="/search/cs?searchtype=author&query=Kyriazis%2C+D">Dimosthenis Kyriazis</a>, 
<a href="/search/cs?searchtype=author&query=Soldatos%2C+I">Ioannis Soldatos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Although much work has been done on explainability in the computer vision and
natural language processing (NLP) fields, there is still much work to be done
to explain methods applied to time series as time series by nature can not be
understood at first sight. In this paper, we present a Deep Neural Network
(DNN) in a teacher-student architecture (distillation model) that offers
interpretability in time-series classification tasks. The explainability of our
approach is based on transforming the time series to 2D plots and applying
image highlight methods (such as LIME and GradCam), making the predictions
interpretable. At the same time, the proposed approach offers increased
accuracy competing with the baseline model with the trade-off of increasing the
training time.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17112" title="Abstract">arXiv:2311.17112</a> [<a href="/pdf/2311.17112" title="Download PDF">pdf</a>, <a href="/format/2311.17112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameter Efficient Fine-tuning via Cross Block Orchestration for  Segment Anything Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zelin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhengqin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhilin Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lingxi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qi Tian</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Wei Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Parameter-efficient fine-tuning (PEFT) is an effective methodology to unleash
the potential of large foundation models in novel scenarios with limited
training data. In the computer vision community, PEFT has shown effectiveness
in image classification, but little research has studied its ability for image
segmentation. Fine-tuning segmentation models usually require a heavier
adjustment of parameters to align the proper projection directions in the
parameter space for new scenarios. This raises a challenge to existing PEFT
algorithms, as they often inject a limited number of individual parameters into
each block, which prevents substantial adjustment of the projection direction
of the parameter space due to the limitation of Hidden Markov Chain along
blocks. In this paper, we equip PEFT with a cross-block orchestration mechanism
to enable the adaptation of the Segment Anything Model (SAM) to various
downstream scenarios. We introduce a novel inter-block communication module,
which integrates a learnable relation matrix to facilitate communication among
different coefficient sets of each PEFT block's parameter space. Moreover, we
propose an intra-block enhancement module, which introduces a linear projection
head whose weights are generated from a hyper-complex layer, further enhancing
the impact of the adjustment of projection directions on the entire parameter
space. Extensive experiments on diverse benchmarks demonstrate that our
proposed approach consistently improves the segmentation performance
significantly on novel scenarios with only around 1K additional parameters.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17113" title="Abstract">arXiv:2311.17113</a> [<a href="/pdf/2311.17113" title="Download PDF">pdf</a>, <a href="/format/2311.17113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Gaussian Splatting: Real-time Rendering of Animatable Avatars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moreau%2C+A">Arthur Moreau</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jifei Song</a>, 
<a href="/search/cs?searchtype=author&query=Dhamo%2C+H">Helisa Dhamo</a>, 
<a href="/search/cs?searchtype=author&query=Shaw%2C+R">Richard Shaw</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yiren Zhou</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez-Pellitero%2C+E">Eduardo P&#xe9;rez-Pellitero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">This work addresses the problem of real-time rendering of photorealistic
human body avatars learned from multi-view videos. While the classical
approaches to model and render virtual humans generally use a textured mesh,
recent research has developed neural body representations that achieve
impressive visual quality. However, these models are difficult to render in
real-time and their quality degrades when the character is animated with body
poses different than the training observations. We propose the first animatable
human model based on 3D Gaussian Splatting, that has recently emerged as a very
efficient alternative to neural radiance fields. Our body is represented by a
set of gaussian primitives in a canonical space which are deformed in a coarse
to fine approach that combines forward skinning and local non-rigid refinement.
We describe how to learn our Human Gaussian Splatting (\OURS) model in an
end-to-end fashion from multi-view observations, and evaluate it against the
state-of-the-art approaches for novel pose synthesis of clothed body. Our
method presents a PSNR 1.5dbB better than the state-of-the-art on THuman4
dataset while being able to render at 20fps or more.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17115" title="Abstract">arXiv:2311.17115</a> [<a href="/pdf/2311.17115" title="Download PDF">pdf</a>, <a href="/ps/2311.17115" title="Download PostScript">ps</a>, <a href="/format/2311.17115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time- and Communication-Efficient Overlay Network Construction via  Gossip
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dufoulon%2C+F">Fabien Dufoulon</a>, 
<a href="/search/cs?searchtype=author&query=Moorman%2C+M">Michael Moorman</a>, 
<a href="/search/cs?searchtype=author&query=Moses%2C+W+K">William K. Moses Jr.</a>, 
<a href="/search/cs?searchtype=author&query=Pandurangan%2C+G">Gopal Pandurangan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Slightly shortened abstract
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">We focus on the well-studied problem of distributed overlay network
construction. We consider a synchronous gossip-based communication model where
in each round a node can send a message of small size to another node whose
identifier it knows. The network is assumed to be reconfigurable, i.e., a node
can add new connections (edges) to other nodes whose identifier it knows or
drop existing connections. Each node initially has only knowledge of its own
identifier and the identifiers of its neighbors. The overlay construction
problem is, given an arbitrary (connected) graph, to reconfigure it to obtain a
bounded-degree expander graph as efficiently as possible. The overlay
construction problem is relevant to building real-world peer-to-peer network
topologies that have desirable properties such as low diameter, high
conductance, robustness to adversarial deletions, etc.
<br />Our main result is that we show that starting from any arbitrary (connected)
graph $G$ on $n$ nodes and $m$ edges, we can construct an overlay network that
is a constant-degree expander in polylog $n$ rounds using only $\tilde{O}(n)$
messages. Our time and message bounds are both essentially optimal (up to
polylogarithmic factors). Our distributed overlay construction protocol is very
lightweight as it uses gossip (each node communicates with only one neighbor in
each round) and also scalable as it uses only $\tilde{O}(n)$ messages, which is
sublinear in $m$ (even when $m$ is moderately dense). To the best of our
knowledge, this is the first result that achieves overlay network construction
in polylog $n$ rounds and $o(m)$ messages. Our protocol uses graph sketches in
a novel way to construct an expander overlay that is both time and
communication efficient. A consequence of our overlay construction protocol is
that distributed computation can be performed very efficiently in this model.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17116" title="Abstract">arXiv:2311.17116</a> [<a href="/pdf/2311.17116" title="Download PDF">pdf</a>, <a href="/format/2311.17116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> REF$^2$-NeRF: Reflection and Refraction aware Neural Radiance Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+W">Wooseok Kim</a>, 
<a href="/search/cs?searchtype=author&query=Fukiage%2C+T">Taiki Fukiage</a>, 
<a href="/search/cs?searchtype=author&query=Oishi%2C+T">Takeshi Oishi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, significant progress has been made in the study of methods for 3D
reconstruction from multiple images using implicit neural representations,
exemplified by the neural radiance field (NeRF) method. Such methods, which are
based on volume rendering, can model various light phenomena, and various
extended methods have been proposed to accommodate different scenes and
situations. However, when handling scenes with multiple glass objects, e.g.,
objects in a glass showcase, modeling the target scene accurately has been
challenging due to the presence of multiple reflection and refraction effects.
Thus, this paper proposes a NeRF-based modeling method for scenes containing a
glass case. In the proposed method, refraction and reflection are modeled using
elements that are dependent and independent of the viewer's perspective. This
approach allows us to estimate the surfaces where refraction occurs, i.e.,
glass surfaces, and enables the separation and modeling of both direct and
reflected light components. Compared to existing methods, the proposed method
enables more accurate modeling of both glass refraction and the overall scene.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17117" title="Abstract">arXiv:2311.17117</a> [<a href="/pdf/2311.17117" title="Download PDF">pdf</a>, <a href="/format/2311.17117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for  Character Animation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Li Hu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+K">Ke Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bo%2C+L">Liefeng Bo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Character Animation aims to generating character videos from still images
through driving signals. Currently, diffusion models have become the mainstream
in visual generation research, owing to their robust generative capabilities.
However, challenges persist in the realm of image-to-video, especially in
character animation, where temporally maintaining consistency with detailed
information from character remains a formidable problem. In this paper, we
leverage the power of diffusion models and propose a novel framework tailored
for character animation. To preserve consistency of intricate appearance
features from reference image, we design ReferenceNet to merge detail features
via spatial attention. To ensure controllability and continuity, we introduce
an efficient pose guider to direct character's movements and employ an
effective temporal modeling approach to ensure smooth inter-frame transitions
between video frames. By expanding the training data, our approach can animate
arbitrary characters, yielding superior results in character animation compared
to other image-to-video methods. Furthermore, we evaluate our method on
benchmarks for fashion video and human dance synthesis, achieving
state-of-the-art results.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17118" title="Abstract">arXiv:2311.17118</a> [<a href="/pdf/2311.17118" title="Download PDF">pdf</a>, <a href="/format/2311.17118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaFocus: Towards End-to-end Weakly Supervised Learning for Long-Video  Action Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiaming Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hanjun Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kun-Yu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Junwei Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Developing end-to-end models for long-video action understanding tasks
presents significant computational and memory challenges. Existing works
generally build models on long-video features extracted by off-the-shelf action
recognition models, which are trained on short-video datasets in different
domains, making the extracted features suffer domain discrepancy. To avoid
this, action recognition models can be end-to-end trained on clips, which are
trimmed from long videos and labeled using action interval annotations. Such
fully supervised annotations are expensive to collect. Thus, a weakly
supervised method is needed for long-video action understanding at scale. Under
the weak supervision setting, action labels are provided for the whole video
without precise start and end times of the action clip. To this end, we propose
an AdaFocus framework. AdaFocus estimates the spike-actionness and temporal
positions of actions, enabling it to adaptively focus on action clips that
facilitate better training without the need for precise annotations.
Experiments on three long-video datasets show its effectiveness. Remarkably, on
two of datasets, models trained with AdaFocus under weak supervision outperform
those trained under full supervision. Furthermore, we form a weakly supervised
feature extraction pipeline with our AdaFocus, which enables significant
improvements on three long-video action understanding tasks.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17119" title="Abstract">arXiv:2311.17119</a> [<a href="/pdf/2311.17119" title="Download PDF">pdf</a>, <a href="/format/2311.17119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous Pose for Monocular Cameras in Neural Implicit Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Q">Qi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Paudel%2C+D+P">Danda Pani Paudel</a>, 
<a href="/search/cs?searchtype=author&query=Chhatkuli%2C+A">Ajad Chhatkuli</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we showcase the effectiveness of optimizing monocular camera
poses as a continuous function of time. The camera poses are represented using
an implicit neural function which maps the given time to the corresponding
camera pose. The mapped camera poses are then used for the downstream tasks
where joint camera pose optimization is also required. While doing so, the
network parameters -- that implicitly represent camera poses -- are optimized.
We exploit the proposed method in four diverse experimental settings, namely,
(1) NeRF from noisy poses; (2) NeRF from asynchronous Events; (3) Visual
Simultaneous Localization and Mapping (vSLAM); and (4) vSLAM with IMUs. In all
four settings, the proposed method performs significantly better than the
compared baselines and the state-of-the-art methods. Additionally, using the
assumption of continuous motion, changes in pose may actually live in a
manifold that has lower than 6 degrees of freedom (DOF) is also realized. We
call this low DOF motion representation as the \emph{intrinsic motion} and use
the approach in vSLAM settings, showing impressive camera tracking performance.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17121" title="Abstract">arXiv:2311.17121</a> [<a href="/pdf/2311.17121" title="Download PDF">pdf</a>, <a href="/format/2311.17121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Data Augmentation Improves Scribble-supervised Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schnell%2C+J">Jacob Schnell</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jieke Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+L">Lu Qi</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+V+T">Vincent Tao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+M">Meng Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advances in generative models, such as diffusion models, have made
generating high-quality synthetic images widely accessible. Prior works have
shown that training on synthetic images improves many perception tasks, such as
image classification, object detection, and semantic segmentation. We are the
first to explore generative data augmentations for scribble-supervised semantic
segmentation. We propose a generative data augmentation method that leverages a
ControlNet diffusion model conditioned on semantic scribbles to produce
high-quality training data. However, naive implementations of generative data
augmentations may inadvertently harm the performance of the downstream
segmentor rather than improve it. We leverage classifier-free diffusion
guidance to enforce class consistency and introduce encode ratios to trade off
data diversity for data realism. Using the guidance scale and encode ratio, we
are able to generate a spectrum of high-quality training images. We propose
multiple augmentation schemes and find that these schemes significantly impact
model performance, especially in the low-data regime. Our framework further
reduces the gap between the performance of scribble-supervised segmentation and
that of fully-supervised segmentation. We also show that our framework
significantly improves segmentation performance on small datasets, even
surpassing fully-supervised segmentation.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17122" title="Abstract">arXiv:2311.17122</a> [<a href="/pdf/2311.17122" title="Download PDF">pdf</a>, <a href="/format/2311.17122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Model Based Referring Camouflaged Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Shupeng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+G">Ge-Peng Ji</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+P">Pengda Qin</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+D">Deng-Ping Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bowen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Peng Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Referring camouflaged object detection (Ref-COD) is a recently-proposed
problem aiming to segment out specified camouflaged objects matched with a
textual or visual reference. This task involves two major challenges: the COD
domain-specific perception and multimodal reference-image alignment. Our
motivation is to make full use of the semantic intelligence and intrinsic
knowledge of recent Multimodal Large Language Models (MLLMs) to decompose this
complex task in a human-like way. As language is highly condensed and
inductive, linguistic expression is the main media of human knowledge learning,
and the transmission of knowledge information follows a multi-level progression
from simplicity to complexity. In this paper, we propose a large-model-based
Multi-Level Knowledge-Guided multimodal method for Ref-COD termed MLKG, where
multi-level knowledge descriptions from MLLM are organized to guide the large
vision model of segmentation to perceive the camouflage-targets and
camouflage-scene progressively and meanwhile deeply align the textual
references with camouflaged photos. To our knowledge, our contributions mainly
include: (1) This is the first time that the MLLM knowledge is studied for
Ref-COD and COD. (2) We, for the first time, propose decomposing Ref-COD into
two main perspectives of perceiving the target and scene by integrating MLLM
knowledge, and contribute a multi-level knowledge-guided method. (3) Our method
achieves the state-of-the-art on the Ref-COD benchmark outperforming numerous
strong competitors. Moreover, thanks to the injected rich knowledge, it
demonstrates zero-shot generalization ability on uni-modal COD datasets. We
will release our code soon.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17123" title="Abstract">arXiv:2311.17123</a> [<a href="/pdf/2311.17123" title="Download PDF">pdf</a>, <a href="/format/2311.17123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConTex-Human: Free-View Rendering of Human from a Single Image with  Texture-Consistent Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiangjun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaopeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yanpei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+L">Long Quan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> see project page: <a href="https://gaoxiangjun.github.io/contex_human/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this work, we propose a method to address the challenge of rendering a 3D
human from a single image in a free-view manner. Some existing approaches could
achieve this by using generalizable pixel-aligned implicit fields to
reconstruct a textured mesh of a human or by employing a 2D diffusion model as
guidance with the Score Distillation Sampling (SDS) method, to lift the 2D
image into 3D space. However, a generalizable implicit field often results in
an over-smooth texture field, while the SDS method tends to lead to a
texture-inconsistent novel view with the input image. In this paper, we
introduce a texture-consistent back view synthesis module that could transfer
the reference image content to the back view through depth and text-guided
attention injection. Moreover, to alleviate the color distortion that occurs in
the side region, we propose a visibility-aware patch consistency regularization
for texture mapping and refinement combined with the synthesized back view
texture. With the above techniques, we could achieve high-fidelity and
texture-consistent human rendering from a single image. Experiments conducted
on both real and synthetic data demonstrate the effectiveness of our method and
show that our approach outperforms previous baseline methods.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17124" title="Abstract">arXiv:2311.17124</a> [<a href="/pdf/2311.17124" title="Download PDF">pdf</a>, <a href="/format/2311.17124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A knowledge-driven AutoML architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cofaru%2C+C">Corneliu Cofaru</a>, 
<a href="/search/cs?searchtype=author&query=Loeckx%2C+J">Johan Loeckx</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
<p class="mathjax">This paper proposes a knowledge-driven AutoML architecture for pipeline and
deep feature synthesis. The main goal is to render the AutoML process
explainable and to leverage domain knowledge in the synthesis of pipelines and
features. The architecture explores several novel ideas: first, the
construction of pipelines and deep features is approached in an unified way.
Next, synthesis is driven by a shared knowledge system, interactively queried
as to what pipeline operations to use or features to compute. Lastly, the
synthesis processes takes decisions at runtime using partial solutions and
results of their application on data. Two experiments are conducted to
demonstrate the functionality of a na\"{\i}ve implementation of the proposed
architecture and to discuss its advantages, trade-offs as well as future
potential for AutoML.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17126" title="Abstract">arXiv:2311.17126</a> [<a href="/pdf/2311.17126" title="Download PDF">pdf</a>, <a href="/format/2311.17126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reason out Your Layout: Evoking the Layout Master from Large Language  Models for Text-to-Image Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaohui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yongfei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yingxiang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jianbo Yuan</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Q">Quanzeng You</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Li-Ping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongxia Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Recent advancements in text-to-image (T2I) generative models have shown
remarkable capabilities in producing diverse and imaginative visuals based on
text prompts. Despite the advancement, these diffusion models sometimes
struggle to translate the semantic content from the text into images entirely.
While conditioning on the layout has shown to be effective in improving the
compositional ability of T2I diffusion models, they typically require manual
layout input. In this work, we introduce a novel approach to improving T2I
diffusion models using Large Language Models (LLMs) as layout generators. Our
method leverages the Chain-of-Thought prompting of LLMs to interpret text and
generate spatially reasonable object layouts. The generated layout is then used
to enhance the generated images' composition and spatial accuracy. Moreover, we
propose an efficient adapter based on a cross-attention mechanism, which
explicitly integrates the layout information into the stable diffusion models.
Our experiments demonstrate significant improvements in image quality and
layout accuracy, showcasing the potential of LLMs in augmenting generative
image models.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17128" title="Abstract">arXiv:2311.17128</a> [<a href="/pdf/2311.17128" title="Download PDF">pdf</a>, <a href="/format/2311.17128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vulnerability Analysis of Transformer-based Optical Character  Recognition to Adversarial Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beerens%2C+L">Lucas Beerens</a>, 
<a href="/search/cs?searchtype=author&query=Higham%2C+D+J">Desmond J. Higham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent advancements in Optical Character Recognition (OCR) have been driven
by transformer-based models. OCR systems are critical in numerous high-stakes
domains, yet their vulnerability to adversarial attack remains largely
uncharted territory, raising concerns about security and compliance with
emerging AI regulations. In this work we present a novel framework to assess
the resilience of Transformer-based OCR (TrOCR) models. We develop and assess
algorithms for both targeted and untargeted attacks. For the untargeted case,
we measure the Character Error Rate (CER), while for the targeted case we use
the success ratio. We find that TrOCR is highly vulnerable to untargeted
attacks and somewhat less vulnerable to targeted attacks. On a benchmark
handwriting data set, untargeted attacks can cause a CER of more than 1 without
being noticeable to the eye. With a similar perturbation size, targeted attacks
can lead to success rates of around $25\%$ -- here we attacked single tokens,
requiring TrOCR to output the tenth most likely token from a large vocabulary.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17129" title="Abstract">arXiv:2311.17129</a> [<a href="/pdf/2311.17129" title="Download PDF">pdf</a>, <a href="/format/2311.17129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feedback RoI Features Improve Aerial Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+B">Botao Ren</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Botian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tengyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhidong Deng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Neuroscience studies have shown that the human visual system utilizes
high-level feedback information to guide lower-level perception, enabling
adaptation to signals of different characteristics. In light of this, we
propose Feedback multi-Level feature Extractor (Flex) to incorporate a similar
mechanism for object detection. Flex refines feature selection based on
image-wise and instance-level feedback information in response to image quality
variation and classification uncertainty. Experimental results show that Flex
offers consistent improvement to a range of existing SOTA methods on the
challenging aerial object detection datasets including DOTA-v1.0, DOTA-v1.5,
and HRSC2016. Although the design originates in aerial image detection, further
experiments on MS COCO also reveal our module's efficacy in general detection
models. Quantitative and qualitative analyses indicate that the improvements
are closely related to image qualities, which match our motivation.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17132" title="Abstract">arXiv:2311.17132</a> [<a href="/pdf/2311.17132" title="Download PDF">pdf</a>, <a href="/format/2311.17132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TransNeXt: Robust Foveal Visual Perception for Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+D">Dai Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code will be released at <a href="https://github.com/DaiShiResearch/TransNeXt">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Due to the depth degradation effect in residual connections, many efficient
Vision Transformers models that rely on stacking layers for information
exchange often fail to form sufficient information mixing, leading to unnatural
visual perception. To address this issue, in this paper, we propose Aggregated
Attention, a biomimetic design-based token mixer that simulates biological
foveal vision and continuous eye movement while enabling each token on the
feature map to have a global perception. Furthermore, we incorporate learnable
tokens that interact with conventional queries and keys, which further
diversifies the generation of affinity matrices beyond merely relying on the
similarity between queries and keys. Our approach does not rely on stacking for
information exchange, thus effectively avoiding depth degradation and achieving
natural visual perception. Additionally, we propose Convolutional GLU, a
channel mixer that bridges the gap between GLU and SE mechanism, which empowers
each token to have channel attention based on its nearest neighbor image
features, enhancing local modeling capability and model robustness. We combine
aggregated attention and convolutional GLU to create a new visual backbone
called TransNeXt. Extensive experiments demonstrate that our TransNeXt achieves
state-of-the-art performance across multiple model sizes. At a resolution of
$224^2$, TransNeXt-Tiny attains an ImageNet accuracy of 84.0%, surpassing
ConvNeXt-B with 69% fewer parameters. Our TransNeXt-Base achieves an ImageNet
accuracy of 86.2% and an ImageNet-A accuracy of 61.6% at a resolution of
$384^2$, a COCO object detection mAP of 57.1, and an ADE20K semantic
segmentation mIoU of 54.7.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17133" title="Abstract">arXiv:2311.17133</a> [<a href="/pdf/2311.17133" title="Download PDF">pdf</a>, <a href="/format/2311.17133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deployment of a Robust and Explainable Mortality Prediction Model: The  COVID-19 Pandemic and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Epifano%2C+J+R">Jacob R. Epifano</a>, 
<a href="/search/cs?searchtype=author&query=Glass%2C+S">Stephen Glass</a>, 
<a href="/search/cs?searchtype=author&query=Ramachandran%2C+R+P">Ravi P. Ramachandran</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+S">Sharad Patel</a>, 
<a href="/search/cs?searchtype=author&query=Masino%2C+A+J">Aaron J. Masino</a>, 
<a href="/search/cs?searchtype=author&query=Rasool%2C+G">Ghulam Rasool</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study investigated the performance, explainability, and robustness of
deployed artificial intelligence (AI) models in predicting mortality during the
COVID-19 pandemic and beyond. The first study of its kind, we found that
Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our
models to maintain performance amidst significant data shifts. Our results
emphasize the importance of developing robust AI models capable of matching or
surpassing clinician predictions, even under challenging conditions. Our
exploration of model explainability revealed that stochastic models generate
more diverse and personalized explanations thereby highlighting the need for AI
models that provide detailed and individualized insights in real-world clinical
settings. Furthermore, we underscored the importance of quantifying uncertainty
in AI models which enables clinicians to make better-informed decisions based
on reliable predictions. Our study advocates for prioritizing implementation
science in AI research for healthcare and ensuring that AI solutions are
practical, beneficial, and sustainable in real-world clinical environments. By
addressing unique challenges and complexities in healthcare settings,
researchers can develop AI models that effectively improve clinical practice
and patient outcomes.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17134" title="Abstract">arXiv:2311.17134</a> [<a href="/pdf/2311.17134" title="Download PDF">pdf</a>, <a href="/format/2311.17134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> \texttt{GlycoNMR}: Dataset and benchmarks for NMR chemical shift  prediction of carbohydrates with graph neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zizhang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Badman%2C+R+P">Ryan Paul Badman</a>, 
<a href="/search/cs?searchtype=author&query=Foley%2C+L">Lachele Foley</a>, 
<a href="/search/cs?searchtype=author&query=Woods%2C+R">Robert Woods</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+P">Pengyu Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Molecular representation learning (MRL) is a powerful tool for bridging the
gap between machine learning and chemical sciences, as it converts molecules
into numerical representations while preserving their chemical features. These
encoded representations serve as a foundation for various downstream
biochemical studies, including property prediction and drug design. MRL has had
great success with proteins and general biomolecule datasets. Yet, in the
growing sub-field of glycoscience (the study of carbohydrates, where longer
carbohydrates are also called glycans), MRL methods have been barely explored.
This under-exploration can be primarily attributed to the limited availability
of comprehensive and well-curated carbohydrate-specific datasets and a lack of
Machine learning (ML) pipelines specifically tailored to meet the unique
problems presented by carbohydrate data. Since interpreting and annotating
carbohydrate-specific data is generally more complicated than protein data,
domain experts are usually required to get involved. The existing MRL methods,
predominately optimized for proteins and small biomolecules, also cannot be
directly used in carbohydrate applications without special modifications. To
address this challenge, accelerate progress in glycoscience, and enrich the
data resources of the MRL community, we introduce GlycoNMR. GlycoNMR contains
two laboriously curated datasets with 2,609 carbohydrate structures and 211,543
annotated nuclear magnetic resonance (NMR) chemical shifts for precise
atomic-level prediction. We tailored carbohydrate-specific features and adapted
existing MRL models to tackle this problem effectively. For illustration, we
benchmark four modified MRL models on our new datasets.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17135" title="Abstract">arXiv:2311.17135</a> [<a href="/pdf/2311.17135" title="Download PDF">pdf</a>, <a href="/format/2311.17135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TLControl: Trajectory and Language Control for Human Motion Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+W">Weilin Wan</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Z">Zhiyang Dou</a>, 
<a href="/search/cs?searchtype=author&query=Komura%2C+T">Taku Komura</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jayaraman%2C+D">Dinesh Jayaraman</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingjie Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Controllable human motion synthesis is essential for applications in AR/VR,
gaming, movies, and embodied AI. Existing methods often focus solely on either
language or full trajectory control, lacking precision in synthesizing motions
aligned with user-specified trajectories, especially for multi-joint control.
To address these issues, we present TLControl, a new method for realistic human
motion synthesis, incorporating both low-level trajectory and high-level
language semantics controls. Specifically, we first train a VQ-VAE to learn a
compact latent motion space organized by body parts. We then propose a Masked
Trajectories Transformer to make coarse initial predictions of full
trajectories of joints based on the learned latent motion space, with
user-specified partial trajectories and text descriptions as conditioning.
Finally, we introduce an efficient test-time optimization to refine these
coarse predictions for accurate trajectory control. Experiments demonstrate
that TLControl outperforms the state-of-the-art in trajectory accuracy and time
efficiency, making it practical for interactive and high-quality animation
generation.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17136" title="Abstract">arXiv:2311.17136</a> [<a href="/pdf/2311.17136" title="Download PDF">pdf</a>, <a href="/format/2311.17136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniIR: Training and Benchmarking Universal Multimodal Information  Retrievers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+C">Cong Wei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haonan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hexiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Ge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Ritter%2C+A">Alan Ritter</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenhu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our code and dataset are available on this project page: <a href="https://tiger-ai-lab.github.io/UniIR/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Existing information retrieval (IR) models often assume a homogeneous format,
limiting their applicability to diverse user needs, such as searching for
images with text descriptions, searching for a news article with a headline
image, or finding a similar photo with a query image. To approach such
different information-seeking demands, we introduce UniIR, a unified
instruction-guided multimodal retriever capable of handling eight distinct
retrieval tasks across modalities. UniIR, a single retrieval system jointly
trained on ten diverse multimodal-IR datasets, interprets user instructions to
execute various retrieval tasks, demonstrating robust performance across
existing datasets and zero-shot generalization to new tasks. Our experiments
highlight that multi-task training and instruction tuning are keys to UniIR's
generalization ability. Additionally, we construct the M-BEIR, a multimodal
retrieval benchmark with comprehensive results, to standardize the evaluation
of universal multimodal information retrieval.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17137" title="Abstract">arXiv:2311.17137</a> [<a href="/pdf/2311.17137" title="Download PDF">pdf</a>, <a href="/format/2311.17137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Models: What do they know? Do they know things? Let&#x27;s find  out!
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xiaodan Du</a>, 
<a href="/search/cs?searchtype=author&query=Kolkin%2C+N">Nicholas Kolkin</a>, 
<a href="/search/cs?searchtype=author&query=Shakhnarovich%2C+G">Greg Shakhnarovich</a>, 
<a href="/search/cs?searchtype=author&query=Bhattad%2C+A">Anand Bhattad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://intrinsic-lora.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Generative models have been shown to be capable of synthesizing highly
detailed and realistic images. It is natural to suspect that they implicitly
learn to model some image intrinsics such as surface normals, depth, or
shadows. In this paper, we present compelling evidence that generative models
indeed internally produce high-quality scene intrinsic maps. We introduce
Intrinsic LoRA (I LoRA), a universal, plug-and-play approach that transforms
any generative model into a scene intrinsic predictor, capable of extracting
intrinsic scene maps directly from the original generator network without
needing additional decoders or fully fine-tuning the original network. Our
method employs a Low-Rank Adaptation (LoRA) of key feature maps, with newly
learned parameters that make up less than 0.6% of the total parameters in the
generative model. Optimized with a small set of labeled images, our
model-agnostic approach adapts to various generative architectures, including
Diffusion models, GANs, and Autoregressive models. We show that the scene
intrinsic maps produced by our method compare well with, and in some cases
surpass those generated by leading supervised techniques.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17138" title="Abstract">arXiv:2311.17138</a> [<a href="/pdf/2311.17138" title="Download PDF">pdf</a>, <a href="/format/2311.17138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shadows Don&#x27;t Lie and Lines Can&#x27;t Bend! Generative Models don&#x27;t know  Projective Geometry...for now
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+A">Ayush Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+H">Hanlin Mai</a>, 
<a href="/search/cs?searchtype=author&query=Mahapatra%2C+A">Amitabh Mahapatra</a>, 
<a href="/search/cs?searchtype=author&query=Lazebnik%2C+S">Svetlana Lazebnik</a>, 
<a href="/search/cs?searchtype=author&query=Forsyth%2C+D+A">D.A. Forsyth</a>, 
<a href="/search/cs?searchtype=author&query=Bhattad%2C+A">Anand Bhattad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://projective-geometry.github.io">this https URL</a> | First three authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Generative models can produce impressively realistic images. This paper
demonstrates that generated images have geometric features different from those
of real images. We build a set of collections of generated images, prequalified
to fool simple, signal-based classifiers into believing they are real. We then
show that prequalified generated images can be identified reliably by
classifiers that only look at geometric properties. We use three such
classifiers. All three classifiers are denied access to image pixels, and look
only at derived geometric features. The first classifier looks at the
perspective field of the image, the second looks at lines detected in the
image, and the third looks at relations between detected objects and shadows.
Our procedure detects generated images more reliably than SOTA local signal
based detectors, for images from a number of distinct generators. Saliency maps
suggest that the classifiers can identify geometric problems reliably. We
conclude that current generators cannot reliably reproduce geometric properties
of real images.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17154" title="Abstract">arXiv:2311.17154</a> [<a href="/pdf/2311.17154" title="Download PDF">pdf</a>, <a href="/format/2311.17154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pragmatic Radiology Report Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D">Dang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chacha Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">He He</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Chenhao Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 1 figure, 18 tables. Code at <a href="https://github.com/ChicagoHAI/llm_radiology">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">When pneumonia is not found on a chest X-ray, should the report describe this
negative observation or omit it? We argue that this question cannot be answered
from the X-ray alone and requires a pragmatic perspective, which captures the
communicative goal that radiology reports serve between radiologists and
patients. However, the standard image-to-text formulation for radiology report
generation fails to incorporate such pragmatic intents. Following this
pragmatic perspective, we demonstrate that the indication, which describes why
a patient comes for an X-ray, drives the mentions of negative observations and
introduce indications as additional input to report generation. With respect to
the output, we develop a framework to identify uninferable information from the
image as a source of model hallucinations, and limit them by cleaning
groundtruth reports. Finally, we use indications and cleaned groundtruth
reports to develop pragmatic models, and show that they outperform existing
methods not only in new pragmatics-inspired metrics (+4.3 Negative F1) but also
in standard metrics (+6.3 Positive F1 and +11.0 BLEU-2).
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17165" title="Abstract">arXiv:2311.17165</a> [<a href="/pdf/2311.17165" title="Download PDF">pdf</a>, <a href="/ps/2311.17165" title="Download PostScript">ps</a>, <a href="/format/2311.17165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> (Ir)rationality in AI: State of the Art, Research Challenges and Open  Questions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Macmillan-Scott%2C+O">Olivia Macmillan-Scott</a>, 
<a href="/search/cs?searchtype=author&query=Musolesi%2C+M">Mirco Musolesi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">The concept of rationality is central to the field of artificial
intelligence. Whether we are seeking to simulate human reasoning, or the goal
is to achieve bounded optimality, we generally seek to make artificial agents
as rational as possible. Despite the centrality of the concept within AI, there
is no unified definition of what constitutes a rational agent. This article
provides a survey of rationality and irrationality in artificial intelligence,
and sets out the open questions in this area. The understanding of rationality
in other fields has influenced its conception within artificial intelligence,
in particular work in economics, philosophy and psychology. Focusing on the
behaviour of artificial agents, we consider irrational behaviours that can
prove to be optimal in certain scenarios. Some methods have been developed to
deal with irrational agents, both in terms of identification and interaction,
however work in this area remains limited. Methods that have up to now been
developed for other purposes, namely adversarial scenarios, may be adapted to
suit interactions with artificial agents. We further discuss the interplay
between human and artificial agents, and the role that rationality plays within
this interaction; many questions remain in this area, relating to potentially
irrational behaviour of both humans and artificial agents.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17173" title="Abstract">arXiv:2311.17173</a> [<a href="/pdf/2311.17173" title="Download PDF">pdf</a>, <a href="/ps/2311.17173" title="Download PostScript">ps</a>, <a href="/format/2311.17173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A personalized Uncertainty Quantification framework for patient survival  models: estimating individual uncertainty of patients with metastatic brain  tumors in the absence of ground truth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Aarzu Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Carpenter%2C+D">David Carpenter</a>, 
<a href="/search/cs?searchtype=author&query=Mullikin%2C+T">Trey Mullikin</a>, 
<a href="/search/cs?searchtype=author&query=Reitman%2C+Z+J">Zachary J. Reitman</a>, 
<a href="/search/cs?searchtype=author&query=Floyd%2C+S">Scott Floyd</a>, 
<a href="/search/cs?searchtype=author&query=Kirkpatrick%2C+J">John Kirkpatrick</a>, 
<a href="/search/cs?searchtype=author&query=Salama%2C+J+K">Joseph K. Salama</a>, 
<a href="/search/cs?searchtype=author&query=Sperduto%2C+P+W">Paul W. Sperduto</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jian-Guo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Bashir%2C+M+R">Mustafa R. Bashir</a>, 
<a href="/search/cs?searchtype=author&query=Lafata%2C+K+J">Kyle J. Lafata</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM); Applications (stat.AP)

</div>
<p class="mathjax">TodevelopanovelUncertaintyQuantification (UQ) framework to estimate the
uncertainty of patient survival models in the absence of ground truth, we
developed and evaluated our approach based on a dataset of 1383 patients
treated with stereotactic radiosurgery (SRS) for brain metastases between
January 2015 and December 2020. Our motivating hypothesis is that a
time-to-event prediction of a test patient on inference is more certain given a
higher feature-space-similarity to patients in the training set. Therefore, the
uncertainty for a particular patient-of-interest is represented by the
concordance index between a patient similarity rank and a prediction similarity
rank. Model uncertainty was defined as the increased percentage of the max
uncertainty-constrained-AUC compared to the model AUC. We evaluated our method
on multiple clinically-relevant endpoints, including time to intracranial
progression (ICP), progression-free survival (PFS) after SRS, overall survival
(OS), and time to ICP and/or death (ICPD), on a variety of both statistical and
non-statistical models, including CoxPH, conditional survival forest (CSF), and
neural multi-task linear regression (NMTLR). Our results show that all models
had the lowest uncertainty on ICP (2.21%) and the highest uncertainty (17.28%)
on ICPD. OS models demonstrated high variation in uncertainty performance,
where NMTLR had the lowest uncertainty(1.96%)and CSF had the highest
uncertainty (14.29%). In conclusion, our method can estimate the uncertainty of
individual patient survival modeling results. As expected, our data empirically
demonstrate that as model uncertainty measured via our technique increases, the
similarity between a feature-space and its predicted outcome decreases.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17177" title="Abstract">arXiv:2311.17177</a> [<a href="/pdf/2311.17177" title="Download PDF">pdf</a>, <a href="/format/2311.17177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> THInImg: Cross-modal Steganography for Presenting Talking Heads in  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+X">Xuefei Ning</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xinru Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Cross-modal Steganography is the practice of concealing secret signals in
publicly available cover signals (distinct from the modality of the secret
signals) unobtrusively. While previous approaches primarily concentrated on
concealing a relatively small amount of information, we propose THInImg, which
manages to hide lengthy audio data (and subsequently decode talking head video)
inside an identity image by leveraging the properties of human face, which can
be effectively utilized for covert communication, transmission and copyright
protection. THInImg consists of two parts: the encoder and decoder. Inside the
encoder-decoder pipeline, we introduce a novel architecture that substantially
increase the capacity of hiding audio in images. Moreover, our framework can be
extended to iteratively hide multiple audio clips into an identity image,
offering multiple levels of control over permissions. We conduct extensive
experiments to prove the effectiveness of our method, demonstrating that
THInImg can present up to 80 seconds of high quality talking-head video
(including audio) in an identity image with 160x160 resolution.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17179" title="Abstract">arXiv:2311.17179</a> [<a href="/pdf/2311.17179" title="Download PDF">pdf</a>, <a href="/format/2311.17179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SatCLIP: Global, General-Purpose Location Embeddings with Satellite  Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klemmer%2C+K">Konstantin Klemmer</a>, 
<a href="/search/cs?searchtype=author&query=Rolf%2C+E">Esther Rolf</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+C">Caleb Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Mackey%2C+L">Lester Mackey</a>, 
<a href="/search/cs?searchtype=author&query=Ru%C3%9Fwurm%2C+M">Marc Ru&#xdf;wurm</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Geographic location is essential for modeling tasks in fields ranging from
ecology to epidemiology to the Earth system sciences. However, extracting
relevant and meaningful characteristics of a location can be challenging, often
entailing expensive data fusion or data distillation from global imagery
datasets. To address this challenge, we introduce Satellite Contrastive
Location-Image Pretraining (SatCLIP), a global, general-purpose geographic
location encoder that learns an implicit representation of locations from
openly available satellite imagery. Trained location encoders provide vector
embeddings summarizing the characteristics of any given location for convenient
usage in diverse downstream tasks. We show that SatCLIP embeddings, pretrained
on globally sampled multi-spectral Sentinel-2 satellite data, can be used in
various predictive tasks that depend on location information but not
necessarily satellite imagery, including temperature prediction, animal
recognition in imagery, and population density estimation. Across tasks,
SatCLIP embeddings consistently outperform embeddings from existing pretrained
location encoders, ranging from models trained on natural images to models
trained on semantic context. SatCLIP embeddings also help to improve geographic
generalization. This demonstrates the potential of general-purpose location
encoders and opens the door to learning meaningful representations of our
planet from the vast, varied, and largely untapped modalities of geospatial
data.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17190" title="Abstract">arXiv:2311.17190</a> [<a href="/pdf/2311.17190" title="Download PDF">pdf</a>, <a href="/format/2311.17190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimax Exploiter: A Data Efficient Approach for Competitive Self-Play
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bairamian%2C+D">Daniel Bairamian</a>, 
<a href="/search/cs?searchtype=author&query=Marcotte%2C+P">Philippe Marcotte</a>, 
<a href="/search/cs?searchtype=author&query=Romoff%2C+J">Joshua Romoff</a>, 
<a href="/search/cs?searchtype=author&query=Robert%2C+G">Gabriel Robert</a>, 
<a href="/search/cs?searchtype=author&query=Nowrouzezahrai%2C+D">Derek Nowrouzezahrai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Recent advances in Competitive Self-Play (CSP) have achieved, or even
surpassed, human level performance in complex game environments such as Dota 2
and StarCraft II using Distributed Multi-Agent Reinforcement Learning (MARL).
One core component of these methods relies on creating a pool of learning
agents -- consisting of the Main Agent, past versions of this agent, and
Exploiter Agents -- where Exploiter Agents learn counter-strategies to the Main
Agents. A key drawback of these approaches is the large computational cost and
physical time that is required to train the system, making them impractical to
deploy in highly iterative real-life settings such as video game productions.
In this paper, we propose the Minimax Exploiter, a game theoretic approach to
exploiting Main Agents that leverages knowledge of its opponents, leading to
significant increases in data efficiency. We validate our approach in a
diversity of settings, including simple turn based games, the arcade learning
environment, and For Honor, a modern video game. The Minimax Exploiter
consistently outperforms strong baselines, demonstrating improved stability and
data efficiency, leading to a robust CSP-MARL method that is both flexible and
easy to deploy.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17197" title="Abstract">arXiv:2311.17197</a> [<a href="/pdf/2311.17197" title="Download PDF">pdf</a>, <a href="/format/2311.17197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Marine$\mathcal{X}$: Design and Implementation of Unmanned Surface  Vessel for Vision Guided Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Din%2C+M+U">Muhayy Ud Din</a>, 
<a href="/search/cs?searchtype=author&query=Humais%2C+A">Ahmed Humais</a>, 
<a href="/search/cs?searchtype=author&query=Akram%2C+W">Waseem Akram</a>, 
<a href="/search/cs?searchtype=author&query=Alblooshi%2C+M">Mohamed Alblooshi</a>, 
<a href="/search/cs?searchtype=author&query=Saoud%2C+L+S">Lyes Saad Saoud</a>, 
<a href="/search/cs?searchtype=author&query=Alblooshi%2C+A">Abdelrahman Alblooshi</a>, 
<a href="/search/cs?searchtype=author&query=Seneviratne%2C+L">Lakmal Seneviratne</a>, 
<a href="/search/cs?searchtype=author&query=Hussain%2C+I">Irfan Hussain</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted in ICAR
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The 21st International Conference on Advanced Robotics (ICAR 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Marine robots, particularly Unmanned Surface Vessels (USVs), have gained
considerable attention for their diverse applications in maritime tasks,
including search and rescue, environmental monitoring, and maritime security.
This paper presents the design and implementation of a USV named
marine$\mathcal{X}$. The hardware components of marine$\mathcal{X}$ are
meticulously developed to ensure robustness, efficiency, and adaptability to
varying environmental conditions. Furthermore, the integration of a
vision-based object tracking algorithm empowers marine$\mathcal{X}$ to
autonomously track and monitor specific objects on the water surface. The
control system utilizes PID control, enabling precise navigation of
marine$\mathcal{X}$ while maintaining a desired course and distance to the
target object. To assess the performance of marine$\mathcal{X}$, comprehensive
testing is conducted, encompassing simulation, trials in the marine pool, and
real-world tests in the open sea. The successful outcomes of these tests
demonstrate the USV's capabilities in achieving real-time object tracking,
showcasing its potential for various applications in maritime operations.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17200" title="Abstract">arXiv:2311.17200</a> [<a href="/pdf/2311.17200" title="Download PDF">pdf</a>, <a href="/format/2311.17200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Greybox fuzzing time-intensive programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huntsman%2C+S">Steve Huntsman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">We examine (directed) greybox fuzzing from a geometrical perspective, viewing
dissimilarities on inputs and on control flow graphs (with dynamical
statistics) as primitive objects of interest. We prototype and evaluate
GoExploreFuzz, a greybox fuzzer for time-intensive programs that incorporates
this perspective. The results indicate useful capabilities for greybox fuzzing
that have hitherto been underutilized, notably quantifying the diversity of
paths and autonomously tuning the "bandwidth" of mutations.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17201" title="Abstract">arXiv:2311.17201</a> [<a href="/pdf/2311.17201" title="Download PDF">pdf</a>, <a href="/format/2311.17201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Control Synthesis for Hybrid Systems through Local Control Barrier  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Black%2C+M">Mitchell Black</a>, 
<a href="/search/cs?searchtype=author&query=Fainekos%2C+G">Georgios Fainekos</a>, 
<a href="/search/cs?searchtype=author&query=Hoxha%2C+B">Bardh Hoxha</a>, 
<a href="/search/cs?searchtype=author&query=Okamoto%2C+H">Hideki Okamoto</a>, 
<a href="/search/cs?searchtype=author&query=Mangharam%2C+R">Rahul Mangharam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Control Barrier Functions (CBF) have provided a very versatile framework for
the synthesis of safe control architectures for a wide class of nonlinear
dynamical systems. Typically, CBF-based synthesis approaches apply to systems
that exhibit nonlinear -- but smooth -- relationship in the state of the system
and linear relationship in the control input. In contrast, the problem of safe
control synthesis using CBF for hybrid dynamical systems, i.e., systems which
have a discontinuous relationship in the system state, remains largely
unexplored. In this work, we build upon the progress on CBF-based control to
formulate a theory for safe control synthesis for hybrid dynamical systems.
Under the assumption that local CBFs can be synthesized for each mode of
operation of the hybrid system, we show how to construct CBF that can guarantee
safe switching between modes. The end result is a switching CBF-based
controller which provides global safety guarantees. The effectiveness of our
proposed approach is demonstrated on two simulation studies.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17203" title="Abstract">arXiv:2311.17203</a> [<a href="/pdf/2311.17203" title="Download PDF">pdf</a>, <a href="/ps/2311.17203" title="Download PostScript">ps</a>, <a href="/format/2311.17203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Review on Cryptocurrency Transaction Methods for Money Laundering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Almeida%2C+H">Hugo Almeida</a>, 
<a href="/search/cs?searchtype=author&query=Pinto%2C+P">Pedro Pinto</a>, 
<a href="/search/cs?searchtype=author&query=Vilas%2C+A+F">Ana Fern&#xe1;ndez Vilas</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 5th International Conference on Finance,
  Economics, Management and IT Business - FEMIB 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Cryptocurrencies are considered relevant assets and they are currently used
as an investment or to carry out transactions. However, specific
characteristics commonly associated with the cryptocurrencies such as
irreversibility, immutability, decentralized architecture, absence of control
authority, mobility, and pseudo-anonymity make them appealing for money
laundering activities. Thus, the collection and characterization of current
cryptocurrency-based methods used for money laundering are paramount to
understanding the circulation flows of physical and digital money and
preventing this illegal activity. In this paper, a collection of cryptocurrency
transaction methods is presented and distributed through the money laundering
life cycle. Each method is analyzed and classified according to the phase of
money laundering it corresponds to. The result of this article may in the
future help design efficient strategies to prevent illegal money laundering
activities.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17204" title="Abstract">arXiv:2311.17204</a> [<a href="/pdf/2311.17204" title="Download PDF">pdf</a>, <a href="/format/2311.17204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal EEG Electrode Set for Emotion Recognition From Brain Signals: An  Empirical Quest
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prodhan%2C+R+A">Rumman Ahmed Prodhan</a>, 
<a href="/search/cs?searchtype=author&query=Akter%2C+S">Sumya Akter</a>, 
<a href="/search/cs?searchtype=author&query=Pias%2C+T+S">Tanmoy Sarkar Pias</a>, 
<a href="/search/cs?searchtype=author&query=Adnan%2C+M+A">Md. Akhtaruzzaman Adnan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The human brain is a complex organ, still completely undiscovered, that
controls almost all the parts of the body. Apart from survival, the human brain
stimulates emotions. Recent research indicates that brain signals can be very
effective for emotion recognition. However, which parts of the brain exhibit
most of the emotions is still under-explored. In this study, we empirically
analyze the contribution of each part of the brain in exhibiting emotions. We
use the DEAP dataset to find the most optimal electrode set which eventually
leads to the effective brain part associated with emotions. We use Fast Fourier
Transformation for effective feature extraction and a 1D-CNN with residual
connection for classification. Though 32 electrodes from the DEAP dataset got
an accuracy of 97.34%, only 12 electrodes (F7, P8, O1, F8, C4, T7, PO3, Fp1,
Fp2, O2, P3, and Fz) achieve 95.81% accuracy. This study also shows that adding
more than 10 electrodes does not improve performance significantly. Moreover,
the frontal lobe is the most important for recognizing emotion.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17211" title="Abstract">arXiv:2311.17211</a> [<a href="/pdf/2311.17211" title="Download PDF">pdf</a>, <a href="/format/2311.17211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LSTM model predicting outcome of strategic thinking task exhibits  representations of level-k thinking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stepanik%2C+M">Mario Stepanik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Which neural mechanisms underlie strategic thinking in the human brain?
Neuroeconomic research has not yet bridged the gap between theoretical models
of higher-order reasoning and the precise mechanisms implemented in neural
networks in the human brain. In this paper, I demonstrate that a recurrent
neural network model can learn to perform strongly in the simple strategic game
Rock-Paper-Scissors. In doing so, it develops implicit representations of
strategically important variables (the levels $k$ of reasoning) which
economists have postulated in theoretical models. These representations can be
extracted from the hidden activations of the neural network. These findings
hint at a connection between the mechanisms implicit in recurrent neural
networks and models of strategic thinking in economic theory. Future empirical
brain research can investigate whether these mechanisms correspond to
mechanisms implicit in biological neural networks.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17212" title="Abstract">arXiv:2311.17212</a> [<a href="/pdf/2311.17212" title="Download PDF">pdf</a>, <a href="/format/2311.17212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Failure Artifact Scenarios to Understand High School Students&#x27; Growth in  Troubleshooting Physical Computing Projects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morales-Navarro%2C+L">L. Morales-Navarro</a>, 
<a href="/search/cs?searchtype=author&query=Fields%2C+D+A">D. A. Fields</a>, 
<a href="/search/cs?searchtype=author&query=Barapatre%2C+D">D. Barapatre</a>, 
<a href="/search/cs?searchtype=author&query=Kafai%2C+Y+B">Y. B. Kafai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Debugging physical computing projects provides a rich context to understand
cross-disciplinary problem solving that integrates multiple domains of
computing and engineering. Yet understanding and assessing students' learning
of debugging remains a challenge, particularly in understudied areas such as
physical computing, since finding and fixing hardware and software bugs is a
deeply contextual practice. In this paper we draw on the rich history of
clinical interviews to develop and pilot "failure artifact scenarios" in order
to study changes in students' approaches to debugging and troubleshooting
electronic textiles (e-textiles). We applied this clinical interview protocol
before and after an eight-week-long e-textiles unit. We analyzed pre/post
clinical interviews from 18 students at four different schools. The analysis
revealed that students improved in identifying bugs with greater specificity,
and across domains, and in considering multiple causes for bugs. We discuss
implications for developing tools to assess students' debugging abilities
through contextualized debugging scenarios in physical computing.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17213" title="Abstract">arXiv:2311.17213</a> [<a href="/pdf/2311.17213" title="Download PDF">pdf</a>, <a href="/ps/2311.17213" title="Download PostScript">ps</a>, <a href="/format/2311.17213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> General-Purpose vs. Domain-Adapted Large Language Models for Extraction  of Data from Thoracic Radiology Reports
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhanaliwala%2C+A+H">Ali H. Dhanaliwala</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+R">Rikhiya Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Karn%2C+S+K">Sanjeev Kumar Karn</a>, 
<a href="/search/cs?searchtype=author&query=Ullaskrishnan%2C+P">Poikavila Ullaskrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Farri%2C+O">Oladimeji Farri</a>, 
<a href="/search/cs?searchtype=author&query=Comaniciu%2C+D">Dorin Comaniciu</a>, 
<a href="/search/cs?searchtype=author&query=Kahn%2C+C+E">Charles E. Kahn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Radiologists produce unstructured data that could be valuable for clinical
care when consumed by information systems. However, variability in style limits
usage. Study compares performance of system using domain-adapted language model
(RadLing) and general-purpose large language model (GPT-4) in extracting common
data elements (CDE) from thoracic radiology reports. Three radiologists
annotated a retrospective dataset of 1300 thoracic reports (900 training, 400
test) and mapped to 21 pre-selected relevant CDEs. RadLing was used to generate
embeddings for sentences and identify CDEs using cosine-similarity, which were
mapped to values using light-weight mapper. GPT-4 system used OpenAI's
general-purpose embeddings to identify relevant CDEs and used GPT-4 to map to
values. The output CDE:value pairs were compared to the reference standard; an
identical match was considered true positive. Precision (positive predictive
value) was 96% (2700/2824) for RadLing and 99% (2034/2047) for GPT-4. Recall
(sensitivity) was 94% (2700/2876) for RadLing and 70% (2034/2887) for GPT-4;
the difference was statistically significant (P&lt;.001). RadLing's domain-adapted
embeddings were more sensitive in CDE identification (95% vs 71%) and its
light-weight mapper had comparable precision in value assignment (95.4% vs
95.0%). RadLing system exhibited higher performance than GPT-4 system in
extracting CDEs from radiology reports. RadLing system's domain-adapted
embeddings outperform general-purpose embeddings from OpenAI in CDE
identification and its light-weight value mapper achieves comparable precision
to large GPT-4. RadLing system offers operational advantages including local
deployment and reduced runtime costs. Domain-adapted RadLing system surpasses
GPT-4 system in extracting common data elements from radiology reports, while
providing benefits of local deployment and lower costs.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17216" title="Abstract">arXiv:2311.17216</a> [<a href="/pdf/2311.17216" title="Download PDF">pdf</a>, <a href="/format/2311.17216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Discovering Interpretable Diffusion Latent Directions for  Responsible Text-to-Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hang Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chengzhi Shen</a>, 
<a href="/search/cs?searchtype=author&query=Torr%2C+P">Philip Torr</a>, 
<a href="/search/cs?searchtype=author&query=Tresp%2C+V">Volker Tresp</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jindong Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diffusion-based models have gained significant popularity for text-to-image
generation due to their exceptional image-generation capabilities. A risk with
these models is the potential generation of inappropriate content, such as
biased or harmful images. However, the underlying reasons for generating such
undesired content from the perspective of the diffusion model's internal
representation remain unclear. Previous work interprets vectors in an
interpretable latent space of diffusion models as semantic concepts. However,
existing approaches cannot discover directions for arbitrary concepts, such as
those related to inappropriate concepts. In this work, we propose a novel
self-supervised approach to find interpretable latent directions for a given
concept. With the discovered vectors, we further propose a simple approach to
mitigate inappropriate generation. Extensive experiments have been conducted to
verify the effectiveness of our mitigation approach, namely, for fair
generation, safe generation, and responsible text-enhancing generation.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17218" title="Abstract">arXiv:2311.17218</a> [<a href="/pdf/2311.17218" title="Download PDF">pdf</a>, <a href="/format/2311.17218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BIM: Block-Wise Self-Supervised Learning with Masked Image Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yixuan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+M">Mengye Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S+Q">Sai Qian Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Like masked language modeling (MLM) in natural language processing, masked
image modeling (MIM) aims to extract valuable insights from image patches to
enhance the feature extraction capabilities of the underlying deep neural
network (DNN). Contrasted with other training paradigms like supervised
learning and unsupervised contrastive learning, masked image modeling (MIM)
pretraining typically demands significant computational resources in order to
manage large training data batches (e.g., 4096). The significant memory and
computation requirements pose a considerable challenge to its broad adoption.
To mitigate this, we introduce a novel learning framework,
termed~\textit{Block-Wise Masked Image Modeling} (BIM). This framework involves
decomposing the MIM tasks into several sub-tasks with independent computation
patterns, resulting in block-wise back-propagation operations instead of the
traditional end-to-end approach. Our proposed BIM maintains superior
performance compared to conventional MIM while greatly reducing peak memory
consumption. Moreover, BIM naturally enables the concurrent training of
numerous DNN backbones of varying depths. This leads to the creation of
multiple trained DNN backbones, each tailored to different hardware platforms
with distinct computing capabilities. This approach significantly reduces
computational costs in comparison with training each DNN backbone individually.
Our framework offers a promising solution for resource constrained training of
MIM.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17224" title="Abstract">arXiv:2311.17224</a> [<a href="/pdf/2311.17224" title="Download PDF">pdf</a>, <a href="/format/2311.17224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Complexity of the Median and Closest Permutation Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cunha%2C+L">Lu&#xed;s Cunha</a>, 
<a href="/search/cs?searchtype=author&query=Sau%2C+I">Ignasi Sau</a>, 
<a href="/search/cs?searchtype=author&query=Souza%2C+U">U&#xe9;verton Souza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">Genome rearrangements are events where large blocks of DNA exchange places
during evolution. The analysis of these events is a promising tool for
understanding evolutionary genomics, providing data for phylogenetic
reconstruction based on genome rearrangement measures. Many pairwise
rearrangement distances have been proposed, based on finding the minimum number
of rearrangement events to transform one genome into the other, using some
predefined operation. When more than two genomes are considered, we have the
more challenging problem of rearrangement-based phylogeny reconstruction. Given
a set of genomes and a distance notion, there are at least two natural ways to
define the "target" genome. On the one hand, finding a genome that minimizes
the sum of the distances from this to any other, called the median genome.
Finding a genome that minimizes the maximum distance to any other, called the
closest genome. Considering genomes as permutations, some distance metrics have
been extensively studied. We investigate median and closest problems on
permutations over the metrics: breakpoint, swap, block-interchange,
short-block-move, and transposition. In biological matters some values are
usually small, such as the solution value d or the number k of input
permutations. For each of these metrics and parameters d or k, we analyze the
closest and the median problems from the viewpoint of parameterized complexity.
We obtain the following results: NP-hardness for finding the median/closest
permutation for some metrics, even for k = 3; Polynomial kernels for the
problems of finding the median permutation of all studied metrics, considering
the target distance d as parameter; NP-hardness result for finding the closest
permutation by short-block-moves; FPT algorithms and infeasibility of
polynomial kernels for finding the closest permutation for some metrics
parameterized by the target distance d.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17225" title="Abstract">arXiv:2311.17225</a> [<a href="/pdf/2311.17225" title="Download PDF">pdf</a>, <a href="/format/2311.17225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invariance assumptions for class distribution estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tasche%2C+D">Dirk Tasche</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, presented at workshop Learning to Quantify: Methods and Applications (LQ 2023), Torino, September 18, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We study the problem of class distribution estimation under dataset shift. On
the training dataset, both features and class labels are observed while on the
test dataset only the features can be observed. The task then is the estimation
of the distribution of the class labels, i.e. the estimation of the class prior
probabilities, in the test dataset. Assumptions of invariance between the
training joint distribution of features and labels and the test distribution
can considerably facilitate this task. We discuss the assumptions of covariate
shift, factorizable joint shift, and sparse joint shift and their implications
for class distribution estimation.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17227" title="Abstract">arXiv:2311.17227</a> [<a href="/pdf/2311.17227" title="Download PDF">pdf</a>, <a href="/format/2311.17227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> War and Peace (WarAgent): Large Language Model-based Multi-Agent  Simulation of World Wars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hua%2C+W">Wenyue Hua</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lizhou Fan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lingyao Li</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+K">Kai Mei</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Jianchao Ji</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yingqiang Ge</a>, 
<a href="/search/cs?searchtype=author&query=Hemphill%2C+L">Libby Hemphill</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongfeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY)

</div>
<p class="mathjax">Can we avoid wars at the crossroads of history? This question has been
pursued by individuals, scholars, policymakers, and organizations throughout
human history. In this research, we attempt to answer the question based on the
recent advances of Artificial Intelligence (AI) and Large Language Models
(LLMs). We propose \textbf{WarAgent}, an LLM-powered multi-agent AI system, to
simulate the participating countries, their decisions, and the consequences, in
historical international conflicts, including the World War I (WWI), the World
War II (WWII), and the Warring States Period (WSP) in Ancient China. By
evaluating the simulation effectiveness, we examine the advancements and
limitations of cutting-edge AI systems' abilities in studying complex
collective human behaviors such as international conflicts under diverse
settings. In these simulations, the emergent interactions among agents also
offer a novel perspective for examining the triggers and conditions that lead
to war. Our findings offer data-driven and AI-augmented insights that can
redefine how we approach conflict resolution and peacekeeping strategies. The
implications stretch beyond historical analysis, offering a blueprint for using
AI to understand human history and possibly prevent future international
conflicts. Code and data are available at
\url{https://github.com/agiresearch/WarAgent}.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17228" title="Abstract">arXiv:2311.17228</a> [<a href="/pdf/2311.17228" title="Download PDF">pdf</a>, <a href="/format/2311.17228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survey on AI Ethics: A Socio-technical Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mbiazi%2C+D">Dave Mbiazi</a>, 
<a href="/search/cs?searchtype=author&query=Bhange%2C+M">Meghana Bhange</a>, 
<a href="/search/cs?searchtype=author&query=Babaei%2C+M">Maryam Babaei</a>, 
<a href="/search/cs?searchtype=author&query=Sheth%2C+I">Ivaxi Sheth</a>, 
<a href="/search/cs?searchtype=author&query=Kenfack%2C+P+J">Patrik Joslin Kenfack</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The past decade has observed a great advancement in AI with deep
learning-based models being deployed in diverse scenarios including
safety-critical applications. As these AI systems become deeply embedded in our
societal infrastructure, the repercussions of their decisions and actions have
significant consequences, making the ethical implications of AI deployment
highly relevant and important. The ethical concerns associated with AI are
multifaceted, including challenging issues of fairness, privacy and data
protection, responsibility and accountability, safety and robustness,
transparency and explainability, and environmental impact. These principles
together form the foundations of ethical AI considerations that concern every
stakeholder in the AI system lifecycle. In light of the present ethical and
future x-risk concerns, governments have shown increasing interest in
establishing guidelines for the ethical deployment of AI. This work unifies the
current and future ethical concerns of deploying AI into society. While we
acknowledge and appreciate the technical surveys for each of the ethical
principles concerned, in this paper, we aim to provide a comprehensive overview
that not only addresses each principle from a technical point of view but also
discusses them from a social perspective.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17232" title="Abstract">arXiv:2311.17232</a> [<a href="/pdf/2311.17232" title="Download PDF">pdf</a>, <a href="/format/2311.17232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReWaRD: Retinal Waves for Pre-Training Artificial Neural Networks  Mimicking Real Prenatal Development
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cappell%2C+B">Benjamin Cappell</a>, 
<a href="/search/cs?searchtype=author&query=Stoll%2C+A">Andreas Stoll</a>, 
<a href="/search/cs?searchtype=author&query=Umah%2C+W+C">Williams Chukwudi Umah</a>, 
<a href="/search/cs?searchtype=author&query=Egger%2C+B">Bernhard Egger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://github.com/BennyCa/ReWaRD/">this https URL</a> IN: Proceedings of the first edition of the Workshop on Unifying Representations in Neural Models (UniReps 2023) @ NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Computational models trained on a large amount of natural images are the
state-of-the-art to study human vision - usually adult vision. Computational
models of infant vision and its further development are gaining more and more
attention in the community. In this work we aim at the very beginning of our
visual experience - pre- and post-natal retinal waves which suggest to be a
pre-training mechanism for the primate visual system at a very early stage of
development. We see this approach as an instance of biologically plausible data
driven inductive bias through pre-training. We built a computational model that
mimics this development mechanism by pre-training different artificial
convolutional neural networks with simulated retinal wave images. The resulting
features of this biologically plausible pre-training closely match the V1
features of the primate visual system. We show that the performance gain by
pre-training with retinal waves is similar to a state-of-the art pre-training
pipeline. Our framework contains the retinal wave generator, as well as a
training strategy, which can be a first step in a curriculum learning based
training diet for various models of development. We release code, data and
trained networks to build the basis for future work on visual development and
based on a curriculum learning approach including prenatal development to
support studies of innate vs. learned properties of the primate visual system.
An additional benefit of our pre-trained networks for neuroscience or computer
vision applications is the absence of biases inherited from datasets like
ImageNet.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17233" title="Abstract">arXiv:2311.17233</a> [<a href="/pdf/2311.17233" title="Download PDF">pdf</a>, <a href="/format/2311.17233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying the redundancy between prosody and text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wolf%2C+L">Lukas Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Pimentel%2C+T">Tiago Pimentel</a>, 
<a href="/search/cs?searchtype=author&query=Fedorenko%2C+E">Evelina Fedorenko</a>, 
<a href="/search/cs?searchtype=author&query=Cotterell%2C+R">Ryan Cotterell</a>, 
<a href="/search/cs?searchtype=author&query=Warstadt%2C+A">Alex Warstadt</a>, 
<a href="/search/cs?searchtype=author&query=Wilcox%2C+E">Ethan Wilcox</a>, 
<a href="/search/cs?searchtype=author&query=Regev%2C+T">Tamar Regev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at The 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">Prosody -- the suprasegmental component of speech, including pitch, loudness,
and tempo -- carries critical aspects of meaning. However, the relationship
between the information conveyed by prosody vs. by the words themselves remains
poorly understood. We use large language models (LLMs) to estimate how much
information is redundant between prosody and the words themselves. Using a
large spoken corpus of English audiobooks, we extract prosodic features aligned
to individual words and test how well they can be predicted from LLM
embeddings, compared to non-contextual word embeddings. We find a high degree
of redundancy between the information carried by the words and prosodic
information across several prosodic features, including intensity, duration,
pauses, and pitch contours. Furthermore, a word's prosodic information is
redundant with both the word itself and the context preceding as well as
following it. Still, we observe that prosodic features can not be fully
predicted from text, suggesting that prosody carries information above and
beyond the words. Along with this paper, we release a general-purpose data
processing pipeline for quantifying the relationship between linguistic
information and extra-linguistic features.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17240" title="Abstract">arXiv:2311.17240</a> [<a href="/pdf/2311.17240" title="Download PDF">pdf</a>, <a href="/ps/2311.17240" title="Download PostScript">ps</a>, <a href="/format/2311.17240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A discussion on numerical shock stability of unstructured finite volume  method: Riemann solvers and limiters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/math?searchtype=author&query=Yuan%2C+Z">Zhichao Yuan</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+J">Jun Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at 2nd International Conference in Aerospace for Young Scientists. 07-08 September 2017, Beijing, P.R.China
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Numerical shock instability is a complexity which may occur in supersonic
simulations. Riemann solver is usually the crucial factor that affects both the
computation accuracy and numerical shock stability. In this paper, several
classical Riemann solvers are discussed, and the intrinsic mechanism of shock
instability is especially concerned. It can be found that the momentum
perturbation traversing shock wave is a major reason that invokes instability.
Furthermore, slope limiters used to depress oscillation across shock wave is
also a key factor for computation stability. Several slope limiters can cause
significant numerical errors near shock waves, and make the computation fail to
converge. Extra dissipation of Riemann solvers and slope limiters can be
helpful to eliminate instability, but reduces the computation accuracy.
Therefore, to properly introduce numerical dissipation is critical for
numerical computations. Here, pressure based shock indicator is used to show
the position of shock wave and tunes the numerical dissipation. Overall, the
presented methods are showing satisfactory results in both the accuracy and
stability.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17241" title="Abstract">arXiv:2311.17241</a> [<a href="/pdf/2311.17241" title="Download PDF">pdf</a>, <a href="/format/2311.17241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-End Temporal Action Detection with 1B Parameters Across 1000  Frames
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chen-Lin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ghanem%2C+B">Bernard Ghanem</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, temporal action detection (TAD) has seen significant performance
improvement with end-to-end training. However, due to the memory bottleneck,
only models with limited scales and limited data volumes can afford end-to-end
training, which inevitably restricts TAD performance. In this paper, we reduce
the memory consumption for end-to-end training, and manage to scale up the TAD
backbone to 1 billion parameters and the input video to 1,536 frames, leading
to significant detection performance. The key to our approach lies in our
proposed temporal-informative adapter (TIA), which is a novel lightweight
module that reduces training memory. Using TIA, we free the humongous backbone
from learning to adapt to the TAD task by only updating the parameters in TIA.
TIA also leads to better TAD representation by temporally aggregating context
from adjacent frames throughout the backbone. We evaluate our model across four
representative datasets. Owing to our efficient design, we are able to train
end-to-end on VideoMAEv2-giant and achieve 75.4% mAP on THUMOS14, being the
first end-to-end model to outperform the best feature-based methods.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17243" title="Abstract">arXiv:2311.17243</a> [<a href="/pdf/2311.17243" title="Download PDF">pdf</a>, <a href="/format/2311.17243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PHG-Net: Persistent Homology Guided Medical Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yaopeng Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongxiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sonka%2C+M">Milan Sonka</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D+Z">Danny Z. Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Modern deep neural networks have achieved great successes in medical image
analysis. However, the features captured by convolutional neural networks
(CNNs) or Transformers tend to be optimized for pixel intensities and neglect
key anatomical structures such as connected components and loops. In this
paper, we propose a persistent homology guided approach (PHG-Net) that explores
topological features of objects for medical image classification. For an input
image, we first compute its cubical persistence diagram and extract topological
features into a vector representation using a small neural network (called the
PH module). The extracted topological features are then incorporated into the
feature map generated by CNN or Transformer for feature fusion. The PH module
is lightweight and capable of integrating topological features into any CNN or
Transformer architectures in an end-to-end fashion. We evaluate our PHG-Net on
three public datasets and demonstrate its considerable improvements on the
target classification tasks over state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17244" title="Abstract">arXiv:2311.17244</a> [<a href="/pdf/2311.17244" title="Download PDF">pdf</a>, <a href="/format/2311.17244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Tenodesis-Modulated Control of an Assistive Hand Exoskeleton for  SCI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Palacios%2C+J">Joaquin Palacios</a>, 
<a href="/search/cs?searchtype=author&query=Deli-Ivanov%2C+A">Alexandra Deli-Ivanov</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Ava Chen</a>, 
<a href="/search/cs?searchtype=author&query=Winterbottom%2C+L">Lauren Winterbottom</a>, 
<a href="/search/cs?searchtype=author&query=Nilsen%2C+D+M">Dawn M. Nilsen</a>, 
<a href="/search/cs?searchtype=author&query=Stein%2C+J">Joel Stein</a>, 
<a href="/search/cs?searchtype=author&query=Ciocarlie%2C+M">Matei Ciocarlie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages, 4 figures. Presented at the IROS 2023 Assistive Robotics for Citizens Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Restoration of hand function is one of the highest priorities for SCI
populations. In this work, we present a prototype of a robotic assistive
orthosis capable of implementing tenodesis user control. The underactuated
device provides active grasping assistance while preserving free wrist mobility
through the use of Bowden cables. This device enables force modulation during
grasping, which was effectively leveraged by a participant with C6 SCI to
demonstrate improved grasping abilities using the orthosis, scoring 11 on the
Grasp and Release Test using the device compared to 1 without it.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17245" title="Abstract">arXiv:2311.17245</a> [<a href="/pdf/2311.17245" title="Download PDF">pdf</a>, <a href="/format/2311.17245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LightGaussian: Unbounded 3D Gaussian Compression with 15x Reduction and  200+ FPS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhiwen Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kevin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+K">Kairun Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zehao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dejia Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16pages, 8figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advancements in real-time neural rendering using point-based
techniques have paved the way for the widespread adoption of 3D
representations. However, foundational approaches like 3D Gaussian Splatting
come with a substantial storage overhead caused by growing the SfM points to
millions, often demanding gigabyte-level disk space for a single unbounded
scene, posing significant scalability challenges and hindering the splatting
efficiency.
<br />To address this challenge, we introduce LightGaussian, a novel method
designed to transform 3D Gaussians into a more efficient and compact format.
Drawing inspiration from the concept of Network Pruning, LightGaussian
identifies Gaussians that are insignificant in contributing to the scene
reconstruction and adopts a pruning and recovery process, effectively reducing
redundancy in Gaussian counts while preserving visual effects. Additionally,
LightGaussian employs distillation and pseudo-view augmentation to distill
spherical harmonics to a lower degree, allowing knowledge transfer to more
compact representations while maintaining reflectance. Furthermore, we propose
a hybrid scheme, VecTree Quantization, to quantize all attributes, resulting in
lower bitwidth representations with minimal accuracy losses.
<br />In summary, LightGaussian achieves an averaged compression rate over 15x
while boosting the FPS from 139 to 215, enabling an efficient representation of
complex scenes on Mip-NeRF 360, Tank and Temple datasets.
<br />Project website: https://lightgaussian.github.io/
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17250" title="Abstract">arXiv:2311.17250</a> [<a href="/pdf/2311.17250" title="Download PDF">pdf</a>, <a href="/format/2311.17250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fourier Neural Differential Equations for learning Quantum Field  Theories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brant%2C+I">Isaac Brant</a>, 
<a href="/search/cs?searchtype=author&query=Norcliffe%2C+A">Alexander Norcliffe</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; High Energy Physics - Phenomenology (hep-ph); Quantum Physics (quant-ph)

</div>
<p class="mathjax">A Quantum Field Theory is defined by its interaction Hamiltonian, and linked
to experimental data by the scattering matrix. The scattering matrix is
calculated as a perturbative series, and represented succinctly as a first
order differential equation in time. Neural Differential Equations (NDEs) learn
the time derivative of a residual network's hidden state, and have proven
efficacy in learning differential equations with physical constraints. Hence
using an NDE to learn particle scattering matrices presents a possible
experiment-theory phenomenological connection. In this paper, NDE models are
used to learn $\phi^4$ theory, Scalar-Yukawa theory and Scalar Quantum
Electrodynamics. A new NDE architecture is also introduced, the Fourier Neural
Differential Equation (FNDE), which combines NDE integration and Fourier
network convolution. The FNDE model demonstrates better generalisability than
the non-integrated equivalent FNO model. It is also shown that by training on
scattering data, the interaction Hamiltonian of a theory can be extracted from
network parameters.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17252" title="Abstract">arXiv:2311.17252</a> [<a href="/pdf/2311.17252" title="Download PDF">pdf</a>, <a href="/format/2311.17252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing the Impact of Tax Credits on Households in Simulated Economic  Systems with Learning Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jialin Dong</a>, 
<a href="/search/cs?searchtype=author&query=Dwarakanath%2C+K">Kshama Dwarakanath</a>, 
<a href="/search/cs?searchtype=author&query=Vyetrenko%2C+S">Svitlana Vyetrenko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; General Economics (econ.GN)

</div>
<p class="mathjax">In economic modeling, there has been an increasing investigation into
multi-agent simulators. Nevertheless, state-of-the-art studies establish the
model based on reinforcement learning (RL) exclusively for specific agent
categories, e.g., households, firms, or the government. It lacks concerns over
the resulting adaptation of other pivotal agents, thereby disregarding the
complex interactions within a real-world economic system. Furthermore, we pay
attention to the vital role of the government policy in distributing tax
credits. Instead of uniform distribution considered in state-of-the-art, it
requires a well-designed strategy to reduce disparities among households and
improve social welfare. To address these limitations, we propose an expansive
multi-agent economic model comprising reinforcement learning agents of numerous
types. Additionally, our research comprehensively explores the impact of tax
credit allocation on household behavior and captures the spectrum of spending
patterns that can be observed across diverse households. Further, we propose an
innovative government policy to distribute tax credits, strategically
leveraging insights from tax credit spending patterns. Simulation results
illustrate the efficacy of the proposed government strategy in ameliorating
inequalities across households.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17256" title="Abstract">arXiv:2311.17256</a> [<a href="/pdf/2311.17256" title="Download PDF">pdf</a>, <a href="/format/2311.17256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pattern retrieval of traffic congestion using graph-based associations  of traffic domain-specific features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+T">Tin T. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Calvert%2C+S+C">Simeon C. Calvert</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guopeng Li</a>, 
<a href="/search/cs?searchtype=author&query=van+Lint%2C+H">Hans van Lint</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">The fast-growing amount of traffic data brings many opportunities for
revealing more insightful information about traffic dynamics. However, it also
demands an effective database management system in which information retrieval
is arguably an important feature. The ability to locate similar patterns in big
datasets potentially paves the way for further valuable analyses in traffic
management. This paper proposes a content-based retrieval system for
spatiotemporal patterns of highway traffic congestion. There are two main
components in our framework, namely pattern representation and similarity
measurement. To effectively interpret retrieval outcomes, the paper proposes a
graph-based approach (relation-graph) for the former component, in which
fundamental traffic phenomena are encoded as nodes and their spatiotemporal
relationships as edges. In the latter component, the similarities between
congestion patterns are customizable with various aspects according to user
expectations. We evaluated the proposed framework by applying it to a dataset
of hundreds of patterns with various complexities (temporally and spatially).
The example queries indicate the effectiveness of the proposed method, i.e. the
obtained patterns present similar traffic phenomena as in the given examples.
In addition, the success of the proposed approach directly derives a new
opportunity for semantic retrieval, in which expected patterns are described by
adopting the relation-graph notion to associate fundamental traffic phenomena.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17259" title="Abstract">arXiv:2311.17259</a> [<a href="/pdf/2311.17259" title="Download PDF">pdf</a>, <a href="/format/2311.17259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoUnD Framework: Analyzing (So)cial Representation in (Un)structured  (D)ata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz%2C+M">Mark D&#xed;az</a>, 
<a href="/search/cs?searchtype=author&query=Dev%2C+S">Sunipa Dev</a>, 
<a href="/search/cs?searchtype=author&query=Reif%2C+E">Emily Reif</a>, 
<a href="/search/cs?searchtype=author&query=Denton%2C+R">Remi Denton</a>, 
<a href="/search/cs?searchtype=author&query=Prabhakaran%2C+V">Vinodkumar Prabhakaran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">The unstructured nature of data used in foundation model development is a
challenge to systematic analyses for making data use and documentation
decisions. From a Responsible AI perspective, these decisions often rely upon
understanding how people are represented in data. We propose a framework
designed to guide analysis of human representation in unstructured data and
identify downstream risks. We apply the framework in two toy examples using the
Common Crawl web text corpus (C4) and LAION-400M. We also propose a set of
hypothetical action steps in service of dataset use, development, and
documentation.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17261" title="Abstract">arXiv:2311.17261</a> [<a href="/pdf/2311.17261" title="Download PDF">pdf</a>, <a href="/format/2311.17261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SceneTex: High-Quality Texture Synthesis for Indoor Scenes via Diffusion  Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+D+Z">Dave Zhenyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hsin-Ying Lee</a>, 
<a href="/search/cs?searchtype=author&query=Tulyakov%2C+S">Sergey Tulyakov</a>, 
<a href="/search/cs?searchtype=author&query=Nie%C3%9Fner%2C+M">Matthias Nie&#xdf;ner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="https://daveredrum.github.io/SceneTex/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose SceneTex, a novel method for effectively generating high-quality
and style-consistent textures for indoor scenes using depth-to-image diffusion
priors. Unlike previous methods that either iteratively warp 2D views onto a
mesh surface or distillate diffusion latent features without accurate geometric
and style cues, SceneTex formulates the texture synthesis task as an
optimization problem in the RGB space where style and geometry consistency are
properly reflected. At its core, SceneTex proposes a multiresolution texture
field to implicitly encode the mesh appearance. We optimize the target texture
via a score-distillation-based objective function in respective RGB renderings.
To further secure the style consistency across views, we introduce a
cross-attention decoder to predict the RGB values by cross-attending to the
pre-sampled reference locations in each instance. SceneTex enables various and
accurate texture synthesis for 3D-FRONT scenes, demonstrating significant
improvements in visual quality and prompt fidelity over the prior texture
generation methods.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17262" title="Abstract">arXiv:2311.17262</a> [<a href="/pdf/2311.17262" title="Download PDF">pdf</a>, <a href="/ps/2311.17262" title="Download PostScript">ps</a>, <a href="/format/2311.17262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parity-check Codes from Disjunct Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haymaker%2C+K">Kathryn Haymaker</a>, 
<a href="/search/cs?searchtype=author&query=McMillon%2C+E">Emily McMillon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The matrix representations of linear codes have been well-studied for use as
disjunct matrices. However, no connection has previously been made between the
properties of disjunct matrices and the parity-check codes obtained from them.
In this paper, we provide some general results on parity-check codes from
disjunct matrices. We then examine properties such as rate, distance, girth,
and density of the families of codes obtained from three specific constructions
of disjunct matrices.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17264" title="Abstract">arXiv:2311.17264</a> [<a href="/pdf/2311.17264" title="Download PDF">pdf</a>, <a href="/format/2311.17264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RETSim: Resilient and Efficient Text Similarity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Marina Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Vallis%2C+O">Owen Vallis</a>, 
<a href="/search/cs?searchtype=author&query=Bumin%2C+A">Aysegul Bumin</a>, 
<a href="/search/cs?searchtype=author&query=Vakharia%2C+T">Tanay Vakharia</a>, 
<a href="/search/cs?searchtype=author&query=Bursztein%2C+E">Elie Bursztein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper introduces RETSim (Resilient and Efficient Text Similarity), a
lightweight, multilingual deep learning model trained to produce robust metric
embeddings for near-duplicate text retrieval, clustering, and dataset
deduplication tasks. We demonstrate that RETSim is significantly more robust
and accurate than MinHash and neural text embeddings, achieving new
state-of-the-art performance on dataset deduplication, adversarial text
retrieval benchmarks, and spam clustering tasks. We also introduce the W4NT3D
benchmark (Wiki-40B 4dversarial Near-T3xt Dataset) for evaluating multilingual,
near-duplicate text retrieval capabilities under adversarial settings. RETSim
and the W4NT3D benchmark are open-sourced under the MIT License at
https://github.com/google/unisim.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17265" title="Abstract">arXiv:2311.17265</a> [<a href="/pdf/2311.17265" title="Download PDF">pdf</a>, <a href="/format/2311.17265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exceptional Mechanical Performance by Spatial Printing with Continuous  Fiber
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+G">Guoxin Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhizhou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Masania%2C+K">Kunal Masania</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C+C+L">Charlie C.L. Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">This work explores a spatial printing method to fabricate continuous
fiber-reinforced thermoplastic composites (CFRTPCs), which can achieve
exceptional mechanical performance. For models giving complex 3D stress
distribution under loads, typical planar-layer based fiber placement usually
fails to provide sufficient reinforcement due to their orientations being
constrained to planes. The effectiveness of fiber reinforcement could be
maximized by using multi-axis additive manufacturing (MAAM) to better control
the orientation of continuous fibers in 3D-printed composites. Here, we propose
a computational approach to generate 3D toolpaths that satisfy two major
reinforcement objectives: 1) following the maximal stress directions in
critical regions and 2) connecting multiple load-bearing regions by continuous
fibers. Principal stress lines are first extracted in an input solid model to
identify critical regions. Curved layers aligned with maximal stresses in these
critical regions are generated by computing an optimized scalar field and
extracting its iso-surfaces. Then, topological analysis and operations are
applied to each curved layer to generate a computational domain that preserves
fiber continuity between load-bearing regions. Lastly, continuous fiber
toolpaths aligned with maximal stresses are generated on each surface layer by
computing an optimized scalar field and extracting its iso-curves. A hardware
system with dual robotic arms is employed to conduct the physical MAAM tasks
depositing polymer or fiber reinforced polymer composite materials by applying
a force normal to the extrusion plane to aid consolidation. When comparing to
planar-layer based printing results in tension, up to 644% breaking forces and
240% stiffness are observed on shapes fabricated by our spatial printing
method.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17267" title="Abstract">arXiv:2311.17267</a> [<a href="/pdf/2311.17267" title="Download PDF">pdf</a>, <a href="/format/2311.17267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E-ViLM: Efficient Video-Language Model via Masked Video Modeling with  Semantic Vector-Quantized Tokenizer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+J+Z">Jacob Zhiyuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Skyler Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+V">Vasu Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Piramuthu%2C+R">Robinson Piramuthu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">To build scalable models for challenging real-world tasks, it is important to
learn from diverse, multi-modal data in various forms (e.g., videos, text, and
images). Among the existing works, a plethora of them have focused on
leveraging large but cumbersome cross-modal architectures. Regardless of their
effectiveness, larger architectures unavoidably prevent the models from being
extended to real-world applications, so building a lightweight VL architecture
and an efficient learning schema is of great practical value. In this paper, we
propose an Efficient Video-Language Model (dubbed as E-ViLM) and a masked video
modeling (MVM) schema, assisted with a semantic vector-quantized tokenizer. In
particular, our E-ViLM learns to reconstruct the semantic labels of masked
video regions, produced by the pre-trained vector-quantized tokenizer, which
discretizes the continuous visual signals into labels. We show that with our
simple MVM task and regular VL pre-training modelings, our E-ViLM, despite its
compactness, is able to learn expressive representations from Video-Language
corpus and generalize well to extensive Video-Language tasks including video
question answering, text-to-video retrieval, etc. In particular, our E-ViLM
obtains obvious efficiency improvements by reaching competing performances with
faster inference speed, i.e., our model reaches $39.3$% Top-$1$ accuracy on the
MSRVTT benchmark, retaining $91.4$% of the accuracy of state-of-the-art larger
VL architecture with only $15%$ parameters and $94.8%$ fewer GFLOPs. We also
provide extensive ablative studies that validate the effectiveness of our
proposed learning schema for E-ViLM.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17269" title="Abstract">arXiv:2311.17269</a> [<a href="/pdf/2311.17269" title="Download PDF">pdf</a>, <a href="/format/2311.17269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An iterative equation solver with low sensitivity on the initial value
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Herzog%2C+A">Alexander Herzog</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">The objective of this publication is to reduce the sensitivity of iterative
equation solvers on the initial value. To this end, at the hand of Newton's
method, we exemplify how to reformulate the initial problem by means of a set
of generalized moment generating functions. The approach allows to choose that
very function, which is best approximated by a linear function and thus allows
to set up an efficient iteration procedure. As a result of this, the number of
iterations required to meet a given precision goal is significantly reduced in
comparison to Newton's method especially for large deviations between the
initial value and the actual root. At the hand of seven academic examples and
three applications we demonstrate that the computing time of the discussed
approach reveals a far lower susceptibility on the initial value when compared
to results from Newton's method. This insensitivity offers the prospect to
implement iterative equation solvers for applications with strict real-time
requirements such as power system simulation or on-demand control algorithms on
embedded systems with low computing power. We are confident that the devised
methodology may be generalized to other well-established iteration algorithms.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17276" title="Abstract">arXiv:2311.17276</a> [<a href="/pdf/2311.17276" title="Download PDF">pdf</a>, <a href="/format/2311.17276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Unlearning in Learned Databases: An Experimental Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kurmanji%2C+M">Meghdad Kurmanji</a>, 
<a href="/search/cs?searchtype=author&query=Triantafillou%2C+E">Eleni Triantafillou</a>, 
<a href="/search/cs?searchtype=author&query=Triantafillou%2C+P">Peter Triantafillou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a conference paper at SIGMOD 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Machine learning models based on neural networks (NNs) are enjoying
ever-increasing attention in the DB community. However, an important issue has
been largely overlooked, namely the challenge of dealing with the highly
dynamic nature of DBs, where data updates are fundamental, highly-frequent
operations. Although some recent research has addressed the issues of
maintaining updated NN models in the presence of new data insertions, the
effects of data deletions (a.k.a., "machine unlearning") remain a blind spot.
With this work, for the first time to our knowledge, we pose and answer the
following key questions: What is the effect of unlearning algorithms on
NN-based DB models? How do these effects translate to effects on downstream DB
tasks, such as selectivity estimation (SE), approximate query processing (AQP),
data generation (DG), and upstream tasks like data classification (DC)? What
metrics should we use to assess the impact and efficacy of unlearning
algorithms in learned DBs? Is the problem of machine unlearning in DBs
different from that of machine learning in DBs in the face of data insertions?
Is the problem of machine unlearning for DBs different from unlearning in the
ML literature? what are the overhead and efficiency of unlearning algorithms?
What is the sensitivity of unlearning on batching delete operations? If we have
a suitable unlearning algorithm, can we combine it with an algorithm handling
data insertions en route to solving the general adaptability/updatability
requirement in learned DBs in the face of both data inserts and deletes? We
answer these questions using a comprehensive set of experiments, various
unlearning algorithms, a variety of downstream DB tasks, and an upstream task
(DC), each with different NNs, and using a variety of metrics on a variety of
real datasets, making this also a first key step towards a benchmark for
learned DB unlearning.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17277" title="Abstract">arXiv:2311.17277</a> [<a href="/pdf/2311.17277" title="Download PDF">pdf</a>, <a href="/format/2311.17277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Online Optimization-Based Decision Support Tool for Small Farmers in  India: Learning in Non-stationary Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tuxun Lu</a>, 
<a href="/search/cs?searchtype=author&query=Prins%2C+A">Aviva Prins</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Crop management decision support systems are specialized tools for farmers
that reduce the riskiness of revenue streams, especially valuable for use under
the current climate changes that impact agricultural productivity.
Unfortunately, small farmers in India, who could greatly benefit from these
tools, do not have access to them. In this paper, we model an individual
greenhouse as a Markov Decision Process (MDP) and adapt Li and Li (2019)'s
Follow the Weighted Leader (FWL) online learning algorithm to offer crop
planning advice. We successfully produce utility-preserving cropping pattern
suggestions in simulations. When we compare against an offline planning
algorithm, we achieve the same cumulative revenue with greatly reduced runtime.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17279" title="Abstract">arXiv:2311.17279</a> [<a href="/pdf/2311.17279" title="Download PDF">pdf</a>, <a href="/format/2311.17279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiveTune: Dynamic Parameter Tuning for Training Deep Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shabgahi%2C+S+Z">Soheil Zibakhsh Shabgahi</a>, 
<a href="/search/cs?searchtype=author&query=Sheybani%2C+N">Nojan Sheybani</a>, 
<a href="/search/cs?searchtype=author&query=Tabrizi%2C+A">Aiden Tabrizi</a>, 
<a href="/search/cs?searchtype=author&query=Koushanfar%2C+F">Farinaz Koushanfar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Performance (cs.PF)

</div>
<p class="mathjax">Traditional machine learning training is a static process that lacks
real-time adaptability of hyperparameters. Popular tuning solutions during
runtime involve checkpoints and schedulers. Adjusting hyper-parameters usually
require the program to be restarted, wasting utilization and time, while
placing unnecessary strain on memory and processors. We present LiveTune, a new
framework allowing real-time parameter tuning during training through
LiveVariables. Live Variables allow for a continuous training session by
storing parameters on designated ports on the system, allowing them to be
dynamically adjusted. Extensive evaluations of our framework show saving up to
60 seconds and 5.4 Kilojoules of energy per hyperparameter change.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17280" title="Abstract">arXiv:2311.17280</a> [<a href="/pdf/2311.17280" title="Download PDF">pdf</a>, <a href="/format/2311.17280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does VLN Pretraining Work with Nonsensical or Irrelevant Instructions?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+I">Ishika Singh</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+R">Robin Jia</a>, 
<a href="/search/cs?searchtype=author&query=Thomason%2C+J">Jesse Thomason</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Data augmentation via back-translation is common when pretraining
Vision-and-Language Navigation (VLN) models, even though the generated
instructions are noisy. But: does that noise matter? We find that nonsensical
or irrelevant language instructions during pretraining can have little effect
on downstream performance for both HAMT and VLN-BERT on R2R, and is still
better than only using clean, human data. To underscore these results, we
concoct an efficient augmentation method, Unigram + Object, which generates
nonsensical instructions that nonetheless improve downstream performance. Our
findings suggest that what matters for VLN R2R pretraining is the quantity of
visual trajectories, not the quality of instructions.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17281" title="Abstract">arXiv:2311.17281</a> [<a href="/pdf/2311.17281" title="Download PDF">pdf</a>, <a href="/ps/2311.17281" title="Download PostScript">ps</a>, <a href="/format/2311.17281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lower Bounds on Adaptive Sensing for Matrix Recovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kacham%2C+P">Praneeth Kacham</a>, 
<a href="/search/cs?searchtype=author&query=Woodruff%2C+D+P">David P Woodruff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages. Abstract shortened
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">We study lower bounds on adaptive sensing algorithms for recovering low rank
matrices using linear measurements. Given an $n \times n$ matrix $A$, a general
linear measurement $S(A)$, for an $n \times n$ matrix $S$, is just the inner
product of $S$ and $A$, each treated as $n^2$-dimensional vectors. By
performing as few linear measurements as possible on a rank-$r$ matrix $A$, we
hope to construct a matrix $\hat{A}$ that satisfies $\|A - \hat{A}\|_F^2 \le
c\|A\|_F^2$, for a small constant $c$. It is commonly assumed that when
measuring $A$ with $S$, the response is corrupted with an independent Gaussian
random variable of mean $0$ and variance $\sigma^2$. Cand\'es and Plan study
non-adaptive algorithms for low rank matrix recovery using random linear
measurements.
<br />At a certain noise level, it is known that their non-adaptive algorithms need
to perform $\Omega(n^2)$ measurements, which amounts to reading the entire
matrix. An important question is whether adaptivity helps in decreasing the
overall number of measurements. We show that any adaptive algorithm that uses
$k$ linear measurements in each round and outputs an approximation to the
underlying matrix with probability $\ge 9/10$ must run for $t =
\Omega(\log(n^2/k)/\log\log n)$ rounds showing that any adaptive algorithm
which uses $n^{2-\beta}$ linear measurements in each round must run for
$\Omega(\log n/\log\log n)$ rounds to compute a reconstruction with probability
$\ge 9/10$. Hence any adaptive algorithm that has $o(\log n/\log\log n)$ rounds
must use an overall $\Omega(n^2)$ linear measurements. Our techniques also
readily extend to obtain lower bounds on adaptive algorithms for tensor
recovery and obtain measurement-vs-rounds trade-off for many sensing problems
in numerical linear algebra, such as spectral norm low rank approximation,
Frobenius norm low rank approximation, singular vector approximation, and more.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17282" title="Abstract">arXiv:2311.17282</a> [<a href="/pdf/2311.17282" title="Download PDF">pdf</a>, <a href="/ps/2311.17282" title="Download PostScript">ps</a>, <a href="/format/2311.17282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing energy consumption of cloud data centers using proper placement  of virtual machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naji%2C+H+R">Hamid Reza Naji</a>, 
<a href="/search/cs?searchtype=author&query=Esmaeili%2C+R">Reza Esmaeili</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2311.16147">arXiv:2311.16147</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In today's world, the use of cloud data centers for easy access to data and
processing resources is expanding rapidly. Rapid technology growth and
increasing number of users make hardware and software architectures upgrade a
constant need. The necessary infrastructure to implement this architecture is
the use of virtual machines in physical systems. The main issue in this
architecture is how to allocate virtual machines to physical machines on the
network. In this paper we have proposed a method to use virtualization for
minimizing energy consumption and decreasing the cloud resource waste. We have
used learning automata as a reinforcement learning model for optimal placement
of virtual machines. The simulation results show the proposed method has good
performance in reducing energy consumption of servers in cloud data centers.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17283" title="Abstract">arXiv:2311.17283</a> [<a href="/pdf/2311.17283" title="Download PDF">pdf</a>, <a href="/format/2311.17283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lineax: unified linear solves and linear least-squares in JAX and  Equinox
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rader%2C+J">Jason Rader</a>, 
<a href="/search/cs?searchtype=author&query=Lyons%2C+T">Terry Lyons</a>, 
<a href="/search/cs?searchtype=author&query=Kidger%2C+P">Patrick Kidger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 1 figure, NeurIPS 2023 AI for Science workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Software (cs.MS)</span>

</div>
<p class="mathjax">We introduce Lineax, a library bringing linear solves and linear
least-squares to the JAX+Equinox scientific computing ecosystem. Lineax uses
general linear operators, and unifies linear solves and least-squares into a
single, autodifferentiable API. Solvers and operators are user-extensible,
without requiring the user to implement any custom derivative rules to get
differentiability. Lineax is available at https://github.com/google/lineax.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17286" title="Abstract">arXiv:2311.17286</a> [<a href="/pdf/2311.17286" title="Download PDF">pdf</a>, <a href="/format/2311.17286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LEOD: Label-Efficient Object Detection for Event Cameras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Ziyi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gehrig%2C+M">Mathias Gehrig</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Q">Qing Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xudong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gilitschenski%2C+I">Igor Gilitschenski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Object detection with event cameras enjoys the property of low latency and
high dynamic range, making it suitable for safety-critical scenarios such as
self-driving. However, labeling event streams with high temporal resolutions
for supervised training is costly. We address this issue with LEOD, the first
framework for label-efficient event-based detection. Our method unifies weakly-
and semi-supervised object detection with a self-training mechanism. We first
utilize a detector pre-trained on limited labels to produce pseudo ground truth
on unlabeled events, and then re-train the detector with both real and
generated labels. Leveraging the temporal consistency of events, we run
bi-directional inference and apply tracking-based post-processing to enhance
the quality of pseudo labels. To stabilize training, we further design a soft
anchor assignment strategy to mitigate the noise in labels. We introduce new
experimental protocols to evaluate the task of label-efficient event-based
detection on Gen1 and 1Mpx datasets. LEOD consistently outperforms supervised
baselines across various labeling ratios. For example, on Gen1, it improves mAP
by 8.6% and 7.8% for RVT-S trained with 1% and 2% labels. On 1Mpx, RVT-S with
10% labels even surpasses its fully-supervised counterpart using 100% labels.
LEOD maintains its effectiveness even when all labeled data are available,
reaching new state-of-the-art results. Finally, we show that our method readily
scales to improve larger detectors as well.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17287" title="Abstract">arXiv:2311.17287</a> [<a href="/pdf/2311.17287" title="Download PDF">pdf</a>, <a href="/format/2311.17287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utilizing Model Residuals to Identify Rental Properties of Interest: The  Price Anomaly Score (PAS) and Its Application to Real-time Data in Manhattan
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sultan%2C+Y">Youssef Sultan</a>, 
<a href="/search/cs?searchtype=author&query=Rafter%2C+J+C">Jackson C. Rafter</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H+T">Huyen T. Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures, dataset is available with DOI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP)

</div>
<p class="mathjax">Understanding whether a property is priced fairly hinders buyers and sellers
since they usually do not have an objective viewpoint of the price distribution
for the overall market of their interest. Drawing from data collected of all
possible available properties for rent in Manhattan as of September 2023, this
paper aims to strengthen our understanding of model residuals; specifically on
machine learning models which generalize for a majority of the distribution of
a well-proportioned dataset. Most models generally perceive deviations from
predicted values as mere inaccuracies, however this paper proposes a different
vantage point: when generalizing to at least 75\% of the data-set, the
remaining deviations reveal significant insights. To harness these insights, we
introduce the Price Anomaly Score (PAS), a metric capable of capturing
boundaries between irregularly predicted prices. By combining relative pricing
discrepancies with statistical significance, the Price Anomaly Score (PAS)
offers a multifaceted view of rental valuations. This metric allows experts to
identify overpriced or underpriced properties within a dataset by aggregating
PAS values, then fine-tuning upper and lower boundaries to any threshold to set
indicators of choice.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17293" title="Abstract">arXiv:2311.17293</a> [<a href="/pdf/2311.17293" title="Download PDF">pdf</a>, <a href="/format/2311.17293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Query Optimizer Performance in the Presence and Absence of  Cardinality Estimates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Datta%2C+A">Asoke Datta</a>, 
<a href="/search/cs?searchtype=author&query=Tsan%2C+B">Brian Tsan</a>, 
<a href="/search/cs?searchtype=author&query=Izenov%2C+Y">Yesdaulet Izenov</a>, 
<a href="/search/cs?searchtype=author&query=Rusu%2C+F">Florin Rusu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Most query optimizers rely on cardinality estimates to determine optimal
execution plans. While traditional databases such as PostgreSQL, Oracle, and
Db2 utilize many types of synopses -- including histograms, samples, and
sketches -- recent main-memory databases like DuckDB and Heavy.AI often operate
with minimal or no estimates, yet their performance does not necessarily
suffer. To the best of our knowledge, no analytical comparison has been
conducted between optimizers with and without cardinality estimates to
understand their performance characteristics in different settings, such as
indexed, non-indexed, and multi-threaded. In this paper, we present a
comparative analysis between optimizers that use cardinality estimates and
those that do not. We use the Join Order Benchmark (JOB) for our evaluation and
true cardinalities as the baseline. Our investigation reveals that cardinality
estimates have marginal impact in non-indexed settings. Meanwhile, when indexes
are available, inaccurate estimates may lead to sub-optimal physical operators
-- even with an optimal join order. Furthermore, the impact of cardinality
estimates is less significant in highly-parallel main-memory databases.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17295" title="Abstract">arXiv:2311.17295</a> [<a href="/pdf/2311.17295" title="Download PDF">pdf</a>, <a href="/format/2311.17295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Elo Uncovered: Robustness and Best Practices in Language Model  Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boubdir%2C+M">Meriem Boubdir</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+E">Edward Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ermis%2C+B">Beyza Ermis</a>, 
<a href="/search/cs?searchtype=author&query=Hooker%2C+S">Sara Hooker</a>, 
<a href="/search/cs?searchtype=author&query=Fadaee%2C+M">Marzieh Fadaee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 7 figures, 2 tables. Revised version of the paper accepted at GEM Workshop, EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In Natural Language Processing (NLP), the Elo rating system, originally
designed for ranking players in dynamic games such as chess, is increasingly
being used to evaluate Large Language Models (LLMs) through "A vs B" paired
comparisons. However, while popular, the system's suitability for assessing
entities with constant skill levels, such as LLMs, remains relatively
unexplored. We study two fundamental axioms that evaluation methods should
adhere to: reliability and transitivity. We conduct extensive evaluation of Elo
behaviour, illustrating that individual Elo computations exhibit volatility and
delving into the impact of varying the Elo rating system's hyperparameters. We
show that these axioms are not always satisfied raising questions about the
reliability of current comparative evaluations of LLMs. If the current use of
Elo scores is intended to substitute the costly head-to-head comparison of
LLMs, it is crucial to ensure the ranking is as robust as possible. Guided by
the axioms, our findings offer concrete guidelines for enhancing the
reliability of LLM evaluation methods, suggesting a need for reassessment of
existing comparative approaches.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17297" title="Abstract">arXiv:2311.17297</a> [<a href="/pdf/2311.17297" title="Download PDF">pdf</a>, <a href="/format/2311.17297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability control for USVs with SINDY-based online dynamic model update
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Unmanned Surface Vehicles (USVs) play a pivotal role in various applications,
including surface rescue, commercial transactions, scientific exploration,
water rescue, and military operations. The effective control of high-speed
unmanned surface boats stands as a critical aspect within the overall USV
system, particularly in challenging environments marked by complex surface
obstacles and dynamic conditions, such as time-varying surges, non-directional
forces, and unpredictable winds. In this paper, we propose a data-driven
control method based on Koopman theory. This involves constructing a
high-dimensional linear model by mapping a low-dimensional nonlinear model to a
higher-dimensional linear space through data identification. The observable
USVs dynamical system is dynamically reconstructed using online error learning.
To enhance tracking control accuracy, we utilize a Constructive Lyapunov
Function (CLF)-Control Barrier Function (CBF)-Quadratic Programming (QP)
approach to regulate the high-dimensional linear dynamical system obtained
through identification. This approach facilitates error compensation, thereby
achieving more precise tracking control.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17299" title="Abstract">arXiv:2311.17299</a> [<a href="/pdf/2311.17299" title="Download PDF">pdf</a>, <a href="/format/2311.17299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Fine-Tuning of Foundation Models via Probabilistic Masking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsouvalas%2C+V">Vasileios Tsouvalas</a>, 
<a href="/search/cs?searchtype=author&query=Asano%2C+Y">Yuki Asano</a>, 
<a href="/search/cs?searchtype=author&query=Saeed%2C+A">Aaqib Saeed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Foundation Models (FMs) have revolutionized machine learning with their
adaptability and high performance across tasks; yet, their integration into
Federated Learning (FL) is challenging due to substantial communication
overhead from their extensive parameterization. Current communication-efficient
FL strategies, such as gradient compression, reduce bitrates to around $1$
bit-per-parameter (bpp). However, these approaches fail to harness the
characteristics of FMs, with their large number of parameters still posing a
challenge to communication efficiency, even at these bitrate regimes. In this
work, we present DeltaMask, a novel method that efficiently fine-tunes FMs in
FL at an ultra-low bitrate, well below 1 bpp. DeltaMask employs stochastic
masking to detect highly effective subnetworks within FMs and leverage
stochasticity and sparsity in client masks to compress updates into a compact
grayscale image using probabilistic filters, deviating from traditional weight
training approaches. Our comprehensive evaluations across various datasets and
architectures demonstrate DeltaMask efficiently achieves bitrates as low as
0.09 bpp, enhancing communication efficiency while maintaining FMs performance,
as measured on 8 datasets and 5 pre-trained models of various network
architectures.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17301" title="Abstract">arXiv:2311.17301</a> [<a href="/pdf/2311.17301" title="Download PDF">pdf</a>, <a href="/format/2311.17301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Models: A Guide for the Perplexed
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Serrano%2C+S">Sofia Serrano</a>, 
<a href="/search/cs?searchtype=author&query=Brumbaugh%2C+Z">Zander Brumbaugh</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+N+A">Noah A. Smith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Given the growing importance of AI literacy, we decided to write this
tutorial to help narrow the gap between the discourse among those who study
language models -- the core technology underlying ChatGPT and similar products
-- and those who are intrigued and want to learn more about them. In short, we
believe the perspective of researchers and educators can add some clarity to
the public's understanding of the technologies beyond what's currently
available, which tends to be either extremely technical or promotional material
generated about products by their purveyors.
<br />Our approach teases apart the concept of a language model from products built
on them, from the behaviors attributed to or desired from those products, and
from claims about similarity to human cognition. As a starting point, we (1)
offer a scientific viewpoint that focuses on questions amenable to study
through experimentation; (2) situate language models as they are today in the
context of the research that led to their development; and (3) describe the
boundaries of what is known about the models at this writing.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17303" title="Abstract">arXiv:2311.17303</a> [<a href="/pdf/2311.17303" title="Download PDF">pdf</a>, <a href="/format/2311.17303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing the Performance of Neural Networks Through Causal Discovery  and Integration of Domain Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao-Lin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+F">Fenglei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+Y">Yiu-Ming Cheung</a>, 
<a href="/search/cs?searchtype=author&query=Bose%2C+I">Indranil Bose</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
<p class="mathjax">In this paper, we develop a generic methodology to encode hierarchical
causality structure among observed variables into a neural network in order to
improve its predictive performance. The proposed methodology, called
causality-informed neural network (CINN), leverages three coherent steps to
systematically map the structural causal knowledge into the layer-to-layer
design of neural network while strictly preserving the orientation of every
causal relationship. In the first step, CINN discovers causal relationships
from observational data via directed acyclic graph (DAG) learning, where causal
discovery is recast as a continuous optimization problem to avoid the
combinatorial nature. In the second step, the discovered hierarchical causality
structure among observed variables is systematically encoded into neural
network through a dedicated architecture and customized loss function. By
categorizing variables in the causal DAG as root, intermediate, and leaf nodes,
the hierarchical causal DAG is translated into CINN with a one-to-one
correspondence between nodes in the causal DAG and units in the CINN while
maintaining the relative order among these nodes. Regarding the loss function,
both intermediate and leaf nodes in the DAG graph are treated as target outputs
during CINN training so as to drive co-learning of causal relationships among
different types of nodes. As multiple loss components emerge in CINN, we
leverage the projection of conflicting gradients to mitigate gradient
interference among the multiple learning tasks. Computational experiments
across a broad spectrum of UCI data sets demonstrate substantial advantages of
CINN in predictive performance over other state-of-the-art methods. In
addition, an ablation study underscores the value of integrating structural and
quantitative causal knowledge in enhancing the neural network's predictive
performance incrementally.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17305" title="Abstract">arXiv:2311.17305</a> [<a href="/pdf/2311.17305" title="Download PDF">pdf</a>, <a href="/format/2311.17305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-Step Reinforcement Learning for Multistage Strategy Card Game
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Godlewski%2C+K">Konrad Godlewski</a>, 
<a href="/search/cs?searchtype=author&query=Sawicki%2C+B">Bartosz Sawicki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">In the realm of artificial intelligence and card games, this study introduces
a two-step reinforcement learning (RL) strategy tailored for "The Lord of the
Rings: The Card Game (LOTRCG)," a complex multistage strategy card game. This
research diverges from conventional RL methods by adopting a phased learning
approach, beginning with a foundational learning stage in a simplified version
of the game and subsequently progressing to the complete, intricate game
environment. This methodology notably enhances the AI agent's adaptability and
performance in the face of LOTRCG's unpredictable and challenging nature. The
paper also explores a multi-agent system, where distinct RL agents are employed
for various decision-making aspects of the game. This approach has demonstrated
a remarkable improvement in game outcomes, with the RL agents achieving a
winrate of 78.5% across a set of 10,000 random games.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17306" title="Abstract">arXiv:2311.17306</a> [<a href="/pdf/2311.17306" title="Download PDF">pdf</a>, <a href="/format/2311.17306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Local Approach to Studying the Time and Space Complexity of  Deterministic and Nondeterministic Decision Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Durdymyradov%2C+K">Kerven Durdymyradov</a>, 
<a href="/search/cs?searchtype=author&query=Moshkov%2C+M">Mikhail Moshkov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2201.01013">arXiv:2201.01013</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">In this paper, we study arbitrary infinite binary information systems each of
which consists of an infinite set called universe and an infinite set of
two-valued functions (attributes) defined on the universe. We consider the
notion of a problem over information system, which is described by a finite
number of attributes and a mapping associating a decision to each tuple of
attribute values. As algorithms for problem solving, we investigate
deterministic and nondeterministic decision trees that use only attributes from
the problem description. Nondeterministic decision trees are representations of
decision rule systems that sometimes have less space complexity than the
original rule systems. As time and space complexity, we study the depth and the
number of nodes in the decision trees. In the worst case, with the growth of
the number of attributes in the problem description, (i) the minimum depth of
deterministic decision trees grows either as a logarithm or linearly, (ii) the
minimum depth of nondeterministic decision trees either is bounded from above
by a constant or grows linearly, (iii) the minimum number of nodes in
deterministic decision trees has either polynomial or exponential growth, and
(iv) the minimum number of nodes in nondeterministic decision trees has either
polynomial or exponential growth. Based on these results, we divide the set of
all infinite binary information systems into three complexity classes. This
allows us to identify nontrivial relationships between deterministic decision
trees and decision rules systems represented by nondeterministic decision
trees. For each class, we study issues related to time-space trade-off for
deterministic and nondeterministic decision trees.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17307" title="Abstract">arXiv:2311.17307</a> [<a href="/pdf/2311.17307" title="Download PDF">pdf</a>, <a href="/format/2311.17307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoKEPG: RoBERTa and Knowledge Enhancement for Prescription Generation of  Traditional Chinese Medicine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pu%2C+H">Hua Pu</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+J">Jiacong Mi</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shan Lu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jieyue He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Traditional Chinese medicine (TCM) prescription is the most critical form of
TCM treatment, and uncovering the complex nonlinear relationship between
symptoms and TCM is of great significance for clinical practice and assisting
physicians in diagnosis and treatment. Although there have been some studies on
TCM prescription generation, these studies consider a single factor and
directly model the symptom-prescription generation problem mainly based on
symptom descriptions, lacking guidance from TCM knowledge. To this end, we
propose a RoBERTa and Knowledge Enhancement model for Prescription Generation
of Traditional Chinese Medicine (RoKEPG). RoKEPG is firstly pre-trained by our
constructed TCM corpus, followed by fine-tuning the pre-trained model, and the
model is guided to generate TCM prescriptions by introducing four classes of
knowledge of TCM through the attention mask matrix. Experimental results on the
publicly available TCM prescription dataset show that RoKEPG improves the F1
metric by about 2% over the baseline model with the best results.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17311" title="Abstract">arXiv:2311.17311</a> [<a href="/pdf/2311.17311" title="Download PDF">pdf</a>, <a href="/format/2311.17311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Self-Consistency for Large Language Model Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Aksitov%2C+R">Renat Aksitov</a>, 
<a href="/search/cs?searchtype=author&query=Alon%2C+U">Uri Alon</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jie Ren</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+K">Kefan Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+P">Pengcheng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Prakash%2C+S">Sushant Prakash</a>, 
<a href="/search/cs?searchtype=author&query=Sutton%2C+C">Charles Sutton</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuezhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Denny Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Self-consistency with chain-of-thought prompting (CoT) has demonstrated
remarkable performance gains on various challenging tasks, by utilizing
multiple reasoning paths sampled from large language models (LLMs). However,
self-consistency relies on the answer extraction process to aggregate multiple
solutions, which is not applicable to free-form answers. In this work, we
propose Universal Self-Consistency (USC), which leverages LLMs themselves to
select the most consistent answer among multiple candidates. We evaluate USC on
a variety of benchmarks, including mathematical reasoning, code generation,
long-context summarization, and open-ended question answering. On open-ended
generation tasks where the original self-consistency method is not applicable,
USC effectively utilizes multiple samples and improves the performance. For
mathematical reasoning, USC matches the standard self-consistency performance
without requiring the answer formats to be similar. Finally, without access to
execution results, USC also matches the execution-based voting performance on
code generation.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17315" title="Abstract">arXiv:2311.17315</a> [<a href="/pdf/2311.17315" title="Download PDF">pdf</a>, <a href="/format/2311.17315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explaining CLIP&#x27;s performance disparities on data from blind/low vision  users
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Massiceti%2C+D">Daniela Massiceti</a>, 
<a href="/search/cs?searchtype=author&query=Longden%2C+C">Camilla Longden</a>, 
<a href="/search/cs?searchtype=author&query=Slowik%2C+A">Agnieszka Slowik</a>, 
<a href="/search/cs?searchtype=author&query=Wills%2C+S">Samuel Wills</a>, 
<a href="/search/cs?searchtype=author&query=Grayson%2C+M">Martin Grayson</a>, 
<a href="/search/cs?searchtype=author&query=Morrison%2C+C">Cecily Morrison</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large multi-modal models (LMMs) hold the potential to usher in a new era of
automated visual assistance for people who are blind or low vision (BLV). Yet,
these models have not been systematically evaluated on data captured by BLV
users. We address this by empirically assessing CLIP, a widely-used LMM likely
to underpin many assistive technologies. Testing 25 CLIP variants in a
zero-shot classification task, we find that their accuracy is 15 percentage
points lower on average for images captured by BLV users than web-crawled
images. This disparity stems from CLIP's sensitivities to 1) image content
(e.g. not recognizing disability objects as well as other objects); 2) image
quality (e.g. not being robust to lighting variation); and 3) text content
(e.g. not recognizing objects described by tactile adjectives as well as visual
ones). We delve deeper with a textual analysis of three common pre-training
datasets: LAION-400M, LAION-2B and DataComp-1B, showing that disability content
is rarely mentioned. We then provide three examples that illustrate how the
performance disparities extend to three downstream models underpinned by CLIP:
OWL-ViT, CLIPSeg and DALL-E2. We find that few-shot learning with as few as 5
images can mitigate CLIP's quality-of-service disparities for BLV users in some
scenarios, which we discuss alongside a set of other possible mitigations.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17317" title="Abstract">arXiv:2311.17317</a> [<a href="/pdf/2311.17317" title="Download PDF">pdf</a>, <a href="/ps/2311.17317" title="Download PostScript">ps</a>, <a href="/format/2311.17317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital Twins for Logistics and Supply Chain Systems: Literature Review,  Conceptual Framework, Research Potential, and Practical Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+T+V">Tho V. Le</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+R">Ruoling Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">To facilitate an effective, efficient, transparent, and timely
decision-making process as well as to provide guidelines for industry planning
and public policy development, a conceptual framework of digital twins (DTs)
for logistics and supply chain systems (LSCS) is needed. This paper first
introduces the background of the logistics and supply chain industry, the DT
and its potential benefits, and the motivations and scope of this research. The
literature review indicates research and practice gaps and needs that motivate
proposing a new conceptual DT framework for LSCS. As each element of the new
framework has different requirements and goals, it initiates new research
opportunities and creates practical implementation challenges. As such, the
future of DT computation involves advanced analytics and modeling techniques to
address the new agenda's requirements. Finally, ideas on the next steps to
deploy a transparent, trustworthy, and resilient DT for LSCS are presented.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17318" title="Abstract">arXiv:2311.17318</a> [<a href="/pdf/2311.17318" title="Download PDF">pdf</a>, <a href="/ps/2311.17318" title="Download PostScript">ps</a>, <a href="/format/2311.17318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impact of Indoor Mobility Behavior on the Respiratory Infectious  Diseases Transmission Trends
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Ziwei Cui</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+M">Ming Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Gongbo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yao Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">The importance of indoor human mobility in the transmission dynamics of
respiratory infectious diseases has been acknowledged. Previous studies have
predominantly addressed a single type of mobility behavior such as queueing and
a series of behaviors under specific scenarios. However, these studies ignore
the abstraction of mobility behavior in various scenes and the critical
examination of how these abstracted behaviors impact disease propagation. To
address these problems, this study considers people's mobility behaviors in a
general scenario, abstracting them into two main categories: crowding behavior,
related to the spatial aspect, and stopping behavior, related to the temporal
aspect. Accordingly, this study investigates their impacts on disease spreading
and the impact of individual spatio-temporal distribution resulting from these
mobility behaviors on epidemic transmission. First, a point of interest (POI)
method is introduced to quantify the crowding-related spatial POI factors
(i.e., the number of crowdings and the distance between crowdings) and
stopping-related temporal POI factors (i.e., the number of stoppings and the
duration of each stopping). Besides, a personal space determined with Voronoi
diagrams is used to construct the individual spatio-temporal distribution
factor. Second, two indicators (i.e., the daily number of new cases and the
average exposure risk of people) are applied to quantify epidemic transmission.
These indicators are derived from a fundamental model which accurately predicts
disease transmission between moving individuals. Third, a set of 200 indoor
scenarios is constructed and simulated to help determine variable values.
Concurrently, the influences and underlying mechanisms of these behavioral
factors on disease transmission are examined using structural equation modeling
and causal inference modeling......
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17319" title="Abstract">arXiv:2311.17319</a> [<a href="/pdf/2311.17319" title="Download PDF">pdf</a>, <a href="/format/2311.17319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Microstructure reconstruction of 2D/3D random materials via  diffusion-based deep generative models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+X">Xianrui Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiaodan Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Microstructure reconstruction serves as a crucial foundation for establishing
Process-Structure-Property (PSP) relationship in material design. Confronting
the limitations of variational autoencoder and generative adversarial network
within generative modeling, this study adopted the denoising diffusion
probability model (DDPM) to learn the probability distribution of
high-dimensional raw data and successfully reconstructed the microstructures of
various composite materials, such as inclusion materials, spinodal
decomposition materials, chessboard materials, fractal noise materials, and so
on. The quality of generated microstructure was evaluated using quantitative
measures like spatial correlation functions and Fourier descriptor. On this
basis, this study also successfully achieved the regulation of microstructure
randomness and the generation of gradient materials through continuous
interpolation in latent space using denoising diffusion implicit model (DDIM).
Furthermore, the two-dimensional microstructure reconstruction is extended to
three-dimensional framework and integrates permeability as a feature encoding
embedding. This enables the conditional generation of three-dimensional
microstructures for random porous materials within a defined permeability
range. The permeabilities of these generated microstructures were further
validated through the application of the Boltzmann method.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17320" title="Abstract">arXiv:2311.17320</a> [<a href="/pdf/2311.17320" title="Download PDF">pdf</a>, <a href="/format/2311.17320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Single Image Reflection Removal In the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yurui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+X">Xueyang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+P">Peng-Tao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qibin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+Z">Zheng-Jun Zha</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This research focuses on the issue of single-image reflection removal (SIRR)
in real-world conditions, examining it from two angles: the collection pipeline
of real reflection pairs and the perception of real reflection locations. We
devise an advanced reflection collection pipeline that is highly adaptable to a
wide range of real-world reflection scenarios and incurs reduced costs in
collecting large-scale aligned reflection pairs. In the process, we develop a
large-scale, high-quality reflection dataset named Reflection Removal in the
Wild (RRW). RRW contains over 14,950 high-resolution real-world reflection
pairs, a dataset forty-five times larger than its predecessors. Regarding
perception of reflection locations, we identify that numerous virtual
reflection objects visible in reflection images are not present in the
corresponding ground-truth images. This observation, drawn from the aligned
pairs, leads us to conceive the Maximum Reflection Filter (MaxRF). The MaxRF
could accurately and explicitly characterize reflection locations from pairs of
images. Building upon this, we design a reflection location-aware cascaded
framework, specifically tailored for SIRR. Powered by these innovative
techniques, our solution achieves superior performance than current leading
methods across multiple real-world benchmarks. Codes and datasets will be
publicly available.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17323" title="Abstract">arXiv:2311.17323</a> [<a href="/pdf/2311.17323" title="Download PDF">pdf</a>, <a href="/format/2311.17323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating DNN Training With Photonics: A Residue Number System-Based  Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Demirkiran%2C+C">Cansu Demirkiran</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guowei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Bunandar%2C+D">Darius Bunandar</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+A">Ajay Joshi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Photonic computing is a compelling avenue for performing highly efficient
matrix multiplication, a crucial operation in Deep Neural Networks (DNNs).
While this method has shown great success in DNN inference, meeting the high
precision demands of DNN training proves challenging due to the precision
limitations imposed by costly data converters and the analog noise inherent in
photonic hardware. This paper proposes Mirage, a photonic DNN training
accelerator that overcomes the precision challenges in photonic hardware using
the Residue Number System (RNS). RNS is a numeral system based on modular
arithmetic$\unicode{x2014}$allowing us to perform high-precision operations via
multiple low-precision modular operations. In this work, we present a novel
micro-architecture and dataflow for an RNS-based photonic tensor core
performing modular arithmetic in the analog domain. By combining RNS and
photonics, Mirage provides high energy efficiency without compromising
precision and can successfully train state-of-the-art DNNs achieving accuracy
comparable to FP32 training. Our study shows that on average across several
DNNs when compared to systolic arrays, Mirage achieves more than $23.8\times$
faster training and $32.1\times$ lower EDP in an iso-energy scenario and
consumes $42.8\times$ lower power with comparable or better EDP in an iso-area
scenario.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17324" title="Abstract">arXiv:2311.17324</a> [<a href="/pdf/2311.17324" title="Download PDF">pdf</a>, <a href="/format/2311.17324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control of complex systems with generalized embedding and empirical  dynamic modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Park%2C+J">Joseph Park</a>, 
<a href="/search/eess?searchtype=author&query=Sugihara%2C+G">George Sugihara</a>, 
<a href="/search/eess?searchtype=author&query=Pao%2C+G">Gerald Pao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Feedback control is ubiquitous in complex systems. Effective control requires
knowledge of the dynamics informing feedback compensation to guide the system
toward desired states. In many control applications this knowledge is expressed
mathematically or through data-driven models, however, as complexity grows
obtaining a satisfactory mathematical representation is increasingly difficult.
Further, many data-driven approaches consist of abstract internal
representations that may have no obvious connection to the underlying dynamics
and control, or, require a-priori specification of functions to represent the
dynamics. To remove these constraints we demonstrate that generalized state
space embedding and prediction can provide data-driven process model
representation for control of complex systems. Generalized embedding naturally
encompasses multivariate dynamics enabling state space variable cross mapping
for direct assessment of multivariate contributions to the dynamics. Further,
state space kernel regression allows inspection of intervariable dependencies.
To illustrate this an agent based model is used to generate nonlinear dynamics
which are then modeled by generalized state space embedding providing state
predictions to a controller regulating the system dynamics. The method is
generally applicable to any dynamic system representable in a state space.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17325" title="Abstract">arXiv:2311.17325</a> [<a href="/pdf/2311.17325" title="Download PDF">pdf</a>, <a href="/format/2311.17325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alternate Diverse Teaching for Semi-supervised Medical Image  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zicheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Longyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yixuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Luping Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> code:<a href="https://github.com/ZhenZHAO/AD-MT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semi-supervised medical image segmentation studies have shown promise in
training models with limited labeled data. However, current dominant
teacher-student based approaches can suffer from the confirmation bias. To
address this challenge, we propose AD-MT, an alternate diverse teaching
approach in a teacher-student framework. It involves a single student model and
two non-trainable teacher models that are momentum-updated periodically and
randomly in an alternate fashion. To mitigate the confirmation bias from the
diverse supervision, the core of AD-MT lies in two proposed modules: the Random
Periodic Alternate (RPA) Updating Module and the Conflict-Combating Module
(CCM). The RPA schedules the alternating diverse updating process with
complementary data batches, distinct data augmentation, and random switching
periods to encourage diverse reasoning from different teaching perspectives.
The CCM employs an entropy-based ensembling strategy to encourage the model to
learn from both the consistent and conflicting predictions between the
teachers. Experimental results demonstrate the effectiveness and superiority of
our AD-MT on the 2D and 3D medical segmentation benchmarks across various
semi-supervised settings.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17326" title="Abstract">arXiv:2311.17326</a> [<a href="/pdf/2311.17326" title="Download PDF">pdf</a>, <a href="/format/2311.17326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mostly Beneficial Clustering: Aggregating Data for Operational Decision  Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengzhang Li</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zhenkang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+Y">Ying Rong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP)

</div>
<p class="mathjax">With increasingly volatile market conditions and rapid product innovations,
operational decision-making for large-scale systems entails solving thousands
of problems with limited data. Data aggregation is proposed to combine the data
across problems to improve the decisions obtained by solving those problems
individually. We propose a novel cluster-based shrunken-SAA approach that can
exploit the cluster structure among problems when implementing the data
aggregation approaches. We prove that, as the number of problems grows,
leveraging the known cluster structure among problems yields additional
benefits over the data aggregation approaches that neglect such structure. When
the cluster structure is unknown, we show that unveiling the cluster structure,
even at the cost of a few data points, can be beneficial, especially when the
distance between clusters of problems is substantial. Our proposed approach can
be extended to general cost functions under mild conditions. When the number of
problems gets large, the optimality gap of our proposed approach decreases
exponentially in the distance between the clusters. We explore the performance
of the proposed approach through the application of managing newsvendor systems
via numerical experiments. We investigate the impacts of distance metrics
between problem instances on the performance of the cluster-based Shrunken-SAA
approach with synthetic data. We further validate our proposed approach with
real data and highlight the advantages of cluster-based data aggregation,
especially in the small-data large-scale regime, compared to the existing
approaches.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17327" title="Abstract">arXiv:2311.17327</a> [<a href="/pdf/2311.17327" title="Download PDF">pdf</a>, <a href="/format/2311.17327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Self-supervised Molecular Representation Learning using  Persistent Homology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yuankai Luo</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Lei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Thost%2C+V">Veronika Thost</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Self-supervised learning (SSL) has great potential for molecular
representation learning given the complexity of molecular graphs, the large
amounts of unlabelled data available, the considerable cost of obtaining labels
experimentally, and the hence often only small training datasets. The
importance of the topic is reflected in the variety of paradigms and
architectures that have been investigated recently. Yet the differences in
performance seem often minor and are barely understood to date. In this paper,
we study SSL based on persistent homology (PH), a mathematical tool for
modeling topological features of data that persist across multiple scales. It
has several unique features which particularly suit SSL, naturally offering:
different views of the data, stability in terms of distance preservation, and
the opportunity to flexibly incorporate domain knowledge. We (1) investigate an
autoencoder, which shows the general representational power of PH, and (2)
propose a contrastive loss that complements existing approaches. We rigorously
evaluate our approach for molecular property prediction and demonstrate its
particular features in improving the embedding space: after SSL, the
representations are better and offer considerably more predictive power than
the baselines over different probing tasks; our loss increases baseline
performance, sometimes largely; and we often obtain substantial improvements
over very small datasets, a common scenario in practice.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17329" title="Abstract">arXiv:2311.17329</a> [<a href="/pdf/2311.17329" title="Download PDF">pdf</a>, <a href="/format/2311.17329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cascade: A Platform for Delay-Sensitive Edge Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+W">Weijia Song</a>, 
<a href="/search/cs?searchtype=author&query=Garrett%2C+T">Thiago Garrett</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuting Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingzhao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tremel%2C+E">Edward Tremel</a>, 
<a href="/search/cs?searchtype=author&query=Rosa%2C+L">Lorenzo Rosa</a>, 
<a href="/search/cs?searchtype=author&query=Merlina%2C+A">Andrea Merlina</a>, 
<a href="/search/cs?searchtype=author&query=Vitenberg%2C+R">Roman Vitenberg</a>, 
<a href="/search/cs?searchtype=author&query=Birman%2C+K">Ken Birman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 12 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Operating Systems (cs.OS)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Interactive intelligent computing applications are increasingly prevalent,
creating a need for AI/ML platforms optimized to reduce per-event latency while
maintaining high throughput and efficient resource management. Yet many
intelligent applications run on AI/ML platforms that optimize for high
throughput even at the cost of high tail-latency. Cascade is a new AI/ML
hosting platform intended to untangle this puzzle. Innovations include a
legacy-friendly storage layer that moves data with minimal copying and a "fast
path" that collocates data and computation to maximize responsiveness. Our
evaluation shows that Cascade reduces latency by orders of magnitude with no
loss of throughput.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17330" title="Abstract">arXiv:2311.17330</a> [<a href="/pdf/2311.17330" title="Download PDF">pdf</a>, <a href="/ps/2311.17330" title="Download PostScript">ps</a>, <a href="/format/2311.17330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Biomedical knowledge graph-enhanced prompt generation for large language  models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soman%2C+K">Karthik Soman</a>, 
<a href="/search/cs?searchtype=author&query=Rose%2C+P+W">Peter W Rose</a>, 
<a href="/search/cs?searchtype=author&query=Morris%2C+J+H">John H Morris</a>, 
<a href="/search/cs?searchtype=author&query=Akbas%2C+R+E">Rabia E Akbas</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+B">Brett Smith</a>, 
<a href="/search/cs?searchtype=author&query=Peetoom%2C+B">Braian Peetoom</a>, 
<a href="/search/cs?searchtype=author&query=Villouta-Reyes%2C+C">Catalina Villouta-Reyes</a>, 
<a href="/search/cs?searchtype=author&query=Cerono%2C+G">Gabriel Cerono</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yongmei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Rizk-Jackson%2C+A">Angela Rizk-Jackson</a>, 
<a href="/search/cs?searchtype=author&query=Israni%2C+S">Sharat Israni</a>, 
<a href="/search/cs?searchtype=author&query=Nelson%2C+C+A">Charlotte A Nelson</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Sui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Baranzini%2C+S+E">Sergio E Baranzini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 5 figures, 2 tables, 1 supplementary file
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have been driving progress in AI at an
unprecedented rate, yet still face challenges in knowledge-intensive domains
like biomedicine. Solutions such as pre-training and domain-specific
fine-tuning add substantial computational overhead, and the latter require
domain-expertise. External knowledge infusion is task-specific and requires
model training. Here, we introduce a task-agnostic Knowledge Graph-based
Retrieval Augmented Generation (KG-RAG) framework by leveraging the massive
biomedical KG SPOKE with LLMs such as Llama-2-13b, GPT-3.5-Turbo and GPT-4, to
generate meaningful biomedical text rooted in established knowledge. KG-RAG
consistently enhanced the performance of LLMs across various prompt types,
including one-hop and two-hop prompts, drug repurposing queries, biomedical
true/false questions, and multiple-choice questions (MCQ). Notably, KG-RAG
provides a remarkable 71% boost in the performance of the Llama-2 model on the
challenging MCQ dataset, demonstrating the framework's capacity to empower
open-source models with fewer parameters for domain-specific questions.
Furthermore, KG-RAG enhanced the performance of proprietary GPT models, such as
GPT-3.5 which exhibited improvement over GPT-4 in context utilization on MCQ
data. Our approach was also able to address drug repurposing questions,
returning meaningful repurposing suggestions. In summary, the proposed
framework combines explicit and implicit knowledge of KG and LLM, respectively,
in an optimized fashion, thus enhancing the adaptability of general-purpose
LLMs to tackle domain-specific questions in a unified framework.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17331" title="Abstract">arXiv:2311.17331</a> [<a href="/pdf/2311.17331" title="Download PDF">pdf</a>, <a href="/format/2311.17331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Top-Down Reasoning: An Explainable Multi-Agent Approach for  Visual Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zeqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+W">Wentao Wan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Runmeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lao%2C+Q">Qiqing Lao</a>, 
<a href="/search/cs?searchtype=author&query=Lang%2C+M">Minjie Lang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Keze Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, Vision Language Models (VLMs) have gained significant attention,
exhibiting notable advancements across various tasks by leveraging extensive
image-text paired data. However, prevailing VLMs often treat Visual Question
Answering (VQA) as perception tasks, employing black-box models that overlook
explicit modeling of relationships between different questions within the same
visual scene. Moreover, the existing VQA methods that rely on Knowledge Bases
(KBs) might frequently encounter biases from limited data and face challenges
in relevant information indexing. Attempt to overcome these limitations, this
paper introduces an explainable multi-agent collaboration framework by tapping
into knowledge embedded in Large Language Models (LLMs) trained on extensive
corpora. Inspired by human cognition, our framework uncovers latent information
within the given question by employing three agents, i.e., Seeker, Responder,
and Integrator, to perform a top-down reasoning process. The Seeker agent
generates relevant issues related to the original question. The Responder
agent, based on VLM, handles simple VQA tasks and provides candidate answers.
The Integrator agent combines information from the Seeker agent and the
Responder agent to produce the final VQA answer. Through the above
collaboration mechanism, our framework explicitly constructs a multi-view
knowledge base for a specific image scene, reasoning answers in a top-down
processing manner. We extensively evaluate our method on diverse VQA datasets
and VLMs, demonstrating its broad applicability and interpretability with
comprehensive experimental results.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17332" title="Abstract">arXiv:2311.17332</a> [<a href="/pdf/2311.17332" title="Download PDF">pdf</a>, <a href="/format/2311.17332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeRFTAP: Enhancing Transferability of Adversarial Patches on Face  Recognition using Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+F">Furao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+F">Feng Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+C">Changhai Nie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Face recognition (FR) technology plays a crucial role in various
applications, but its vulnerability to adversarial attacks poses significant
security concerns. Existing research primarily focuses on transferability to
different FR models, overlooking the direct transferability to victim's face
images, which is a practical threat in real-world scenarios. In this study, we
propose a novel adversarial attack method that considers both the
transferability to the FR model and the victim's face image, called NeRFTAP.
Leveraging NeRF-based 3D-GAN, we generate new view face images for the source
and target subjects to enhance transferability of adversarial patches. We
introduce a style consistency loss to ensure the visual similarity between the
adversarial UV map and the target UV map under a 0-1 mask, enhancing the
effectiveness and naturalness of the generated adversarial face images.
Extensive experiments and evaluations on various FR models demonstrate the
superiority of our approach over existing attack techniques. Our work provides
valuable insights for enhancing the robustness of FR systems in practical
adversarial settings.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17333" title="Abstract">arXiv:2311.17333</a> [<a href="/pdf/2311.17333" title="Download PDF">pdf</a>, <a href="/format/2311.17333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Path integral molecular dynamics approximations of quantum canonical  observables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Huang%2C+X">Xin Huang</a>, 
<a href="/search/math?searchtype=author&query=Plechac%2C+P">Petr Plechac</a>, 
<a href="/search/math?searchtype=author&query=Sandberg%2C+M">Mattias Sandberg</a>, 
<a href="/search/math?searchtype=author&query=Szepessy%2C+A">Anders Szepessy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Mean-field molecular dynamics based on path integrals is used to approximate
canonical quantum observables for particle systems consisting of nuclei and
electrons. A computational bottleneck is the sampling from the Gibbs density of
the electron operator, which due to the fermion sign problem has a
computational complexity that scales exponentially with the number of
electrons. In this work we construct an algorithm that approximates the
mean-field Hamiltonian by path integrals for fermions. The algorithm is based
on the determinant of a matrix with components based on Brownian bridges
connecting permuted electron coordinates. The computational work for $n$
electrons is $\mathcal O(n^3)$, which reduces the computational complexity
associated with the fermion sign problem. We analyze a bias resulting from this
approximation and provide a computational error indicator. It remains to
rigorously explain the surprisingly high accuracy.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17334" title="Abstract">arXiv:2311.17334</a> [<a href="/pdf/2311.17334" title="Download PDF">pdf</a>, <a href="/format/2311.17334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long-tailed multi-label classification with noisy label of thoracic  diseases from chest X-ray
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+H">Haoran Lai</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Q">Qingsong Yao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhiyang He</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+X">Xiaodong Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S+K">S Kevin Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Chest X-rays (CXR) often reveal rare diseases, demanding precise diagnosis.
However, current computer-aided diagnosis (CAD) methods focus on common
diseases, leading to inadequate detection of rare conditions due to the absence
of comprehensive datasets. To overcome this, we present a novel benchmark for
long-tailed multi-label classification in CXRs, encapsulating both common and
rare thoracic diseases. Our approach includes developing the "LTML-MIMIC-CXR"
dataset, an augmentation of MIMIC-CXR with 26 additional rare diseases. We
propose a baseline method for this classification challenge, integrating
adaptive negative regularization to address negative logits' over-suppression
in tail classes, and a large loss reconsideration strategy for correcting noisy
labels from automated annotations. Our evaluation on LTML-MIMIC-CXR
demonstrates significant advancements in rare disease detection. This work
establishes a foundation for robust CAD methods, achieving a balance in
identifying a spectrum of thoracic diseases in CXRs. Access to our code and
dataset is provided at:https://github.com/laihaoran/LTML-MIMIC-CXR.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17335" title="Abstract">arXiv:2311.17335</a> [<a href="/pdf/2311.17335" title="Download PDF">pdf</a>, <a href="/format/2311.17335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> eMotions: A Large-Scale Dataset for Emotion Recognition in Short Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xuecheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Heli Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+J">Junxiao Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+R">Ruofan Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+X">Xiangyan Kong</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+J">Jiayu Nie</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Liang He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Nowadays, short videos (SVs) are essential to information acquisition and
sharing in our life. The prevailing use of SVs to spread emotions leads to the
necessity of emotion recognition in SVs. Considering the lack of SVs emotion
data, we introduce a large-scale dataset named eMotions, comprising 27,996
videos. Meanwhile, we alleviate the impact of subjectivities on labeling
quality by emphasizing better personnel allocations and multi-stage
annotations. In addition, we provide the category-balanced and test-oriented
variants through targeted data sampling. Some commonly used videos (e.g.,
facial expressions and postures) have been well studied. However, it is still
challenging to understand the emotions in SVs. Since the enhanced content
diversity brings more distinct semantic gaps and difficulties in learning
emotion-related features, and there exists information gaps caused by the
emotion incompleteness under the prevalently audio-visual co-expressions. To
tackle these problems, we present an end-to-end baseline method AV-CPNet that
employs the video transformer to better learn semantically relevant
representations. We further design the two-stage cross-modal fusion module to
complementarily model the correlations of audio-visual features. The EP-CE
Loss, incorporating three emotion polarities, is then applied to guide model
optimization. Extensive experimental results on nine datasets verify the
effectiveness of AV-CPNet. Datasets and code will be open on
https://github.com/XuecWu/eMotions.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17336" title="Abstract">arXiv:2311.17336</a> [<a href="/pdf/2311.17336" title="Download PDF">pdf</a>, <a href="/format/2311.17336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incremental Neural Controlled Differential Equations for Modeling of  Path-dependent Materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yangzi He</a>, 
<a href="/search/cs?searchtype=author&query=Semnani%2C+S+J">Shabnam J. Semnani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Data-driven surrogate modeling or metamodeling has emerged as a promising
approach for reducing computational expenses of multiscale simulations.
Recurrent Neural Network (RNN) is a common choice for modeling of
path-dependent behavior. However, previous studies have shown that RNNs fail to
make predictions that are consistent with perturbation in the input strain,
leading to potential oscillations and lack of convergence when implemented
within finite element simulations. In this work, we leverage neural
differential equations which have recently emerged to model time series in a
continuous manner and show their robustness in modeling elasto-plastic
path-dependent material behavior. We develop a new sequential model called
Incremental Neural Controlled Differential Equation (INCDE) for general
time-variant dynamical systems, including path-dependent constitutive models.
INCDE is formulated and analyzed in terms of stability and convergence. A
surrogate model based on INCDE is subsequently trained and tested for J2
plasticity. The surrogate model is implemented for material point simulations
and boundary value problems solved using the finite element method with various
cyclic and monotonic loading protocols to demonstrate the robustness,
consistency and accuracy of the proposed approach.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17338" title="Abstract">arXiv:2311.17338</a> [<a href="/pdf/2311.17338" title="Download PDF">pdf</a>, <a href="/format/2311.17338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VideoAssembler: Identity-Consistent Video Generation with Reference  Entities using Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haoyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tianyi Lu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiaxi Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zuxuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu-Gang Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Identity-consistent video generation seeks to synthesize videos that are
guided by both textual prompts and reference images of entities. Current
approaches typically utilize cross-attention layers to integrate the appearance
of the entity, which predominantly captures semantic attributes, resulting in
compromised fidelity of entities. Moreover, these methods necessitate iterative
fine-tuning for each new entity encountered, thereby limiting their
applicability. To address these challenges, we introduce VideoAssembler, a
novel end-to-end framework for identity-consistent video generation that can
conduct inference directly when encountering new entities. VideoAssembler is
adept at producing videos that are not only flexible with respect to the input
reference entities but also responsive to textual conditions. Additionally, by
modulating the quantity of input images for the entity, VideoAssembler enables
the execution of tasks ranging from image-to-video generation to sophisticated
video editing. VideoAssembler comprises two principal components: the Reference
Entity Pyramid (REP) encoder and the Entity-Prompt Attention Fusion (EPAF)
module. The REP encoder is designed to infuse comprehensive appearance details
into the denoising stages of the stable diffusion model. Concurrently, the EPAF
module is utilized to integrate text-aligned features effectively. Furthermore,
to mitigate the challenge of scarce data, we present a methodology for the
preprocessing of training data. Our evaluation of the VideoAssembler framework
on the UCF-101, MSR-VTT, and DAVIS datasets indicates that it achieves good
performances in both quantitative and qualitative analyses (346.84 in FVD and
48.01 in IS on UCF-101). Our project page is at
https://videoassembler.github.io/videoassembler.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17339" title="Abstract">arXiv:2311.17339</a> [<a href="/pdf/2311.17339" title="Download PDF">pdf</a>, <a href="/format/2311.17339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RADAP: A Robust and Adaptive Defense Against Diverse Adversarial Patches  on Face Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+F">Furao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+C">Changhai Nie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Face recognition (FR) systems powered by deep learning have become widely
used in various applications. However, they are vulnerable to adversarial
attacks, especially those based on local adversarial patches that can be
physically applied to real-world objects. In this paper, we propose RADAP, a
robust and adaptive defense mechanism against diverse adversarial patches in
both closed-set and open-set FR systems. RADAP employs innovative techniques,
such as FCutout and F-patch, which use Fourier space sampling masks to improve
the occlusion robustness of the FR model and the performance of the patch
segmenter. Moreover, we introduce an edge-aware binary cross-entropy (EBCE)
loss function to enhance the accuracy of patch detection. We also present the
split and fill (SAF) strategy, which is designed to counter the vulnerability
of the patch segmenter to complete white-box adaptive attacks. We conduct
comprehensive experiments to validate the effectiveness of RADAP, which shows
significant improvements in defense performance against various adversarial
patches, while maintaining clean accuracy higher than that of the undefended
Vanilla model.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17345" title="Abstract">arXiv:2311.17345</a> [<a href="/pdf/2311.17345" title="Download PDF">pdf</a>, <a href="/ps/2311.17345" title="Download PostScript">ps</a>, <a href="/format/2311.17345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perancangan UI/UX Aplikasi Sistem Informasi Layanan Administrasi dalam  Perspektif Psikologi Menggunakan Metode Prototype
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Febriani%2C+S">Sania Febriani</a>, 
<a href="/search/cs?searchtype=author&query=Sutabri%2C+T">Tata Sutabri</a>, 
<a href="/search/cs?searchtype=author&query=Megawaty">Megawaty</a>, 
<a href="/search/cs?searchtype=author&query=Abdillah%2C+L+A">Leon A. Abdillah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Journal Article, in Indonesian language
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> JTIK, vol. 9, no. 2,2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Bina Darma University student administration services are still carried out
conventionally. Students meet the lecturer to ask the lecturer to sign their
administrative documents. However, cases of forged signatures still occur at
Bina Darma University. This problem can cause material loss and is included in
the category of criminal offense. The aim of this research is to design an
Administrative Services Information System (SILASTRI) interface by applying
color psychology theory, Gestalt principles with a good user experience.
SILASTRI is designed to support student administration services at Bina Darma
University. Data collection through observation, distributing questionnaires
and literature study. This research uses a prototype method which consists of
communication, quick plan, modeling quick design, construction of prototype and
deployment delivery &amp; feedback. The prototype method proves technical
feasibility and validates the usability of the user interface display by
estimating the software so that if there are deficiencies they can be corrected
immediately. Based on the results of usability testing using Maze, which was
tested by 70 respondents, the Maze usability value was 89 and the SUS
calculation value was 88, which is in the good category. Therefore, it can be
concluded that the UI/UX design of the SILASTRI application by applying a
psychological perspective has an interface and user experience that is well
received by users. The results of this testing and evaluation prove that the
SILASTRI display design is ready to be developed into an application.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17347" title="Abstract">arXiv:2311.17347</a> [<a href="/pdf/2311.17347" title="Download PDF">pdf</a>, <a href="/format/2311.17347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-driven Bandwidth Adaptation for Radio Access Network Slices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nikolaidis%2C+P">Panagiotis Nikolaidis</a>, 
<a href="/search/cs?searchtype=author&query=Zoulkarni%2C+A">Asim Zoulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Baras%2C+J">John Baras</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">We develop a Bandwidth Demand Estimator (BDE); a network function that
periodically monitors the traffic of a Network Slice (NS) and adapts the
bandwidth at the base station to efficiently meet its packet delay
requirements. We design the BDE based on a data-driven approach that utilizes
QoS feedback. Given the traffic of the NS, the BDE needs to learn the bandwidth
required to satisfy the QoS. However, it also needs to consider the future
effects of its actions since low bandwidths may create large packet queues that
hinder the allocation process later on. For this reason, we propose a
reinforcement learning approach. The action is the allocated bandwidth. The
state describes the traffic, the wireless channel and the packet queue of the
NS. The cost is a weighted sum of the bandwidth and of a binary variable that
equals 1 if the QoS is violated. We periodically estimate the transition matrix
of the system and perform value iteration to find the optimal policy. To speed
up the estimation process, we initialize our algorithm with multi-armed bandits
and exploit the monotonicity of the cost w.r.t. the action. The overall
approach can be viewed as a data-driven version of receding horizon control. We
implement our BDE on a 3GPP compliant testbed developed by Amarisoft.
Experimental results show that the BDE reduces both the average allocated
bandwidth and the QoS violations in the NS when compared to baseline schemes.
The BDE can also satisfy per user tail packet delay requirements.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17349" title="Abstract">arXiv:2311.17349</a> [<a href="/pdf/2311.17349" title="Download PDF">pdf</a>, <a href="/format/2311.17349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A positivity preserving scheme for Poisson-Nernst-Planck Navier-Stokes  equations and its error analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yu%2C+Z">Ziyao Yu</a>, 
<a href="/search/math?searchtype=author&query=Cheng%2C+Q">Qing Cheng</a>, 
<a href="/search/math?searchtype=author&query=Shen%2C+J">Jie Shen</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+C">Changyou Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">We consider in this paper a numerical approximation of
Poisson-Nernst-Planck-Navier- Stokes (PNP-NS) system. We construct a decoupled
semi-discrete and fully discrete scheme that enjoys the properties of
positivity preserving, mass conserving, and unconditionally energy stability.
Then, we establish the well-posedness and regularity of the initial and
(periodic) boundary value problem of the PNP-NS system under suitable
assumptions on the initial data, and carry out a rigorous convergence analysis
for the fully discretized scheme. We also present some numerical results to
validate the positivity-preserving property and the accuracy of our scheme.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17350" title="Abstract">arXiv:2311.17350</a> [<a href="/pdf/2311.17350" title="Download PDF">pdf</a>, <a href="/format/2311.17350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit-explicit Integrated Representations for Multi-view Video  Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+G">Guo Lu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bing He</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+R">Rong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Li Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">With the increasing consumption of 3D displays and virtual reality,
multi-view video has become a promising format. However, its high resolution
and multi-camera shooting result in a substantial increase in data volume,
making storage and transmission a challenging task. To tackle these
difficulties, we propose an implicit-explicit integrated representation for
multi-view video compression. Specifically, we first use the explicit
representation-based 2D video codec to encode one of the source views.
Subsequently, we propose employing the implicit neural representation
(INR)-based codec to encode the remaining views. The implicit codec takes the
time and view index of multi-view video as coordinate inputs and generates the
corresponding implicit reconstruction frames.To enhance the compressibility, we
introduce a multi-level feature grid embedding and a fully convolutional
architecture into the implicit codec. These components facilitate
coordinate-feature and feature-RGB mapping, respectively. To further enhance
the reconstruction quality from the INR codec, we leverage the high-quality
reconstructed frames from the explicit codec to achieve inter-view
compensation. Finally, the compensated results are fused with the implicit
reconstructions from the INR to obtain the final reconstructed frames. Our
proposed framework combines the strengths of both implicit neural
representation and explicit 2D codec. Extensive experiments conducted on public
datasets demonstrate that the proposed framework can achieve comparable or even
superior performance to the latest multi-view video compression standard MIV
and other INR-based schemes in terms of view compression and scene modeling.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17351" title="Abstract">arXiv:2311.17351</a> [<a href="/pdf/2311.17351" title="Download PDF">pdf</a>, <a href="/format/2311.17351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Large Language Models for Human Mobility Prediction under  Public Events
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuebing Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yichao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaohan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhan Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Public events, such as concerts and sports games, can be major attractors for
large crowds, leading to irregular surges in travel demand. Accurate human
mobility prediction for public events is thus crucial for event planning as
well as traffic or crowd management. While rich textual descriptions about
public events are commonly available from online sources, it is challenging to
encode such information in statistical or machine learning models. Existing
methods are generally limited in incorporating textual information, handling
data sparsity, or providing rationales for their predictions. To address these
challenges, we introduce a framework for human mobility prediction under public
events (LLM-MPE) based on Large Language Models (LLMs), leveraging their
unprecedented ability to process textual data, learn from minimal examples, and
generate human-readable explanations. Specifically, LLM-MPE first transforms
raw, unstructured event descriptions from online sources into a standardized
format, and then segments historical mobility data into regular and
event-related components. A prompting strategy is designed to direct LLMs in
making and rationalizing demand predictions considering historical mobility and
event features. A case study is conducted for Barclays Center in New York City,
based on publicly available event information and taxi trip data. Results show
that LLM-MPE surpasses traditional models, particularly on event days, with
textual data significantly enhancing its accuracy. Furthermore, LLM-MPE offers
interpretable insights into its predictions. Despite the great potential of
LLMs, we also identify key challenges including misinformation and high costs
that remain barriers to their broader adoption in large-scale human mobility
analysis.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17352" title="Abstract">arXiv:2311.17352</a> [<a href="/pdf/2311.17352" title="Download PDF">pdf</a>, <a href="/format/2311.17352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Stitchable Task Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+H">Haoyu He</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zizheng Pan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+J">Jianfei Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+B">Bohan Zhuang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Source code will be released at <a href="https://github.com/ziplab/Stitched_LLaMA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The paradigm of pre-training and fine-tuning has laid the foundation for
deploying deep learning models. However, most fine-tuning methods are designed
to meet a specific resource budget. Recently, considering diverse deployment
scenarios with various resource budgets, stitchable neural network (SN-Net) is
introduced to quickly obtain numerous new networks (stitches) from the
pre-trained models (anchors) in a model family via model stitching. Although
promising, SN-Net confronts new challenges when adapting it to new target
domains, including huge memory and storage requirements and a long and
sub-optimal multistage adaptation process. In this work, we present a novel
framework, Efficient Stitchable Task Adaptation (ESTA), to efficiently produce
a palette of fine-tuned models that adhere to diverse resource constraints.
Specifically, we first tailor parameter-efficient fine-tuning to share low-rank
updates among the stitches while maintaining independent bias terms. In this
way, we largely reduce fine-tuning memory burdens and mitigate the interference
among stitches that arises in task adaptation. Furthermore, we streamline a
simple yet effective one-stage deployment pipeline, which estimates the
important stitches to deploy with training-time gradient statistics. By
assigning higher sampling probabilities to important stitches, we also get a
boosted Pareto frontier. Extensive experiments on 25 downstream visual
recognition tasks demonstrate that our ESTA is capable of generating stitches
with smooth accuracy-efficiency trade-offs and surpasses the direct SN-Net
adaptation by remarkable margins with significantly lower training time and
fewer trainable parameters. Furthermore, we demonstrate the flexibility and
scalability of our ESTA framework by stitching LLMs from LLaMA family,
obtaining chatbot stitches of assorted sizes.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17354" title="Abstract">arXiv:2311.17354</a> [<a href="/pdf/2311.17354" title="Download PDF">pdf</a>, <a href="/ps/2311.17354" title="Download PostScript">ps</a>, <a href="/format/2311.17354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A natural language processing-based approach: mapping human perception  by understanding deep semantic features in street view images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Haoran Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Dongdong Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the past decade, using Street View images and machine learning to measure
human perception has become a mainstream research approach in urban science.
However, this approach using only image-shallow information makes it difficult
to comprehensively understand the deep semantic features of human perception of
a scene. In this study, we proposed a new framework based on a pre-train
natural language model to understand the relationship between human perception
and the sense of a scene. Firstly, Place Pulse 2.0 was used as our base
dataset, which contains a variety of human-perceived labels, namely, beautiful,
safe, wealthy, depressing, boring, and lively. An image captioning network was
used to extract the description information of each street view image.
Secondly, a pre-trained BERT model was finetuning and added a regression
function for six human perceptual dimensions. Furthermore, we compared the
performance of five traditional regression methods with our approach and
conducted a migration experiment in Hong Kong. Our results show that human
perception scoring by deep semantic features performed better than previous
studies by machine learning methods with shallow features. The use of deep
scene semantic features provides new ideas for subsequent human perception
research, as well as better explanatory power in the face of spatial
heterogeneity.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17355" title="Abstract">arXiv:2311.17355</a> [<a href="/pdf/2311.17355" title="Download PDF">pdf</a>, <a href="/format/2311.17355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Large Language Models Good Fact Checkers: A Preliminary Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Han Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+L">Lingwei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mengyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Songlin Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recently, Large Language Models (LLMs) have drawn significant attention due
to their outstanding reasoning capabilities and extensive knowledge repository,
positioning them as superior in handling various natural language processing
tasks compared to other language models. In this paper, we present a
preliminary investigation into the potential of LLMs in fact-checking. This
study aims to comprehensively evaluate various LLMs in tackling specific
fact-checking subtasks, systematically evaluating their capabilities, and
conducting a comparative analysis of their performance against pre-trained and
state-of-the-art low-parameter models. Experiments demonstrate that LLMs
achieve competitive performance compared to other small models in most
scenarios. However, they encounter challenges in effectively handling Chinese
fact verification and the entirety of the fact-checking pipeline due to
language inconsistencies and hallucinations. These findings underscore the need
for further exploration and research to enhance the proficiency of LLMs as
reliable fact-checkers, unveiling the potential capability of LLMs and the
possible challenges in fact-checking tasks.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17358" title="Abstract">arXiv:2311.17358</a> [<a href="/pdf/2311.17358" title="Download PDF">pdf</a>, <a href="/format/2311.17358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenSense: An Open-World Sensing Framework for Incremental Learning and  Dynamic Sensor Scheduling on Embedded Edge Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bukhari%2C+A">Abdulrahman Bukhari</a>, 
<a href="/search/eess?searchtype=author&query=Hosseinimotlagh%2C+S">Seyedmehdi Hosseinimotlagh</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+H">Hyoseung Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Recent advances in Internet-of-Things (IoT) technologies have sparked
significant interest towards developing learning-based sensing applications on
embedded edge devices. These efforts, however, are being challenged by the
complexities of adapting to unforeseen conditions in an open-world environment,
mainly due to the intensive computational and energy demands exceeding the
capabilities of edge devices. In this paper, we propose OpenSense, an
open-world time-series sensing framework for making inferences from time-series
sensor data and achieving incremental learning on an embedded edge device with
limited resources. The proposed framework is able to achieve two essential
tasks, inference and incremental learning, eliminating the necessity for
powerful cloud servers. In addition, to secure enough time for incremental
learning and reduce energy consumption, we need to schedule sensing activities
without missing any events in the environment. Therefore, we propose two
dynamic sensor scheduling techniques: (i) a class-level period assignment
scheduler that finds an appropriate sensing period for each inferred class, and
(ii) a Q-learning-based scheduler that dynamically determines the sensing
interval for each classification moment by learning the patterns of event
classes. With this framework, we discuss the design choices made to ensure
satisfactory learning performance and efficient resource usage. Experimental
results demonstrate the ability of the system to incrementally adapt to
unforeseen conditions and to efficiently schedule to run on a
resource-constrained device.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17361" title="Abstract">arXiv:2311.17361</a> [<a href="/pdf/2311.17361" title="Download PDF">pdf</a>, <a href="/ps/2311.17361" title="Download PostScript">ps</a>, <a href="/format/2311.17361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How does spatial structure affect psychological restoration? A method  based on Graph Neural Networks and Street View Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Haoran Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Pengyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhua%2C+P">Pengyu Zhua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 7 figures, Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The Attention Restoration Theory (ART) presents a theoretical framework with
four essential indicators (being away, extent, fascinating, and compatibility)
for comprehending urban and natural restoration quality. However, previous
studies relied on non-sequential data and non-spatial dependent methods, which
overlooks the impact of spatial structure defined here as the positional
relationships between scene entities on restoration quality. The past methods
also make it challenging to measure restoration quality on an urban scale. In
this work, a spatial-dependent graph neural networks (GNNs) approach is
proposed to reveal the relation between spatial structure and restoration
quality on an urban scale. Specifically, we constructed two different types of
graphs at the street and city levels. The street-level graphs, using sequential
street view images (SVIs) of road segments to capture position relationships
between entities, were used to represent spatial structure. The city-level
graph, modeling the topological relationships of roads as non-Euclidean data
structures and embedding urban features (including Perception-features,
Spatial-features, and Socioeconomic-features), was used to measure restoration
quality. The results demonstrate that: 1) spatial-dependent GNNs model
outperforms traditional methods (Acc = 0.735, F1 = 0.732); 2) spatial structure
portrayed through sequential SVIs data significantly influences restoration
quality; 3) spaces with the same restoration quality exhibited distinct spatial
structures patterns. This study clarifies the association between spatial
structure and restoration quality, providing a new perspective to improve urban
well-being in the future.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17365" title="Abstract">arXiv:2311.17365</a> [<a href="/pdf/2311.17365" title="Download PDF">pdf</a>, <a href="/ps/2311.17365" title="Download PostScript">ps</a>, <a href="/format/2311.17365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symbol-LLM: Leverage Language Models for Symbolic System in Visual Human  Activity Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaoqian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong-Lu Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jianhua Sun</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human reasoning can be understood as a cooperation between the intuitive,
associative "System-1" and the deliberative, logical "System-2". For existing
System-1-like methods in visual activity understanding, it is crucial to
integrate System-2 processing to improve explainability, generalization, and
data efficiency. One possible path of activity reasoning is building a symbolic
system composed of symbols and rules, where one rule connects multiple symbols,
implying human knowledge and reasoning abilities. Previous methods have made
progress, but are defective with limited symbols from handcraft and limited
rules from visual-based annotations, failing to cover the complex patterns of
activities and lacking compositional generalization. To overcome the defects,
we propose a new symbolic system with two ideal important properties:
broad-coverage symbols and rational rules. Collecting massive human knowledge
via manual annotations is expensive to instantiate this symbolic system.
Instead, we leverage the recent advancement of LLMs (Large Language Models) as
an approximation of the two ideal properties, i.e., Symbols from Large Language
Models (Symbol-LLM). Then, given an image, visual contents from the images are
extracted and checked as symbols and activity semantics are reasoned out based
on rules via fuzzy logic calculation. Our method shows superiority in extensive
activity understanding tasks. Code and data are available at
https://mvig-rhos.com/symbol_llm.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17366" title="Abstract">arXiv:2311.17366</a> [<a href="/pdf/2311.17366" title="Download PDF">pdf</a>, <a href="/format/2311.17366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Hierarchical Temporal Transformer for Hand Action Recognition  and Motion Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yilin Wen</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+H">Hao Pan</a>, 
<a href="/search/cs?searchtype=author&query=Ohkawa%2C+T">Takehiko Ohkawa</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jia Pan</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+Y">Yoichi Sato</a>, 
<a href="/search/cs?searchtype=author&query=Komura%2C+T">Taku Komura</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a novel framework that concurrently tackles hand action
recognition and 3D future hand motion prediction. While previous works focus on
either recognition or prediction, we propose a generative Transformer VAE
architecture to jointly capture both aspects, facilitating realistic motion
prediction by leveraging the short-term hand motion and long-term action
consistency observed across timestamps.To ensure faithful representation of the
semantic dependency and different temporal granularity of hand pose and action,
our framework is decomposed into two cascaded VAE blocks. The lower pose block
models short-span poses, while the upper action block models long-span action.
These are connected by a mid-level feature that represents sub-second series of
hand poses.Our framework is trained across multiple datasets, where pose and
action blocks are trained separately to fully utilize pose-action annotations
of different qualities. Evaluations show that on multiple datasets, the joint
modeling of recognition and prediction improves over separate solutions, and
the semantic and temporal hierarchy enables long-term pose and action modeling.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17368" title="Abstract">arXiv:2311.17368</a> [<a href="/pdf/2311.17368" title="Download PDF">pdf</a>, <a href="/format/2311.17368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two Scalable Approaches for Burned-Area Mapping Using U-Net and Landsat  Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mancilla-Wulff%2C+I">Ian Mancilla-Wulff</a>, 
<a href="/search/cs?searchtype=author&query=Carrasco%2C+J">Jaime Carrasco</a>, 
<a href="/search/cs?searchtype=author&query=Pais%2C+C">Cristobal Pais</a>, 
<a href="/search/cs?searchtype=author&query=Miranda%2C+A">Alejandro Miranda</a>, 
<a href="/search/cs?searchtype=author&query=Weintraub%2C+A">Andres Weintraub</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Monitoring wildfires is an essential step in minimizing their impact on the
planet, understanding the many negative environmental, economic, and social
consequences. Recent advances in remote sensing technology combined with the
increasing application of artificial intelligence methods have improved
real-time, high-resolution fire monitoring. This study explores two proposed
approaches based on the U-Net model for automating and optimizing the
burned-area mapping process. Denoted 128 and AllSizes (AS), they are trained on
datasets with a different class balance by cropping input images to different
sizes. They are then applied to Landsat imagery and time-series data from two
fire-prone regions in Chile. The results obtained after enhancement of model
performance by hyperparameter optimization demonstrate the effectiveness of
both approaches. Tests based on 195 representative images of the study area
show that increasing dataset balance using the AS model yields better
performance. More specifically, AS exhibited a Dice Coefficient (DC) of 0.93,
an Omission Error (OE) of 0.086, and a Commission Error (CE) of 0.045, while
the 128 model achieved a DC of 0.86, an OE of 0.12, and a CE of 0.12. These
findings should provide a basis for further development of scalable automatic
burned-area mapping tools.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17370" title="Abstract">arXiv:2311.17370</a> [<a href="/pdf/2311.17370" title="Download PDF">pdf</a>, <a href="/format/2311.17370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient and Scalable Architecture for Multiple-chip Implementation of  Simulated Bifurcation Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kashimata%2C+T">Tomoya Kashimata</a>, 
<a href="/search/cs?searchtype=author&query=Yamasaki%2C+M">Masaya Yamasaki</a>, 
<a href="/search/cs?searchtype=author&query=Hidaka%2C+R">Ryo Hidaka</a>, 
<a href="/search/cs?searchtype=author&query=Tatsumura%2C+K">Kosuke Tatsumura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Hardware Architecture (cs.AR); Distributed, Parallel, and Cluster Computing (cs.DC); Performance (cs.PF)

</div>
<p class="mathjax">Ising machines are specialized computers for finding the lowest energy states
of Ising spin models, onto which many practical combinatorial optimization
problems can be mapped. Simulated bifurcation (SB) is a quantum-inspired
parallelizable algorithm for Ising problems that enables scalable multi-chip
implementations of Ising machines. However, the computational performance of a
previously proposed multi-chip architecture tends to saturate as the number of
chips increases for a given problem size because both computation and
communication are exclusive in the time domain. In this paper, we propose a
streaming architecture for multi-chip implementations of SB-based Ising
machines with full spin-to-spin connectivity. The data flow in in-chip
computation is harmonized with the data flow in inter-chip communication,
enabling the computation and communication to overlap and the communication
time to be hidden. Systematic experiments demonstrate linear strong scaling of
performance up to the vicinity of the ideal communication limit determined only
by the latency of chip-to-chip communication. Our eight-FPGA
(field-programmable gate array) cluster can compute a 32,768-spin problem with
a high pipeline efficiency of 97.9%. The performance of a 79-FPGA cluster for a
100,000-spin problem, projected using a theoretical performance model validated
on smaller experimental clusters, is comparable to that of a state-of-the-art
100,000-spin optical Ising machine.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17371" title="Abstract">arXiv:2311.17371</a> [<a href="/pdf/2311.17371" title="Download PDF">pdf</a>, <a href="/format/2311.17371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are we going MAD? Benchmarking Multi-Agent Debate between Language  Models for Medical Q&amp;A
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Smit%2C+A">Andries Smit</a>, 
<a href="/search/cs?searchtype=author&query=Duckworth%2C+P">Paul Duckworth</a>, 
<a href="/search/cs?searchtype=author&query=Grinsztajn%2C+N">Nathan Grinsztajn</a>, 
<a href="/search/cs?searchtype=author&query=Tessera%2C+K">Kale-ab Tessera</a>, 
<a href="/search/cs?searchtype=author&query=Barrett%2C+T+D">Thomas D. Barrett</a>, 
<a href="/search/cs?searchtype=author&query=Pretorius%2C+A">Arnu Pretorius</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures, NeurIPS DGM4H Workshop 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent advancements in large language models (LLMs) underscore their
potential for responding to medical inquiries. However, ensuring that
generative agents provide accurate and reliable answers remains an ongoing
challenge. In this context, multi-agent debate (MAD) has emerged as a prominent
strategy for enhancing the truthfulness of LLMs. In this work, we provide a
comprehensive benchmark of MAD strategies for medical Q&amp;A, along with
open-source implementations. This explores the effective utilization of various
strategies including the trade-offs between cost, time, and accuracy. We build
upon these insights to provide a novel debate-prompting strategy based on agent
agreement that outperforms previously published strategies on medical Q&amp;A
tasks.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17373" title="Abstract">arXiv:2311.17373</a> [<a href="/pdf/2311.17373" title="Download PDF">pdf</a>, <a href="/format/2311.17373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Devil is in the Data: Learning Fair Graph Neural Networks via  Partial Knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuchang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jintang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zibin Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WSDM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graph neural networks (GNNs) are being increasingly used in many high-stakes
tasks, and as a result, there is growing attention on their fairness recently.
GNNs have been shown to be unfair as they tend to make discriminatory decisions
toward certain demographic groups, divided by sensitive attributes such as
gender and race. While recent works have been devoted to improving their
fairness performance, they often require accessible demographic information.
This greatly limits their applicability in real-world scenarios due to legal
restrictions. To address this problem, we present a demographic-agnostic method
to learn fair GNNs via knowledge distillation, namely FairGKD. Our work is
motivated by the empirical observation that training GNNs on partial data
(i.e., only node attributes or topology data) can improve their fairness,
albeit at the cost of utility. To make a balanced trade-off between fairness
and utility performance, we employ a set of fairness experts (i.e., GNNs
trained on different partial data) to construct the synthetic teacher, which
distills fairer and informative knowledge to guide the learning of the GNN
student. Experiments on several benchmark datasets demonstrate that FairGKD,
which does not require access to demographic information, significantly
improves the fairness of GNNs by a large margin while maintaining their
utility.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17374" title="Abstract">arXiv:2311.17374</a> [<a href="/pdf/2311.17374" title="Download PDF">pdf</a>, <a href="/format/2311.17374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attribute Simulation for Item Embedding Enhancement in Multi-interest  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yaokun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaowang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+M">Minghui Zou</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhiyong Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by the 17th ACM International Conference on Web Search and Data Mining (WSDM 2024). The camera-ready version will be available in the conference proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Although multi-interest recommenders have achieved significant progress in
the matching stage, our research reveals that existing models tend to exhibit
an under-clustered item embedding space, which leads to a low discernibility
between items and hampers item retrieval. This highlights the necessity for
item embedding enhancement. However, item attributes, which serve as effective
and straightforward side information for enhancement, are either unavailable or
incomplete in many public datasets due to the labor-intensive nature of manual
annotation tasks. This dilemma raises two meaningful questions: 1. Can we
bypass manual annotation and directly simulate complete attribute information
from the interaction data? And 2. If feasible, how to simulate attributes with
high accuracy and low complexity in the matching stage?
<br />In this paper, we first establish an inspiring theoretical feasibility that
the item-attribute correlation matrix can be approximated through elementary
transformations on the item co-occurrence matrix. Then based on formula
derivation, we propose a simple yet effective module, SimEmb (Item Embedding
Enhancement via Simulated Attribute), in the multi-interest recommendation of
the matching stage to implement our findings. By simulating attributes with the
co-occurrence matrix, SimEmb discards the item ID-based embedding and employs
the attribute-weighted summation for item embedding enhancement. Comprehensive
experiments on four benchmark datasets demonstrate that our approach notably
enhances the clustering of item embedding and significantly outperforms SOTA
models with an average improvement of 25.59% on Recall@20.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17376" title="Abstract">arXiv:2311.17376</a> [<a href="/pdf/2311.17376" title="Download PDF">pdf</a>, <a href="/format/2311.17376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CESAR: Automatic Induction of Compositional Instructions for Multi-turn  Dialogs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aksu%2C+T">Taha Aksu</a>, 
<a href="/search/cs?searchtype=author&query=Hazarika%2C+D">Devamanyu Hazarika</a>, 
<a href="/search/cs?searchtype=author&query=Mehri%2C+S">Shikib Mehri</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seokhwan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hakkani-T%C3%BCr%2C+D">Dilek Hakkani-T&#xfc;r</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Namazifar%2C+M">Mahdi Namazifar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Instruction-based multitasking has played a critical role in the success of
large language models (LLMs) in multi-turn dialog applications. While publicly
available LLMs have shown promising performance, when exposed to complex
instructions with multiple constraints, they lag against state-of-the-art
models like ChatGPT. In this work, we hypothesize that the availability of
large-scale complex demonstrations is crucial in bridging this gap. Focusing on
dialog applications, we propose a novel framework, CESAR, that unifies a large
number of dialog tasks in the same format and allows programmatic induction of
complex instructions without any manual effort.
<br />We apply CESAR on InstructDial, a benchmark for instruction-based dialog
tasks. We further enhance InstructDial with new datasets and tasks and utilize
CESAR to induce complex tasks with compositional instructions. This results in
a new benchmark called InstructDial++, which includes 63 datasets with 86 basic
tasks and 68 composite tasks. Through rigorous experiments, we demonstrate the
scalability of CESAR in providing rich instructions. Models trained on
InstructDial++ can follow compositional prompts, such as prompts that ask for
multiple stylistic constraints.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17389" title="Abstract">arXiv:2311.17389</a> [<a href="/pdf/2311.17389" title="Download PDF">pdf</a>, <a href="/format/2311.17389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 360Loc: A Dataset and Benchmark for Omnidirectional Visual Localization  with Cross-device Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huajian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Changkun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yipeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hui Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Braud%2C+T">Tristan Braud</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+S">Sai-Kit Yeung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Portable 360$^\circ$ cameras are becoming a cheap and efficient tool to
establish large visual databases. By capturing omnidirectional views of a
scene, these cameras could expedite building environment models that are
essential for visual localization. However, such an advantage is often
overlooked due to the lack of valuable datasets. This paper introduces a new
benchmark dataset, 360Loc, composed of 360$^\circ$ images with ground truth
poses for visual localization. We present a practical implementation of
360$^\circ$ mapping combining 360$^\circ$ images with lidar data to generate
the ground truth 6DoF poses. 360Loc is the first dataset and benchmark that
explores the challenge of cross-device visual positioning, involving
360$^\circ$ reference frames, and query frames from pinhole, ultra-wide FoV
fisheye, and 360$^\circ$ cameras. We propose a virtual camera approach to
generate lower-FoV query frames from 360$^\circ$ images, which ensures a fair
comparison of performance among different query types in visual localization
tasks. We also extend this virtual camera approach to feature matching-based
and pose regression-based methods to alleviate the performance loss caused by
the cross-device domain gap, and evaluate its effectiveness against
state-of-the-art baselines. We demonstrate that omnidirectional visual
localization is more robust in challenging large-scale scenes with symmetries
and repetitive structures. These results provide new insights into 360-camera
mapping and omnidirectional visual localization with cross-device queries.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17391" title="Abstract">arXiv:2311.17391</a> [<a href="/pdf/2311.17391" title="Download PDF">pdf</a>, <a href="/format/2311.17391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling the Implicit Toxicity in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Jiaxin Wen</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+P">Pei Ke</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhexin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengfei Li</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jinfeng Bai</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Minlie Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 Main Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The open-endedness of large language models (LLMs) combined with their
impressive capabilities may lead to new safety issues when being exploited for
malicious use. While recent studies primarily focus on probing toxic outputs
that can be easily detected with existing toxicity classifiers, we show that
LLMs can generate diverse implicit toxic outputs that are exceptionally
difficult to detect via simply zero-shot prompting. Moreover, we propose a
reinforcement learning (RL) based attacking method to further induce the
implicit toxicity in LLMs. Specifically, we optimize the language model with a
reward that prefers implicit toxic outputs to explicit toxic and non-toxic
ones. Experiments on five widely-adopted toxicity classifiers demonstrate that
the attack success rate can be significantly improved through RL fine-tuning.
For instance, the RL-finetuned LLaMA-13B model achieves an attack success rate
of 90.04% on BAD and 62.85% on Davinci003. Our findings suggest that LLMs pose
a significant threat in generating undetectable implicit toxic outputs. We
further show that fine-tuning toxicity classifiers on the annotated examples
from our attacking method can effectively enhance their ability to detect
LLM-generated implicit toxic language. The code is publicly available at
https://github.com/thu-coai/Implicit-Toxicity.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17392" title="Abstract">arXiv:2311.17392</a> [<a href="/pdf/2311.17392" title="Download PDF">pdf</a>, <a href="/format/2311.17392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Internet-wide Penetration Study on NAT Boxes via TCP/IP Side Channel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xuan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haining Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Network Address Translation (NAT) plays an essential role in shielding
devices inside an internal local area network from direct malicious accesses
from the public Internet. However, recent studies show the possibilities of
penetrating NAT boxes in some specific circumstances. The penetrated NAT box
can be exploited by attackers as a pivot to abuse the otherwise inaccessible
internal network resources, leading to serious security consequences. In this
paper, we aim to conduct an Internet-wide penetration testing on NAT boxes. The
main difference between our study and the previous ones is that ours is based
on the TCP/IP side channels. We explore the TCP/IP side channels in the
research literature, and find that the shared-IPID side channel is the most
suitable for NAT-penetration testing, as it satisfies the three requirements of
our study: generality, ethics, and robustness. Based on this side channel, we
develop an adaptive scanner that can accomplish the Internet-wide scanning in 5
days in a very non-aggressive manner. The evaluation shows that our scanner is
effective in both the controlled network and the real network. Our measurement
results reveal that more than 30,000 network middleboxes are potentially
vulnerable to NAT penetration. They are distributed across 154 countries and
4,146 different organizations, showing that NAT-penetration poses a serious
security threat.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17393" title="Abstract">arXiv:2311.17393</a> [<a href="/pdf/2311.17393" title="Download PDF">pdf</a>, <a href="/format/2311.17393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparison of metaheuristics for the firebreak placement problem: a  simulation-based optimization approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Palacios-Meneses%2C+D">David Palacios-Meneses</a>, 
<a href="/search/cs?searchtype=author&query=Carrasco%2C+J">Jaime Carrasco</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%A1vila%2C+S">Sebasti&#xe1;n D&#xe1;vila</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez%2C+M">Maximiliano Mart&#xed;nez</a>, 
<a href="/search/cs?searchtype=author&query=Mahaluf%2C+R">Rodrigo Mahaluf</a>, 
<a href="/search/cs?searchtype=author&query=Weintraub%2C+A">Andr&#xe9;s Weintraub</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The problem of firebreak placement is crucial for fire prevention, and its
effectiveness at landscape scale will depend on their ability to impede the
progress of future wildfires. To provide an adequate response, it is therefore
necessary to consider the stochastic nature of fires, which are highly
unpredictable from ignition to extinction. Thus, the placement of firebreaks
can be considered a stochastic optimization problem where: (1) the objective
function is to minimize the expected cells burnt of the landscape; (2) the
decision variables being the location of firebreaks; and (3) the random
variable being the spatial propagation/behavior of fires. In this paper, we
propose a solution approach for the problem from the perspective of
simulation-based optimization (SbO), where the objective function is not
available (a black-box function), but can be computed (and/or approximated) by
wildfire simulations. For this purpose, Genetic Algorithm and GRASP are
implemented. The final implementation yielded favorable results for the Genetic
Algorithm, demonstrating strong performance in scenarios with medium to high
operational capacity, as well as medium levels of stochasticity
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17394" title="Abstract">arXiv:2311.17394</a> [<a href="/pdf/2311.17394" title="Download PDF">pdf</a>, <a href="/ps/2311.17394" title="Download PostScript">ps</a>, <a href="/format/2311.17394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deepfakes, Misinformation, and Disinformation in the Era of Frontier AI,  Generative AI, and Large AI Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shoaib%2C+M+R">Mohamed R. Shoaib</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zefan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ahvanooey%2C+M+T">Milad Taleby Ahvanooey</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper appears in IEEE International Conference on Computer and Applications (ICCA) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">With the advent of sophisticated artificial intelligence (AI) technologies,
the proliferation of deepfakes and the spread of m/disinformation have emerged
as formidable threats to the integrity of information ecosystems worldwide.
This paper provides an overview of the current literature. Within the frontier
AI's crucial application in developing defense mechanisms for detecting
deepfakes, we highlight the mechanisms through which generative AI based on
large models (LM-based GenAI) craft seemingly convincing yet fabricated
contents. We explore the multifaceted implications of LM-based GenAI on
society, politics, and individual privacy violations, underscoring the urgent
need for robust defense strategies. To address these challenges, in this study,
we introduce an integrated framework that combines advanced detection
algorithms, cross-platform collaboration, and policy-driven initiatives to
mitigate the risks associated with AI-Generated Content (AIGC). By leveraging
multi-modal analysis, digital watermarking, and machine learning-based
authentication techniques, we propose a defense mechanism adaptable to AI
capabilities of ever-evolving nature. Furthermore, the paper advocates for a
global consensus on the ethical usage of GenAI and implementing cyber-wellness
educational programs to enhance public awareness and resilience against
m/disinformation. Our findings suggest that a proactive and collaborative
approach involving technological innovation and regulatory oversight is
essential for safeguarding netizens while interacting with cyberspace against
the insidious effects of deepfakes and GenAI-enabled m/disinformation
campaigns.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17396" title="Abstract">arXiv:2311.17396</a> [<a href="/pdf/2311.17396" title="Download PDF">pdf</a>, <a href="/format/2311.17396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral and Polarization Vision: Spectro-polarimetric Real-world  Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeon%2C+Y">Yujin Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+E">Eunsue Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Youngchan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+Y">Yunseong Moon</a>, 
<a href="/search/cs?searchtype=author&query=Omer%2C+K">Khalid Omer</a>, 
<a href="/search/cs?searchtype=author&query=Heide%2C+F">Felix Heide</a>, 
<a href="/search/cs?searchtype=author&query=Baek%2C+S">Seung-Hwan Baek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Image datasets are essential not only in validating existing methods in
computer vision but also in developing new methods. Most existing image
datasets focus on trichromatic intensity images to mimic human vision. However,
polarization and spectrum, the wave properties of light that animals in harsh
environments and with limited brain capacity often rely on, remain
underrepresented in existing datasets. Although spectro-polarimetric datasets
exist, these datasets have insufficient object diversity, limited illumination
conditions, linear-only polarization data, and inadequate image count. Here, we
introduce two spectro-polarimetric datasets: trichromatic Stokes images and
hyperspectral Stokes images. These novel datasets encompass both linear and
circular polarization; they introduce multiple spectral channels; and they
feature a broad selection of real-world scenes. With our dataset in hand, we
analyze the spectro-polarimetric image statistics, develop efficient
representations of such high-dimensional data, and evaluate spectral dependency
of shape-from-polarization methods. As such, the proposed dataset promises a
foundation for data-driven spectro-polarimetric imaging and vision research.
Dataset and code will be publicly available.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17400" title="Abstract">arXiv:2311.17400</a> [<a href="/pdf/2311.17400" title="Download PDF">pdf</a>, <a href="/format/2311.17400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the Robustness of Transformer-based Large Language Models with  Dynamic Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Lujia Shen</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+Y">Yuwen Pu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shouling Ji</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changjiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+C">Chunpeng Ge</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Ting Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Transformer-based models, such as BERT and GPT, have been widely adopted in
natural language processing (NLP) due to their exceptional performance.
However, recent studies show their vulnerability to textual adversarial attacks
where the model's output can be misled by intentionally manipulating the text
inputs. Despite various methods that have been proposed to enhance the model's
robustness and mitigate this vulnerability, many require heavy consumption
resources (e.g., adversarial training) or only provide limited protection
(e.g., defensive dropout). In this paper, we propose a novel method called
dynamic attention, tailored for the transformer architecture, to enhance the
inherent robustness of the model itself against various adversarial attacks.
Our method requires no downstream task knowledge and does not incur additional
costs. The proposed dynamic attention consists of two modules: (I) attention
rectification, which masks or weakens the attention value of the chosen tokens,
and (ii) dynamic modeling, which dynamically builds the set of candidate
tokens. Extensive experiments demonstrate that dynamic attention significantly
mitigates the impact of adversarial attacks, improving up to 33\% better
performance than previous methods against widely-used adversarial attacks. The
model-level design of dynamic attention enables it to be easily combined with
other defense methods (e.g., adversarial training) to further enhance the
model's robustness. Furthermore, we demonstrate that dynamic attention
preserves the state-of-the-art robustness space of the original model compared
to other dynamic modeling methods.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17401" title="Abstract">arXiv:2311.17401</a> [<a href="/pdf/2311.17401" title="Download PDF">pdf</a>, <a href="/format/2311.17401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gene-MOE: A Sparsely-gated Framework for Pan-Cancer Genomic Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+X">Xiangyu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+T">Tao Song</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Huanhuan Dai</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+L">Lian Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Hongzhen Ding</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+L">Long Hao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xun Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submit to bioinformatics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Analyzing the genomic information from the Pan-Cancer database can help us
understand cancer-related factors and contribute to the cancer diagnosis and
prognosis. However, existing computational methods and deep learning methods
can not effectively find the deep correlations between tens of thousands of
genes, which leads to precision loss. In this paper, we proposed a novel
pretrained model called Gene-MOE to learn the general feature representations
of the Pan-Cancer dataset and transfer the pretrained weights to the downstream
tasks. The Gene-MOE fully exploits the mixture of expert (MOE) layers to learn
rich feature representations of high-dimensional genes. At the same time, we
build a mixture of attention expert (MOAE) model to learn the deep semantic
relationships within genetic features. Finally, we proposed a new
self-supervised pretraining strategy including loss function design, data
enhancement, and optimization strategy to train the Gene-MOE and further
improve the performance for the downstream analysis. We carried out cancer
classification and survival analysis experiments based on the Gene-MOE.
According to the survival analysis results on 14 cancer types, using Gene-MOE
outperformed state-of-the-art models on 12 cancer types. According to the
classification results, the total accuracy of the classification model for 33
cancer classifications reached 95.2\%. Through detailed feature analysis, we
found the Gene-MOE model can learn rich feature representations of
high-dimensional genes.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17404" title="Abstract">arXiv:2311.17404</a> [<a href="/pdf/2311.17404" title="Download PDF">pdf</a>, <a href="/format/2311.17404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VITATECS: A Diagnostic Dataset for Temporal Concept Understanding of  Video-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shicheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Shuhuai Ren</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Rundong Gao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Lu Hou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 6 figures, 18 tables, data is available at <a href="https://github.com/lscpku/VITATECS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">The ability to perceive how objects change over time is a crucial ingredient
in human intelligence. However, current benchmarks cannot faithfully reflect
the temporal understanding abilities of video-language models (VidLMs) due to
the existence of static visual shortcuts. To remedy this issue, we present
VITATECS, a diagnostic VIdeo-Text dAtaset for the evaluation of TEmporal
Concept underStanding. Specifically, we first introduce a fine-grained taxonomy
of temporal concepts in natural language in order to diagnose the capability of
VidLMs to comprehend different temporal aspects. Furthermore, to disentangle
the correlation between static and temporal information, we generate
counterfactual video descriptions that differ from the original one only in the
specified temporal aspect. We employ a semi-automatic data collection framework
using large language models and human-in-the-loop annotation to obtain
high-quality counterfactual descriptions efficiently. Evaluation of
representative video-language understanding models confirms their deficiency in
temporal understanding, revealing the need for greater emphasis on the temporal
elements in video-language research.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17405" title="Abstract">arXiv:2311.17405</a> [<a href="/pdf/2311.17405" title="Download PDF">pdf</a>, <a href="/format/2311.17405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning and Autonomy for Extraterrestrial Terrain Sampling: An  Experience Report from OWLAT Deployment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thangeda%2C+P">Pranay Thangeda</a>, 
<a href="/search/cs?searchtype=author&query=Goel%2C+A">Ashish Goel</a>, 
<a href="/search/cs?searchtype=author&query=Tevere%2C+E">Erica Tevere</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yifan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Kramer%2C+E">Erik Kramer</a>, 
<a href="/search/cs?searchtype=author&query=Daca%2C+A">Adriana Daca</a>, 
<a href="/search/cs?searchtype=author&query=Nayar%2C+H">Hari Nayar</a>, 
<a href="/search/cs?searchtype=author&query=Hauser%2C+K">Kris Hauser</a>, 
<a href="/search/cs?searchtype=author&query=Ornik%2C+M">Melkior Ornik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Extraterrestrial autonomous lander missions increasingly demand adaptive
capabilities to handle the unpredictable and diverse nature of the terrain.
This paper discusses the deployment of a Deep Meta-Learning with Controlled
Deployment Gaps (CoDeGa) trained model for terrain scooping tasks in Ocean
Worlds Lander Autonomy Testbed (OWLAT) at NASA Jet Propulsion Laboratory. The
CoDeGa-powered scooping strategy is designed to adapt to novel terrains,
selecting scooping actions based on the available RGB-D image data and limited
experience. The paper presents our experiences with transferring the scooping
framework with CoDeGa-trained model from a low-fidelity testbed to the
high-fidelity OWLAT testbed. Additionally, it validates the method's
performance in novel, realistic environments, and shares the lessons learned
from deploying learning-based autonomy algorithms for space exploration.
Experimental results from OWLAT substantiate the efficacy of CoDeGa in rapidly
adapting to unfamiliar terrains and effectively making autonomous decisions
under considerable domain shifts, thereby endorsing its potential utility in
future extraterrestrial missions.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17406" title="Abstract">arXiv:2311.17406</a> [<a href="/pdf/2311.17406" title="Download PDF">pdf</a>, <a href="/format/2311.17406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-State: Expandable State Representation for Long-horizon Task  Planning in the Open World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+A">Anxing Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+D">David Hsu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This work addresses the problem of long-horizon task planning with the Large
Language Model (LLM) in an open-world household environment. Existing works
fail to explicitly track key objects and attributes, leading to erroneous
decisions in long-horizon tasks, or rely on highly engineered state features
and feedback, which is not generalizable. We propose a novel, expandable state
representation that provides continuous expansion and updating of object
attributes from the LLM's inherent capabilities for context understanding and
historical action reasoning. Our proposed representation maintains a
comprehensive record of an object's attributes and changes, enabling robust
retrospective summary of the sequence of actions leading to the current state.
This allows enhanced context understanding for decision-making in task
planning. We validate our model through experiments across simulated and
real-world task planning scenarios, demonstrating significant improvements over
baseline methods in a variety of tasks requiring long-horizon state tracking
and reasoning.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17408" title="Abstract">arXiv:2311.17408</a> [<a href="/pdf/2311.17408" title="Download PDF">pdf</a>, <a href="/format/2311.17408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Dense Graph Convolutional Network for Skeleton-based Human  Motion Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinshun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wanying Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Can Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mengyuan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Graph Convolutional Networks (GCN) which typically follows a neural message
passing framework to model dependencies among skeletal joints has achieved high
success in skeleton-based human motion prediction task. Nevertheless, how to
construct a graph from a skeleton sequence and how to perform message passing
on the graph are still open problems, which severely affect the performance of
GCN. To solve both problems, this paper presents a Dynamic Dense Graph
Convolutional Network (DD-GCN), which constructs a dense graph and implements
an integrated dynamic message passing. More specifically, we construct a dense
graph with 4D adjacency modeling as a comprehensive representation of motion
sequence at different levels of abstraction. Based on the dense graph, we
propose a dynamic message passing framework that learns dynamically from data
to generate distinctive messages reflecting sample-specific relevance among
nodes in the graph. Extensive experiments on benchmark Human 3.6M and CMU Mocap
datasets verify the effectiveness of our DD-GCN which obviously outperforms
state-of-the-art GCN-based methods, especially when using long-term and our
proposed extremely long-term protocol.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17409" title="Abstract">arXiv:2311.17409</a> [<a href="/pdf/2311.17409" title="Download PDF">pdf</a>, <a href="/format/2311.17409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Talking Head(?) Anime from a Single Image 4: Improved Model and Its  Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khungurn%2C+P">Pramook Khungurn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We study the problem of creating a character model that can be controlled in
real time from a single image of an anime character. A solution to this problem
would greatly reduce the cost of creating avatars, computer games, and other
interactive applications.
<br />Talking Head Anime 3 (THA3) is an open source project that attempts to
directly addresses the problem. It takes as input (1) an image of an anime
character's upper body and (2) a 45-dimensional pose vector and outputs a new
image of the same character taking the specified pose. The range of possible
movements is expressive enough for personal avatars and certain types of game
characters. However, the system is too slow to generate animations in real time
on common PCs, and its image quality can be improved.
<br />In this paper, we improve THA3 in two ways. First, we propose new
architectures for constituent networks that rotate the character's head and
body based on U-Nets with attention that are widely used in modern generative
models. The new architectures consistently yield better image quality than the
THA3 baseline. Nevertheless, they also make the whole system much slower: it
takes up to 150 milliseconds to generate a frame. Second, we propose a
technique to distill the system into a small network (less than 2 MB) that can
generate 512x512 animation frames in real time (under 30 FPS) using consumer
gaming GPUs while keeping the image quality close to that of the full system.
This improvement makes the whole system practical for real-time applications.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17410" title="Abstract">arXiv:2311.17410</a> [<a href="/pdf/2311.17410" title="Download PDF">pdf</a>, <a href="/format/2311.17410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GNNFlow: A Distributed Framework for Continuous Temporal GNN Learning on  Dynamic Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yuchen Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+G">Guangming Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+T">Tianzuo Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Minjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Q">Quan Gan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chuan Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Graph Neural Networks (GNNs) play a crucial role in various fields. However,
most existing deep graph learning frameworks assume pre-stored static graphs
and do not support training on graph streams. In contrast, many real-world
graphs are dynamic and contain time domain information. We introduce GNNFlow, a
distributed framework that enables efficient continuous temporal graph
representation learning on dynamic graphs on multi-GPU machines. GNNFlow
introduces an adaptive time-indexed block-based data structure that effectively
balances memory usage with graph update and sampling operation efficiency. It
features a hybrid GPU-CPU graph data placement for rapid GPU-based temporal
neighborhood sampling and kernel optimizations for enhanced sampling processes.
A dynamic GPU cache for node and edge features is developed to maximize cache
hit rates through reuse and restoration strategies. GNNFlow supports
distributed training across multiple machines with static scheduling to ensure
load balance. We implement GNNFlow based on DGL and PyTorch. Our experimental
results show that GNNFlow provides up to 21.1x faster continuous learning than
existing systems.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17425" title="Abstract">arXiv:2311.17425</a> [<a href="/pdf/2311.17425" title="Download PDF">pdf</a>, <a href="/format/2311.17425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpeechAct: Towards Generating Whole-body Motion from Speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinsong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Minjie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuxiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yebin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kun Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="http://cic.tju.edu.cn/faculty/likun/projects/SpeechAct">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper addresses the problem of generating whole-body motion from speech.
Despite great successes, prior methods still struggle to produce reasonable and
diverse whole-body motions from speech. This is due to their reliance on
suboptimal representations and a lack of strategies for generating diverse
results. To address these challenges, we present a novel hybrid point
representation to achieve accurate and continuous motion generation, e.g.,
avoiding foot skating, and this representation can be transformed into an
easy-to-use representation, i.e., SMPL-X body mesh, for many applications. To
generate whole-body motion from speech, for facial motion, closely tied to the
audio signal, we introduce an encoder-decoder architecture to achieve
deterministic outcomes. However, for the body and hands, which have weaker
connections to the audio signal, we aim to generate diverse yet reasonable
motions. To boost diversity in motion generation, we propose a contrastive
motion learning method to encourage the model to produce more distinctive
representations. Specifically, we design a robust VQ-VAE to learn a quantized
motion codebook using our hybrid representation. Then, we regress the motion
representation from the audio signal by a translation model employing our
contrastive motion learning method. Experimental results validate the superior
performance and the correctness of our model. The project page is available for
research purposes at <a href="http://cic.tju.edu.cn/faculty/likun/projects/SpeechAct.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17428" title="Abstract">arXiv:2311.17428</a> [<a href="/pdf/2311.17428" title="Download PDF">pdf</a>, <a href="/format/2311.17428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SigFormer: Sparse Signal-Guided Transformer for Multi-Modal Human Action  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinchen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+X">Xiaoyan Gu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wu Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multi-modal human action segmentation is a critical and challenging task with
a wide range of applications. Nowadays, the majority of approaches concentrate
on the fusion of dense signals (i.e., RGB, optical flow, and depth maps).
However, the potential contributions of sparse IoT sensor signals, which can be
crucial for achieving accurate recognition, have not been fully explored. To
make up for this, we introduce a Sparse signalguided Transformer (SigFormer) to
combine both dense and sparse signals. We employ mask attention to fuse
localized features by constraining cross-attention within the regions where
sparse signals are valid. However, since sparse signals are discrete, they lack
sufficient information about the temporal action boundaries. Therefore, in
SigFormer, we propose to emphasize the boundary information at two stages to
alleviate this problem. In the first feature extraction stage, we introduce an
intermediate bottleneck module to jointly learn both category and boundary
features of each dense modality through the inner loss functions. After the
fusion of dense modalities and sparse signals, we then devise a two-branch
architecture that explicitly models the interrelationship between action
category and temporal boundary. Experimental results demonstrate that SigFormer
outperforms the state-of-the-art approaches on a multi-modal action
segmentation dataset from real industrial environments, reaching an outstanding
F1 score of 0.958. The codes and pre-trained models have been available at
https://github.com/LIUQI-creat/SigFormer.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17429" title="Abstract">arXiv:2311.17429</a> [<a href="/pdf/2311.17429" title="Download PDF">pdf</a>, <a href="/ps/2311.17429" title="Download PostScript">ps</a>, <a href="/format/2311.17429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TARGET: Template-Transferable Backdoor Attack Against Prompt-based NLP  Models via GPT4
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zihao Tan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qingliang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yongjian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+C">Chen Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Prompt-based learning has been widely applied in many low-resource NLP tasks
such as few-shot scenarios. However, this paradigm has been shown to be
vulnerable to backdoor attacks. Most of the existing attack methods focus on
inserting manually predefined templates as triggers in the pre-training phase
to train the victim model and utilize the same triggers in the downstream task
to perform inference, which tends to ignore the transferability and
stealthiness of the templates. In this work, we propose a novel approach of
TARGET (Template-trAnsfeRable backdoor attack aGainst prompt-basEd NLP models
via GPT4), which is a data-independent attack method. Specifically, we first
utilize GPT4 to reformulate manual templates to generate tone-strong and normal
templates, and the former are injected into the model as a backdoor trigger in
the pre-training phase. Then, we not only directly employ the above templates
in the downstream task, but also use GPT4 to generate templates with similar
tone to the above templates to carry out transferable attacks. Finally we have
conducted extensive experiments on five NLP datasets and three BERT series
models, with experimental results justifying that our TARGET method has better
attack performance and stealthiness compared to the two-external baseline
methods on direct attacks, and in addition achieves satisfactory attack
capability in the unseen tone-similar templates.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17431" title="Abstract">arXiv:2311.17431</a> [<a href="/pdf/2311.17431" title="Download PDF">pdf</a>, <a href="/format/2311.17431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grounding Foundation Models through Federated Transfer Learning: A  General Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yan Kang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+T">Tao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hanlin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lixin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qiang Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Foundation Models (FMs) such as GPT-4 encoded with vast knowledge and
powerful emergent abilities have achieved remarkable success in various natural
language processing and computer vision tasks. Grounding FMs by adapting them
to domain-specific tasks or augmenting them with domain-specific knowledge
enables us to exploit the full potential of FMs. However, grounding FMs faces
several challenges, stemming primarily from constrained computing resources,
data privacy, model heterogeneity, and model ownership. Federated Transfer
Learning (FTL), the combination of federated learning and transfer learning,
provides promising solutions to address these challenges. In recent years, the
need for grounding FMs leveraging FTL, coined FTL-FM, has arisen strongly in
both academia and industry. Motivated by the strong growth in FTL-FM research
and the potential impact of FTL-FM on industrial applications, we propose an
FTL-FM framework that formulates problems of grounding FMs in the federated
learning setting, construct a detailed taxonomy based on the FTL-FM framework
to categorize state-of-the-art FTL-FM works, and comprehensively overview
FTL-FM works based on the proposed taxonomy. We also establish correspondences
between FTL-FM and conventional phases of adapting FM so that FM practitioners
can align their research works with FTL-FM. In addition, we overview advanced
efficiency-improving and privacy-preserving techniques because efficiency and
privacy are critical concerns in FTL-FM. Last, we discuss opportunities and
future research directions of FTL-FM.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17434" title="Abstract">arXiv:2311.17434</a> [<a href="/pdf/2311.17434" title="Download PDF">pdf</a>, <a href="/format/2311.17434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Group-wise Sparse and Explainable Adversarial Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sadiku%2C+S">Shpresim Sadiku</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+M">Moritz Wagner</a>, 
<a href="/search/cs?searchtype=author&query=Pokutta%2C+S">Sebastian Pokutta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">Sparse adversarial attacks fool deep neural networks (DNNs) through minimal
pixel perturbations, typically regularized by the $\ell_0$ norm. Recent efforts
have replaced this norm with a structural sparsity regularizer, such as the
nuclear group norm, to craft group-wise sparse adversarial attacks. The
resulting perturbations are thus explainable and hold significant practical
relevance, shedding light on an even greater vulnerability of DNNs than
previously anticipated. However, crafting such attacks poses an optimization
challenge, as it involves computing norms for groups of pixels within a
non-convex objective. In this paper, we tackle this challenge by presenting an
algorithm that simultaneously generates group-wise sparse attacks within
semantically meaningful areas of an image. In each iteration, the core
operation of our algorithm involves the optimization of a quasinorm adversarial
loss. This optimization is achieved by employing the $1/2$-quasinorm proximal
operator for some iterations, a method tailored for nonconvex programming.
Subsequently, the algorithm transitions to a projected Nesterov's accelerated
gradient descent with $2$-norm regularization applied to perturbation
magnitudes. We rigorously evaluate the efficacy of our novel attack in both
targeted and non-targeted attack scenarios, on CIFAR-10 and ImageNet datasets.
When compared to state-of-the-art methods, our attack consistently results in a
remarkable increase in group-wise sparsity, e.g., an increase of $48.12\%$ on
CIFAR-10 and $40.78\%$ on ImageNet (average case, targeted attack), all while
maintaining lower perturbation magnitudes. Notably, this performance is
complemented by a significantly faster computation time and a $100\%$ attack
success rate.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17435" title="Abstract">arXiv:2311.17435</a> [<a href="/pdf/2311.17435" title="Download PDF">pdf</a>, <a href="/format/2311.17435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MM-Narrator: Narrating Long-form Videos with Multimodal In-Context  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaoyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kevin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhengyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chung-Ching Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zicheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lijuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page at <a href="https://mm-narrator.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present MM-Narrator, a novel system leveraging GPT-4 with multimodal
in-context learning for the generation of audio descriptions (AD). Unlike
previous methods that primarily focused on downstream fine-tuning with short
video clips, MM-Narrator excels in generating precise audio descriptions for
videos of extensive lengths, even beyond hours, in an autoregressive manner.
This capability is made possible by the proposed memory-augmented generation
process, which effectively utilizes both the short-term textual context and
long-term visual memory through an efficient register-and-recall mechanism.
These contextual memories compile pertinent past information, including
storylines and character identities, ensuring an accurate tracking and
depicting of story-coherent and character-centric audio descriptions.
Maintaining the training-free design of MM-Narrator, we further propose a
complexity-based demonstration selection strategy to largely enhance its
multi-step reasoning capability via few-shot multimodal in-context learning
(MM-ICL). Experimental results on MAD-eval dataset demonstrate that MM-Narrator
consistently outperforms both the existing fine-tuning-based approaches and
LLM-based approaches in most scenarios, as measured by standard evaluation
metrics. Additionally, we introduce the first segment-based evaluator for
recurrent text generation. Empowered by GPT-4, this evaluator comprehensively
reasons and marks AD generation performance in various extendable dimensions.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17438" title="Abstract">arXiv:2311.17438</a> [<a href="/pdf/2311.17438" title="Download PDF">pdf</a>, <a href="/format/2311.17438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLOMO: Counterfactual Logical Modification with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yinya Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+R">Ruixin Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+W">Wei Shao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhicheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Changshui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaodan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Linqi Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this study, we delve into the realm of counterfactual reasoning
capabilities of large language models (LLMs). Our primary objective is to
cultivate the counterfactual thought processes within LLMs and rigorously
assess these processes for their validity. Specifically, we introduce a novel
task, Counterfactual Logical Modification (CLOMO), and a high-quality
human-annotated benchmark. In this task, LLMs must adeptly alter a given
argumentative text to uphold a predetermined logical relationship. To
effectively evaluate a generation model's counterfactual capabilities, we
propose an innovative evaluation metric, the LogicAware Counterfactual Score to
directly evaluate the natural language output of LLMs instead of modeling the
task as a multiple-choice problem. Analysis shows that the proposed automatic
metric aligns well with human preference. Our experimental results show that
while LLMs demonstrate a notable capacity for logical counterfactual thinking,
there remains a discernible gap between their current abilities and human
performance.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17440" title="Abstract">arXiv:2311.17440</a> [<a href="/pdf/2311.17440" title="Download PDF">pdf</a>, <a href="/ps/2311.17440" title="Download PostScript">ps</a>, <a href="/format/2311.17440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Violating Constant Degree Hypothesis Requires Breaking Symmetry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kawa%C5%82ek%2C+P">Piotr Kawa&#x142;ek</a>, 
<a href="/search/cs?searchtype=author&query=Wei%C3%9F%2C+A">Armin Wei&#xdf;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">The Constant Degree Hypothesis was introduced by Barrington et. al. (1990) to
study some extensions of $q$-groups by nilpotent groups and the power of these
groups in a certain computational model. In its simplest formulation, it
establishes exponential lower bounds for $\mathrm{AND}_d \circ \mathrm{MOD}_m
\circ \mathrm{MOD}_q$ circuits computing AND of unbounded arity $n$ (for
constant integers $d,m$ and a prime $q$). While it has been proved in some
special cases (including $d=1$), it remains wide open in its general form for
over 30 years.
<br />In this paper we prove that the hypothesis holds when we restrict our
attention to symmetric circuits with $m$ being a prime. While we build upon
techniques by Grolmusz and Tardos (2000), we have to prove a new symmetric
version of their Degree Decreasing Lemma and apply it in a highly non-trivial
way. Moreover, to establish the result we perform a careful analysis of
automorphism groups of $\mathrm{AND} \circ \mathrm{MOD}_m$ subcircuits and
study the periodic behaviour of the computed functions.
<br />Finally, our methods also yield lower bounds when $d$ is treated as a
function of $n$.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17441" title="Abstract">arXiv:2311.17441</a> [<a href="/pdf/2311.17441" title="Download PDF">pdf</a>, <a href="/format/2311.17441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asynchronous Merkle Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kharangate%2C+A">Anoushk Kharangate</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Merkle trees have become a widely successful cryptographic data structure.
Enabling a vast variety of applications from checking for inconsistencies in
databases like Dynamo to essential tools like Git to large scale distributed
systems like Bitcoin and other blockchains. There have also been various
versions of Merkle trees like Jellyfish Merkle Trees and Sparse Merkle Trees
designed for different applications. However, one key drawback of all these
Merkle trees is that with a large data set the cost of computing the tree
increases significantly, moreover insert operations on a single leaf require
re-building the entire tree. For certain use cases building the tree this way
is acceptable, however in environments where compute time needs to be as low as
possible and where data is processed in parallel, we are presented with a need
for asynchronous computation. This paper proposes a solution where given a
batch of data that has to be processed concurrently, a Merkle Tree can be
constructed from the batch asynchronously without needing to recalculate the
tree for every insert.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17446" title="Abstract">arXiv:2311.17446</a> [<a href="/pdf/2311.17446" title="Download PDF">pdf</a>, <a href="/format/2311.17446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty in Additive Feature Attribution methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madaan%2C+A">Abhishek Madaan</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+T">Tanya Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Rana%2C+N">Neha Rana</a>, 
<a href="/search/cs?searchtype=author&query=Allan%2C+J">James Allan</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+T">Tanmoy Chakraborty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this work, we explore various topics that fall under the umbrella of
Uncertainty in post-hoc Explainable AI (XAI) methods. We in particular focus on
the class of additive feature attribution explanation methods. We first
describe our specifications of uncertainty and compare various statistical and
recent methods to quantify the same. Next, for a particular instance, we study
the relationship between a feature's attribution and its uncertainty and
observe little correlation. As a result, we propose a modification in the
distribution from which perturbations are sampled in LIME-based algorithms such
that the important features have minimal uncertainty without an increase in
computational cost. Next, while studying how the uncertainty in explanations
varies across the feature space of a classifier, we observe that a fraction of
instances show near-zero uncertainty. We coin the term "stable instances" for
such instances and diagnose factors that make an instance stable. Next, we
study how an XAI algorithm's uncertainty varies with the size and complexity of
the underlying model. We observe that the more complex the model, the more
inherent uncertainty is exhibited by it. As a result, we propose a measure to
quantify the relative complexity of a blackbox classifier. This could be
incorporated, for example, in LIME-based algorithms' sampling densities, to
help different explanation algorithms achieve tighter confidence levels.
Together, the above measures would have a strong impact on making XAI models
relatively trustworthy for the end-user as well as aiding scientific discovery.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17447" title="Abstract">arXiv:2311.17447</a> [<a href="/pdf/2311.17447" title="Download PDF">pdf</a>, <a href="/format/2311.17447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning-driven Zero Trust in Distributed Computing Continuum Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Murturi%2C+I">Ilir Murturi</a>, 
<a href="/search/cs?searchtype=author&query=Donta%2C+P+K">Praveen Kumar Donta</a>, 
<a href="/search/cs?searchtype=author&query=Pujol%2C+V+C">Victor Casamayor Pujol</a>, 
<a href="/search/cs?searchtype=author&query=Morichetta%2C+A">Andrea Morichetta</a>, 
<a href="/search/cs?searchtype=author&query=Dustdar%2C+S">Schahram Dustdar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Converging Zero Trust (ZT) with learning techniques can solve various
operational and security challenges in Distributed Computing Continuum Systems
(DCCS). Implementing centralized ZT architecture is seen as unsuitable for the
computing continuum (e.g., computing entities with limited connectivity and
visibility, etc.). At the same time, implementing decentralized ZT in the
computing continuum requires understanding infrastructure limitations and novel
approaches to enhance resource access management decisions. To overcome such
challenges, we present a novel learning-driven ZT conceptual architecture
designed for DCCS. We aim to enhance ZT architecture service quality by
incorporating lightweight learning strategies such as Representation Learning
(ReL) and distributing ZT components across the computing continuum. The ReL
helps to improve the decision-making process by predicting threats or untrusted
requests. Through an illustrative example, we show how the learning process
detects and blocks the requests, enhances resource access control, and reduces
network and computation overheads. Lastly, we discuss the conceptual
architecture, processes, and provide a research agenda.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17449" title="Abstract">arXiv:2311.17449</a> [<a href="/pdf/2311.17449" title="Download PDF">pdf</a>, <a href="/format/2311.17449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly-semi-supervised object detection in remotely sensed imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J+H">Ji Hun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Irvin%2C+J">Jeremy Irvin</a>, 
<a href="/search/cs?searchtype=author&query=Behar%2C+B+K">Beri Kohen Behar</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+H">Ha Tran</a>, 
<a href="/search/cs?searchtype=author&query=Samavedam%2C+R">Raghav Samavedam</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+Q">Quentin Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+A+Y">Andrew Y. Ng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tackling Climate Change with Machine Learning at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep learning for detecting objects in remotely sensed imagery can enable new
technologies for important applications including mitigating climate change.
However, these models often require large datasets labeled with bounding box
annotations which are expensive to curate, prohibiting the development of
models for new tasks and geographies. To address this challenge, we develop
weakly-semi-supervised object detection (WSSOD) models on remotely sensed
imagery which can leverage a small amount of bounding boxes together with a
large amount of point labels that are easy to acquire at scale in geospatial
data. We train WSSOD models which use large amounts of point-labeled images
with varying fractions of bounding box labeled images in FAIR1M and a wind
turbine detection dataset, and demonstrate that they substantially outperform
fully supervised models trained with the same amount of bounding box labeled
images on both datasets. Furthermore, we find that the WSSOD models trained
with 2-10x fewer bounding box labeled images can perform similarly to or
outperform fully supervised models trained on the full set of bounding-box
labeled images. We believe that the approach can be extended to other remote
sensing tasks to reduce reliance on bounding box labels and increase
development of models for impactful applications.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17450" title="Abstract">arXiv:2311.17450</a> [<a href="/pdf/2311.17450" title="Download PDF">pdf</a>, <a href="/format/2311.17450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Learning for Image Segmentation with Dynamic Query
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Weijia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuzhong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+L">Lianlei Shan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/weijiawu/CisDQ">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> TCSVT 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image segmentation based on continual learning exhibits a critical drop of
performance, mainly due to catastrophic forgetting and background shift, as
they are required to incorporate new classes continually. In this paper, we
propose a simple, yet effective Continual Image Segmentation method with
incremental Dynamic Query (CISDQ), which decouples the representation learning
of both old and new knowledge with lightweight query embedding. CISDQ mainly
includes three contributions: 1) We define dynamic queries with adaptive
background class to exploit past knowledge and learn future classes naturally.
2) CISDQ proposes a class/instance-aware Query Guided Knowledge Distillation
strategy to overcome catastrophic forgetting by capturing the inter-class
diversity and intra-class identity. 3) Apart from semantic segmentation, CISDQ
introduce the continual learning for instance segmentation in which
instance-wise labeling and supervision are considered. Extensive experiments on
three datasets for two tasks (i.e., continual semantic and instance
segmentation are conducted to demonstrate that CISDQ achieves the
state-of-the-art performance, specifically, obtaining 4.4% and 2.9% mIoU
improvements for the ADE 100-10 (6 steps) setting and ADE 100-5 (11 steps)
setting.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17451" title="Abstract">arXiv:2311.17451</a> [<a href="/pdf/2311.17451" title="Download PDF">pdf</a>, <a href="/format/2311.17451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wireless Network Digital Twin for 6G: Generative AI as A Key Enabler
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+Z">Zhenyu Tao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yongming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoyun Wang</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+X">Xiaohu You</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Digital twin, which enables emulation, evaluation, and optimization of
physical entities through synchronized digital replicas, has gained
increasingly attention as a promising technology for intricate wireless
networks. For 6G, numerous innovative wireless technologies and network
architectures have posed new challenges in establishing wireless network
digital twins. To tackle these challenges, artificial intelligence (AI),
particularly the flourishing generative AI, emerges as a potential solution. In
this article, we discuss emerging prerequisites for wireless network digital
twins considering the complicated network architecture, tremendous network
scale, extensive coverage, and diversified application scenarios in the 6G era.
We further explore the applications of generative AI, such as transformer and
diffusion model, to empower the 6G digital twin from multiple perspectives
including implementation, physical-digital synchronization, and slicing
capability. Subsequently, we propose a hierarchical generative AI-enabled
wireless network digital twin at both the message-level and policy-level, and
provide a typical use case with numerical results to validate the effectiveness
and efficiency. Finally, open research issues for wireless network digital
twins in the 6G era are discussed.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17453" title="Abstract">arXiv:2311.17453</a> [<a href="/pdf/2311.17453" title="Download PDF">pdf</a>, <a href="/format/2311.17453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy Measurement in Tabular Synthetic Data: State of the Art and  Future Research Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boudewijn%2C+A">Alexander Boudewijn</a>, 
<a href="/search/cs?searchtype=author&query=Ferraris%2C+A+F">Andrea Filippo Ferraris</a>, 
<a href="/search/cs?searchtype=author&query=Panfilo%2C+D">Daniele Panfilo</a>, 
<a href="/search/cs?searchtype=author&query=Cocca%2C+V">Vanessa Cocca</a>, 
<a href="/search/cs?searchtype=author&query=Zinutti%2C+S">Sabrina Zinutti</a>, 
<a href="/search/cs?searchtype=author&query=De+Schepper%2C+K">Karel De Schepper</a>, 
<a href="/search/cs?searchtype=author&query=Chauvenet%2C+C+R">Carlo Rossi Chauvenet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 4 tables, 8 figures; NeurIPS 2023 Workshop on Synthetic Data Generation with Generative AI
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023 Workshop on Synthetic Data Generation with Generative
  AI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Cryptography and Security (cs.CR); Databases (cs.DB); Machine Learning (stat.ML)

</div>
<p class="mathjax">Synthetic data (SD) have garnered attention as a privacy enhancing
technology. Unfortunately, there is no standard for quantifying their degree of
privacy protection. In this paper, we discuss proposed quantification
approaches. This contributes to the development of SD privacy standards;
stimulates multi-disciplinary discussion; and helps SD researchers make
informed modeling and evaluation decisions.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17454" title="Abstract">arXiv:2311.17454</a> [<a href="/pdf/2311.17454" title="Download PDF">pdf</a>, <a href="/format/2311.17454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eden: An Ultra Fast, Provably Secure, and Fully Decentralized Blockchain  Interoperability Protocol
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+K">Ke Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">As the blockchain ecosystem continues to evolve and expand, the need for
seamless interoperability between disparate blockchain networks has become
increasingly paramount. Interoperability not only enhances the functionality
and reach of individual blockchains but also fosters a collaborative
environment that can unlock new possibilities for decentralized applications.
In this paper, we present Eden, an elastic decentralized envoy network that
leverage zero-knowledge MapReduce framework to facilitates ultra-fast and
secure cross-chain communication while maintaining complete decentralization.
We detail the Eden's design choices, its comprehensive security model, and the
innovative mechanisms it incorporates to ensure elasticity and resilience, even
under challenging network conditions.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17456" title="Abstract">arXiv:2311.17456</a> [<a href="/pdf/2311.17456" title="Download PDF">pdf</a>, <a href="/format/2311.17456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DifFlow3D: Toward Robust Uncertainty-Aware Scene Flow Estimation with  Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiuming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guangming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+W">Weicai Ye</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chaokang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jinru Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guofeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+D">Dalong Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hesheng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Scene flow estimation, which aims to predict per-point 3D displacements of
dynamic scenes, is a fundamental task in the computer vision field. However,
previous works commonly suffer from unreliable correlation caused by locally
constrained searching ranges, and struggle with accumulated inaccuracy arising
from the coarse-to-fine structure. To alleviate these problems, we propose a
novel uncertainty-aware scene flow estimation network (DifFlow3D) with the
diffusion probabilistic model. Iterative diffusion-based refinement is designed
to enhance the correlation robustness and resilience to challenging cases,
e.g., dynamics, noisy inputs, repetitive patterns, etc. To restrain the
generation diversity, three key flow-related features are leveraged as
conditions in our diffusion model. Furthermore, we also develop an uncertainty
estimation module within diffusion to evaluate the reliability of estimated
scene flow. Our DifFlow3D achieves state-of-the-art performance, with 6.7\% and
19.1\% EPE3D reduction respectively on FlyingThings3D and KITTI 2015 datasets.
Notably, our method achieves an unprecedented millimeter-level accuracy
(0.0089m in EPE3D) on the KITTI dataset. Additionally, our diffusion-based
refinement paradigm can be readily integrated as a plug-and-play module into
existing scene flow networks, significantly increasing their estimation
accuracy. Codes will be released later.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17460" title="Abstract">arXiv:2311.17460</a> [<a href="/pdf/2311.17460" title="Download PDF">pdf</a>, <a href="/format/2311.17460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> W-HMR: Human Mesh Recovery in World Space with Weak-supervised Camera  Calibration and Orientation Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Wei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yunlian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jinhui Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://yw0208.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">For a long time, in the field of reconstructing 3D human bodies from
monocular images, most methods opted to simplify the task by minimizing the
influence of the camera. Using a coarse focal length setting results in the
reconstructed bodies not aligning well with distorted images. Ignoring camera
rotation leads to an unrealistic reconstructed body pose in world space.
Consequently, existing methods' application scenarios are confined to
controlled environments. And they struggle to achieve accurate and reasonable
reconstruction in world space when confronted with complex and diverse
in-the-wild images. To address the above issues, we propose W-HMR, which
decouples global body recovery into camera calibration, local body recovery and
global body orientation correction. We design the first weak-supervised camera
calibration method for body distortion, eliminating dependence on focal length
labels and achieving finer mesh-image alignment. We propose a novel orientation
correction module to allow the reconstructed human body to remain normal in
world space. Decoupling body orientation and body pose enables our model to
consider the accuracy in camera coordinate and the reasonableness in world
coordinate simultaneously, expanding the range of applications. As a result,
W-HMR achieves high-quality reconstruction in dual coordinate systems,
particularly in challenging scenes. Codes will be released on
https://yw0208.github.io/ after publication.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17461" title="Abstract">arXiv:2311.17461</a> [<a href="/pdf/2311.17461" title="Download PDF">pdf</a>, <a href="/format/2311.17461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When StyleGAN Meets Stable Diffusion: a $\mathscr{W}_+$ Adapter for  Personalized Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoming Li</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+X">Xinyu Hou</a>, 
<a href="/search/cs?searchtype=author&query=Loy%2C+C+C">Chen Change Loy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Text-to-image diffusion models have remarkably excelled in producing diverse,
high-quality, and photo-realistic images. This advancement has spurred a
growing interest in incorporating specific identities into generated content.
Most current methods employ an inversion approach to embed a target visual
concept into the text embedding space using a single reference image. However,
the newly synthesized faces either closely resemble the reference image in
terms of facial attributes, such as expression, or exhibit a reduced capacity
for identity preservation. Text descriptions intended to guide the facial
attributes of the synthesized face may fall short, owing to the intricate
entanglement of identity information with identity-irrelevant facial attributes
derived from the reference image. To address these issues, we present the novel
use of the extended StyleGAN embedding space $\mathcal{W}_+$, to achieve
enhanced identity preservation and disentanglement for diffusion models. By
aligning this semantically meaningful human face latent space with
text-to-image diffusion models, we succeed in maintaining high fidelity in
identity preservation, coupled with the capacity for semantic editing.
Additionally, we propose new training objectives to balance the influences of
both prompt and identity conditions, ensuring that the identity-irrelevant
background remains unaffected during facial attribute modifications. Extensive
experiments reveal that our method adeptly generates personalized text-to-image
outputs that are not only compatible with prompt descriptions but also amenable
to common StyleGAN editing directions in diverse settings. Our source code will
be available at \url{https://github.com/csxmli2016/w-plus-adapter}.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17463" title="Abstract">arXiv:2311.17463</a> [<a href="/pdf/2311.17463" title="Download PDF">pdf</a>, <a href="/format/2311.17463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constructing Optimal $L_{\infty}$ Star Discrepancy Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cl%C3%A9ment%2C+F">Fran&#xe7;ois Cl&#xe9;ment</a>, 
<a href="/search/cs?searchtype=author&query=Doerr%2C+C">Carola Doerr</a>, 
<a href="/search/cs?searchtype=author&query=Klamroth%2C+K">Kathrin Klamroth</a>, 
<a href="/search/cs?searchtype=author&query=Paquete%2C+L">Lu&#xed;s Paquete</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Numerical Analysis (math.NA); Optimization and Control (math.OC)

</div>
<p class="mathjax">The $L_{\infty}$ star discrepancy is a very well-studied measure used to
quantify the uniformity of a point set distribution. Constructing optimal point
sets for this measure is seen as a very hard problem in the discrepancy
community. Indeed, optimal point sets are, up to now, known only for $n\leq 6$
in dimension 2 and $n \leq 2$ for higher dimensions. We introduce in this paper
mathematical programming formulations to construct point sets with as low
$L_{\infty}$ star discrepancy as possible. Firstly, we present two models to
construct optimal sets and show that there always exist optimal sets with the
property that no two points share a coordinate. Then, we provide possible
extensions of our models to other measures, such as the extreme and periodic
discrepancies. For the $L_{\infty}$ star discrepancy, we are able to compute
optimal point sets for up to 21 points in dimension 2 and for up to 8 points in
dimension 3. For $d=2$ and $n\ge 7$ points, these point sets have around a 50%
lower discrepancy than the current best point sets, and show a very different
structure.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17465" title="Abstract">arXiv:2311.17465</a> [<a href="/pdf/2311.17465" title="Download PDF">pdf</a>, <a href="/format/2311.17465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AgentAvatar: Disentangling Planning, Driving and Rendering for  Photorealistic Avatar Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Duomin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bin Dai</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yu Deng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Baoyuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this study, our goal is to create interactive avatar agents that can
autonomously plan and animate nuanced facial movements realistically, from both
visual and behavioral perspectives. Given high-level inputs about the
environment and agent profile, our framework harnesses LLMs to produce a series
of detailed text descriptions of the avatar agents' facial motions. These
descriptions are then processed by our task-agnostic driving engine into motion
token sequences, which are subsequently converted into continuous motion
embeddings that are further consumed by our standalone neural-based renderer to
generate the final photorealistic avatar animations. These streamlined
processes allow our framework to adapt to a variety of non-verbal avatar
interactions, both monadic and dyadic. Our extensive study, which includes
experiments on both newly compiled and existing datasets featuring two types of
agents -- one capable of monadic interaction with the environment, and the
other designed for dyadic conversation -- validates the effectiveness and
versatility of our approach. To our knowledge, we advanced a leap step by
combining LLMs and neural rendering for generalized non-verbal prediction and
photo-realistic rendering of avatar agents.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17466" title="Abstract">arXiv:2311.17466</a> [<a href="/pdf/2311.17466" title="Download PDF">pdf</a>, <a href="/format/2311.17466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Slot-Mixup with Subsampling: A Simple Regularization for WSI  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Keum%2C+S">Seongho Keum</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sanghyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Soojeong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Juho Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Whole slide image (WSI) classification requires repetitive zoom-in and out
for pathologists, as only small portions of the slide may be relevant to
detecting cancer. Due to the lack of patch-level labels, multiple instance
learning (MIL) is a common practice for training a WSI classifier. One of the
challenges in MIL for WSIs is the weak supervision coming only from the
slide-level labels, often resulting in severe overfitting. In response,
researchers have considered adopting patch-level augmentation or applying mixup
augmentation, but their applicability remains unverified. Our approach augments
the training dataset by sampling a subset of patches in the WSI without
significantly altering the underlying semantics of the original slides.
Additionally, we introduce an efficient model (Slot-MIL) that organizes patches
into a fixed number of slots, the abstract representation of patches, using an
attention mechanism. We empirically demonstrate that the subsampling
augmentation helps to make more informative slots by restricting the
over-concentration of attention and to improve interpretability. Finally, we
illustrate that combining our attention-based aggregation model with
subsampling and mixup, which has shown limited compatibility in existing MIL
methods, can enhance both generalization and calibration. Our proposed methods
achieve the state-of-the-art performance across various benchmark datasets
including class imbalance and distribution shifts.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17471" title="Abstract">arXiv:2311.17471</a> [<a href="/pdf/2311.17471" title="Download PDF">pdf</a>, <a href="/format/2311.17471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed AI in Zero-touch Provisioning for Edge Networks: Challenges  and Research Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hazra%2C+A">Abhishek Hazra</a>, 
<a href="/search/cs?searchtype=author&query=Morichetta%2C+A">Andrea Morichetta</a>, 
<a href="/search/cs?searchtype=author&query=Murturi%2C+I">Ilir Murturi</a>, 
<a href="/search/cs?searchtype=author&query=Lov%C3%A9n%2C+L">Lauri Lov&#xe9;n</a>, 
<a href="/search/cs?searchtype=author&query=Dehury%2C+C+K">Chinmaya Kumar Dehury</a>, 
<a href="/search/cs?searchtype=author&query=Pujol%2C+V+C">Victor Casamayor Pujol</a>, 
<a href="/search/cs?searchtype=author&query=Donta%2C+P+K">Praveen Kumar Donta</a>, 
<a href="/search/cs?searchtype=author&query=Dustdar%2C+S">Schahram Dustdar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Zero-touch network is anticipated to inaugurate the generation of intelligent
and highly flexible resource provisioning strategies where multiple service
providers collaboratively offer computation and storage resources. This
transformation presents substantial challenges to network administration and
service providers regarding sustainability and scalability. This article
combines Distributed Artificial Intelligence (DAI) with Zero-touch Provisioning
(ZTP) for edge networks. This combination helps to manage network devices
seamlessly and intelligently by minimizing human intervention. In addition,
several advantages are also highlighted that come with incorporating
Distributed AI into ZTP in the context of edge networks. Further, we draw
potential research directions to foster novel studies in this field and
overcome the current limitations.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17473" title="Abstract">arXiv:2311.17473</a> [<a href="/pdf/2311.17473" title="Download PDF">pdf</a>, <a href="/ps/2311.17473" title="Download PostScript">ps</a>, <a href="/format/2311.17473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Multi-Reader Buffers and Channel Placement during Dataflow  Network Mapping to Heterogeneous Many-core Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Letras%2C+M">Martin Letras</a>, 
<a href="/search/cs?searchtype=author&query=Falk%2C+J">Joachim Falk</a>, 
<a href="/search/cs?searchtype=author&query=Teich%2C+J">J&#xfc;rgen Teich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">This paper presents an approach for reducing the memory requirements of
dataflow applications, while minimizing the execution period when deployed on a
many-core target. Often, straightforward implementations of dataflow
applications suffer from data duplication if identical data has to be processed
by multiple actors. In fact, multi-cast actors can produce huge memory
overheads when storing and communicating copies of the same data. As a remedy,
so-called Multi-Reader Buffers (MRBs) can be utilized to forward identical data
to multiple actors in a FIFO manner while storing each data item only once.
However, MRBs may increase the achievable period due to communication
contention when accessing the shared data. A novel multi-objective design space
exploration approach is proposed that selectively replaces multi-cast actors
with MRBs and explores actor and FIFO channel mappings to find trade-offs
between the objectives of period, memory footprint, and core cost. Our approach
considers (i) memory-size constraints, (ii) hierarchical memories to implement
the buffers, (iii) supports heterogeneous many-core platforms, and (iv)
optimizes the buffer placement and overall scheduling to minimize the execution
period by proposing a novel combined actor and communications scheduling
heuristic for period minimization called CAPS-HMS. Our results show that the
explored Pareto fronts improve a hypervolume indicator over a reference
approach by up to 66 % for small to mid-size applications and 90 % for large
applications. Moreover, selectively replacing multi-cast actors with
corresponding MRBs proves to be always superior to never or always replacing
them. Finally, it is shown that the quality of the explored Pareto fronts does
not degrade when replacing the efficient scheduling heuristic CAPS-HMS by an
exact integer linear programming (ILP) solver.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17474" title="Abstract">arXiv:2311.17474</a> [<a href="/pdf/2311.17474" title="Download PDF">pdf</a>, <a href="/format/2311.17474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Networking: Applications, Enabling Techniques,  and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yudong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Hongyang Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiawen Kang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zehui Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The rapid evolution of network technologies and the growing complexity of
network tasks necessitate a paradigm shift in how networks are designed,
configured, and managed. With a wealth of knowledge and expertise, large
language models (LLMs) are one of the most promising candidates. This paper
aims to pave the way for constructing domain-adapted LLMs for networking.
Firstly, we present potential LLM applications for vertical network fields and
showcase the mapping from natural language to network language. Then, several
enabling technologies are investigated, including parameter-efficient
finetuning and prompt engineering. The insight is that language understanding
and tool usage are both required for network LLMs. Driven by the idea of
embodied intelligence, we propose the ChatNet, a domain-adapted network LLM
framework with access to various external network tools. ChatNet can reduce the
time required for burdensome network planning tasks significantly, leading to a
substantial improvement in efficiency. Finally, key challenges and future
research directions are highlighted.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17475" title="Abstract">arXiv:2311.17475</a> [<a href="/pdf/2311.17475" title="Download PDF">pdf</a>, <a href="/format/2311.17475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLiSA: A Hierarchical Hybrid Transformer Model using Orthogonal Cross  Attention for Satellite Image Cloud Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paul%2C+S">Subhajit Paul</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Ashutosh Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 11 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Clouds in optical satellite images are a major concern since their presence
hinders the ability to carry accurate analysis as well as processing. Presence
of clouds also affects the image tasking schedule and results in wastage of
valuable storage space on ground as well as space-based systems. Due to these
reasons, deriving accurate cloud masks from optical remote-sensing images is an
important task. Traditional methods such as threshold-based, spatial filtering
for cloud detection in satellite images suffer from lack of accuracy. In recent
years, deep learning algorithms have emerged as a promising approach to solve
image segmentation problems as it allows pixel-level classification and
semantic-level segmentation. In this paper, we introduce a deep-learning model
based on hybrid transformer architecture for effective cloud mask generation
named CLiSA - Cloud segmentation via Lipschitz Stable Attention network. In
this context, we propose an concept of orthogonal self-attention combined with
hierarchical cross attention model, and we validate its Lipschitz stability
theoretically and empirically. We design the whole setup under adversarial
setting in presence of Lov\'asz-Softmax loss. We demonstrate both qualitative
and quantitative outcomes for multiple satellite image datasets including
Landsat-8, Sentinel-2, and Cartosat-2s. Performing comparative study we show
that our model performs preferably against other state-of-the-art methods and
also provides better generalization in precise cloud extraction from satellite
multi-spectral (MX) images. We also showcase different ablation studies to
endorse our choices corresponding to different architectural elements and
objective functions.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17479" title="Abstract">arXiv:2311.17479</a> [<a href="/pdf/2311.17479" title="Download PDF">pdf</a>, <a href="/format/2311.17479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CrimeGNN: Harnessing the Power of Graph Neural Networks for Community  Detection in Criminal Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chen Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">In this paper, we introduce CrimeGNN, a novel application of Graph Neural
Networks (GNNs) specifically designed to uncover hidden communities within
criminal networks. As criminal activities increasingly rely on complex network
structures, traditional methods of network analysis often fall short in
detecting the intricate and dynamic communities within these networks.
Leveraging the power of GNNs, CrimeGNN provides an advanced and specialized
solution to this problem. The model ingests a graph structure of a criminal
network, where vertices represent individuals and edges represent relationships
between them. CrimeGNN aims to identify a partition of the vertex set, such
that each subset represents a distinct community within the network, maximizing
the modularity function. Experimental results on several benchmark datasets
demonstrate the effectiveness of CrimeGNN, outperforming existing methods in
terms of both accuracy and computational efficiency. The proposed framework
offers significant potential for aiding law enforcement agencies in proactive
policing and crime prevention measures by providing a more in-depth
understanding of the structure and operation of criminal networks.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17482" title="Abstract">arXiv:2311.17482</a> [<a href="/pdf/2311.17482" title="Download PDF">pdf</a>, <a href="/ps/2311.17482" title="Download PostScript">ps</a>, <a href="/format/2311.17482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges for Conflict Mitigation in O-RAN&#x27;s RAN Intelligent  Controllers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adamczyk%2C+C">Cezary Adamczyk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in the proceedings of 2023 SoftCOM conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">The O-RAN architecture enables a more flexible and dynamic radio access
network (RAN) control by separating hardware and software components. However,
the distributed nature of the O-RAN architecture also presents several
challenges for mitigating network control conflicts that can arise between
different network elements. In this article, we identify key challenges for
conflict mitigation in O-RAN networks, including reliable conflict detection,
efficient maintenance of conflict mitigation configuration, optimal conflict
resolution logic, testing and evaluation methodologies, and limited
observability of O-RAN components. We propose solutions to these challenges,
including pre-deployment conflict mitigation, conflict detection and
resolution, and supervision and adaptation. The article concludes by
highlighting the need for ongoing research to address these challenges and
ensure effective conflict mitigation in O-RAN deployments.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17483" title="Abstract">arXiv:2311.17483</a> [<a href="/pdf/2311.17483" title="Download PDF">pdf</a>, <a href="/format/2311.17483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification, Challenges, and Automated Approaches to Handle  Non-Functional Requirements in ML-Enabled Systems: A Systematic Literature  Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Martino%2C+V">Vincenzo De Martino</a>, 
<a href="/search/cs?searchtype=author&query=Palomba%2C+F">Fabio Palomba</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Machine learning (ML) is nowadays so pervasive and diffused that virtually no
application can avoid its use. Nonetheless, its enormous potential is
constantly threatened by non-functional requirements, such as sustainability.
In particular, we noticed the lack of a comprehensive synthesis of the research
efforts done so far and how these may drive further research. In this paper, we
propose a systematic literature review targeting three key aspects such as (1)
the classification of the non-functional requirements investigated so far, (2)
the challenges to face when dealing with them, and (3) the automated approaches
proposed in literature to support practitioners when optimizing them in
practice. Through the combination of well-established guidelines for conducting
systematic literature reviews and additional search criteria, we survey a total
amount of 69 research articles. Our findings report that current research
identified \revised{30} different non-functional requirements, which can be
grouped into six main classes. We also deliver a catalog of over 23 software
engineering challenges that further research should consider, besides an
overview of the automated approaches researchers proposed to support
practitioners when optimizing non-functional requirements of machine
learning-enabled systems. We conclude our work by distilling implications and a
future outlook on the topic.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17484" title="Abstract">arXiv:2311.17484</a> [<a href="/pdf/2311.17484" title="Download PDF">pdf</a>, <a href="/ps/2311.17484" title="Download PostScript">ps</a>, <a href="/format/2311.17484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Notes on data-driven output-feedback control of linear MIMO systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Alsalti%2C+M">Mohammad Alsalti</a>, 
<a href="/search/eess?searchtype=author&query=Lopez%2C+V+G">Victor G. Lopez</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%BCller%2C+M+A">Matthias A. M&#xfc;ller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Recent works have approached the data-driven design of output-feedback
controllers for discrete-time LTI systems by constructing non-minimal state
vectors composed of past inputs and outputs. Depending on the system's
complexity (order, lag and number of inputs), it was observed in several works
that such an approach presents certain limitations, but no methods were
proposed to overcome them. In this note, we clarify these limitations and solve
them by proposing the construction of (alternative) non-minimal state vectors
that facilitate output-feedback control of MIMO discrete-time LTI systems.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17485" title="Abstract">arXiv:2311.17485</a> [<a href="/pdf/2311.17485" title="Download PDF">pdf</a>, <a href="/format/2311.17485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discrete Empirical Interpolation Method for nonlinear softening problems  involving damage and plasticity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kastian%2C+S">Steffen Kastian</a>, 
<a href="/search/cs?searchtype=author&query=Kehls%2C+J">Jannick Kehls</a>, 
<a href="/search/cs?searchtype=author&query=Brepols%2C+T">Tim Brepols</a>, 
<a href="/search/cs?searchtype=author&query=Reese%2C+S">Stefanie Reese</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 28 figures, 2 tables, 3 algorithms
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Accurate simulations are essential for engineering applications, and
intricate continuum mechanical material models are constructed to achieve this
goal. However, the increasing complexity of the material models and geometrical
properties lead to a significant increase in computational effort. Model order
reduction aims to implement efficient methods for accelerating the simulation
process while preserving a high degree of accuracy. Numerous studies have
already demonstrated the benefits of this method for linear elastic material
modeling. However, in the present work, we investigate a two-surface
gradient-extended damage-plasticity model. We conducted complex simulations
with this model, demonstrating both damage behavior and softening. The
POD-based discrete empirical interpolation method (DEIM) is introduced and
implemented. To accomplish simulations with DEIM and softening behaviour, we
propose the implementation of a reduced form of the arc-length method. Existing
research on calculating models with both damage and softening behavior using
the DEIM and arc-length method is limited. To validate the methods, two
numerical examples are thoroughly investigated in this study: a plate with a
hole and an asymmetrically notched specimen. The results show that the proposed
methods can create a reduced order model with high accuracy and a significant
speedup of the simulation. For both examples, the analysis is conducted in
three steps: first, plasticity without damage is examined, followed by damage
without plasticity, and finally, the combination of plasticity and damage is
investigated.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17486" title="Abstract">arXiv:2311.17486</a> [<a href="/pdf/2311.17486" title="Download PDF">pdf</a>, <a href="/format/2311.17486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Visible Light Data Synthesis and Application: A Case Study for  Synthetic Aperture Radar Imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zichen Tian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhaozheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qianru Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We explore the "hidden" ability of large-scale pre-trained image generation
models, such as Stable Diffusion and Imagen, in non-visible light domains,
taking Synthetic Aperture Radar (SAR) data for a case study. Due to the
inherent challenges in capturing satellite data, acquiring ample SAR training
samples is infeasible. For instance, for a particular category of ship in the
open sea, we can collect only few-shot SAR images which are too limited to
derive effective ship recognition models. If large-scale models pre-trained
with regular images can be adapted to generating novel SAR images, the problem
is solved. In preliminary study, we found that fine-tuning these models with
few-shot SAR images is not working, as the models can not capture the two
primary differences between SAR and regular images: structure and modality. To
address this, we propose a 2-stage low-rank adaptation method, and we call it
2LoRA. In the first stage, the model is adapted using aerial-view regular image
data (whose structure matches SAR), followed by the second stage where the base
model from the first stage is further adapted using SAR modality data.
Particularly in the second stage, we introduce a novel prototype LoRA (pLoRA),
as an improved version of 2LoRA, to resolve the class imbalance problem in SAR
datasets. For evaluation, we employ the resulting generation model to
synthesize additional SAR data. This augmentation, when integrated into the
training process of SAR classification as well as segmentation models, yields
notably improved performance for minor classes
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17487" title="Abstract">arXiv:2311.17487</a> [<a href="/pdf/2311.17487" title="Download PDF">pdf</a>, <a href="/format/2311.17487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taiwan LLM: Bridging the Linguistic Divide with a Culturally Aligned  Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yen-Ting Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yun-Nung Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the realm of language models, the nuanced linguistic and cultural
intricacies of Traditional Chinese, as spoken in Taiwan, have been largely
overlooked. This paper introduces Taiwan LLM, a pioneering Large Language Model
that specifically caters to the Traditional Chinese language, with a focus on
the variant used in Taiwan. Leveraging a comprehensive pretraining corpus and
instruction-finetuning datasets, we have developed a model that not only
understands the complexities of Traditional Chinese but also embodies the
cultural context of Taiwan. Taiwan LLM represents the first of its kind, a
model that is not only linguistically accurate but also culturally resonant
with its user base. Our evaluations demonstrate that Taiwan LLM achieves
superior performance in understanding and generating Traditional Chinese text,
outperforming existing models that are predominantly trained on Simplified
Chinese or English. The open-source release of Taiwan LLM invites collaboration
and further innovation, ensuring that the linguistic diversity of Chinese
speakers is embraced and well-served. The model, datasets, and further
resources are made publicly available to foster ongoing research and
development in this field.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17491" title="Abstract">arXiv:2311.17491</a> [<a href="/pdf/2311.17491" title="Download PDF">pdf</a>, <a href="/format/2311.17491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spherical Frustum Sparse Convolution Network for LiDAR Point Cloud  Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guangming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiuming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pollefeys%2C+M">Marc Pollefeys</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hesheng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 10 figures, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">LiDAR point cloud semantic segmentation enables the robots to obtain
fine-grained semantic information of the surrounding environment. Recently,
many works project the point cloud onto the 2D image and adopt the 2D
Convolutional Neural Networks (CNNs) or vision transformer for LiDAR point
cloud semantic segmentation. However, since more than one point can be
projected onto the same 2D position but only one point can be preserved, the
previous 2D image-based segmentation methods suffer from inevitable quantized
information loss. To avoid quantized information loss, in this paper, we
propose a novel spherical frustum structure. The points projected onto the same
2D position are preserved in the spherical frustums. Moreover, we propose a
memory-efficient hash-based representation of spherical frustums. Through the
hash-based representation, we propose the Spherical Frustum sparse Convolution
(SFC) and Frustum Fast Point Sampling (F2PS) to convolve and sample the points
stored in spherical frustums respectively. Finally, we present the Spherical
Frustum sparse Convolution Network (SFCNet) to adopt 2D CNNs for LiDAR point
cloud semantic segmentation without quantized information loss. Extensive
experiments on the SemanticKITTI and nuScenes datasets demonstrate that our
SFCNet outperforms the 2D image-based semantic segmentation methods based on
conventional spherical projection. The source code will be released later.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17492" title="Abstract">arXiv:2311.17492</a> [<a href="/pdf/2311.17492" title="Download PDF">pdf</a>, <a href="/format/2311.17492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mergen: The First Manchu-Korean Machine Translation Model Trained on  Augmented Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seo%2C+J">Jean Seo</a>, 
<a href="/search/cs?searchtype=author&query=Byun%2C+S">Sungjoo Byun</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+M">Minha Kang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sangah Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> emnlp2023/mrl2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The Manchu language, with its roots in the historical Manchurian region of
Northeast China, is now facing a critical threat of extinction, as there are
very few speakers left. In our efforts to safeguard the Manchu language, we
introduce Mergen, the first-ever attempt at a Manchu-Korean Machine Translation
(MT) model. To develop this model, we utilize valuable resources such as the
Manwen Laodang(a historical book) and a Manchu-Korean dictionary. Due to the
scarcity of a Manchu-Korean parallel dataset, we expand our data by employing
word replacement guided by GloVe embeddings, trained on both monolingual and
parallel texts. Our approach is built around an encoder-decoder neural machine
translation model, incorporating a bi-directional Gated Recurrent Unit (GRU)
layer. The experiments have yielded promising results, showcasing a significant
enhancement in Manchu-Korean translation, with a remarkable 20-30 point
increase in the BLEU score.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17493" title="Abstract">arXiv:2311.17493</a> [<a href="/pdf/2311.17493" title="Download PDF">pdf</a>, <a href="/format/2311.17493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Higher Ranks via Adversarial Weight Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuchuan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hanting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Tianyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhe Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Convolutional Neural Networks (CNNs) are hard to deploy on edge devices due
to its high computation and storage complexities. As a common practice for
model compression, network pruning consists of two major categories:
unstructured and structured pruning, where unstructured pruning constantly
performs better. However, unstructured pruning presents a structured pattern at
high pruning rates, which limits its performance. To this end, we propose a
Rank-based PruninG (RPG) method to maintain the ranks of sparse weights in an
adversarial manner. In each step, we minimize the low-rank approximation error
for the weight matrices using singular value decomposition, and maximize their
distance by pushing the weight matrices away from its low rank approximation.
This rank-based optimization objective guides sparse weights towards a
high-rank topology. The proposed method is conducted in a gradual pruning
fashion to stabilize the change of rank during training. Experimental results
on various datasets and different tasks demonstrate the effectiveness of our
algorithm in high sparsity. The proposed RPG outperforms the state-of-the-art
performance by 1.13% top-1 accuracy on ImageNet in ResNet-50 with 98% sparsity.
The codes are available at
https://github.com/huawei-noah/Efficient-Computing/tree/master/Pruning/RPG and
https://gitee.com/mindspore/models/tree/master/research/cv/RPG.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17498" title="Abstract">arXiv:2311.17498</a> [<a href="/pdf/2311.17498" title="Download PDF">pdf</a>, <a href="/format/2311.17498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multiparty Commutative Hashing Protocol based on the Discrete  Logarithm Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zentai%2C+D">Daniel Zentai</a>, 
<a href="/search/cs?searchtype=author&query=Plesa%2C+M">Mihail Plesa</a>, 
<a href="/search/cs?searchtype=author&query=Frot%2C+R">Robin Frot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 2 figures, presented at the 3rd International Conference on Cryptography and Blockchain, published in Computer Science &amp; Information Technology (CS &amp; IT), ISSN : 2231 - 5403, Volume 13, Number 21, November 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Science &amp; Information Technology (CS &amp; IT), ISSN : 2231 -
  5403, Volume 13, Number 21, November 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Let $\mathcal{X}$ and $\mathcal{Y}$ be two sets and suppose that a set of
participants $P=\{P_1,P_2,\dots,P_n\}$ would like to calculate the keyed hash
value of some message $m\in\mathcal{X}$ known to a single participant in $P$
called the data owner. Also, suppose that each participant $P_i$ knows a secret
value $x_i\in\mathcal{X}$. In this paper, we will propose a protocol that
enables the participants in this setup to calculate the value
$y=H(m,x_1,x_2,\dots ,x_n)$ of a hash function
$H:\mathcal{X}^{n+1}\rightarrow\mathcal{Y}$ such that the function $H$ is a
one-way function, participants in $P\backslash\{P_i\}$ cannot obtain $x_i$,
participants other than the data owner cannot obtain $m$, and the hash value
$y=H(m,x_1,x_2,\dots ,x_n)$ remains the same regardless the order of the secret
$x_i$ values.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17500" title="Abstract">arXiv:2311.17500</a> [<a href="/pdf/2311.17500" title="Download PDF">pdf</a>, <a href="/format/2311.17500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spline Upwind for space--time Isogeometric Analysis of cardiac  electrophysiology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Antonietti%2C+P+F">P. F. Antonietti</a>, 
<a href="/search/math?searchtype=author&query=Ded%C3%A8%2C+L">L. Ded&#xe8;</a>, 
<a href="/search/math?searchtype=author&query=Loli%2C+G">G. Loli</a>, 
<a href="/search/math?searchtype=author&query=Sangalli%2C+G">G. Sangalli</a>, 
<a href="/search/math?searchtype=author&query=Tesini%2C+P">P. Tesini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present an elaboration and application of Spline Upwind (SU) stabilization
method, designed in space--time Isogeometric Analysis framework, in order to
make this stabilization as suitable as possible in the context of cardiac
electrophysiology. Our aim is to propose a formulation as simple and efficient
as possible, effectual in preventing spurious oscillations present in plain
Galerkin method and also reasonable from the computational cost point of view.
For these reasons we validate the method's capability with numerical
experiments, focusing on accuracy and computational aspects.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17502" title="Abstract">arXiv:2311.17502</a> [<a href="/pdf/2311.17502" title="Download PDF">pdf</a>, <a href="/format/2311.17502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Answer Selection in Community Question Answering with  Pre-trained and Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xinghang Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24pages, 4 figures, 14tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Community Question Answering (CQA) becomes increasingly prevalent in recent
years. However, there are a large number of answers, which is difficult for
users to select the relevant answers. Therefore, answer selection is a very
significant subtask of CQA. In this paper, we first propose the Question-Answer
cross attention networks (QAN) with pre-trained models for answer selection and
utilize large language model (LLM) to perform answer selection with knowledge
augmentation. Specifically, we apply the BERT model as the encoder layer to do
pre-training for question subjects, question bodies and answers, respectively,
then the cross attention mechanism selects the most relevant answer for
different questions. Experiments show that the QAN model achieves
state-of-the-art performance on two datasets, SemEval2015 and SemEval2017.
Moreover, we use the LLM to generate external knowledge from questions and
correct answers to achieve knowledge augmentation for the answer selection task
by LLM, while optimizing the prompt of LLM in different aspects. The results
show that the introduction of external knowledge can improve the correct answer
selection rate of LLM on datasets SemEval2015 and SemEval2017. Meanwhile, LLM
can also select the correct answer on more questions by optimized prompt.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17504" title="Abstract">arXiv:2311.17504</a> [<a href="/pdf/2311.17504" title="Download PDF">pdf</a>, <a href="/format/2311.17504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PViT-6D: Overclocking Vision Transformers for 6D Pose Estimation with  Confidence-Level Prediction and Pose Tokens
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stapf%2C+S">Sebastian Stapf</a>, 
<a href="/search/cs?searchtype=author&query=Bauernfeind%2C+T">Tobias Bauernfeind</a>, 
<a href="/search/cs?searchtype=author&query=Riboldi%2C+M">Marco Riboldi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the current state of 6D pose estimation, top-performing techniques depend
on complex intermediate correspondences, specialized architectures, and
non-end-to-end algorithms. In contrast, our research reframes the problem as a
straightforward regression task by exploring the capabilities of Vision
Transformers for direct 6D pose estimation through a tailored use of
classification tokens. We also introduce a simple method for determining pose
confidence, which can be readily integrated into most 6D pose estimation
frameworks. This involves modifying the transformer architecture by decreasing
the number of query elements based on the network's assessment of the scene
complexity. Our method that we call Pose Vision Transformer or PViT-6D provides
the benefits of simple implementation and being end-to-end learnable while
outperforming current state-of-the-art methods by +0.3% ADD(-S) on
Linemod-Occlusion and +2.7% ADD(-S) on the YCB-V dataset. Moreover, our method
enhances both the model's interpretability and the reliability of its
performance during inference.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17507" title="Abstract">arXiv:2311.17507</a> [<a href="/pdf/2311.17507" title="Download PDF">pdf</a>, <a href="/ps/2311.17507" title="Download PostScript">ps</a>, <a href="/format/2311.17507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computation of outer inverse of tensors based on $t$-product
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Behera%2C+R">Ratikanta Behera</a>, 
<a href="/search/math?searchtype=author&query=Sahoo%2C+J+K">Jajati Keshari Sahoo</a>, 
<a href="/search/math?searchtype=author&query=Wei%2C+Y">Yimin Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Tensor operations play an essential role in various fields of science and
engineering, including multiway data analysis. In this study, we establish a
few basic properties of the range and null space of a tensor using block
circulant matrices and the discrete Fourier matrix. We then discuss the outer
inverse of tensors based on $t$-product with a prescribed range and kernel of
third-order tensors. We address the relation of this outer inverse with other
generalized inverses, such as the Moore-Penrose inverse, group inverse, and
Drazin inverse. In addition, we present a few algorithms for computing the
outer inverses of the tensors. In particular, a $t$-QR decomposition based
algorithm is developed for computing the outer inverses.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17508" title="Abstract">arXiv:2311.17508</a> [<a href="/pdf/2311.17508" title="Download PDF">pdf</a>, <a href="/format/2311.17508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Performance Prediction for Hyperparameter Optimization of Deep  Learning Models Using High Performance Computing and Quantum Annealing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amboage%2C+J+P+G">Juan Pablo Garc&#xed;a Amboage</a>, 
<a href="/search/cs?searchtype=author&query=Wulff%2C+E">Eric Wulff</a>, 
<a href="/search/cs?searchtype=author&query=Girone%2C+M">Maria Girone</a>, 
<a href="/search/cs?searchtype=author&query=Pena%2C+T+F">Tom&#xe1;s F. Pena</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">Hyperparameter Optimization (HPO) of Deep Learning-based models tends to be a
compute resource intensive process as it usually requires to train the target
model with many different hyperparameter configurations. We show that
integrating model performance prediction with early stopping methods holds
great potential to speed up the HPO process of deep learning models. Moreover,
we propose a novel algorithm called Swift-Hyperband that can use either
classical or quantum support vector regression for performance prediction and
benefit from distributed High Performance Computing environments. This
algorithm is tested not only for the Machine-Learned Particle Flow model used
in High Energy Physics, but also for a wider range of target models from
domains such as computer vision and natural language processing.
Swift-Hyperband is shown to find comparable (or better) hyperparameters as well
as using less computational resources in all test cases.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17510" title="Abstract">arXiv:2311.17510</a> [<a href="/pdf/2311.17510" title="Download PDF">pdf</a>, <a href="/format/2311.17510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StructRe: Rewriting for Structured Shape Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang">Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiepeng">Jiepeng</a>, Pan, Hao, Liu, 
<a href="/search/cs?searchtype=author&query=Yang">Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tong">Tong</a>, Xin, 
<a href="/search/cs?searchtype=author&query=Komura">Komura</a>, 
<a href="/search/cs?searchtype=author&query=Taku">Taku</a>, 
<a href="/search/cs?searchtype=author&query=Wang">Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wenping">Wenping</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Man-made 3D shapes are naturally organized in parts and hierarchies; such
structures provide important constraints for shape reconstruction and
generation. Modeling shape structures is difficult, because there can be
multiple hierarchies for a given shape, causing ambiguity, and across different
categories the shape structures are correlated with semantics, limiting
generalization. We present StructRe, a structure rewriting system, as a novel
approach to structured shape modeling. Given a 3D object represented by points
and components, StructRe can rewrite it upward into more concise structures, or
downward into more detailed structures; by iterating the rewriting process,
hierarchies are obtained. Such a localized rewriting process enables
probabilistic modeling of ambiguous structures and robust generalization across
object categories. We train StructRe on PartNet data and show its
generalization to cross-category and multiple object hierarchies, and test its
extension to ShapeNet. We also demonstrate the benefits of probabilistic and
generalizable structure modeling for shape reconstruction, generation and
editing tasks.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17514" title="Abstract">arXiv:2311.17514</a> [<a href="/pdf/2311.17514" title="Download PDF">pdf</a>, <a href="/format/2311.17514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Replaces Supervision: Query focused Summarization using  Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nath%2C+S">Swaroop Nath</a>, 
<a href="/search/cs?searchtype=author&query=Khadilkar%2C+H">Harshad Khadilkar</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharyya%2C+P">Pushpak Bhattacharyya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Query-focused Summarization (QfS) deals with systems that generate summaries
from document(s) based on a query. Motivated by the insight that Reinforcement
Learning (RL) provides a generalization to Supervised Learning (SL) for Natural
Language Generation, and thereby performs better (empirically) than SL, we use
an RL-based approach for this task of QfS. Additionally, we also resolve the
conflict of employing RL in Transformers with Teacher Forcing. We develop
multiple Policy Gradient networks, trained on various reward signals: ROUGE,
BLEU, and Semantic Similarity, which lead to a 10-point improvement over the
State-of-the-Art approach on the ROUGE-L metric for a benchmark dataset (ELI5).
We also show performance of our approach in zero-shot setting for another
benchmark dataset (DebatePedia) -- our approach leads to results comparable to
baselines, which were specifically trained on DebatePedia. To aid the RL
training, we propose a better semantic similarity reward, enabled by a novel
Passage Embedding scheme developed using Cluster Hypothesis. Lastly, we
contribute a gold-standard test dataset to further research in QfS and
Long-form Question Answering (LfQA).
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17516" title="Abstract">arXiv:2311.17516</a> [<a href="/pdf/2311.17516" title="Download PDF">pdf</a>, <a href="/format/2311.17516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MMA-Diffusion: MultiModal Attack on Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yijun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Ruiyuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaosen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+N">Nan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qiang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In recent years, Text-to-Image (T2I) models have seen remarkable
advancements, gaining widespread adoption. However, this progress has
inadvertently opened avenues for potential misuse, particularly in generating
inappropriate or Not-Safe-For-Work (NSFW) content. Our work introduces
MMA-Diffusion, a framework that presents a significant and realistic threat to
the security of T2I models by effectively circumventing current defensive
measures in both open-source models and commercial online services. Unlike
previous approaches, MMA-Diffusion leverages both textual and visual modalities
to bypass safeguards like prompt filters and post-hoc safety checkers, thus
exposing and highlighting the vulnerabilities in existing defense mechanisms.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17518" title="Abstract">arXiv:2311.17518</a> [<a href="/pdf/2311.17518" title="Download PDF">pdf</a>, <a href="/format/2311.17518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The devil is in the fine-grained details: Evaluating open-vocabulary  object detectors for fine-grained understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bianchi%2C+L">Lorenzo Bianchi</a>, 
<a href="/search/cs?searchtype=author&query=Carrara%2C+F">Fabio Carrara</a>, 
<a href="/search/cs?searchtype=author&query=Messina%2C+N">Nicola Messina</a>, 
<a href="/search/cs?searchtype=author&query=Gennaro%2C+C">Claudio Gennaro</a>, 
<a href="/search/cs?searchtype=author&query=Falchi%2C+F">Fabrizio Falchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advancements in large vision-language models enabled visual object
detection in open-vocabulary scenarios, where object classes are defined in
free-text formats during inference. In this paper, we aim to probe the
state-of-the-art methods for open-vocabulary object detection to determine to
what extent they understand fine-grained properties of objects and their parts.
To this end, we introduce an evaluation protocol based on dynamic vocabulary
generation to test whether models detect, discern, and assign the correct
fine-grained description to objects in the presence of hard-negative classes.
We contribute with a benchmark suite of increasing difficulty and probing
different properties like color, pattern, and material. We further enhance our
investigation by evaluating several state-of-the-art open-vocabulary object
detectors using the proposed protocol and find that most existing solutions,
which shine in standard open-vocabulary benchmarks, struggle to accurately
capture and distinguish finer object details. We conclude the paper by
highlighting the limitations of current methodologies and exploring promising
research directions to overcome the discovered drawbacks. Data and code are
available at https://github.com/lorebianchi98/FG-OVD.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17524" title="Abstract">arXiv:2311.17524</a> [<a href="/pdf/2311.17524" title="Download PDF">pdf</a>, <a href="/format/2311.17524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Stability during Upsampling -- on the Importance of Spatial  Context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agnihotri%2C+S">Shashank Agnihotri</a>, 
<a href="/search/cs?searchtype=author&query=Grabinski%2C+J">Julia Grabinski</a>, 
<a href="/search/cs?searchtype=author&query=Keuper%2C+M">Margret Keuper</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Stable upsampling, reduction in spectral artifacts
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">State-of-the-art models for pixel-wise prediction tasks such as image
restoration, image segmentation, or disparity estimation, involve several
stages of data resampling, in which the resolution of feature maps is first
reduced to aggregate information and then sequentially increased to generate a
high-resolution output. Several previous works have investigated the effect of
artifacts that are invoked during downsampling and diverse cures have been
proposed that facilitate to improve prediction stability and even robustness
for image classification. However, equally relevant, artifacts that arise
during upsampling have been less discussed. This is significantly relevant as
upsampling and downsampling approaches face fundamentally different challenges.
While during downsampling, aliases and artifacts can be reduced by blurring
feature maps, the emergence of fine details is crucial during upsampling.
Blurring is therefore not an option and dedicated operations need to be
considered. In this work, we are the first to explore the relevance of context
during upsampling by employing convolutional upsampling operations with
increasing kernel size while keeping the encoder unchanged. We find that
increased kernel sizes can in general improve the prediction stability in tasks
such as image restoration or image segmentation, while a block that allows for
a combination of small-size kernels for fine details and large-size kernels for
artifact removal and increased context yields the best results.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17527" title="Abstract">arXiv:2311.17527</a> [<a href="/pdf/2311.17527" title="Download PDF">pdf</a>, <a href="/ps/2311.17527" title="Download PostScript">ps</a>, <a href="/format/2311.17527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On $(n,&#x3c3;)-$equivalence relation between skew constacyclic codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ou-azzoua%2C+H">Hassan Ou-azzoua</a>, 
<a href="/search/cs?searchtype=author&query=Najmeddine%2C+M">Mustapha Najmeddine</a>, 
<a href="/search/cs?searchtype=author&query=Aydin%2C+N">Nuh Aydin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper we generalize the notion of $n$-equivalence relation introduced
by Chen et al. in \cite{Chen2014} to classify constacyclic codes of length $n$
over a finite field $\Fq,$ where $q=p^r$ is a prime power, to the case of skew
constacyclic codes without derivation. We call this relation
$(n,\sigma)$-equivalence relation, where $n$ is the length of the code and $
\sigma$ is an automorphism of the finite field. We compute the number of
$(n,\sigma)$-equivalence classes, and we give conditions on $ \lambda$ and
$\mu$ for which $(\sigma, \lambda)$-constacyclic codes and $(\sigma,
\lambda)$-constacyclic codes are equivalent with respect to our
$(n,\sigma)$-equivalence relation. Under some conditions on $n$ and $q$ we
prove that skew constacyclic codes are equivalent to cyclic codes. We also
prove that when $q$ is even and $\sigma$ is the Frobenius autmorphism, skew
constacyclic codes of length $n$ are equivalent to cyclic codes when
$\gcd(n,r)=1$. Finally we give some examples as applications of the theory
developed here.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17528" title="Abstract">arXiv:2311.17528</a> [<a href="/pdf/2311.17528" title="Download PDF">pdf</a>, <a href="/format/2311.17528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HiDiffusion: Unlocking High-Resolution Creativity and Efficiency in  Low-Resolution Trained Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhaowei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhenyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+W">Wengang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jiajun Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce HiDiffusion, a tuning-free framework comprised of
Resolution-Aware U-Net (RAU-Net) and Modified Shifted Window Multi-head
Self-Attention (MSW-MSA) to enable pretrained large text-to-image diffusion
models to efficiently generate high-resolution images (e.g. 1024$\times$1024)
that surpass the training image resolution. Pretrained diffusion models
encounter unreasonable object duplication in generating images beyond the
training image resolution. We attribute it to the mismatch between the feature
map size of high-resolution images and the receptive field of U-Net's
convolution. To address this issue, we propose a simple yet scalable method
named RAU-Net. RAU-Net dynamically adjusts the feature map size to match the
convolution's receptive field in the deep block of U-Net. Another obstacle in
high-resolution synthesis is the slow inference speed of U-Net. Our
observations reveal that the global self-attention in the top block, which
exhibits locality, however, consumes the majority of computational resources.
To tackle this issue, we propose MSW-MSA. Unlike previous window attention
mechanisms, our method uses a much larger window size and dynamically shifts
windows to better accommodate diffusion models. Extensive experiments
demonstrate that our HiDiffusion can scale diffusion models to generate
1024$\times$1024, 2048$\times$2048, or even 4096$\times$4096 resolution images,
while simultaneously reducing inference time by 40\%-60\%, achieving
state-of-the-art performance on high-resolution image synthesis. The most
significant revelation of our work is that a pretrained diffusion model on
low-resolution images is scalable for high-resolution generation without
further tuning. We hope this revelation can provide insights for future
research on the scalability of diffusion models.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17530" title="Abstract">arXiv:2311.17530</a> [<a href="/pdf/2311.17530" title="Download PDF">pdf</a>, <a href="/ps/2311.17530" title="Download PostScript">ps</a>, <a href="/format/2311.17530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallelizing Optimal Multiple Sequence Alignment by Dynamic Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Helal%2C+M">Manal Helal</a>, 
<a href="/search/cs?searchtype=author&query=El-Gindy%2C+H">Hossam El-Gindy</a>, 
<a href="/search/cs?searchtype=author&query=Mullin%2C+L">Lenore Mullin</a>, 
<a href="/search/cs?searchtype=author&query=Gaeta%2C+B">Bruno Gaeta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Optimal multiple sequence alignment by dynamic programming, like many highly
dimensional scientific computing problems, has failed to benefit from the
improvements in computing performance brought about by multi-processor systems,
due to the lack of suitable scheme to manage partitioning and dependencies. A
scheme for parallel implementation of the dynamic programming multiple sequence
alignment is presented, based on a peer to peer design and a multidimensional
array indexing method. This design results in up to 5-fold improvement compared
to a previously described master/slave design, and scales favourably with the
number of processors used. This study demonstrates an approach for
parallelising multi-dimensional dynamic programming and similar algorithms
utilizing multi-processor architectures.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17532" title="Abstract">arXiv:2311.17532</a> [<a href="/pdf/2311.17532" title="Download PDF">pdf</a>, <a href="/format/2311.17532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly-Supervised Emotion Transition Learning for Diverse 3D Co-speech  Gesture Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xingqun Qi</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jiahao Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+R">Ruibin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+X">Xiaowei Chi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengfei Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Wenhan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+W">Wei Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanghang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qifeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yike Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The code and dataset will be released as soon as possible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generating vivid and emotional 3D co-speech gestures is crucial for virtual
avatar animation in human-machine interaction applications. While the existing
methods enable generating the gestures to follow a single emotion label, they
overlook that long gesture sequence modeling with emotion transition is more
practical in real scenes. In addition, the lack of large-scale available
datasets with emotional transition speech and corresponding 3D human gestures
also limits the addressing of this task. To fulfill this goal, we first
incorporate the ChatGPT-4 and an audio inpainting approach to construct the
high-fidelity emotion transition human speeches. Considering obtaining the
realistic 3D pose annotations corresponding to the dynamically inpainted
emotion transition audio is extremely difficult, we propose a novel weakly
supervised training strategy to encourage authority gesture transitions.
Specifically, to enhance the coordination of transition gestures w.r.t
different emotional ones, we model the temporal association representation
between two different emotional gesture sequences as style guidance and infuse
it into the transition generation. We further devise an emotion mixture
mechanism that provides weak supervision based on a learnable mixed emotion
label for transition gestures. Last, we present a keyframe sampler to supply
effective initial posture cues in long sequences, enabling us to generate
diverse gestures. Extensive experiments demonstrate that our method outperforms
the state-of-the-art models constructed by adapting single emotion-conditioned
counterparts on our newly defined emotion transition task and datasets.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17536" title="Abstract">arXiv:2311.17536</a> [<a href="/pdf/2311.17536" title="Download PDF">pdf</a>, <a href="/format/2311.17536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smooth Video Synthesis with Noise Constraints on Diffusion Models for  One-shot Video Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+L">Liang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Haoran Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Ruisi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Linxuan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Chaotian Song</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Qinglin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Boxi Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent one-shot video tuning methods, which fine-tune the network on a
specific video based on pre-trained text-to-image models (e.g., Stable
Diffusion), are popular in the community because of the flexibility. However,
these methods often produce videos marred by incoherence and inconsistency. To
address these limitations, this paper introduces a simple yet effective noise
constraint across video frames. This constraint aims to regulate noise
predictions across their temporal neighbors, resulting in smooth latents. It
can be simply included as a loss term during the training phase. By applying
the loss to existing one-shot video tuning methods, we significantly improve
the overall consistency and smoothness of the generated videos. Furthermore, we
argue that current video evaluation metrics inadequately capture smoothness. To
address this, we introduce a novel metric that considers detailed features and
their temporal dynamics. Experimental results validate the effectiveness of our
approach in producing smoother videos on various one-shot video tuning
baselines. The source codes and video demos are available at
\href{https://github.com/SPengLiang/SmoothVideo}{https://github.com/SPengLiang/SmoothVideo}.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17539" title="Abstract">arXiv:2311.17539</a> [<a href="/pdf/2311.17539" title="Download PDF">pdf</a>, <a href="/format/2311.17539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Effects of Overparameterization on Sharpness-aware Minimization: An  Empirical and Theoretical Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shin%2C+S">Sungbin Shin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongyeop Lee</a>, 
<a href="/search/cs?searchtype=author&query=Andriushchenko%2C+M">Maksym Andriushchenko</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+N">Namhoon Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Training an overparameterized neural network can yield minimizers of the same
level of training loss and yet different generalization capabilities. With
evidence that indicates a correlation between sharpness of minima and their
generalization errors, increasing efforts have been made to develop an
optimization method to explicitly find flat minima as more generalizable
solutions. This sharpness-aware minimization (SAM) strategy, however, has not
been studied much yet as to how overparameterization can actually affect its
behavior. In this work, we analyze SAM under varying degrees of
overparameterization and present both empirical and theoretical results that
suggest a critical influence of overparameterization on SAM. Specifically, we
first use standard techniques in optimization to prove that SAM can achieve a
linear convergence rate under overparameterization in a stochastic setting. We
also show that the linearly stable minima found by SAM are indeed flatter and
have more uniformly distributed Hessian moments compared to those of SGD. These
results are corroborated with our experiments that reveal a consistent trend
that the generalization improvement made by SAM continues to increase as the
model becomes more overparameterized. We further present that sparsity can open
up an avenue for effective overparameterization in practice.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17541" title="Abstract">arXiv:2311.17541</a> [<a href="/pdf/2311.17541" title="Download PDF">pdf</a>, <a href="/format/2311.17541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TaskWeaver: A Code-First Agent Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiao%2C+B">Bo Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liqun Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shilin He</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yu Kang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaoyun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fangkai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+M">Minghua Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Pu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+S">Si Qin</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+X">Xiaoting Qin</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+C">Chao Du</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qingwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Rajmohan%2C+S">Saravan Rajmohan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Language Language Models (LLMs) have shown impressive abilities in natural
language understanding and generation, leading to their use in applications
such as chatbots and virtual assistants. However, existing LLM frameworks face
limitations in handling domain-specific data analytics tasks with rich data
structures. Moreover, they struggle with flexibility to meet diverse user
requirements. To address these issues, TaskWeaver is proposed as a code-first
framework for building LLM-powered autonomous agents. It converts user requests
into executable code and treats user-defined plugins as callable functions.
TaskWeaver provides support for rich data structures, flexible plugin usage,
and dynamic plugin selection, and leverages LLM coding capabilities for complex
logic. It also incorporates domain-specific knowledge through examples and
ensures the secure execution of generated code. TaskWeaver offers a powerful
and flexible framework for creating intelligent conversational agents that can
handle complex tasks and adapt to domain-specific scenarios. The code is
open-sourced at https://github.com/microsoft/TaskWeaver/.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17545" title="Abstract">arXiv:2311.17545</a> [<a href="/pdf/2311.17545" title="Download PDF">pdf</a>, <a href="/ps/2311.17545" title="Download PostScript">ps</a>, <a href="/format/2311.17545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance Evaluation of Checkpoint/Restart Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azeem%2C+B+A">Basma Abdel Azeem</a>, 
<a href="/search/cs?searchtype=author&query=Helal%2C+M">Manal Helal</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The 9th International Conference on INFOrmatics and Systems
  (INFOS2014) -- 15-17 December Parallel and Distributed Computing Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Distributed applications running on a large cluster environment, such as the
cloud instances will have shorter execution time. However, the application
might suffer from sudden termination due to unpredicted computing node
failures, thus loosing the whole computation. Checkpoint/restart is a fault
tolerance technique used to solve this problem. In this work we evaluated the
performance of two of the most commonly used checkpoint/restart techniques
(Distributed Multithreaded Checkpointing (DMTCP) and Berkeley Lab
Checkpoint/Restart library (BLCR) integrated into the OpenMPI framework). We
aimed to test their validity and evaluate their performance in both local and
Amazon Elastic Compute Cloud (EC2) environments. The experiments were conducted
on Amazon EC2 as a well-known proprietary cloud computing service provider.
Results obtained were reported and compared to evaluate checkpoint and restart
time values, data scalability and compute processes scalability. The findings
proved that DMTCP performs better than BLCR for checkpoint and restart speed,
data scalability and compute processes scalability experiments.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17546" title="Abstract">arXiv:2311.17546</a> [<a href="/pdf/2311.17546" title="Download PDF">pdf</a>, <a href="/format/2311.17546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VINNA for Neonates -- Orientation Independence through Latent  Augmentations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Henschel%2C+L">Leonie Henschel</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%BCgler%2C+D">David K&#xfc;gler</a>, 
<a href="/search/cs?searchtype=author&query=Z%C3%B6llei%2C+L">Lilla Z&#xf6;llei</a>, 
<a href="/search/cs?searchtype=author&query=Reuter%2C+M">Martin Reuter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review at Imaging Neuroscience
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Fast and accurate segmentation of neonatal brain images is highly desired to
better understand and detect changes during development and disease. Yet, the
limited availability of ground truth datasets, lack of standardized acquisition
protocols, and wide variations of head positioning pose challenges for method
development. A few automated image analysis pipelines exist for newborn brain
MRI segmentation, but they often rely on time-consuming procedures and require
resampling to a common resolution, subject to loss of information due to
interpolation and down-sampling. Without registration and image resampling,
variations with respect to head positions and voxel resolutions have to be
addressed differently. In deep-learning, external augmentations are
traditionally used to artificially expand the representation of spatial
variability, increasing the training dataset size and robustness. However,
these transformations in the image space still require resampling, reducing
accuracy specifically in the context of label interpolation. We recently
introduced the concept of resolution-independence with the Voxel-size
Independent Neural Network framework, VINN. Here, we extend this concept by
additionally shifting all rigid-transforms into the network architecture with a
four degree of freedom (4-DOF) transform module, enabling resolution-aware
internal augmentations (VINNA). In this work we show that VINNA (i)
significantly outperforms state-of-the-art external augmentation approaches,
(ii) effectively addresses the head variations present specifically in newborn
datasets, and (iii) retains high segmentation accuracy across a range of
resolutions (0.5-1.0 mm). The 4-DOF transform module is a powerful, general
approach to implement spatial augmentation without requiring image or label
interpolation. The specific network application to newborns will be made
publicly available as VINNA4neonates.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17552" title="Abstract">arXiv:2311.17552</a> [<a href="/pdf/2311.17552" title="Download PDF">pdf</a>, <a href="/format/2311.17552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient Illumination Invariant Tiger Detection Framework for  Wildlife Surveillance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pendharkar%2C+G">Gaurav Pendharkar</a>, 
<a href="/search/cs?searchtype=author&query=Micheal%2C+A+A">A.Ancy Micheal</a>, 
<a href="/search/cs?searchtype=author&query=Misquitta%2C+J">Jason Misquitta</a>, 
<a href="/search/cs?searchtype=author&query=Kaippada%2C+R">Ranjeesh Kaippada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at ICCIS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Tiger conservation necessitates the strategic deployment of multifaceted
initiatives encompassing the preservation of ecological habitats, anti-poaching
measures, and community involvement for sustainable growth in the tiger
population. With the advent of artificial intelligence, tiger surveillance can
be automated using object detection. In this paper, an accurate illumination
invariant framework is proposed based on EnlightenGAN and YOLOv8 for tiger
detection. The fine-tuned YOLOv8 model achieves a mAP score of 61% without
illumination enhancement. The illumination enhancement improves the mAP by
0.7%. The approaches elevate the state-of-the-art performance on the ATRW
dataset by approximately 6% to 7%.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17556" title="Abstract">arXiv:2311.17556</a> [<a href="/pdf/2311.17556" title="Download PDF">pdf</a>, <a href="/format/2311.17556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing Tensor Generalized bilateral inverses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Behera%2C+R">Ratikanta Behera</a>, 
<a href="/search/math?searchtype=author&query=Sahoo%2C+J+K">Jajati Keshari Sahoo</a>, 
<a href="/search/math?searchtype=author&query=Stanimirovic%2C+P+S">Predrag S. Stanimirovic</a>, 
<a href="/search/math?searchtype=author&query=Stupina%2C+A">Alena Stupina</a>, 
<a href="/search/math?searchtype=author&query=Stupin%2C+A">Artem Stupin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We introduce tensor generalized bilateral inverses (TGBIs) under the Einstein
tensor product as an extension of generalized bilateral inverses (GBIs) in the
matrix environment. Moreover, the TBGI class includes so far considered
composite generalized inverses (CGIs) for matrices and tensors. Applications of
TBGIs for solving multilinear systems are presented. The characterizations and
representations of TGBI were studied and verified using a specific algebraic
approach. Further, a few characterizations of known CGIs (such as CMP, DMP,
MPD, MPCEP, and CEPMP) are derived. The main properties of the TGBIs ware
exploited and verified through numerical examples.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17559" title="Abstract">arXiv:2311.17559</a> [<a href="/pdf/2311.17559" title="Download PDF">pdf</a>, <a href="/ps/2311.17559" title="Download PostScript">ps</a>, <a href="/format/2311.17559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizations of Weighted Generalized Inverses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sitha%2C+B">Bibekananda Sitha</a>, 
<a href="/search/math?searchtype=author&query=Behera%2C+R">Ratikanta Behera</a>, 
<a href="/search/math?searchtype=author&query=Sahoo%2C+J+K">Jajati Keshari Sahoo</a>, 
<a href="/search/math?searchtype=author&query=Mohapatra%2C+R+N">R. N. Mohapatra</a>, 
<a href="/search/math?searchtype=author&query=Stanimirovic%2C+P">Predrag Stanimirovic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The main objective of this paper is to introduce unique representations and
characterizations for the weighted core inverse of matrices. We also
investigate various properties and representations of these inverses and their
relationships with other generalized inverses. Proposed representations of the
matrix weighted core inverse will help us to discuss some results associated
with the reverse order law for these inverses. Furthermore,this paper
introduces an extension of the concepts of generalized bilateral inverse, and
$\{1,2,3,1^k\}$-inverse and their respective dual for complex rectangular
matrices. Furthermore, we establish characterizations of EP-ness and the
condition when both $W$-weighted $\{1,2,3\}$ and $W$-weighted $\{1,2,3,1^k\}$
inverses coincide. In addition, we define the dual inverses for both weighted
bilateral inverses and $\{1,2,3,1^k\}$-inverse. Characteristics that lead to
self-duality in weighted bilateral inverses are also examined.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17560" title="Abstract">arXiv:2311.17560</a> [<a href="/pdf/2311.17560" title="Download PDF">pdf</a>, <a href="/format/2311.17560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpreting Differentiable Latent States for Healthcare Time-series  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bijlani%2C+N">Nivedita Bijlani</a>, 
<a href="/search/cs?searchtype=author&query=Kouchaki%2C+S">Samaneh Kouchaki</a>, 
<a href="/search/cs?searchtype=author&query=Barnaghi%2C+P">Payam Barnaghi</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Workshop on Interpretable ML in Healthcare at International Con-
  ference on Machine Learning (ICML), Honolulu, Hawaii, USA. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Machine learning enables extracting clinical insights from large temporal
datasets. The applications of such machine learning models include identifying
disease patterns and predicting patient outcomes. However, limited
interpretability poses challenges for deploying advanced machine learning in
digital healthcare. Understanding the meaning of latent states is crucial for
interpreting machine learning models, assuming they capture underlying
patterns. In this paper, we present a concise algorithm that allows for i)
interpreting latent states using highly related input features; ii)
interpreting predictions using subsets of input features via latent states; and
iii) interpreting changes in latent states over time. The proposed algorithm is
feasible for any model that is differentiable. We demonstrate that this
approach enables the identification of a daytime behavioral pattern for
predicting nocturnal behavior in a real-world healthcare dataset.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17565" title="Abstract">arXiv:2311.17565</a> [<a href="/pdf/2311.17565" title="Download PDF">pdf</a>, <a href="/format/2311.17565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bias Resilient Multi-Step Off-Policy Goal-Conditioned Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lisheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Ke Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In goal-conditioned reinforcement learning (GCRL), sparse rewards present
significant challenges, often obstructing efficient learning. Although
multi-step GCRL can boost this efficiency, it can also lead to off-policy
biases in target values. This paper dives deep into these biases, categorizing
them into two distinct categories: "shooting" and "shifting". Recognizing that
certain behavior policies can hasten policy refinement, we present solutions
designed to capitalize on the positive aspects of these biases while minimizing
their drawbacks, enabling the use of larger step sizes to speed up GCRL. An
empirical study demonstrates that our approach ensures a resilient and robust
improvement, even in ten-step learning scenarios, leading to superior learning
efficiency and performance that generally surpass the baseline and several
state-of-the-art multi-step GCRL benchmarks.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17567" title="Abstract">arXiv:2311.17567</a> [<a href="/pdf/2311.17567" title="Download PDF">pdf</a>, <a href="/format/2311.17567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Network characteristics of financial networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boersma%2C+M">M. Boersma</a>, 
<a href="/search/cs?searchtype=author&query=Sourabh%2C+S">S. Sourabh</a>, 
<a href="/search/cs?searchtype=author&query=Hoogduin%2C+L+A">L.A. Hoogduin</a>, 
<a href="/search/cs?searchtype=author&query=Kandhai%2C+D">D. Kandhai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">We embrace a fresh perspective to auditing by analyzing a large set of
companies as complex financial networks rather than static aggregates of
balance sheet data. Preliminary analyses show that network centrality measures
within these networks could significantly enhance auditors' insights into
financial structures. Utilizing data from over 300 diverse companies, we
examine the structure of financial statement networks through bipartite graph
analysis, exploring their scale-freeness by comparing degree distributions to
power-law and exponential models. Our findings indicate heavy-tailed degree
distribution for financial account nodes, networks that grow with the same
diameter, and the presence of influential hubs. This study lays the groundwork
for future auditing methodologies where baseline network statistics could serve
as indicators for anomaly detection, marking a substantial advancement in audit
research and network science.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17571" title="Abstract">arXiv:2311.17571</a> [<a href="/pdf/2311.17571" title="Download PDF">pdf</a>, <a href="/format/2311.17571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LGFCTR: Local and Global Feature Convolutional Transformer for Image  Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+W">Wenhao Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jie Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages of main text, 7 pages of supplementary material, 3 pages of references, 6 figures in main text and 8 figures in supplementary material, 5 tables in main text and 2 tables in supplementary material
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image matching that finding robust and accurate correspondences across images
is a challenging task under extreme conditions. Capturing local and global
features simultaneously is an important way to mitigate such an issue but
recent transformer-based decoders were still stuck in the issues that CNN-based
encoders only extract local features and the transformers lack locality.
Inspired by the locality and implicit positional encoding of convolutions, a
novel convolutional transformer is proposed to capture both local contexts and
global structures more sufficiently for detector-free matching. Firstly, a
universal FPN-like framework captures global structures in self-encoder as well
as cross-decoder by transformers and compensates local contexts as well as
implicit positional encoding by convolutions. Secondly, a novel convolutional
transformer module explores multi-scale long range dependencies by a novel
multi-scale attention and further aggregates local information inside
dependencies for enhancing locality. Finally, a novel regression-based
sub-pixel refinement module exploits the whole fine-grained window features for
fine-level positional deviation regression. The proposed method achieves
superior performances on a wide range of benchmarks. The code will be available
on https://github.com/zwh0527/LGFCTR.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17578" title="Abstract">arXiv:2311.17578</a> [<a href="/pdf/2311.17578" title="Download PDF">pdf</a>, <a href="/ps/2311.17578" title="Download PostScript">ps</a>, <a href="/format/2311.17578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Driven Approaches to Cybersecurity Governance for Board  Decision-Making -- A Systematic Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Modi%2C+A">Anita Modi</a>, 
<a href="/search/cs?searchtype=author&query=Kuzminykh%2C+I">Ievgeniia Kuzminykh</a>, 
<a href="/search/cs?searchtype=author&query=Ghita%2C+B">Bogdan Ghita</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Cybersecurity governance influences the quality of strategic decision-making
to ensure cyber risks are managed effectively. Board of Directors are the
decisions-makers held accountable for managing this risk; however, they lack
adequate and efficient information necessary for making such decisions. In
addition to the myriad of challenges they face, they are often insufficiently
versed in the technology or cybersecurity terminology or not provided with the
correct tools to support them to make sound decisions to govern cybersecurity
effectively. A different approach is needed to ensure BoDs are clear on the
approach the business is taking to build a cyber resilient organization. This
systematic literature review investigates the existing risk measurement
instruments, cybersecurity metrics, and associated models for supporting BoDs.
We identified seven conceptual themes through literature analysis that form the
basis of this study's main contribution. The findings showed that, although
sophisticated cybersecurity tools exist and are developing, there is limited
information for Board of Directors to support them in terms of metrics and
models to govern cybersecurity in a language they understand. The review also
provides some recommendations on theories and models that can be further
investigated to provide support to Board of Directors.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17581" title="Abstract">arXiv:2311.17581</a> [<a href="/pdf/2311.17581" title="Download PDF">pdf</a>, <a href="/ps/2311.17581" title="Download PostScript">ps</a>, <a href="/format/2311.17581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Composable Constraint Models for Permutation Enumeration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoffmann%2C+R">Ruth Hoffmann</a>, 
<a href="/search/cs?searchtype=author&query=Akg%C3%BCn%2C+%C3%96">&#xd6;zg&#xfc;r Akg&#xfc;n</a>, 
<a href="/search/cs?searchtype=author&query=Jefferson%2C+C">Christopher Jefferson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">Constraint programming (CP) is a powerful tool for modeling mathematical
concepts and objects and finding both solutions or counter examples. One of the
major strengths of CP is that problems can easily be combined or expanded. In
this paper, we illustrate that this versatility makes CP an ideal tool for
exploring problems in permutation patterns.
<br />We declaratively define permutation properties, permutation pattern avoidance
and containment constraints using CP and show how this allows us to solve a
wide range of problems. We show how this approach enables the arbitrary
composition of these conditions, and also allows the easy addition of extra
conditions. We demonstrate the effectiveness of our techniques by modelling the
containment and avoidance of six permutation patterns, eight permutation
properties and measuring five statistics on the resulting permutations. In
addition to calculating properties and statistics for the generated
permutations, we show that arbitrary additional constraints can also be easily
and efficiently added.
<br />This approach enables mathematicians to investigate permutation pattern
problems in a quick and efficient manner. We demonstrate the utility of
constraint programming for permutation patterns by showing how we can easily
and efficiently extend the known permutation counts for a conjecture involving
the class of 1324 avoiding permutations. For this problem, we expand the
enumeration of 1324-avoiding permutations with a fixed number of inversions to
permutations of length 16 and show for the first time that in the enumeration
there is a pattern occurring which follows a unique sequence on the Online
Encyclopedia of Integer Sequences.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17582" title="Abstract">arXiv:2311.17582</a> [<a href="/pdf/2311.17582" title="Download PDF">pdf</a>, <a href="/format/2311.17582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LoCoMotif: Discovering time-warped motifs in time series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van+Wesenbeeck%2C+D">Daan Van Wesenbeeck</a>, 
<a href="/search/cs?searchtype=author&query=Yurtman%2C+A">Aras Yurtman</a>, 
<a href="/search/cs?searchtype=author&query=Meert%2C+W">Wannes Meert</a>, 
<a href="/search/cs?searchtype=author&query=Blockeel%2C+H">Hendrik Blockeel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 15 figures. Submitted to the journal track of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECMLPKDD) 2024 in partnership with the Data Mining and Knowledge Discovery journal. Source code of the method is available at <a href="http://github.com/ML-KULeuven/locomotif">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Time Series Motif Discovery (TSMD) refers to the task of identifying patterns
that occur multiple times (possibly with minor variations) in a time series.
All existing methods for TSMD have one or more of the following limitations:
they only look for the two most similar occurrences of a pattern; they only
look for patterns of a pre-specified, fixed length; they cannot handle
variability along the time axis; and they only handle univariate time series.
In this paper, we present a new method, LoCoMotif, that has none of these
limitations. The method is motivated by a concrete use case from physiotherapy.
We demonstrate the value of the proposed method on this use case. We also
introduce a new quantitative evaluation metric for motif discovery, and
benchmark data for comparing TSMD methods. LoCoMotif substantially outperforms
the existing methods, on top of being more broadly applicable.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17583" title="Abstract">arXiv:2311.17583</a> [<a href="/pdf/2311.17583" title="Download PDF">pdf</a>, <a href="/format/2311.17583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIPC8: Face liveness detection algorithm based on image-text pairs and  contrastive learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yurong Song</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Wenzhe Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Face recognition technology is widely used in the financial field, and
various types of liveness attack behaviors need to be addressed. Existing
liveness detection algorithms are trained on specific training datasets and
tested on testing datasets, but their performance and robustness in
transferring to unseen datasets are relatively poor. To tackle this issue, we
propose a face liveness detection method based on image-text pairs and
contrastive learning, dividing liveness attack problems in the financial field
into eight categories and using text information to describe the images of
these eight types of attacks. The text encoder and image encoder are used to
extract feature vector representations for the classification description text
and face images, respectively. By maximizing the similarity of positive samples
and minimizing the similarity of negative samples, the model learns shared
representations between images and texts. The proposed method is capable of
effectively detecting specific liveness attack behaviors in certain scenarios,
such as those occurring in dark environments or involving the tampering of ID
card photos. Additionally, it is also effective in detecting traditional
liveness attack methods, such as printing photo attacks and screen remake
attacks. The zero-shot capabilities of face liveness detection on five public
datasets, including NUAA, CASIA-FASD, Replay-Attack, OULU-NPU and MSU-MFSD also
reaches the level of commercial algorithms. The detection capability of
proposed algorithm was verified on 5 types of testing datasets, and the results
show that the method outperformed commercial algorithms, and the detection
rates reached 100% on multiple datasets. Demonstrating the effectiveness and
robustness of introducing image-text pairs and contrastive learning into
liveness detection tasks as proposed in this paper.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17586" title="Abstract">arXiv:2311.17586</a> [<a href="/pdf/2311.17586" title="Download PDF">pdf</a>, <a href="/format/2311.17586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Online and Bandit Convex Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patel%2C+K+K">Kumar Kshitij Patel</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lingxiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+A">Aadirupa Saha</a>, 
<a href="/search/cs?searchtype=author&query=Sebro%2C+N">Nati Sebro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study the problems of distributed online and bandit convex optimization
against an adaptive adversary. We aim to minimize the average regret on $M$
machines working in parallel over $T$ rounds with $R$ intermittent
communications. Assuming the underlying cost functions are convex and can be
generated adaptively, our results show that collaboration is not beneficial
when the machines have access to the first-order gradient information at the
queried points. This is in contrast to the case for stochastic functions, where
each machine samples the cost functions from a fixed distribution. Furthermore,
we delve into the more challenging setting of federated online optimization
with bandit (zeroth-order) feedback, where the machines can only access values
of the cost functions at the queried points. The key finding here is
identifying the high-dimensional regime where collaboration is beneficial and
may even lead to a linear speedup in the number of machines. We further
illustrate our findings through federated adversarial linear bandits by
developing novel distributed single and two-point feedback algorithms. Our work
is the first attempt towards a systematic understanding of federated online
optimization with limited feedback, and it attains tight regret bounds in the
intermittent communication setting for both first and zeroth-order feedback.
Our results thus bridge the gap between stochastic and adaptive settings in
federated online optimization.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17587" title="Abstract">arXiv:2311.17587</a> [<a href="/pdf/2311.17587" title="Download PDF">pdf</a>, <a href="/format/2311.17587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning Graphs: Feedback Motion Planning via Neural  Lyapunov Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ghanbarzadeh%2C+A">Armin Ghanbarzadeh</a>, 
<a href="/search/eess?searchtype=author&query=Najafi%2C+E">Esmaeil Najafi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Recent advancements in model-free deep reinforcement learning have enabled
efficient agent training. However, challenges arise when determining the region
of attraction for these controllers, especially if the region does not fully
cover the desired area. This paper addresses this issue by introducing a
feedback motion control algorithm that utilizes data-driven techniques and
neural networks. The algorithm constructs a graph of connected
reinforcement-learning based controllers, each with its own defined region of
attraction. This incremental approach effectively covers a bounded region of
interest, creating a trajectory of interconnected nodes that guide the system
from an initial state to the goal. Two approaches are presented for connecting
nodes within the algorithm. The first is a tree-structured method, facilitating
"point-to-point" control by constructing a tree connecting the initial state to
the goal state. The second is a graph-structured method, enabling
"space-to-space" control by building a graph within a bounded region. This
approach allows for control from arbitrary initial and goal states. The
proposed method's performance is evaluated on a first-order dynamic system,
considering scenarios both with and without obstacles. The results demonstrate
the effectiveness of the proposed algorithm in achieving the desired control
objectives.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17589" title="Abstract">arXiv:2311.17589</a> [<a href="/pdf/2311.17589" title="Download PDF">pdf</a>, <a href="/format/2311.17589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergent Outcomes of the veToken Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lloyd%2C+T">Thomas Lloyd</a>, 
<a href="/search/cs?searchtype=author&query=O%27Broin%2C+D">Daire O&#x27;Broin</a>, 
<a href="/search/cs?searchtype=author&query=Harrigan%2C+M">Martin Harrigan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Decentralised organisations use blockchains as a basis for governance: they
use on-chain transactions to allocate voting weight, publish proposals, cast
votes, and enact the results.
<br />However, blockchain-based governance structures have challenges, mostly
notably, the need to align the short-term outlook of pseudononymous voters with
the long-term growth and success of the decentralised organisation. The
Vote-Escrowed Token (veToken) model attempts to resolve this tension by
requiring voters to escrow or lock tokens of value for an extended period in
exchange for voting weight.
<br />In this paper, we describe the veToken model and analyse its emergent
outcomes. We show that voting behaviour follows bribes set by higher-level
protocols, and that the cost per vote varies depending on how it is acquired.
We describe the implementation of the veToken model by Curve Finance, a popular
automated market maker for stablecoins, and the ecosystem of protocols that has
arisen on top of this implementation. We show that voting markets such as
Votium largely determine the outcome of fortnightly votes held by Convex
Finance, and we show that Frax Finance, a stablecoin issuer, plays a central
role in the ecosystem even though they directly lock relatively few tokens with
Curve. Instead, they indirectly lock tokens through yield aggregators such as
Convex Finance and purchase voting weight through voting markets such as
Votium.
<br />Although the veToken model in isolation is straight-forward and easily
explained, it leads to many complex and emergent outcomes. Decentralised
organisations should consider these outcomes before adopting the model.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17590" title="Abstract">arXiv:2311.17590</a> [<a href="/pdf/2311.17590" title="Download PDF">pdf</a>, <a href="/format/2311.17590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SyncTalk: The Devil is in the Synchronization for Talking Head Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Ziqiao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wentao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yue Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiangyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaomei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jun He</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongyan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhaoxin Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Achieving high synchronization in the synthesis of realistic, speech-driven
talking head videos presents a significant challenge. Traditional Generative
Adversarial Networks (GAN) struggle to maintain consistent facial identity,
while Neural Radiance Fields (NeRF) methods, although they can address this
issue, often produce mismatched lip movements, inadequate facial expressions,
and unstable head poses. A lifelike talking head requires synchronized
coordination of subject identity, lip movements, facial expressions, and head
poses. The absence of these synchronizations is a fundamental flaw, leading to
unrealistic and artificial outcomes. To address the critical issue of
synchronization, identified as the "devil" in creating realistic talking heads,
we introduce SyncTalk. This NeRF-based method effectively maintains subject
identity, enhancing synchronization and realism in talking head synthesis.
SyncTalk employs a Face-Sync Controller to align lip movements with speech and
innovatively uses a 3D facial blendshape model to capture accurate facial
expressions. Our Head-Sync Stabilizer optimizes head poses, achieving more
natural head movements. The Portrait-Sync Generator restores hair details and
blends the generated head with the torso for a seamless visual experience.
Extensive experiments and user studies demonstrate that SyncTalk outperforms
state-of-the-art methods in synchronization and realism. We recommend watching
the supplementary video: https://ziqiaopeng.github.io/synctalk
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17592" title="Abstract">arXiv:2311.17592</a> [<a href="/pdf/2311.17592" title="Download PDF">pdf</a>, <a href="/ps/2311.17592" title="Download PostScript">ps</a>, <a href="/format/2311.17592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Correlated Equilibrium: Definition and Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Misra%2C+R">Rahul Misra</a>, 
<a href="/search/eess?searchtype=author&query=Wisniewski%2C+R">Rafa&#x142; Wisniewski</a>, 
<a href="/search/eess?searchtype=author&query=Kalles%C3%B8e%2C+C+S">Carsten Skovmose Kalles&#xf8;e</a>, 
<a href="/search/eess?searchtype=author&query=Bujorianu%2C+M+L">Manuela L. Bujorianu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint submitted to Automatica
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Multiagent Systems (cs.MA); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study N-player finite games with costs perturbed due to time-varying
disturbances in the underlying system and to that end we propose the concept of
Robust Correlated Equilibrium that generalizes the definition of Correlated
Equilibrium. Conditions under which the Robust Correlated Equilibrium exists
are specified and a decentralized algorithm for learning strategies that are
optimal in the sense of Robust Correlated Equilibrium is proposed. The primary
contribution of the paper is the convergence analysis of the algorithm and to
that end, we propose an extension of the celebrated Blackwell's Approachability
theorem to games with costs that are not just time-average as in the original
Blackwell's Approachability Theorem but also include time-average of previous
algorithm iterates. The designed algorithm is applied to a practical water
distribution network with pumps being the controllers and their costs being
perturbed by uncertain consumption by consumers. Simulation results show that
each controller achieves no regret and empirical distributions converge to the
Robust Correlated Equilibrium.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17593" title="Abstract">arXiv:2311.17593</a> [<a href="/pdf/2311.17593" title="Download PDF">pdf</a>, <a href="/format/2311.17593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LanGWM: Language Grounded World Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poudel%2C+R+P+K">Rudra P.K. Poudel</a>, 
<a href="/search/cs?searchtype=author&query=Pandya%2C+H">Harit Pandya</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cipolla%2C+R">Roberto Cipolla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
<p class="mathjax">Recent advances in deep reinforcement learning have showcased its potential
in tackling complex tasks. However, experiments on visual control tasks have
revealed that state-of-the-art reinforcement learning models struggle with
out-of-distribution generalization. Conversely, expressing higher-level
concepts and global contexts is relatively easy using language.
<br />Building upon recent success of the large language models, our main objective
is to improve the state abstraction technique in reinforcement learning by
leveraging language for robust action selection. Specifically, we focus on
learning language-grounded visual features to enhance the world model learning,
a model-based reinforcement learning technique.
<br />To enforce our hypothesis explicitly, we mask out the bounding boxes of a few
objects in the image observation and provide the text prompt as descriptions
for these masked objects. Subsequently, we predict the masked objects along
with the surrounding regions as pixel reconstruction, similar to the
transformer-based masked autoencoder approach.
<br />Our proposed LanGWM: Language Grounded World Model achieves state-of-the-art
performance in out-of-distribution test at the 100K interaction steps
benchmarks of iGibson point navigation tasks. Furthermore, our proposed
technique of explicit language-grounded visual representation learning has the
potential to improve models for human-robot interaction because our extracted
visual features are language grounded.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17597" title="Abstract">arXiv:2311.17597</a> [<a href="/pdf/2311.17597" title="Download PDF">pdf</a>, <a href="/format/2311.17597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Self-supervised Learning: Towards Universal Multi-modal  Medical Data Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yiwen Ye</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yutong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianpeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Ziyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yong Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Self-supervised learning is an efficient pre-training method for medical
image analysis. However, current research is mostly confined to
specific-modality data pre-training, consuming considerable time and resources
without achieving universality across different modalities. A straightforward
solution is combining all modality data for joint self-supervised pre-training,
which poses practical challenges. Firstly, our experiments reveal conflicts in
representation learning as the number of modalities increases. Secondly,
multi-modal data collected in advance cannot cover all real-world scenarios. In
this paper, we reconsider versatile self-supervised learning from the
perspective of continual learning and propose MedCoSS, a continuous
self-supervised learning approach for multi-modal medical data. Unlike joint
self-supervised learning, MedCoSS assigns different modality data to different
training stages, forming a multi-stage pre-training process. To balance modal
conflicts and prevent catastrophic forgetting, we propose a rehearsal-based
continual learning method. We introduce the k-means sampling strategy to retain
data from previous modalities and rehearse it when learning new modalities.
Instead of executing the pretext task on buffer data, a feature distillation
strategy and an intra-modal mixup strategy are applied to these data for
knowledge retention. We conduct continuous self-supervised pre-training on a
large-scale multi-modal unlabeled dataset, including clinical reports, X-rays,
CT scans, MRI scans, and pathological images. Experimental results demonstrate
MedCoSS's exceptional generalization ability across nine downstream datasets
and its significant scalability in integrating new modality data. Code and
pre-trained weight are available at https://github.com/yeerwen/MedCoSS.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17598" title="Abstract">arXiv:2311.17598</a> [<a href="/pdf/2311.17598" title="Download PDF">pdf</a>, <a href="/format/2311.17598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving embedding of graphs with missing data by soft manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marinoni%2C+A">Andrea Marinoni</a>, 
<a href="/search/cs?searchtype=author&query=Lio%27%2C+P">Pietro Lio&#x27;</a>, 
<a href="/search/cs?searchtype=author&query=Barp%2C+A">Alessandro Barp</a>, 
<a href="/search/cs?searchtype=author&query=Jutten%2C+C">Christian Jutten</a>, 
<a href="/search/cs?searchtype=author&query=Girolami%2C+M">Mark Girolami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Geometry (cs.CG)

</div>
<p class="mathjax">Embedding graphs in continous spaces is a key factor in designing and
developing algorithms for automatic information extraction to be applied in
diverse tasks (e.g., learning, inferring, predicting). The reliability of graph
embeddings directly depends on how much the geometry of the continuous space
matches the graph structure. Manifolds are mathematical structure that can
enable to incorporate in their topological spaces the graph characteristics,
and in particular nodes distances. State-of-the-art of manifold-based graph
embedding algorithms take advantage of the assumption that the projection on a
tangential space of each point in the manifold (corresponding to a node in the
graph) would locally resemble a Euclidean space. Although this condition helps
in achieving efficient analytical solutions to the embedding problem, it does
not represent an adequate set-up to work with modern real life graphs, that are
characterized by weighted connections across nodes often computed over sparse
datasets with missing records. In this work, we introduce a new class of
manifold, named soft manifold, that can solve this situation. In particular,
soft manifolds are mathematical structures with spherical symmetry where the
tangent spaces to each point are hypocycloids whose shape is defined according
to the velocity of information propagation across the data points. Using soft
manifolds for graph embedding, we can provide continuous spaces to pursue any
task in data analysis over complex datasets. Experimental results on
reconstruction tasks on synthetic and real datasets show how the proposed
approach enable more accurate and reliable characterization of graphs in
continuous spaces with respect to the state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17600" title="Abstract">arXiv:2311.17600</a> [<a href="/pdf/2311.17600" title="Download PDF">pdf</a>, <a href="/format/2311.17600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Query-Relevant Images Jailbreak Large Multi-Modal Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yichen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yunshi Lan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technique report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Warning: This paper contains examples of harmful language and images, and
reader discretion is recommended. The security concerns surrounding Large
Language Models (LLMs) have been extensively explored, yet the safety of Large
Multi-Modal Models (LMMs) remains understudied. In our study, we present a
novel visual prompt attack that exploits query-relevant images to jailbreak the
open-source LMMs. Our method creates a composite image from one image generated
by diffusion models and another that displays the text as typography, based on
keywords extracted from a malicious query. We show LLMs can be easily attacked
by our approach, even if the employed Large Language Models are safely aligned.
To evaluate the extent of this vulnerability in open-source LMMs, we have
compiled a substantial dataset encompassing 13 scenarios with a total of 5,040
text-image pairs, using our presented attack technique. Our evaluation of 12
cutting-edge LMMs using this dataset shows the vulnerability of existing
multi-modal models on adversarial attacks. This finding underscores the need
for a concerted effort to strengthen and enhance the safety measures of
open-source LMMs against potential malicious exploits. The resource is
available at \href{this https URL}{https://github.com/isXinLiu/MM-SafetyBench}.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17601" title="Abstract">arXiv:2311.17601</a> [<a href="/pdf/2311.17601" title="Download PDF">pdf</a>, <a href="/ps/2311.17601" title="Download PostScript">ps</a>, <a href="/format/2311.17601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Learning with Low Rank Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wistuba%2C+M">Martin Wistuba</a>, 
<a href="/search/cs?searchtype=author&query=Sivaprasad%2C+P+T">Prabhu Teja Sivaprasad</a>, 
<a href="/search/cs?searchtype=author&query=Balles%2C+L">Lukas Balles</a>, 
<a href="/search/cs?searchtype=author&query=Zappella%2C+G">Giovanni Zappella</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Workshop on Distribution Shifts (DistShift), NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent work using pretrained transformers has shown impressive performance
when fine-tuned with data from the downstream problem of interest. However,
they struggle to retain that performance when the data characteristics changes.
In this paper, we focus on continual learning, where a pre-trained transformer
is updated to perform well on new data, while retaining its performance on data
it was previously trained on. Earlier works have tackled this primarily through
methods inspired from prompt tuning. We question this choice, and investigate
the applicability of Low Rank Adaptation (LoRA) to continual learning. On a
range of domain-incremental learning benchmarks, our LoRA-based solution,
CoLoR, yields state-of-the-art performance, while still being as parameter
efficient as the prompt tuning based methods.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17603" title="Abstract">arXiv:2311.17603</a> [<a href="/pdf/2311.17603" title="Download PDF">pdf</a>, <a href="/format/2311.17603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> sec-certs: Examining the security certification practice for better  vulnerability mitigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Janovsky%2C+A">Adam Janovsky</a>, 
<a href="/search/cs?searchtype=author&query=Jancar%2C+J">Jan Jancar</a>, 
<a href="/search/cs?searchtype=author&query=Svenda%2C+P">Petr Svenda</a>, 
<a href="/search/cs?searchtype=author&query=Chmielewski%2C+%C5%81">&#x141;ukasz Chmielewski</a>, 
<a href="/search/cs?searchtype=author&query=Michalik%2C+J">Jiri Michalik</a>, 
<a href="/search/cs?searchtype=author&query=Matyas%2C+V">Vashek Matyas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Products certified under security certification frameworks such as Common
Criteria undergo significant scrutiny during the costly certification process.
Yet, critical vulnerabilities, including private key recovery (ROCA, Minerva,
TPM-Fail...), get discovered in certified products with high assurance levels.
Furthermore, assessing which certified products are impacted by such
vulnerabilities is complicated due to the large amount of unstructured
certification-related data and unclear relationships between the certificates.
To address these problems, we conducted a large-scale automated analysis of
Common Criteria and FIPS 140 certificates. We trained unsupervised models to
learn which vulnerabilities from NIST's National Vulnerability Database impact
existing certified products and how certified products reference each other.
Our tooling automates the analysis of tens of thousands of
certification-related documents, extracting machine-readable features where
manual analysis is unattainable. Further, we identify the security requirements
that are associated with products being affected by fewer and less severe
vulnerabilities (on average). This indicates which aspects of certification
correlate with higher security. We demonstrate how our tool can be used for
better vulnerability mitigation on four case studies of known, high-profile
vulnerabilities. All tools and continuously updated results are available at
https://seccerts.org.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17604" title="Abstract">arXiv:2311.17604</a> [<a href="/pdf/2311.17604" title="Download PDF">pdf</a>, <a href="/format/2311.17604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Poisson-disk Subsampling for Massive Point Cloud Decimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Comino-Trinidad%2C+M">Marc Comino-Trinidad</a>, 
<a href="/search/cs?searchtype=author&query=Chica%2C+A">Antonio Chica</a>, 
<a href="/search/cs?searchtype=author&query=and%C3%BAjar%2C+C">Carlos and&#xfa;jar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">Scanning devices often produce point clouds exhibiting highly uneven
distributions of point samples across the surfaces being captured. Different
point cloud subsampling techniques have been proposed to generate more evenly
distributed samples. Poisson-disk sampling approaches assign each sample a cost
value so that subsampling reduces to sorting the samples by cost and then
removing the desired ratio of samples with the highest cost. Unfortunately,
these approaches compute the sample cost using pairwise distances of the points
within a constant search radius, which is very costly for massive point clouds
with uneven densities. In this paper, we revisit Poisson-disk sampling for
point clouds. Instead of optimizing for equal densities, we propose to maximize
the distance to the closest point, which is equivalent to estimating the local
point density as a value inversely proportional to this distance. This
algorithm can be efficiently implemented using k nearest-neighbors searches.
Besides a kd-tree, our algorithm also uses a voxelization to speed up the
searches required to compute per-sample costs. We propose a new strategy to
minimize cost updates that is amenable for out-of-core operation. We
demonstrate the benefits of our approach in terms of performance, scalability,
and output quality. We also discuss extensions based on adding
orientation-based and color-based terms to the cost function.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17607" title="Abstract">arXiv:2311.17607</a> [<a href="/pdf/2311.17607" title="Download PDF">pdf</a>, <a href="/format/2311.17607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topology-Preserving Adversarial Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mi%2C+X">Xiaoyue Mi</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+F">Fan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+Y">Yepeng Weng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Danding Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Juan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Sheng Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite the effectiveness in improving the robustness of neural networks,
adversarial training has suffered from the natural accuracy degradation
problem, i.e., accuracy on natural samples has reduced significantly. In this
study, we reveal that natural accuracy degradation is highly related to the
disruption of the natural sample topology in the representation space by
quantitative and qualitative experiments. Based on this observation, we propose
Topology-pReserving Adversarial traINing (TRAIN) to alleviate the problem by
preserving the topology structure of natural samples from a standard model
trained only on natural samples during adversarial training. As an additional
regularization, our method can easily be combined with various popular
adversarial training algorithms in a plug-and-play manner, taking advantage of
both sides. Extensive experiments on CIFAR-10, CIFAR-100, and Tiny ImageNet
show that our proposed method achieves consistent and significant improvements
over various strong baselines in most cases. Specifically, without additional
data, our proposed method achieves up to 8.78% improvement in natural accuracy
and 4.50% improvement in robust accuracy.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17608" title="Abstract">arXiv:2311.17608</a> [<a href="/pdf/2311.17608" title="Download PDF">pdf</a>, <a href="/format/2311.17608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Robust Memory-Based Continual Learner
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mi%2C+X">Xiaoyue Mi</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+F">Fan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zonghan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Danding Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Juan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite the remarkable advances that have been made in continual learning,
the adversarial vulnerability of such methods has not been fully discussed. We
delve into the adversarial robustness of memory-based continual learning
algorithms and observe limited robustness improvement by directly applying
adversarial training techniques. Preliminary studies reveal the twin challenges
for building adversarial robust continual learners: accelerated forgetting in
continual learning and gradient obfuscation in adversarial robustness. In this
study, we put forward a novel adversarial robust memory-based continual learner
that adjusts data logits to mitigate the forgetting of pasts caused by
adversarial samples. Furthermore, we devise a gradient-based data selection
mechanism to overcome the gradient obfuscation caused by limited stored data.
The proposed approach can widely integrate with existing memory-based continual
learning as well as adversarial training algorithms in a plug-and-play way.
Extensive experiments on Split-CIFAR10/100 and Split-Tiny-ImageNet demonstrate
the effectiveness of our approach, achieving up to 8.13% higher accuracy for
adversarial data.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17609" title="Abstract">arXiv:2311.17609</a> [<a href="/pdf/2311.17609" title="Download PDF">pdf</a>, <a href="/format/2311.17609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnyLens: A Generative Diffusion Model with Any Rendering Lens
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Voynov%2C+A">Andrey Voynov</a>, 
<a href="/search/cs?searchtype=author&query=Hertz%2C+A">Amir Hertz</a>, 
<a href="/search/cs?searchtype=author&query=Arar%2C+M">Moab Arar</a>, 
<a href="/search/cs?searchtype=author&query=Fruchter%2C+S">Shlomi Fruchter</a>, 
<a href="/search/cs?searchtype=author&query=Cohen-Or%2C+D">Daniel Cohen-Or</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">State-of-the-art diffusion models can generate highly realistic images based
on various conditioning like text, segmentation, and depth. However, an
essential aspect often overlooked is the specific camera geometry used during
image capture. The influence of different optical systems on the final scene
appearance is frequently overlooked. This study introduces a framework that
intimately integrates a text-to-image diffusion model with the particular lens
geometry used in image rendering. Our method is based on a per-pixel coordinate
conditioning method, enabling the control over the rendering geometry. Notably,
we demonstrate the manipulation of curvature properties, achieving diverse
visual effects, such as fish-eye, panoramic views, and spherical texturing
using a single diffusion model.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17617" title="Abstract">arXiv:2311.17617</a> [<a href="/pdf/2311.17617" title="Download PDF">pdf</a>, <a href="/format/2311.17617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Framework for Multi-Hop Wireless Relaying with Hardware  Impairments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soleimani-Nasab%2C+E">Ehsan Soleimani-Nasab</a>, 
<a href="/search/cs?searchtype=author&query=Coleri%2C+S">Sinem Coleri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 figures, journal paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Relaying increases the coverage area and reliability of wireless
communications systems by mitigating the fading effect on the received signal.
Most technical contributions in the context of these systems assume ideal
hardware (ID) by neglecting the non-idealities of the transceivers, which
include phase noise, in-phase/quadrature mismatch and high power amplifier
nonlinearities. These non-idealities create distortion on the received signal
by causing variations in the phase and attenuating the amplitude. The resulting
deterioration of the performance of wireless communication systems is further
magnified as the frequency of transmission increases. In this paper, we
investigate the aggregate impact of hardware impairments (HI) on the general
multi-hop relay system using amplify-and-forward (AF) and decode-and-forward
(DF) relaying techniques over a general H-fading model. H-fading model includes
free space optics, radio frequency, millimeter wave, Terahertz, and underwater
fading models. Closed-form expressions of outage probability, bit error
probability and ergodic capacity are derived in terms of H-functions. Following
an asymptotic analysis at high signal-to-noise ratio (SNR), practical
optimization problems have been formulated with the objective of finding the
optimal level of HI subject to the limitation on the total HI level. The
analytical solution has been derived for the Nakagami-m fading channel which is
a special case of H-fading for AF and DF relaying techniques. The overall
instantaneous signal-to-noise-plus-distortion ratio has been demonstrated to
reach a ceiling at high SNRs which has a reciprocal proportion to the HI level
of all hops transceivers on the contrary to the ID.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17618" title="Abstract">arXiv:2311.17618</a> [<a href="/pdf/2311.17618" title="Download PDF">pdf</a>, <a href="/format/2311.17618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ShapeGPT: 3D Shape Generation with A Unified Multi-modal Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+F">Fukun Yin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Biao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zibo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jiayuan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Gang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Taihao Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The advent of large language models, enabling flexibility through
instruction-driven approaches, has revolutionized many traditional generative
tasks, but large models for 3D data, particularly in comprehensively handling
3D shapes with other modalities, are still under-explored. By achieving
instruction-based shape generations, versatile multimodal generative shape
models can significantly benefit various fields like 3D virtual construction
and network-aided design. In this work, we present ShapeGPT, a shape-included
multi-modal framework to leverage strong pre-trained language models to address
multiple shape-relevant tasks. Specifically, ShapeGPT employs a
word-sentence-paragraph framework to discretize continuous shapes into shape
words, further assembles these words for shape sentences, as well as integrates
shape with instructional text for multi-modal paragraphs. To learn this
shape-language model, we use a three-stage training scheme, including shape
representation, multimodal alignment, and instruction-based generation, to
align shape-language codebooks and learn the intricate correlations among these
modalities. Extensive experiments demonstrate that ShapeGPT achieves comparable
performance across shape-relevant tasks, including text-to-shape,
shape-to-text, shape completion, and shape editing.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17620" title="Abstract">arXiv:2311.17620</a> [<a href="/pdf/2311.17620" title="Download PDF">pdf</a>, <a href="/format/2311.17620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear Matching of JavaScript Regular Expressions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barri%C3%A8re%2C+A">Aur&#xe8;le Barri&#xe8;re</a> (EPFL), 
<a href="/search/cs?searchtype=author&query=Pit-Claudel%2C+C">Cl&#xe9;ment Pit-Claudel</a> (EPFL)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">Modern regex languages have strayed far from well-understood traditional
regular expressions: they include features that fundamentally transform the
matching problem. In exchange for these features, modern regex engines at times
suffer from exponential complexity blowups, a frequent source of
denial-of-service vulnerabilities in JavaScript applications. Worse, regex
semantics differ across languages, and the impact of these divergences on
algorithmic design and worst-case matching complexity has seldom been
investigated.
<br />This paper provides a novel perspective on JavaScript's regex semantics by
identifying a larger-than-previously-understood subset of the language that can
be matched with linear time guarantees. In the process, we discover several
cases where state-of-the-art algorithms were either wrong (semantically
incorrect), inefficient (suffering from superlinear complexity) or excessively
restrictive (assuming certain features could not be matched linearly). We
introduce novel algorithms to restore correctness and linear complexity. We
further advance the state-of-the-art in linear regex matching by presenting the
first nonbacktracking algorithms for matching lookarounds in linear time: one
supporting captureless lookbehinds in any regex language, and another
leveraging a JavaScript property to support unrestricted lookaheads and
lookbehinds. Finally, we describe new time and space complexity tradeoffs for
regex engines. All of our algorithms are practical: we validated them in a
prototype implementation, and some have also been merged in the V8 JavaScript
implementation used in Chrome and Node.js.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17621" title="Abstract">arXiv:2311.17621</a> [<a href="/pdf/2311.17621" title="Download PDF">pdf</a>, <a href="/format/2311.17621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The AutoSPADA Platform: User-Friendly Edge Computing for Distributed  Learning and Data Analytics in Connected Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nilsson%2C+A">Adrian Nilsson</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+S">Simon Smith</a>, 
<a href="/search/cs?searchtype=author&query=Hagmar%2C+J">Jonas Hagmar</a>, 
<a href="/search/cs?searchtype=author&query=%C3%96nnheim%2C+M">Magnus &#xd6;nnheim</a>, 
<a href="/search/cs?searchtype=author&query=Jirstrand%2C+M">Mats Jirstrand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 figures, 3 tables, 1 algorithm, 1 code listing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Contemporary connected vehicles host numerous applications, such as
diagnostics and navigation, and new software is continuously being developed.
However, the development process typically requires offline batch processing of
large data volumes. In an edge computing approach, data analysts and developers
can instead process sensor data directly on computational resources inside
vehicles. This enables rapid prototyping to shorten development cycles and
reduce the time to create new business values or insights. This paper presents
the design, implementation, and operation of the AutoSPADA edge computing
platform for distributed data analytics. The platform's design follows
scalability, reliability, resource efficiency, privacy, and security principles
promoted through mature and industrially proven technologies. In AutoSPADA,
computational tasks are general Python scripts, and we provide a library to,
for example, read signals from the vehicle and publish results to the cloud.
Hence, users only need Python knowledge to use the platform. Moreover, the
platform is designed to be extended to support additional programming
languages.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17626" title="Abstract">arXiv:2311.17626</a> [<a href="/pdf/2311.17626" title="Download PDF">pdf</a>, <a href="/format/2311.17626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Focus on Query: Adversarial Mining Transformer for Few-Shot Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+N">Naisong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianzhu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Few-shot segmentation (FSS) aims to segment objects of new categories given
only a handful of annotated samples. Previous works focus their efforts on
exploring the support information while paying less attention to the mining of
the critical query branch. In this paper, we rethink the importance of support
information and propose a new query-centric FSS model Adversarial Mining
Transformer (AMFormer), which achieves accurate query image segmentation with
only rough support guidance or even weak support labels. The proposed AMFormer
enjoys several merits. First, we design an object mining transformer (G) that
can achieve the expansion of incomplete region activated by support clue, and a
detail mining transformer (D) to discriminate the detailed local difference
between the expanded mask and the ground truth. Second, we propose to train G
and D via an adversarial process, where G is optimized to generate more
accurate masks approaching ground truth to fool D. We conduct extensive
experiments on commonly used Pascal-5i and COCO-20i benchmarks and achieve
state-of-the-art results across all settings. In addition, the decent
performance with weak support labels in our query-centric paradigm may inspire
the development of more general FSS models. Code will be available at
https://github.com/Wyxdm/AMNet.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17627" title="Abstract">arXiv:2311.17627</a> [<a href="/pdf/2311.17627" title="Download PDF">pdf</a>, <a href="/format/2311.17627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invisible Women in Digital Diplomacy: A Multidimensional Framework for  Online Gender Bias Against Women Ambassadors Worldwide
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Golovchenko%2C+Y">Yevgeniy Golovchenko</a>, 
<a href="/search/cs?searchtype=author&query=Sta%C5%84czak%2C+K">Karolina Sta&#x144;czak</a>, 
<a href="/search/cs?searchtype=author&query=Adler-Nissen%2C+R">Rebecca Adler-Nissen</a>, 
<a href="/search/cs?searchtype=author&query=Wangen%2C+P">Patrice Wangen</a>, 
<a href="/search/cs?searchtype=author&query=Augenstein%2C+I">Isabelle Augenstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Despite mounting evidence that women in foreign policy often bear the brunt
of online hostility, the extent of online gender bias against diplomats remains
unexplored. This paper offers the first global analysis of the treatment of
women diplomats on social media. Introducing a multidimensional and
multilingual methodology for studying online gender bias, it focuses on three
critical elements: gendered language, negativity in tweets directed at
diplomats, and the visibility of women diplomats. Our unique dataset
encompasses ambassadors from 164 countries, their tweets, and the direct
responses to these tweets in 65 different languages. Using automated content
and sentiment analysis, our findings reveal a crucial gender bias. The language
in responses to diplomatic tweets is only mildly gendered and largely pertains
to international affairs and, generally, women ambassadors do not receive more
negative reactions to their tweets than men, yet the pronounced discrepancy in
online visibility stands out as a significant form of gender bias. Women
receive a staggering 66.4% fewer retweets than men. By unraveling the
invisibility that obscures women diplomats on social media, we hope to spark
further research on online bias in international politics.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17629" title="Abstract">arXiv:2311.17629</a> [<a href="/pdf/2311.17629" title="Download PDF">pdf</a>, <a href="/format/2311.17629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Decoder for End-to-End Oriented Object Detection in Remote  Sensing Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiaqi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zeyu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hancheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Wenliang Du</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+R">Rui Yao</a>, 
<a href="/search/cs?searchtype=author&query=Saddik%2C+A+E">Abdulmotaleb El Saddik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Object instances in remote sensing images often distribute with
multi-orientations, varying scales, and dense distribution. These issues bring
challenges to end-to-end oriented object detectors including multi-scale
features alignment and a large number of queries. To address these limitations,
we propose an end-to-end oriented detector equipped with an efficient decoder,
which incorporates two technologies, Rotated RoI attention (RRoI attention) and
Selective Distinct Queries (SDQ). Specifically, RRoI attention effectively
focuses on oriented regions of interest through a cross-attention mechanism and
aligns multi-scale features. SDQ collects queries from intermediate decoder
layers and then filters similar queries to obtain distinct queries. The
proposed SDQ can facilitate the optimization of one-to-one label assignment,
without introducing redundant initial queries or extra auxiliary branches.
Extensive experiments on five datasets demonstrate the effectiveness of our
method. Notably, our method achieves state-of-the-art performance on DIOR-R
(67.31% mAP), DOTA-v1.5 (67.43% mAP), and DOTA-v2.0 (53.28% mAP) with the
ResNet50 backbone.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17630" title="Abstract">arXiv:2311.17630</a> [<a href="/pdf/2311.17630" title="Download PDF">pdf</a>, <a href="/format/2311.17630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimization in Mobile Augmented Reality Systems for the Metaverse over  Wireless Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lan%2C+T">Tianming Lan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper appears in IEEE Global Communications Conference (GLOBECOM) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">As the essential technical support for Metaverse, Mobile Augmented Reality
(MAR) has attracted the attention of many researchers. MAR applications rely on
real-time processing of visual and audio data, and thus those heavy workloads
can quickly drain the battery of a mobile device. To address such problem,
edge-based solutions have appeared for handling some tasks that require more
computing power. However, such strategies introduce a new trade-off: reducing
the network latency and overall energy consumption requires limiting the size
of the data sent to the edge server, which, in turn, results in lower accuracy.
In this paper, we design an edge-based MAR system and propose a mathematical
model to describe it and analyze the trade-off between latency, accuracy,
server resources allocation and energy consumption. Furthermore, an algorithm
named LEAO is proposed to solve this problem. We evaluate the performance of
the LEAO and other related algorithms across various simulation scenarios. The
results demonstrate the superiority of the LEAO algorithm. Finally, our work
provides insight into optimization problem in edge-based MAR system for
Metaverse.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17631" title="Abstract">arXiv:2311.17631</a> [<a href="/pdf/2311.17631" title="Download PDF">pdf</a>, <a href="/format/2311.17631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Q-learning Based Optimal False Data Injection Attack on Probabilistic  Boolean Control Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Peng%2C+X">Xianlun Peng</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+Y">Yang Tang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+F">Fangfei Li</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we present a reinforcement learning (RL) method for solving
optimal false data injection attack problems in probabilistic Boolean control
networks (PBCNs) where the attacker lacks knowledge of the system model.
Specifically, we employ a Q-learning (QL) algorithm to address this problem. We
then propose an improved QL algorithm that not only enhances learning
efficiency but also obtains optimal attack strategies for large-scale PBCNs
that the standard QL algorithm cannot handle. Finally, we verify the
effectiveness of our proposed approach by considering two attacked PBCNs,
including a 10-node network and a 28-node network.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17633" title="Abstract">arXiv:2311.17633</a> [<a href="/pdf/2311.17633" title="Download PDF">pdf</a>, <a href="/format/2311.17633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Introduction to Transformers: an NLP Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Tong Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jingbo Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 119 pages and 21 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Transformers have dominated empirical machine learning models of natural
language processing. In this paper, we introduce basic concepts of Transformers
and present key techniques that form the recent advances of these models. This
includes a description of the standard Transformer architecture, a series of
model refinements, and common applications. Given that Transformers and related
deep learning techniques might be evolving in ways we have never seen, we
cannot dive into all the model details or cover all the technical areas.
Instead, we focus on just those concepts that are helpful for gaining a good
understanding of Transformers and their variants. We also summarize the key
ideas that impact this field, thereby yielding some insights into the strengths
and limitations of these models.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17634" title="Abstract">arXiv:2311.17634</a> [<a href="/pdf/2311.17634" title="Download PDF">pdf</a>, <a href="/format/2311.17634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Erasing the Ephemeral: Joint Camera Refinement and Transient Object  Removal for Street View Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deka%2C+M+S">Mreenav Shyam Deka</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+L">Lu Sang</a>, 
<a href="/search/cs?searchtype=author&query=Cremers%2C+D">Daniel Cremers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Synthesizing novel views for urban environments is crucial for tasks like
autonomous driving and virtual tours. Compared to object-level or indoor
situations, outdoor settings present unique challenges, such as inconsistency
across frames due to moving vehicles and camera pose drift over lengthy
sequences. In this paper, we introduce a method that tackles these challenges
on view synthesis for outdoor scenarios. We employ a neural point light field
scene representation and strategically detect and mask out dynamic objects to
reconstruct novel scenes without artifacts. Moreover, we simultaneously
optimize camera pose along with the view synthesis process, and thus, we
simultaneously refine both elements. Through validation on real-world urban
datasets, we demonstrate state-of-the-art results in synthesizing novel views
of urban scenes.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17643" title="Abstract">arXiv:2311.17643</a> [<a href="/pdf/2311.17643" title="Download PDF">pdf</a>, <a href="/format/2311.17643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Fields with Thermal Activations for Arbitrary-Scale  Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Becker%2C+A">Alexander Becker</a>, 
<a href="/search/cs?searchtype=author&query=Daudt%2C+R+C">Rodrigo Caye Daudt</a>, 
<a href="/search/cs?searchtype=author&query=Metzger%2C+N">Nando Metzger</a>, 
<a href="/search/cs?searchtype=author&query=Wegner%2C+J+D">Jan Dirk Wegner</a>, 
<a href="/search/cs?searchtype=author&query=Schindler%2C+K">Konrad Schindler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent approaches for arbitrary-scale single image super-resolution (ASSR)
have used local neural fields to represent continuous signals that can be
sampled at different rates. However, in such formulation, the point-wise query
of field values does not naturally match the point spread function (PSF) of a
given pixel. In this work we present a novel way to design neural fields such
that points can be queried with a Gaussian PSF, which serves as anti-aliasing
when moving across resolutions for ASSR. We achieve this using a novel
activation function derived from Fourier theory and the heat equation. This
comes at no additional cost: querying a point with a Gaussian PSF in our
framework does not affect computational cost, unlike filtering in the image
domain. Coupled with a hypernetwork, our method not only provides theoretically
guaranteed anti-aliasing, but also sets a new bar for ASSR while also being
more parameter-efficient than previous methods.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17647" title="Abstract">arXiv:2311.17647</a> [<a href="/pdf/2311.17647" title="Download PDF">pdf</a>, <a href="/format/2311.17647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VIM: Probing Multimodal Large Language Models for Visual Embedded  Instruction Following
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yujie Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiujun Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W+Y">William Yang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yejin Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 8 figures, 20 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">We introduce VISUAL EMBEDDED INSTRUCTION (VIM), a new framework designed to
evaluate the visual instruction following capability of Multimodal Large
Language Models (MLLMs). As illustrated in Figure 2, VIM challenges the MLLMs
by embedding the instructions into the visual scenes, demanding strong visual
interpretative skills for instruction following. We adapt VIM to various
benchmarks, including VQAv2, MME, MM-Vet, and RefCOCO series, compose a VIM
bench, and probe diverse MLLMs across three distinct in-context learning
settings: Zero Shot, One Shot, and Pair Shot. We observe that there is a
significant performance disparity between the open-source MLLMs and GPT-4V,
implying that their proficiency in visual instruction comprehension is not up
to par. Our results highlight a promising direction for the enhancement of
MLLMs capabilities on instruction following. We aim VIM to serve as a useful
norm for advancing the state of the art and driving further progress in the
field.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17650" title="Abstract">arXiv:2311.17650</a> [<a href="/pdf/2311.17650" title="Download PDF">pdf</a>, <a href="/format/2311.17650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Creator Context for Tweet Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hombaiah%2C+S+A">Spurthi Amba Hombaiah</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bendersky%2C+M">Michael Bendersky</a>, 
<a href="/search/cs?searchtype=author&query=Najork%2C+M">Marc Najork</a>, 
<a href="/search/cs?searchtype=author&query=Colen%2C+M">Matt Colen</a>, 
<a href="/search/cs?searchtype=author&query=Levi%2C+S">Sergey Levi</a>, 
<a href="/search/cs?searchtype=author&query=Ofitserov%2C+V">Vladimir Ofitserov</a>, 
<a href="/search/cs?searchtype=author&query=Amin%2C+T">Tanvir Amin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">When discussing a tweet, people usually not only refer to the content it
delivers, but also to the person behind the tweet. In other words, grounding
the interpretation of the tweet in the context of its creator plays an
important role in deciphering the true intent and the importance of the tweet.
<br />In this paper, we attempt to answer the question of how creator context
should be used to advance tweet understanding. Specifically, we investigate the
usefulness of different types of creator context, and examine different model
structures for incorporating creator context in tweet modeling. We evaluate our
tweet understanding models on a practical use case -- recommending relevant
tweets to news articles. This use case already exists in popular news apps, and
can also serve as a useful assistive tool for journalists. We discover that
creator context is essential for tweet understanding, and can improve
application metrics by a large margin. However, we also observe that not all
creator contexts are equal. Creator context can be time sensitive and noisy.
Careful creator context selection and deliberate model structure design play an
important role in creator context effectiveness.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17655" title="Abstract">arXiv:2311.17655</a> [<a href="/pdf/2311.17655" title="Download PDF">pdf</a>, <a href="/format/2311.17655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vulnerability of Automatic Identity Recognition to Audio-Visual  Deepfakes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Korshunov%2C+P">Pavel Korshunov</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haolin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Garner%2C+P+N">Philip N. Garner</a>, 
<a href="/search/cs?searchtype=author&query=Marcel%2C+S">Sebastien Marcel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The task of deepfakes detection is far from being solved by speech or vision
researchers. Several publicly available databases of fake synthetic video and
speech were built to aid the development of detection methods. However,
existing databases typically focus on visual or voice modalities and provide no
proof that their deepfakes can in fact impersonate any real person. In this
paper, we present the first realistic audio-visual database of deepfakes
SWAN-DF, where lips and speech are well synchronized and video have high visual
and audio qualities. We took the publicly available SWAN dataset of real videos
with different identities to create audio-visual deepfakes using several models
from DeepFaceLab and blending techniques for face swapping and HiFiVC, DiffVC,
YourTTS, and FreeVC models for voice conversion. From the publicly available
speech dataset LibriTTS, we also created a separate database of only audio
deepfakes LibriTTS-DF using several latest text to speech methods: YourTTS,
Adaspeech, and TorToiSe. We demonstrate the vulnerability of a state of the art
speaker recognition system, such as ECAPA-TDNN-based model from SpeechBrain, to
the synthetic voices. Similarly, we tested face recognition system based on the
MobileFaceNet architecture to several variants of our visual deepfakes. The
vulnerability assessment show that by tuning the existing pretrained deepfake
models to specific identities, one can successfully spoof the face and speaker
recognition systems in more than 90% of the time and achieve a very realistic
looking and sounding fake video of a given person.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17656" title="Abstract">arXiv:2311.17656</a> [<a href="/pdf/2311.17656" title="Download PDF">pdf</a>, <a href="/format/2311.17656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiple Toddler Tracking in Indoor Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amraee%2C+S">Somaieh Amraee</a>, 
<a href="/search/cs?searchtype=author&query=Galoaa%2C+B">Bishoy Galoaa</a>, 
<a href="/search/cs?searchtype=author&query=Goodwin%2C+M">Matthew Goodwin</a>, 
<a href="/search/cs?searchtype=author&query=Hatamimajoumerd%2C+E">Elaheh Hatamimajoumerd</a>, 
<a href="/search/cs?searchtype=author&query=Ostadabbas%2C+S">Sarah Ostadabbas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multiple toddler tracking (MTT) involves identifying and differentiating
toddlers in video footage. While conventional multi-object tracking (MOT)
algorithms are adept at tracking diverse objects, toddlers pose unique
challenges due to their unpredictable movements, various poses, and similar
appearance. Tracking toddlers in indoor environments introduces additional
complexities such as occlusions and limited fields of view. In this paper, we
address the challenges of MTT and propose MTTSort, a customized method built
upon the DeepSort algorithm. MTTSort is designed to track multiple toddlers in
indoor videos accurately. Our contributions include discussing the primary
challenges in MTT, introducing a genetic algorithm to optimize hyperparameters,
proposing an accurate tracking algorithm, and curating the MTTrack dataset
using unbiased AI co-labeling techniques. We quantitatively compare MTTSort to
state-of-the-art MOT methods on MTTrack, DanceTrack, and MOT15 datasets. In our
evaluation, the proposed method outperformed other MOT methods, achieving 0.98,
0.68, and 0.98 in multiple object tracking accuracy (MOTA), higher order
tracking accuracy (HOTA), and iterative and discriminative framework 1 (IDF1)
metrics, respectively.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17657" title="Abstract">arXiv:2311.17657</a> [<a href="/pdf/2311.17657" title="Download PDF">pdf</a>, <a href="/format/2311.17657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Volumetric Cloud Field Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jacob Lin</a>, 
<a href="/search/cs?searchtype=author&query=Farinha%2C+M">Miguel Farinha</a>, 
<a href="/search/cs?searchtype=author&query=Gryspeerdt%2C+E">Edward Gryspeerdt</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+R">Ronald Clark</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page at <a href="https://cloud-field.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Volumetric phenomena, such as clouds and fog, present a significant challenge
for 3D reconstruction systems due to their translucent nature and their complex
interactions with light. Conventional techniques for reconstructing scattering
volumes rely on controlled setups, limiting practical applications. This paper
introduces an approach to reconstructing volumes from a few input stereo pairs.
We propose a novel deep learning framework that integrates a deep stereo model
with a 3D Convolutional Neural Network (3D CNN) and an advection module,
capable of capturing the shape and dynamics of volumes. The stereo depths are
used to carve empty space around volumes, providing the 3D CNN with a prior for
coping with the lack of input views. Refining our output, the advection module
leverages the temporal evolution of the medium, providing a mechanism to infer
motion and improve temporal consistency. The efficacy of our system is
demonstrated through its ability to estimate density and velocity fields of
large-scale volumes, in this case, clouds, from a sparse set of stereo image
pairs.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17662" title="Abstract">arXiv:2311.17662</a> [<a href="/pdf/2311.17662" title="Download PDF">pdf</a>, <a href="/ps/2311.17662" title="Download PostScript">ps</a>, <a href="/format/2311.17662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Issue Report Validation in an Industrial Context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aktas%2C+E+U">Ethem Utku Aktas</a>, 
<a href="/search/cs?searchtype=author&query=Cakmak%2C+E">Ebru Cakmak</a>, 
<a href="/search/cs?searchtype=author&query=Inan%2C+M+C">Mete Cihad Inan</a>, 
<a href="/search/cs?searchtype=author&query=Yilmaz%2C+C">Cemal Yilmaz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE'23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Effective issue triaging is crucial for software development teams to improve
software quality, and thus customer satisfaction. Validating issue reports
manually can be time-consuming, hindering the overall efficiency of the
triaging process. This paper presents an approach on automating the validation
of issue reports to accelerate the issue triaging process in an industrial
set-up. We work on 1,200 randomly selected issue reports in banking domain,
written in Turkish, an agglutinative language, meaning that new words can be
formed with linear concatenation of suffixes to express entire sentences. We
manually label these reports for validity, and extract the relevant patterns
indicating that they are invalid. Since the issue reports we work on are
written in an agglutinative language, we use morphological analysis to extract
the features. Using the proposed feature extractors, we utilize a machine
learning based approach to predict the issue reports' validity, performing a
0.77 F1-score.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17663" title="Abstract">arXiv:2311.17663</a> [<a href="/pdf/2311.17663" title="Download PDF">pdf</a>, <a href="/format/2311.17663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cam4DOcc: Benchmark for Camera-Only 4D Occupancy Forecasting in  Autonomous Driving Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Junyi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xieyuanli Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiawei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jingyi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhen Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jintao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+W">Weihao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+R">Rui Ai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hesheng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Understanding how the surrounding environment changes is crucial for
performing downstream tasks safely and reliably in autonomous driving
applications. Recent occupancy estimation techniques using only camera images
as input can provide dense occupancy representations of large-scale scenes
based on the current observation. However, they are mostly limited to
representing the current 3D space and do not consider the future state of
surrounding objects along the time axis. To extend camera-only occupancy
estimation into spatiotemporal prediction, we propose Cam4DOcc, a new benchmark
for camera-only 4D occupancy forecasting, evaluating the surrounding scene
changes in a near future. We build our benchmark based on multiple publicly
available datasets, including nuScenes, nuScenes-Occupancy, and Lyft-Level5,
which provides sequential occupancy states of general movable and static
objects, as well as their 3D backward centripetal flow. To establish this
benchmark for future research with comprehensive comparisons, we introduce four
baseline types from diverse camera-based perception and prediction
implementations, including a static-world occupancy model, voxelization of
point cloud prediction, 2D-3D instance-based prediction, and our proposed novel
end-to-end 4D occupancy forecasting network. Furthermore, the standardized
evaluation protocol for preset multiple tasks is also provided to compare the
performance of all the proposed baselines on present and future occupancy
estimation with respect to objects of interest in autonomous driving scenarios.
The dataset and our implementation of all four baselines in the proposed
Cam4DOcc benchmark will be released here: https://github.com/haomo-ai/Cam4DOcc.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17664" title="Abstract">arXiv:2311.17664</a> [<a href="/pdf/2311.17664" title="Download PDF">pdf</a>, <a href="/format/2311.17664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Convergence Rate of Linear Datalogo over Stable Semirings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Im%2C+S">Sungjin Im</a>, 
<a href="/search/cs?searchtype=author&query=Moseley%2C+B">Benjamin Moseley</a>, 
<a href="/search/cs?searchtype=author&query=Ngo%2C+H">Hung Ngo</a>, 
<a href="/search/cs?searchtype=author&query=Pruhs%2C+K">Kirk Pruhs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Datalogo is an extension of Datalog, where instead of a program being a
collection of union of conjunctive queries over the standard Boolean semiring,
a program may now be a collection of sum-sum-product queries over an arbitrary
commutative partially ordered pre-semiring. Datalogo is more powerful than
Datalog in that its additional algebraic structure alows for supporting
recursion with aggregation. At the same time, Datalogo retains the syntactic
and semantic simplicity of Datalog: Datalogo has declarative least fixpoint
semantics. The least fixpoint can be found via the na\"ive evaluation algorithm
that repeatedly applies the immediate sequence opeator until no further change
is possible.
<br />It was shown that, when the underlying semiring is $p$-stable, then the naive
evaluation of any Datalogo program over the semiring converges in a finite
number of steps. However, the upper bounds on the rate of convergence were
exponential in the number of ground IDB atoms.
<br />This paper establishes polynomial upper bounds on the convergence rate of the
na\"ive algorithm on {\bf linear} Datalogo programs, which is quite common in
practice. In particular, the main result of this paper is that the convergence
rate of linear Datalogo programs under any $p$-stable semiring is $O(pn^3)$.
Furthermore, we show a matching lower bound by constructing a $p$-stable
semiring and a linear Datalogo program that requires $\Omega(pn^3)$ iterations
for the na\"ive iteration algorithm to converge. Next, we study the convergence
rate in terms of the number of elements in the semiring for linear Datalogo
programs. When $L$ is the number of elements, the convergence rate is bounded
by $O(pn \log L)$. This significantly improves the convergence rate for small
$L$. We show a nearly matching lower bound as well.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17665" title="Abstract">arXiv:2311.17665</a> [<a href="/pdf/2311.17665" title="Download PDF">pdf</a>, <a href="/ps/2311.17665" title="Download PostScript">ps</a>, <a href="/format/2311.17665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Irradiation Tests for Commercial Off-the Shelf Components with  Atmospheric-like Neutrons and Heavy-Ions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Branchini%2C+P">Paolo Branchini</a> (1), 
<a href="/search/eess?searchtype=author&query=Fabbri%2C+A">Andrea Fabbri</a> (1), 
<a href="/search/eess?searchtype=author&query=Cormenier%2C+S">Sacha Cormenier</a> (1 and 2), 
<a href="/search/eess?searchtype=author&query=Bernardini%2C+M">Marco Bernardini</a> (1 and 2), 
<a href="/search/eess?searchtype=author&query=Romanelli%2C+G">Giovanni Romanelli</a> (3), 
<a href="/search/eess?searchtype=author&query=Preziosi%2C+E">Enrico Preziosi</a> (3), 
<a href="/search/eess?searchtype=author&query=Senesi%2C+R">Roberto Senesi</a> (3), 
<a href="/search/eess?searchtype=author&query=Andreani%2C+C">Carla Andreani</a> (3), 
<a href="/search/eess?searchtype=author&query=Frost%2C+C">C. Frost</a> (4), 
<a href="/search/eess?searchtype=author&query=Cazzaniga%2C+C">Carlo Cazzaniga</a> (4), 
<a href="/search/eess?searchtype=author&query=Catalano%2C+T+F">Toni Fabio Catalano</a> (5), 
<a href="/search/eess?searchtype=author&query=Buffardo%2C+M">Mario Buffardo</a> (5) ((1) INFN, Roma Tre Section, (2) Maths and Physics Department, Universit&#xe0; degli Studi di Roma Roma Tre, (3) NAST Centre and Physics Department, Universit&#xe0; degli Studi di Roma Tor Vergata, (4) Thales Alenia Space Italia, (5) ISIS Facility, STFC Rutherford Appleton Laboratory)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 10 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents the results of the irradiation, performed with
atmospheric-like neutrons and heavy-ions, of Commercial Off-the Shelf
Components (COTS), which can be used in space missions. In such cases, it is
crucial to perform tests in a radiation environment that emulates the
environment of different orbits around Earth. In our study we used
atmosphericlike neutrons with fluences up to 1011 neutrons/cm-2 and Kr ions of
fluences up to 107 ions/cm-2. These intensities are augmented with respect to
the atmospheric one in order to shorten the irradiation time while simulating a
long-time exposure during a possible mission in Low Earth Orbit (LEO). A
similar radiation environment to LEO can also be present during High-Energy
Physics experiments. Therefore, the study herby reported can also be helpful
for accelerator physics. In this paper we show in detail procedures, setup and
results we have obtained on a commercial device normally exploited in
automotive environments.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17667" title="Abstract">arXiv:2311.17667</a> [<a href="/pdf/2311.17667" title="Download PDF">pdf</a>, <a href="/format/2311.17667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TimeBench: A Comprehensive Evaluation of Temporal Reasoning Abilities in  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+Z">Zheng Chu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingchang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qianglong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Weijiang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haotian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Ming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+B">Bing Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Resources at: <a href="https://github.com/zchuz/TimeBench">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Understanding time is a pivotal aspect of human cognition, crucial in the
broader framework of grasping the intricacies of the world. Previous studies
typically focus on specific aspects of time, lacking a comprehensive temporal
reasoning benchmark. To address this issue, we propose TimeBench, a
comprehensive hierarchical temporal reasoning benchmark that covers a broad
spectrum of temporal reasoning phenomena, which provides a thorough evaluation
for investigating the temporal reasoning capabilities of large language models.
We conduct extensive experiments on popular LLMs, such as GPT-4, LLaMA2, and
Mistral, incorporating chain-of-thought prompting. Our experimental results
indicate a significant performance gap between the state-of-the-art LLMs and
humans, highlighting that there is still a considerable distance to cover in
temporal reasoning. We aspire for TimeBench to serve as a comprehensive
benchmark, fostering research in temporal reasoning for LLMs. Our resource is
available at https://github.com/zchuz/TimeBench
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17668" title="Abstract">arXiv:2311.17668</a> [<a href="/pdf/2311.17668" title="Download PDF">pdf</a>, <a href="/format/2311.17668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RACED: Routing in Payment Channel Networks Using Distributed Hash Tables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kolachala%2C+K">Kartick Kolachala</a>, 
<a href="/search/cs?searchtype=author&query=Ababneh%2C+M">Mohammed Ababneh</a>, 
<a href="/search/cs?searchtype=author&query=Vishwanathan%2C+R">Roopa Vishwanathan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A short version of this work has been accepted to the 19th ACM ASIA Conference on Computer and Communications Security (ACM ASIACCS 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">The Bitcoin scalability problem has led to the development of off-chain
financial mechanisms such as payment channel networks (PCNs) which help users
process transactions of varying amounts, including micro-payment transactions,
without writing each transaction to the blockchain. Since PCNs only allow
path-based transactions, effective, secure routing protocols that find a path
between a sender and receiver are fundamental to PCN operations. In this paper,
we propose RACED, a routing protocol that leverages the idea of Distributed
Hash Tables (DHTs) to route transactions in PCNs in a fast and secure way. Our
experiments on real-world transaction datasets show that RACED gives an average
transaction success ratio of 98.74%, an average pathfinding time of 31.242
seconds, which is $1.65*10^3$, $1.8*10^3$, and $4*10^2$ times faster than three
other recent routing protocols that offer comparable security/privacy
properties. We rigorously analyze and prove the security of RACED in the
Universal Composability framework.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17676" title="Abstract">arXiv:2311.17676</a> [<a href="/pdf/2311.17676" title="Download PDF">pdf</a>, <a href="/format/2311.17676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Minority Stress Detection with Emotions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ivey%2C+J">Jonathan Ivey</a>, 
<a href="/search/cs?searchtype=author&query=Gauch%2C+S">Susan Gauch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Psychological stress detection is an important task for mental healthcare
research, but there has been little prior work investigating the effectiveness
of psychological stress models on minority individuals, who are especially
vulnerable to poor mental health outcomes. In this work, we use the related
task of minority stress detection to evaluate the ability of psychological
stress models to understand the language of sexual and gender minorities. We
find that traditional psychological stress models underperform on minority
stress detection, and we propose using emotion-infused models to reduce that
performance disparity. We further demonstrate that multi-task psychological
stress models outperform the current state-of-the-art for minority stress
detection without directly training on minority stress data. We provide
explanatory analysis showing that minority communities have different
distributions of emotions than the general population and that emotion-infused
models improve the performance of stress models on underrepresented groups
because of their effectiveness in low-data environments, and we propose that
integrating emotions may benefit underrepresented groups in other mental health
detection tasks.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17681" title="Abstract">arXiv:2311.17681</a> [<a href="/pdf/2311.17681" title="Download PDF">pdf</a>, <a href="/format/2311.17681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Intersection Management for Non-Communicative Autonomous  Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Katole%2C+R">Rugved Katole</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+A">Arpita Sinha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 11 figures 3 tables. Pre-print version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">This paper addresses the traffic management problem for autonomous vehicles
at intersections without traffic signals. In the current system, a road
junction has no traffic signals when the traffic volume is low to medium.
Installing infrastructure at each unsignalled crossing to coordinate autonomous
cars can be formidable. We propose a novel decentralized strategy where the
vehicles use a harmony matrix to find the best possible combination of the cars
to cross the intersection without any crashes. We formulate a maximal clique
problem using harmony matrix that maximizes the intersection throughput. This
algorithm does not require communication between the vehicles. We compared our
work with state-of-the-art communicative strategies and widely used traditional
and modern methods for intersection management. Through extensive simulation,
we showed that our algorithm is comparable to state-of-the-art and outperforms
traditional methods.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17684" title="Abstract">arXiv:2311.17684</a> [<a href="/pdf/2311.17684" title="Download PDF">pdf</a>, <a href="/format/2311.17684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Who can help me? Reconstructing users&#x27; psychological journeys in  depression-related social media interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morini%2C+V">Virginia Morini</a>, 
<a href="/search/cs?searchtype=author&query=Citraro%2C+S">Salvatore Citraro</a>, 
<a href="/search/cs?searchtype=author&query=Sajno%2C+E">Elena Sajno</a>, 
<a href="/search/cs?searchtype=author&query=Sansoni%2C+M">Maria Sansoni</a>, 
<a href="/search/cs?searchtype=author&query=Riva%2C+G">Giuseppe Riva</a>, 
<a href="/search/cs?searchtype=author&query=Stella%2C+M">Massimo Stella</a>, 
<a href="/search/cs?searchtype=author&query=Rossetti%2C+G">Giulio Rossetti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> main article + supporting information
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Social media are increasingly being used as self-help boards, where
individuals can disclose personal experiences and feelings and look for support
from peers or experts. Here we investigate several popular mental
health-related Reddit boards about depression while proposing a novel
psycho-social framework. We reconstruct users' psychological/linguistic
profiles together with their social interactions. We cover a total of 303,016
users, engaging in 378,483 posts and 1,475,044 comments from 01/05/2018 to
01/05/2020. After identifying a network of users' interactions, e.g., who
replied to whom, we open an unprecedented window over psycholinguistic,
cognitive, and affective digital traces with relevance for mental health
research. Through user-generated content, we identify four categories or
archetypes of users in agreement with the Patient Health Engagement model: the
emotionally turbulent/under blackout, the aroused, the adherent-yet-conflicted,
and the eudaimonically hopeful. Analyzing users' transitions over time through
conditional Markov processes, we show how these four archetypes are not
consecutive stages. We do not find a linear progression or sequential patient
journey, where users evolve from struggling to serenity through feelings of
conflict. Instead, we find online users to follow spirals towards both negative
and positive archetypal stages. Through psychological/linguistic and social
network modelling, we can provide compelling quantitative pieces of evidence on
how such a complex path unfolds through positive, negative, and conflicting
online contexts. Our approach opens the way to data-informed understandings of
psychological coping with mental health issues through social media.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17686" title="Abstract">arXiv:2311.17686</a> [<a href="/pdf/2311.17686" title="Download PDF">pdf</a>, <a href="/ps/2311.17686" title="Download PostScript">ps</a>, <a href="/format/2311.17686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AviationGPT: A Large Language Model for the Aviation Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liya Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chou%2C+J">Jason Chou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tien%2C+A">Alex Tien</a>, 
<a href="/search/cs?searchtype=author&query=Baumgartner%2C+D+M">Diane M Baumgartner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The advent of ChatGPT and GPT-4 has captivated the world with large language
models (LLMs), demonstrating exceptional performance in question-answering,
summarization, and content generation. The aviation industry is characterized
by an abundance of complex, unstructured text data, replete with technical
jargon and specialized terminology. Moreover, labeled data for model building
are scarce in this domain, resulting in low usage of aviation text data. The
emergence of LLMs presents an opportunity to transform this situation, but
there is a lack of LLMs specifically designed for the aviation domain. To
address this gap, we propose AviationGPT, which is built on open-source LLaMA-2
and Mistral architectures and continuously trained on a wealth of carefully
curated aviation datasets. Experimental results reveal that AviationGPT offers
users multiple advantages, including the versatility to tackle diverse natural
language processing (NLP) problems (e.g., question-answering, summarization,
document writing, information extraction, report querying, data cleaning, and
interactive data exploration). It also provides accurate and contextually
relevant responses within the aviation domain and significantly improves
performance (e.g., over a 40% performance gain in tested cases). With
AviationGPT, the aviation industry is better equipped to address more complex
research problems and enhance the efficiency and safety of National Airspace
System (NAS) operations.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17688" title="Abstract">arXiv:2311.17688</a> [<a href="/pdf/2311.17688" title="Download PDF">pdf</a>, <a href="/format/2311.17688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> mango: A Modular Python-Based Agent Simulation Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schrage%2C+R">Rico Schrage</a>, 
<a href="/search/cs?searchtype=author&query=Sager%2C+J">Jens Sager</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B6rding%2C+J+P">Jan Philipp H&#xf6;rding</a>, 
<a href="/search/cs?searchtype=author&query=Holly%2C+S">Stefanie Holly</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">Agent-based simulations, especially those including communication, are
complex to model and execute. To help researchers deal with this complexity and
to encourage modular and maintainable research software, the Python-based
framework mango (modular python agent framework) has been developed. The
framework enables users to quickly implement software agents with different
communication protocols (e.g., TCP) and message codecs (e.g., JSON).
Furthermore, mango provides various options for developing an integrated agent
simulation. This includes a scheduler module, which can control the agents'
tasks, a (distributed) clock mechanism for time synchronization, and a specific
simulation component, which can be coupled with other (co-)simulation software.
These features are complemented by modular implementation patterns and a
well-evaluated performance with the ability to simulate across multiple
processes to ensure scalability.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17693" title="Abstract">arXiv:2311.17693</a> [<a href="/pdf/2311.17693" title="Download PDF">pdf</a>, <a href="/format/2311.17693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward a Surgeon-in-the-Loop Ophthalmic Robotic Apprentice using  Reinforcement and Imitation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gomaa%2C+A">Amr Gomaa</a>, 
<a href="/search/cs?searchtype=author&query=Mahdy%2C+B">Bilal Mahdy</a>, 
<a href="/search/cs?searchtype=author&query=Kleer%2C+N">Niko Kleer</a>, 
<a href="/search/cs?searchtype=author&query=Kr%C3%BCger%2C+A">Antonio Kr&#xfc;ger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Robotic-assisted surgical systems have demonstrated significant potential in
enhancing surgical precision and minimizing human errors. However, existing
systems lack the ability to accommodate the unique preferences and requirements
of individual surgeons. Additionally, they primarily focus on general surgeries
(e.g., laparoscopy) and are not suitable for highly precise microsurgeries,
such as ophthalmic procedures. Thus, we propose a simulation-based image-guided
approach for surgeon-centered autonomous agents that can adapt to the
individual surgeon's skill level and preferred surgical techniques during
ophthalmic cataract surgery. Our approach utilizes a simulated environment to
train reinforcement and imitation learning agents guided by image data to
perform all tasks of the incision phase of cataract surgery. By integrating the
surgeon's actions and preferences into the training process with the
surgeon-in-the-loop, our approach enables the robot to implicitly learn and
adapt to the individual surgeon's unique approach through demonstrations. This
results in a more intuitive and personalized surgical experience for the
surgeon. Simultaneously, it ensures consistent performance for the autonomous
robotic apprentice. We define and evaluate the effectiveness of our approach
using our proposed metrics; and highlight the trade-off between a generic agent
and a surgeon-centered adapted agent. Moreover, our approach has the potential
to extend to other ophthalmic surgical procedures, opening the door to a new
generation of surgeon-in-the-loop autonomous surgical robots. We provide an
open-source simulation framework for future development and reproducibility.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17695" title="Abstract">arXiv:2311.17695</a> [<a href="/pdf/2311.17695" title="Download PDF">pdf</a>, <a href="/format/2311.17695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Text-to-Image Diffusion via Fair Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Lijie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tianhang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we address the limitations of existing text-to-image diffusion
models in generating demographically fair results when given human-related
descriptions. These models often struggle to disentangle the target language
context from sociocultural biases, resulting in biased image generation. To
overcome this challenge, we propose Fair Mapping, a general, model-agnostic,
and lightweight approach that modifies a pre-trained text-to-image model by
controlling the prompt to achieve fair image generation. One key advantage of
our approach is its high efficiency. The training process only requires
updating a small number of parameters in an additional linear mapping network.
This not only reduces the computational cost but also accelerates the
optimization process. We first demonstrate the issue of bias in generated
results caused by language biases in text-guided diffusion models. By
developing a mapping network that projects language embeddings into an unbiased
space, we enable the generation of relatively balanced demographic results
based on a keyword specified in the prompt. With comprehensive experiments on
face image generation, we show that our method significantly improves image
generation performance when prompted with descriptions related to human faces.
By effectively addressing the issue of bias, we produce more fair and diverse
image outputs. This work contributes to the field of text-to-image generation
by enhancing the ability to generate images that accurately reflect the
intended demographic characteristics specified in the text.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17696" title="Abstract">arXiv:2311.17696</a> [<a href="/pdf/2311.17696" title="Download PDF">pdf</a>, <a href="/ps/2311.17696" title="Download PostScript">ps</a>, <a href="/format/2311.17696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Build an AI Tutor that Can Adapt to Any Course and Provide  Accurate Answers Using Large Language Model and Retrieval-Augmented  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+C">Chenxi Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Artificial intelligence is transforming education through data-driven,
personalized learning solutions. This paper introduces AI Tutor, an innovative
web application that provides personalized tutoring in any subject using
state-of-the-art Large Language Model (LLM). AI Tutor ingests course materials
to construct an adaptive knowledge base tailored to the course. When students
pose questions, it retrieves the most relevant information and generates
detailed, conversational responses citing supporting evidence. The system is
powered by advanced large language models and Retrieval-Augmented Generation
(RAG) techniques for accurate, natural question answering. We present a
fully-functional web interface and video demonstration that showcase AI Tutor's
versatility across diverse subjects and its ability to produce pedagogically
cogent responses. While an initial prototype, this work represents a pioneering
step toward AI-enabled tutoring systems that can democratize access to
high-quality, customized educational support.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17697" title="Abstract">arXiv:2311.17697</a> [<a href="/pdf/2311.17697" title="Download PDF">pdf</a>, <a href="/format/2311.17697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Swarm Synergy: A Silent Way of Forming Community
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Sweksha Jain</a>, 
<a href="/search/cs?searchtype=author&query=Katole%2C+R">Rugved Katole</a>, 
<a href="/search/cs?searchtype=author&query=Vachhani%2C+L">Leena Vachhani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 Pages, 8 figures, 6 tables, pre-print version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">In this paper, we introduce a novel swarm application, swarm synergy, where
robots in a swarm intend to form communities. Each robot is considered to make
independent decisions without any communication capability (silent agent). The
proposed algorithm is based on parameters local to individual robots. Engaging
scenarios are studied where the silent robots form communities without the
preset conditions on the number of communities, community size, goal location
of each community, and specific members in the community. Our approach allows
silent robots to achieve this self-organized swarm behavior using only sensory
inputs from the environment. The algorithm facilitates the formation of
multiple swarm communities at arbitrary locations with unspecified goal
locations. We further infer the behavior of swarm synergy to ensure the
anonymity/untraceability of both robots and communities. The robots intend to
form a community by sensing the neighbors, creating synergy in a bounded
environment. The time to achieve synergy depends on the environment boundary
and the onboard sensor's field of view. Compared to the state-of-art with
similar objectives, the proposed communication-free swarm synergy shows
comparative time to synergize with untraceability features.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17704" title="Abstract">arXiv:2311.17704</a> [<a href="/pdf/2311.17704" title="Download PDF">pdf</a>, <a href="/format/2311.17704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient Algorithm for Unbalanced 1D Transportation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gouvine%2C+G">Gabriel Gouvine</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Optimal transport (OT) and unbalanced optimal transport (UOT) are central in
many machine learning, statistics and engineering applications. 1D OT is easily
solved, with complexity O(n log n), but no efficient algorithm was known for 1D
UOT. We present a new approach that leverages the successive shortest path
algorithm for the corresponding network flow problem. By employing a suitable
representation, we bundle together multiple steps that do not change the cost
of the shortest path. We prove that our algorithm solves 1D UOT in O(n log n),
closing the gap.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17705" title="Abstract">arXiv:2311.17705</a> [<a href="/pdf/2311.17705" title="Download PDF">pdf</a>, <a href="/format/2311.17705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Q-PAC: Automated Detection of Quantum Bug-Fix Patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nayak%2C+P+K">Pranav K. Nayak</a>, 
<a href="/search/cs?searchtype=author&query=Kher%2C+K+V">Krishn V. Kher</a>, 
<a href="/search/cs?searchtype=author&query=Chandra%2C+M+B">M. Bharat Chandra</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+M+V+P">M. V. Panduranga Rao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Context: Bug-fix pattern detection has been investigated in the past in the
context of classical software. However, while quantum software is developing
rapidly, the literature still lacks automated methods and tools to identify,
analyze, and detect bug-fix patterns. To the best of our knowledge, our work
previously published in SEKE'23 was the first to leverage classical techniques
to detect bug-fix patterns in quantum code.
<br />Objective: To extend our previous effort, we present a research agenda
(Q-Repair), including a series of testing and debugging methodologies, to
improve the quality of quantum software. The ultimate goal is to utilize
machine learning techniques to automatically predict fix patterns for existing
quantum bugs.
<br />Method: As part of the first stage of the agenda, we extend our initial study
and propose a more comprehensive automated framework, called Q-PAC, for
detecting bug-fix patterns in IBM Qiskit quantum code. In the framework, we
develop seven bug-fix pattern detectors using abstract syntax trees, syntactic
filters, and semantic checks.
<br />Results: To demonstrate our method, we run Q-PAC on a variety of quantum
bug-fix patterns using both real-world and handcrafted examples of bugs and
fixes. The experimental results show that Q-PAC can effectively identify
bug-fix patterns in IBM Qiskit.
<br />Conclusion: We hope our initial study on quantum bug-fix detection can bring
awareness of quantum software engineering to both researchers and
practitioners. Thus, we also publish Q-PAC as an open-source software on
GitHub. We would like to encourage other researchers to work on research
directions (such as Q-Repair) to improve the quality of the quantum
programming.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17707" title="Abstract">arXiv:2311.17707</a> [<a href="/pdf/2311.17707" title="Download PDF">pdf</a>, <a href="/format/2311.17707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAMPro3D: Locating SAM Prompts in 3D for Zero-Shot Scene Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mutian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xingyilang Yin</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Lingteng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+X">Xin Tong</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaoguang Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://mutianxu.github.io/sampro3d/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce SAMPro3D for zero-shot 3D indoor scene segmentation. Given the
3D point cloud and multiple posed 2D frames of 3D scenes, our approach segments
3D scenes by applying the pretrained Segment Anything Model (SAM) to 2D frames.
Our key idea involves locating 3D points in scenes as natural 3D prompts to
align their projected pixel prompts across frames, ensuring frame-consistency
in both pixel prompts and their SAM-predicted masks. Moreover, we suggest
filtering out low-quality 3D prompts based on feedback from all 2D frames, for
enhancing segmentation quality. We also propose to consolidate different 3D
prompts if they are segmenting the same object, bringing a more comprehensive
segmentation. Notably, our method does not require any additional training on
domain-specific data, enabling us to preserve the zero-shot power of SAM.
Extensive qualitative and quantitative results show that our method
consistently achieves higher quality and more diverse segmentation than
previous zero-shot or fully supervised approaches, and in many cases even
surpasses human-level annotations. The project page can be accessed at
https://mutianxu.github.io/sampro3d/.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17717" title="Abstract">arXiv:2311.17717</a> [<a href="/pdf/2311.17717" title="Download PDF">pdf</a>, <a href="/format/2311.17717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Receler: Reliable Concept Erasing of Text-to-Image Diffusion Models via  Lightweight Erasers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chi-Pin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kai-Po Chang</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+C">Chung-Ting Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">Yung-Hsuan Lai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y+F">Yu-Chiang Frank Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Concept erasure in text-to-image diffusion models aims to disable pre-trained
diffusion models from generating images related to a target concept. To perform
reliable concept erasure, the properties of robustness and locality are
desirable. The former refrains the model from producing images associated with
the target concept for any paraphrased or learned prompts, while the latter
preserves the model ability in generating images for non-target concepts. In
this paper, we propose Reliable Concept Erasing via Lightweight Erasers
(Receler), which learns a lightweight Eraser to perform concept erasing and
enhances locality and robustness with the proposed concept-localized
regularization and adversarial prompt learning, respectively. Comprehensive
quantitative and qualitative experiments with various concept prompts verify
the superiority of Receler over the previous erasing methods on the above two
desirable properties.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17718" title="Abstract">arXiv:2311.17718</a> [<a href="/pdf/2311.17718" title="Download PDF">pdf</a>, <a href="/ps/2311.17718" title="Download PostScript">ps</a>, <a href="/format/2311.17718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial and rational convergence rates for Laplace problems on planar  domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Trefethen%2C+L+N">Lloyd N. Trefethen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Complex Variables (math.CV)

</div>
<p class="mathjax">Laplace problems on planar domains can be solved by means of least-squares
expansions associated with polynomial or rational approximations. Here it is
shown that, even in the context of an analytic domain with analytic boundary
data, the difference in convergence rates may be huge when the domain is
nonconvex. Our proofs combine the theory of the Schwarz function for analytic
continuation, potential theory for polynomial and rational approximation rates,
and the theory of crowding of conformal maps.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17722" title="Abstract">arXiv:2311.17722</a> [<a href="/pdf/2311.17722" title="Download PDF">pdf</a>, <a href="/format/2311.17722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SenTest: Evaluating Robustness of Sentence Encoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chavan%2C+T">Tanmay Chavan</a>, 
<a href="/search/cs?searchtype=author&query=Patankar%2C+S">Shantanu Patankar</a>, 
<a href="/search/cs?searchtype=author&query=Kane%2C+A">Aditya Kane</a>, 
<a href="/search/cs?searchtype=author&query=Gokhale%2C+O">Omkar Gokhale</a>, 
<a href="/search/cs?searchtype=author&query=Kale%2C+G">Geetanjali Kale</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+R">Raviraj Joshi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Contrastive learning has proven to be an effective method for pre-training
models using weakly labeled data in the vision domain. Sentence transformers
are the NLP counterparts to this architecture, and have been growing in
popularity due to their rich and effective sentence representations. Having
effective sentence representations is paramount in multiple tasks, such as
information retrieval, retrieval augmented generation (RAG), and sentence
comparison. Keeping in mind the deployability factor of transformers,
evaluating the robustness of sentence transformers is of utmost importance.
This work focuses on evaluating the robustness of the sentence encoders. We
employ several adversarial attacks to evaluate its robustness. This system uses
character-level attacks in the form of random character substitution,
word-level attacks in the form of synonym replacement, and sentence-level
attacks in the form of intra-sentence word order shuffling. The results of the
experiments strongly undermine the robustness of sentence encoders. The models
produce significantly different predictions as well as embeddings on perturbed
datasets. The accuracy of the models can fall up to 15 percent on perturbed
datasets as compared to unperturbed datasets. Furthermore, the experiments
demonstrate that these embeddings does capture the semantic and syntactic
structure (sentence order) of sentences. However, existing supervised
classification strategies fail to leverage this information, and merely
function as n-gram detectors.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17726" title="Abstract">arXiv:2311.17726</a> [<a href="/pdf/2311.17726" title="Download PDF">pdf</a>, <a href="/format/2311.17726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-dimensional Energy Limitation in Sphere Shaping for Nonlinear  Interference Noise Mitigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingtian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Awwad%2C+%C3%89">&#xc9;lie Awwad</a>, 
<a href="/search/cs?searchtype=author&query=Jaou%C3%ABn%2C+Y">Yves Jaou&#xeb;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">We propose Four-Dimensional (4D) energy limit enumerative sphere shaping
(ESS) of $M$-QAM signaling to minimize rate loss and improve the transmission
performance over non-linear WDM optical-fiber systems. Simulation results show
that the proposed scheme outperforms the conventional ESS by
$0.19$~bit/4D-symbol in achievable information rate over a $205$-km single-span
link and a WDM transmission of five polarization-division-multiplexed channels
with $400$-Gbit/s net rate per channel. We also study the achieved performance
over several shaping block lengths and show that the achieved gains do not
scale well over multi-span systems.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17728" title="Abstract">arXiv:2311.17728</a> [<a href="/pdf/2311.17728" title="Download PDF">pdf</a>, <a href="/format/2311.17728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Know your audience
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Charron-Bost%2C+B">Bernadette Charron-Bost</a>, 
<a href="/search/cs?searchtype=author&query=Lambein-Monette%2C+P">Patrick Lambein-Monette</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Distributed function computation is the problem, for a networked system of
$n$ autonomous agents, to collectively compute the value $f(v_1, \ldots, v_n)$
of some input values, each initially private to one agent in the network. Here,
we study and organize results pertaining to distributed function computation in
anonymous networks, both for the static and the dynamic case, under a
communication model of directed and synchronous message exchanges, but with
varying assumptions in the degree of awareness or control that a single agent
has over its outneighbors.
<br />Our main argument is three-fold. First, in the "blind broadcast" model, where
in each round an agent merely casts out a unique message without any knowledge
or control over its addressees, the computable functions are those that only
depend on the set of the input values, but not on their multiplicities or
relative frequencies in the input. Second, in contrast, when we assume either
that a) in each round, the agents know how many outneighbors they have; b) all
communications links in the network are bidirectional; or c) the agents may
address each of their outneighbors individually, then the set of computable
functions grows to contain all functions that depend on the relative
frequencies of each value in the input - such as the average - but not on their
multiplicities - thus, not the sum. Third, however, if one or several agents
are distinguished as leaders, or if the cardinality of the network is known,
then under any of the above three assumptions it becomes possible to recover
the complete multiset of the input values, and thus compute any function of the
distributed input as long as it is invariant under permutation of its
arguments. In the case of dynamic networks, we also discuss the impact of
multiple connectivity assumptions.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17729" title="Abstract">arXiv:2311.17729</a> [<a href="/pdf/2311.17729" title="Download PDF">pdf</a>, <a href="/ps/2311.17729" title="Download PostScript">ps</a>, <a href="/format/2311.17729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reliability-aware Control of Power Converters in Mobility Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rezaeizadeh%2C+A">Amin Rezaeizadeh</a>, 
<a href="/search/eess?searchtype=author&query=Zardini%2C+G">Gioele Zardini</a>, 
<a href="/search/eess?searchtype=author&query=Frazzoli%2C+E">Emilio Frazzoli</a>, 
<a href="/search/eess?searchtype=author&query=Mastellone%2C+S">Silvia Mastellone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ECC 20204 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper introduces an automatic control method designed to enhance the
operation of electric vehicles, besides the speed tracking objectives, by
including reliability and lifetime requirements. The research considers an
automotive power converter which supplies electric power to a permanent magnet
synchronous motor (PMSM). The primary control objective is to mitigate the
thermal stress on the power electronic Insulate Gate Bipolar Transistors
(IGBTs), while simultaneously ensuring effective speed tracking performance. To
achieve these goals, we propose an extended H-inf design framework, which
includes reliability models. The method is tested in two distinct scenarios:
reliability-aware, and reliability-free cases. Furthermore, the paper conducts
a lifetime analysis of the IGBTs, leveraging the Rainflow algorithm and
temperature data.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17737" title="Abstract">arXiv:2311.17737</a> [<a href="/pdf/2311.17737" title="Download PDF">pdf</a>, <a href="/format/2311.17737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GenZI: Zero-Shot 3D Human-Scene Interaction Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+A">Angela Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://craigleili.github.io/projects/genzi/">this https URL</a> Video: <a href="https://youtu.be/ozfs6E0JIMY">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Can we synthesize 3D humans interacting with scenes without learning from any
3D human-scene interaction data? We propose GenZI, the first zero-shot approach
to generating 3D human-scene interactions. Key to GenZI is our distillation of
interaction priors from large vision-language models (VLMs), which have learned
a rich semantic space of 2D human-scene compositions. Given a natural language
description and a coarse point location of the desired interaction in a 3D
scene, we first leverage VLMs to imagine plausible 2D human interactions
inpainted into multiple rendered views of the scene. We then formulate a robust
iterative optimization to synthesize the pose and shape of a 3D human model in
the scene, guided by consistency with the 2D interaction hypotheses. In
contrast to existing learning-based approaches, GenZI circumvents the
conventional need for captured 3D interaction data, and allows for flexible
control of the 3D interaction synthesis with easy-to-use text prompts.
Extensive experiments show that our zero-shot approach has high flexibility and
generality, making it applicable to diverse scene types, including both indoor
and outdoor environments.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17741" title="Abstract">arXiv:2311.17741</a> [<a href="/pdf/2311.17741" title="Download PDF">pdf</a>, <a href="/ps/2311.17741" title="Download PostScript">ps</a>, <a href="/format/2311.17741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-end Joint Rich and Normalized ASR with a limited amount of rich  training data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+C">Can Cui</a> (MULTISPEECH), 
<a href="/search/cs?searchtype=author&query=Sheikh%2C+I+A">Imran Ahamad Sheikh</a>, 
<a href="/search/cs?searchtype=author&query=Sadeghi%2C+M">Mostafa Sadeghi</a> (MULTISPEECH), 
<a href="/search/cs?searchtype=author&query=Vincent%2C+E">Emmanuel Vincent</a> (MULTISPEECH)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Joint rich and normalized automatic speech recognition (ASR), that produces
transcriptions both with and without punctuation and capitalization, remains a
challenge. End-to-end (E2E) ASR models offer both convenience and the ability
to perform such joint transcription of speech. Training such models requires
paired speech and rich text data, which is not widely available. In this paper,
we compare two different approaches to train a stateless Transducer-based E2E
joint rich and normalized ASR system, ready for streaming applications, with a
limited amount of rich labeled data. The first approach uses a language model
to generate pseudo-rich transcriptions of normalized training data. The second
approach uses a single decoder conditioned on the type of the output. The first
approach leads to E2E rich ASR which perform better on out-of-domain data, with
up to 9% relative reduction in errors. The second approach demonstrates the
feasibility of an E2E joint rich and normalized ASR system using as low as 5%
rich training data with moderate (2.42% absolute) increase in errors.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17742" title="Abstract">arXiv:2311.17742</a> [<a href="/pdf/2311.17742" title="Download PDF">pdf</a>, <a href="/ps/2311.17742" title="Download PostScript">ps</a>, <a href="/format/2311.17742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Localization and Tracking of UAVs in OTFS-based Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nordio%2C+A">Alessandro Nordio</a>, 
<a href="/search/cs?searchtype=author&query=Chiasserini%2C+C+F">Carla Fabiana Chiasserini</a>, 
<a href="/search/cs?searchtype=author&query=Viterbo%2C+E">Emanuele Viterbo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">We consider the problem of accurately localizing N unmanned aerial vehicles
(UAV) in 3D space where the UAVs are part of a swarm and communicate with each
other through orthogonal time-frequency space (OTFS) modulated signals. Each
receiving UAV estimates the multipath wireless channel on each link formed by
the line-of-sight (LoS) transmission and by the single reflections from the
remaining N-2 UAVs. The estimated power delay profiles are communicated to an
edge server, which is in charge of computing the exact location and speed of
the UAVs. To obtain the UAVs locations and velocities, we propose an iterative
algorithm, named Turbo Iterative Positioning (TIP), which, using a
belief-propagation approach, effectively exploits the time difference of
arrival (TDoA) measurements between the LoS and the non-LoS paths. Enabling a
full cold start (no prior knowledge), our solution first maps each TDoA's
profile element to a specific ID of the reflecting UAV's. The Doppler shifts
measured by the OTFS receivers associated with each path are also used to
estimate the UAV's velocities. The localization of the N UAVs is then derived
via gradient descent optimization, with the aid of turbo-like iterations that
can progressively correct some of the residual errors in the initial ID mapping
operation. Our numerical results, obtained also using real-world traces, show
how the multipath links are beneficial to achieving very accurate localization
and speed of all UAVs, even with a limited delay-Doppler resolution. Robustness
of our scheme is proven by its performance approaching the Cramer-Rao bound.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17743" title="Abstract">arXiv:2311.17743</a> [<a href="/pdf/2311.17743" title="Download PDF">pdf</a>, <a href="/format/2311.17743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mukhyansh: A Headline Generation Dataset for Indic Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madasu%2C+L">Lokesh Madasu</a>, 
<a href="/search/cs?searchtype=author&query=Kanumolu%2C+G">Gopichand Kanumolu</a>, 
<a href="/search/cs?searchtype=author&query=Surange%2C+N">Nirmal Surange</a>, 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+M">Manish Shrivastava</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at PACLIC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The task of headline generation within the realm of Natural Language
Processing (NLP) holds immense significance, as it strives to distill the true
essence of textual content into concise and attention-grabbing summaries. While
noteworthy progress has been made in headline generation for widely spoken
languages like English, there persist numerous challenges when it comes to
generating headlines in low-resource languages, such as the rich and diverse
Indian languages. A prominent obstacle that specifically hinders headline
generation in Indian languages is the scarcity of high-quality annotated data.
To address this crucial gap, we proudly present Mukhyansh, an extensive
multilingual dataset, tailored for Indian language headline generation.
Comprising an impressive collection of over 3.39 million article-headline
pairs, Mukhyansh spans across eight prominent Indian languages, namely Telugu,
Tamil, Kannada, Malayalam, Hindi, Bengali, Marathi, and Gujarati. We present a
comprehensive evaluation of several state-of-the-art baseline models.
Additionally, through an empirical analysis of existing works, we demonstrate
that Mukhyansh outperforms all other models, achieving an impressive average
ROUGE-L score of 31.43 across all 8 languages.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17744" title="Abstract">arXiv:2311.17744</a> [<a href="/pdf/2311.17744" title="Download PDF">pdf</a>, <a href="/format/2311.17744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Bayes image restoration with compressive autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biquard%2C+M">Maud Biquard</a>, 
<a href="/search/cs?searchtype=author&query=Chabert%2C+M">Marie Chabert</a>, 
<a href="/search/cs?searchtype=author&query=Oberlin%2C+T">Thomas Oberlin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Regularization of inverse problems is of paramount importance in
computational imaging. The ability of neural networks to learn efficient image
representations has been recently exploited to design powerful data-driven
regularizers. While state-of-the-art plug-and-play methods rely on an implicit
regularization provided by neural denoisers, alternative Bayesian approaches
consider Maximum A Posteriori (MAP) estimation in the latent space of a
generative model, thus with an explicit regularization. However,
state-of-the-art deep generative models require a huge amount of training data
compared to denoisers. Besides, their complexity hampers the optimization of
the latent MAP. In this work, we propose to use compressive autoencoders for
latent estimation. These networks, which can be seen as variational
autoencoders with a flexible latent prior, are smaller and easier to train than
state-of-the-art generative models. We then introduce the Variational Bayes
Latent Estimation (VBLE) algorithm, which performs this estimation within the
framework of variational inference. This allows for fast and easy (approximate)
posterior sampling. Experimental results on image datasets BSD and FFHQ
demonstrate that VBLE reaches similar performance than state-of-the-art
plug-and-play methods, while being able to quantify uncertainties faster than
other existing posterior sampling techniques.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17750" title="Abstract">arXiv:2311.17750</a> [<a href="/pdf/2311.17750" title="Download PDF">pdf</a>, <a href="/format/2311.17750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Addressing Membership Inference Attack in Federated Learning with Model  Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=N%C3%A9meth%2C+G+D">Gergely D&#xe1;niel N&#xe9;meth</a>, 
<a href="/search/cs?searchtype=author&query=Lozano%2C+M+%C3%81">Miguel &#xc1;ngel Lozano</a>, 
<a href="/search/cs?searchtype=author&query=Quadrianto%2C+N">Novi Quadrianto</a>, 
<a href="/search/cs?searchtype=author&query=Oliver%2C+N">Nuria Oliver</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Federated Learning (FL) has been proposed as a privacy-preserving solution
for machine learning. However, recent works have shown that Federated Learning
can leak private client data through membership attacks. In this paper, we show
that the effectiveness of these attacks on the clients negatively correlates
with the size of the client datasets and model complexity. Based on this
finding, we propose model-agnostic Federated Learning as a privacy-enhancing
solution because it enables the use of models of varying complexity in the
clients. To this end, we present $\texttt{MaPP-FL}$, a novel privacy-aware FL
approach that leverages model compression on the clients while keeping a full
model on the server. We compare the performance of $\texttt{MaPP-FL}$ against
state-of-the-art model-agnostic FL methods on the CIFAR-10, CIFAR-100, and
FEMNIST vision datasets. Our experiments show the effectiveness of
$\texttt{MaPP-FL}$ in preserving the clients' and the server's privacy while
achieving competitive classification accuracies.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17752" title="Abstract">arXiv:2311.17752</a> [<a href="/pdf/2311.17752" title="Download PDF">pdf</a>, <a href="/format/2311.17752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BAND-2k: Banding Artifact Noticeable Database for Banding Detection and  Quality Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zijian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jun Jia</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+F">Fangfang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zicheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Ru Huang</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+X">Xiongkuo Min</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+G">Guangtao Zhai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Databases (cs.DB); Multimedia (cs.MM)

</div>
<p class="mathjax">Banding, also known as staircase-like contours, frequently occurs in flat
areas of images/videos processed by the compression or quantization algorithms.
As undesirable artifacts, banding destroys the original image structure, thus
degrading users' quality of experience (QoE). In this paper, we systematically
investigate the banding image quality assessment (IQA) problem, aiming to
detect the image banding artifacts and evaluate their perceptual visual
quality. Considering that the existing image banding databases only contain
limited content sources and banding generation methods, and lack perceptual
quality labels (i.e. mean opinion scores), we first build the largest banding
IQA database so far, named Banding Artifact Noticeable Database (BAND-2k),
which consists of 2,000 banding images generated by 15 compression and
quantization schemes. A total of 23 workers participated in the subjective IQA
experiment, yielding over 214,000 patch-level banding class labels and 44,371
reliable image-level quality ratings. Subsequently, we develop an effective
no-reference (NR) banding evaluator for banding detection and quality
assessment by leveraging frequency characteristics of banding artifacts. A dual
convolutional neural network is employed to concurrently learn the feature
representation from the high-frequency and low-frequency maps, thereby
enhancing the ability to discern banding artifacts. The quality score of a
banding image is generated by pooling the banding detection maps masked by the
spatial frequency filters. Experiments demonstrate that our banding evaluator
achieves a remarkably high accuracy in banding detection and also exhibits high
SRCC and PLCC results with the perceptual quality labels. These findings unveil
the strong correlations between the intensity of banding artifacts and the
perceptual visual quality, thus validating the necessity of banding quality
assessment.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17754" title="Abstract">arXiv:2311.17754</a> [<a href="/pdf/2311.17754" title="Download PDF">pdf</a>, <a href="/format/2311.17754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cinematic Behavior Transfer via NeRF-based Differentiable Filming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xuekun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+A">Anyi Rao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingbo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bo Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://virtualfilmstudio.github.io/projects/cinetransfer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Human-Computer Interaction (cs.HC); Multimedia (cs.MM)

</div>
<p class="mathjax">In the evolving landscape of digital media and video production, the precise
manipulation and reproduction of visual elements like camera movements and
character actions are highly desired. Existing SLAM methods face limitations in
dynamic scenes and human pose estimation often focuses on 2D projections,
neglecting 3D statuses. To address these issues, we first introduce a reverse
filming behavior estimation technique. It optimizes camera trajectories by
leveraging NeRF as a differentiable renderer and refining SMPL tracks. We then
introduce a cinematic transfer pipeline that is able to transfer various shot
types to a new 2D video or a 3D virtual environment. The incorporation of 3D
engine workflow enables superior rendering and control abilities, which also
achieves a higher rating in the user study.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17757" title="Abstract">arXiv:2311.17757</a> [<a href="/pdf/2311.17757" title="Download PDF">pdf</a>, <a href="/format/2311.17757" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Scheduling in Cloud Environment Based on Heuristic Optimization  Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiaxin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+H">Haiyang Kuang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Aiming at analyzing performance in cloud computing, some unpredictable
perturbations which may lead to performance downgrade are essential factors
that should not be neglected. To avoid performance downgrade in cloud computing
system, it is reasonable to measure the impact of the perturbations, and
further propose a robust scheduling strategy to maintain the performance of the
system at an acceptable level. In this paper, we first describe the
supply-demand relationship of service between cloud service providers and
customers, in which the profit and waiting time are objectives they most
concerned. Then, on the basis of introducing the lowest acceptable profit and
longest acceptable waiting time for cloud service providers and customers
respectively, we define a robustness metric method to declare that the number
and speed of servers should be adequately configured in a feasible region, such
that the performance of cloud computing system can stay at an acceptable level
when it is subject to the perturbations. Subsequently, we discuss the
robustness metric method in several cases, and propose heuristic optimization
algorithm to enhance the robustness of the system as much as possible. At last,
the performances of the proposed algorithm are validated by comparing with DE
and PSO algorithm, the results show the superiority of the proposed algorithm.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17766" title="Abstract">arXiv:2311.17766</a> [<a href="/pdf/2311.17766" title="Download PDF">pdf</a>, <a href="/ps/2311.17766" title="Download PostScript">ps</a>, <a href="/format/2311.17766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustness Approaches for the Examination Timetabling Problem under Data  Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bassimir%2C+B">Bernd Bassimir</a>, 
<a href="/search/cs?searchtype=author&query=Wanka%2C+R">Rolf Wanka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> original paper: 15 pages, published at the Multidisciplinary International Scheduling Conference 2019 (MISTA 2019)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In the literature the examination timetabling problem (ETTP) is often
considered a post-enrollment problem (PE-ETTP). In the real world, universities
often schedule their exams before students register using information from
previous terms. A direct consequence of this approach is the uncertainty
present in the resulting models. In this work we discuss several approaches
available in the robust optimization literature. We consider the implications
of each approach in respect to the examination timetabling problem and present
how the most favorable approaches can be applied to the ETTP. Afterwards we
analyze the impact of some possible implementations of the given robustness
approaches on two real world instances and several random instances generated
by our instance generation framework which we introduce in this work.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17769" title="Abstract">arXiv:2311.17769</a> [<a href="/pdf/2311.17769" title="Download PDF">pdf</a>, <a href="/format/2311.17769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple and General Operational Framework to Deploy Optimal Routes with  Source Routing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bramas%2C+Q">Quentin Bramas</a> (UNISTRA, ICube), 
<a href="/search/cs?searchtype=author&query=Luttringer%2C+J">Jean-Romain Luttringer</a> (UNISTRA, ICube), 
<a href="/search/cs?searchtype=author&query=M%C3%A9rindol%2C+P">Pascal M&#xe9;rindol</a> (UNISTRA, ICube)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Source Routing, currently facilitated by Segment Routing (SR), enables
precise control of forwarding paths by specifying detours (or segments) to
deviate IP packets along routes with advanced properties beyond typical
shortest IGP paths. Computing the desired optimal segment lists, known as
encoding, leads to interesting challenges as the number of detours is tightly
constrained for hardware performance. Existing solutions either lack
generality, correctness, optimality, or practical computing efficiency-in
particular for sparse realistic networks. In this paper, we address all such
challenges with GOFOR-SR. Our framework extends usual path computation
algorithms to inherently look at optimal and feasible segment lists,
streamlining the deployment of TE-compliant paths. By integrating encoding
within the path computation itself and modifying the distance comparison
method, GOFOR allows algorithms with various optimization objectives to
efficiently compute optimal segment lists. Despite the loss of substructure
optimality induced by SR, GOFOR proves particularly efficient, inducing only a
linear overhead at worst. It also offers different strategies and path
diversity options for intricate TE-aware loadbalancing. We formally prove the
correctness and optimality of GOFOR, implement our framework for various
practical usecases, and demonstrate its performance and benefits on both real
and challenging topologies.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17770" title="Abstract">arXiv:2311.17770</a> [<a href="/pdf/2311.17770" title="Download PDF">pdf</a>, <a href="/format/2311.17770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PillarNeSt: Embracing Backbone Scaling and Pretraining for Pillar-based  3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+W">Weixin Mao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tiancai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Diankun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junjie Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yoshie%2C+O">Osamu Yoshie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This paper shows the effectiveness of 2D backbone scaling and pretraining for
pillar-based 3D object detectors. Pillar-based methods mainly employ randomly
initialized 2D convolution neural network (ConvNet) for feature extraction and
fail to enjoy the benefits from the backbone scaling and pretraining in the
image domain. To show the scaling-up capacity in point clouds, we introduce the
dense ConvNet pretrained on large-scale image datasets (e.g., ImageNet) as the
2D backbone of pillar-based detectors. The ConvNets are adaptively designed
based on the model size according to the specific features of point clouds,
such as sparsity and irregularity. Equipped with the pretrained ConvNets, our
proposed pillar-based detector, termed PillarNeSt, outperforms the existing 3D
object detectors by a large margin on the nuScenes and Argoversev2 datasets.
Our code shall be released upon acceptance.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17771" title="Abstract">arXiv:2311.17771</a> [<a href="/pdf/2311.17771" title="Download PDF">pdf</a>, <a href="/format/2311.17771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supervising the Centroid Baseline for Extractive Multi-Document  Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gon%C3%A7alves%2C+S">Sim&#xe3;o Gon&#xe7;alves</a>, 
<a href="/search/cs?searchtype=author&query=Correia%2C+G">Gon&#xe7;alo Correia</a>, 
<a href="/search/cs?searchtype=author&query=Pernes%2C+D">Diogo Pernes</a>, 
<a href="/search/cs?searchtype=author&query=Mendes%2C+A">Afonso Mendes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at "The 4th New Frontiers in Summarization (with LLMs) Workshop"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The centroid method is a simple approach for extractive multi-document
summarization and many improvements to its pipeline have been proposed. We
further refine it by adding a beam search process to the sentence selection and
also a centroid estimation attention model that leads to improved results. We
demonstrate this in several multi-document summarization datasets, including in
a multilingual scenario.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17774" title="Abstract">arXiv:2311.17774</a> [<a href="/pdf/2311.17774" title="Download PDF">pdf</a>, <a href="/ps/2311.17774" title="Download PostScript">ps</a>, <a href="/format/2311.17774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enumeration of Minimum Weight Codewords of Pre-Transformed Polar Codes  by Tree Intersection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zunker%2C+A">Andreas Zunker</a>, 
<a href="/search/cs?searchtype=author&query=Geiselhart%2C+M">Marvin Geiselhart</a>, 
<a href="/search/cs?searchtype=author&query=Brink%2C+S+t">Stephan ten Brink</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Pre-transformed polar codes (PTPCs) form a class of codes that perform close
to the finite-length capacity bounds. The minimum distance and the number of
minimum weight codewords are two decisive properties for their performance. In
this work, we propose an efficient algorithm to determine the number of minimum
weight codewords of general PTPCs, which eliminates all redundant visits of
nodes of the search tree, reducing the computational complexity from
state-of-the-art algorithms typically by several orders of magnitude. The
algorithm is demonstrated for randomly pre-transformed Reed-Muller (RM) codes
and polarization-adjusted convolutional (PAC) codes. Optimal convolutional
polynomials for PAC codes are designed, minimizing the number of minimum weight
codewords.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17776" title="Abstract">arXiv:2311.17776</a> [<a href="/pdf/2311.17776" title="Download PDF">pdf</a>, <a href="/format/2311.17776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-Shot Open Affordance Learning with Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gen Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Deqing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Sevilla-Lara%2C+L">Laura Sevilla-Lara</a>, 
<a href="/search/cs?searchtype=author&query=Jampani%2C+V">Varun Jampani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce One-shot Open Affordance Learning (OOAL), where a model is
trained with just one example per base object category, but is expected to
identify novel objects and affordances. While vision-language models excel at
recognizing novel objects and scenes, they often struggle to understand finer
levels of granularity such as affordances. To handle this issue, we conduct a
comprehensive analysis of existing foundation models, to explore their inherent
understanding of affordances and assess the potential for data-limited
affordance learning. We then propose a vision-language framework with simple
and effective designs that boost the alignment between visual features and
affordance text embeddings. Experiments on two affordance segmentation
benchmarks show that the proposed method outperforms state-of-the-art models
with less than 1% of the full training data, and exhibits reasonable
generalization capability on unseen objects and affordances.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17777" title="Abstract">arXiv:2311.17777</a> [<a href="/pdf/2311.17777" title="Download PDF">pdf</a>, <a href="/ps/2311.17777" title="Download PostScript">ps</a>, <a href="/format/2311.17777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the leakage process for multi-scale water infrastructure  asset management: necessity for a dialogue between sociological and data  sciences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Collet%2C+M">Marie Collet</a> (UR ETTIS), 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+N">Nicolas Rodriguez</a> (UR ETTIS), 
<a href="/search/cs?searchtype=author&query=Baati%2C+S">Selma Baati</a> (UR ETTIS), 
<a href="/search/cs?searchtype=author&query=Husson%2C+A">Alain Husson</a> (UR ETTIS), 
<a href="/search/cs?searchtype=author&query=Renaud%2C+E">Eddy Renaud</a> (UR ETTIS), 
<a href="/search/cs?searchtype=author&query=Caillaud%2C+K">Kevin Caillaud</a> (UR ETTIS), 
<a href="/search/cs?searchtype=author&query=Gat%2C+Y+L">Yves Le Gat</a> (UR ETTIS)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> LESAM 2022, INRAE UR ETTIS; IWA, May 2022, Bordeaux, France
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Reducing water losses is one of the most pressing issues for modern water
utilities. To that end, improving the efficiency of the pipe leakage and repair
process and aiding the selection of the pipes that are to be renewed or
rehabilitated are essential. To help addressing these tasks, in this work, we
develop a model predicting the probability of a pipe to be leaking. This work
is set the context of a multidisciplinary project with Soci{\'e}t{\'e} Wallone
des Eaux and it is aligned with their goal to improve their Infrastructure
Asset Management in the short and the long terms. Developing and feeding this
leakage probability model relies on an intense data processing phase,
mobilizing data and water engineering sciences, since the raw data from SWDE is
not ready to be used in the model. Complementarily, we thus employ techniques
from sociology (e.g., interviews, analyses of the human/non-human actors and of
the tools, sociotechnical translations) in order to complete the data, to
improve our understanding of its production, and to increase its value and its
availability for the prediction of the pipe leakage probability. This model
will be implemented in SWDE's information system and used for strategies to
reduce water losses.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17780" title="Abstract">arXiv:2311.17780</a> [<a href="/pdf/2311.17780" title="Download PDF">pdf</a>, <a href="/format/2311.17780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $Q_{bias}$ -- A Dataset on Media Bias in Search Queries and Query  Suggestions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haak%2C+F">Fabian Haak</a>, 
<a href="/search/cs?searchtype=author&query=Schaer%2C+P">Philipp Schaer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted at ACM Web Science Conference 2023. 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">This publication describes the motivation and generation of $Q_{bias}$, a
large dataset of Google and Bing search queries, a scraping tool and dataset
for biased news articles, as well as language models for the investigation of
bias in online search. Web search engines are a major factor and trusted source
in information search, especially in the political domain. However, biased
information can influence opinion formation and lead to biased opinions. To
interact with search engines, users formulate search queries and interact with
search query suggestions provided by the search engines. A lack of datasets on
search queries inhibits research on the subject. We use $Q_{bias}$ to evaluate
different approaches to fine-tuning transformer-based language models with the
goal of producing models capable of biasing text with left and right political
stance. Additionally to this work we provided datasets and language models for
biasing texts that allow further research on bias in online information search.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17781" title="Abstract">arXiv:2311.17781</a> [<a href="/pdf/2311.17781" title="Download PDF">pdf</a>, <a href="/format/2311.17781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Propagate &amp; Distill: Towards Effective Graph Learners Using  Propagation-Embracing MLPs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shin%2C+Y">Yong-Min Shin</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+W">Won-Yong Shin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 2 figures, 8 tables; 2nd Learning on Graphs Conference (LoG 2023) (Please cite our conference version.). arXiv admin note: substantial text overlap with <a href="/abs/2311.11759">arXiv:2311.11759</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT); Neural and Evolutionary Computing (cs.NE); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Recent studies attempted to utilize multilayer perceptrons (MLPs) to solve
semisupervised node classification on graphs, by training a student MLP by
knowledge distillation from a teacher graph neural network (GNN). While
previous studies have focused mostly on training the student MLP by matching
the output probability distributions between the teacher and student models
during distillation, it has not been systematically studied how to inject the
structural information in an explicit and interpretable manner. Inspired by
GNNs that separate feature transformation $T$ and propagation $\Pi$, we
re-frame the distillation process as making the student MLP learn both $T$ and
$\Pi$. Although this can be achieved by applying the inverse propagation
$\Pi^{-1}$ before distillation from the teacher, it still comes with a high
computational cost from large matrix multiplications during training. To solve
this problem, we propose Propagate &amp; Distill (P&amp;D), which propagates the output
of the teacher before distillation, which can be interpreted as an approximate
process of the inverse propagation. We demonstrate that P&amp;D can readily improve
the performance of the student MLP.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17783" title="Abstract">arXiv:2311.17783</a> [<a href="/pdf/2311.17783" title="Download PDF">pdf</a>, <a href="/format/2311.17783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying Dynamic Regulation with Adversarial Surrogates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Teichner%2C+R">Ron Teichner</a>, 
<a href="/search/eess?searchtype=author&query=Brenner%2C+N">Naama Brenner</a>, 
<a href="/search/eess?searchtype=author&query=Meir%2C+R">Ron Meir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Homeostasis, the ability to maintain a stable internal environment in the
face of perturbations, is essential for the functioning of living systems.
Given observations of a system, or even a detailed model of one, it is both
valuable and extremely challenging to extract the control objectives of the
homeostatic mechanisms. Lacking a clear separation between plant and
controller, frameworks such as inverse optimal control and inverse
reinforcement learning are unable to identify the homeostatic mechanisms. A
recently developed data-driven algorithm, Identifying Regulation with
Adversarial Surrogates (IRAS), detects highly regulated or conserved quantities
as the solution of a min-max optimization scheme that automates classical
surrogate data methods. Yet, the definition of homeostasis as regulation within
narrow limits is too strict for biological systems which show sustained
oscillations such as circadian rhythms. In this work, we introduce Identifying
Dynamic Regulation with Adversarial Surrogates (IDRAS), a generalization of the
IRAS algorithm, capable of identifying control objectives that are regulated
with respect to a dynamical reference value. We test the algorithm on
simulation data from realistic biological models and benchmark physical
systems, demonstrating excellent empirical results.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17786" title="Abstract">arXiv:2311.17786</a> [<a href="/pdf/2311.17786" title="Download PDF">pdf</a>, <a href="/format/2311.17786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DSS: Synthesizing long Digital Ink using Data augmentation, Style  encoding and Split generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Timofeev%2C+A">Aleksandr Timofeev</a>, 
<a href="/search/cs?searchtype=author&query=Fadeeva%2C+A">Anastasiia Fadeeva</a>, 
<a href="/search/cs?searchtype=author&query=Afonin%2C+A">Andrei Afonin</a>, 
<a href="/search/cs?searchtype=author&query=Musat%2C+C">Claudiu Musat</a>, 
<a href="/search/cs?searchtype=author&query=Maksai%2C+A">Andrii Maksai</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Document Analysis and Recognition - ICDAR 2023. ICDAR 2023.
  Lecture Notes in Computer Science, vol 14190, pages 217-235, Springer, Cham
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">As text generative models can give increasingly long answers, we tackle the
problem of synthesizing long text in digital ink. We show that the commonly
used models for this task fail to generalize to long-form data and how this
problem can be solved by augmenting the training data, changing the model
architecture and the inference procedure. These methods use contrastive
learning technique and are tailored specifically for the handwriting domain.
They can be applied to any encoder-decoder model that works with digital ink.
We demonstrate that our method reduces the character error rate on long-form
English data by half compared to baseline RNN and by 16% compared to the
previous approach that aims at addressing the same problem. We show that all
three parts of the method improve recognizability of generated inks. In
addition, we evaluate synthesized data in a human study and find that people
perceive most of generated data as real.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17787" title="Abstract">arXiv:2311.17787</a> [<a href="/pdf/2311.17787" title="Download PDF">pdf</a>, <a href="/format/2311.17787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative software design and modeling in virtual reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stancek%2C+M">Martin Stancek</a>, 
<a href="/search/cs?searchtype=author&query=Polasek%2C+I">Ivan Polasek</a>, 
<a href="/search/cs?searchtype=author&query=Zalabai%2C+T">Tibor Zalabai</a>, 
<a href="/search/cs?searchtype=author&query=Vincur%2C+J">Juraj Vincur</a>, 
<a href="/search/cs?searchtype=author&query=Jolak%2C+R">Rodi Jolak</a>, 
<a href="/search/cs?searchtype=author&query=Chaudron%2C+M">Michel Chaudron</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Context: Software engineering is becoming more and more distributed.
Developers and other stakeholders are often located in different locations,
departments, and countries and operating within different time zones. Most
online software design and modeling tools are not adequate for distributed
collaboration since they do not support awareness and lack features for
effective communication.
<br />Objective: The aim of our research is to support distributed software design
activities in Virtual Reality (VR).
<br />Method: Using design science research methodology, we design and evaluate a
tool for collaborative design in VR. We evaluate the collaboration efficiency
and recall of design information when using the VR software design environment
compared to a non-VR software design environment. Moreover, we collect the
perceptions and preferences of users to explore the opportunities and
challenges that were incurred by using the VR software design environment.
<br />Results: We find that there is no significant difference in the efficiency
and recall of design information when using the VR compared to the non-VR
environment. Furthermore, we find that developers are more satisfied with
collaboration in VR.
<br />Conclusion: The results of our research and similar studies show that working
in VR is not yet faster or more efficient than working on standard desktops. It
is very important to improve the interface in VR (gestures with haptics,
keyboard and voice input), as confirmed by the difference in results between
the first and second evaluation.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17789" title="Abstract">arXiv:2311.17789</a> [<a href="/pdf/2311.17789" title="Download PDF">pdf</a>, <a href="/format/2311.17789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Symmetric alpha-Stable Privacy Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zawacki%2C+C">Christopher Zawacki</a>, 
<a href="/search/cs?searchtype=author&query=Abed%2C+E">Eyad Abed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures, Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">With the rapid growth of digital platforms, there is increasing apprehension
about how personal data is being collected, stored, and used by various
entities. These concerns range from data breaches and cyber-attacks to
potential misuse of personal information for targeted advertising and
surveillance. As a result, differential privacy (DP) has emerged as a prominent
tool for quantifying a system's level of protection. The Gaussian mechanism is
commonly used because the Gaussian density is closed under convolution, a
common method utilized when aggregating datasets. However, the Gaussian
mechanism only satisfies approximate differential privacy. In this work, we
present novel analysis of the Symmetric alpha-Stable (SaS) mechanism. We prove
that the mechanism is purely differentially private while remaining closed
under convolution. From our analysis, we believe the SaS Mechanism is an
appealing choice for privacy focused applications.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17790" title="Abstract">arXiv:2311.17790</a> [<a href="/pdf/2311.17790" title="Download PDF">pdf</a>, <a href="/format/2311.17790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FAT-HuBERT: Front-end Adaptive Training of Hidden-unit BERT for  Distortion-Invariant Robust Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Dongning Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yanmin Qian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Advancements in monaural speech enhancement (SE) techniques have greatly
improved the perceptual quality of speech. However, integrating these
techniques into automatic speech recognition (ASR) systems has not yielded the
expected performance gains, primarily due to the introduction of distortions
during the SE process. In this paper, we propose a novel approach called
FAT-HuBERT, which leverages distortion-invariant self-supervised learning (SSL)
to enhance the robustness of ASR. To address the distortions introduced by the
SE frontends, we introduce layer-wise fusion modules that incorporate features
extracted from both observed noisy signals and enhanced signals. During
training, the SE frontend is randomly selected from a pool of models. We
evaluate the performance of FAT-HuBERT on simulated noisy speech generated from
LibriSpeech as well as real-world noisy speech from the CHiME-4 1-channel
dataset. The experimental results demonstrate a significant relative reduction
in word error rate (WER).
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17795" title="Abstract">arXiv:2311.17795</a> [<a href="/pdf/2311.17795" title="Download PDF">pdf</a>, <a href="/ps/2311.17795" title="Download PostScript">ps</a>, <a href="/format/2311.17795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Marginal Laplacian Score
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hay%2C+G">Guy Hay</a>, 
<a href="/search/cs?searchtype=author&query=Volk%2C+O">Ohad Volk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">High-dimensional imbalanced data poses a machine learning challenge. In the
absence of sufficient or high-quality labels, unsupervised feature selection
methods are crucial for the success of subsequent algorithms. Therefore, there
is a growing need for unsupervised feature selection algorithms focused on
imbalanced data. Thus, we propose a Marginal Laplacian Score (MLS) a
modification of the well-known Laplacian Score (LS) to be better suited for
imbalance data. We introduce an assumption that the minority class or anomalous
appear more frequently in the margin of the features. Consequently, MLS aims to
preserve the local structure of the data set's margin. As MLS is better suited
for handling imbalanced data, we propose its integration into modern feature
selection methods that utilize the Laplacian score. We integrate the MLS
algorithm into the Differentiable Unsupervised Feature Selection (DUFS),
resulting in DUFS-MLS. The proposed methods demonstrate robust and improved
performance on synthetic and public data sets.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17797" title="Abstract">arXiv:2311.17797</a> [<a href="/pdf/2311.17797" title="Download PDF">pdf</a>, <a href="/format/2311.17797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Simulate: Generative Metamodeling via Quantile Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+L+J">L. Jeff Hong</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yanxi Hou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingkai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaowei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main body: 36 pages, 7 figures; supplemental material: 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">Stochastic simulation models, while effective in capturing the dynamics of
complex systems, are often too slow to run for real-time decision-making.
Metamodeling techniques are widely used to learn the relationship between a
summary statistic of the outputs (e.g., the mean or quantile) and the inputs of
the simulator, so that it can be used in real time. However, this methodology
requires the knowledge of an appropriate summary statistic in advance, making
it inflexible for many practical situations. In this paper, we propose a new
metamodeling concept, called generative metamodeling, which aims to construct a
"fast simulator of the simulator". This technique can generate random outputs
substantially faster than the original simulation model, while retaining an
approximately equal conditional distribution given the same inputs. Once
constructed, a generative metamodel can instantaneously generate a large amount
of random outputs as soon as the inputs are specified, thereby facilitating the
immediate computation of any summary statistic for real-time decision-making.
Furthermore, we propose a new algorithm -- quantile-regression-based generative
metamodeling (QRGMM) -- and study its convergence and rate of convergence.
Extensive numerical experiments are conducted to investigate the empirical
performance of QRGMM, compare it with other state-of-the-art generative
algorithms, and demonstrate its usefulness in practical real-time
decision-making.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17801" title="Abstract">arXiv:2311.17801</a> [<a href="/pdf/2311.17801" title="Download PDF">pdf</a>, <a href="/format/2311.17801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Efficient Hyperdimensional Computing Using Photonics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fayza%2C+F">Farbin Fayza</a>, 
<a href="/search/cs?searchtype=author&query=Demirkiran%2C+C">Cansu Demirkiran</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hanning Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Che-Kai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mohan%2C+A">Avi Mohan</a>, 
<a href="/search/cs?searchtype=author&query=Errahmouni%2C+H">Hamza Errahmouni</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+S">Sanggeon Yun</a>, 
<a href="/search/cs?searchtype=author&query=Imani%2C+M">Mohsen Imani</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">David Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bunandar%2C+D">Darius Bunandar</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+A">Ajay Joshi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Hardware Architecture (cs.AR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Over the past few years, silicon photonics-based computing has emerged as a
promising alternative to CMOS-based computing for Deep Neural Networks (DNN).
Unfortunately, the non-linear operations and the high-precision requirements of
DNNs make it extremely challenging to design efficient silicon photonics-based
systems for DNN inference and training. Hyperdimensional Computing (HDC) is an
emerging, brain-inspired machine learning technique that enjoys several
advantages over existing DNNs, including being lightweight, requiring
low-precision operands, and being robust to noise introduced by the
nonidealities in the hardware. For HDC, computing in-memory (CiM) approaches
have been widely used, as CiM reduces the data transfer cost if the operands
can fit into the memory. However, inefficient multi-bit operations, high write
latency, and low endurance make CiM ill-suited for HDC. On the other hand, the
existing electro-photonic DNN accelerators are inefficient for HDC because they
are specifically optimized for matrix multiplication in DNNs and consume a lot
of power with high-precision data converters.
<br />In this paper, we argue that photonic computing and HDC complement each other
better than photonic computing and DNNs, or CiM and HDC. We propose PhotoHDC,
the first-ever electro-photonic accelerator for HDC training and inference,
supporting the basic, record-based, and graph encoding schemes. Evaluating with
popular datasets, we show that our accelerator can achieve two to five orders
of magnitude lower EDP than the state-of-the-art electro-photonic DNN
accelerators for implementing HDC training and inference. PhotoHDC also
achieves four orders of magnitude lower energy-delay product than CiM-based
accelerators for both HDC training and inference.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17804" title="Abstract">arXiv:2311.17804</a> [<a href="/pdf/2311.17804" title="Download PDF">pdf</a>, <a href="/format/2311.17804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aggregation Model Hyperparameters Matter in Digital Pathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bredell%2C+G">Gustav Bredell</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+M">Marcel Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Szostak%2C+P">Przemyslaw Szostak</a>, 
<a href="/search/cs?searchtype=author&query=Abbasi-Sureshjani%2C+S">Samaneh Abbasi-Sureshjani</a>, 
<a href="/search/cs?searchtype=author&query=Gomariz%2C+A">Alvaro Gomariz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Digital pathology has significantly advanced disease detection and
pathologist efficiency through the analysis of gigapixel whole-slide images
(WSI). In this process, WSIs are first divided into patches, for which a
feature extractor model is applied to obtain feature vectors, which are
subsequently processed by an aggregation model to predict the respective WSI
label. With the rapid evolution of representation learning, numerous new
feature extractor models, often termed foundational models, have emerged.
Traditional evaluation methods, however, rely on fixed aggregation model
hyperparameters, a framework we identify as potentially biasing the results.
Our study uncovers a co-dependence between feature extractor models and
aggregation model hyperparameters, indicating that performance comparability
can be skewed based on the chosen hyperparameters. By accounting for this
co-dependency, we find that the performance of many current feature extractor
models is notably similar. We support this insight by evaluating seven feature
extractor models across three different datasets with 162 different aggregation
model configurations. This comprehensive approach provides a more nuanced
understanding of the relationship between feature extractors and aggregation
models, leading to a fairer and more accurate assessment of feature extractor
models in digital pathology.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17810" title="Abstract">arXiv:2311.17810</a> [<a href="/pdf/2311.17810" title="Download PDF">pdf</a>, <a href="/format/2311.17810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coloring the Past: Neural Historical Buildings Reconstruction from  Archival Photography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Komorowicz%2C+D">David Komorowicz</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+L">Lu Sang</a>, 
<a href="/search/cs?searchtype=author&query=Maiwald%2C+F">Ferdinand Maiwald</a>, 
<a href="/search/cs?searchtype=author&query=Cremers%2C+D">Daniel Cremers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Historical buildings are a treasure and milestone of human cultural heritage.
Reconstructing the 3D models of these building hold significant value. The
rapid development of neural rendering methods makes it possible to recover the
3D shape only based on archival photographs. However, this task presents
considerable challenges due to the limitations of such datasets. Historical
photographs are often limited in number and the scenes in these photos might
have altered over time. The radiometric quality of these images is also often
sub-optimal. To address these challenges, we introduce an approach to
reconstruct the geometry of historical buildings, employing volumetric
rendering techniques. We leverage dense point clouds as a geometric prior and
introduce a color appearance embedding loss to recover the color of the
building given limited available color images. We aim for our work to spark
increased interest and focus on preserving historical buildings. Thus, we also
introduce a new historical dataset of the Hungarian National Theater, providing
a new benchmark for the reconstruction method.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17812" title="Abstract">arXiv:2311.17812</a> [<a href="/pdf/2311.17812" title="Download PDF">pdf</a>, <a href="/format/2311.17812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DAP: Domain-aware Prompt Learning for Vision-and-Language Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yue Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wansen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Youkai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Q">Quanjun Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages. arXiv admin note: substantial text overlap with <a href="/abs/2309.03661">arXiv:2309.03661</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Following language instructions to navigate in unseen environments is a
challenging task for autonomous embodied agents. With strong representation
capabilities, pretrained vision-and-language models are widely used in VLN.
However, most of them are trained on web-crawled general-purpose datasets,
which incurs a considerable domain gap when used for VLN tasks. To address the
problem, we propose a novel and model-agnostic domain-aware prompt learning
(DAP) framework. For equipping the pretrained models with specific object-level
and scene-level cross-modal alignment in VLN tasks, DAP applies a low-cost
prompt tuning paradigm to learn soft visual prompts for extracting in-domain
image semantics. Specifically, we first generate a set of in-domain image-text
pairs with the help of the CLIP model. Then we introduce soft visual prompts in
the input space of the visual encoder in a pretrained model. DAP injects
in-domain visual knowledge into the visual encoder of the pretrained model in
an efficient way. Experimental results on both R2R and REVERIE show the
superiority of DAP compared to existing state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17813" title="Abstract">arXiv:2311.17813</a> [<a href="/pdf/2311.17813" title="Download PDF">pdf</a>, <a href="/format/2311.17813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Higher-Order DisCoCat (Peirce-Lambek-Montague semantics)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Toumi%2C+A">Alexis Toumi</a>, 
<a href="/search/cs?searchtype=author&query=de+Felice%2C+G">Giovanni de Felice</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Category Theory (math.CT)

</div>
<p class="mathjax">We propose a new definition of higher-order DisCoCat (categorical
compositional distributional) models where the meaning of a word is not a
diagram, but a diagram-valued higher-order function. Our models can be seen as
a variant of Montague semantics based on a lambda calculus where the primitives
act on string diagrams rather than logical formulae. As a special case, we show
how to translate from the Lambek calculus into Peirce's system beta for
first-order logic. This allows us to give a purely diagrammatic treatment of
higher-order and non-linear processes in natural language semantics: adverbs,
prepositions, negation and quantifiers. The theoretical definition presented in
this article comes with a proof-of-concept implementation in DisCoPy, the
Python library for string diagrams.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17815" title="Abstract">arXiv:2311.17815</a> [<a href="/pdf/2311.17815" title="Download PDF">pdf</a>, <a href="/format/2311.17815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Design Methodologies for Accelerating Deep Learning on  Heterogeneous Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferrandi%2C+F">Fabrizio Ferrandi</a>, 
<a href="/search/cs?searchtype=author&query=Curzel%2C+S">Serena Curzel</a>, 
<a href="/search/cs?searchtype=author&query=Fiorin%2C+L">Leandro Fiorin</a>, 
<a href="/search/cs?searchtype=author&query=Ielmini%2C+D">Daniele Ielmini</a>, 
<a href="/search/cs?searchtype=author&query=Silvano%2C+C">Cristina Silvano</a>, 
<a href="/search/cs?searchtype=author&query=Conti%2C+F">Francesco Conti</a>, 
<a href="/search/cs?searchtype=author&query=Burrello%2C+A">Alessio Burrello</a>, 
<a href="/search/cs?searchtype=author&query=Barchi%2C+F">Francesco Barchi</a>, 
<a href="/search/cs?searchtype=author&query=Benini%2C+L">Luca Benini</a>, 
<a href="/search/cs?searchtype=author&query=Lavagno%2C+L">Luciano Lavagno</a>, 
<a href="/search/cs?searchtype=author&query=Urso%2C+T">Teodoro Urso</a>, 
<a href="/search/cs?searchtype=author&query=Calore%2C+E">Enrico Calore</a>, 
<a href="/search/cs?searchtype=author&query=Schifano%2C+S+F">Sebastiano Fabio Schifano</a>, 
<a href="/search/cs?searchtype=author&query=Zambelli%2C+C">Cristian Zambelli</a>, 
<a href="/search/cs?searchtype=author&query=Palesi%2C+M">Maurizio Palesi</a>, 
<a href="/search/cs?searchtype=author&query=Ascia%2C+G">Giuseppe Ascia</a>, 
<a href="/search/cs?searchtype=author&query=Russo%2C+E">Enrico Russo</a>, 
<a href="/search/cs?searchtype=author&query=Petra%2C+N">Nicola Petra</a>, 
<a href="/search/cs?searchtype=author&query=De+Caro%2C+D">Davide De Caro</a>, 
<a href="/search/cs?searchtype=author&query=Di+Meo%2C+G">Gennaro Di Meo</a>, 
<a href="/search/cs?searchtype=author&query=Cardellini%2C+V">Valeria Cardellini</a>, 
<a href="/search/cs?searchtype=author&query=Filippone%2C+S">Salvatore Filippone</a>, 
<a href="/search/cs?searchtype=author&query=Presti%2C+F+L">Francesco Lo Presti</a>, 
<a href="/search/cs?searchtype=author&query=Silvestri%2C+F">Francesco Silvestri</a>, 
<a href="/search/cs?searchtype=author&query=Palazzari%2C+P">Paolo Palazzari</a>, 
<a href="/search/cs?searchtype=author&query=Perri%2C+S">Stefania Perri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In recent years, the field of Deep Learning has seen many disruptive and
impactful advancements. Given the increasing complexity of deep neural
networks, the need for efficient hardware accelerators has become more and more
pressing to design heterogeneous HPC platforms. The design of Deep Learning
accelerators requires a multidisciplinary approach, combining expertise from
several areas, spanning from computer architecture to approximate computing,
computational models, and machine learning algorithms. Several methodologies
and tools have been proposed to design accelerators for Deep Learning,
including hardware-software co-design approaches, high-level synthesis methods,
specific customized compilers, and methodologies for design space exploration,
modeling, and simulation. These methodologies aim to maximize the exploitable
parallelism and minimize data movement to achieve high performance and energy
efficiency. This survey provides a holistic review of the most influential
design methodologies and EDA tools proposed in recent years to implement Deep
Learning accelerators, offering the reader a wide perspective in this rapidly
evolving field. In particular, this work complements the previous survey
proposed by the same authors in [203], which focuses on Deep Learning hardware
accelerators for heterogeneous HPC platforms.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17822" title="Abstract">arXiv:2311.17822</a> [<a href="/pdf/2311.17822" title="Download PDF">pdf</a>, <a href="/format/2311.17822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anomalous Behavior Detection in Trajectory Data of Older Drivers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghoreishi%2C+S+G+A">Seyedeh Gol Ara Ghoreishi</a>, 
<a href="/search/cs?searchtype=author&query=Moshfeghi%2C+S">Sonia Moshfeghi</a>, 
<a href="/search/cs?searchtype=author&query=Jan%2C+M+T">Muhammad Tanveer Jan</a>, 
<a href="/search/cs?searchtype=author&query=Conniff%2C+J">Joshua Conniff</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">KwangSoo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+J">Jinwoo Jang</a>, 
<a href="/search/cs?searchtype=author&query=Furht%2C+B">Borko Furht</a>, 
<a href="/search/cs?searchtype=author&query=Tappen%2C+R">Ruth Tappen</a>, 
<a href="/search/cs?searchtype=author&query=Newman%2C+D">David Newman</a>, 
<a href="/search/cs?searchtype=author&query=Rosselli%2C+M">Monica Rosselli</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+J">Jiannan Zhai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE HONET 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Given a road network and a set of trajectory data, the anomalous behavior
detection (ABD) problem is to identify drivers that show significant
directional deviations, hardbrakings, and accelerations in their trips. The ABD
problem is important in many societal applications, including Mild Cognitive
Impairment (MCI) detection and safe route recommendations for older drivers.
The ABD problem is computationally challenging due to the large size of
temporally-detailed trajectories dataset. In this paper, we propose an
Edge-Attributed Matrix that can represent the key properties of
temporally-detailed trajectory datasets and identify abnormal driving
behaviors. Experiments using real-world datasets demonstrated that our approach
identifies abnormal driving behaviors.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17833" title="Abstract">arXiv:2311.17833</a> [<a href="/pdf/2311.17833" title="Download PDF">pdf</a>, <a href="/format/2311.17833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing and Explaining Image Classifiers via Diffusion Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Augustin%2C+M">Maximilian Augustin</a>, 
<a href="/search/cs?searchtype=author&query=Neuhaus%2C+Y">Yannic Neuhaus</a>, 
<a href="/search/cs?searchtype=author&query=Hein%2C+M">Matthias Hein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">While deep learning has led to huge progress in complex image classification
tasks like ImageNet, unexpected failure modes, e.g. via spurious features, call
into question how reliably these classifiers work in the wild. Furthermore, for
safety-critical tasks the black-box nature of their decisions is problematic,
and explanations or at least methods which make decisions plausible are needed
urgently. In this paper, we address these problems by generating images that
optimize a classifier-derived objective using a framework for guided image
generation. We analyze the behavior and decisions of image classifiers by
visual counterfactual explanations (VCEs), detection of systematic mistakes by
analyzing images where classifiers maximally disagree, and visualization of
neurons to verify potential spurious features. In this way, we validate
existing observations, e.g. the shape bias of adversarially robust models, as
well as novel failure modes, e.g. systematic errors of zero-shot CLIP
classifiers, or identify harmful spurious features. Moreover, our VCEs
outperform previous work while being more versatile.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17834" title="Abstract">arXiv:2311.17834</a> [<a href="/pdf/2311.17834" title="Download PDF">pdf</a>, <a href="/format/2311.17834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPiC-E : Structural Priors in 3D Diffusion Models using Cross Entity  Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sella%2C+E">Etai Sella</a>, 
<a href="/search/cs?searchtype=author&query=Fiebelman%2C+G">Gal Fiebelman</a>, 
<a href="/search/cs?searchtype=author&query=Atia%2C+N">Noam Atia</a>, 
<a href="/search/cs?searchtype=author&query=Averbuch-Elor%2C+H">Hadar Averbuch-Elor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project webpage: <a href="https://tau-vailab.github.io/spic-e">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We are witnessing rapid progress in automatically generating and manipulating
3D assets due to the availability of pretrained text-image diffusion models.
However, time-consuming optimization procedures are required for synthesizing
each sample, hindering their potential for democratizing 3D content creation.
Conversely, 3D diffusion models now train on million-scale 3D datasets,
yielding high-quality text-conditional 3D samples within seconds. In this work,
we present SPiC-E - a neural network that adds structural guidance to 3D
diffusion models, extending their usage beyond text-conditional generation. At
its core, our framework introduces a cross-entity attention mechanism that
allows for multiple entities (in particular, paired input and guidance 3D
shapes) to interact via their internal representations within the denoising
network. We utilize this mechanism for learning task-specific structural priors
in 3D diffusion models from auxiliary guidance shapes. We show that our
approach supports a variety of applications, including 3D stylization, semantic
shape editing and text-conditional abstraction-to-3D, which transforms
primitive-based abstractions into highly-expressive shapes. Extensive
experiments demonstrate that SPiC-E achieves SOTA performance over these tasks
while often being considerably faster than alternative methods. Importantly,
this is accomplished without tailoring our approach for any specific task.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17836" title="Abstract">arXiv:2311.17836</a> [<a href="/pdf/2311.17836" title="Download PDF">pdf</a>, <a href="/ps/2311.17836" title="Download PostScript">ps</a>, <a href="/format/2311.17836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Scaling Robust Feedback Control and State Estimation Problems in  Power Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bahavarnia%2C+M">MirSaleh Bahavarnia</a>, 
<a href="/search/eess?searchtype=author&query=Nadeem%2C+M">Muhammad Nadeem</a>, 
<a href="/search/eess?searchtype=author&query=Taha%2C+A+F">Ahmad F. Taha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Press
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sustainable Energy, Grids and Networks, November 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Many mainstream robust control/estimation algorithms for power networks are
designed using the Lyapunov theory as it provides performance guarantees for
linear/nonlinear models of uncertain power networks but comes at the expense of
scalability and sensitivity. In particular, Lyapunov-based approaches rely on
forming semi-definite programs (SDPs) that are (i) not scalable and (ii)
extremely sensitive to the choice of the bounding scalar that ensures the
strict feasibility of the linear matrix inequalities (LMIs). This paper
addresses these two issues by employing a celebrated non-Lyapunov approach
(NLA) from the control theory literature. In lieu of linearized models of power
grids, we focus on (the more representative) nonlinear differential algebraic
equation (DAE) models and showcase the simplicity, scalability, and
parameter-resiliency of NLA. For some power systems, the approach is nearly
fifty times faster than solving SDPs via standard solvers with almost no impact
on the performance. The case studies also demonstrate that NLA can be applied
to more realistic scenarios in which (i) only partial state data is available
and (ii) sparsity structures are imposed on the feedback gain. The paper also
showcases that virtually no degradation in state estimation quality is
experienced when applying NLA.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17837" title="Abstract">arXiv:2311.17837</a> [<a href="/pdf/2311.17837" title="Download PDF">pdf</a>, <a href="/format/2311.17837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anytime Replanning of Robot Coverage Paths for Partially Unknown  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramesh%2C+M">Megnath Ramesh</a>, 
<a href="/search/cs?searchtype=author&query=Imeson%2C+F">Frank Imeson</a>, 
<a href="/search/cs?searchtype=author&query=Fidan%2C+B">Baris Fidan</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+S+L">Stephen L. Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 15 figures, Paper submitted to T-RO
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this paper, we propose a method to replan coverage paths for a robot
operating in an environment with initially unknown static obstacles. Existing
coverage approaches reduce coverage time by covering along the minimum number
of coverage lines (straight-line paths). However, recomputing such paths online
can be computationally expensive resulting in robot stoppages that increase
coverage time. A naive alternative is greedy detour replanning, i.e.,
replanning with minimum deviation from the initial path, which is efficient to
compute but may result in unnecessary detours. In this work, we propose an
anytime coverage replanning approach named OARP-Replan that performs
near-optimal replans to an interrupted coverage path within a given time
budget. We do this by solving linear relaxations of mixed-integer linear
programs (MILPs) to identify sections of the interrupted path that can be
optimally replanned within the time budget. We validate our approach in
simulation using maps of real-world environments and compare our approach
against a greedy detour replanner and other state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17840" title="Abstract">arXiv:2311.17840</a> [<a href="/pdf/2311.17840" title="Download PDF">pdf</a>, <a href="/format/2311.17840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A quasi-polynomial time algorithm for Multi-Dimensional Scaling via LP  hierarchies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bakshi%2C+A">Ainesh Bakshi</a>, 
<a href="/search/cs?searchtype=author&query=Cohen-Addad%2C+V">Vincent Cohen-Addad</a>, 
<a href="/search/cs?searchtype=author&query=Hopkins%2C+S+B">Samuel B. Hopkins</a>, 
<a href="/search/cs?searchtype=author&query=Jayaram%2C+R">Rajesh Jayaram</a>, 
<a href="/search/cs?searchtype=author&query=Lattanzi%2C+S">Silvio Lattanzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Multi-dimensional Scaling (MDS) is a family of methods for embedding
pair-wise dissimilarities between $n$ objects into low-dimensional space. MDS
is widely used as a data visualization tool in the social and biological
sciences, statistics, and machine learning. We study the Kamada-Kawai
formulation of MDS: given a set of non-negative dissimilarities $\{d_{i,j}\}_{i
, j \in [n]}$ over $n$ points, the goal is to find an embedding
$\{x_1,\dots,x_n\} \subset \mathbb{R}^k$ that minimizes \[ \text{OPT} =
\min_{x} \mathbb{E}_{i,j \in [n]} \left[ \left(1-\frac{\|x_i -
x_j\|}{d_{i,j}}\right)^2 \right] \]
<br />Despite its popularity, our theoretical understanding of MDS is extremely
limited. Recently, Demaine, Hesterberg, Koehler, Lynch, and Urschel
(<a href="/abs/2109.11505">arXiv:2109.11505</a>) gave the first approximation algorithm with provable
guarantees for Kamada-Kawai, which achieves an embedding with cost $\text{OPT}
+\epsilon$ in $n^2 \cdot 2^{\tilde{\mathcal{O}}(k \Delta^4 / \epsilon^2)}$
time, where $\Delta$ is the aspect ratio of the input dissimilarities. In this
work, we give the first approximation algorithm for MDS with quasi-polynomial
dependency on $\Delta$: for target dimension $k$, we achieve a solution with
cost $\mathcal{O}(\text{OPT}^{ \hspace{0.04in}1/k } \cdot \log(\Delta/\epsilon)
)+ \epsilon$ in time $n^{ \mathcal{O}(1)} \cdot 2^{\tilde{\mathcal{O}}( k^2
(\log(\Delta)/\epsilon)^{k/2 + 1} ) }$.
<br />Our approach is based on a novel analysis of a conditioning-based rounding
scheme for the Sherali-Adams LP Hierarchy. Crucially, our analysis exploits the
geometry of low-dimensional Euclidean space, allowing us to avoid an
exponential dependence on the aspect ratio $\Delta$. We believe our
geometry-aware treatment of the Sherali-Adams Hierarchy is an important step
towards developing general-purpose techniques for efficient metric optimization
algorithms.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17841" title="Abstract">arXiv:2311.17841</a> [<a href="/pdf/2311.17841" title="Download PDF">pdf</a>, <a href="/ps/2311.17841" title="Download PostScript">ps</a>, <a href="/format/2311.17841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast list-decoding of univariate multiplicity and folded Reed-Solomon  codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goyal%2C+R">Rohan Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Harsha%2C+P">Prahladh Harsha</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+M">Mrinal Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Shankar%2C+A">Ashutosh Shankar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">We show that the known list-decoding algorithms for univariate multiplicity
and folded Reed-Solomon (FRS) codes can be made to run in nearly-linear time.
This yields, to our knowledge, the first known family of codes that can be
decoded in nearly linear time, even as they approach the list decoding
capacity. Univariate multiplicity codes and FRS codes are natural variants of
Reed-Solomon codes that were discovered and studied for their applications to
list-decoding. It is known that for every $\epsilon &gt;0$, and rate $R \in
(0,1)$, there exist explicit families of these codes that have rate $R$ and can
be list-decoded from a $(1-R-\epsilon)$ fraction of errors with constant list
size in polynomial time (Guruswami &amp; Wang (IEEE Trans. Inform. Theory, 2013)
and Kopparty, Ron-Zewi, Saraf &amp; Wootters (SIAM J. Comput. 2023)). In this work,
we present randomized algorithms that perform the above tasks in nearly linear
time. Our algorithms have two main components. The first builds upon the
lattice-based approach of Alekhnovich (IEEE Trans. Inf. Theory 2005), who
designed a nearly linear time list-decoding algorithm for Reed-Solomon codes
approaching the Johnson radius. As part of the second component, we design
nearly-linear time algorithms for two natural algebraic problems. The first
algorithm solves linear differential equations of the form $Q\left(x, f(x),
\frac{df}{dx}, \dots,\frac{d^m f}{dx^m}\right) \equiv 0$ where $Q$ has the form
$Q(x,y_0,\dots,y_m) = \tilde{Q}(x) + \sum_{i = 0}^m Q_i(x)\cdot y_i$. The
second solves functional equations of the form $Q\left(x, f(x), f(\gamma x),
\dots,f(\gamma^m x)\right) \equiv 0$ where $\gamma$ is a high-order field
element. These algorithms can be viewed as generalizations of classical
algorithms of Sieveking (Computing 1972) and Kung (Numer. Math. 1974) for
computing the modular inverse of a power series, and might be of independent
interest.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17842" title="Abstract">arXiv:2311.17842</a> [<a href="/pdf/2311.17842" title="Download PDF">pdf</a>, <a href="/format/2311.17842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Look Before You Leap: Unveiling the Power of GPT-4V in Robotic  Vision-Language Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yingdong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+F">Fanqi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+L">Li Yi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this study, we are interested in imbuing robots with the capability of
physically-grounded task planning. Recent advancements have shown that large
language models (LLMs) possess extensive knowledge useful in robotic tasks,
especially in reasoning and planning. However, LLMs are constrained by their
lack of world grounding and dependence on external affordance models to
perceive environmental information, which cannot jointly reason with LLMs. We
argue that a task planner should be an inherently grounded, unified multimodal
system. To this end, we introduce Robotic Vision-Language Planning (ViLa), a
novel approach for long-horizon robotic planning that leverages vision-language
models (VLMs) to generate a sequence of actionable steps. ViLa directly
integrates perceptual data into its reasoning and planning process, enabling a
profound understanding of commonsense knowledge in the visual world, including
spatial layouts and object attributes. It also supports flexible multimodal
goal specification and naturally incorporates visual feedback. Our extensive
evaluation, conducted in both real-robot and simulated environments,
demonstrates ViLa's superiority over existing LLM-based planners, highlighting
its effectiveness in a wide array of open-world manipulation tasks.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17846" title="Abstract">arXiv:2311.17846</a> [<a href="/pdf/2311.17846" title="Download PDF">pdf</a>, <a href="/format/2311.17846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Real-World Focus Stacking with Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Araujo%2C+A">Alexandre Araujo</a>, 
<a href="/search/cs?searchtype=author&query=Ponce%2C+J">Jean Ponce</a>, 
<a href="/search/cs?searchtype=author&query=Mairal%2C+J">Julien Mairal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Focus stacking is widely used in micro, macro, and landscape photography to
reconstruct all-in-focus images from multiple frames obtained with focus
bracketing, that is, with shallow depth of field and different focus planes.
Existing deep learning approaches to the underlying multi-focus image fusion
problem have limited applicability to real-world imagery since they are
designed for very short image sequences (two to four images), and are typically
trained on small, low-resolution datasets either acquired by light-field
cameras or generated synthetically. We introduce a new dataset consisting of 94
high-resolution bursts of raw images with focus bracketing, with pseudo ground
truth computed from the data using state-of-the-art commercial software. This
dataset is used to train the first deep learning algorithm for focus stacking
capable of handling bursts of sufficient length for real-world applications.
Qualitative experiments demonstrate that it is on par with existing commercial
solutions in the long-burst, realistic regime while being significantly more
tolerant to noise. The code and dataset are available at
https://github.com/araujoalexandre/FocusStackingDataset.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17847" title="Abstract">arXiv:2311.17847</a> [<a href="/pdf/2311.17847" title="Download PDF">pdf</a>, <a href="/format/2311.17847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FastSample: Accelerating Distributed Graph Neural Network Training for  Billion-Scale Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mostafa%2C+H">Hesham Mostafa</a>, 
<a href="/search/cs?searchtype=author&query=Grabowski%2C+A">Adam Grabowski</a>, 
<a href="/search/cs?searchtype=author&query=Turja%2C+M+A">Md Asadullah Turja</a>, 
<a href="/search/cs?searchtype=author&query=Cervino%2C+J">Juan Cervino</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+A">Alejandro Ribeiro</a>, 
<a href="/search/cs?searchtype=author&query=Himayat%2C+N">Nageen Himayat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Training Graph Neural Networks(GNNs) on a large monolithic graph presents
unique challenges as the graph cannot fit within a single machine and it cannot
be decomposed into smaller disconnected components. Distributed sampling-based
training distributes the graph across multiple machines and trains the GNN on
small parts of the graph that are randomly sampled every training iteration. We
show that in a distributed environment, the sampling overhead is a significant
component of the training time for large-scale graphs. We propose FastSample
which is composed of two synergistic techniques that greatly reduce the
distributed sampling time: 1)a new graph partitioning method that eliminates
most of the communication rounds in distributed sampling , 2)a novel highly
optimized sampling kernel that reduces memory movement during sampling. We test
FastSample on large-scale graph benchmarks and show that FastSample speeds up
distributed sampling-based GNN training by up to 2x with no loss in accuracy.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17849" title="Abstract">arXiv:2311.17849</a> [<a href="/pdf/2311.17849" title="Download PDF">pdf</a>, <a href="/format/2311.17849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Traversing automata with current state uncertainty under LTL$_f$  constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ryzhikov%2C+A">Andrew Ryzhikov</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+P">Petra Wolf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">In this paper, we consider a problem which we call LTL$_f$ model checking on
paths: given a DFA $\mathcal{A}$ and a formula $\phi$ in LTL on finite traces,
does there exist a word $w$ such that every path starting in a state of
$\mathcal{A}$ and labeled by $w$ satisfies $\phi$? The original motivation for
this problem comes from the constrained parts orienting problem, introduced in
[Petra Wolf, "Synchronization Under Dynamic Constraints", FSTTCS 2020], where
the input constraints restrict the order in which certain states are visited
for the first or the last time while reading a word $w$ which is also required
to synchronize $\mathcal{A}$. We identify very general conditions under which
LTL$_f$ model checking on paths is solvable in polynomial space. For the
particular constraints in the parts orienting problem, we consider
PSPACE-complete cases and one NP-complete case. The former provide very strong
lower bound for LTL$_f$ model checking on paths. The latter is related to
(classical) LTL$_f$ model checking for formulas with the until modality only
and with no nesting of operators. We also consider LTL$_f$ model checking of
the power-set automaton of a given DFA, and get similar results for this
setting. For all our problems, we consider the case where the required word
must also be synchronizing, and prove that if the problem does not become
trivial, then this additional constraint does not change the complexity.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17851" title="Abstract">arXiv:2311.17851</a> [<a href="/pdf/2311.17851" title="Download PDF">pdf</a>, <a href="/format/2311.17851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating VLMs for Score-Based, Multi-Probe Annotation of 3D Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kabra%2C+R">Rishabh Kabra</a>, 
<a href="/search/cs?searchtype=author&query=Matthey%2C+L">Loic Matthey</a>, 
<a href="/search/cs?searchtype=author&query=Lerchner%2C+A">Alexander Lerchner</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+N+J">Niloy J. Mitra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unlabeled 3D objects present an opportunity to leverage pretrained vision
language models (VLMs) on a range of annotation tasks -- from describing object
semantics to physical properties. An accurate response must take into account
the full appearance of the object in 3D, various ways of phrasing the
question/prompt, and changes in other factors that affect the response. We
present a method to marginalize over any factors varied across VLM queries,
utilizing the VLM's scores for sampled responses. We first show that this
probabilistic aggregation can outperform a language model (e.g., GPT4) for
summarization, for instance avoiding hallucinations when there are contrasting
details between responses. Secondly, we show that aggregated annotations are
useful for prompt-chaining; they help improve downstream VLM predictions (e.g.,
of object material when the object's type is specified as an auxiliary input in
the prompt). Such auxiliary inputs allow ablating and measuring the
contribution of visual reasoning over language-only reasoning. Using these
evaluations, we show how VLMs can approach, without additional training or
in-context learning, the quality of human-verified type and material
annotations on the large-scale Objaverse dataset.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17852" title="Abstract">arXiv:2311.17852</a> [<a href="/pdf/2311.17852" title="Download PDF">pdf</a>, <a href="/format/2311.17852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Computing-in-Memory-based One-Class Hyperdimensional Computing Model  for Outlier Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruixuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+S+H">Sabrina Hassan Moon</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X+S">Xiaobo Sharon Hu</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+X">Xun Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Reis%2C+D">Dayane Reis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">In this work, we present ODHD, an algorithm for outlier detection based on
hyperdimensional computing (HDC), a non-classical learning paradigm. Along with
the HDC-based algorithm, we propose IM-ODHD, a computing-in-memory (CiM)
implementation based on hardware/software (HW/SW) codesign for improved latency
and energy efficiency. The training and testing phases of ODHD may be performed
with conventional CPU/GPU hardware or our IM-ODHD, SRAM-based CiM architecture
using the proposed HW/SW codesign techniques. We evaluate the performance of
ODHD on six datasets from different application domains using three metrics,
namely accuracy, F1 score, and ROC-AUC, and compare it with multiple baseline
methods such as OCSVM, isolation forest, and autoencoder. The experimental
results indicate that ODHD outperforms all the baseline methods in terms of
these three metrics on every dataset for both CPU/GPU and CiM implementations.
Furthermore, we perform an extensive design space exploration to demonstrate
the tradeoff between delay, energy efficiency, and performance of ODHD. We
demonstrate that the HW/SW codesign implementation of the outlier detection on
IM-ODHD is able to outperform the GPU-based implementation of ODHD by at least
293x/419x in terms of training/testing latency (and on average 16.0x/15.9x in
terms of training/testing energy consumption).
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17853" title="Abstract">arXiv:2311.17853</a> [<a href="/pdf/2311.17853" title="Download PDF">pdf</a>, <a href="/format/2311.17853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Adversarial Robustness of Graph Contrastive Learning Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guerranti%2C+F">Filippo Guerranti</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+Z">Zinuo Yi</a>, 
<a href="/search/cs?searchtype=author&query=Starovoit%2C+A">Anna Starovoit</a>, 
<a href="/search/cs?searchtype=author&query=Kamel%2C+R">Rafiq Kamel</a>, 
<a href="/search/cs?searchtype=author&query=Geisler%2C+S">Simon Geisler</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCnnemann%2C+S">Stephan G&#xfc;nnemann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023 New Frontiers in Graph Learning Workshop (NeurIPS GLFrontiers 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Contrastive learning (CL) has emerged as a powerful framework for learning
representations of images and text in a self-supervised manner while enhancing
model robustness against adversarial attacks. More recently, researchers have
extended the principles of contrastive learning to graph-structured data,
giving birth to the field of graph contrastive learning (GCL). However, whether
GCL methods can deliver the same advantages in adversarial robustness as their
counterparts in the image and text domains remains an open question. In this
paper, we introduce a comprehensive robustness evaluation protocol tailored to
assess the robustness of GCL models. We subject these models to adaptive
adversarial attacks targeting the graph structure, specifically in the evasion
scenario. We evaluate node and graph classification tasks using diverse
real-world datasets and attack strategies. With our work, we aim to offer
insights into the robustness of GCL methods and hope to open avenues for
potential future research directions.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17855" title="Abstract">arXiv:2311.17855</a> [<a href="/pdf/2311.17855" title="Download PDF">pdf</a>, <a href="/format/2311.17855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximum Entropy Model Correction in Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rakhsha%2C+A">Amin Rakhsha</a>, 
<a href="/search/cs?searchtype=author&query=Kemertas%2C+M">Mete Kemertas</a>, 
<a href="/search/cs?searchtype=author&query=Ghavamzadeh%2C+M">Mohammad Ghavamzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Farahmand%2C+A">Amir-massoud Farahmand</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">We propose and theoretically analyze an approach for planning with an
approximate model in reinforcement learning that can reduce the adverse impact
of model error. If the model is accurate enough, it accelerates the convergence
to the true value function too. One of its key components is the MaxEnt Model
Correction (MoCo) procedure that corrects the model's next-state distributions
based on a Maximum Entropy density estimation formulation. Based on MoCo, we
introduce the Model Correcting Value Iteration (MoCoVI) algorithm, and its
sampled-based variant MoCoDyna. We show that MoCoVI and MoCoDyna's convergence
can be much faster than the conventional model-free algorithms. Unlike
traditional model-based algorithms, MoCoVI and MoCoDyna effectively utilize an
approximate model and still converge to the correct value function.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17856" title="Abstract">arXiv:2311.17856</a> [<a href="/pdf/2311.17856" title="Download PDF">pdf</a>, <a href="/format/2311.17856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Graph Diffusion Models for Network Refinement Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Trivedi%2C+P">Puja Trivedi</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+R">Ryan Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Arbour%2C+D">David Arbour</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Dernoncourt%2C+F">Franck Dernoncourt</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sungchul Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lipka%2C+N">Nedim Lipka</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+N">Namyong Park</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+N+K">Nesreen K. Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Koutra%2C+D">Danai Koutra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in Progress. 21 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Most real-world networks are noisy and incomplete samples from an unknown
target distribution. Refining them by correcting corruptions or inferring
unobserved regions typically improves downstream performance. Inspired by the
impressive generative capabilities that have been used to correct corruptions
in images, and the similarities between "in-painting" and filling in missing
nodes and edges conditioned on the observed graph, we propose a novel graph
generative framework, SGDM, which is based on subgraph diffusion. Our framework
not only improves the scalability and fidelity of graph diffusion models, but
also leverages the reverse process to perform novel, conditional generation
tasks. In particular, through extensive empirical analysis and a set of novel
metrics, we demonstrate that our proposed model effectively supports the
following refinement tasks for partially observable networks: T1: denoising
extraneous subgraphs, T2: expanding existing subgraphs and T3: performing
"style" transfer by regenerating a particular subgraph to match the
characteristics of a different node or subgraph.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17857" title="Abstract">arXiv:2311.17857</a> [<a href="/pdf/2311.17857" title="Download PDF">pdf</a>, <a href="/format/2311.17857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Shell Maps for Efficient 3D Human Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdal%2C+R">Rameen Abdal</a>, 
<a href="/search/cs?searchtype=author&query=Yifan%2C+W">Wang Yifan</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zifan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yinghao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Po%2C+R">Ryan Po</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+Z">Zhengfei Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+D">Dit-Yan Yeung</a>, 
<a href="/search/cs?searchtype=author&query=Wetzstein%2C+G">Gordon Wetzstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page : <a href="https://rameenabdal.github.io/GaussianShellMaps/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Efficient generation of 3D digital humans is important in several industries,
including virtual reality, social media, and cinematic production. 3D
generative adversarial networks (GANs) have demonstrated state-of-the-art
(SOTA) quality and diversity for generated assets. Current 3D GAN
architectures, however, typically rely on volume representations, which are
slow to render, thereby hampering the GAN training and requiring
multi-view-inconsistent 2D upsamplers. Here, we introduce Gaussian Shell Maps
(GSMs) as a framework that connects SOTA generator network architectures with
emerging 3D Gaussian rendering primitives using an articulable multi
shell--based scaffold. In this setting, a CNN generates a 3D texture stack with
features that are mapped to the shells. The latter represent inflated and
deflated versions of a template surface of a digital human in a canonical body
pose. Instead of rasterizing the shells directly, we sample 3D Gaussians on the
shells whose attributes are encoded in the texture features. These Gaussians
are efficiently and differentiably rendered. The ability to articulate the
shells is important during GAN training and, at inference time, to deform a
body into arbitrary user-defined poses. Our efficient rendering scheme bypasses
the need for view-inconsistent upsamplers and achieves high-quality multi-view
consistent renderings at a native resolution of $512 \times 512$ pixels. We
demonstrate that GSMs successfully generate 3D humans when trained on
single-view datasets, including SHHQ and DeepFashion.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17860" title="Abstract">arXiv:2311.17860</a> [<a href="/pdf/2311.17860" title="Download PDF">pdf</a>, <a href="/ps/2311.17860" title="Download PostScript">ps</a>, <a href="/format/2311.17860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Verification of the Correctness of a Subgraph Construction  Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%B6ltz%2C+L">Lucas B&#xf6;ltz</a>, 
<a href="/search/cs?searchtype=author&query=Sofronie-Stokkermans%2C+V">Viorica Sofronie-Stokkermans</a>, 
<a href="/search/cs?searchtype=author&query=Frey%2C+H">Hannes Frey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 50 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">We automatically verify the crucial steps in the original proof of
correctness of an algorithm which, given a geometric graph satisfying certain
additional properties removes edges in a systematic way for producing a
connected graph in which edges do not (geometrically) intersect. The challenge
in this case is representing and reasoning about geometric properties of graphs
in the Euclidean plane, about their vertices and edges, and about connectivity.
For modelling the geometric aspects, we use an axiomatization of plane
geometry; for representing the graph structure we use additional predicates;
for representing certain classes of paths in geometric graphs we use linked
lists.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17861" title="Abstract">arXiv:2311.17861</a> [<a href="/pdf/2311.17861" title="Download PDF">pdf</a>, <a href="/format/2311.17861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Method for robotic motion compensation during PET imaging of mobile  subjects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Iordachita%2C+I+I">Iulian I. Iordachita</a>, 
<a href="/search/cs?searchtype=author&query=Kazanzides%2C+P">Peter Kazanzides</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Studies of the human brain during natural activities, such as locomotion,
would benefit from the ability to image deep brain structures during these
activities. While Positron Emission Tomography (PET) can image these
structures, the bulk and weight of current scanners are not compatible with the
desire for a wearable device. This has motivated the design of a robotic system
to support a PET imaging system around the subject's head and to move the
system to accommodate natural motion. We report here the design and
experimental evaluation of a prototype robotic system that senses motion of a
subject's head, using parallel string encoders connected between the
robot-supported imaging ring and a helmet worn by the subject. This measurement
is used to robotically move the imaging ring (coarse motion correction) and to
compensate for residual motion during image reconstruction (fine motion
correction). Minimization of latency and measurement error are the key design
goals, respectively, for coarse and fine motion correction. The system is
evaluated using recorded human head motions during locomotion, with a mock
imaging system consisting of lasers and cameras, and is shown to provide an
overall system latency of about 80 ms, which is sufficient for coarse motion
correction and collision avoidance, as well as a measurement accuracy of about
0.5 mm for fine motion correction.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17863" title="Abstract">arXiv:2311.17863</a> [<a href="/pdf/2311.17863" title="Download PDF">pdf</a>, <a href="/format/2311.17863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of a measurement system for PET imaging studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Ti Wu</a>, 
<a href="/search/cs?searchtype=author&query=Iordachita%2C+I+I">Iulian I. Iordachita</a>, 
<a href="/search/cs?searchtype=author&query=Kazanzides%2C+P">Peter Kazanzides</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2022 International Symposium on Medical Robotics (ISMR), GA, USA,
  2022, pp. 1-6
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Positron Emission Tomography (PET) enables functional imaging of deep brain
structures, but the bulk and weight of current systems preclude their use
during many natural human activities, such as locomotion. The proposed
long-term solution is to construct a robotic system that can support an imaging
system surrounding the subject's head, and then move the system to accommodate
natural motion. This requires a system to measure the motion of the head with
respect to the imaging ring, for use by both the robotic system and the image
reconstruction software. We report here the design and experimental evaluation
of a parallel string encoder mechanism for sensing this motion. Our preliminary
results indicate that the measurement system may achieve accuracy within 0.5
mm, especially for small motions, with improved accuracy possible through
kinematic calibration.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17868" title="Abstract">arXiv:2311.17868</a> [<a href="/pdf/2311.17868" title="Download PDF">pdf</a>, <a href="/ps/2311.17868" title="Download PostScript">ps</a>, <a href="/format/2311.17868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Space-Optimal Profile Estimation in Data Streams with Applications to  Symmetric Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J+Y">Justin Y. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Indyk%2C+P">Piotr Indyk</a>, 
<a href="/search/cs?searchtype=author&query=Woodruff%2C+D+P">David P. Woodruff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in ITCS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We revisit the problem of estimating the profile (also known as the rarity)
in the data stream model. Given a sequence of $m$ elements from a universe of
size $n$, its profile is a vector $\phi$ whose $i$-th entry $\phi_i$ represents
the number of distinct elements that appear in the stream exactly $i$ times. A
classic paper by Datar and Muthukrishan from 2002 gave an algorithm which
estimates any entry $\phi_i$ up to an additive error of $\pm \epsilon D$ using
$O(1/\epsilon^2 (\log n + \log m))$ bits of space, where $D$ is the number of
distinct elements in the stream. In this paper, we considerably improve on this
result by designing an algorithm which simultaneously estimates many
coordinates of the profile vector $\phi$ up to small overall error. We give an
algorithm which, with constant probability, produces an estimated profile
$\hat\phi$ with the following guarantees in terms of space and estimation
error:
<br />- For any constant $\tau$, with $O(1 / \epsilon^2 + \log n)$ bits of space,
$\sum_{i=1}^\tau |\phi_i - \hat\phi_i| \leq \epsilon D$.
<br />- With $O(1/ \epsilon^2\log (1/\epsilon) + \log n + \log \log m)$ bits of
space, $\sum_{i=1}^m |\phi_i - \hat\phi_i| \leq \epsilon m$.
<br />In addition to bounding the error across multiple coordinates, our space
bounds separate the terms that depend on $1/\epsilon$ and those that depend on
$n$ and $m$. We prove matching lower bounds on space in both regimes.
Application of our profile estimation algorithm gives estimates within error
$\pm \epsilon D$ of several symmetric functions of frequencies in
$O(1/\epsilon^2 + \log n)$ bits. This generalizes space-optimal algorithms for
the distinct elements problems to other problems including estimating the Huber
and Tukey losses as well as frequency cap statistics.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17869" title="Abstract">arXiv:2311.17869</a> [<a href="/pdf/2311.17869" title="Download PDF">pdf</a>, <a href="/format/2311.17869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAIBench: A Structural Interpretation of AI for Science Through  Benchmarks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yatao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+J">Jianfeng Zhan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Artificial Intelligence for Science (AI4S) is an emerging research field that
utilizes machine learning advancements to tackle complex scientific
computational issues, aiming to enhance computational efficiency and accuracy.
However, the data-driven nature of AI4S lacks the correctness or accuracy
assurances of conventional scientific computing, posing challenges when
deploying AI4S models in real-world applications. To mitigate these, more
comprehensive benchmarking procedures are needed to better understand AI4S
models. This paper introduces a novel benchmarking approach, known as
structural interpretation, which addresses two key requirements: identifying
the trusted operating range in the problem space and tracing errors back to
their computational components. This method partitions both the problem and
metric spaces, facilitating a structural exploration of these spaces. The
practical utility and effectiveness of structural interpretation are
illustrated through its application to three distinct AI4S workloads:
machine-learning force fields (MLFF), jet tagging, and precipitation
nowcasting. The benchmarks effectively model the trusted operating range, trace
errors, and reveal novel perspectives for refining the model, training process,
and data sampling strategy. This work is part of the SAIBench project, an AI4S
benchmarking suite.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17871" title="Abstract">arXiv:2311.17871</a> [<a href="/pdf/2311.17871" title="Download PDF">pdf</a>, <a href="/ps/2311.17871" title="Download PostScript">ps</a>, <a href="/format/2311.17871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimation of Dynamic Gaussian Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=van+Hulst%2C+J">Jilles van Hulst</a>, 
<a href="/search/eess?searchtype=author&query=van+Zuijlen%2C+R">Roy van Zuijlen</a>, 
<a href="/search/eess?searchtype=author&query=Antunes%2C+D">Duarte Antunes</a>, 
<a href="/search/eess?searchtype=author&query=H.%2C+W+P+M">W.P.M.H.</a> (Maurice)
<a href="/search/eess?searchtype=author&query=Heemels">Heemels</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, to be presented at 62nd IEEE Conference on Decision and Control, CDC 2023, Singapore, Singapore
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Gaussian processes provide a compact representation for modeling and
estimating an unknown function, that can be updated as new measurements of the
function are obtained. This paper extends this powerful framework to the case
where the unknown function dynamically changes over time. Specifically, we
assume that the function evolves according to an integro-difference equation
and that the measurements are obtained locally in a spatial sense. In this
setting, we will provide the expressions for the conditional mean and
covariance of the process given the measurements, which results in a
generalized estimation framework, for which we coined the term Dynamic Gaussian
Process (DGP) estimation. This new framework generalizes both Gaussian process
regression and Kalman filtering. For a broad class of kernels, described by a
set of basis functions, fast implementations are provided. We illustrate the
results on a numerical example, demonstrating that the method can accurately
estimate an evolving continuous function, even in the presence of noisy
measurements and disturbances.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17872" title="Abstract">arXiv:2311.17872</a> [<a href="/pdf/2311.17872" title="Download PDF">pdf</a>, <a href="/format/2311.17872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing the reliability of multistate flow networks considering  distance constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Forghani-elahabad%2C+M">Majid Forghani-elahabad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">Evaluating the reliability of complex technical networks, such as those in
energy distribution, logistics, and transportation systems, is of paramount
importance. These networks are often represented as multistate flow networks
(MFNs). While there has been considerable research on assessing MFN
reliability, many studies still need to pay more attention to a critical
factor: transmission distance constraints. These constraints are typical in
real-world applications, such as Internet infrastructure, where controlling the
distances between data centers, network nodes, and end-users is vital for
ensuring low latency and efficient data transmission. This paper addresses the
evaluation of MFN reliability under distance constraints. Specifically, it
focuses on determining the probability that a minimum of $d$ flow units can be
transmitted successfully from a source node to a sink node, using only paths
with lengths not exceeding a predefined distance limit of $\lambda $. We
introduce an effective algorithm to tackle this challenge, provide a benchmark
example to illustrate its application and analyze its computational complexity.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17874" title="Abstract">arXiv:2311.17874</a> [<a href="/pdf/2311.17874" title="Download PDF">pdf</a>, <a href="/format/2311.17874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FisherRF: Active View Selection and Uncertainty Quantification for  Radiance Fields using Fisher Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+B">Boshu Lei</a>, 
<a href="/search/cs?searchtype=author&query=Daniilidis%2C+K">Kostas Daniilidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://jiangwenpl.github.io/FisherRF/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This study addresses the challenging problem of active view selection and
uncertainty quantification within the domain of Radiance Fields. Neural
Radiance Fields (NeRF) have greatly advanced image rendering and
reconstruction, but the limited availability of 2D images poses uncertainties
stemming from occlusions, depth ambiguities, and imaging errors. Efficiently
selecting informative views becomes crucial, and quantifying NeRF model
uncertainty presents intricate challenges. Existing approaches either depend on
model architecture or are based on assumptions regarding density distributions
that are not generally applicable. By leveraging Fisher Information, we
efficiently quantify observed information within Radiance Fields without ground
truth data. This can be used for the next best view selection and pixel-wise
uncertainty quantification. Our method overcomes existing limitations on model
architecture and effectiveness, achieving state-of-the-art results in both view
selection and uncertainty quantification, demonstrating its potential to
advance the field of Radiance Fields. Our method with the 3D Gaussian Splatting
backend could perform view selections at 70 fps.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17876" title="Abstract">arXiv:2311.17876</a> [<a href="/pdf/2311.17876" title="Download PDF">pdf</a>, <a href="/format/2311.17876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Post-Hoc Explanation Benchmark Reliability for Image  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gomez%2C+T">Tristan Gomez</a>, 
<a href="/search/cs?searchtype=author&query=Mouch%C3%A8re%2C+H">Harold Mouch&#xe8;re</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep neural networks, while powerful for image classification, often operate
as "black boxes," complicating the understanding of their decision-making
processes. Various explanation methods, particularly those generating saliency
maps, aim to address this challenge. However, the inconsistency issues of
faithfulness metrics hinder reliable benchmarking of explanation methods. This
paper employs an approach inspired by psychometrics, utilizing Krippendorf's
alpha to quantify the benchmark reliability of post-hoc methods in image
classification. The study proposes model training modifications, including
feeding perturbed samples and employing focal loss, to enhance robustness and
calibration. Empirical evaluations demonstrate significant improvements in
benchmark reliability across metrics, datasets, and post-hoc methods. This
pioneering work establishes a foundation for more reliable evaluation practices
in the realm of post-hoc explanation methods, emphasizing the importance of
model robustness in the assessment process.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17878" title="Abstract">arXiv:2311.17878</a> [<a href="/pdf/2311.17878" title="Download PDF">pdf</a>, <a href="/format/2311.17878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TSDF-Sampling: Efficient Sampling for Neural Surface Field using  Truncated Signed Distance Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Min%2C+C">Chaerin Min</a>, 
<a href="/search/cs?searchtype=author&query=Cha%2C+S">Sehyun Cha</a>, 
<a href="/search/cs?searchtype=author&query=Won%2C+C">Changhee Won</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+J">Jongwoo Lim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-view neural surface reconstruction has exhibited impressive results.
However, a notable limitation is the prohibitively slow inference time when
compared to traditional techniques, primarily attributed to the dense sampling,
required to maintain the rendering quality. This paper introduces a novel
approach that substantially reduces the number of samplings by incorporating
the Truncated Signed Distance Field (TSDF) of the scene. While prior works have
proposed importance sampling, their dependence on initial uniform samples over
the entire space makes them unable to avoid performance degradation when trying
to use less number of samples. In contrast, our method leverages the TSDF
volume generated only by the trained views, and it proves to provide a
reasonable bound on the sampling from upcoming novel views. As a result, we
achieve high rendering quality by fully exploiting the continuous neural SDF
estimation within the bounds given by the TSDF volume. Notably, our method is
the first approach that can be robustly plug-and-play into a diverse array of
neural surface field models, as long as they use the volume rendering
technique. Our empirical results show an 11-fold increase in inference speed
without compromising performance. The result videos are available at our
project page: https://tsdf-sampling.github.io/
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17889" title="Abstract">arXiv:2311.17889</a> [<a href="/pdf/2311.17889" title="Download PDF">pdf</a>, <a href="/ps/2311.17889" title="Download PostScript">ps</a>, <a href="/format/2311.17889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scale Ratio Tuning of Group Based Job Scheduling in HPC Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S.%2C+L+D">Lyakhovets D. S.</a>, 
<a href="/search/cs?searchtype=author&query=V.%2C+B+A">Baranov A. V.</a>, 
<a href="/search/cs?searchtype=author&query=N%2C+T+P">Telegin P. N</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Mathematical Software (cs.MS)

</div>
<p class="mathjax">During the initialization of a supercomputer job, no useful calculations are
performed. A high proportion of initialization time results in idle computing
resources and less computational efficiency. Certain methods and algorithms
combining jobs into groups are used to optimize scheduling of jobs with high
initialization proportion. The article considers the influence of the scale
ratio setting in algorithm for the job groups formation, on the performance
metrics of the workload manager. The study was carried out on the developed by
authors Aleabased workload manager model. The model makes it possible to
conduct a large number of experiments in reasonable time without losing the
accuracy of the simulation. We performed a series of experiments involving
various characteristics of the workload. The article represents the results of
a study of the scale ratio influence on efficiency metrics for different
initialization time proportions and input workflows with varying intensity and
homogeneity. The presented results allow the workload managers administrators
to set a scale ratio that provides an appropriate balance with contradictory
efficiency metrics.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17891" title="Abstract">arXiv:2311.17891</a> [<a href="/pdf/2311.17891" title="Download PDF">pdf</a>, <a href="/format/2311.17891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pose Anything: A Graph-Based Approach for Category-Agnostic Pose  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hirschorn%2C+O">Or Hirschorn</a>, 
<a href="/search/cs?searchtype=author&query=Avidan%2C+S">Shai Avidan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Traditional 2D pose estimation models are limited by their category-specific
design, making them suitable only for predefined object categories. This
restriction becomes particularly challenging when dealing with novel objects
due to the lack of relevant training data.
<br />To address this limitation, category-agnostic pose estimation (CAPE) was
introduced. CAPE aims to enable keypoint localization for arbitrary object
categories using a single model, requiring minimal support images with
annotated keypoints. This approach not only enables object pose generation
based on arbitrary keypoint definitions but also significantly reduces the
associated costs, paving the way for versatile and adaptable pose estimation
applications.
<br />We present a novel approach to CAPE that leverages the inherent geometrical
relations between keypoints through a newly designed Graph Transformer Decoder.
By capturing and incorporating this crucial structural information, our method
enhances the accuracy of keypoint localization, marking a significant departure
from conventional CAPE techniques that treat keypoints as isolated entities.
<br />We validate our approach on the MP-100 benchmark, a comprehensive dataset
comprising over 20,000 images spanning more than 100 categories. Our method
outperforms the prior state-of-the-art by substantial margins, achieving
remarkable improvements of 2.16% and 1.82% under 1-shot and 5-shot settings,
respectively. Furthermore, our method's end-to-end training demonstrates both
scalability and efficiency compared to previous CAPE approaches.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17892" title="Abstract">arXiv:2311.17892</a> [<a href="/pdf/2311.17892" title="Download PDF">pdf</a>, <a href="/format/2311.17892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Pipeline For Discourse Circuits From CCG
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jonathon Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shaikh%2C+R+A">Razin A. Shaikh</a>, 
<a href="/search/cs?searchtype=author&query=Rodatz%2C+B">Benjamin Rodatz</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+R">Richie Yeung</a>, 
<a href="/search/cs?searchtype=author&query=Coecke%2C+B">Bob Coecke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, many figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">There is a significant disconnect between linguistic theory and modern NLP
practice, which relies heavily on inscrutable black-box architectures.
DisCoCirc is a newly proposed model for meaning that aims to bridge this
divide, by providing neuro-symbolic models that incorporate linguistic
structure. DisCoCirc represents natural language text as a `circuit' that
captures the core semantic information of the text. These circuits can then be
interpreted as modular machine learning models. Additionally, DisCoCirc fulfils
another major aim of providing an NLP model that can be implemented on
near-term quantum computers.
<br />In this paper we describe a software pipeline that converts English text to
its DisCoCirc representation. The pipeline achieves coverage over a large
fragment of the English language. It relies on Combinatory Categorial Grammar
(CCG) parses of the input text as well as coreference resolution information.
This semantic and syntactic information is used in several steps to convert the
text into a simply-typed $\lambda$-calculus term, and then into a circuit
diagram. This pipeline will enable the application of the DisCoCirc framework
to NLP tasks, using both classical and quantum approaches.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17893" title="Abstract">arXiv:2311.17893</a> [<a href="/pdf/2311.17893" title="Download PDF">pdf</a>, <a href="/format/2311.17893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Betrayed by Attention: A Simple yet Effective Approach for  Self-supervised Video Object Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+S">Shuangrui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+R">Rui Qian</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haohang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hongkai Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we propose a simple yet effective approach for self-supervised
video object segmentation (VOS). Our key insight is that the inherent
structural dependencies present in DINO-pretrained Transformers can be
leveraged to establish robust spatio-temporal correspondences in videos.
Furthermore, simple clustering on this correspondence cue is sufficient to
yield competitive segmentation results. Previous self-supervised VOS techniques
majorly resort to auxiliary modalities or utilize iterative slot attention to
assist in object discovery, which restricts their general applicability and
imposes higher computational requirements. To deal with these challenges, we
develop a simplified architecture that capitalizes on the emerging objectness
from DINO-pretrained Transformers, bypassing the need for additional modalities
or slot attention. Specifically, we first introduce a single spatio-temporal
Transformer block to process the frame-wise DINO features and establish
spatio-temporal dependencies in the form of self-attention. Subsequently,
utilizing these attention maps, we implement hierarchical clustering to
generate object segmentation masks. To train the spatio-temporal block in a
fully self-supervised manner, we employ semantic and dynamic motion consistency
coupled with entropy normalization. Our method demonstrates state-of-the-art
performance across multiple unsupervised VOS benchmarks and particularly excels
in complex real-world multi-object video segmentation tasks such as
DAVIS-17-Unsupervised and YouTube-VIS-19. The code and model checkpoints will
be released at https://github.com/shvdiwnkozbw/SSL-UVOS.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17898" title="Abstract">arXiv:2311.17898</a> [<a href="/pdf/2311.17898" title="Download PDF">pdf</a>, <a href="/format/2311.17898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Pursuit Prompting for Zero-Shot Multimodal Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jinqi Luo</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+K+H+R">Kwan Ho Ryan Chan</a>, 
<a href="/search/cs?searchtype=author&query=Dimos%2C+D">Dimitris Dimos</a>, 
<a href="/search/cs?searchtype=author&query=Vidal%2C+R">Ren&#xe9; Vidal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Hallucinations and unfaithful synthesis due to inaccurate prompts with
insufficient semantic details are widely observed in multimodal generative
models. A prevalent strategy to align multiple modalities is to fine-tune the
generator with a large number of annotated text-image pairs. However, such a
procedure is labor-consuming and resource-draining. The key question we ask is:
can we enhance the quality and faithfulness of text-driven generative models
beyond extensive text-image pair annotations? To address this question, we
propose Knowledge Pursuit Prompting (KPP), a zero-shot framework that
iteratively incorporates external knowledge to help generators produce reliable
visual content. Instead of training generators to handle generic prompts, KPP
employs a recursive knowledge query process to gather informative external
facts from the knowledge base, instructs a language model to compress the
acquired knowledge for prompt refinement, and utilizes text-driven generators
for visual synthesis. The entire process is zero-shot, without accessing the
architectures and parameters of generative models. We evaluate the framework
across multiple text-driven generative tasks (image, 3D rendering, and video)
on datasets of different domains. We further demonstrate the extensibility and
adaptability of KPP through varying foundation model bases and instructions.
Our results show that KPP is capable of generating faithful and semantically
rich content across diverse visual domains, offering a promising solution to
improve multimodal generative models.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17901" title="Abstract">arXiv:2311.17901</a> [<a href="/pdf/2311.17901" title="Download PDF">pdf</a>, <a href="/format/2311.17901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SODA: Bottleneck Diffusion Models for Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hudson%2C+D+A">Drew A. Hudson</a>, 
<a href="/search/cs?searchtype=author&query=Zoran%2C+D">Daniel Zoran</a>, 
<a href="/search/cs?searchtype=author&query=Malinowski%2C+M">Mateusz Malinowski</a>, 
<a href="/search/cs?searchtype=author&query=Lampinen%2C+A+K">Andrew K. Lampinen</a>, 
<a href="/search/cs?searchtype=author&query=Jaegle%2C+A">Andrew Jaegle</a>, 
<a href="/search/cs?searchtype=author&query=McClelland%2C+J+L">James L. McClelland</a>, 
<a href="/search/cs?searchtype=author&query=Matthey%2C+L">Loic Matthey</a>, 
<a href="/search/cs?searchtype=author&query=Hill%2C+F">Felix Hill</a>, 
<a href="/search/cs?searchtype=author&query=Lerchner%2C+A">Alexander Lerchner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce SODA, a self-supervised diffusion model, designed for
representation learning. The model incorporates an image encoder, which
distills a source view into a compact representation, that, in turn, guides the
generation of related novel views. We show that by imposing a tight bottleneck
between the encoder and a denoising decoder, and leveraging novel view
synthesis as a self-supervised objective, we can turn diffusion models into
strong representation learners, capable of capturing visual semantics in an
unsupervised manner. To the best of our knowledge, SODA is the first diffusion
model to succeed at ImageNet linear-probe classification, and, at the same
time, it accomplishes reconstruction, editing and synthesis tasks across a wide
range of datasets. Further investigation reveals the disentangled nature of its
emergent latent space, that serves as an effective interface to control and
manipulate the model's produced images. All in all, we aim to shed light on the
exciting and promising potential of diffusion models, not only for image
generation, but also for learning rich and robust representations.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17902" title="Abstract">arXiv:2311.17902</a> [<a href="/pdf/2311.17902" title="Download PDF">pdf</a>, <a href="/format/2311.17902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language-conditioned Detection Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+J+H">Jang Hyun Cho</a>, 
<a href="/search/cs?searchtype=author&query=Kr%C3%A4henb%C3%BChl%2C+P">Philipp Kr&#xe4;henb&#xfc;hl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is at <a href="https://github.com/janghyuncho/DECOLA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a new open-vocabulary detection framework. Our framework uses both
image-level labels and detailed detection annotations when available. Our
framework proceeds in three steps. We first train a language-conditioned object
detector on fully-supervised detection data. This detector gets to see the
presence or absence of ground truth classes during training, and conditions
prediction on the set of present classes. We use this detector to pseudo-label
images with image-level labels. Our detector provides much more accurate
pseudo-labels than prior approaches with its conditioning mechanism. Finally,
we train an unconditioned open-vocabulary detector on the pseudo-annotated
images. The resulting detector, named DECOLA, shows strong zero-shot
performance in open-vocabulary LVIS benchmark as well as direct zero-shot
transfer benchmarks on LVIS, COCO, Object365, and OpenImages. DECOLA
outperforms the prior arts by 17.1 AP-rare and 9.4 mAP on zero-shot LVIS
benchmark. DECOLA achieves state-of-the-art results in various model sizes,
architectures, and datasets by only training on open-sourced data and
academic-scale computing. Code is available at
https://github.com/janghyuncho/DECOLA.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17905" title="Abstract">arXiv:2311.17905</a> [<a href="/pdf/2311.17905" title="Download PDF">pdf</a>, <a href="/format/2311.17905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SLO/GO Degradation-Loss Sensitivity in Climate-Human System Coupling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cabrera%2C+S">Sierra Cabrera</a>, 
<a href="/search/cs?searchtype=author&query=Babayan%2C+I">Irina Babayan</a>, 
<a href="/search/cs?searchtype=author&query=Aliahmadi%2C+H">Hazhir Aliahmadi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dongmei Chen</a>, 
<a href="/search/cs?searchtype=author&query=van+Anders%2C+G">Greg van Anders</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">The potential of extreme environmental change driven by a destabilized
climate system is an alarming prospect for humanity. But the intricate, subtle
ways Earth's climate couples to social and economic systems raise the question
of when more incremental climate change signals the need for alarm. Questions
about incremental sensitivity are particularly crucial for human systems that
are organized by optimization. Optimization is most valuable in resolving
complex interactions among multiple factors, however, those interactions can
obscure coupling to underlying drivers such as environmental degradation. Here,
using Multi-Objective Land Allocation as an example, we show that model
features that are common across non-convex optimization problems drive
hypersensitivities in climate-induced degradation--loss response. We show that
catastrophic losses in human systems can occur well before catastrophic climate
collapse. We find punctuated insensitive/hypersensitive degradation--loss
response, which we trace to the contrasting effects of environmental
degradation on subleading, local versus global optima (SLO/GO). We argue that
the SLO/GO response we identify in land-allocation problems traces to features
that are common across non-convex optimization problems more broadly. Given the
broad range of human systems that rely on non-convex optimization, our results
therefore suggest that substantial social and economic risks could be lurking
in a broad range in human systems that are coupled to the environment, even in
the absence of catastrophic changes to the environment itself.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17907" title="Abstract">arXiv:2311.17907</a> [<a href="/pdf/2311.17907" title="Download PDF">pdf</a>, <a href="/format/2311.17907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CG3D: Compositional Generation for Text-to-3D via Gaussian Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vilesov%2C+A">Alexander Vilesov</a>, 
<a href="/search/cs?searchtype=author&query=Chari%2C+P">Pradyumna Chari</a>, 
<a href="/search/cs?searchtype=author&query=Kadambi%2C+A">Achuta Kadambi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the onset of diffusion-based generative models and their ability to
generate text-conditioned images, content generation has received a massive
invigoration. Recently, these models have been shown to provide useful guidance
for the generation of 3D graphics assets. However, existing work in
text-conditioned 3D generation faces fundamental constraints: (i) inability to
generate detailed, multi-object scenes, (ii) inability to textually control
multi-object configurations, and (iii) physically realistic scene composition.
In this work, we propose CG3D, a method for compositionally generating scalable
3D assets that resolves these constraints. We find that explicit Gaussian
radiance fields, parameterized to allow for compositions of objects, possess
the capability to enable semantically and physically consistent scenes. By
utilizing a guidance framework built around this explicit representation, we
show state of the art results, capable of even exceeding the guiding diffusion
model in terms of object combinations and physics accuracy.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17909" title="Abstract">arXiv:2311.17909</a> [<a href="/pdf/2311.17909" title="Download PDF">pdf</a>, <a href="/format/2311.17909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distance-coupling as an Approach to Position and Formation Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Napoli%2C+M">Michael Napoli</a>, 
<a href="/search/eess?searchtype=author&query=Tron%2C+R">Roberto Tron</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Studies of coordinated motion in autonomous vehicle groups have become a
significant topic of interest in recent years. In this letter, we study the
case when the agents are limited to distance measurements from predetermined
reference points, or anchors. A novel approach, referred to as
distance-coupling, is proposed for approximating agent positions from anchor
distances. By taking the difference between squared distance functions, we
cancel out the quadratic term and obtain a linear function of the position for
the point of interest. We apply this method to the homing problem and prove
Lyapunov stability with and without anchor placement error: defining bounds on
the region of attraction. To further increase complexity, we show how the
policy can be implemented on the formation control problem for a set of
autonomous agents. In this context we prove results on the equilibria of the
distance-coupled formation controller and its convergence under perturbations
of the initial conditions. The performance for both controllers are
subsequently validated through simulation.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17910" title="Abstract">arXiv:2311.17910</a> [<a href="/pdf/2311.17910" title="Download PDF">pdf</a>, <a href="/format/2311.17910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HUGS: Human Gaussian Splats
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kocabas%2C+M">Muhammed Kocabas</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+J+R">Jen-Hao Rick Chang</a>, 
<a href="/search/cs?searchtype=author&query=Gabriel%2C+J">James Gabriel</a>, 
<a href="/search/cs?searchtype=author&query=Tuzel%2C+O">Oncel Tuzel</a>, 
<a href="/search/cs?searchtype=author&query=Ranjan%2C+A">Anurag Ranjan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Recent advances in neural rendering have improved both training and rendering
times by orders of magnitude. While these methods demonstrate state-of-the-art
quality and speed, they are designed for photogrammetry of static scenes and do
not generalize well to freely moving humans in the environment. In this work,
we introduce Human Gaussian Splats (HUGS) that represents an animatable human
together with the scene using 3D Gaussian Splatting (3DGS). Our method takes
only a monocular video with a small number of (50-100) frames, and it
automatically learns to disentangle the static scene and a fully animatable
human avatar within 30 minutes. We utilize the SMPL body model to initialize
the human Gaussians. To capture details that are not modeled by SMPL (e.g.
cloth, hairs), we allow the 3D Gaussians to deviate from the human body model.
Utilizing 3D Gaussians for animated humans brings new challenges, including the
artifacts created when articulating the Gaussians. We propose to jointly
optimize the linear blend skinning weights to coordinate the movements of
individual Gaussians during animation. Our approach enables novel-pose
synthesis of human and novel view synthesis of both the human and the scene. We
achieve state-of-the-art rendering quality with a rendering speed of 60 FPS
while being ~100x faster to train over previous work. Our code will be
announced here: https://github.com/apple/ml-hugs
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17911" title="Abstract">arXiv:2311.17911</a> [<a href="/pdf/2311.17911" title="Download PDF">pdf</a>, <a href="/format/2311.17911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OPERA: Alleviating Hallucination in Multi-Modal Large Language Models  via Over-Trust Penalty and Retrospection-Allocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qidong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xiaoyi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Conghui He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+N">Nenghai Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Hallucination, posed as a pervasive challenge of multi-modal large language
models (MLLMs), has significantly impeded their real-world usage that demands
precise judgment. Existing methods mitigate this issue with either training
with specific designed data or inferencing with external knowledge from other
sources, incurring inevitable additional costs. In this paper, we present
OPERA, a novel MLLM decoding method grounded in an Over-trust Penalty and a
Retrospection-Allocation strategy, serving as a nearly free lunch to alleviate
the hallucination issue without additional data, knowledge, or training. Our
approach begins with an interesting observation that, most hallucinations are
closely tied to the knowledge aggregation patterns manifested in the
self-attention matrix, i.e., MLLMs tend to generate new tokens by focusing on a
few summary tokens, but not all the previous tokens. Such partial over-trust
inclination results in the neglecting of image tokens and describes the image
content with hallucination. Statistically, we observe an 80%$\sim$95%
co-currency rate between hallucination contents and such knowledge aggregation
patterns. Based on the observation, OPERA introduces a penalty term on the
model logits during the beam-search decoding to mitigate the over-trust issue,
along with a rollback strategy that retrospects the presence of summary tokens
in the previously generated tokens, and re-allocate the token selection if
necessary. With extensive experiments, OPERA shows significant
hallucination-mitigating performance on different MLLMs and metrics, proving
its effectiveness and generality. Our code is available at:
https://github.com/shikiw/OPERA.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17917" title="Abstract">arXiv:2311.17917</a> [<a href="/pdf/2311.17917" title="Download PDF">pdf</a>, <a href="/format/2311.17917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AvatarStudio: High-fidelity and Animatable 3D Avatar Creation from Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuanmeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huichao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liew%2C+J+H">Jun Hao Liew</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenxu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiashi Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page at <a href="http://jeff95.me/projects/avatarstudio.html">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We study the problem of creating high-fidelity and animatable 3D avatars from
only textual descriptions. Existing text-to-avatar methods are either limited
to static avatars which cannot be animated or struggle to generate animatable
avatars with promising quality and precise pose control. To address these
limitations, we propose AvatarStudio, a coarse-to-fine generative model that
generates explicit textured 3D meshes for animatable human avatars.
Specifically, AvatarStudio begins with a low-resolution NeRF-based
representation for coarse generation, followed by incorporating SMPL-guided
articulation into the explicit mesh representation to support avatar animation
and high resolution rendering. To ensure view consistency and pose
controllability of the resulting avatars, we introduce a 2D diffusion model
conditioned on DensePose for Score Distillation Sampling supervision. By
effectively leveraging the synergy between the articulated mesh representation
and the DensePose-conditional diffusion model, AvatarStudio can create
high-quality avatars from text that are ready for animation, significantly
outperforming previous methods. Moreover, it is competent for many
applications, e.g., multimodal avatar animations and style-guided avatar
creation. For more results, please refer to our project page:
<a href="http://jeff95.me/projects/avatarstudio.html">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17918" title="Abstract">arXiv:2311.17918</a> [<a href="/pdf/2311.17918" title="Download PDF">pdf</a>, <a href="/format/2311.17918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Driving into the Future: Multiview Visual Forecasting and Planning with  World Model for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiawei He</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lue Fan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuntao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoxiang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://drive-wm.github.io.">this https URL</a> Code: <a href="https://github.com/BraveGroup/Drive-WM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In autonomous driving, predicting future events in advance and evaluating the
foreseeable risks empowers autonomous vehicles to better plan their actions,
enhancing safety and efficiency on the road. To this end, we propose Drive-WM,
the first driving world model compatible with existing end-to-end planning
models. Through a joint spatial-temporal modeling facilitated by view
factorization, our model generates high-fidelity multiview videos in driving
scenes. Building on its powerful generation ability, we showcase the potential
of applying the world model for safe driving planning for the first time.
Particularly, our Drive-WM enables driving into multiple futures based on
distinct driving maneuvers, and determines the optimal trajectory according to
the image-based rewards. Evaluation on real-world driving datasets verifies
that our method could generate high-quality, consistent, and controllable
multiview videos, opening up possibilities for real-world simulations and safe
planning.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17919" title="Abstract">arXiv:2311.17919</a> [<a href="/pdf/2311.17919" title="Download PDF">pdf</a>, <a href="/format/2311.17919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Anagrams: Generating Multi-View Optical Illusions with Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geng%2C+D">Daniel Geng</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+I">Inbum Park</a>, 
<a href="/search/cs?searchtype=author&query=Owens%2C+A">Andrew Owens</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We address the problem of synthesizing multi-view optical illusions: images
that change appearance upon a transformation, such as a flip or rotation. We
propose a simple, zero-shot method for obtaining these illusions from
off-the-shelf text-to-image diffusion models. During the reverse diffusion
process, we estimate the noise from different views of a noisy image. We then
combine these noise estimates together and denoise the image. A theoretical
analysis suggests that this method works precisely for views that can be
written as orthogonal transformations, of which permutations are a subset. This
leads to the idea of a visual anagram--an image that changes appearance under
some rearrangement of pixels. This includes rotations and flips, but also more
exotic pixel permutations such as a jigsaw rearrangement. Our approach also
naturally extends to illusions with more than two views. We provide both
qualitative and quantitative results demonstrating the effectiveness and
flexibility of our method. Please see our project webpage for additional
visualizations and results: https://dangeng.github.io/visual_anagrams/
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17921" title="Abstract">arXiv:2311.17921</a> [<a href="/pdf/2311.17921" title="Download PDF">pdf</a>, <a href="/format/2311.17921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do text-free diffusion models learn discriminative visual  representations?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mukhopadhyay%2C+S">Soumik Mukhopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Gwilliam%2C+M">Matthew Gwilliam</a>, 
<a href="/search/cs?searchtype=author&query=Yamaguchi%2C+Y">Yosuke Yamaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+V">Vatsal Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Padmanabhan%2C+N">Namitha Padmanabhan</a>, 
<a href="/search/cs?searchtype=author&query=Swaminathan%2C+A">Archana Swaminathan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+A">Abhinav Shrivastava</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Website: see <a href="https://mgwillia.github.io/diffssl/">this https URL</a> . Code: see <a href="https://github.com/soumik-kanad/diffssl">this https URL</a> . The first two authors contributed equally. 15 pages, 9 figures, 15 tables. Submission under review. arXiv admin note: text overlap with <a href="/abs/2307.08702">arXiv:2307.08702</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While many unsupervised learning models focus on one family of tasks, either
generative or discriminative, we explore the possibility of a unified
representation learner: a model which addresses both families of tasks
simultaneously. We identify diffusion models, a state-of-the-art method for
generative tasks, as a prime candidate. Such models involve training a U-Net to
iteratively predict and remove noise, and the resulting model can synthesize
high-fidelity, diverse, novel images. We find that the intermediate feature
maps of the U-Net are diverse, discriminative feature representations. We
propose a novel attention mechanism for pooling feature maps and further
leverage this mechanism as DifFormer, a transformer feature fusion of features
from different diffusion U-Net blocks and noise steps. We also develop DifFeed,
a novel feedback mechanism tailored to diffusion. We find that diffusion models
are better than GANs, and, with our fusion and feedback mechanisms, can compete
with state-of-the-art unsupervised image representation learning methods for
discriminative tasks - image classification with full and semi-supervision,
transfer for fine-grained classification, object detection and segmentation,
and semantic segmentation. Our project website
(https://mgwillia.github.io/diffssl/) and code
(https://github.com/soumik-kanad/diffssl) are available publicly.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17922" title="Abstract">arXiv:2311.17922</a> [<a href="/pdf/2311.17922" title="Download PDF">pdf</a>, <a href="/format/2311.17922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple Recipe for Language-guided Domain Generalized Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fahes%2C+M">Mohammad Fahes</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+T">Tuan-Hung Vu</a>, 
<a href="/search/cs?searchtype=author&query=Bursuc%2C+A">Andrei Bursuc</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+P">Patrick P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=de+Charette%2C+R">Raoul de Charette</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://astra-vision.github.io/FAMix">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generalization to new domains not seen during training is one of the
long-standing goals and challenges in deploying neural networks in real-world
applications. Existing generalization techniques necessitate substantial data
augmentation, potentially sourced from external datasets, and aim at learning
invariant representations by imposing various alignment constraints.
Large-scale pretraining has recently shown promising generalization
capabilities, along with the potential of bridging different modalities. For
instance, the recent advent of vision-language models like CLIP has opened the
doorway for vision models to exploit the textual modality. In this paper, we
introduce a simple framework for generalizing semantic segmentation networks by
employing language as the source of randomization. Our recipe comprises three
key ingredients: i) the preservation of the intrinsic CLIP robustness through
minimal fine-tuning, ii) language-driven local style augmentation, and iii)
randomization by locally mixing the source and augmented styles during
training. Extensive experiments report state-of-the-art results on various
generalization benchmarks. The code will be made available.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Thu, 30 Nov 23</h3>
<dl>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08706" title="Abstract">arXiv:2303.08706</a> (cross-list from eess.SY) [<a href="/pdf/2303.08706" title="Download PDF">pdf</a>, <a href="/format/2303.08706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Modular Redundancy: Exploring Modular Redundancy Approaches in  RISC-V Multi-Core Computing Clusters for Reliable Processing in Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rogenmoser%2C+M">Michael Rogenmoser</a>, 
<a href="/search/eess?searchtype=author&query=Tortorella%2C+Y">Yvan Tortorella</a>, 
<a href="/search/eess?searchtype=author&query=Rossi%2C+D">Davide Rossi</a>, 
<a href="/search/eess?searchtype=author&query=Conti%2C+F">Francesco Conti</a>, 
<a href="/search/eess?searchtype=author&query=Benini%2C+L">Luca Benini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Space Cyber-Physical Systems (S-CPS) such as spacecraft and satellites
strongly rely on the reliability of onboard computers to guarantee the success
of their missions. Relying solely on radiation-hardened technologies is
extremely expensive, and developing inflexible architectural and
microarchitectural modifications to introduce modular redundancy within a
system leads to significant area increase and performance degradation. To
mitigate the overheads of traditional radiation hardening and modular
redundancy approaches, we present a novel Hybrid Modular Redundancy (HMR)
approach, a redundancy scheme that features a cluster of RISC-V processors with
a flexible on-demand dual-core and triple-core lockstep grouping of computing
cores with runtime split-lock capabilities. Further, we propose two recovery
approaches, software-based and hardware-based, trading off performance and area
overhead. Running at 430 MHz, our fault-tolerant cluster achieves up to 1160
MOPS on a matrix multiplication benchmark when configured in non-redundant mode
and 617 and 414 MOPS in dual and triple mode, respectively. A software-based
recovery in triple mode requires 363 clock cycles and occupies 0.612 mm2,
representing a 1.3% area overhead over a non-redundant 12-core RISC-V cluster.
As a high-performance alternative, a new hardware-based method provides rapid
fault recovery in just 24 clock cycles and occupies 0.660 mm2, namely ~9.4%
area overhead over the baseline non-redundant RISC-V cluster. The cluster is
also enhanced with split-lock capabilities to enter one of the redundant modes
with minimum performance loss, allowing execution of a mission-critical or a
performance section, with &lt;400 clock cycles overhead for entry and exit. The
proposed system is the first to integrate these functionalities on an
open-source RISC-V-based compute device, enabling finely tunable reliability
vs. performance trade-offs.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16410" title="Abstract">arXiv:2311.16410</a> (cross-list from math.NA) [<a href="/pdf/2311.16410" title="Download PDF">pdf</a>, <a href="/format/2311.16410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reduced-order modeling for parameterized PDEs via implicit neural  representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wen%2C+T">Tianshu Wen</a>, 
<a href="/search/math?searchtype=author&query=Lee%2C+K">Kookjin Lee</a>, 
<a href="/search/math?searchtype=author&query=Choi%2C+Y">Youngsoo Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures, Machine Learning and the Physical Sciences Workshop, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Mathematical Physics (math-ph); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">We present a new data-driven reduced-order modeling approach to efficiently
solve parametrized partial differential equations (PDEs) for many-query
problems. This work is inspired by the concept of implicit neural
representation (INR), which models physics signals in a continuous manner and
independent of spatial/temporal discretization. The proposed framework encodes
PDE and utilizes a parametrized neural ODE (PNODE) to learn latent dynamics
characterized by multiple PDE parameters. PNODE can be inferred by a
hypernetwork to reduce the potential difficulties in learning PNODE due to a
complex multilayer perceptron (MLP). The framework uses an INR to decode the
latent dynamics and reconstruct accurate PDE solutions. Further, a
physics-informed loss is also introduced to correct the prediction of unseen
parameter instances. Incorporating the physics-informed loss also enables the
model to be fine-tuned in an unsupervised manner on unseen PDE parameters. A
numerical experiment is performed on a two-dimensional Burgers equation with a
large variation of PDE parameters. We evaluate the proposed method at a large
Reynolds number and obtain up to speedup of O(10^3) and ~1% relative error to
the ground truth values.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16457" title="Abstract">arXiv:2311.16457</a> (cross-list from physics.soc-ph) [<a href="/pdf/2311.16457" title="Download PDF">pdf</a>, <a href="/format/2311.16457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fixation dynamics on multilayer networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Liu%2C+R">Ruodan Liu</a>, 
<a href="/search/physics?searchtype=author&query=Masuda%2C+N">Naoki Masuda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Network structure has a large impact on constant-selection evolutionary
dynamics, with which multiple types of different fitnesses (i.e., strengths)
compete on the network. Here we study constant-selection dynamics on two-layer
networks in which the fitness of a node in one layer affects that in the other
layer, under birth-death processes and uniform initialization, which are
commonly assumed. We show mathematically and numerically that two-layer
networks are suppressors of selection, which suppresses the effects of the
different fitness values between the different types on final outcomes of the
evolutionary dynamics (called fixation probability), relative to the
constituent one-layer networks. In fact, many two-layer networks are
suppressors of selection relative to the most basic baseline, the Moran
process. This result is in stark contrast with the results for conventional
one-layer networks for which most networks are amplifiers of selection.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17065" title="Abstract">arXiv:2311.17065</a> (cross-list from eess.AS) [<a href="/pdf/2311.17065" title="Download PDF">pdf</a>, <a href="/format/2311.17065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Deep Speech Understanding at the Edge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+R">Rongxiang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+F">Felix Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Contemporary Speech Understanding (SU) involves a sophisticated pipeline:
capturing real-time voice input, the pipeline encompasses a deep neural network
with an encoder-decoder architecture enhanced by beam search. This network
periodically assesses attention and Connectionist Temporal Classification (CTC)
scores in its autoregressive output.
<br />This paper aims to enhance SU performance on edge devices with limited
resources. It pursues two intertwined goals: accelerating on-device execution
and efficiently handling inputs that surpass the on-device model's capacity.
While these objectives are well-established, we introduce innovative solutions
that specifically address SU's distinctive challenges: 1. Late
contextualization: Enables the parallel execution of a model's attentive
encoder during input ingestion. 2. Pilot decoding: Alleviates temporal load
imbalances. 3. Autoregression offramps: Facilitate offloading decisions based
on partial output sequences.
<br />Our techniques seamlessly integrate with existing SU models, pipelines, and
frameworks, allowing for independent or combined application. Together, they
constitute a hybrid solution for edge SU, exemplified by our prototype, XYZ.
Evaluated on platforms equipped with 6-8 Arm cores, our system achieves
State-of-the-Art (SOTA) accuracy, reducing end-to-end latency by 2x and halving
offloading requirements.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17066" title="Abstract">arXiv:2311.17066</a> (cross-list from q-bio.QM) [<a href="/pdf/2311.17066" title="Download PDF">pdf</a>, <a href="/ps/2311.17066" title="Download PostScript">ps</a>, <a href="/format/2311.17066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cluster trajectory of SOFA score in predicting mortality in sepsis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Ke%2C+Y">Yuhe Ke</a>, 
<a href="/search/q-bio?searchtype=author&query=Tang%2C+M+S+S">Matilda Swee Sun Tang</a>, 
<a href="/search/q-bio?searchtype=author&query=Loh%2C+C+J+L">Celestine Jia Ling Loh</a>, 
<a href="/search/q-bio?searchtype=author&query=Abdullah%2C+H+R">Hairil Rizal Abdullah</a>, 
<a href="/search/q-bio?searchtype=author&query=Shannon%2C+N+B">Nicholas Brian Shannon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 4 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Objective: Sepsis is a life-threatening condition. Sequential Organ Failure
Assessment (SOFA) score is commonly used to assess organ dysfunction and
predict ICU mortality, but it is taken as a static measurement and fails to
capture dynamic changes. This study aims to investigate the relationship
between dynamic changes in SOFA scores over the first 72 hours of ICU admission
and patient outcomes.
<br />Design, setting, and participants: 3,253 patients in the Medical Information
Mart for Intensive Care IV database who met the sepsis-3 criteria and were
admitted from the emergency department with at least 72 hours of ICU admission
and full-active resuscitation status were analysed. Group-based trajectory
modelling with dynamic time warping and k-means clustering identified distinct
trajectory patterns in dynamic SOFA scores. They were subsequently compared
using Python.
<br />Main outcome measures: Outcomes including hospital and ICU mortality, length
of stay in hospital and ICU, and readmission during hospital stay, were
collected. Discharge time from ICU to wards and cut-offs at 7-day and 14-day
were taken.
<br />Results: Four clusters were identified: A (consistently low SOFA scores), B
(rapid increase followed by a decline in SOFA scores), C (higher baseline
scores with gradual improvement), and D (persistently elevated scores). Cluster
D had the longest ICU and hospital stays, highest ICU and hospital mortality.
Discharge rates from ICU were similar for Clusters A and B, while Cluster C had
initially comparable rates but a slower transition to ward.
<br />Conclusion: Monitoring dynamic changes in SOFA score is valuable for
assessing sepsis severity and treatment responsiveness.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17103" title="Abstract">arXiv:2311.17103</a> (cross-list from q-bio.GN) [<a href="/pdf/2311.17103" title="Download PDF">pdf</a>, <a href="/format/2311.17103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-cell Multi-view Clustering via Community Detection with Unknown  Number of Clusters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Hu%2C+D">Dayu Hu</a>, 
<a href="/search/q-bio?searchtype=author&query=Dong%2C+Z">Zhibin Dong</a>, 
<a href="/search/q-bio?searchtype=author&query=Liang%2C+K">Ke Liang</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+S">Siwei Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+X">Xinwang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Single-cell multi-view clustering enables the exploration of cellular
heterogeneity within the same cell from different views. Despite the
development of several multi-view clustering methods, two primary challenges
persist. Firstly, most existing methods treat the information from both
single-cell RNA (scRNA) and single-cell Assay of Transposase Accessible
Chromatin (scATAC) views as equally significant, overlooking the substantial
disparity in data richness between the two views. This oversight frequently
leads to a degradation in overall performance. Additionally, the majority of
clustering methods necessitate manual specification of the number of clusters
by users. However, for biologists dealing with cell data, precisely determining
the number of distinct cell types poses a formidable challenge. To this end, we
introduce scUNC, an innovative multi-view clustering approach tailored for
single-cell data, which seamlessly integrates information from different views
without the need for a predefined number of clusters. The scUNC method
comprises several steps: initially, it employs a cross-view fusion network to
create an effective embedding, which is then utilized to generate initial
clusters via community detection. Subsequently, the clusters are automatically
merged and optimized until no further clusters can be merged. We conducted a
comprehensive evaluation of scUNC using three distinct single-cell datasets.
The results underscored that scUNC outperforms the other baseline methods.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17141" title="Abstract">arXiv:2311.17141</a> (cross-list from astro-ph.CO) [<a href="/pdf/2311.17141" title="Download PDF">pdf</a>, <a href="/format/2311.17141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A point cloud approach to generative modeling for galaxy surveys at the  field level
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Cuesta-Lazaro%2C+C">Carolina Cuesta-Lazaro</a>, 
<a href="/search/astro-ph?searchtype=author&query=Mishra-Sharma%2C+S">Siddharth Mishra-Sharma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15+3 pages, 7+4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cosmology and Nongalactic Astrophysics (astro-ph.CO)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">We introduce a diffusion-based generative model to describe the distribution
of galaxies in our Universe directly as a collection of points in 3-D space
(coordinates) optionally with associated attributes (e.g., velocities and
masses), without resorting to binning or voxelization. The custom diffusion
model can be used both for emulation, reproducing essential summary statistics
of the galaxy distribution, as well as inference, by computing the conditional
likelihood of a galaxy field. We demonstrate a first application to massive
dark matter haloes in the Quijote simulation suite. This approach can be
extended to enable a comprehensive analysis of cosmological data, circumventing
limitations inherent to summary statistic -- as well as neural simulation-based
inference methods.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17143" title="Abstract">arXiv:2311.17143</a> (cross-list from astro-ph.IM) [<a href="/pdf/2311.17143" title="Download PDF">pdf</a>, <a href="/format/2311.17143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting the Age of Astronomical Transients from Real-Time  Multivariate Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Huang%2C+H">Hali Huang</a>, 
<a href="/search/astro-ph?searchtype=author&query=Muthukrishna%2C+D">Daniel Muthukrishna</a>, 
<a href="/search/astro-ph?searchtype=author&query=Nair%2C+P">Prajna Nair</a>, 
<a href="/search/astro-ph?searchtype=author&query=Zhang%2C+Z">Zimi Zhang</a>, 
<a href="/search/astro-ph?searchtype=author&query=Fausnaugh%2C+M">Michael Fausnaugh</a>, 
<a href="/search/astro-ph?searchtype=author&query=Majumder%2C+T">Torsha Majumder</a>, 
<a href="/search/astro-ph?searchtype=author&query=Foley%2C+R+J">Ryan J. Foley</a>, 
<a href="/search/astro-ph?searchtype=author&query=Ricker%2C+G+R">George R. Ricker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures. Accepted at the NeurIPS 2023 Machine Learning and the Physical Sciences workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; High Energy Astrophysical Phenomena (astro-ph.HE); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Astronomical transients, such as supernovae and other rare stellar
explosions, have been instrumental in some of the most significant discoveries
in astronomy. New astronomical sky surveys will soon record unprecedented
numbers of transients as sparsely and irregularly sampled multivariate time
series. To improve our understanding of the physical mechanisms of transients
and their progenitor systems, early-time measurements are necessary.
Prioritizing the follow-up of transients based on their age along with their
class is crucial for new surveys. To meet this demand, we present the first
method of predicting the age of transients in real-time from multi-wavelength
time-series observations. We build a Bayesian probabilistic recurrent neural
network. Our method can accurately predict the age of a transient with robust
uncertainties as soon as it is initially triggered by a survey telescope. This
work will be essential for the advancement of our understanding of the numerous
young transients being detected by ongoing and upcoming astronomical surveys.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17162" title="Abstract">arXiv:2311.17162</a> (cross-list from hep-ex) [<a href="/pdf/2311.17162" title="Download PDF">pdf</a>, <a href="/format/2311.17162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Particle-based Anomaly Detection Algorithm with Variational  Autoencoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ex?searchtype=author&query=Liu%2C+R">Ryan Liu</a>, 
<a href="/search/hep-ex?searchtype=author&query=Gandrakota%2C+A">Abhijith Gandrakota</a>, 
<a href="/search/hep-ex?searchtype=author&query=Ngadiuba%2C+J">Jennifer Ngadiuba</a>, 
<a href="/search/hep-ex?searchtype=author&query=Spiropulu%2C+M">Maria Spiropulu</a>, 
<a href="/search/hep-ex?searchtype=author&query=Vlimant%2C+J">Jean-Roch Vlimant</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, accepted at the Machine Learning and the Physical Sciences Workshop, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Experiment (hep-ex)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Model-agnostic anomaly detection is one of the promising approaches in the
search for new beyond the standard model physics. In this paper, we present
Set-VAE, a particle-based variational autoencoder (VAE) anomaly detection
algorithm. We demonstrate a 2x signal efficiency gain compared with traditional
subjettiness-based jet selection. Furthermore, with an eye to the future
deployment to trigger systems, we propose the CLIP-VAE, which reduces the
inference-time cost of anomaly detection by using the KL-divergence loss as the
anomaly score, resulting in a 2x acceleration in latency and reducing the
caching requirement.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17166" title="Abstract">arXiv:2311.17166</a> (cross-list from cond-mat.stat-mech) [<a href="/pdf/2311.17166" title="Download PDF">pdf</a>, <a href="/format/2311.17166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is stochastic thermodynamics the key to understanding the energy costs  of computation?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Wolpert%2C+D">David Wolpert</a>, 
<a href="/search/cond-mat?searchtype=author&query=Korbel%2C+J">Jan Korbel</a>, 
<a href="/search/cond-mat?searchtype=author&query=Lynn%2C+C">Christopher Lynn</a>, 
<a href="/search/cond-mat?searchtype=author&query=Tasnim%2C+F">Farita Tasnim</a>, 
<a href="/search/cond-mat?searchtype=author&query=Grochow%2C+J">Joshua Grochow</a>, 
<a href="/search/cond-mat?searchtype=author&query=Karde%C5%9F%2C+G">G&#xfc;lce Karde&#x15f;</a>, 
<a href="/search/cond-mat?searchtype=author&query=Aimone%2C+J">James Aimone</a>, 
<a href="/search/cond-mat?searchtype=author&query=Balasubramanian%2C+V">Vijay Balasubramanian</a>, 
<a href="/search/cond-mat?searchtype=author&query=de+Giuli%2C+E">Eric de Giuli</a>, 
<a href="/search/cond-mat?searchtype=author&query=Doty%2C+D">David Doty</a>, 
<a href="/search/cond-mat?searchtype=author&query=Freitas%2C+N">Nahuel Freitas</a>, 
<a href="/search/cond-mat?searchtype=author&query=Marsili%2C+M">Matteo Marsili</a>, 
<a href="/search/cond-mat?searchtype=author&query=Ouldridge%2C+T+E">Thomas E. Ouldridge</a>, 
<a href="/search/cond-mat?searchtype=author&query=Richa%2C+A">Andrea Richa</a>, 
<a href="/search/cond-mat?searchtype=author&query=Riechers%2C+P">Paul Riechers</a>, 
<a href="/search/cond-mat?searchtype=author&query=Rold%C3%A1n%2C+%C3%89">&#xc9;dgar Rold&#xe1;n</a>, 
<a href="/search/cond-mat?searchtype=author&query=Rubenstein%2C+B">Brenda Rubenstein</a>, 
<a href="/search/cond-mat?searchtype=author&query=Toroczkai%2C+Z">Zoltan Toroczkai</a>, 
<a href="/search/cond-mat?searchtype=author&query=Paradiso%2C+J">Joseph Paradiso</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Mechanics (cond-mat.stat-mech)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">The relationship between the thermodynamic and computational characteristics
of dynamical physical systems has been a major theoretical interest since at
least the 19th century, and has been of increasing practical importance as the
energetic cost of digital devices has exploded over the last half century. One
of the most important thermodynamic features of real world computers is that
they operate very far from thermal equilibrium, in finite time, with many
quickly (co-)evolving degrees of freedom - in contrast to the quasi-statically
slow processes considered in 20th century analyses of the thermodynamics of
computational processes. Such processes also must obey multiple physical
constraints on how they work. For example, all modern digital computers are
periodic processes, governed by a global clock. Another example is that many
computers are modular, hierarchical systems, with strong restrictions on the
connectivity of their subsystems. This is true for naturally occurring
computers, like brains or Eukaryotic cells, as well as digital systems.
However, the field of stochastic thermodynamics has been developed in the last
few decades, and it provides the formal tools for analyzing exactly these kinds
of computational systems. We argue here that these tools, together with new
ones currently being developed in stochastic thermodynamics, may help us
understand at a far deeper level just how the fundamental physical properties
of dynamic systems are related to the computation that they perform.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17210" title="Abstract">arXiv:2311.17210</a> (cross-list from math.LO) [<a href="/pdf/2311.17210" title="Download PDF">pdf</a>, <a href="/format/2311.17210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ordinals and recursive algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shiboli%2C+L">Lior Shiboli</a>, 
<a href="/search/math?searchtype=author&query=Nivasch%2C+G">Gabriel Nivasch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We prove the following result, which generalizes results of Erickson et al.
(2022) and Bufetov et al. (2024): Call a function $f:\mathbb{R}\to \mathbb{R}$
ordinal decreasing if for every infinite decreasing sequence
$x_0&gt;x_1&gt;x_2&gt;\cdots$ there exist $i&lt;j$ such that $f(x_j) \geq f(x_i)$. Given
ordinal decreasing functions $f,g_0,\ldots,g_k,s$ that are larger than $0$,
define the recursive algorithm "$M(x)$: if $x&lt;0$ return $f(x)$, else return
$g_0(-M(x-g_1(-M(x-\cdots-g_k(-M(x-s(x)))\cdots))))$". Then $M(x)$ halts and is
ordinal decreasing for all $x \in \mathbb{R}$.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17215" title="Abstract">arXiv:2311.17215</a> (cross-list from math.NT) [<a href="/pdf/2311.17215" title="Download PDF">pdf</a>, <a href="/format/2311.17215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applications of Moments of Dirichlet Coefficients in Elliptic Curve  Families
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Batterman%2C+Z">Zo&#xeb; Batterman</a>, 
<a href="/search/math?searchtype=author&query=Jambhale%2C+A">Aditya Jambhale</a>, 
<a href="/search/math?searchtype=author&query=Miller%2C+S+J">Steven J. Miller</a>, 
<a href="/search/math?searchtype=author&query=Narayanan%2C+A+L">Akash L. Narayanan</a>, 
<a href="/search/math?searchtype=author&query=Sharma%2C+K">Kishan Sharma</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+A">Andrew Yang</a>, 
<a href="/search/math?searchtype=author&query=Yao%2C+C">Chris Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Number Theory (math.NT)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">The moments of the coefficients of elliptic curve L-functions are related to
numerous arithmetic problems. Rosen and Silverman proved a conjecture of Nagao
relating the first moment of one-parameter families satisfying Tate's
conjecture to the rank of the corresponding elliptic surface over Q(T); one can
also construct families of moderate rank by finding families with large first
moments. Michel proved that if j(T) is not constant, then the second moment of
the family is of size p^2 + O(p^(3/2)); these two moments show that for
suitably small support the behavior of zeros near the central point agree with
that of eigenvalues from random matrix ensembles, with the higher moments
impacting the rate of convergence.
<br />In his thesis, Miller noticed a negative bias in the second moment of every
one-parameter family of elliptic curves over the rationals whose second moment
had a calculable closed-form expression, specifically the first lower order
term which does not average to zero is on average negative. This Bias
Conjecture is confirmed for many families; however, these are highly
non-generic families whose resulting Legendre sums can be determined. Inspired
by the recent successes by Yang-Hui He, Kyu-Hwan Lee, Thomas Oliver, Alexey
Pozdnyakov and others in investigations of murmurations of elliptic curve
coefficients with machine learning techniques, we pose a similar problem for
trying to understand the Bias Conjecture. As a start to this program, we
numerically investigate the Bias Conjecture for a family whose bias is positive
for half the primes. Since the numerics do not offer conclusive evidence that
negative bias for the other half is enough to overwhelm the positive bias, the
Bias Conjecture cannot be verified for the family.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17248" title="Abstract">arXiv:2311.17248</a> (cross-list from eess.SP) [<a href="/pdf/2311.17248" title="Download PDF">pdf</a>, <a href="/format/2311.17248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Regularized Compound Gaussian Network for Solving Linear Inverse  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lyons%2C+C">Carter Lyons</a>, 
<a href="/search/eess?searchtype=author&query=Raj%2C+R+G">Raghu G. Raj</a>, 
<a href="/search/eess?searchtype=author&query=Cheney%2C+M">Margaret Cheney</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review by IEEE TCI. 16 pages, 8 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Incorporating prior information into inverse problems, e.g. via
maximum-a-posteriori estimation, is an important technique for facilitating
robust inverse problem solutions. In this paper, we devise two novel approaches
for linear inverse problems that permit problem-specific statistical prior
selections within the compound Gaussian (CG) class of distributions. The CG
class subsumes many commonly used priors in signal and image reconstruction
methods including those of sparsity-based approaches. The first method
developed is an iterative algorithm, called generalized compound Gaussian least
squares (G-CG-LS), that minimizes a regularized least squares objective
function where the regularization enforces a CG prior. G-CG-LS is then
unrolled, or unfolded, to furnish our second method, which is a novel deep
regularized (DR) neural network, called DR-CG-Net, that learns the prior
information. A detailed computational theory on convergence properties of
G-CG-LS and thorough numerical experiments for DR-CG-Net are provided. Due to
the comprehensive nature of the CG prior, these experiments show that our
unrolled DR-CG-Net outperforms competitive prior art methods in tomographic
imaging and compressive sensing, especially in challenging low-training
scenarios.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17251" title="Abstract">arXiv:2311.17251</a> (cross-list from eess.IV) [<a href="/pdf/2311.17251" title="Download PDF">pdf</a>, <a href="/format/2311.17251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SubZero: Subspace Zero-Shot MRI Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yu%2C+H">Heng Yu</a>, 
<a href="/search/eess?searchtype=author&query=Arefeen%2C+Y">Yamin Arefeen</a>, 
<a href="/search/eess?searchtype=author&query=Bilgic%2C+B">Berkin Bilgic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ISMRM 2023 Power Pitch
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recently introduced zero-shot self-supervised learning (ZS-SSL) has shown
potential in accelerated MRI in a scan-specific scenario, which enabled
high-quality reconstructions without access to a large training dataset. ZS-SSL
has been further combined with the subspace model to accelerate 2D T2-shuffling
acquisitions. In this work, we propose a parallel network framework and
introduce an attention mechanism to improve subspace-based zero-shot
self-supervised learning and enable higher acceleration factors. We name our
method SubZero and demonstrate that it can achieve improved performance
compared with current methods in T1 and T2 mapping acquisitions.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17284" title="Abstract">arXiv:2311.17284</a> (cross-list from math.OC) [<a href="/pdf/2311.17284" title="Download PDF">pdf</a>, <a href="/format/2311.17284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discrete-to-continuum limits of optimal transport with linear growth on  periodic graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Portinale%2C+L">Lorenzo Portinale</a>, 
<a href="/search/math?searchtype=author&query=Quattrocchi%2C+F">Filippo Quattrocchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Analysis of PDEs (math.AP); Numerical Analysis (math.NA)

</div>
<p class="mathjax">We prove discrete-to-continuum convergence for dynamical optimal transport on
$\mathbb{Z}^d$-periodic graphs with energy density having linear growth at
infinity. This result provides an answer to a problem left open by Gladbach,
Kopfer, Maas, and Portinale (Calc Var Partial Differential Equations 62(5),
2023), where the convergence behaviour of discrete boundary-value dynamical
transport problems is proved under the stronger assumption of superlinear
growth. Our result extends the known literature to some important classes of
examples, such as scaling limits of 1-Wasserstein transport problems. Similarly
to what happens in the quadratic case, the geometry of the graph plays a
crucial role in the structure of the limit cost function, as we discuss in the
final part of this work, which includes some visual representations.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17340" title="Abstract">arXiv:2311.17340</a> (cross-list from eess.IV) [<a href="/pdf/2311.17340" title="Download PDF">pdf</a>, <a href="/format/2311.17340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Scope Spatial-Spectral Information Aggregation for Hyperspectral  Image Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+S">Shi Chen</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Lefei Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Liangpei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Hyperspectral image super-resolution has attained widespread prominence to
enhance the spatial resolution of hyperspectral images. However,
convolution-based methods have encountered challenges in harnessing the global
spatial-spectral information. The prevailing transformer-based methods have not
adequately captured the long-range dependencies in both spectral and spatial
dimensions. To alleviate this issue, we propose a novel cross-scope
spatial-spectral Transformer (CST) to efficiently investigate long-range
spatial and spectral similarities for single hyperspectral image
super-resolution. Specifically, we devise cross-attention mechanisms in spatial
and spectral dimensions to comprehensively model the long-range
spatial-spectral characteristics. By integrating global information into the
rectangle-window self-attention, we first design a cross-scope spatial
self-attention to facilitate long-range spatial interactions. Then, by
leveraging appropriately characteristic spatial-spectral features, we construct
a cross-scope spectral self-attention to effectively capture the intrinsic
correlations among global spectral bands. Finally, we elaborate a concise
feed-forward neural network to enhance the feature representation capacity in
the Transformer structure. Extensive experiments over three hyperspectral
datasets demonstrate that the proposed CST is superior to other
state-of-the-art methods both quantitatively and visually. The code is
available at \url{https://github.com/Tomchenshi/CST.git}.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17343" title="Abstract">arXiv:2311.17343</a> (cross-list from q-bio.PE) [<a href="/pdf/2311.17343" title="Download PDF">pdf</a>, <a href="/format/2311.17343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forays into Fungal Fighting and Mycological Moisture Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Blackwelder%2C+J">John Blackwelder</a>, 
<a href="/search/q-bio?searchtype=author&query=DiSilvio%2C+S">Steven DiSilvio</a>, 
<a href="/search/q-bio?searchtype=author&query=Ozerov%2C+A">Anthony Ozerov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Populations and Evolution (q-bio.PE)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">As the impending consequences of climate change loom over the Earth, it has
become vital for researchers to understand the role microorganisms play in this
process. In this paper, we examine how environmental factors, including
moisture levels and temperature, affect the expression of certain fungal
characteristics on a microscale, and how these in turn affect fungal
biodiversity and ecosystem decomposition rates over time.
<br />We first present a differential equation model to understand how the
distribution of different fungal isolates depends on regional moisture levels.
We introduce both slow and sudden variations into the environment in order to
represent the various ways climate change will impact fungal ecosystems. This
model demonstrates that increased variability in moisture (both short-term and
long-term) increases biodiversity and that fungal populations will shift
towards more stress-tolerant fungi as aridity increases. The model further
suggests the lack of any direct link between biodiversity and decomposition
rates.
<br />To better describe fungal competition with respect to space, we develop a
local agent-based model (ABM). Unlike the previous model, our ABM focuses on
individuals, tracking each fungus and the result of its interactions. Our ABM
also features a more accurate spatial combat system, allowing us to precisely
discern the influence of fungal interactions on the environment. This model
corroborates the results of the differential equation model and further
suggests that moisture, through its link with temperature and effects on fungal
population, also plays a strong role in determining fungal decomposition rates.
<br />Together, these models suggest that climate change, which portends increasing
variability in regional conditions and higher average temperatures worldwide,
will lead to an increase in both wood decomposition rates and, independently,
fungal biodiversity.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17353" title="Abstract">arXiv:2311.17353</a> (cross-list from quant-ph) [<a href="/pdf/2311.17353" title="Download PDF">pdf</a>, <a href="/format/2311.17353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous optimization by quantum adaptive distribution search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Morimoto%2C+K">Kohei Morimoto</a>, 
<a href="/search/quant-ph?searchtype=author&query=Takase%2C+Y">Yusuke Takase</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mitarai%2C+K">Kosuke Mitarai</a>, 
<a href="/search/quant-ph?searchtype=author&query=Fujii%2C+K">Keisuke Fujii</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we introduce the quantum adaptive distribution search (QuADS),
a quantum continuous optimization algorithm that integrates Grover adaptive
search (GAS) with the covariance matrix adaptation - evolution strategy
(CMA-ES), a classical technique for continuous optimization. QuADS utilizes the
quantum-based search capabilities of GAS and enhances them with the principles
of CMA-ES for more efficient optimization. It employs a multivariate normal
distribution for the initial state of the quantum search and repeatedly updates
it throughout the optimization process. Our numerical experiments show that
QuADS outperforms both GAS and CMA-ES. This is achieved through adaptive
refinement of the initial state distribution rather than consistently using a
uniform state, resulting in fewer oracle calls. This study presents an
important step toward exploiting the potential of quantum computing for
continuous optimization.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17383" title="Abstract">arXiv:2311.17383</a> (cross-list from nlin.AO) [<a href="/pdf/2311.17383" title="Download PDF">pdf</a>, <a href="/format/2311.17383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamical manifold dimensionality as characterization measure of chimera  states in bursting neuronal networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/nlin?searchtype=author&query=Dogonasheva%2C+O">Olesia Dogonasheva</a>, 
<a href="/search/nlin?searchtype=author&query=Radushev%2C+D">Daniil Radushev</a>, 
<a href="/search/nlin?searchtype=author&query=Gutkin%2C+B">Boris Gutkin</a>, 
<a href="/search/nlin?searchtype=author&query=Zakharov%2C+D">Denis Zakharov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Adaptation and Self-Organizing Systems (nlin.AO)</span>; Dynamical Systems (math.DS); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Methods that distinguish dynamical regimes in networks of active elements
make it possible to design the dynamics of models of realistic networks. A
particularly salient example is partial synchronization, which may play a
pivotal role in elucidating the dynamics of biological neural networks. Such
emergent partial synchronization in structurally homogeneous networks is
commonly denoted as chimera states. While several methods for detecting
chimeras in networks of spiking neurons have been proposed, these are less
effective when applied to networks of bursting neurons. Here we introduce the
correlation dimension as a novel approach to identifying dynamic network
states. To assess the viability of this new method, we study a network of
intrinsically Hindmarsh-Rose neurons with non-local connections. In comparison
to other measures of chimera states, the correlation dimension effectively
characterizes chimeras in burst neurons, whether the incoherence arises in
spikes or bursts. The generality of dimensionality measures inherent in the
correlation dimension renders this approach applicable to any dynamic system,
facilitating the comparison of simulated and experimental data. We anticipate
that this methodology will enable the tuning and simulation of when modelling
intricate network processes, contributing to a deeper understanding of neural
dynamics.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17407" title="Abstract">arXiv:2311.17407</a> (cross-list from math.ST) [<a href="/pdf/2311.17407" title="Download PDF">pdf</a>, <a href="/ps/2311.17407" title="Download PostScript">ps</a>, <a href="/format/2311.17407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strong consistency of an estimator by the truncated singular value  decomposition for an errors-in-variables regression model with collinearity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aishima%2C+K">Kensuke Aishima</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2302.06824">arXiv:2302.06824</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this paper, we prove strong consistency of an estimator by the truncated
singular value decomposition for a multivariate errors-in-variables linear
regression model with collinearity. This result is an extension of Gleser's
proof of the strong consistency of total least squares solutions to the case
with modern rank constraints. While the usual discussion of consistency in the
absence of solution uniqueness deals with the minimal norm solution, the
contribution of this study is to develop a theory that shows the strong
consistency of a set of solutions. The proof is based on properties of
orthogonal projections, specifically properties of the Rayleigh-Ritz procedure
for computing eigenvalues. This makes it suitable for targeting problems where
some row vectors of the matrices do not contain noise. Therefore, this paper
gives a proof for the regression model with the above condition on the row
vectors, resulting in a natural generalization of the strong consistency for
the standard TLS estimator.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17458" title="Abstract">arXiv:2311.17458</a> (cross-list from quant-ph) [<a href="/pdf/2311.17458" title="Download PDF">pdf</a>, <a href="/format/2311.17458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Neural Networks under Depolarization Noise: Exploring White-Box  Attacks and Defenses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Winderl%2C+D">David Winderl</a>, 
<a href="/search/quant-ph?searchtype=author&query=Franco%2C+N">Nicola Franco</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lorenz%2C+J+M">Jeanette Miriam Lorenz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Poster at Quantum Techniques in Machine Learning (QTML) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Leveraging the unique properties of quantum mechanics, Quantum Machine
Learning (QML) promises computational breakthroughs and enriched perspectives
where traditional systems reach their boundaries. However, similarly to
classical machine learning, QML is not immune to adversarial attacks. Quantum
adversarial machine learning has become instrumental in highlighting the weak
points of QML models when faced with adversarial crafted feature vectors.
Diving deep into this domain, our exploration shines light on the interplay
between depolarization noise and adversarial robustness. While previous results
enhanced robustness from adversarial threats through depolarization noise, our
findings paint a different picture. Interestingly, adding depolarization noise
discontinued the effect of providing further robustness for a multi-class
classification scenario. Consolidating our findings, we conducted experiments
with a multi-class classifier adversarially trained on gate-based quantum
simulators, further elucidating this unexpected behavior.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17490" title="Abstract">arXiv:2311.17490</a> (cross-list from quant-ph) [<a href="/pdf/2311.17490" title="Download PDF">pdf</a>, <a href="/format/2311.17490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multithreaded parallelism for heterogeneous clusters of QPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Seitz%2C+P">Philipp Seitz</a>, 
<a href="/search/quant-ph?searchtype=author&query=Geiger%2C+M">Manuel Geiger</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mendl%2C+C+B">Christian B. Mendl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, 1 table, 1 algorithm
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In this work, we present MILQ, a quantum unrelated parallel machines
scheduler and cutter. The setting of unrelated parallel machines considers
independent hardware backends, each distinguished by differing setup and
processing times. MILQ optimizes the total execution time of a batch of
circuits scheduled on multiple quantum devices. It leverages state-of-the-art
circuit-cutting techniques to fit circuits onto the devices and schedules them
based on a mixed-integer linear program. Our results show a total improvement
of up to 26 % compared to a baseline approach.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17515" title="Abstract">arXiv:2311.17515</a> (cross-list from eess.IV) [<a href="/pdf/2311.17515" title="Download PDF">pdf</a>, <a href="/ps/2311.17515" title="Download PostScript">ps</a>, <a href="/format/2311.17515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fusion of Single and Integral Multispectral Aerial Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Youssef%2C+M">Mohamed Youssef</a>, 
<a href="/search/eess?searchtype=author&query=Bimber%2C+O">Oliver Bimber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We present a novel hybrid (model- and learning-based) architecture for fusing
the most significant features from conventional aerial images and integral
aerial images that result from synthetic aperture sensing for removing
occlusion caused by dense vegetation. It combines the environment's spatial
references with features of unoccluded targets. Our method out-beats the
state-of-the-art, does not require manually tuned parameters, can be extended
to an arbitrary number and combinations of spectral channels, and is
reconfigurable to address different use-cases.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17521" title="Abstract">arXiv:2311.17521</a> (cross-list from stat.AP) [<a href="/pdf/2311.17521" title="Download PDF">pdf</a>, <a href="/ps/2311.17521" title="Download PostScript">ps</a>, <a href="/format/2311.17521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spinal Muscle Atrophy Disease Modelling as Bayesian Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Helal%2C+M+E">Mohammed Ezzat Helal</a>, 
<a href="/search/stat?searchtype=author&query=Helal%2C+M+E">Manal Ezzat Helal</a>, 
<a href="/search/stat?searchtype=author&query=Fahmy%2C+S+F">Sherif Fadel Fahmy</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Physics: Conference Series 2128 (2021) 012015
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We investigate the molecular gene expressions studies and public databases
for disease modelling using Probabilistic Graphical Models and Bayesian
Inference. A case study on Spinal Muscle Atrophy Genome-Wide Association Study
results is modelled and analyzed. The genes up and down-regulated in two stages
of the disease development are linked to prior knowledge published in the
public domain and co-expressions network is created and analyzed. The Molecular
Pathways triggered by these genes are identified. The Bayesian inference
posteriors distributions are estimated using a variational analytical algorithm
and a Markov chain Monte Carlo sampling algorithm. Assumptions, limitations and
possible future work are concluded.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17525" title="Abstract">arXiv:2311.17525</a> (cross-list from eess.IV) [<a href="/pdf/2311.17525" title="Download PDF">pdf</a>, <a href="/ps/2311.17525" title="Download PostScript">ps</a>, <a href="/format/2311.17525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A publicly available vessel segmentation algorithm for SLO images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Threlfall%2C+A">Adam Threlfall</a>, 
<a href="/search/eess?searchtype=author&query=Gibbon%2C+S">Samuel Gibbon</a>, 
<a href="/search/eess?searchtype=author&query=Cameron%2C+J">James Cameron</a>, 
<a href="/search/eess?searchtype=author&query=MacGillivray%2C+T">Tom MacGillivray</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Background and Objective: Infra-red scanning laser ophthalmoscope (IRSLO)
images are akin to colour fundus photographs in displaying the posterior pole
and retinal vasculature fine detail. While there are many trained networks
readily available for retinal vessel segmentation in colour fundus photographs,
none cater to IRSLO images. Accordingly, we aimed to develop (and release as
open source) a vessel segmentation algorithm tailored specifically to IRSLO
images. Materials and Methods: We used 23 expertly annotated IRSLO images from
the RAVIR dataset, combined with 7 additional images annotated in-house. We
trained a U-Net (convolutional neural network) to label pixels as 'vessel' or
'background'. Results: On an unseen test set (4 images), our model achieved an
AUC of 0.981, and an AUPRC of 0.815. Upon thresholding, it achieved a
sensitivity of 0.844, a specificity of 0.983, and an F1 score of 0.857.
Conclusion: We have made our automatic segmentation algorithm publicly
available and easy to use. Researchers can use the generated vessel maps to
compute metrics such as fractal dimension and vessel density.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17538" title="Abstract">arXiv:2311.17538</a> (cross-list from q-bio.GN) [<a href="/pdf/2311.17538" title="Download PDF">pdf</a>, <a href="/ps/2311.17538" title="Download PostScript">ps</a>, <a href="/format/2311.17538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Programming Algorithms for Discovery of Antibiotic Resistance in  Microbial Genomes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Helal%2C+M">Manal Helal</a>, 
<a href="/search/q-bio?searchtype=author&query=Sintchenko%2C+V">Vitali Sintchenko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://citeseerx.ist.psu.edu/document?repid=rep1">this https URL</a>&amp;type=pdf&amp;doi=d06cf32f66c6866e2867abdca587419d4958af1e
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> electronic Journal of Health Informatics Vol 6, No 1 (2011): e10
  http://www.ejhi.net
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">The translation of comparative genomics into clinical decision support tools
often depends on the quality of sequence alignments. However, currently used
methods of multiple sequence alignments suffer from significant biases and
problems with aligning diverged sequences. The objective of this study was to
develop and test a new multiple sequence alignment (MSA) algorithm suitable for
the high-throughput comparative analysis of different microbial genomes. This
algorithm employs an innovative tensor indexing method for partitioning the
dynamic programming hyper-cube space for parallel processing. We have used the
clinically relevant task of identifying regions that determine resistance to
antibiotics to test the new algorithm and to compare its performance with
existing MSA methods. The new method "mmDst" performed better than existing MSA
algorithms for more divergent sequences because it employs a simultaneous
alignment scoring recurrence, which effectively approximated the score for edge
missing cell scores that fall outside the scoring region.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17596" title="Abstract">arXiv:2311.17596</a> (cross-list from math.OC) [<a href="/pdf/2311.17596" title="Download PDF">pdf</a>, <a href="/format/2311.17596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Polynomial Chaos Approach to Stochastic LQ Optimal Control: Error  Bounds and Infinite-Horizon Results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ou%2C+R">Ruchuan Ou</a>, 
<a href="/search/math?searchtype=author&query=Schie%C3%9Fl%2C+J">Jonas Schie&#xdf;l</a>, 
<a href="/search/math?searchtype=author&query=Baumann%2C+M+H">Michael Heinrich Baumann</a>, 
<a href="/search/math?searchtype=author&query=Gr%C3%BCne%2C+L">Lars Gr&#xfc;ne</a>, 
<a href="/search/math?searchtype=author&query=Faulwasser%2C+T">Timm Faulwasser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The stochastic linear-quadratic regulator problem subject to Gaussian
disturbances is well known and usually addressed via a moment-based
reformulation. Here, we leverage polynomial chaos expansions, which model
random variables via series expansions in a suitable $\mathcal{L}^2$
probability space, to tackle the non-Gaussian case. We present the optimal
solutions for finite and infinite horizons. Moreover, we quantify the
truncation error and we analyze the infinite-horizon asymptotics. We show that
the limit of the optimal trajectory is the unique solution to a stationary
optimization problem in the sense of probability measures. A numerical example
illustrates our findings.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17624" title="Abstract">arXiv:2311.17624</a> (cross-list from eess.SP) [<a href="/pdf/2311.17624" title="Download PDF">pdf</a>, <a href="/format/2311.17624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combating Multi-path Interference to Improve Chirp-based Underwater  Acoustic Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xie%2C+W">Wenjun Xie</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+E">Enqi Zhang</a>, 
<a href="/search/eess?searchtype=author&query=You%2C+L">Lizhao You</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+D">Deqing Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zhaorui Wang</a>, 
<a href="/search/eess?searchtype=author&query=Fu%2C+L">Liqun Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Linear chirp-based underwater acoustic communication has been widely used due
to its reliability and long-range transmission capability. However, unlike the
counterpart chirp technology in wireless -- LoRa, its throughput is severely
limited by the number of modulated chirps in a symbol. The fundamental
challenge lies in the underwater multi-path channel, where the delayed copied
of one symbol may cause inter-symbol and intra-symbol interfere. In this paper,
we present UWLoRa+, a system that realizes the same chirp modulation as LoRa
with higher data rate, and enhances LoRa's design to address the multi-path
challenge via the following designs: a) we replace the linear chirp used by
LoRa with the non-linear chirp to reduce the signal interference range and the
collision probability; b) we design an algorithm that first demodulates each
path and then combines the demodulation results of detected paths; and c) we
replace the Hamming codes used by LoRa with the non-binary LDPC codes to
mitigate the impact of the inevitable collision.Experiment results show that
the new designs improve the bit error rate (BER) by 3x, and the packet error
rate (PER) significantly, compared with the LoRa's naive design. Compared with
an state-of-the-art system for decoding underwater LoRa chirp signal, UWLoRa+
improves the throughput by up to 50 times.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17646" title="Abstract">arXiv:2311.17646</a> (cross-list from quant-ph) [<a href="/pdf/2311.17646" title="Download PDF">pdf</a>, <a href="/format/2311.17646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A novel feature selection method based on quantum support vector machine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+H">Haiyan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Feature selection is critical in machine learning to reduce dimensionality
and improve model accuracy and efficiency. The exponential growth in feature
space dimensionality for modern datasets directly results in ambiguous samples
and redundant features, which can severely degrade classification accuracy.
Quantum machine learning offers potential advantages for addressing this
challenge. In this paper, we propose a novel method, quantum support vector
machine feature selection (QSVMF), integrating quantum support vector machines
with multi-objective genetic algorithm. QSVMF optimizes multiple simultaneous
objectives: maximizing classification accuracy, minimizing selected features
and quantum circuit costs, and reducing feature covariance. We apply QSVMF for
feature selection on a breast cancer dataset, comparing the performance of
QSVMF against classical approaches with the selected features. Experimental
results show that QSVMF achieves superior performance. Furthermore, The Pareto
front solutions of QSVMF enable analysis of accuracy versus feature set size
trade-offs, identifying extremely sparse yet accurate feature subsets. We
contextualize the biological relevance of the selected features in terms of
known breast cancer biomarkers. This work highlights the potential of
quantum-based feature selection to enhance machine learning efficiency and
performance on complex real-world data.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17670" title="Abstract">arXiv:2311.17670</a> (cross-list from math.CO) [<a href="/pdf/2311.17670" title="Download PDF">pdf</a>, <a href="/ps/2311.17670" title="Download PostScript">ps</a>, <a href="/format/2311.17670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 2-covers of wide Young diagrams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aharoni%2C+R">Ron Aharoni</a>, 
<a href="/search/math?searchtype=author&query=Berger%2C+E">Eli Berger</a>, 
<a href="/search/math?searchtype=author&query=Guo%2C+H">He Guo</a>, 
<a href="/search/math?searchtype=author&query=Kotlar%2C+D">Daniel Kotlar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">A Young diagram $Y$ is called wide if every sub-diagram $Z$ formed by a
subset of the rows of $Y$ dominates $Z'$, the conjugate of $Z$. A Young diagram
$Y$ is called Latin if its squares can be assigned numbers so that for each
$i$, the $i$th row is filled injectively with the numbers $1, \ldots ,a_i$,
where $a_i$ is the length of $i$th row of $Y$, and every column is also filled
injectively. A conjecture of Chow and Taylor, publicized by Chow, Fan, Goemans,
and Vondrak is that a wide Young diagram is Latin. We prove a dual version of
the conjecture.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17673" title="Abstract">arXiv:2311.17673</a> (cross-list from stat.ML) [<a href="/pdf/2311.17673" title="Download PDF">pdf</a>, <a href="/format/2311.17673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Ornstein-Uhlenbeck Process to understand Denoising Diffusion  Probabilistic Model and its Noise Schedules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Santos%2C+J+E">Javier E. Santos</a>, 
<a href="/search/stat?searchtype=author&query=Lin%2C+Y+T">Yen Ting Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Statistical Mechanics (cond-mat.stat-mech); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Mathematical Physics (math-ph)

</div>
<p class="mathjax">The aim of this short note is to show that Denoising Diffusion Probabilistic
Model DDPM, a non-homogeneous discrete-time Markov process, can be represented
by a time-homogeneous continuous-time Markov process observed at non-uniformly
sampled discrete times. Surprisingly, this continuous-time Markov process is
the well-known and well-studied Ornstein-Ohlenbeck (OU) process, which was
developed in 1930's for studying Brownian particles in Harmonic potentials. We
establish the formal equivalence between DDPM and the OU process using its
analytical solution. We further demonstrate that the design problem of the
noise scheduler for non-homogeneous DDPM is equivalent to designing observation
times for the OU process. We present several heuristic designs for observation
times based on principled quantities such as auto-variance and Fisher
Information and connect them to ad hoc noise schedules for DDPM. Interestingly,
we show that the Fisher-Information-motivated schedule corresponds exactly the
cosine schedule, which was developed without any theoretical foundation but is
the current state-of-the-art noise schedule.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17677" title="Abstract">arXiv:2311.17677</a> (cross-list from eess.IV) [<a href="/pdf/2311.17677" title="Download PDF">pdf</a>, <a href="/format/2311.17677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COVIDx CXR-4: An Expanded Multi-Institutional Open-Source Benchmark  Dataset for Chest X-ray Image-Based Computer-Aided COVID-19 Diagnostics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wu%2C+Y">Yifan Wu</a>, 
<a href="/search/eess?searchtype=author&query=Gunraj%2C+H">Hayden Gunraj</a>, 
<a href="/search/eess?searchtype=author&query=Tai%2C+C+A">Chi-en Amy Tai</a>, 
<a href="/search/eess?searchtype=author&query=Wong%2C+A">Alexander Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The global ramifications of the COVID-19 pandemic remain significant,
exerting persistent pressure on nations even three years after its initial
outbreak. Deep learning models have shown promise in improving COVID-19
diagnostics but require diverse and larger-scale datasets to improve
performance. In this paper, we introduce COVIDx CXR-4, an expanded
multi-institutional open-source benchmark dataset for chest X-ray image-based
computer-aided COVID-19 diagnostics. COVIDx CXR-4 expands significantly on the
previous COVIDx CXR-3 dataset by increasing the total patient cohort size by
greater than 2.66 times, resulting in 84,818 images from 45,342 patients across
multiple institutions. We provide extensive analysis on the diversity of the
patient demographic, imaging metadata, and disease distributions to highlight
potential dataset biases. To the best of the authors' knowledge, COVIDx CXR-4
is the largest and most diverse open-source COVID-19 CXR dataset and is made
publicly available as part of an open initiative to advance research to aid
clinicians against the COVID-19 disease.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17727" title="Abstract">arXiv:2311.17727</a> (cross-list from eess.SP) [<a href="/pdf/2311.17727" title="Download PDF">pdf</a>, <a href="/format/2311.17727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Odor-Based Molecular Communications: State-of-the-Art, Vision,  Challenges, and Frontier Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Aktas%2C+D">Dilara Aktas</a>, 
<a href="/search/eess?searchtype=author&query=Ortlek%2C+B+E">Beyza Ezgi Ortlek</a>, 
<a href="/search/eess?searchtype=author&query=Civas%2C+M">Meltem Civas</a>, 
<a href="/search/eess?searchtype=author&query=Baradari%2C+E">Elham Baradari</a>, 
<a href="/search/eess?searchtype=author&query=Okcu%2C+A+S">Ayse Sila Okcu</a>, 
<a href="/search/eess?searchtype=author&query=Whitfield%2C+M">Melanie Whitfield</a>, 
<a href="/search/eess?searchtype=author&query=Cetinkaya%2C+O">Oktay Cetinkaya</a>, 
<a href="/search/eess?searchtype=author&query=Akan%2C+O+B">Ozgur Baris Akan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Humankind mimics the processes and strategies that nature has perfected and
uses them as a model to address its problems. That has recently found a new
direction, i.e., a novel communication technology called molecular
communication (MC), using molecules to encode, transmit, and receive
information. Despite extensive research, an innate MC method with plenty of
natural instances, i.e., olfactory or odor communication, has not yet been
studied with the tools of information and communication technologies (ICT).
Existing studies focus on digitizing this sense and developing actuators
without inspecting the principles of odor-based information coding and MC,
which significantly limits its application potential. Hence, there is a need to
focus cross-disciplinary research efforts to reveal the fundamentals of this
unconventional communication modality from an ICT perspective. The ways of
natural odor MC in nature need to be anatomized and engineered for end-to-end
communication among humans and human-made things to enable several multi-sense
augmented reality technologies reinforced with olfactory senses for novel
applications and solutions in the Internet of Everything (IoE). This paper
introduces the concept of odor-based molecular communication (OMC) and provides
a comprehensive examination of olfactory systems. It explores odor
communication in nature, including aspects of odor information, channels,
reception, spatial perception, and cognitive functions. Additionally, a
comprehensive comparison of various communication systems sets the foundation
for further investigation. By highlighting the unique characteristics,
advantages, and potential applications of OMC through this comparative
analysis, the paper lays the groundwork for exploring the modeling of an
end-to-end OMC channel, considering the design of OMC transmitters and
receivers, and developing innovative OMC techniques.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17740" title="Abstract">arXiv:2311.17740</a> (cross-list from eess.IV) [<a href="/pdf/2311.17740" title="Download PDF">pdf</a>, <a href="/format/2311.17740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A transductive few-shot learning approach for classification of digital  histopathological slides from liver cancer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sadraoui%2C+A">Aymen Sadraoui</a> (OPIS, CVN), 
<a href="/search/eess?searchtype=author&query=Martin%2C+S">S&#xe9;gol&#xe8;ne Martin</a> (OPIS, CVN), 
<a href="/search/eess?searchtype=author&query=Barbot%2C+E">Eliott Barbot</a> (OPIS, CVN), 
<a href="/search/eess?searchtype=author&query=Laurent-Bellue%2C+A">Astrid Laurent-Bellue</a>, 
<a href="/search/eess?searchtype=author&query=Pesquet%2C+J">Jean-Christophe Pesquet</a> (OPIS, CVN), 
<a href="/search/eess?searchtype=author&query=Guettier%2C+C">Catherine Guettier</a>, 
<a href="/search/eess?searchtype=author&query=Ayed%2C+I+B">Ismail Ben Ayed</a> (ETS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG); Tissues and Organs (q-bio.TO)

</div>
<p class="mathjax">This paper presents a new approach for classifying 2D histopathology patches
using few-shot learning. The method is designed to tackle a significant
challenge in histopathology, which is the limited availability of labeled data.
By applying a sliding window technique to histopathology slides, we illustrate
the practical benefits of transductive learning (i.e., making joint predictions
on patches) to achieve consistent and accurate classification. Our approach
involves an optimization-based strategy that actively penalizes the prediction
of a large number of distinct classes within each window. We conducted
experiments on histopathological data to classify tissue classes in digital
slides of liver cancer, specifically hepatocellular carcinoma. The initial
results show the effectiveness of our method and its potential to enhance the
process of automated cancer diagnosis and treatment, all while reducing the
time and effort required for expert annotation.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17749" title="Abstract">arXiv:2311.17749</a> (cross-list from math.OC) [<a href="/pdf/2311.17749" title="Download PDF">pdf</a>, <a href="/format/2311.17749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Free Terminal Time Optimal Closed-loop Control of Manipulators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hu%2C+W">Wei Hu</a>, 
<a href="/search/math?searchtype=author&query=Zhao%2C+Y">Yue Zhao</a>, 
<a href="/search/math?searchtype=author&query=E%2C+W">Weinan E</a>, 
<a href="/search/math?searchtype=author&query=Han%2C+J">Jiequn Han</a>, 
<a href="/search/math?searchtype=author&query=Long%2C+J">Jihao Long</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This paper presents a novel approach to learning free terminal time
closed-loop control for robotic manipulation tasks, enabling dynamic adjustment
of task duration and control inputs to enhance performance. We extend the
supervised learning approach, namely solving selected optimal open-loop
problems and utilizing them as training data for a policy network, to the free
terminal time scenario. Three main challenges are addressed in this extension.
First, we introduce a marching scheme that enhances the solution quality and
increases the success rate of the open-loop solver by gradually refining time
discretization. Second, we extend the QRnet in Nakamura-Zimmerer et al. (2021b)
to the free terminal time setting to address discontinuity and improve
stability at the terminal state. Third, we present a more automated version of
the initial value problem (IVP) enhanced sampling method from previous work
(Zhang et al., 2022) to adaptively update the training dataset, significantly
improving its quality. By integrating these techniques, we develop a
closed-loop policy that operates effectively over a broad domain with varying
optimal time durations, achieving near globally optimal total costs.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17778" title="Abstract">arXiv:2311.17778</a> (cross-list from stat.ML) [<a href="/pdf/2311.17778" title="Download PDF">pdf</a>, <a href="/format/2311.17778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified Binary and Multiclass Margin-Based Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wang%2C+Y">Yutong Wang</a>, 
<a href="/search/stat?searchtype=author&query=Scott%2C+C">Clayton Scott</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The notion of margin loss has been central to the development and analysis of
algorithms for binary classification. To date, however, there remains no
consensus as to the analogue of the margin loss for multiclass classification.
In this work, we show that a broad range of multiclass loss functions,
including many popular ones, can be expressed in the relative margin form, a
generalization of the margin form of binary losses. The relative margin form is
broadly useful for understanding and analyzing multiclass losses as shown by
our prior work (Wang and Scott, 2020, 2021). To further demonstrate the utility
of this way of expressing multiclass losses, we use it to extend the seminal
result of Bartlett et al. (2006) on classification-calibration of binary margin
losses to multiclass. We then analyze the class of Fenchel-Young losses, and
expand the set of these losses that are known to be classification-calibrated.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17791" title="Abstract">arXiv:2311.17791</a> (cross-list from eess.IV) [<a href="/pdf/2311.17791" title="Download PDF">pdf</a>, <a href="/format/2311.17791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> U-Net v2: Rethinking the Skip Connections of U-Net for Medical Image  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Peng%2C+Y">Yaopeng Peng</a>, 
<a href="/search/eess?searchtype=author&query=Sonka%2C+M">Milan Sonka</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+D+Z">Danny Z. Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this paper, we introduce U-Net v2, a new robust and efficient U-Net
variant for medical image segmentation. It aims to augment the infusion of
semantic information into low-level features while simultaneously refining
high-level features with finer details. For an input image, we begin by
extracting multi-level features with a deep neural network encoder. Next, we
enhance the feature map of each level by infusing semantic information from
higher-level features and integrating finer details from lower-level features
through Hadamard product. Our novel skip connections empower features of all
the levels with enriched semantic characteristics and intricate details. The
improved features are subsequently transmitted to the decoder for further
processing and segmentation. Our method can be seamlessly integrated into any
Encoder-Decoder network. We evaluate our method on several public medical image
segmentation datasets for skin lesion segmentation and polyp segmentation, and
the experimental results demonstrate the segmentation accuracy of our new
method over state-of-the-art methods, while preserving memory and computational
efficiency. Code is available at: https://github.com/yaoppeng/U-Net\_v2
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17865" title="Abstract">arXiv:2311.17865</a> (cross-list from math.DS) [<a href="/pdf/2311.17865" title="Download PDF">pdf</a>, <a href="/format/2311.17865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Assisted Non-Intrusive Model Reduction for Forced Nonlinear Finite  Elements Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cenedese%2C+M">Mattia Cenedese</a>, 
<a href="/search/math?searchtype=author&query=Marconi%2C+J">Jacopo Marconi</a>, 
<a href="/search/math?searchtype=author&query=Haller%2C+G">George Haller</a>, 
<a href="/search/math?searchtype=author&query=Jain%2C+S">Shobhit Jain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Spectral submanifolds (SSMs) have emerged as accurate and predictive model
reduction tools for dynamical systems defined either by equations or data sets.
While finite-elements (FE) models belong to the equation-based class of
problems, their implementations in commercial solvers do not generally provide
information on the nonlinearities required for the analytical construction of
SSMs. Here, we overcome this limitation by developing a data-driven
construction of SSM-reduced models from a small number of unforced FE
simulations. We then use these models to predict the forced response of the FE
model without performing any costly forced simulation. This approach yields
accurate forced response predictions even in the presence of internal
resonances or quasi-periodic forcing, as we illustrate on several FE models.
Our examples range from simple structures, such as beams and shells, to more
complex geometries, such as a micro-resonator model containing more than a
million degrees of freedom. In the latter case, our algorithm predicts accurate
forced response curves in a small fraction of the time it takes to verify just
a few points on those curves by simulating the full forced-response.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17885" title="Abstract">arXiv:2311.17885</a> (cross-list from stat.ML) [<a href="/pdf/2311.17885" title="Download PDF">pdf</a>, <a href="/format/2311.17885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are ensembles getting better all the time?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Mattei%2C+P">Pierre-Alexandre Mattei</a>, 
<a href="/search/stat?searchtype=author&query=Garreau%2C+D">Damien Garreau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST); Methodology (stat.ME)

</div>
<p class="mathjax">Ensemble methods combine the predictions of several base models. We study
whether or not including more models in an ensemble always improve its average
performance. Such a question depends on the kind of ensemble considered, as
well as the predictive metric chosen. We focus on situations where all members
of the ensemble are a priori expected to perform as well, which is the case of
several popular methods like random forests or deep ensembles. In this setting,
we essentially show that ensembles are getting better all the time if, and only
if, the considered loss function is convex. More precisely, in that case, the
average loss of the ensemble is a decreasing function of the number of models.
When the loss function is nonconvex, we show a series of results that can be
summarised by the insight that ensembles of good models keep getting better,
and ensembles of bad models keep getting worse. To this end, we prove a new
result on the monotonicity of tail probabilities that may be of independent
interest. We illustrate our results on a simple machine learning problem
(diagnosing melanomas using neural nets).
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17894" title="Abstract">arXiv:2311.17894</a> (cross-list from cond-mat.mes-hall) [<a href="/pdf/2311.17894" title="Download PDF">pdf</a>, <a href="/format/2311.17894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning and Controlling Silicon Dopant Transitions in Graphene using  Scanning Transmission Electron Microscopy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Schwarzer%2C+M">Max Schwarzer</a>, 
<a href="/search/cond-mat?searchtype=author&query=Farebrother%2C+J">Jesse Farebrother</a>, 
<a href="/search/cond-mat?searchtype=author&query=Greaves%2C+J">Joshua Greaves</a>, 
<a href="/search/cond-mat?searchtype=author&query=Cubuk%2C+E+D">Ekin Dogus Cubuk</a>, 
<a href="/search/cond-mat?searchtype=author&query=Agarwal%2C+R">Rishabh Agarwal</a>, 
<a href="/search/cond-mat?searchtype=author&query=Courville%2C+A">Aaron Courville</a>, 
<a href="/search/cond-mat?searchtype=author&query=Bellemare%2C+M+G">Marc G. Bellemare</a>, 
<a href="/search/cond-mat?searchtype=author&query=Kalinin%2C+S">Sergei Kalinin</a>, 
<a href="/search/cond-mat?searchtype=author&query=Mordatch%2C+I">Igor Mordatch</a>, 
<a href="/search/cond-mat?searchtype=author&query=Castro%2C+P+S">Pablo Samuel Castro</a>, 
<a href="/search/cond-mat?searchtype=author&query=Roccapriore%2C+K+M">Kevin M. Roccapriore</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mesoscale and Nanoscale Physics (cond-mat.mes-hall)</span>; Materials Science (cond-mat.mtrl-sci); Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce a machine learning approach to determine the transition dynamics
of silicon atoms on a single layer of carbon atoms, when stimulated by the
electron beam of a scanning transmission electron microscope (STEM). Our method
is data-centric, leveraging data collected on a STEM. The data samples are
processed and filtered to produce symbolic representations, which we use to
train a neural network to predict transition probabilities. These learned
transition dynamics are then leveraged to guide a single silicon atom
throughout the lattice to pre-determined target destinations. We present
empirical analyses that demonstrate the efficacy and generality of our
approach.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Thu, 30 Nov 23</h3>
<dl>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2004.08127" title="Abstract">arXiv:2004.08127</a> (replaced) [<a href="/pdf/2004.08127" title="Download PDF">pdf</a>, <a href="/format/2004.08127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Infinity Laplacian eigenvalue problem: reformulation and a numerical  scheme
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bozorgnia%2C+F">Farid Bozorgnia</a>, 
<a href="/search/math?searchtype=author&query=Bungert%2C+L">Leon Bungert</a>, 
<a href="/search/math?searchtype=author&query=Tenbrinck%2C+D">Daniel Tenbrinck</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> version as accepted for publication at the Journal for Scientific Computing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP); Spectral Theory (math.SP)

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2006.09017" title="Abstract">arXiv:2006.09017</a> (replaced) [<a href="/pdf/2006.09017" title="Download PDF">pdf</a>, <a href="/ps/2006.09017" title="Download PostScript">ps</a>, <a href="/format/2006.09017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimates on Learning Rates for Multi-Penalty Distribution Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+D+W+C">Daniel W. C. Ho</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.01502" title="Abstract">arXiv:2010.01502</a> (replaced) [<a href="/pdf/2010.01502" title="Download PDF">pdf</a>, <a href="/format/2010.01502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-turn Response Selection using Dialogue Dependency Relations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+Q">Qi Jia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yizhu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Siyu Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K+Q">Kenny Q. Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Haifeng Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication as a long paper in EMNLP2020
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 2020 Conference on Empirical Methods in Natural
  Language Processing (EMNLP)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.13563" title="Abstract">arXiv:2010.13563</a> (replaced) [<a href="/pdf/2010.13563" title="Download PDF">pdf</a>, <a href="/format/2010.13563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Framework for Double Sweep Methods for the Helmholtz Equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bouziani%2C+N">Nacime Bouziani</a>, 
<a href="/search/math?searchtype=author&query=Nataf%2C+F">Fr&#xe9;d&#xe9;ric Nataf</a> (ALPINES), 
<a href="/search/math?searchtype=author&query=Tournier%2C+P">Pierre-Henri Tournier</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Computational Physics, 2023, 490, pp.112305
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.07737" title="Abstract">arXiv:2102.07737</a> (replaced) [<a href="/pdf/2102.07737" title="Download PDF">pdf</a>, <a href="/format/2102.07737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Self-Supervised Learning for MRI Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yaman%2C+B">Burhaneddin Yaman</a>, 
<a href="/search/eess?searchtype=author&query=Hosseini%2C+S+A+H">Seyed Amir Hossein Hosseini</a>, 
<a href="/search/eess?searchtype=author&query=Ak%C3%A7akaya%2C+M">Mehmet Ak&#xe7;akaya</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Conference on Learning Representations (ICLR), 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Signal Processing (eess.SP); Medical Physics (physics.med-ph)

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.01093" title="Abstract">arXiv:2110.01093</a> (replaced) [<a href="/e-print/2110.01093" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TSP on manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zisselman%2C+D">David Zisselman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was uploaded prematurely and contains several errors, mainly the proof of theorem 5.15 on p.44. As such I wish to withdraw it
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.04442" title="Abstract">arXiv:2110.04442</a> (replaced) [<a href="/pdf/2110.04442" title="Download PDF">pdf</a>, <a href="/format/2110.04442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Primer on Deep Learning for Causal Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koch%2C+B">Bernard Koch</a>, 
<a href="/search/cs?searchtype=author&query=Sainburg%2C+T">Tim Sainburg</a>, 
<a href="/search/cs?searchtype=author&query=Geraldo%2C+P">Pablo Geraldo</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Song Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yizhou Sun</a>, 
<a href="/search/cs?searchtype=author&query=Foster%2C+J+G">Jacob Gates Foster</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Forthcoming in Sociological Methods and Research
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Econometrics (econ.EM); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.12403" title="Abstract">arXiv:2110.12403</a> (replaced) [<a href="/pdf/2110.12403" title="Download PDF">pdf</a>, <a href="/format/2110.12403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Estimate Without Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diskin%2C+T">Tzvi Diskin</a>, 
<a href="/search/cs?searchtype=author&query=Eldar%2C+Y+C">Yonina C. Eldar</a>, 
<a href="/search/cs?searchtype=author&query=Wiesel%2C+A">Ami Wiesel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.04678" title="Abstract">arXiv:2111.04678</a> (replaced) [<a href="/pdf/2111.04678" title="Download PDF">pdf</a>, <a href="/ps/2111.04678" title="Download PostScript">ps</a>, <a href="/format/2111.04678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Optimization of Uplink Power and Computational Resources in Mobile  Edge Computing-Enabled Cell-Free Massive MIMO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Interdonato%2C+G">Giovanni Interdonato</a>, 
<a href="/search/cs?searchtype=author&query=Buzzi%2C+S">Stefano Buzzi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been published in IEEE Transactions on Communications on November 23, 2023. {\copyright} 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.12971" title="Abstract">arXiv:2111.12971</a> (replaced) [<a href="/pdf/2111.12971" title="Download PDF">pdf</a>, <a href="/format/2111.12971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Natural &amp; Adversarial Bokeh Rendering via Circle-of-Confusion Predictive  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yihao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Juefei-Xu%2C+F">Felix Juefei-Xu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+G">Geguang Pu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, accepted by TMM
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.03865" title="Abstract">arXiv:2112.03865</a> (replaced) [<a href="/pdf/2112.03865" title="Download PDF">pdf</a>, <a href="/format/2112.03865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universalizing Weak Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shin%2C+C">Changho Shin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Winfred Li</a>, 
<a href="/search/cs?searchtype=author&query=Vishwakarma%2C+H">Harit Vishwakarma</a>, 
<a href="/search/cs?searchtype=author&query=Roberts%2C+N">Nicholas Roberts</a>, 
<a href="/search/cs?searchtype=author&query=Sala%2C+F">Frederic Sala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.05020" title="Abstract">arXiv:2112.05020</a> (replaced) [<a href="/pdf/2112.05020" title="Download PDF">pdf</a>, <a href="/format/2112.05020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Double Saddle-Point Preconditioning for Krylov Methods in the Inexact  Sequential Homotopy Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pearson%2C+J+W">John W. Pearson</a>, 
<a href="/search/math?searchtype=author&query=Potschka%2C+A">Andreas Potschka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.01660" title="Abstract">arXiv:2202.01660</a> (replaced) [<a href="/pdf/2202.01660" title="Download PDF">pdf</a>, <a href="/format/2202.01660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Complexity of Winner Determination and Strategic Control in  Conditional Approval Voting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Markakis%2C+E">Evangelos Markakis</a>, 
<a href="/search/cs?searchtype=author&query=Papasotiropoulos%2C+G">Georgios Papasotiropoulos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.00948" title="Abstract">arXiv:2203.00948</a> (replaced) [<a href="/pdf/2203.00948" title="Download PDF">pdf</a>, <a href="/format/2203.00948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CD-GAN: a robust fusion-based generative adversarial network for  unsupervised remote sensing change detection with heterogeneous sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jin-Ju Wang</a>, 
<a href="/search/eess?searchtype=author&query=Dobigeon%2C+N">Nicolas Dobigeon</a>, 
<a href="/search/eess?searchtype=author&query=Chabert%2C+M">Marie Chabert</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+D">Ding-Cheng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+T">Ting-Zhu Huang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+J">Jie Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.02142" title="Abstract">arXiv:2205.02142</a> (replaced) [<a href="/pdf/2205.02142" title="Download PDF">pdf</a>, <a href="/format/2205.02142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semimodules and the (syntactically-)linear lambda calculus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz-Caro%2C+A">Alejandro D&#xed;az-Caro</a>, 
<a href="/search/cs?searchtype=author&query=Malherbe%2C+O">Octavio Malherbe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Category Theory (math.CT); Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.11952" title="Abstract">arXiv:2205.11952</a> (replaced) [<a href="/pdf/2205.11952" title="Download PDF">pdf</a>, <a href="/format/2205.11952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D helical CT Reconstruction with a Memory Efficient Learned Primal-Dual  Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rudzusika%2C+J">Jevgenija Rudzusika</a>, 
<a href="/search/eess?searchtype=author&query=Baji%C4%87%2C+B">Buda Baji&#x107;</a>, 
<a href="/search/eess?searchtype=author&query=Koehler%2C+T">Thomas Koehler</a>, 
<a href="/search/eess?searchtype=author&query=%C3%96ktem%2C+O">Ozan &#xd6;ktem</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.10586" title="Abstract">arXiv:2206.10586</a> (replaced) [<a href="/pdf/2206.10586" title="Download PDF">pdf</a>, <a href="/format/2206.10586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> D-CIPHER: Discovery of Closed-form Partial Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kacprzyk%2C+K">Krzysztof Kacprzyk</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Z">Zhaozhi Qian</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Schaar%2C+M">Mihaela van der Schaar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the Proceedings of the 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.12201" title="Abstract">arXiv:2206.12201</a> (replaced) [<a href="/pdf/2206.12201" title="Download PDF">pdf</a>, <a href="/format/2206.12201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimental graybox quantum system identification and control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Youssry%2C+A">Akram Youssry</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chapman%2C+R+J">Robert J. Chapman</a>, 
<a href="/search/quant-ph?searchtype=author&query=Haylock%2C+B">Ben Haylock</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lenzini%2C+F">Francesco Lenzini</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lobino%2C+M">Mirko Lobino</a>, 
<a href="/search/quant-ph?searchtype=author&query=Peruzzo%2C+A">Alberto Peruzzo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Systems and Control (eess.SY); Optics (physics.optics)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.04502" title="Abstract">arXiv:2207.04502</a> (replaced) [<a href="/pdf/2207.04502" title="Download PDF">pdf</a>, <a href="/format/2207.04502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building Open Knowledge Graph for Metal-Organic Frameworks (MOF-KG):  Challenges and Case Studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+Y">Yuan An</a>, 
<a href="/search/cs?searchtype=author&query=Greenberg%2C+J">Jane Greenberg</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xintong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaohua Hu</a>, 
<a href="/search/cs?searchtype=author&query=McCLellan%2C+S">Scott McCLellan</a>, 
<a href="/search/cs?searchtype=author&query=Kalinowski%2C+A">Alex Kalinowski</a>, 
<a href="/search/cs?searchtype=author&query=Uribe-Romo%2C+F+J">Fernando J. Uribe-Romo</a>, 
<a href="/search/cs?searchtype=author&query=Langlois%2C+K">Kyle Langlois</a>, 
<a href="/search/cs?searchtype=author&query=Furst%2C+J">Jacob Furst</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez-Gualdr%C3%B3n%2C+D+A">Diego A. G&#xf3;mez-Gualdr&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Fajardo-Rojas%2C+F">Fernando Fajardo-Rojas</a>, 
<a href="/search/cs?searchtype=author&query=Ardila%2C+K">Katherine Ardila</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the International Workshop on Knowledge Graphs and Open Knowledge Network (OKN'22) Co-located with the 28th ACM SIGKDD Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.04869" title="Abstract">arXiv:2207.04869</a> (replaced) [<a href="/pdf/2207.04869" title="Download PDF">pdf</a>, <a href="/format/2207.04869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph-based Molecular Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Guo%2C+Z">Zhichun Guo</a>, 
<a href="/search/q-bio?searchtype=author&query=Guo%2C+K">Kehan Guo</a>, 
<a href="/search/q-bio?searchtype=author&query=Nan%2C+B">Bozhao Nan</a>, 
<a href="/search/q-bio?searchtype=author&query=Tian%2C+Y">Yijun Tian</a>, 
<a href="/search/q-bio?searchtype=author&query=Iyer%2C+R+G">Roshni G. Iyer</a>, 
<a href="/search/q-bio?searchtype=author&query=Ma%2C+Y">Yihong Ma</a>, 
<a href="/search/q-bio?searchtype=author&query=Wiest%2C+O">Olaf Wiest</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+X">Xiangliang Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+C">Chuxu Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Chawla%2C+N+V">Nitesh V. Chawla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.02132" title="Abstract">arXiv:2208.02132</a> (replaced) [<a href="/pdf/2208.02132" title="Download PDF">pdf</a>, <a href="/format/2208.02132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simple and Tighter Derivation of Achievability for Classical  Communication over Quantum Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Cheng%2C+H">Hao-Chung Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v2: Introduction revised
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> PRX Quantum 4, 040330, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT); Mathematical Physics (math-ph)

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.07626" title="Abstract">arXiv:2208.07626</a> (replaced) [<a href="/pdf/2208.07626" title="Download PDF">pdf</a>, <a href="/format/2208.07626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithmic Assistance with Recommendation-Dependent Preferences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McLaughlin%2C+B">Bryce McLaughlin</a>, 
<a href="/search/cs?searchtype=author&query=Spiess%2C+J">Jann Spiess</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC); General Economics (econ.GN)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.04671" title="Abstract">arXiv:2210.04671</a> (replaced) [<a href="/pdf/2210.04671" title="Download PDF">pdf</a>, <a href="/format/2210.04671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TCDM: Transformational Complexity Based Distortion Metric for Perceptual  Point Cloud Quality Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yujie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yifei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaozhong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Le Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yiling Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.06591" title="Abstract">arXiv:2210.06591</a> (replaced) [<a href="/pdf/2210.06591" title="Download PDF">pdf</a>, <a href="/format/2210.06591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rigorous dynamical mean field theory for stochastic gradient descent  methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math-ph?searchtype=author&query=Gerbelot%2C+C">Cedric Gerbelot</a>, 
<a href="/search/math-ph?searchtype=author&query=Troiani%2C+E">Emanuele Troiani</a>, 
<a href="/search/math-ph?searchtype=author&query=Mignacco%2C+F">Francesca Mignacco</a>, 
<a href="/search/math-ph?searchtype=author&query=Krzakala%2C+F">Florent Krzakala</a>, 
<a href="/search/math-ph?searchtype=author&query=Zdeborova%2C+L">Lenka Zdeborova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Physics (math-ph)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.15787" title="Abstract">arXiv:2210.15787</a> (replaced) [<a href="/pdf/2210.15787" title="Download PDF">pdf</a>, <a href="/format/2210.15787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convolutional Codes with Optimum Bidirectional Distance Profile
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stanojevi%C4%87%2C+I">Ivan Stanojevi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0enk%2C+V">Vojin &#x160;enk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03803" title="Abstract">arXiv:2211.03803</a> (replaced) [<a href="/pdf/2211.03803" title="Download PDF">pdf</a>, <a href="/format/2211.03803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum-probabilistic Hamiltonian learning for generative modelling &amp;  anomaly detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Araz%2C+J+Y">Jack Y. Araz</a>, 
<a href="/search/quant-ph?searchtype=author&query=Spannowsky%2C+M">Michael Spannowsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures. Accepted version for publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex); High Energy Physics - Phenomenology (hep-ph); Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.05368" title="Abstract">arXiv:2211.05368</a> (replaced) [<a href="/pdf/2211.05368" title="Download PDF">pdf</a>, <a href="/format/2211.05368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Survey on Distributed Training of Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Haiyang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+M">Mingyu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xiaochun Ye</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+D">Dongrui Fan</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shirui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenguang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yuan Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To Appear in Proceedings of the IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.10649" title="Abstract">arXiv:2211.10649</a> (replaced) [<a href="/pdf/2211.10649" title="Download PDF">pdf</a>, <a href="/format/2211.10649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LibSignal: An Open Library for Traffic Signal Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mei%2C+H">Hao Mei</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+X">Xiaoliang Lei</a>, 
<a href="/search/cs?searchtype=author&query=Da%2C+L">Longchao Da</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Bin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Hua Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages + 6 pages appendix. Accepted by Machine Learning Journal (2023). A short version is accepted by NeurIPS 2022 Workshop: Reinforcement Learning for Real Life. Website: <a href="https://darl-libsignal.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.12337" title="Abstract">arXiv:2211.12337</a> (replaced) [<a href="/pdf/2211.12337" title="Download PDF">pdf</a>, <a href="/format/2211.12337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quality-diversity in dissimilarity spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huntsman%2C+S">Steve Huntsman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added Section 7 (for journal submission to supersede GECCO 2023 at DOI 10.1145/3583131.3590409) which discusses "extremal" diversity at scale zero; some other inconsequential changes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Neural and Evolutionary Computing (cs.NE); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.15646" title="Abstract">arXiv:2211.15646</a> (replaced) [<a href="/pdf/2211.15646" title="Download PDF">pdf</a>, <a href="/format/2211.15646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Invariance: Test-Time Label-Shift Adaptation for Distributions  with &quot;Spurious&quot; Correlations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sun%2C+Q">Qingyao Sun</a> (Cornell University), 
<a href="/search/stat?searchtype=author&query=Murphy%2C+K">Kevin Murphy</a> (Google DeepMind), 
<a href="/search/stat?searchtype=author&query=Ebrahimi%2C+S">Sayna Ebrahimi</a> (Google Cloud AI Research), 
<a href="/search/stat?searchtype=author&query=D%27Amour%2C+A">Alexander D&#x27;Amour</a> (Google DeepMind)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.06872" title="Abstract">arXiv:2212.06872</a> (replaced) [<a href="/pdf/2212.06872" title="Download PDF">pdf</a>, <a href="/format/2212.06872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing the Decision-Making Mechanisms by Transformers and CNNs via  Explanation Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Mingqi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Khorram%2C+S">Saeed Khorram</a>, 
<a href="/search/cs?searchtype=author&query=Fuxin%2C+L">Li Fuxin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages with 36 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07566" title="Abstract">arXiv:2212.07566</a> (replaced) [<a href="/pdf/2212.07566" title="Download PDF">pdf</a>, <a href="/format/2212.07566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying and Explaining Safety-critical Scenarios for Autonomous  Vehicles via Key Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neelofar">Neelofar</a>, 
<a href="/search/cs?searchtype=author&query=Aleti%2C+A">Aldeida Aleti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.10240" title="Abstract">arXiv:2212.10240</a> (replaced) [<a href="/pdf/2212.10240" title="Download PDF">pdf</a>, <a href="/format/2212.10240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Glancing Transformer for Parallel Sequence to Sequence  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+L">Lihua Qian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mingxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hao Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00545" title="Abstract">arXiv:2301.00545</a> (replaced) [<a href="/pdf/2301.00545" title="Download PDF">pdf</a>, <a href="/format/2301.00545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knockoffs-SPR: Clean Sample Selection in Learning with Noisy Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yikai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yanwei Fu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xinwei Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> update: final version, to appear in TPAMI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09818" title="Abstract">arXiv:2301.09818</a> (replaced) [<a href="/pdf/2301.09818" title="Download PDF">pdf</a>, <a href="/ps/2301.09818" title="Download PostScript">ps</a>, <a href="/format/2301.09818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the convergence of Sobolev gradient flow for the Gross-Pitaevskii  eigenvalue problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+Z">Ziang Chen</a>, 
<a href="/search/math?searchtype=author&query=Lu%2C+J">Jianfeng Lu</a>, 
<a href="/search/math?searchtype=author&query=Lu%2C+Y">Yulong Lu</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+X">Xiangxiong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11695" title="Abstract">arXiv:2301.11695</a> (replaced) [<a href="/pdf/2301.11695" title="Download PDF">pdf</a>, <a href="/format/2301.11695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LegendreTron: Uprising Proper Multiclass Loss Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Lam%2C+K">Kevin Lam</a>, 
<a href="/search/stat?searchtype=author&query=Walder%2C+C">Christian Walder</a>, 
<a href="/search/stat?searchtype=author&query=Penev%2C+S">Spiridon Penev</a>, 
<a href="/search/stat?searchtype=author&query=Nock%2C+R">Richard Nock</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 40th International Conference on Machine Learning (ICML 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01714" title="Abstract">arXiv:2302.01714</a> (replaced) [<a href="/pdf/2302.01714" title="Download PDF">pdf</a>, <a href="/format/2302.01714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning End-to-End Channel Coding with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Muah Kim</a>, 
<a href="/search/cs?searchtype=author&query=Fritschek%2C+R">Rick Fritschek</a>, 
<a href="/search/cs?searchtype=author&query=Schaefer%2C+R+F">Rafael F. Schaefer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, WSA/SCC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02124" title="Abstract">arXiv:2302.02124</a> (replaced) [<a href="/pdf/2302.02124" title="Download PDF">pdf</a>, <a href="/ps/2302.02124" title="Download PostScript">ps</a>, <a href="/format/2302.02124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transform, Contrast and Tell: Coherent Entity-Aware Multi-Image  Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingqiang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 11 tables, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09251" title="Abstract">arXiv:2302.09251</a> (replaced) [<a href="/pdf/2302.09251" title="Download PDF">pdf</a>, <a href="/format/2302.09251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StyLIP: Multi-Scale Style-Conditioned Prompt Learning for CLIP-based  Domain Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bose%2C+S">Shirsha Bose</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+A">Ankit Jha</a>, 
<a href="/search/cs?searchtype=author&query=Fini%2C+E">Enrico Fini</a>, 
<a href="/search/cs?searchtype=author&query=Singha%2C+M">Mainak Singha</a>, 
<a href="/search/cs?searchtype=author&query=Ricci%2C+E">Elisa Ricci</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+B">Biplab Banerjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages,5 figures, 7 tables, Accepted in WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11455" title="Abstract">arXiv:2302.11455</a> (replaced) [<a href="/pdf/2302.11455" title="Download PDF">pdf</a>, <a href="/format/2302.11455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical approximation of SDEs with fractional noise and distributional  drift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gouden%C3%A8ge%2C+L">Ludovic Gouden&#xe8;ge</a>, 
<a href="/search/math?searchtype=author&query=Haress%2C+E+M">El Mehdi Haress</a>, 
<a href="/search/math?searchtype=author&query=Richard%2C+A">Alexandre Richard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14545" title="Abstract">arXiv:2302.14545</a> (replaced) [<a href="/pdf/2302.14545" title="Download PDF">pdf</a>, <a href="/ps/2302.14545" title="Download PostScript">ps</a>, <a href="/format/2302.14545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modern Bayesian Experimental Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Rainforth%2C+T">Tom Rainforth</a>, 
<a href="/search/stat?searchtype=author&query=Foster%2C+A">Adam Foster</a>, 
<a href="/search/stat?searchtype=author&query=Ivanova%2C+D+R">Desi R Ivanova</a>, 
<a href="/search/stat?searchtype=author&query=Smith%2C+F+B">Freddie Bickford Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Statistical Science
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06753" title="Abstract">arXiv:2303.06753</a> (replaced) [<a href="/pdf/2303.06753" title="Download PDF">pdf</a>, <a href="/format/2303.06753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modular Quantization-Aware Training: Increasing Accuracy by Decreasing  Precision in 6D Object Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Javed%2C+S">Saqib Javed</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengkun Li</a>, 
<a href="/search/cs?searchtype=author&query=Price%2C+A">Andrew Price</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yinlin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Salzmann%2C+M">Mathieu Salzmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06842" title="Abstract">arXiv:2303.06842</a> (replaced) [<a href="/pdf/2303.06842" title="Download PDF">pdf</a>, <a href="/format/2303.06842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Relationships: A New Perspective to Enhance Scene Graph  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bowen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+C+J">Camillo J. Taylor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 New Frontiers in Graph Learning Workshop (NeurIPS GLFrontiers 2023); NeurIPS 2023 Queer in AI Workshop. This paper is a preliminary work of the full paper available at <a href="/abs/2311.12889">arXiv:2311.12889</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07321" title="Abstract">arXiv:2303.07321</a> (replaced) [<a href="/pdf/2303.07321" title="Download PDF">pdf</a>, <a href="/format/2303.07321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collision Cross-entropy for Soft Class Labels and Deep Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhongwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Boykov%2C+Y">Yuri Boykov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07509" title="Abstract">arXiv:2303.07509</a> (replaced) [<a href="/pdf/2303.07509" title="Download PDF">pdf</a>, <a href="/ps/2303.07509" title="Download PostScript">ps</a>, <a href="/format/2303.07509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Improved Approach for Output Feedback Model Predictive Control of  Hybrid Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sadeghnejad%2C+S">Soroush Sadeghnejad</a>, 
<a href="/search/eess?searchtype=author&query=Khadivar%2C+F">Farshad Khadivar</a>, 
<a href="/search/eess?searchtype=author&query=Esfandiari%2C+M">Mojtaba Esfandiari</a>, 
<a href="/search/eess?searchtype=author&query=Amirkhani%2C+G">Golchehr Amirkhani</a>, 
<a href="/search/eess?searchtype=author&query=Moradi%2C+H">Hamed Moradi</a>, 
<a href="/search/eess?searchtype=author&query=Farahmand%2C+F">Farzam Farahmand</a>, 
<a href="/search/eess?searchtype=author&query=Vossoughi%2C+G">Gholamreza Vossoughi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08646" title="Abstract">arXiv:2303.08646</a> (replaced) [<a href="/pdf/2303.08646" title="Download PDF">pdf</a>, <a href="/format/2303.08646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-level Feature Guided Decoding for Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Ye Huang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+D">Di Kang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shenghua Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wen Li</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+L">Lixin Duan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revised version, refactored presentation and added more experiments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10426" title="Abstract">arXiv:2303.10426</a> (replaced) [<a href="/pdf/2303.10426" title="Download PDF">pdf</a>, <a href="/format/2303.10426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering Predictable Latent Factors for Time Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Jingyi Hou</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiayu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhijie Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11530" title="Abstract">arXiv:2303.11530</a> (replaced) [<a href="/pdf/2303.11530" title="Download PDF">pdf</a>, <a href="/format/2303.11530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Coarse-to-Fine Segmentation of Moveable Parts from Real Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Patil%2C+A+G">Akshay Gadi Patil</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Fenggen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15799" title="Abstract">arXiv:2303.15799</a> (replaced) [<a href="/pdf/2303.15799" title="Download PDF">pdf</a>, <a href="/format/2303.15799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedAgg: Adaptive Federated Learning with Aggregated Gradients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Wenhao Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuehe Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17713" title="Abstract">arXiv:2303.17713</a> (replaced) [<a href="/pdf/2303.17713" title="Download PDF">pdf</a>, <a href="/format/2303.17713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Source Bias for Fairer Weak Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shin%2C+C">Changho Shin</a>, 
<a href="/search/cs?searchtype=author&query=Cromp%2C+S">Sonia Cromp</a>, 
<a href="/search/cs?searchtype=author&query=Adila%2C+D">Dyah Adila</a>, 
<a href="/search/cs?searchtype=author&query=Sala%2C+F">Frederic Sala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00450" title="Abstract">arXiv:2304.00450</a> (replaced) [<a href="/pdf/2304.00450" title="Download PDF">pdf</a>, <a href="/format/2304.00450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sketch-based Video Object Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Woo%2C+S">Sangmin Woo</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+S">So-Yeong Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jinyoung Park</a>, 
<a href="/search/cs?searchtype=author&query=Son%2C+M">Minji Son</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sumin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Changick Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024; Code: <a href="https://github.com/sangminwoo/SVOL">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01552" title="Abstract">arXiv:2304.01552</a> (replaced) [<a href="/pdf/2304.01552" title="Download PDF">pdf</a>, <a href="/format/2304.01552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-Learning with a Geometry-Adaptive Preconditioner
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">Suhyun Kang</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+D">Duhun Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Eo%2C+M">Moonjung Eo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taesup Kim</a>, 
<a href="/search/cs?searchtype=author&query=Rhee%2C+W">Wonjong Rhee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CVPR 2023. Code is available at: <a href="https://github.com/Suhyun777/CVPR23-GAP">this https URL</a>; This is an extended version of our previous CVPR23 work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01628" title="Abstract">arXiv:2304.01628</a> (replaced) [<a href="/pdf/2304.01628" title="Download PDF">pdf</a>, <a href="/format/2304.01628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equivariant Parameter Sharing for Porous Crystalline Materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Petkovi%C4%87%2C+M">Marko Petkovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Romero-Marimon%2C+P">Pablo Romero-Marimon</a>, 
<a href="/search/cs?searchtype=author&query=Menkovski%2C+V">Vlado Menkovski</a>, 
<a href="/search/cs?searchtype=author&query=Calero%2C+S">Sofia Calero</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Additional results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Materials Science (cond-mat.mtrl-sci)

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01928" title="Abstract">arXiv:2304.01928</a> (replaced) [<a href="/pdf/2304.01928" title="Download PDF">pdf</a>, <a href="/format/2304.01928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Attitude Estimation for Multi-agent Systems on $SO(3)$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Boughellaba%2C+M">Mouaad Boughellaba</a>, 
<a href="/search/eess?searchtype=author&query=Tayebi%2C+A">Abdelhamid Tayebi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03373" title="Abstract">arXiv:2304.03373</a> (replaced) [<a href="/pdf/2304.03373" title="Download PDF">pdf</a>, <a href="/format/2304.03373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training-Free Layout Control with Cross-Attention Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Minghao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Laina%2C+I">Iro Laina</a>, 
<a href="/search/cs?searchtype=author&query=Vedaldi%2C+A">Andrea Vedaldi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024, Project Page: <a href="https://silent-chen.github.io/layout-guidance/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04940" title="Abstract">arXiv:2304.04940</a> (replaced) [<a href="/pdf/2304.04940" title="Download PDF">pdf</a>, <a href="/format/2304.04940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Family of Iteration Functions for General Linear Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kalantari%2C+B">Bahman Kalantari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 6 figures, 4 tables, 6 algorithms. The new version improves the theoretical complexity of a proposed algorithm and also provides some computational results and comparisons with well-known linear solvers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05259" title="Abstract">arXiv:2304.05259</a> (replaced) [<a href="/pdf/2304.05259" title="Download PDF">pdf</a>, <a href="/format/2304.05259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Holographic MIMO Communications with Arbitrary Surface Placements:  Near-Field LoS Channel Model and Capacity Limit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gong%2C+T">Tierui Gong</a>, 
<a href="/search/eess?searchtype=author&query=Wei%2C+L">Li Wei</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+C">Chongwen Huang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Z">Zhijia Yang</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+J">Jiguang He</a>, 
<a href="/search/eess?searchtype=author&query=Debbah%2C+M">M&#xe9;rouane Debbah</a>, 
<a href="/search/eess?searchtype=author&query=Yuen%2C+C">Chau Yuen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> double column, 17 pages, 13 figures, accepted by IEEE Journal on Selected Areas in Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06255" title="Abstract">arXiv:2304.06255</a> (replaced) [<a href="/pdf/2304.06255" title="Download PDF">pdf</a>, <a href="/format/2304.06255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPColor: Semantic Prior Guided Exemplar-based Image Colorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xueming Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xianlin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mingdao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11282" title="Abstract">arXiv:2304.11282</a> (replaced) [<a href="/pdf/2304.11282" title="Download PDF">pdf</a>, <a href="/format/2304.11282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On-Device Intelligence for 5G RAN: Knowledge Transfer and Federated  Learning enabled UE-Centric Traffic Steering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Han Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Elsayed%2C+M">Medhat Elsayed</a>, 
<a href="/search/cs?searchtype=author&query=Bavand%2C+M">Majid Bavand</a>, 
<a href="/search/cs?searchtype=author&query=Gaigalas%2C+R">Raimundas Gaigalas</a>, 
<a href="/search/cs?searchtype=author&query=Ozcan%2C+Y">Yigit Ozcan</a>, 
<a href="/search/cs?searchtype=author&query=Erol-Kantarci%2C+M">Melike Erol-Kantarci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by IEEE Transactions on Cognitive Communications and Networking
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00192" title="Abstract">arXiv:2305.00192</a> (replaced) [<a href="/pdf/2305.00192" title="Download PDF">pdf</a>, <a href="/format/2305.00192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MIMO Grid Impedance Identification of Three-Phase Power Systems:  Parametric vs. Nonparametric Approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=H%C3%A4berle%2C+V">Verena H&#xe4;berle</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+L">Linbin Huang</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+X">Xiuqiang He</a>, 
<a href="/search/eess?searchtype=author&query=Prieto-Araujo%2C+E">Eduardo Prieto-Araujo</a>, 
<a href="/search/eess?searchtype=author&query=Smith%2C+R+S">Roy S. Smith</a>, 
<a href="/search/eess?searchtype=author&query=D%C3%B6rfler%2C+F">Florian D&#xf6;rfler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04096" title="Abstract">arXiv:2305.04096</a> (replaced) [<a href="/pdf/2305.04096" title="Download PDF">pdf</a>, <a href="/format/2305.04096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Game of Pawns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Avni%2C+G">Guy Avni</a>, 
<a href="/search/cs?searchtype=author&query=Ghorpade%2C+P">Pranav Ghorpade</a>, 
<a href="/search/cs?searchtype=author&query=Guha%2C+S">Shibashis Guha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of CONCUR 2023 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04118" title="Abstract">arXiv:2305.04118</a> (replaced) [<a href="/pdf/2305.04118" title="Download PDF">pdf</a>, <a href="/format/2305.04118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Human-Like Translation Strategy with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhiwei He</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+T">Tian Liang</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+W">Wenxiang Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhuosheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujiu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhaopeng Tu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xing Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in TACL (pre-MIT Press publication version)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05062" title="Abstract">arXiv:2305.05062</a> (replaced) [<a href="/pdf/2305.05062" title="Download PDF">pdf</a>, <a href="/format/2305.05062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Feasibility Study on Indoor Localization and Multi-person Tracking  Using Sparsely Distributed Camera Network with Edge Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwon%2C+H">Hyeokhyen Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Hegde%2C+C">Chaitra Hegde</a>, 
<a href="/search/cs?searchtype=author&query=Kiarashi%2C+Y">Yashar Kiarashi</a>, 
<a href="/search/cs?searchtype=author&query=Madala%2C+V+S+K">Venkata Siva Krishna Madala</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+R">Ratan Singh</a>, 
<a href="/search/cs?searchtype=author&query=Nakum%2C+A">ArjunSinh Nakum</a>, 
<a href="/search/cs?searchtype=author&query=Tweedy%2C+R">Robert Tweedy</a>, 
<a href="/search/cs?searchtype=author&query=Tonetto%2C+L+M">Leandro Miletto Tonetto</a>, 
<a href="/search/cs?searchtype=author&query=Zimring%2C+C+M">Craig M. Zimring</a>, 
<a href="/search/cs?searchtype=author&query=Doiron%2C+M">Matthew Doiron</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+A+D">Amy D. Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Levey%2C+A+I">Allan I. Levey</a>, 
<a href="/search/cs?searchtype=author&query=Clifford%2C+G+D">Gari D. Clifford</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05189" title="Abstract">arXiv:2305.05189</a> (replaced) [<a href="/pdf/2305.05189" title="Download PDF">pdf</a>, <a href="/format/2305.05189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SUR-adapter: Enhancing Text-to-Image Pre-trained Diffusion Models with  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+S">Shanshan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhongzhan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+W">Wushao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jinghui Qin</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Liang Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by ACM MM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05656" title="Abstract">arXiv:2305.05656</a> (replaced) [<a href="/pdf/2305.05656" title="Download PDF">pdf</a>, <a href="/format/2305.05656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cover Your Bases: How to Minimize the Sequencing Coverage in DNA Storage  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bar-Lev%2C+D">Daniella Bar-Lev</a>, 
<a href="/search/cs?searchtype=author&query=Sabary%2C+O">Omer Sabary</a>, 
<a href="/search/cs?searchtype=author&query=Gabrys%2C+R">Ryan Gabrys</a>, 
<a href="/search/cs?searchtype=author&query=Yaakobi%2C+E">Eitan Yaakobi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Information Theory (cs.IT); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07598" title="Abstract">arXiv:2305.07598</a> (replaced) [<a href="/pdf/2305.07598" title="Download PDF">pdf</a>, <a href="/format/2305.07598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hausdorff Distance Matching with Adaptive Query Denoising for Rotated  Detection Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hakjin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Minki Song</a>, 
<a href="/search/cs?searchtype=author&query=Koo%2C+J">Jamyoung Koo</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+J">Junghoon Seo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review, 16 pages, 12 tables, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09556" title="Abstract">arXiv:2305.09556</a> (replaced) [<a href="/pdf/2305.09556" title="Download PDF">pdf</a>, <a href="/ps/2305.09556" title="Download PostScript">ps</a>, <a href="/format/2305.09556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapting Sentence Transformers for the Aviation Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liya Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chou%2C+J">Jason Chou</a>, 
<a href="/search/cs?searchtype=author&query=Rouck%2C+D">Dave Rouck</a>, 
<a href="/search/cs?searchtype=author&query=Tien%2C+A">Alex Tien</a>, 
<a href="/search/cs?searchtype=author&query=Baumgartner%2C+D+M">Diane M Baumgartner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10004" title="Abstract">arXiv:2305.10004</a> (replaced) [<a href="/pdf/2305.10004" title="Download PDF">pdf</a>, <a href="/format/2305.10004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rate-Limited Quantum-to-Classical Optimal Transport in Finite and  Continuous-Variable Quantum Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Garmaroudi%2C+H+M">Hafez M. Garmaroudi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pradhan%2C+S+S">S. Sandeep Pradhan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+J">Jun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 51 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10361" title="Abstract">arXiv:2305.10361</a> (replaced) [<a href="/pdf/2305.10361" title="Download PDF">pdf</a>, <a href="/format/2305.10361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Choice Prediction in Language-based Non-Cooperative Games:  Simulation-based Off-Policy Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shapira%2C+E">Eilam Shapira</a>, 
<a href="/search/cs?searchtype=author&query=Apel%2C+R">Reut Apel</a>, 
<a href="/search/cs?searchtype=author&query=Tennenholtz%2C+M">Moshe Tennenholtz</a>, 
<a href="/search/cs?searchtype=author&query=Reichart%2C+R">Roi Reichart</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10579" title="Abstract">arXiv:2305.10579</a> (replaced) [<a href="/pdf/2305.10579" title="Download PDF">pdf</a>, <a href="/format/2305.10579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultiPlaneNeRF: Neural Radiance Field with Non-Trainable Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zimny%2C+D">Dominik Zimny</a>, 
<a href="/search/cs?searchtype=author&query=Kasymov%2C+A">Artur Kasymov</a>, 
<a href="/search/cs?searchtype=author&query=Kania%2C+A">Adam Kania</a>, 
<a href="/search/cs?searchtype=author&query=Tabor%2C+J">Jacek Tabor</a>, 
<a href="/search/cs?searchtype=author&query=Zi%C4%99ba%2C+M">Maciej Zi&#x119;ba</a>, 
<a href="/search/cs?searchtype=author&query=Spurek%2C+P">Przemys&#x142;aw Spurek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10665" title="Abstract">arXiv:2305.10665</a> (replaced) [<a href="/pdf/2305.10665" title="Download PDF">pdf</a>, <a href="/format/2305.10665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Content-based Unrestricted Adversarial Attack
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhaoyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shuang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+K">Kaixun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+S">Shouhong Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenqiang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11120" title="Abstract">arXiv:2305.11120</a> (replaced) [<a href="/pdf/2305.11120" title="Download PDF">pdf</a>, <a href="/format/2305.11120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Compound Gaussian Least Squares Algorithm and Unrolled Network for  Linear Inverse Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lyons%2C+C">Carter Lyons</a>, 
<a href="/search/eess?searchtype=author&query=Raj%2C+R+G">Raghu G. Raj</a>, 
<a href="/search/eess?searchtype=author&query=Cheney%2C+M">Margaret Cheney</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper and supplementary material published in IEEE TSP. 16 pages, 9 figures, 6 tables; references updated
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in IEEE Transactions on Signal Processing, vol. 71, pp. 4303-4316,
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12534" title="Abstract">arXiv:2305.12534</a> (replaced) [<a href="/pdf/2305.12534" title="Download PDF">pdf</a>, <a href="/format/2305.12534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BertRLFuzzer: A BERT and Reinforcement Learning based Fuzzer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jha%2C+P">Piyush Jha</a>, 
<a href="/search/cs?searchtype=author&query=Scott%2C+J">Joseph Scott</a>, 
<a href="/search/cs?searchtype=author&query=Ganeshna%2C+J+S">Jaya Sriram Ganeshna</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+M">Mudit Singh</a>, 
<a href="/search/cs?searchtype=author&query=Ganesh%2C+V">Vijay Ganesh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14662" title="Abstract">arXiv:2305.14662</a> (replaced) [<a href="/pdf/2305.14662" title="Download PDF">pdf</a>, <a href="/format/2305.14662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic wind power forecasting resilient to missing values: an  adaptive quantile regression approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wen%2C+H">Honglin Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, submitted to Elsevier
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14912" title="Abstract">arXiv:2305.14912</a> (replaced) [<a href="/pdf/2305.14912" title="Download PDF">pdf</a>, <a href="/format/2305.14912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SVDinsTN: A Tensor Network Paradigm for Efficient Structure Search from  Regularized Modeling Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yu-Bang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xi-Le Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+J">Junhua Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qibin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Heng-Chao Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Ting-Zhu Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14991" title="Abstract">arXiv:2305.14991</a> (replaced) [<a href="/pdf/2305.14991" title="Download PDF">pdf</a>, <a href="/format/2305.14991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MuLER: Detailed and Scalable Reference-based Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karidi%2C+T">Taelin Karidi</a>, 
<a href="/search/cs?searchtype=author&query=Choshen%2C+L">Leshem Choshen</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+G">Gal Patel</a>, 
<a href="/search/cs?searchtype=author&query=Abend%2C+O">Omri Abend</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16316" title="Abstract">arXiv:2305.16316</a> (replaced) [<a href="/pdf/2305.16316" title="Download PDF">pdf</a>, <a href="/format/2305.16316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making Vision Transformers Truly Shift-Equivariant
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rojas-Gomez%2C+R+A">Renan A. Rojas-Gomez</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+T">Teck-Yian Lim</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+M+N">Minh N. Do</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+R+A">Raymond A. Yeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18381" title="Abstract">arXiv:2305.18381</a> (replaced) [<a href="/pdf/2305.18381" title="Download PDF">pdf</a>, <a href="/format/2305.18381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distill Gold from Massive Ores: Efficient Dataset Distillation via  Critical Samples Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yue Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong-Lu Li</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+K">Kaitong Cui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Tai%2C+Y">Yu-Wing Tai</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chi-Keung Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18409" title="Abstract">arXiv:2305.18409</a> (replaced) [<a href="/pdf/2305.18409" title="Download PDF">pdf</a>, <a href="/format/2305.18409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Direction-oriented Multi-objective Learning: Simple and Provable  Stochastic Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+P">Peiyao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Ban%2C+H">Hao Ban</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+K">Kaiyi Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19103" title="Abstract">arXiv:2305.19103</a> (replaced) [<a href="/pdf/2305.19103" title="Download PDF">pdf</a>, <a href="/format/2305.19103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does Conceptual Representation Require Embodiment? Insights From Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qihui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yingying Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Minghua Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+F">Feng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Chodorow%2C+M">Martin Chodorow</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Ping Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19487" title="Abstract">arXiv:2305.19487</a> (replaced) [<a href="/pdf/2305.19487" title="Download PDF">pdf</a>, <a href="/format/2305.19487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPGNN-API: A Transferable Graph Neural Network for Attack Paths  Identification and Autonomous Mitigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jmal%2C+H">Houssem Jmal</a>, 
<a href="/search/cs?searchtype=author&query=Hmida%2C+F+B">Firas Ben Hmida</a>, 
<a href="/search/cs?searchtype=author&query=Basta%2C+N">Nardine Basta</a>, 
<a href="/search/cs?searchtype=author&query=Ikram%2C+M">Muhammad Ikram</a>, 
<a href="/search/cs?searchtype=author&query=Kaafar%2C+M+A">Mohamed Ali Kaafar</a>, 
<a href="/search/cs?searchtype=author&query=Walker%2C+A">Andy Walker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Transactions on Information Forensics &amp; Security (TIFS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Neural and Evolutionary Computing (cs.NE); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19891" title="Abstract">arXiv:2305.19891</a> (replaced) [<a href="/pdf/2305.19891" title="Download PDF">pdf</a>, <a href="/format/2305.19891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Neighborhood Construction for Structured Large Discrete Action  Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akkerman%2C+F">Fabian Akkerman</a>, 
<a href="/search/cs?searchtype=author&query=Luy%2C+J">Julius Luy</a>, 
<a href="/search/cs?searchtype=author&query=van+Heeswijk%2C+W">Wouter van Heeswijk</a>, 
<a href="/search/cs?searchtype=author&query=Schiffer%2C+M">Maximilian Schiffer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02027" title="Abstract">arXiv:2306.02027</a> (replaced) [<a href="/pdf/2306.02027" title="Download PDF">pdf</a>, <a href="/format/2306.02027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolving Knowledge Mining for Class Incremental Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhihe Lu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shuicheng Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinchao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03436" title="Abstract">arXiv:2306.03436</a> (replaced) [<a href="/pdf/2306.03436" title="Download PDF">pdf</a>, <a href="/format/2306.03436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intellectual Property Protection of Diffusion Models via the Watermark  Diffusion Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Sen Peng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yufei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiaohua Jia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05382" title="Abstract">arXiv:2306.05382</a> (replaced) [<a href="/pdf/2306.05382" title="Download PDF">pdf</a>, <a href="/format/2306.05382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Blending Algorithm with Automatic Mask Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Haochen Xue</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Mingyu Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuxuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+Q">Qian Weng</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xiaobo Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Conference on Neural Information Processing 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08722" title="Abstract">arXiv:2306.08722</a> (replaced) [<a href="/pdf/2306.08722" title="Download PDF">pdf</a>, <a href="/format/2306.08722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Stabilize High-dimensional Unknown Systems Using  Lyapunov-guided Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+S">Songyuan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Fan%2C+C">Chuchu Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08977" title="Abstract">arXiv:2306.08977</a> (replaced) [<a href="/pdf/2306.08977" title="Download PDF">pdf</a>, <a href="/format/2306.08977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Path Generation for Wheeled Robots Autonomous Navigation on Vegetated  Terrain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jian%2C+Z">Zhuozhu Jian</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zejia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+H">Haoyu Shao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xueqian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinlei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+B">Bin Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10720" title="Abstract">arXiv:2306.10720</a> (replaced) [<a href="/pdf/2306.10720" title="Download PDF">pdf</a>, <a href="/format/2306.10720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Relationship between Samples and Masks for Robust Defect  Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yaping Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15832" title="Abstract">arXiv:2306.15832</a> (replaced) [<a href="/pdf/2306.15832" title="Download PDF">pdf</a>, <a href="/format/2306.15832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Easing Color Shifts in Score-Based Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deck%2C+K">Katherine Deck</a>, 
<a href="/search/cs?searchtype=author&query=Bischoff%2C+T">Tobias Bischoff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16269" title="Abstract">arXiv:2306.16269</a> (replaced) [<a href="/pdf/2306.16269" title="Download PDF">pdf</a>, <a href="/format/2306.16269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RSPrompter: Learning to Prompt for Remote Sensing Instance Segmentation  based on Visual Foundation Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Keyan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chenyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haotian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Z">Zhengxia Zou</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhenwei Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16741" title="Abstract">arXiv:2306.16741</a> (replaced) [<a href="/pdf/2306.16741" title="Download PDF">pdf</a>, <a href="/format/2306.16741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foundation Model for Endoscopy Video Analysis via Large-scale  Self-supervised Pre-train
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaoting Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Q">Qi Dou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MICCAI 2023 camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16772" title="Abstract">arXiv:2306.16772</a> (replaced) [<a href="/pdf/2306.16772" title="Download PDF">pdf</a>, <a href="/format/2306.16772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning from Synthetic Human Group Activities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Che-Jui Chang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Danrui Li</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+D">Deep Patel</a>, 
<a href="/search/cs?searchtype=author&query=Goel%2C+P">Parth Goel</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Honglu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+S">Seonghyeon Moon</a>, 
<a href="/search/cs?searchtype=author&query=Sohn%2C+S+S">Samuel S. Sohn</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S">Sejong Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Pavlovic%2C+V">Vladimir Pavlovic</a>, 
<a href="/search/cs?searchtype=author&query=Kapadia%2C+M">Mubbasir Kapadia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03705" title="Abstract">arXiv:2307.03705</a> (replaced) [<a href="/pdf/2307.03705" title="Download PDF">pdf</a>, <a href="/format/2307.03705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligent Robotic Sonographer: Mutual Information-based Disentangled  Reward Learning from Few Demonstrations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhongliang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+Y">Yuan Bi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mingchuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Ying Hu</a>, 
<a href="/search/cs?searchtype=author&query=Burke%2C+M">Michael Burke</a>, 
<a href="/search/cs?searchtype=author&query=Navab%2C+N">Nassir Navab</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04085" title="Abstract">arXiv:2307.04085</a> (replaced) [<a href="/pdf/2307.04085" title="Download PDF">pdf</a>, <a href="/format/2307.04085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vector Commitments with Efficient Updates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tas%2C+E+N">Ertem Nusret Tas</a>, 
<a href="/search/cs?searchtype=author&query=Boneh%2C+D">Dan Boneh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Advances in Financial Technologies - AFT 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04760" title="Abstract">arXiv:2307.04760</a> (replaced) [<a href="/pdf/2307.04760" title="Download PDF">pdf</a>, <a href="/format/2307.04760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Spatial Features from Audio-Visual Correspondence in Egocentric  Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Majumder%2C+S">Sagnik Majumder</a>, 
<a href="/search/cs?searchtype=author&query=Al-Halah%2C+Z">Ziad Al-Halah</a>, 
<a href="/search/cs?searchtype=author&query=Grauman%2C+K">Kristen Grauman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05052" title="Abstract">arXiv:2307.05052</a> (replaced) [<a href="/pdf/2307.05052" title="Download PDF">pdf</a>, <a href="/format/2307.05052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Understanding In-Context Learning with Contrastive  Demonstrations and Saliency Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Paiheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fuxiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongxia Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hyemi Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05468" title="Abstract">arXiv:2307.05468</a> (replaced) [<a href="/pdf/2307.05468" title="Download PDF">pdf</a>, <a href="/format/2307.05468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> My3DGen: A Scalable Personalized 3D Generative Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+L">Luchao Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiaye Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A+N">Annie N. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shengze Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+R">Roni Sengupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://luchaoqi.com/my3dgen/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09349" title="Abstract">arXiv:2307.09349</a> (replaced) [<a href="/pdf/2307.09349" title="Download PDF">pdf</a>, <a href="/format/2307.09349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A generic characterization of generalized unary temporal logic and  two-variable first-order logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Place%2C+T">Thomas Place</a>, 
<a href="/search/cs?searchtype=author&query=Zeitoun%2C+M">Marc Zeitoun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of CLS 2024 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12120" title="Abstract">arXiv:2307.12120</a> (replaced) [<a href="/pdf/2307.12120" title="Download PDF">pdf</a>, <a href="/ps/2307.12120" title="Download PostScript">ps</a>, <a href="/format/2307.12120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Money from Abelian Group Actions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Zhandry%2C+M">Mark Zhandry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added attack on the Knowledge of Group Element Assumption, as well as a generic group action model proof
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13868" title="Abstract">arXiv:2307.13868</a> (replaced) [<a href="/pdf/2307.13868" title="Download PDF">pdf</a>, <a href="/format/2307.13868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning sources of variability from high-dimensional observational  studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bridgeford%2C+E+W">Eric W. Bridgeford</a>, 
<a href="/search/stat?searchtype=author&query=Chung%2C+J">Jaewon Chung</a>, 
<a href="/search/stat?searchtype=author&query=Gilbert%2C+B">Brian Gilbert</a>, 
<a href="/search/stat?searchtype=author&query=Panda%2C+S">Sambit Panda</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+A">Adam Li</a>, 
<a href="/search/stat?searchtype=author&query=Shen%2C+C">Cencheng Shen</a>, 
<a href="/search/stat?searchtype=author&query=Badea%2C+A">Alexandra Badea</a>, 
<a href="/search/stat?searchtype=author&query=Caffo%2C+B">Brian Caffo</a>, 
<a href="/search/stat?searchtype=author&query=Vogelstein%2C+J+T">Joshua T. Vogelstein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13903" title="Abstract">arXiv:2307.13903</a> (replaced) [<a href="/pdf/2307.13903" title="Download PDF">pdf</a>, <a href="/ps/2307.13903" title="Download PostScript">ps</a>, <a href="/format/2307.13903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Corruption-Robust Lipschitz Contextual Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zuo%2C+S">Shiliang Zuo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00688" title="Abstract">arXiv:2308.00688</a> (replaced) [<a href="/pdf/2308.00688" title="Download PDF">pdf</a>, <a href="/format/2308.00688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnyLoc: Towards Universal Visual Place Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Keetha%2C+N">Nikhil Keetha</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+A">Avneesh Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Karhade%2C+J">Jay Karhade</a>, 
<a href="/search/cs?searchtype=author&query=Jatavallabhula%2C+K+M">Krishna Murthy Jatavallabhula</a>, 
<a href="/search/cs?searchtype=author&query=Scherer%2C+S">Sebastian Scherer</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+M">Madhava Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+S">Sourav Garg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE RA-L 2023 (Presented at ICRA 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01050" title="Abstract">arXiv:2308.01050</a> (replaced) [<a href="/pdf/2308.01050" title="Download PDF">pdf</a>, <a href="/format/2308.01050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Counterfactual Safety Margin Perspective on the Scoring of Autonomous  Vehicles&#x27; Riskiness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zanardi%2C+A">Alessandro Zanardi</a>, 
<a href="/search/cs?searchtype=author&query=Censi%2C+A">Andrea Censi</a>, 
<a href="/search/cs?searchtype=author&query=Atzei%2C+M">Margherita Atzei</a>, 
<a href="/search/cs?searchtype=author&query=Di+Lillo%2C+L">Luigi Di Lillo</a>, 
<a href="/search/cs?searchtype=author&query=Frazzoli%2C+E">Emilio Frazzoli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> updated experiments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01766" title="Abstract">arXiv:2308.01766</a> (replaced) [<a href="/pdf/2308.01766" title="Download PDF">pdf</a>, <a href="/format/2308.01766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Poisson Surface Reconstruction: Resolution-Agnostic Shape  Reconstruction from Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Andrade-Loarca%2C+H">Hector Andrade-Loarca</a>, 
<a href="/search/cs?searchtype=author&query=Hege%2C+J">Julius Hege</a>, 
<a href="/search/cs?searchtype=author&query=Cremers%2C+D">Daniel Cremers</a>, 
<a href="/search/cs?searchtype=author&query=Kutyniok%2C+G">Gitta Kutyniok</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03818" title="Abstract">arXiv:2308.03818</a> (replaced) [<a href="/pdf/2308.03818" title="Download PDF">pdf</a>, <a href="/format/2308.03818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A sparse coding approach to inverse problems with application to  microwave tomography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Caiafa%2C+C+F">Cesar F. Caiafa</a>, 
<a href="/search/eess?searchtype=author&query=Irastorza%2C+R+M">Ramiro M. Irastorza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to RevMexAA (conference series)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04638" title="Abstract">arXiv:2308.04638</a> (replaced) [<a href="/pdf/2308.04638" title="Download PDF">pdf</a>, <a href="/format/2308.04638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GeoAdapt: Self-Supervised Test-Time Adaptation in LiDAR Place  Recognition Using Geometric Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Knights%2C+J">Joshua Knights</a>, 
<a href="/search/cs?searchtype=author&query=Hausler%2C+S">Stephen Hausler</a>, 
<a href="/search/cs?searchtype=author&query=Sridharan%2C+S">Sridha Sridharan</a>, 
<a href="/search/cs?searchtype=author&query=Fookes%2C+C">Clinton Fookes</a>, 
<a href="/search/cs?searchtype=author&query=Moghadam%2C+P">Peyman Moghadam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Robotics and Automation Letters (RA-L) November 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05485" title="Abstract">arXiv:2308.05485</a> (replaced) [<a href="/pdf/2308.05485" title="Download PDF">pdf</a>, <a href="/format/2308.05485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Substitution for Non-Wellfounded Syntax with Binders through Monoidal  Categories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Matthes%2C+R">Ralph Matthes</a>, 
<a href="/search/cs?searchtype=author&query=Wullaert%2C+K">Kobe Wullaert</a>, 
<a href="/search/cs?searchtype=author&query=Ahrens%2C+B">Benedikt Ahrens</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v2: changed title, expanded introduction and example, minor changes in formulations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05754" title="Abstract">arXiv:2308.05754</a> (replaced) [<a href="/pdf/2308.05754" title="Download PDF">pdf</a>, <a href="/format/2308.05754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SLAM for Multiple Extended Targets using 5G Signal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jiang%2C+W">Wangjun Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Wei%2C+Z">Zhiqing Wei</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+Z">Zhiyong Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06107" title="Abstract">arXiv:2308.06107</a> (replaced) [<a href="/pdf/2308.06107" title="Download PDF">pdf</a>, <a href="/format/2308.06107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Test-Time Backdoor Defense via Detecting and Repairing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+J">Jiyang Guan</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jian Liang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ran He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06703" title="Abstract">arXiv:2308.06703</a> (replaced) [<a href="/pdf/2308.06703" title="Download PDF">pdf</a>, <a href="/format/2308.06703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the robustness difference between stochastic gradient  descent and adaptive gradient methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+A">Avery Ma</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yangchen Pan</a>, 
<a href="/search/cs?searchtype=author&query=Farahmand%2C+A">Amir-massoud Farahmand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at TMLR (Featured Certification). Code: see <a href="https://github.com/averyma/opt-robust">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08333" title="Abstract">arXiv:2308.08333</a> (replaced) [<a href="/pdf/2308.08333" title="Download PDF">pdf</a>, <a href="/format/2308.08333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Depth Gradient Continuity in Transformers: A Comparative Study  on Monocular Depth Estimation with CNN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiawei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaofeng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09791" title="Abstract">arXiv:2308.09791</a> (replaced) [<a href="/pdf/2308.09791" title="Download PDF">pdf</a>, <a href="/ps/2308.09791" title="Download PostScript">ps</a>, <a href="/format/2308.09791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient High-Dimensional Gene Selection Approach based on Binary  Horse Herd Optimization Algorithm for Biological Data Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehrabi%2C+N">Niloufar Mehrabi</a>, 
<a href="/search/cs?searchtype=author&query=Boroujeni%2C+S+P+H">Sayed Pedram Haeri Boroujeni</a>, 
<a href="/search/cs?searchtype=author&query=Pashaei%2C+E">Elnaz Pashaei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10743" title="Abstract">arXiv:2308.10743</a> (replaced) [<a href="/pdf/2308.10743" title="Download PDF">pdf</a>, <a href="/format/2308.10743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Adversarial Attacks: The Similar Target Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziruo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zikai Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huanran Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11030" title="Abstract">arXiv:2308.11030</a> (replaced) [<a href="/pdf/2308.11030" title="Download PDF">pdf</a>, <a href="/format/2308.11030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ramulator 2.0: A Modern, Modular, and Extensible DRAM Simulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haocong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Tu%C4%9Frul%2C+Y+C">Yahya Can Tu&#x11f;rul</a>, 
<a href="/search/cs?searchtype=author&query=Bostanc%C4%B1%2C+F+N">F. Nisa Bostanc&#x131;</a>, 
<a href="/search/cs?searchtype=author&query=Olgun%2C+A">Ataberk Olgun</a>, 
<a href="/search/cs?searchtype=author&query=Ya%C4%9Fl%C4%B1k%C3%A7%C4%B1%2C+A+G">A. Giray Ya&#x11f;l&#x131;k&#xe7;&#x131;</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15068" title="Abstract">arXiv:2308.15068</a> (replaced) [<a href="/pdf/2308.15068" title="Download PDF">pdf</a>, <a href="/format/2308.15068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Augmentation Framework for Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yaping Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15131" title="Abstract">arXiv:2308.15131</a> (replaced) [<a href="/pdf/2308.15131" title="Download PDF">pdf</a>, <a href="/format/2308.15131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Transceiver Design for Covert Integrated Sensing and  Communications With Imperfect CSI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuchen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+W">Wanli Ni</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianquan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wanbin Tang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+M">Min Jia</a>, 
<a href="/search/cs?searchtype=author&query=Eldar%2C+Y+C">Yonina C. Eldar</a>, 
<a href="/search/cs?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to IEEE journal for publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00519" title="Abstract">arXiv:2309.00519</a> (replaced) [<a href="/pdf/2309.00519" title="Download PDF">pdf</a>, <a href="/format/2309.00519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Score and Rank Semi-Monotonicity for Closeness, Betweenness and Harmonic  Centrality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boldi%2C+P">Paolo Boldi</a>, 
<a href="/search/cs?searchtype=author&query=D%27Ascenzo%2C+D">Davide D&#x27;Ascenzo</a>, 
<a href="/search/cs?searchtype=author&query=Furia%2C+F">Flavio Furia</a>, 
<a href="/search/cs?searchtype=author&query=Vigna%2C+S">Sebastiano Vigna</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01029" title="Abstract">arXiv:2309.01029</a> (replaced) [<a href="/pdf/2309.01029" title="Download PDF">pdf</a>, <a href="/format/2309.01029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainability for Large Language Models: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haiyan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hanjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ninghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+H">Huiqi Deng</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+H">Hengyi Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuaiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Dawei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+M">Mengnan Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02685" title="Abstract">arXiv:2309.02685</a> (replaced) [<a href="/pdf/2309.02685" title="Download PDF">pdf</a>, <a href="/format/2309.02685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-EDFs: Bi-equivariant Denoising Generative Modeling on SE(3)  for Visual Robotic Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ryu%2C+H">Hyunwoo Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jiwoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+H">Hyunseok An</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+J">Junwoo Chang</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+J">Joohwan Seo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taehan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yubin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+C">Chaewon Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jongeun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Horowitz%2C+R">Roberto Horowitz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03060" title="Abstract">arXiv:2309.03060</a> (replaced) [<a href="/pdf/2309.03060" title="Download PDF">pdf</a>, <a href="/format/2309.03060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoLA: Exploiting Compositional Structure for Automatic and Efficient  Numerical Linear Algebra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Potapczynski%2C+A">Andres Potapczynski</a>, 
<a href="/search/cs?searchtype=author&query=Finzi%2C+M">Marc Finzi</a>, 
<a href="/search/cs?searchtype=author&query=Pleiss%2C+G">Geoff Pleiss</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+A+G">Andrew Gordon Wilson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code available at <a href="https://github.com/wilson-labs/cola.">this https URL</a> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03579" title="Abstract">arXiv:2309.03579</a> (replaced) [<a href="/pdf/2309.03579" title="Download PDF">pdf</a>, <a href="/format/2309.03579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DTW+S: Shape-based Comparison of Time-series with Ordered Local Trend
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+A">Ajitesh Srivastava</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 11 figures Update: Included barycenter averaging with DTW+S along with results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06800" title="Abstract">arXiv:2309.06800</a> (replaced) [<a href="/pdf/2309.06800" title="Download PDF">pdf</a>, <a href="/format/2309.06800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-aware Traffic Prediction under Missing Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mei%2C+H">Hao Mei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junxian Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zhiming Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+G">Guanjie Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Bin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Hua Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures, a short version of this paper is accepted by ICDM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12931" title="Abstract">arXiv:2309.12931</a> (replaced) [<a href="/pdf/2309.12931" title="Download PDF">pdf</a>, <a href="/format/2309.12931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Separate Normalization in Self-supervised Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaohui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yinkai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yuanqi Du</a>, 
<a href="/search/cs?searchtype=author&query=Hassoun%2C+S">Soha Hassoun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Li-Ping Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13731" title="Abstract">arXiv:2309.13731</a> (replaced) [<a href="/pdf/2309.13731" title="Download PDF">pdf</a>, <a href="/format/2309.13731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Arabic Sentiment Analysis with Noisy Deep Explainable Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atabuzzaman%2C+M">Md. Atabuzzaman</a>, 
<a href="/search/cs?searchtype=author&query=Shajalal%2C+M">Md Shajalal</a>, 
<a href="/search/cs?searchtype=author&query=Baby%2C+M+B">Maksuda Bilkis Baby</a>, 
<a href="/search/cs?searchtype=author&query=Boden%2C+A">Alexander Boden</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the pre-print version of our accepted paper at the 7th International Conference on Natural Language Processing and Information Retrieval~(ACM NLPIR'2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14327" title="Abstract">arXiv:2309.14327</a> (replaced) [<a href="/pdf/2309.14327" title="Download PDF">pdf</a>, <a href="/format/2309.14327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepSpeed-VisualChat: Multi-Round Multi-Image Interleave Chat via  Multi-Modal Causal Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zhewei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaoxia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Conglong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Minjia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Heyang Qin</a>, 
<a href="/search/cs?searchtype=author&query=Ruwase%2C+O">Olatunji Ruwase</a>, 
<a href="/search/cs?searchtype=author&query=Awan%2C+A+A">Ammar Ahmad Awan</a>, 
<a href="/search/cs?searchtype=author&query=Rajbhandari%2C+S">Samyam Rajbhandari</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuxiong He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00402" title="Abstract">arXiv:2310.00402</a> (replaced) [<a href="/pdf/2310.00402" title="Download PDF">pdf</a>, <a href="/format/2310.00402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiskANN++: Efficient Page-based Search over Isomorphic Mapped Graph  Index using Query-sensitivity Entry Vertex
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+J">Jiongkang Ni</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaoliang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Can Li</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiajie Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+S">Shihai Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuecang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages including references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00489" title="Abstract">arXiv:2310.00489</a> (replaced) [<a href="/pdf/2310.00489" title="Download PDF">pdf</a>, <a href="/format/2310.00489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic DAG Discovery for Interpretable Imitation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tianxiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenchao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Suhang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuncong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yanchi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+W">Wei Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haifeng Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00965" title="Abstract">arXiv:2310.00965</a> (replaced) [<a href="/pdf/2310.00965" title="Download PDF">pdf</a>, <a href="/format/2310.00965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effective Learning with Node Perturbation in Deep Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dalm%2C+S">Sander Dalm</a>, 
<a href="/search/cs?searchtype=author&query=van+Gerven%2C+M">Marcel van Gerven</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+N">Nasir Ahmad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01406" title="Abstract">arXiv:2310.01406</a> (replaced) [<a href="/pdf/2310.01406" title="Download PDF">pdf</a>, <a href="/format/2310.01406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HumanNorm: Learning Normal Diffusion Model for High-quality and  Realistic 3D Human Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+R">Ruizhi Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Ying Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yebin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qing Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The project page of HumanNorm is <a href="https://humannorm.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01768" title="Abstract">arXiv:2310.01768</a> (replaced) [<a href="/pdf/2310.01768" title="Download PDF">pdf</a>, <a href="/format/2310.01768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backdiff: a diffusion model for generalized transferable protein  backmapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+Y">Yikai Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+M">Ming Chen</a>, 
<a href="/search/q-bio?searchtype=author&query=Lin%2C+G">Guang Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01870" title="Abstract">arXiv:2310.01870</a> (replaced) [<a href="/pdf/2310.01870" title="Download PDF">pdf</a>, <a href="/format/2310.01870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepDecipher: Accessing and Investigating Neuron Activation in Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garde%2C+A">Albert Garde</a>, 
<a href="/search/cs?searchtype=author&query=Kran%2C+E">Esben Kran</a>, 
<a href="/search/cs?searchtype=author&query=Barez%2C+F">Fazl Barez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages (9 total), 1 figure, submitted to NeurIPS 2023 Workshop XAIA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01929" title="Abstract">arXiv:2310.01929</a> (replaced) [<a href="/pdf/2310.01929" title="Download PDF">pdf</a>, <a href="/format/2310.01929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating Cultural Chasms: Exploring and Unlocking the Cultural POV of  Text-To-Image Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ventura%2C+M">Mor Ventura</a>, 
<a href="/search/cs?searchtype=author&query=Ben-David%2C+E">Eyal Ben-David</a>, 
<a href="/search/cs?searchtype=author&query=Korhonen%2C+A">Anna Korhonen</a>, 
<a href="/search/cs?searchtype=author&query=Reichart%2C+R">Roi Reichart</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03605" title="Abstract">arXiv:2310.03605</a> (replaced) [<a href="/pdf/2310.03605" title="Download PDF">pdf</a>, <a href="/format/2310.03605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FASER: Binary Code Similarity Search through the use of Intermediate  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Collyer%2C+J">Josh Collyer</a>, 
<a href="/search/cs?searchtype=author&query=Watson%2C+T">Tim Watson</a>, 
<a href="/search/cs?searchtype=author&query=Phillips%2C+I">Iain Phillips</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, Proceedings of the Conference on Applied Machine Learning in Information Security (CAMLIS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03684" title="Abstract">arXiv:2310.03684</a> (replaced) [<a href="/pdf/2310.03684" title="Download PDF">pdf</a>, <a href="/format/2310.03684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Robey%2C+A">Alexander Robey</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+E">Eric Wong</a>, 
<a href="/search/cs?searchtype=author&query=Hassani%2C+H">Hamed Hassani</a>, 
<a href="/search/cs?searchtype=author&query=Pappas%2C+G+J">George J. Pappas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05055" title="Abstract">arXiv:2310.05055</a> (replaced) [<a href="/pdf/2310.05055" title="Download PDF">pdf</a>, <a href="/format/2310.05055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FairTune: Optimizing Parameter Efficient Fine Tuning for Fairness in  Medical Image Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dutt%2C+R">Raman Dutt</a>, 
<a href="/search/cs?searchtype=author&query=Bohdal%2C+O">Ondrej Bohdal</a>, 
<a href="/search/cs?searchtype=author&query=Tsaftaris%2C+S+A">Sotirios A. Tsaftaris</a>, 
<a href="/search/cs?searchtype=author&query=Hospedales%2C+T">Timothy Hospedales</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 tables, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05199" title="Abstract">arXiv:2310.05199</a> (replaced) [<a href="/pdf/2310.05199" title="Download PDF">pdf</a>, <a href="/format/2310.05199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Loose lips sink ships: Mitigating Length Bias in Reinforcement Learning  from Human Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Wei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Rui Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+W">Wenyu Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+S">Shihan Dou</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+T">Tao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP 2023 findings, Length Bias in RLHF, Mitigate bias in reward modeling
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05703" title="Abstract">arXiv:2310.05703</a> (replaced) [<a href="/pdf/2310.05703" title="Download PDF">pdf</a>, <a href="/format/2310.05703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Attribution Method for Siamese Encoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%B6ller%2C+L">Lucas M&#xf6;ller</a>, 
<a href="/search/cs?searchtype=author&query=Nikolaev%2C+D">Dmitry Nikolaev</a>, 
<a href="/search/cs?searchtype=author&query=Pad%C3%B3%2C+S">Sebastian Pad&#xf3;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to EMNLP'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05866" title="Abstract">arXiv:2310.05866</a> (replaced) [<a href="/pdf/2310.05866" title="Download PDF">pdf</a>, <a href="/format/2310.05866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative quantum machine learning via denoising diffusion  probabilistic models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+B">Bingzhi Zhang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Xu%2C+P">Peng Xu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+X">Xiaohui Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhuang%2C+Q">Quntao Zhuang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5+7 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05989" title="Abstract">arXiv:2310.05989</a> (replaced) [<a href="/pdf/2310.05989" title="Download PDF">pdf</a>, <a href="/format/2310.05989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DynamicBEV: Leveraging Dynamic Queries and Temporal Context for 3D  Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiawei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">Yingxin Lai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06389" title="Abstract">arXiv:2310.06389</a> (replaced) [<a href="/pdf/2310.06389" title="Download PDF">pdf</a>, <a href="/format/2310.06389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Stackable and Skippable LEGO Bricks for Efficient,  Reconfigurable, and Variable-Resolution Diffusion Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Huangjie Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhendong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jianbo Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+G">Guanghan Ning</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+P">Pengcheng He</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Q">Quanzeng You</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongxia Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mingyuan Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06530" title="Abstract">arXiv:2310.06530</a> (replaced) [<a href="/pdf/2310.06530" title="Download PDF">pdf</a>, <a href="/format/2310.06530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Refining Decompiled C Code with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wong%2C+W+K">Wai Kin Wong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huaijin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhibo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Q">Qiyi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+S">Sen Nie</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shi Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08235" title="Abstract">arXiv:2310.08235</a> (replaced) [<a href="/pdf/2310.08235" title="Download PDF">pdf</a>, <a href="/format/2310.08235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GROOT: Learning to Follow Instructions by Watching Gameplay Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+S">Shaofei Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bowei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaojian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Anji Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yitao Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08812" title="Abstract">arXiv:2310.08812</a> (replaced) [<a href="/pdf/2310.08812" title="Download PDF">pdf</a>, <a href="/format/2310.08812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A novel decomposed-ensemble time series forecasting framework: capturing  underlying volatility information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Gui%2C+Z">Zhengtao Gui</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+H">Haoyuan Li</a>, 
<a href="/search/stat?searchtype=author&query=Xu%2C+S">Sijie Xu</a>, 
<a href="/search/stat?searchtype=author&query=Chen%2C+Y">Yu Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09932" title="Abstract">arXiv:2310.09932</a> (replaced) [<a href="/pdf/2310.09932" title="Download PDF">pdf</a>, <a href="/format/2310.09932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Reading Between the Heat&quot;: Co-Teaching Body Thermal Signatures for  Non-intrusive Stress Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yi Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+H">Harshit Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhongyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bergen-Cico%2C+D">Dessa Bergen-Cico</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+T">Tauhidur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Salekin%2C+A">Asif Salekin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09949" title="Abstract">arXiv:2310.09949</a> (replaced) [<a href="/pdf/2310.09949" title="Download PDF">pdf</a>, <a href="/format/2310.09949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chameleon: a heterogeneous and disaggregated accelerator system for  retrieval-augmented language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wenqi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zeller%2C+M">Marco Zeller</a>, 
<a href="/search/cs?searchtype=author&query=Waleffe%2C+R">Roger Waleffe</a>, 
<a href="/search/cs?searchtype=author&query=Hoefler%2C+T">Torsten Hoefler</a>, 
<a href="/search/cs?searchtype=author&query=Alonso%2C+G">Gustavo Alonso</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11518" title="Abstract">arXiv:2310.11518</a> (replaced) [<a href="/pdf/2310.11518" title="Download PDF">pdf</a>, <a href="/format/2310.11518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guarantees for Self-Play in Multiplayer Games via Polymatrix  Decomposability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=MacQueen%2C+R">Revan MacQueen</a>, 
<a href="/search/cs?searchtype=author&query=Wright%2C+J+R">James R. Wright</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12819" title="Abstract">arXiv:2310.12819</a> (replaced) [<a href="/pdf/2310.12819" title="Download PDF">pdf</a>, <a href="/format/2310.12819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Search for Efficient Planning with Completeness Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kujanp%C3%A4%C3%A4%2C+K">Kalle Kujanp&#xe4;&#xe4;</a>, 
<a href="/search/cs?searchtype=author&query=Pajarinen%2C+J">Joni Pajarinen</a>, 
<a href="/search/cs?searchtype=author&query=Ilin%2C+A">Alexander Ilin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Poster
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12835" title="Abstract">arXiv:2310.12835</a> (replaced) [<a href="/pdf/2310.12835" title="Download PDF">pdf</a>, <a href="/format/2310.12835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High Dynamic Range mmWave Massive MU-MIMO with Householder Reflections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Palhares%2C+V">Victoria Palhares</a>, 
<a href="/search/cs?searchtype=author&query=Marti%2C+G">Gian Marti</a>, 
<a href="/search/cs?searchtype=author&query=Casta%C3%B1eda%2C+O">Oscar Casta&#xf1;eda</a>, 
<a href="/search/cs?searchtype=author&query=Studer%2C+C">Christoph Studer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the Asilomar Conference on Signals, Systems, and Computers 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12913" title="Abstract">arXiv:2310.12913</a> (replaced) [<a href="/pdf/2310.12913" title="Download PDF">pdf</a>, <a href="/ps/2310.12913" title="Download PostScript">ps</a>, <a href="/format/2310.12913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deterministic 3SUM-Hardness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fischer%2C+N">Nick Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Kaliciak%2C+P">Piotr Kaliciak</a>, 
<a href="/search/cs?searchtype=author&query=Polak%2C+A">Adam Polak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at ITCS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14522" title="Abstract">arXiv:2310.14522</a> (replaced) [<a href="/pdf/2310.14522" title="Download PDF">pdf</a>, <a href="/format/2310.14522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A kernel-based method for Schr&#xf6;dinger bridges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Nakano%2C+Y">Yumiharu Nakano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14566" title="Abstract">arXiv:2310.14566</a> (replaced) [<a href="/pdf/2310.14566" title="Download PDF">pdf</a>, <a href="/format/2310.14566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HallusionBench: An Advanced Diagnostic Suite for Entangled Language  Hallucination &amp; Visual Illusion in Large Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+T">Tianrui Guan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fuxiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+R">Ruiqi Xian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongxia Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xijun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lichang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Furong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yacoob%2C+Y">Yaser Yacoob</a>, 
<a href="/search/cs?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16267" title="Abstract">arXiv:2310.16267</a> (replaced) [<a href="/pdf/2310.16267" title="Download PDF">pdf</a>, <a href="/format/2310.16267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Student Classroom Behavior Detection based on Spatio-Temporal Network  and Multi-Model Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaofei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2310.02522">arXiv:2310.02522</a>; text overlap with <a href="/abs/2306.03318">arXiv:2306.03318</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17347" title="Abstract">arXiv:2310.17347</a> (replaced) [<a href="/pdf/2310.17347" title="Download PDF">pdf</a>, <a href="/format/2310.17347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CADS: Unleashing the Diversity of Diffusion Models through  Condition-Annealed Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sadat%2C+S">Seyedmorteza Sadat</a>, 
<a href="/search/cs?searchtype=author&query=Buhmann%2C+J">Jakob Buhmann</a>, 
<a href="/search/cs?searchtype=author&query=Bradley%2C+D">Derek Bradley</a>, 
<a href="/search/cs?searchtype=author&query=Hilliges%2C+O">Otmar Hilliges</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+R+M">Romann M. Weber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17462" title="Abstract">arXiv:2310.17462</a> (replaced) [<a href="/pdf/2310.17462" title="Download PDF">pdf</a>, <a href="/format/2310.17462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Learning Monocular 3D Object Localization From 2D Labels using  the Physical Laws of Motion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kienzle%2C+D">Daniel Kienzle</a>, 
<a href="/search/cs?searchtype=author&query=Lorenz%2C+J">Julian Lorenz</a>, 
<a href="/search/cs?searchtype=author&query=Ludwig%2C+K">Katja Ludwig</a>, 
<a href="/search/cs?searchtype=author&query=Lienhart%2C+R">Rainer Lienhart</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18023" title="Abstract">arXiv:2310.18023</a> (replaced) [<a href="/pdf/2310.18023" title="Download PDF">pdf</a>, <a href="/format/2310.18023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SentMix-3L: A Bangla-English-Hindi Code-Mixed Dataset for Sentiment  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raihan%2C+M+N">Md Nishat Raihan</a>, 
<a href="/search/cs?searchtype=author&query=Goswami%2C+D">Dhiman Goswami</a>, 
<a href="/search/cs?searchtype=author&query=Mahmud%2C+A">Antara Mahmud</a>, 
<a href="/search/cs?searchtype=author&query=Anastasopoulos%2C+A">Antonios Anastasopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Zampieri%2C+M">Marcos Zampieri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18297" title="Abstract">arXiv:2310.18297</a> (replaced) [<a href="/pdf/2310.18297" title="Download PDF">pdf</a>, <a href="/format/2310.18297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Clustering Conditioned on Text Criteria
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kwon%2C+S">Sehyun Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jaeseung Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minkyu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+J">Jaewoong Cho</a>, 
<a href="/search/cs?searchtype=author&query=Ryu%2C+E+K">Ernest K. Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kangwook Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18348" title="Abstract">arXiv:2310.18348</a> (replaced) [<a href="/pdf/2310.18348" title="Download PDF">pdf</a>, <a href="/format/2310.18348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meaning Representations from Trajectories in Autoregressive Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T+Y">Tian Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Trager%2C+M">Matthew Trager</a>, 
<a href="/search/cs?searchtype=author&query=Achille%2C+A">Alessandro Achille</a>, 
<a href="/search/cs?searchtype=author&query=Perera%2C+P">Pramuditha Perera</a>, 
<a href="/search/cs?searchtype=author&query=Zancato%2C+L">Luca Zancato</a>, 
<a href="/search/cs?searchtype=author&query=Soatto%2C+S">Stefano Soatto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19583" title="Abstract">arXiv:2310.19583</a> (replaced) [<a href="/pdf/2310.19583" title="Download PDF">pdf</a>, <a href="/format/2310.19583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GC-MVSNet: Multi-View, Multi-Scale, Geometrically-Consistent Multi-View  Stereo
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vats%2C+V+K">Vibhas K. Vats</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+S">Sripad Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Crandall%2C+D+J">David J. Crandall</a>, 
<a href="/search/cs?searchtype=author&query=Reza%2C+M+A">Md. Alimoor Reza</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+S">Soon-heung Jung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in WACV 2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the IEEE/CVF Winter Conference on Applications of
  Computer Vision (WACV) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20208" title="Abstract">arXiv:2310.20208</a> (replaced) [<a href="/pdf/2310.20208" title="Download PDF">pdf</a>, <a href="/format/2310.20208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZoomNeXt: A Unified Collaborative Pyramid Network for Camouflaged Object  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pang%2C+Y">Youwei Pang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiaoqi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+T">Tian-Zhu Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lihe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Huchuan Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extensions to the conference version: <a href="/abs/2203.02688">arXiv:2203.02688</a>; Fixed some word errors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00213" title="Abstract">arXiv:2311.00213</a> (replaced) [<a href="/pdf/2311.00213" title="Download PDF">pdf</a>, <a href="/format/2311.00213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consistent Video-to-Video Transfer Using Synthetic Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jiaxin Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Tianjun Xiao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tong He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00290" title="Abstract">arXiv:2311.00290</a> (replaced) [<a href="/pdf/2311.00290" title="Download PDF">pdf</a>, <a href="/format/2311.00290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inference of CO2 flow patterns -- a feasibility study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gahlot%2C+A+P">Abhinav Prakash Gahlot</a>, 
<a href="/search/cs?searchtype=author&query=Erdinc%2C+H+T">Huseyin Tuna Erdinc</a>, 
<a href="/search/cs?searchtype=author&query=Orozco%2C+R">Rafael Orozco</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Ziyi Yin</a>, 
<a href="/search/cs?searchtype=author&query=Herrmann%2C+F+J">Felix J. Herrmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in NeurIPS 2023 Workshop - Tackling Climate Change with Machine Learning (Spotlight)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Mathematical Physics (math-ph); Geophysics (physics.geo-ph)

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00423" title="Abstract">arXiv:2311.00423</a> (replaced) [<a href="/pdf/2311.00423" title="Download PDF">pdf</a>, <a href="/format/2311.00423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMRec: Large Language Models with Graph Augmentation for Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xubin Ren</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiabin Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qinyong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+L">Lixin Su</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Suqi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Dawei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WSDM 2024 Oral Presentation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02416" title="Abstract">arXiv:2311.02416</a> (replaced) [<a href="/pdf/2311.02416" title="Download PDF">pdf</a>, <a href="/ps/2311.02416" title="Download PostScript">ps</a>, <a href="/format/2311.02416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expressive Power of Hypergraph Lambek Grammars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pshenitsyn%2C+T">Tikhon Pshenitsyn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02957" title="Abstract">arXiv:2311.02957</a> (replaced) [<a href="/pdf/2311.02957" title="Download PDF">pdf</a>, <a href="/format/2311.02957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe and Efficient Trajectory Optimization for Autonomous Vehicles using  B-spline with Incremental Path Flattening
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jongseo Choi</a>, 
<a href="/search/cs?searchtype=author&query=Chin%2C+H">Hyuntai Chin</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Hyunwoo Park</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+D">Daehyeok Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sanghyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Baek%2C+D">Doosan Baek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 21 figures, 4 tables, 3 algorithms
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07184" title="Abstract">arXiv:2311.07184</a> (replaced) [<a href="/pdf/2311.07184" title="Download PDF">pdf</a>, <a href="/ps/2311.07184" title="Download PostScript">ps</a>, <a href="/format/2311.07184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Axis Transformer with 2D Rotary Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Erickson%2C+L">Lily Erickson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07574" title="Abstract">arXiv:2311.07574</a> (replaced) [<a href="/pdf/2311.07574" title="Download PDF">pdf</a>, <a href="/format/2311.07574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To See is to Believe: Prompting GPT-4V for Better Visual Instruction  Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junke Wang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+L">Lingchen Meng</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+Z">Zejia Weng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bo He</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zuxuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu-Gang Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> techical report; work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07965" title="Abstract">arXiv:2311.07965</a> (replaced) [<a href="/pdf/2311.07965" title="Download PDF">pdf</a>, <a href="/format/2311.07965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DQR-TTS: Semi-supervised Text-to-speech Synthesis with Dynamic Quantized  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiangzong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pengcheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xulong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+N">Ning Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jing Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 21st IEEE International Symposium on Parallel and Distributed Processing with Applications (IEEE ISPA 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08088" title="Abstract">arXiv:2311.08088</a> (replaced) [<a href="/pdf/2311.08088" title="Download PDF">pdf</a>, <a href="/format/2311.08088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interconnection of Discrete-Time Dissipative Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Martinelli%2C+A">Andrea Martinelli</a>, 
<a href="/search/math?searchtype=author&query=Aboudonia%2C+A">Ahmed Aboudonia</a>, 
<a href="/search/math?searchtype=author&query=Lygeros%2C+J">John Lygeros</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08100" title="Abstract">arXiv:2311.08100</a> (replaced) [<a href="/pdf/2311.08100" title="Download PDF">pdf</a>, <a href="/format/2311.08100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepEMplanner: An End-to-End EM Motion Planner with Iterative  Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhili Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+M">Maosheng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shuangjie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+T">Tongyi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qifeng Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08569" title="Abstract">arXiv:2311.08569</a> (replaced) [<a href="/pdf/2311.08569" title="Download PDF">pdf</a>, <a href="/ps/2311.08569" title="Download PostScript">ps</a>, <a href="/format/2311.08569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty Quantification in Neural-Network Based Pain Intensity  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ozek%2C+B">Burcu Ozek</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhenyuan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Radhakrishnan%2C+S">Srinivasan Radhakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Kamarthi%2C+S">Sagar Kamarthi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 5 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08745" title="Abstract">arXiv:2311.08745</a> (replaced) [<a href="/pdf/2311.08745" title="Download PDF">pdf</a>, <a href="/format/2311.08745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Stochastic Gradient Descent to Smooth Nonconvex Functions:  Analysis of Implicit Graduated Optimization with Optimal Noise Scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sato%2C+N">Naoki Sato</a>, 
<a href="/search/cs?searchtype=author&query=Iiduka%2C+H">Hideaki Iiduka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The latest version was updated on Nov. 29
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08972" title="Abstract">arXiv:2311.08972</a> (replaced) [<a href="/pdf/2311.08972" title="Download PDF">pdf</a>, <a href="/format/2311.08972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised approaches based on optimal transport and convex analysis  for inverse problems in imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carioni%2C+M">Marcello Carioni</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+S">Subhadip Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+H+Y">Hong Ye Tan</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Junqi Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09257" title="Abstract">arXiv:2311.09257</a> (replaced) [<a href="/pdf/2311.09257" title="Download PDF">pdf</a>, <a href="/format/2311.09257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UFOGen: You Forward Once Large Scale Text-to-Image Generation via  Diffusion GANs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yanwu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zhisheng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+T">Tingbo Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09511" title="Abstract">arXiv:2311.09511</a> (replaced) [<a href="/pdf/2311.09511" title="Download PDF">pdf</a>, <a href="/format/2311.09511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying Systems with Symmetries using Equivariant Autoregressive  Reservoir Computers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Vides%2C+F">Fredy Vides</a>, 
<a href="/search/eess?searchtype=author&query=Nogueira%2C+I+B+R">Idelfonso B. R. Nogueira</a>, 
<a href="/search/eess?searchtype=author&query=Banegas%2C+L">Lendy Banegas</a>, 
<a href="/search/eess?searchtype=author&query=Flores%2C+E">Evelyn Flores</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The views expressed in the article do not necessarily represent the views of the National Commission of Banks and Insurance Companies of Honduras
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10357" title="Abstract">arXiv:2311.10357</a> (replaced) [<a href="/pdf/2311.10357" title="Download PDF">pdf</a>, <a href="/ps/2311.10357" title="Download PostScript">ps</a>, <a href="/format/2311.10357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast algorithms for classical specifications of stabiliser states and  Clifford gates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=de+Silva%2C+N">Nadish de Silva</a>, 
<a href="/search/quant-ph?searchtype=author&query=Salmon%2C+W">Wilfred Salmon</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yin%2C+M">Ming Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Python implementations available at <a href="https://github.com/ndesilva/stabiliser-tools.">this https URL</a> New in v2: new algorithm for extracting the stabiliser tableau of a Clifford gate matrix that is exponentially faster compared to v1, more thorough complexity analyses
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10642" title="Abstract">arXiv:2311.10642</a> (replaced) [<a href="/pdf/2311.10642" title="Download PDF">pdf</a>, <a href="/format/2311.10642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Attention: Exploring Shallow Feed-Forward Neural Networks as  an Alternative to Attention Layers in Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bozic%2C+V">Vukasin Bozic</a>, 
<a href="/search/cs?searchtype=author&query=Dordevic%2C+D">Danilo Dordevic</a>, 
<a href="/search/cs?searchtype=author&query=Coppola%2C+D">Daniele Coppola</a>, 
<a href="/search/cs?searchtype=author&query=Thommes%2C+J">Joseph Thommes</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S+P">Sidak Pal Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI24(<a href="https://aaai.org/aaai-conference/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10793" title="Abstract">arXiv:2311.10793</a> (replaced) [<a href="/pdf/2311.10793" title="Download PDF">pdf</a>, <a href="/format/2311.10793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Traffic Sign Interpretation in Real Road Scene
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chuang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+K">Kai Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mulin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Haozhao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xu Han</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+T">Tao Han</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Changxing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+H">Han Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bingxuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10813" title="Abstract">arXiv:2311.10813</a> (replaced) [<a href="/pdf/2311.10813" title="Download PDF">pdf</a>, <a href="/format/2311.10813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Language Agent for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+J">Jiageng Mao</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Junjie Ye</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yuxi Qian</a>, 
<a href="/search/cs?searchtype=author&query=Pavone%2C+M">Marco Pavone</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://usc-gvl.github.io/Agent-Driver/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11254" title="Abstract">arXiv:2311.11254</a> (replaced) [<a href="/pdf/2311.11254" title="Download PDF">pdf</a>, <a href="/format/2311.11254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BOIS: Bayesian Optimization of Interconnected Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Gonz%C3%A1lez%2C+L+D">Leonardo D. Gonz&#xe1;lez</a>, 
<a href="/search/stat?searchtype=author&query=Zavala%2C+V+M">Victor M. Zavala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11772" title="Abstract">arXiv:2311.11772</a> (replaced) [<a href="/pdf/2311.11772" title="Download PDF">pdf</a>, <a href="/format/2311.11772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Good Feature Extractor Is All You Need for Weakly Supervised Learning  in Histopathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=W%C3%B6lflein%2C+G">Georg W&#xf6;lflein</a>, 
<a href="/search/cs?searchtype=author&query=Ferber%2C+D">Dyke Ferber</a>, 
<a href="/search/cs?searchtype=author&query=Meneghetti%2C+A+R">Asier Rabasco Meneghetti</a>, 
<a href="/search/cs?searchtype=author&query=Nahhas%2C+O+S+M+E">Omar S. M. El Nahhas</a>, 
<a href="/search/cs?searchtype=author&query=Truhn%2C+D">Daniel Truhn</a>, 
<a href="/search/cs?searchtype=author&query=Carrero%2C+Z+I">Zunamys I. Carrero</a>, 
<a href="/search/cs?searchtype=author&query=Harrison%2C+D+J">David J. Harrison</a>, 
<a href="/search/cs?searchtype=author&query=Arandjelovi%C4%87%2C+O">Ognjen Arandjelovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Kather%2C+J+N">Jakob N. Kather</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12754" title="Abstract">arXiv:2311.12754</a> (replaced) [<a href="/pdf/2311.12754" title="Download PDF">pdf</a>, <a href="/format/2311.12754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SelfOcc: Self-Supervised Vision-Based 3D Occupancy Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuanhui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Wenzhao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Borui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiwen Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at: <a href="https://github.com/huang-yh/SelfOcc">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12775" title="Abstract">arXiv:2311.12775</a> (replaced) [<a href="/pdf/2311.12775" title="Download PDF">pdf</a>, <a href="/format/2311.12775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SuGaR: Surface-Aligned Gaussian Splatting for Efficient 3D Mesh  Reconstruction and High-Quality Mesh Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%C3%A9don%2C+A">Antoine Gu&#xe9;don</a>, 
<a href="/search/cs?searchtype=author&query=Lepetit%2C+V">Vincent Lepetit</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We identified a minor typographical error in Equation 6; We updated the paper accordingly. Project Webpage: <a href="https://imagine.enpc.fr/~guedona/sugar/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13010" title="Abstract">arXiv:2311.13010</a> (replaced) [<a href="/e-print/2311.13010" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Catoni: Sharper Rates for Heavy-Tailed and Robust Mean Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gupta%2C+S">Shivam Gupta</a>, 
<a href="/search/math?searchtype=author&query=Hopkins%2C+S+B">Samuel B. Hopkins</a>, 
<a href="/search/math?searchtype=author&query=Price%2C+E">Eric Price</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Error in proof of Theorem 1.1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Data Structures and Algorithms (cs.DS); Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13187" title="Abstract">arXiv:2311.13187</a> (replaced) [<a href="/pdf/2311.13187" title="Download PDF">pdf</a>, <a href="/format/2311.13187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeISF: Neural Incident Stokes Field for Geometry and Material Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Ono%2C+T">Taishi Ono</a>, 
<a href="/search/cs?searchtype=author&query=Uemori%2C+T">Takeshi Uemori</a>, 
<a href="/search/cs?searchtype=author&query=Mihara%2C+H">Hajime Mihara</a>, 
<a href="/search/cs?searchtype=author&query=Gatto%2C+A">Alexander Gatto</a>, 
<a href="/search/cs?searchtype=author&query=Nagahara%2C+H">Hajime Nagahara</a>, 
<a href="/search/cs?searchtype=author&query=Moriuchi%2C+Y">Yusuke Moriuchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13373" title="Abstract">arXiv:2311.13373</a> (replaced) [<a href="/pdf/2311.13373" title="Download PDF">pdf</a>, <a href="/format/2311.13373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Model is a Good Policy Teacher for Training Reinforcement  Learning Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zihao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Bin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chenyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13517" title="Abstract">arXiv:2311.13517</a> (replaced) [<a href="/pdf/2311.13517" title="Download PDF">pdf</a>, <a href="/format/2311.13517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning-Based Relaxation of Completeness Requirements for Data Entry  Forms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belgacem%2C+H">Hichem Belgacem</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaochen Li</a>, 
<a href="/search/cs?searchtype=author&query=Bianculli%2C+D">Domenico Bianculli</a>, 
<a href="/search/cs?searchtype=author&query=Briand%2C+L+C">Lionel C. Briand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication by ACM Transactions on Software Engineering and Methodology (TOSEM)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13534" title="Abstract">arXiv:2311.13534</a> (replaced) [<a href="/pdf/2311.13534" title="Download PDF">pdf</a>, <a href="/format/2311.13534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LM-Cocktail: Resilient Tuning of Language Models via Model Merging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+S">Shitao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peitian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+X">Xingrun Xing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13562" title="Abstract">arXiv:2311.13562</a> (replaced) [<a href="/pdf/2311.13562" title="Download PDF">pdf</a>, <a href="/format/2311.13562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Soulstyler: Using Large Language Model to Guide Image Style Transfer for  Target Object
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+P">Peng Rong</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jingbo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chao Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+H">Hongwu Lv</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages,3 figures,ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13967" title="Abstract">arXiv:2311.13967</a> (replaced) [<a href="/pdf/2311.13967" title="Download PDF">pdf</a>, <a href="/format/2311.13967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unconstrained learning of networked nonlinear systems via free  parametrization of stable interconnected operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Massai%2C+L">Leonardo Massai</a>, 
<a href="/search/eess?searchtype=author&query=Saccani%2C+D">Danilo Saccani</a>, 
<a href="/search/eess?searchtype=author&query=Furieri%2C+L">Luca Furieri</a>, 
<a href="/search/eess?searchtype=author&query=Ferrari-Trecate%2C+G">Giancarlo Ferrari-Trecate</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13994" title="Abstract">arXiv:2311.13994</a> (replaced) [<a href="/pdf/2311.13994" title="Download PDF">pdf</a>, <a href="/format/2311.13994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient Distributed Nash Equilibrium Seeking with Compressed and  Event-triggered Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xiaomeng Chen</a>, 
<a href="/search/eess?searchtype=author&query=Huo%2C+W">Wei Huo</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Y">Yuchi Wu</a>, 
<a href="/search/eess?searchtype=author&query=Dey%2C+S">Subhrakanti Dey</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+L">Ling Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14056" title="Abstract">arXiv:2311.14056</a> (replaced) [<a href="/pdf/2311.14056" title="Download PDF">pdf</a>, <a href="/format/2311.14056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DPSUR: Accelerating Differentially Private Stochastic Gradient Descent  Using Selective Update and Release
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qingqing Ye</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Haibo Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhili Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lulu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kuncan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ran%2C+X">Xun Ran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by VLDB 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14284" title="Abstract">arXiv:2311.14284</a> (replaced) [<a href="/pdf/2311.14284" title="Download PDF">pdf</a>, <a href="/format/2311.14284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Paragraph-to-Image Generation with Information-Enriched Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Weijia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuang Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yefei He</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chunhua Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lele Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yan Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+T">Tingting Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Di Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongyuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The project website is at: <a href="https://weijiawu.github.io/ParaDiffusionPage/.">this https URL</a> Code: <a href="https://github.com/weijiawu/ParaDiffusion">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14675" title="Abstract">arXiv:2311.14675</a> (replaced) [<a href="/pdf/2311.14675" title="Download PDF">pdf</a>, <a href="/format/2311.14675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast and Expressive Gesture Recognition using a Combination-Homomorphic  Electromyogram Encoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Smedemark-Margulies%2C+N">Niklas Smedemark-Margulies</a>, 
<a href="/search/cs?searchtype=author&query=Bicer%2C+Y">Yunus Bicer</a>, 
<a href="/search/cs?searchtype=author&query=Sunger%2C+E">Elifnur Sunger</a>, 
<a href="/search/cs?searchtype=author&query=Imbiriba%2C+T">Tales Imbiriba</a>, 
<a href="/search/cs?searchtype=author&query=Tunik%2C+E">Eugene Tunik</a>, 
<a href="/search/cs?searchtype=author&query=Erdogmus%2C+D">Deniz Erdogmus</a>, 
<a href="/search/cs?searchtype=author&query=Yarossi%2C+M">Mathew Yarossi</a>, 
<a href="/search/cs?searchtype=author&query=Walters%2C+R">Robin Walters</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 7 figures, 6 tables V2: add link to code, fix bibliography
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14698" title="Abstract">arXiv:2311.14698</a> (replaced) [<a href="/pdf/2311.14698" title="Download PDF">pdf</a>, <a href="/format/2311.14698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Business Policy Experiments using Fractional Factorial Designs: Consumer  Retention on DoorDash
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Tang%2C+Y">Yixin Tang</a>, 
<a href="/search/stat?searchtype=author&query=Lin%2C+Y">Yicong Lin</a>, 
<a href="/search/stat?searchtype=author&query=Sahni%2C+N+S">Navdeep S. Sahni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Econometrics (econ.EM)

</div>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14706" title="Abstract">arXiv:2311.14706</a> (replaced) [<a href="/pdf/2311.14706" title="Download PDF">pdf</a>, <a href="/ps/2311.14706" title="Download PostScript">ps</a>, <a href="/format/2311.14706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social AI Improves Well-Being Among Female Young Adults
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Ebony Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiaoding Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14713" title="Abstract">arXiv:2311.14713</a> (replaced) [<a href="/pdf/2311.14713" title="Download PDF">pdf</a>, <a href="/ps/2311.14713" title="Download PostScript">ps</a>, <a href="/format/2311.14713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Rise of the AI Co-Pilot: Lessons for Design from Aviation and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sellen%2C+A">Abigail Sellen</a>, 
<a href="/search/cs?searchtype=author&query=Horvitz%2C+E">Eric Horvitz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, no figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14743" title="Abstract">arXiv:2311.14743</a> (replaced) [<a href="/pdf/2311.14743" title="Download PDF">pdf</a>, <a href="/format/2311.14743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Baseline Analysis of Reward Models&#x27; Ability To Accurately Analyze  Foundation Models Under Distribution Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pikus%2C+B">Ben Pikus</a>, 
<a href="/search/cs?searchtype=author&query=LeVine%2C+W">Will LeVine</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tony Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hendryx%2C+S">Sean Hendryx</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14897" title="Abstract">arXiv:2311.14897</a> (replaced) [<a href="/pdf/2311.14897" title="Download PDF">pdf</a>, <a href="/format/2311.14897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Scalable 3D Anomaly Detection and Localization: A Benchmark via  3D Anomaly Synthesis and A Self-Supervised Learning Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenqiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaohao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Bozhong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shenghua Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yingna Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14961" title="Abstract">arXiv:2311.14961</a> (replaced) [<a href="/pdf/2311.14961" title="Download PDF">pdf</a>, <a href="/format/2311.14961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Repetition factorization of automatic sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shallit%2C+J">Jeffrey Shallit</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xinhao Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15406" title="Abstract">arXiv:2311.15406</a> (replaced) [<a href="/pdf/2311.15406" title="Download PDF">pdf</a>, <a href="/format/2311.15406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Optimize the Environmental Impact of Transformed NoSQL Schemas  through a Multidimensional Cost Model?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mali%2C+J">Jihane Mali</a>, 
<a href="/search/cs?searchtype=author&query=Atigui%2C+F">Faten Atigui</a>, 
<a href="/search/cs?searchtype=author&query=Azough%2C+A">Ahmed Azough</a>, 
<a href="/search/cs?searchtype=author&query=Travers%2C+N">Nicolas Travers</a>, 
<a href="/search/cs?searchtype=author&query=Ahvar%2C+S">Shohreh Ahvar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15556" title="Abstract">arXiv:2311.15556</a> (replaced) [<a href="/pdf/2311.15556" title="Download PDF">pdf</a>, <a href="/format/2311.15556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PKU-I2IQA: An Image-to-Image Quality Assessment Database for AI  Generated Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jiquan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xinyan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changjin Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fanyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jinlong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xixin Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15940" title="Abstract">arXiv:2311.15940</a> (replaced) [<a href="/pdf/2311.15940" title="Download PDF">pdf</a>, <a href="/format/2311.15940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-informed neural networks for transformed geometries and  manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Burbulla%2C+S">Samuel Burbulla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15994" title="Abstract">arXiv:2311.15994</a> (replaced) [<a href="/pdf/2311.15994" title="Download PDF">pdf</a>, <a href="/format/2311.15994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Doodles: Interpretable and Human-drawable Attacks Provide  Describable Insights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nara%2C+R">Ryoya Nara</a>, 
<a href="/search/cs?searchtype=author&query=Matsui%2C+Y">Yusuke Matsui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16027" title="Abstract">arXiv:2311.16027</a> (replaced) [<a href="/pdf/2311.16027" title="Download PDF">pdf</a>, <a href="/ps/2311.16027" title="Download PostScript">ps</a>, <a href="/format/2311.16027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An HCAI Methodological Framework: Putting It Into Action to Enable  Human-Centered AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zaifeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Dainoff%2C+M">Marvin Dainoff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16133" title="Abstract">arXiv:2311.16133</a> (replaced) [<a href="/pdf/2311.16133" title="Download PDF">pdf</a>, <a href="/format/2311.16133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effective Quantization for Diffusion Models on CPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">Hanwen Chang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Haihao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yiyang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xinyu Ye</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhenzhong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+W">Wenhua Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+K">Kaokao Lv</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yintong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Heng Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16153" title="Abstract">arXiv:2311.16153</a> (replaced) [<a href="/pdf/2311.16153" title="Download PDF">pdf</a>, <a href="/format/2311.16153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying and Mitigating Vulnerabilities in LLM-Integrated  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+F">Fengqing Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhangchen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+L">Luyao Niu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Boxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jinyuan Jia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Poovendran%2C+R">Radha Poovendran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16203" title="Abstract">arXiv:2311.16203</a> (replaced) [<a href="/pdf/2311.16203" title="Download PDF">pdf</a>, <a href="/format/2311.16203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatTraffic: Text-to-Traffic Generation via Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chengyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Q">Qitan Shao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Y">Yisheng Lv</a>, 
<a href="/search/cs?searchtype=author&query=Piao%2C+X">Xinglin Piao</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+B">Baocai Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16337" title="Abstract">arXiv:2311.16337</a> (replaced) [<a href="/pdf/2311.16337" title="Download PDF">pdf</a>, <a href="/ps/2311.16337" title="Download PostScript">ps</a>, <a href="/format/2311.16337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-3D-Models Registration-Based Augmented Reality (AR) Instructions  for Assembly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Canadinc%2C+S+T">Seda Tuzun Canadinc</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+W">Wei Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16444" title="Abstract">arXiv:2311.16444</a> (replaced) [<a href="/pdf/2311.16444" title="Download PDF">pdf</a>, <a href="/format/2311.16444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exo2EgoDVC: Dense Video Captioning of Egocentric Procedural Activities  Using Web Instructional Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ohkawa%2C+T">Takehiko Ohkawa</a>, 
<a href="/search/cs?searchtype=author&query=Yagi%2C+T">Takuma Yagi</a>, 
<a href="/search/cs?searchtype=author&query=Nishimura%2C+T">Taichi Nishimura</a>, 
<a href="/search/cs?searchtype=author&query=Furuta%2C+R">Ryosuke Furuta</a>, 
<a href="/search/cs?searchtype=author&query=Hashimoto%2C+A">Atsushi Hashimoto</a>, 
<a href="/search/cs?searchtype=author&query=Ushiku%2C+Y">Yoshitaka Ushiku</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+Y">Yoichi Sato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16519" title="Abstract">arXiv:2311.16519</a> (replaced) [<a href="/pdf/2311.16519" title="Download PDF">pdf</a>, <a href="/format/2311.16519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> B-LSTM-MIONet: Bayesian LSTM-based Neural Operators for Learning the  Response of Complex Dynamical Systems to Length-Variant Multiple Input  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+Z">Zhihao Kong</a>, 
<a href="/search/cs?searchtype=author&query=Mollaali%2C+A">Amirhossein Mollaali</a>, 
<a href="/search/cs?searchtype=author&query=Moya%2C+C">Christian Moya</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+N">Na Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guang Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16614" title="Abstract">arXiv:2311.16614</a> (replaced) [<a href="/pdf/2311.16614" title="Download PDF">pdf</a>, <a href="/format/2311.16614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multivariate Unimodality Test Harnenssing the Dip Statistic of  Mahalanobis Distances Over Random Projections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kolyvakis%2C+P">Prodromos Kolyvakis</a>, 
<a href="/search/stat?searchtype=author&query=Likas%2C+A">Aristidis Likas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16668" title="Abstract">arXiv:2311.16668</a> (replaced) [<a href="/pdf/2311.16668" title="Download PDF">pdf</a>, <a href="/format/2311.16668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiveNVS: Neural View Synthesis on Live RGB-D Streams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fink%2C+L">Laura Fink</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%BCckert%2C+D">Darius R&#xfc;ckert</a>, 
<a href="/search/cs?searchtype=author&query=Franke%2C+L">Linus Franke</a>, 
<a href="/search/cs?searchtype=author&query=Keinert%2C+J">Joachim Keinert</a>, 
<a href="/search/cs?searchtype=author&query=Stamminger%2C+M">Marc Stamminger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> main paper: 8 pages, total number of pages: 15, 13 figures, to be published in SIGGRAPH Asia 2023 Conference Papers; edits: link was fixed
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16680" title="Abstract">arXiv:2311.16680</a> (replaced) [<a href="/pdf/2311.16680" title="Download PDF">pdf</a>, <a href="/format/2311.16680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ROSO: Improving Robotic Policy Inference via Synthetic Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miyashita%2C+Y">Yusuke Miyashita</a>, 
<a href="/search/cs?searchtype=author&query=Gahtidis%2C+D">Dimitris Gahtidis</a>, 
<a href="/search/cs?searchtype=author&query=La%2C+C">Colin La</a>, 
<a href="/search/cs?searchtype=author&query=Rabinowicz%2C+J">Jeremy Rabinowicz</a>, 
<a href="/search/cs?searchtype=author&query=Leitner%2C+J">Jurgen Leitner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACRA 2023 Oral
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16834" title="Abstract">arXiv:2311.16834</a> (replaced) [<a href="/pdf/2311.16834" title="Download PDF">pdf</a>, <a href="/format/2311.16834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modular Neural Networks for Time Series Forecasting: Interpretability  and Feature Selection using Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+Q">Qiqi Su</a>, 
<a href="/search/cs?searchtype=author&query=Kloukinas%2C+C">Christos Kloukinas</a>, 
<a href="/search/cs?searchtype=author&query=Garcez%2C+A+d">Artur d&#x27;Avila Garcez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16835" title="Abstract">arXiv:2311.16835</a> (replaced) [<a href="/pdf/2311.16835" title="Download PDF">pdf</a>, <a href="/format/2311.16835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified-modal Salient Object Detection via Adaptive Prompt Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kunpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenglong Li</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhengzheng Tu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bin Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16854" title="Abstract">arXiv:2311.16854</a> (replaced) [<a href="/pdf/2311.16854" title="Download PDF">pdf</a>, <a href="/format/2311.16854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Approach for Text- and Image-guided 4D Scene Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yufeng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xueting Li</a>, 
<a href="/search/cs?searchtype=author&query=Nagano%2C+K">Koki Nagano</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sifei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kreis%2C+K">Karsten Kreis</a>, 
<a href="/search/cs?searchtype=author&query=Hilliges%2C+O">Otmar Hilliges</a>, 
<a href="/search/cs?searchtype=author&query=De+Mello%2C+S">Shalini De Mello</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://research.nvidia.com/labs/nxp/dream-in-4d/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16883" title="Abstract">arXiv:2311.16883</a> (replaced) [<a href="/pdf/2311.16883" title="Download PDF">pdf</a>, <a href="/format/2311.16883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compressing the Backward Pass of Large-Scale Neural Architectures by  Structured Activation Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barley%2C+D">Daniel Barley</a>, 
<a href="/search/cs?searchtype=author&query=Fr%C3%B6ning%2C+H">Holger Fr&#xf6;ning</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 11 figures, submitted to the 6th AccML workshop at HiPEAC conference 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16953" title="Abstract">arXiv:2311.16953</a> (replaced) [<a href="/pdf/2311.16953" title="Download PDF">pdf</a>, <a href="/format/2311.16953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local certification of geometric graph classes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Defrain%2C+O">Oscar Defrain</a>, 
<a href="/search/cs?searchtype=author&query=Esperet%2C+L">Louis Esperet</a>, 
<a href="/search/cs?searchtype=author&query=Lagoutte%2C+A">Aur&#xe9;lie Lagoutte</a>, 
<a href="/search/cs?searchtype=author&query=Morin%2C+P">Pat Morin</a>, 
<a href="/search/cs?searchtype=author&query=Raymond%2C+J">Jean-Florent Raymond</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 16 figures; v2: new reference added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16989" title="Abstract">arXiv:2311.16989</a> (replaced) [<a href="/pdf/2311.16989" title="Download PDF">pdf</a>, <a href="/format/2311.16989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT&#x27;s One-year Anniversary: Are Open-Source Large Language Models  Catching up?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hailin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+F">Fangkai Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+C">Chengwei Qin</a>, 
<a href="/search/cs?searchtype=author&query=Ravaut%2C+M">Mathieu Ravaut</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Ruochen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Caiming Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Joty%2C+S">Shafiq Joty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> version v2, applied several minor changes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17041" title="Abstract">arXiv:2311.17041</a> (replaced) [<a href="/pdf/2311.17041" title="Download PDF">pdf</a>, <a href="/format/2311.17041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient In-Context Learning in Vision-Language Models for Egocentric  Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+K+P">Keunwoo Peter Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+F">Fengyuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+J">Joyce Chai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, LaTeX; added acknowledgments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item358">Cross-lists</a></li>
<li><a href="#item398">Replacements</a></li>
</ul>
<small>[ total of 617 entries:  <b>1-617</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2311">2311</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
