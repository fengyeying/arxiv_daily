<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Wed 26 Jul 23  to  Thu 27 Jul 23, announced Fri, 28 Jul 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item274">Cross-lists</a></li>
<li><a href="#item322">Replacements</a></li>
</ul>
<small>[ total of 490 entries:  <b>1-490</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Fri, 28 Jul 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14343" title="Abstract">arXiv:2307.14343</a> [<a href="/pdf/2307.14343" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pruning Distorted Images in MNIST Handwritten Digits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=R%2C+A">Amarnath R</a>, 
<a href="/search/cs?searchtype=author&query=V%2C+V+K">Vinay Kumar V</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 10 figures, 14 tables, 54 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recognizing handwritten digits is a challenging task primarily due to the
diversity of writing styles and the presence of noisy images. The widely used
MNIST dataset, which is commonly employed as a benchmark for this task,
includes distorted digits with irregular shapes, incomplete strokes, and
varying skew in both the training and testing datasets. Consequently, these
factors contribute to reduced accuracy in digit recognition. To overcome this
challenge, we propose a two-stage deep learning approach. In the first stage,
we create a simple neural network to identify distorted digits within the
training set. This model serves to detect and filter out such distorted and
ambiguous images. In the second stage, we exclude these identified images from
the training dataset and proceed to retrain the model using the filtered
dataset. This process aims to improve the classification accuracy and
confidence levels while mitigating issues of underfitting and overfitting. Our
experimental results demonstrate the effectiveness of the proposed approach,
achieving an accuracy rate of over 99.5% on the testing dataset. This
significant improvement showcases the potential of our method in enhancing
digit classification accuracy. In our future work, we intend to explore the
scalability of this approach and investigate techniques to further enhance
accuracy by reducing the size of the training data.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14345" title="Abstract">arXiv:2307.14345</a> [<a href="/pdf/2307.14345" title="Download PDF">pdf</a>, <a href="/format/2307.14345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NOMA for STAR-RIS Assisted UAV Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+J">Jiayi Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tiankui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+X">Xidong Mu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanwei Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Emerging Technologies (cs.ET); Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper proposes a novel simultaneously transmitting and reflecting
reconfigurable intelligent surface (STAR-RIS) assisted unmanned aerial vehicle
(UAV) non-orthogonal multiple access (NOMA) emergency communication network.
Multiple STAR-RISs are deployed to provide additional and intelligent
transmission links between trapped users and UAV-mounted base station (BS).
Each user selects the nearest STAR-RIS for uploading data, and NOMA is employed
for users located at the same side of the same STAR-RIS. Considering piratical
requirements of post-disaster emergency communications, we formulate a
throughput maximization problem subject to constraints on minimum average rate
and maximum energy consumption, where the UAV trajectory, STAR-RIS passive
beamforming, and time and power allocation are jointly optimized. Furthermore,
we propose a Lagrange based reward constrained proximal policy optimization
(LRCPPO) algorithm, which provides an adaptive method for solving the long-term
optimization problem with cumulative constraints. Specifically, using Lagrange
relaxation, the original problem is transformed into an unconstrained problem
with a two-layer structure. The inner layer is solved by penalized reward based
proximal policy optimization (PPO) algorithm. In the outer layer, Lagrange
multipliers are updated by gradient descent. Numerical results show the
proposed algorithm can effectively improve network performance while satisfying
the constraints well. It also demonstrates the superiority of the proposed
STAR-RIS assisted UAV NOMA network architecture over the benchmark schemes
employing reflecting-only RISs and orthogonal multiple access.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14346" title="Abstract">arXiv:2307.14346</a> [<a href="/pdf/2307.14346" title="Download PDF">pdf</a>, <a href="/format/2307.14346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-objective Deep Reinforcement Learning for Mobile Edge Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+N">Ning Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Junrui Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Meng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+M">Ming Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Received by IEEE WiOpt 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Mobile edge computing (MEC) is essential for next-generation mobile network
applications that prioritize various performance metrics, including delays and
energy consumption. However, conventional single-objective scheduling solutions
cannot be directly applied to practical systems in which the preferences of
these applications (i.e., the weights of different objectives) are often
unknown or challenging to specify in advance. In this study, we address this
issue by formulating a multi-objective offloading problem for MEC with multiple
edges to minimize expected long-term energy consumption and transmission delay
while considering unknown preferences as parameters. To address the challenge
of unknown preferences, we design a multi-objective (deep) reinforcement
learning (MORL)-based resource scheduling scheme with proximal policy
optimization (PPO). In addition, we introduce a well-designed state encoding
method for constructing features for multiple edges in MEC systems, a
sophisticated reward function for accurately computing the utilities of delay
and energy consumption. Simulation results demonstrate that our proposed MORL
scheme enhances the hypervolume of the Pareto front by up to 233.1% compared to
benchmarks. Our full framework is available at
https://github.com/gracefulning/mec_morl_multipolicy.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14348" title="Abstract">arXiv:2307.14348</a> [<a href="/pdf/2307.14348" title="Download PDF">pdf</a>, <a href="/format/2307.14348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving the inverse potential problem in the parabolic equation by the  deep neural networks method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+M">Mengmeng Zhang</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Z">Zhidong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph)

</div>
<p class="mathjax">In this work, we consider an inverse potential problem in the parabolic
equation, where the unknown potential is a space-dependent function and the
used measurement is the final time data. The unknown potential in this inverse
problem is parameterized by deep neural networks (DNNs) for the reconstruction
scheme. First, the uniqueness of the inverse problem is proved under some
regularities assumption on the input sources. Then we propose a new loss
function with regularization terms depending on the derivatives of the
residuals for partial differential equations (PDEs) and the measurements. These
extra terms effectively induce higher regularity in solutions so that the
ill-posedness of the inverse problem can be handled. Moreover, we establish the
corresponding generalization error estimates rigorously. Our proofs exploit the
conditional stability of the classical linear inverse source problems, and the
mollification on the noisy measurement data which is set to reduce the
perturbation errors. Finally, the numerical algorithm and some numerical
results are provided.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14349" title="Abstract">arXiv:2307.14349</a> [<a href="/pdf/2307.14349" title="Download PDF">pdf</a>, <a href="/format/2307.14349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Copilot for Xcode: Exploring AI-Assisted Programming by Prompting  Cloud-based Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+C+W">Chee Wei Tan</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Shangxin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+M+F">Man Fai Wong</a>, 
<a href="/search/cs?searchtype=author&query=Hang%2C+C+N">Ching Nam Hang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents an AI-assisted programming tool called Copilot for Xcode
for program composition and design to support human software developers. By
seamlessly integrating cloud-based Large Language Models (LLM) with Apple's
local development environment, Xcode, this tool enhances productivity and
unleashes creativity for software development in Apple software ecosystem
(e.g., iOS apps, macOS). Leveraging advanced natural language processing (NLP)
techniques, Copilot for Xcode effectively processes source code tokens and
patterns within code repositories, enabling features such as code generation,
autocompletion, documentation, and error detection. Software developers can
also query and make "small" decisions for program composition, some of which
can be made simultaneously, and this is facilitated through prompt engineering
in a chat interface of Copilot for Xcode. Finally, we present simple case
studies as evidence of the effectiveness of utilizing NLP in Xcode to prompt
popular LLM services like OpenAI ChatGPT for program composition and design.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14352" title="Abstract">arXiv:2307.14352</a> [<a href="/pdf/2307.14352" title="Download PDF">pdf</a>, <a href="/format/2307.14352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> General Image-to-Image Translation with One-Shot Image Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+B">Bin Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zuhao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yunbo Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yue Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large-scale text-to-image models pre-trained on massive text-image pairs show
excellent performance in image synthesis recently. However, image can provide
more intuitive visual concepts than plain text. People may ask: how can we
integrate the desired visual concept into an existing image, such as our
portrait? Current methods are inadequate in meeting this demand as they lack
the ability to preserve content or translate visual concepts effectively.
Inspired by this, we propose a novel framework named visual concept translator
(VCT) with the ability to preserve content in the source image and translate
the visual concepts guided by a single reference image. The proposed VCT
contains a content-concept inversion (CCI) process to extract contents and
concepts, and a content-concept fusion (CCF) process to gather the extracted
information to obtain the target image. Given only one reference image, the
proposed VCT can complete a wide range of general image-to-image translation
tasks with excellent results. Extensive experiments are conducted to prove the
superiority and effectiveness of the proposed methods. Codes are available at
https://github.com/CrystalNeuro/visual-concept-translator.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14354" title="Abstract">arXiv:2307.14354</a> [<a href="/pdf/2307.14354" title="Download PDF">pdf</a>, <a href="/format/2307.14354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learned Gridification for Efficient Point Cloud Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+der+Linden%2C+P+A">Putri A. van der Linden</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+D+W">David W. Romero</a>, 
<a href="/search/cs?searchtype=author&query=Bekkers%2C+E+J">Erik J. Bekkers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Neural operations that rely on neighborhood information are much more
expensive when deployed on point clouds than on grid data due to the irregular
distances between points in a point cloud. In a grid, on the other hand, we can
compute the kernel only once and reuse it for all query positions. As a result,
operations that rely on neighborhood information scale much worse for point
clouds than for grid data, specially for large inputs and large neighborhoods.
<br />In this work, we address the scalability issue of point cloud methods by
tackling its root cause: the irregularity of the data. We propose learnable
gridification as the first step in a point cloud processing pipeline to
transform the point cloud into a compact, regular grid. Thanks to
gridification, subsequent layers can use operations defined on regular grids,
e.g., Conv3D, which scale much better than native point cloud methods. We then
extend gridification to point cloud to point cloud tasks, e.g., segmentation,
by adding a learnable de-gridification step at the end of the point cloud
processing pipeline to map the compact, regular grid back to its original point
cloud form. Through theoretical and empirical analysis, we show that gridified
networks scale better in terms of memory and time than networks directly
applied on raw point cloud data, while being able to achieve competitive
results. Our code is publicly available at
https://github.com/computri/gridifier.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14355" title="Abstract">arXiv:2307.14355</a> [<a href="/pdf/2307.14355" title="Download PDF">pdf</a>, <a href="/format/2307.14355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Framing Relevance for Safety-Critical Autonomous Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rakow%2C+A">Astrid Rakow</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2209.14038">arXiv:2209.14038</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">We are in the process of building complex highly autonomous systems that have
build-in beliefs, perceive their environment and exchange information. These
systems construct their respective world view and based on it they plan their
future manoeuvres, i.e., they choose their actions in order to establish their
goals based on their prediction of the possible futures. Usually these systems
face an overwhelming flood of information provided by a variety of sources
where by far not everything is relevant. The goal of our work is to develop a
formal approach to determine what is relevant for a safety critical autonomous
system at its current mission, i.e., what information suffices to build an
appropriate world view to accomplish its mission goals.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14357" title="Abstract">arXiv:2307.14357</a> [<a href="/pdf/2307.14357" title="Download PDF">pdf</a>, <a href="/ps/2307.14357" title="Download PostScript">ps</a>, <a href="/format/2307.14357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Boolean reliability algebra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bori%C4%8Di%C4%87%2C+B">Branislav Bori&#x10d;i&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Ili%C4%87%2C+M">Mirjana Ili&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Stanojevi%C4%87%2C+J">Jelena Stanojevi&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Logic (math.LO); Probability (math.PR)

</div>
<p class="mathjax">In this paper we consider systems which consist of binary components with
known reliabilities. We discuss their algebraic properties and define the
corresponding algebraic structure, which we call the reliability algebra. We
prove that the reliability algebra is a Boolean algebra. The reliability
algebra seems an appropriate context for defining fuzziness measure i.e.
membership function with reliability values.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14366" title="Abstract">arXiv:2307.14366</a> [<a href="/pdf/2307.14366" title="Download PDF">pdf</a>, <a href="/format/2307.14366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Disparity Compensation for Efficient Fair Ranking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gale%2C+A">Abraham Gale</a>, 
<a href="/search/cs?searchtype=author&query=Marian%2C+A">Am&#xc9;lie Marian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Databases (cs.DB)

</div>
<p class="mathjax">Ranking functions that are used in decision systems often produce disparate
results for different populations because of bias in the underlying data.
Addressing, and compensating for, these disparate outcomes is a critical
problem for fair decision-making. Recent compensatory measures have mostly
focused on opaque transformations of the ranking functions to satisfy fairness
guarantees or on the use of quotas or set-asides to guarantee a minimum number
of positive outcomes to members of underrepresented groups. In this paper we
propose easily explainable data-driven compensatory measures for ranking
functions. Our measures rely on the generation of bonus points given to members
of underrepresented groups to address disparity in the ranking function. The
bonus points can be set in advance, and can be combined, allowing for
considering the intersections of representations and giving better transparency
to stakeholders. We propose efficient sampling-based algorithms to calculate
the number of bonus points to minimize disparity. We validate our algorithms
using real-world school admissions and recidivism datasets, and compare our
results with that of existing fair ranking algorithms.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14368" title="Abstract">arXiv:2307.14368</a> [<a href="/pdf/2307.14368" title="Download PDF">pdf</a>, <a href="/format/2307.14368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthesis of Procedural Models for Deterministic Transition Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Segovia-Aguas%2C+J">Javier Segovia-Aguas</a>, 
<a href="/search/cs?searchtype=author&query=Ferrer-Mestres%2C+J">Jonathan Ferrer-Mestres</a>, 
<a href="/search/cs?searchtype=author&query=Jim%C3%A9nez%2C+S">Sergio Jim&#xe9;nez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference paper accepted at ECAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper introduces a general approach for synthesizing procedural models
of the state-transitions of a given discrete system. The approach is general in
that it accepts different target languages for modeling the state-transitions
of a discrete system; different model acquisition tasks with different target
languages, such as the synthesis of STRIPS action models, or the update rule of
a cellular automaton, fit as particular instances of our general approach. We
follow an inductive approach to synthesis meaning that a set of examples of
state-transitions, represented as (pre-state, action, post-state) tuples, are
given as input. The goal is to synthesize a structured program that, when
executed on a given pre-state, outputs its associated post-state. Our synthesis
method implements a combinatorial search in the space of well-structured
terminating programs that can be built using a Random-Access Machine (RAM),
with a minimalist instruction set, and a finite amount of memory. The
combinatorial search is guided with functions that asses the complexity of the
candidate programs, as well as their fitness to the given input set of
examples.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14371" title="Abstract">arXiv:2307.14371</a> [<a href="/pdf/2307.14371" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prediction of depression status in college students using a Naive Bayes  classifier based machine learning model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cruz%2C+F+T">Fred Torres Cruz</a>, 
<a href="/search/cs?searchtype=author&query=Flores%2C+E+E+C">Evelyn Eliana Coaquira Flores</a>, 
<a href="/search/cs?searchtype=author&query=Quispe%2C+S+J+C">Sebastian Jarom Condori Quispe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP)

</div>
<p class="mathjax">This study presents a machine learning model based on the Naive Bayes
classifier for predicting the level of depression in university students, the
objective was to improve prediction accuracy using a machine learning model
involving 70% training data and 30% validation data based on the Naive Bayes
classifier, the collected data includes factors associated with depression from
519 university students, the results showed an accuracy of 78.03%, high
sensitivity in detecting positive cases of depression, especially at moderate
and severe levels, and significant specificity in correctly classifying
negative cases, these findings highlight the effectiveness of the model in
early detection and treatment of depression, benefiting vulnerable sectors and
contributing to the improvement of mental health in the student population.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14373" title="Abstract">arXiv:2307.14373</a> [<a href="/pdf/2307.14373" title="Download PDF">pdf</a>, <a href="/ps/2307.14373" title="Download PostScript">ps</a>, <a href="/format/2307.14373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Piecewise Linear Functions Representable with Infinite Width Shallow  ReLU Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McCarty%2C+S">Sarah McCarty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Functional Analysis (math.FA)

</div>
<p class="mathjax">This paper analyzes representations of continuous piecewise linear functions
with infinite width, finite cost shallow neural networks using the rectified
linear unit (ReLU) as an activation function. Through its integral
representation, a shallow neural network can be identified by the corresponding
signed, finite measure on an appropriate parameter space. We map these measures
on the parameter space to measures on the projective $n$-sphere cross
$\mathbb{R}$, allowing points in the parameter space to be bijectively mapped
to hyperplanes in the domain of the function. We prove a conjecture of Ongie et
al. that every continuous piecewise linear function expressible with this kind
of infinite width neural network is expressible as a finite width shallow ReLU
neural network.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14374" title="Abstract">arXiv:2307.14374</a> [<a href="/pdf/2307.14374" title="Download PDF">pdf</a>, <a href="/format/2307.14374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forecasting, capturing and activation of carbon-dioxide (CO$_2$):  Integration of Time Series Analysis, Machine Learning, and Material Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sadhukhan%2C+S">Suchetana Sadhukhan</a>, 
<a href="/search/cs?searchtype=author&query=Yadav%2C+V+K">Vivek Kumar Yadav</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This study provides a comprehensive time series analysis of daily
industry-specific, country-wise CO$_2$ emissions from January 2019 to February
2023. The research focuses on the Power, Industry, Ground Transport, Domestic
Aviation, and International Aviation sectors in European countries (EU27 &amp; UK,
Italy, Germany, Spain) and India, utilizing near-real-time activity data from
the Carbon Monitor research initiative. To identify regular emission patterns,
the data from the year 2020 is excluded due to the disruptive effects caused by
the COVID-19 pandemic. The study then performs a principal component analysis
(PCA) to determine the key contributors to CO$_2$ emissions. The analysis
reveals that the Power, Industry, and Ground Transport sectors account for a
significant portion of the variance in the dataset. A 7-day moving averaged
dataset is employed for further analysis to facilitate robust predictions. This
dataset captures both short-term and long-term trends and enhances the quality
of the data for prediction purposes. The study utilizes Long Short-Term Memory
(LSTM) models on the 7-day moving averaged dataset to effectively predict
emissions and provide insights for policy decisions, mitigation strategies, and
climate change efforts. During the training phase, the stability and
convergence of the LSTM models are ensured, which guarantees their reliability
in the testing phase. The evaluation of the loss function indicates this
reliability. The model achieves high efficiency, as demonstrated by $R^2$
values ranging from 0.8242 to 0.995 for various countries and sectors.
Furthermore, there is a proposal for utilizing scandium and
boron/aluminium-based thin films as exceptionally efficient materials for
capturing CO$_2$ (with a binding energy range from -3.0 to -3.5 eV). These
materials are shown to surpass the affinity of graphene and boron nitride
sheets in this regard.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14375" title="Abstract">arXiv:2307.14375</a> [<a href="/pdf/2307.14375" title="Download PDF">pdf</a>, <a href="/format/2307.14375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DBGSA: A Novel Data Adaptive Bregman Clustering Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Ying Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hou-biao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu-pu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">With the development of Big data technology, data analysis has become
increasingly important. Traditional clustering algorithms such as K-means are
highly sensitive to the initial centroid selection and perform poorly on
non-convex datasets. In this paper, we address these problems by proposing a
data-driven Bregman divergence parameter optimization clustering algorithm
(DBGSA), which combines the Universal Gravitational Algorithm to bring similar
points closer in the dataset. We construct a gravitational coefficient equation
with a special property that gradually reduces the influence factor as the
iteration progresses. Furthermore, we introduce the Bregman divergence
generalized power mean information loss minimization to identify cluster
centers and build a hyperparameter identification optimization model, which
effectively solves the problems of manual adjustment and uncertainty in the
improved dataset. Extensive experiments are conducted on four simulated
datasets and six real datasets. The results demonstrate that DBGSA
significantly improves the accuracy of various clustering algorithms by an
average of 63.8\% compared to other similar approaches like enhanced clustering
algorithms and improved datasets. Additionally, a three-dimensional grid search
was established to compare the effects of different parameter values within
threshold conditions, and it was discovered the parameter set provided by our
model is optimal. This finding provides strong evidence of the high accuracy
and robustness of the algorithm.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14377" title="Abstract">arXiv:2307.14377</a> [<a href="/pdf/2307.14377" title="Download PDF">pdf</a>, <a href="/format/2307.14377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Can Large Language Models Help Humans in Design and Manufacturing?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Makatura%2C+L">Liane Makatura</a>, 
<a href="/search/cs?searchtype=author&query=Foshey%2C+M">Michael Foshey</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bohan Wang</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%A4hnLein%2C+F">Felix H&#xe4;hnLein</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+P">Pingchuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+B">Bolei Deng</a>, 
<a href="/search/cs?searchtype=author&query=Tjandrasuwita%2C+M">Megan Tjandrasuwita</a>, 
<a href="/search/cs?searchtype=author&query=Spielberg%2C+A">Andrew Spielberg</a>, 
<a href="/search/cs?searchtype=author&query=Owens%2C+C+E">Crystal Elaine Owens</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P+Y">Peter Yichen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+A">Allan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+A">Amy Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Norton%2C+W+J">Wil J Norton</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+E">Edward Gu</a>, 
<a href="/search/cs?searchtype=author&query=Jacob%2C+J">Joshua Jacob</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yifei Li</a>, 
<a href="/search/cs?searchtype=author&query=Schulz%2C+A">Adriana Schulz</a>, 
<a href="/search/cs?searchtype=author&query=Matusik%2C+W">Wojciech Matusik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The advancement of Large Language Models (LLMs), including GPT-4, provides
exciting new opportunities for generative design. We investigate the
application of this tool across the entire design and manufacturing workflow.
Specifically, we scrutinize the utility of LLMs in tasks such as: converting a
text-based prompt into a design specification, transforming a design into
manufacturing instructions, producing a design space and design variations,
computing the performance of a design, and searching for designs predicated on
performance. Through a series of examples, we highlight both the benefits and
the limitations of the current LLMs. By exposing these limitations, we aspire
to catalyze the continued improvement and progression of these models.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14380" title="Abstract">arXiv:2307.14380</a> [<a href="/pdf/2307.14380" title="Download PDF">pdf</a>, <a href="/format/2307.14380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Assignment of Labels for Active Learning with Sparse and Noisy  Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ka%C5%82u%C5%BCa%2C+D">Daniel Ka&#x142;u&#x17c;a</a>, 
<a href="/search/cs?searchtype=author&query=Janusz%2C+A">Andrzej Janusz</a>, 
<a href="/search/cs?searchtype=author&query=%C5%9Al%C4%99zak%2C+D">Dominik &#x15a;l&#x119;zak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures, 4 tables Extended version of paper accepted for 26th European Conference on Artificial Intelligence ECAI 2023 with appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Supervised classification algorithms are used to solve a growing number of
real-life problems around the globe. Their performance is strictly connected
with the quality of labels used in training. Unfortunately, acquiring
good-quality annotations for many tasks is infeasible or too expensive to be
done in practice. To tackle this challenge, active learning algorithms are
commonly employed to select only the most relevant data for labeling. However,
this is possible only when the quality and quantity of labels acquired from
experts are sufficient. Unfortunately, in many applications, a trade-off
between annotating individual samples by multiple annotators to increase label
quality vs. annotating new samples to increase the total number of labeled
instances is necessary. In this paper, we address the issue of faulty data
annotations in the context of active learning. In particular, we propose two
novel annotation unification algorithms that utilize unlabeled parts of the
sample space. The proposed methods require little to no intersection between
samples annotated by different experts. Our experiments on four public datasets
indicate the robustness and superiority of the proposed methods in both, the
estimation of the annotator's reliability, and the assignment of actual labels,
against the state-of-the-art algorithms and the simple majority voting.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14381" title="Abstract">arXiv:2307.14381</a> [<a href="/pdf/2307.14381" title="Download PDF">pdf</a>, <a href="/format/2307.14381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EdgeConvEns: Convolutional Ensemble Learning for Edge Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sikdokur%2C+I">Ilkay Sikdokur</a>, 
<a href="/search/cs?searchtype=author&query=Bayta%C5%9F%2C+%C4%B0+M">&#x130;nci M. Bayta&#x15f;</a>, 
<a href="/search/cs?searchtype=author&query=Yurdakul%2C+A">Arda Yurdakul</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Deep edge intelligence aims to deploy deep learning models that demand
computationally expensive training in the edge network with limited
computational power. Moreover, many deep edge intelligence applications require
handling distributed data that cannot be transferred to a central server due to
privacy concerns. Decentralized learning methods, such as federated learning,
offer solutions where models are learned collectively by exchanging learned
weights. However, they often require complex models that edge devices may not
handle and multiple rounds of network communication to achieve state-of-the-art
performances. This study proposes a convolutional ensemble learning approach,
coined EdgeConvEns, that facilitates training heterogeneous weak models on edge
and learning to ensemble them where data on edge are heterogeneously
distributed. Edge models are implemented and trained independently on
Field-Programmable Gate Array (FPGA) devices with various computational
capacities. Learned data representations are transferred to a central server
where the ensemble model is trained with the learned features received from the
edge devices to boost the overall prediction performance. Extensive experiments
demonstrate that the EdgeConvEns can outperform the state-of-the-art
performance with fewer communications and less data in various training
scenarios.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14382" title="Abstract">arXiv:2307.14382</a> [<a href="/pdf/2307.14382" title="Download PDF">pdf</a>, <a href="/format/2307.14382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Multi-Task Learning Meets Partial Supervision: A Computer Vision  Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fontana%2C+M">Maxime Fontana</a>, 
<a href="/search/cs?searchtype=author&query=Spratling%2C+M">Michael Spratling</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+M">Miaojing Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 4 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Multi-Task Learning (MTL) aims to learn multiple tasks simultaneously while
exploiting their mutual relationships. By using shared resources to
simultaneously calculate multiple outputs, this learning paradigm has the
potential to have lower memory requirements and inference times compared to the
traditional approach of using separate methods for each task. Previous work in
MTL has mainly focused on fully-supervised methods, as task relationships can
not only be leveraged to lower the level of data-dependency of those methods
but they can also improve performance. However, MTL introduces a set of
challenges due to a complex optimisation scheme and a higher labeling
requirement. This review focuses on how MTL could be utilised under different
partial supervision settings to address these challenges. First, this review
analyses how MTL traditionally uses different parameter sharing techniques to
transfer knowledge in between tasks. Second, it presents the different
challenges arising from such a multi-objective optimisation scheme. Third, it
introduces how task groupings can be achieved by analysing task relationships.
Fourth, it focuses on how partially supervised methods applied to MTL can
tackle the aforementioned challenges. Lastly, this review presents the
available datasets, tools and benchmarking results of such methods.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14383" title="Abstract">arXiv:2307.14383</a> [<a href="/pdf/2307.14383" title="Download PDF">pdf</a>, <a href="/format/2307.14383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Large-Scale Feasibility Study of Screen-based 3D Visualization and  Augmented Reality Tools for Human Anatomy Education: Exploring Gender  Perspectives in Learning Experience
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barmaki%2C+R+L">Roghayeh Leila Barmaki</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kangsoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qile Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kevin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Pearlman%2C+R">Rebecca Pearlman</a>, 
<a href="/search/cs?searchtype=author&query=Navab%2C+N">Nassir Navab</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">While anatomy learning is an essential part of medical education, there
remain significant challenges in traditional learning methods, In this paper,
we introduce two in-house anatomy training solutions that can visualize and
superimpose 3D virtual anatomy models with informative labels using a hand-held
tablet or a wide-screen AR. To investigate the feasibility and effectiveness of
the proposed tablet-based 3D visualization and AR tools, we conducted a
large-scale study with 236 students enrolled in undergraduate premedical
programs (95 M, 141F in 118 dyadic teams). In this study, participant students
were split into three groups to use one of the following learning tools in a
team-based anatomy painting activity: (1) conventional textbook, (2) hand-held
tablet-based 3D visualization, and (3) screen-based AR. The results showed that
students who used the tablet-based visualization tool or the AR learning tool
reported significantly higher (more positive) learning experience scores than
those who used a textbook. Though we did not observe a significant difference
in knowledge retention among the three learning tools, our further analysis of
gender effects revealed that male participants generally reported more positive
learning experience scores than female participants. Also, the overall
experience of mixed-gender dyads was reported to be significantly lower than
others in most of the learning experience and performance measures. While
discussing the implications of our results in the context of anatomy and
medical education, we highlight the potential of our learning tools with
additional considerations related to gender and team dynamics in body painting
anatomy learning interventions.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14384" title="Abstract">arXiv:2307.14384</a> [<a href="/pdf/2307.14384" title="Download PDF">pdf</a>, <a href="/format/2307.14384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperFed: Hyperbolic Prototypes Exploration with Consistent Aggregation  for Non-IID Data in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+X">Xinting Liao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaochao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pengyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Huabin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yanchao Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yue Qi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IJCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Federated learning (FL) collaboratively models user data in a decentralized
way. However, in the real world, non-identical and independent data
distributions (non-IID) among clients hinder the performance of FL due to three
issues, i.e., (1) the class statistics shifting, (2) the insufficient
hierarchical information utilization, and (3) the inconsistency in aggregating
clients. To address the above issues, we propose HyperFed which contains three
main modules, i.e., hyperbolic prototype Tammes initialization (HPTI),
hyperbolic prototype learning (HPL), and consistent aggregation (CA). Firstly,
HPTI in the server constructs uniformly distributed and fixed class prototypes,
and shares them with clients to match class statistics, further guiding
consistent feature representation for local clients. Secondly, HPL in each
client captures the hierarchical information in local data with the supervision
of shared class prototypes in the hyperbolic model space. Additionally, CA in
the server mitigates the impact of the inconsistent deviations from clients to
server. Extensive studies of four datasets prove that HyperFed is effective in
enhancing the performance of FL under the non-IID set.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14385" title="Abstract">arXiv:2307.14385</a> [<a href="/pdf/2307.14385" title="Download PDF">pdf</a>, <a href="/format/2307.14385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Large Language Models for Mental Health Prediction via Online  Text Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xuhai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+B">Bingshen Yao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuanzhe Dong</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Hendler%2C+J">James Hendler</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+A+K">Anind K. Dey</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dakuo Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The recent technology boost of large language models (LLMs) has empowered a
variety of applications. However, there is very little research on
understanding and improving LLMs' capability for the mental health domain. In
this work, we present the first comprehensive evaluation of multiple LLMs,
including Alpaca, Alpaca-LoRA, and GPT-3.5, on various mental health prediction
tasks via online text data. We conduct a wide range of experiments, covering
zero-shot prompting, few-shot prompting, and instruction finetuning. The
results indicate the promising yet limited performance of LLMs with zero-shot
and few-shot prompt designs for mental health tasks. More importantly, our
experiments show that instruction finetuning can significantly boost the
performance of LLMs for all tasks simultaneously. Our best-finetuned model,
Mental-Alpaca, outperforms GPT-3.5 (25 times bigger) by 16.7\% on balanced
accuracy and performs on par with the state-of-the-art task-specific model. We
summarize our findings into a set of action guidelines for future researchers,
engineers, and practitioners on how to empower LLMs with better mental health
domain knowledge and become an expert in mental health prediction tasks.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14387" title="Abstract">arXiv:2307.14387</a> [<a href="/pdf/2307.14387" title="Download PDF">pdf</a>, <a href="/format/2307.14387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-Space Attacks against Random-Walk-based Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+Y">Yuni Lai</a>, 
<a href="/search/cs?searchtype=author&query=Waniek%2C+M">Marcin Waniek</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yulin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liying Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jingwen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Michalak%2C+T+P">Tomasz P. Michalak</a>, 
<a href="/search/cs?searchtype=author&query=Rahwan%2C+T">Talal Rahwan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kai Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Random Walks-based Anomaly Detection (RWAD) is commonly used to identify
anomalous patterns in various applications. An intriguing characteristic of
RWAD is that the input graph can either be pre-existing or constructed from raw
features. Consequently, there are two potential attack surfaces against RWAD:
graph-space attacks and feature-space attacks. In this paper, we explore this
vulnerability by designing practical dual-space attacks, investigating the
interplay between graph-space and feature-space attacks. To this end, we
conduct a thorough complexity analysis, proving that attacking RWAD is NP-hard.
Then, we proceed to formulate the graph-space attack as a bi-level optimization
problem and propose two strategies to solve it: alternative iteration
(alterI-attack) or utilizing the closed-form solution of the random walk model
(cf-attack). Finally, we utilize the results from the graph-space attacks as
guidance to design more powerful feature-space attacks (i.e., graph-guided
attacks). Comprehensive experiments demonstrate that our proposed attacks are
effective in enabling the target nodes from RWAD with a limited attack budget.
In addition, we conduct transfer attack experiments in a black-box setting,
which show that our feature attack significantly decreases the anomaly scores
of target nodes. Our study opens the door to studying the dual-space attack
against graph anomaly detection in which the graph space relies on the feature
space.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14388" title="Abstract">arXiv:2307.14388</a> [<a href="/pdf/2307.14388" title="Download PDF">pdf</a>, <a href="/format/2307.14388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Context-aware Data Release with Sequence Information Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>, 
<a href="/search/cs?searchtype=author&query=Tandon%2C+R">Ravi Tandon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Publishing streaming data in a privacy-preserving manner has been a key
research focus for many years. This issue presents considerable challenges,
particularly due to the correlations prevalent within the data stream. Existing
approaches either fall short in effectively leveraging these correlations,
leading to a suboptimal utility-privacy tradeoff, or they involve complex
mechanism designs that increase the computation complexity with respect to the
sequence length. In this paper, we introduce Sequence Information Privacy
(SIP), a new privacy notion designed to guarantee privacy for an entire data
stream, taking into account the intrinsic data correlations. We show that SIP
provides a similar level of privacy guarantee compared to local differential
privacy (LDP), and it also enjoys a lightweight modular mechanism design. We
further study two online data release models (instantaneous or batched) and
propose corresponding privacy-preserving data perturbation mechanisms. We
provide a numerical evaluation of how correlations influence noise addition in
data streams. Lastly, we conduct experiments using real-world data to compare
the utility-privacy tradeoff offered by our approaches with those from existing
literature. The results reveal that our mechanisms offer utility improvements
more than twice those based on LDP-based mechanisms.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14392" title="Abstract">arXiv:2307.14392</a> [<a href="/pdf/2307.14392" title="Download PDF">pdf</a>, <a href="/format/2307.14392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-centric Scene Understanding for 3D Large-scale Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yiteng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cong%2C+P">Peishan Cong</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yichen Yao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Runnan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yuenan Hou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xinge Zhu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xuming He</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jingyi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yuexin Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human-centric scene understanding is significant for real-world applications,
but it is extremely challenging due to the existence of diverse human poses and
actions, complex human-environment interactions, severe occlusions in crowds,
etc. In this paper, we present a large-scale multi-modal dataset for
human-centric scene understanding, dubbed HuCenLife, which is collected in
diverse daily-life scenarios with rich and fine-grained annotations. Our
HuCenLife can benefit many 3D perception tasks, such as segmentation,
detection, action recognition, etc., and we also provide benchmarks for these
tasks to facilitate related research. In addition, we design novel modules for
LiDAR-based segmentation and action recognition, which are more applicable for
large-scale human-centric scenarios and achieve state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14394" title="Abstract">arXiv:2307.14394</a> [<a href="/pdf/2307.14394" title="Download PDF">pdf</a>, <a href="/format/2307.14394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypergraph Isomorphism Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yifan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jiashu Han</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+S">Shihui Ying</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yue Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The isomorphism problem is a fundamental problem in network analysis, which
involves capturing both low-order and high-order structural information. In
terms of extracting low-order structural information, graph isomorphism
algorithms analyze the structural equivalence to reduce the solver space
dimension, which demonstrates its power in many applications, such as protein
design, chemical pathways, and community detection. For the more commonly
occurring high-order relationships in real-life scenarios, the problem of
hypergraph isomorphism, which effectively captures these high-order structural
relationships, cannot be straightforwardly addressed using graph isomorphism
methods. Besides, the existing hypergraph kernel methods may suffer from high
memory consumption or inaccurate sub-structure identification, thus yielding
sub-optimal performance. In this paper, to address the abovementioned problems,
we first propose the hypergraph Weisfiler-Lehman test algorithm for the
hypergraph isomorphism test problem by generalizing the Weisfiler-Lehman test
algorithm from graphs to hypergraphs. Secondly, based on the presented
algorithm, we propose a general hypergraph Weisfieler-Lehman kernel framework
and implement two instances, which are Hypergraph Weisfeiler-Lehamn Subtree
Kernel and Hypergraph Weisfeiler-Lehamn Hyperedge Kernel. In order to fulfill
our research objectives, a comprehensive set of experiments was meticulously
designed, including seven graph classification datasets and 12 hypergraph
classification datasets. Results on hypergraph classification datasets show
significant improvements compared to other typical kernel-based methods, which
demonstrates the effectiveness of the proposed methods. In our evaluation, we
found that our proposed methods outperform the second-best method in terms of
runtime, running over 80 times faster when handling complex hypergraph
structures.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14395" title="Abstract">arXiv:2307.14395</a> [<a href="/pdf/2307.14395" title="Download PDF">pdf</a>, <a href="/format/2307.14395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to simulate partially known spatio-temporal dynamics with  trainable difference operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuoyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongsheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zidong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hongye Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+B">Bin Dong</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+B">Bei Hua</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, using neural networks to simulate spatio-temporal dynamics has
received a lot of attention. However, most existing methods adopt pure
data-driven black-box models, which have limited accuracy and interpretability.
By combining trainable difference operators with black-box models, we propose a
new hybrid architecture explicitly embedded with partial prior knowledge of the
underlying PDEs named PDE-Net++. Furthermore, we introduce two distinct options
called the trainable flipping difference layer (TFDL) and the trainable dynamic
difference layer (TDDL) for the difference operators. Numerous numerical
experiments have demonstrated that PDE-Net++ has superior prediction accuracy
and better extrapolation performance than black-box models.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14397" title="Abstract">arXiv:2307.14397</a> [<a href="/pdf/2307.14397" title="Download PDF">pdf</a>, <a href="/format/2307.14397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Generative Modeling with Limited Data, Few Shots, and Zero  Shot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdollahzadeh%2C+M">Milad Abdollahzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Malekzadeh%2C+T">Touba Malekzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Teo%2C+C+T+H">Christopher T. H. Teo</a>, 
<a href="/search/cs?searchtype=author&query=Chandrasegaran%2C+K">Keshigeyan Chandrasegaran</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guimeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+N">Ngai-Man Cheung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Survey. Touba Malekzadeh, Christopher T.H. Teo, Keshigeyan Chandrasegaran contribute equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In machine learning, generative modeling aims to learn to generate new data
statistically similar to the training data distribution. In this paper, we
survey learning generative models under limited data, few shots and zero shot,
referred to as Generative Modeling under Data Constraint (GM-DC). This is an
important topic when data acquisition is challenging, e.g. healthcare
applications. We discuss background, challenges, and propose two taxonomies:
one on GM-DC tasks and another on GM-DC approaches. Importantly, we study
interactions between different GM-DC tasks and approaches. Furthermore, we
highlight research gaps, research trends, and potential avenues for future
exploration. Project website: https://gmdc-survey.github.io.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14401" title="Abstract">arXiv:2307.14401</a> [<a href="/pdf/2307.14401" title="Download PDF">pdf</a>, <a href="/format/2307.14401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring Americanization: A Global Quantitative Study of Interest in  American Topics on Wikipedia
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Konieczny%2C+P">Piotr Konieczny</a>, 
<a href="/search/cs?searchtype=author&query=Lewoniewski%2C+W">W&#x142;odzimierz Lewoniewski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended and interactive version of bubble chart with Wikipedia languages: <a href="https://data.lewoniewski.info/americanwiki">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Applications (stat.AP)

</div>
<p class="mathjax">We conducted a global comparative analysis of the coverage of American topics
in different language versions of Wikipedia, using over 90 million Wikidata
items and 40 million Wikipedia articles in 58 languages. Our study aimed to
investigate whether Americanization is more or less dominant in different
regions and cultures and to determine whether interest in American topics is
universal.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14404" title="Abstract">arXiv:2307.14404</a> [<a href="/pdf/2307.14404" title="Download PDF">pdf</a>, <a href="/ps/2307.14404" title="Download PostScript">ps</a>, <a href="/format/2307.14404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain preserving and strongly converging explicit scheme for the  stochastic SIS epidemic model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kiouvrekis%2C+Y">Yiannis Kiouvrekis</a>, 
<a href="/search/math?searchtype=author&query=Stamatiou%2C+I+S">Ioannis S. Stamatiou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
<p class="mathjax">In this article, we construct a numerical method for a stochastic version of
the Susceptible Infected Susceptible (SIS) epidemic model, expressed by a
suitable stochastic differential equation (SDE), by using the semi-discrete
method to a suitable transformed process. We prove the strong convergence of
the proposed method, with order $1,$ and examine its stability properties.
Since SDEs generally lack analytical solutions, numerical techniques are
commonly employed. Hence, the research will seek numerical solutions for
existing stochastic models by constructing suitable numerical schemes and
comparing them with other schemes. The objective is to achieve a qualitative
and efficient approach to solving the equations. Additionally, for models that
have not yet been proposed for stochastic modeling using SDEs, the research
will formulate them appropriately, conduct theoretical analysis of the model
properties, and subsequently solve the corresponding SDEs.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14406" title="Abstract">arXiv:2307.14406</a> [<a href="/pdf/2307.14406" title="Download PDF">pdf</a>, <a href="/format/2307.14406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demystifying Code Snippets in Code Reviews: A Study of the OpenStack and  Qt Communities and A Practitioner Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Beiqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+L">Liming Fu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Peng Liang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiaxin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages, 9 images, 13 tables, Manuscript submitted to a Journal (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Code review is widely known as one of the best practices for software quality
assurance in software development. In a typical code review process, reviewers
check the code committed by developers to ensure the quality of the code,
during which reviewers and developers would communicate with each other in
review comments to exchange necessary information. As a result, understanding
the information in review comments is a prerequisite for reviewers and
developers to conduct an effective code review. Code snippet, as a special form
of code, can be used to convey necessary information in code reviews. For
example, reviewers can use code snippets to make suggestions or elaborate their
ideas to meet developers' information needs in code reviews. However, little
research has focused on the practices of providing code snippets in code
reviews. To bridge this gap, we conduct a mixed-methods study to mine
information and knowledge related to code snippets in code reviews, which can
help practitioners and researchers get a better understanding about using code
snippets in code review. Specifically, our study includes two phases: mining
code review data and conducting practitioners' survey. The study results
highlight that reviewers can provide code snippets in appropriate scenarios to
meet developers' specific information needs in code reviews, which will
facilitate and accelerate the code review process.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14430" title="Abstract">arXiv:2307.14430</a> [<a href="/pdf/2307.14430" title="Download PDF">pdf</a>, <a href="/format/2307.14430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Skill-it! A Data-Driven Skills Framework for Understanding and Training  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+M+F">Mayee F. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Roberts%2C+N">Nicholas Roberts</a>, 
<a href="/search/cs?searchtype=author&query=Bhatia%2C+K">Kush Bhatia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Ce Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sala%2C+F">Frederic Sala</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%A9%2C+C">Christopher R&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The quality of training data impacts the performance of pre-trained large
language models (LMs). Given a fixed budget of tokens, we study how to best
select data that leads to good downstream model performance across tasks. We
develop a new framework based on a simple hypothesis: just as humans acquire
interdependent skills in a deliberate order, language models also follow a
natural order when learning a set of skills from their training data. If such
an order exists, it can be utilized for improved understanding of LMs and for
data-efficient training. Using this intuition, our framework formalizes the
notion of a skill and of an ordered set of skills in terms of the associated
data. First, using both synthetic and real data, we demonstrate that these
ordered skill sets exist, and that their existence enables more advanced skills
to be learned with less data when we train on their prerequisite skills.
Second, using our proposed framework, we introduce an online data sampling
algorithm, Skill-It, over mixtures of skills for both continual pre-training
and fine-tuning regimes, where the objective is to efficiently learn multiple
skills in the former and an individual skill in the latter. On the LEGO
synthetic in the continual pre-training setting, Skill-It obtains 36.5 points
higher accuracy than random sampling. On the Natural Instructions dataset in
the fine-tuning setting, Skill-It reduces the validation loss on the target
skill by 13.6% versus training on data associated with the target skill itself.
We apply our skills framework on the recent RedPajama dataset to continually
pre-train a 3B-parameter LM, achieving higher accuracy on the LM Evaluation
Harness with 1B tokens than the baseline approach of sampling uniformly over
data sources with 3B tokens.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14433" title="Abstract">arXiv:2307.14433</a> [<a href="/pdf/2307.14433" title="Download PDF">pdf</a>, <a href="/format/2307.14433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProtoASNet: Dynamic Prototypes for Inherently Interpretable and  Uncertainty-Aware Aortic Stenosis Classification in Echocardiography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vaseli%2C+H">Hooman Vaseli</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+A+N">Ang Nan Gu</a>, 
<a href="/search/cs?searchtype=author&query=Amiri%2C+S+N+A">S. Neda Ahmadi Amiri</a>, 
<a href="/search/cs?searchtype=author&query=Tsang%2C+M+Y">Michael Y. Tsang</a>, 
<a href="/search/cs?searchtype=author&query=Fung%2C+A">Andrea Fung</a>, 
<a href="/search/cs?searchtype=author&query=Kondori%2C+N">Nima Kondori</a>, 
<a href="/search/cs?searchtype=author&query=Saadat%2C+A">Armin Saadat</a>, 
<a href="/search/cs?searchtype=author&query=Abolmaesumi%2C+P">Purang Abolmaesumi</a>, 
<a href="/search/cs?searchtype=author&query=Tsang%2C+T+S+M">Teresa S. M. Tsang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Aortic stenosis (AS) is a common heart valve disease that requires accurate
and timely diagnosis for appropriate treatment. Most current automatic AS
severity detection methods rely on black-box models with a low level of
trustworthiness, which hinders clinical adoption. To address this issue, we
propose ProtoASNet, a prototypical network that directly detects AS from B-mode
echocardiography videos, while making interpretable predictions based on the
similarity between the input and learned spatio-temporal prototypes. This
approach provides supporting evidence that is clinically relevant, as the
prototypes typically highlight markers such as calcification and restricted
movement of aortic valve leaflets. Moreover, ProtoASNet utilizes abstention
loss to estimate aleatoric uncertainty by defining a set of prototypes that
capture ambiguity and insufficient information in the observed data. This
provides a reliable system that can detect and explain when it may fail. We
evaluate ProtoASNet on a private dataset and the publicly available TMED-2
dataset, where it outperforms existing state-of-the-art methods with an
accuracy of 80.0% and 79.7%, respectively. Furthermore, ProtoASNet provides
interpretability and an uncertainty measure for each prediction, which can
improve transparency and facilitate the interactive usage of deep networks to
aid clinical decision-making. Our source code is available at:
https://github.com/hooman007/ProtoASNet.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14437" title="Abstract">arXiv:2307.14437</a> [<a href="/pdf/2307.14437" title="Download PDF">pdf</a>, <a href="/format/2307.14437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A grid-overlay finite difference method for the fractional Laplacian on  arbitrary bounded domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Huang%2C+W">Weizhang Huang</a>, 
<a href="/search/math?searchtype=author&query=Shen%2C+J">Jinye Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">A grid-overlay finite difference method is proposed for the numerical
approximation of the fractional Laplacian on arbitrary bounded domains. The
method uses an unstructured simplicial mesh and an overlay uniform grid for the
underlying domain and constructs the approximation based on a uniform-grid
finite difference approximation and a data transfer from the unstructured mesh
to the uniform grid. The method takes full advantage of both uniform-grid
finite difference approximation in efficient matrix-vector multiplication via
the fast Fourier transform and unstructured meshes for complex geometries. It
is shown that its stiffness matrix is similar to a symmetric and positive
definite matrix and thus invertible if the data transfer has full column rank
and positive column sums. Piecewise linear interpolation is studied as a
special example for the data transfer. It is proved that the full column rank
and positive column sums of linear interpolation is guaranteed if the spacing
of the uniform grid is smaller than or equal to a positive bound proportional
to the minimum element height of the unstructured mesh. Moreover, a sparse
preconditioner is proposed for the iterative solution of the resulting linear
system for the homogeneous Dirichlet problem of the fractional Laplacian.
Numerical examples demonstrate that the new method has similar convergence
behavior as existing finite difference and finite element methods and that the
sparse preconditioning is effective. Furthermore, the new method can readily be
incorporated with existing mesh adaptation strategies. Numerical results
obtained by combining with the so-called MMPDE moving mesh method are also
presented.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14439" title="Abstract">arXiv:2307.14439</a> [<a href="/pdf/2307.14439" title="Download PDF">pdf</a>, <a href="/format/2307.14439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fixed Integral Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kortvelesy%2C+R">Ryan Kortvelesy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">It is often useful to perform integration over learned functions represented
by neural networks. However, this integration is usually performed numerically,
as analytical integration over learned functions (especially neural networks)
is generally viewed as intractable. In this work, we present a method for
representing the analytical integral of a learned function $f$. This allows the
exact integral of a neural network to be computed, and enables constrained
neural networks to be parametrised by applying constraints directly to the
integral. Crucially, we also introduce a method to constrain $f$ to be
positive, a necessary condition for many applications (e.g. probability
distributions, distance metrics, etc). Finally, we introduce several
applications where our fixed-integral neural network (FINN) can be utilised.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14440" title="Abstract">arXiv:2307.14440</a> [<a href="/pdf/2307.14440" title="Download PDF">pdf</a>, <a href="/format/2307.14440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controllable Generation of Dialogue Acts for Dialogue Systems via  Few-Shot Response Generation and Ranking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramirez%2C+A">Angela Ramirez</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+K">Karik Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Juraska%2C+J">Juraj Juraska</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+U">Utkarsh Garg</a>, 
<a href="/search/cs?searchtype=author&query=Walker%2C+M+A">Marilyn A. Walker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To Appear in SIGDIAL 2023. Proceedings of the 24th Annual Meeting of the Special Interest Group on Discourse and Dialogue. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Dialogue systems need to produce responses that realize multiple types of
dialogue acts (DAs) with high semantic fidelity. In the past, natural language
generators (NLGs) for dialogue were trained on large parallel corpora that map
from a domain-specific DA and its semantic attributes to an output utterance.
Recent work shows that pretrained language models (LLMs) offer new
possibilities for controllable NLG using prompt-based learning. Here we develop
a novel few-shot overgenerate-and-rank approach that achieves the controlled
generation of DAs. We compare eight few-shot prompt styles that include a novel
method of generating from textual pseudo-references using a textual style
transfer approach. We develop six automatic ranking functions that identify
outputs with both the correct DA and high semantic accuracy at generation time.
We test our approach on three domains and four LLMs. To our knowledge, this is
the first work on NLG for dialogue that automatically ranks outputs using both
DA and attribute accuracy. For completeness, we compare our results to
fine-tuned few-shot models trained with 5 to 100 instances per DA. Our results
show that several prompt settings achieve perfect DA accuracy, and near perfect
semantic accuracy (99.81%) and perform better than few-shot fine-tuning.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14446" title="Abstract">arXiv:2307.14446</a> [<a href="/pdf/2307.14446" title="Download PDF">pdf</a>, <a href="/format/2307.14446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Few-shot Learning for Semantic Segmentation: An  Annotation-free Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karimijafarbigloo%2C+S">Sanaz Karimijafarbigloo</a>, 
<a href="/search/cs?searchtype=author&query=Azad%2C+R">Reza Azad</a>, 
<a href="/search/cs?searchtype=author&query=Merhof%2C+D">Dorit Merhof</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MICCAI 2023 workshop PRIME
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Few-shot semantic segmentation (FSS) offers immense potential in the field of
medical image analysis, enabling accurate object segmentation with limited
training data. However, existing FSS techniques heavily rely on annotated
semantic classes, rendering them unsuitable for medical images due to the
scarcity of annotations. To address this challenge, multiple contributions are
proposed: First, inspired by spectral decomposition methods, the problem of
image decomposition is reframed as a graph partitioning task. The eigenvectors
of the Laplacian matrix, derived from the feature affinity matrix of
self-supervised networks, are analyzed to estimate the distribution of the
objects of interest from the support images. Secondly, we propose a novel
self-supervised FSS framework that does not rely on any annotation. Instead, it
adaptively estimates the query mask by leveraging the eigenvectors obtained
from the support images. This approach eliminates the need for manual
annotation, making it particularly suitable for medical images with limited
annotated data. Thirdly, to further enhance the decoding of the query image
based on the information provided by the support image, we introduce a
multi-scale large kernel attention module. By selectively emphasizing relevant
features and details, this module improves the segmentation process and
contributes to better object delineation. Evaluations on both natural and
medical image datasets demonstrate the efficiency and effectiveness of our
method. Moreover, the proposed approach is characterized by its generality and
model-agnostic nature, allowing for seamless integration with various deep
architectures. The code is publicly available at
\href{https://github.com/mindflow-institue/annotation_free_fewshot}{\textcolor{magenta}{GitHub}}.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14448" title="Abstract">arXiv:2307.14448</a> [<a href="/pdf/2307.14448" title="Download PDF">pdf</a>, <a href="/format/2307.14448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VISPUR: Visual Aids for Identifying and Interpreting Spurious  Associations in Data-Driven Decisions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teng%2C+X">Xian Teng</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+Y">Yongsu Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yu-Ru Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Big data and machine learning tools have jointly empowered humans in making
data-driven decisions. However, many of them capture empirical associations
that might be spurious due to confounding factors and subgroup heterogeneity.
The famous Simpson's paradox is such a phenomenon where aggregated and
subgroup-level associations contradict with each other, causing cognitive
confusions and difficulty in making adequate interpretations and decisions.
Existing tools provide little insights for humans to locate, reason about, and
prevent pitfalls of spurious association in practice. We propose VISPUR, a
visual analytic system that provides a causal analysis framework and a
human-centric workflow for tackling spurious associations. These include a
CONFOUNDER DASHBOARD, which can automatically identify possible confounding
factors, and a SUBGROUP VIEWER, which allows for the visualization and
comparison of diverse subgroup patterns that likely or potentially result in a
misinterpretation of causality. Additionally, we propose a REASONING
STORYBOARD, which uses a flow-based approach to illustrate paradoxical
phenomena, as well as an interactive DECISION DIAGNOSIS panel that helps ensure
accountable decision-making. Through an expert interview and a controlled user
experiment, our qualitative and quantitative results demonstrate that the
proposed "de-paradox" workflow and the designed visual analytic system are
effective in helping human users to identify and understand spurious
associations, as well as to make accountable causal decisions.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14450" title="Abstract">arXiv:2307.14450</a> [<a href="/pdf/2307.14450" title="Download PDF">pdf</a>, <a href="/format/2307.14450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating Offline Reinforcement Learning with Transformers for  Sequential Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xi%2C+X">Xumei Xi</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuke Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Quan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+L">Liwen Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yang Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">We consider the problem of sequential recommendation, where the current
recommendation is made based on past interactions. This recommendation task
requires efficient processing of the sequential data and aims to provide
recommendations that maximize the long-term reward. To this end, we train a
farsighted recommender by using an offline RL algorithm with the policy network
in our model architecture that has been initialized from a pre-trained
transformer model. The pre-trained model leverages the superb ability of the
transformer to process sequential information. Compared to prior works that
rely on online interaction via simulation, we focus on implementing a fully
offline RL framework that is able to converge in a fast and stable way. Through
extensive experiments on public datasets, we show that our method is robust
across various recommendation regimes, including e-commerce and movie
suggestions. Compared to state-of-the-art supervised learning algorithms, our
algorithm yields recommendations of higher quality, demonstrating the clear
advantage of combining RL and transformers.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14453" title="Abstract">arXiv:2307.14453</a> [<a href="/pdf/2307.14453" title="Download PDF">pdf</a>, <a href="/format/2307.14453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predictive Maintenance of Armoured Vehicles using Machine Learning  Approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+P">Prajit Sengupta</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+A">Anant Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Rana%2C+P+S">Prashant Singh Rana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Conference Proceedings of INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE, MACHINE LEARNING AND ARTIFICIAL INTELLIGENCE (pg:25-31) - (New Delhi, 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Armoured vehicles are specialized and complex pieces of machinery designed to
operate in high-stress environments, often in combat or tactical situations.
This study proposes a predictive maintenance-based ensemble system that aids in
predicting potential maintenance needs based on sensor data collected from
these vehicles. The proposed model's architecture involves various models such
as Light Gradient Boosting, Random Forest, Decision Tree, Extra Tree Classifier
and Gradient Boosting to predict the maintenance requirements of the vehicles
accurately. In addition, K-fold cross validation, along with TOPSIS analysis,
is employed to evaluate the proposed ensemble model's stability. The results
indicate that the proposed system achieves an accuracy of 98.93%, precision of
99.80% and recall of 99.03%. The algorithm can effectively predict maintenance
needs, thereby reducing vehicle downtime and improving operational efficiency.
Through comparisons between various algorithms and the suggested ensemble, this
study highlights the potential of machine learning-based predictive maintenance
solutions.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14460" title="Abstract">arXiv:2307.14460</a> [<a href="/pdf/2307.14460" title="Download PDF">pdf</a>, <a href="/format/2307.14460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MiDaS v3.1 -- A Model Zoo for Robust Monocular Relative Depth Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Birkl%2C+R">Reiner Birkl</a>, 
<a href="/search/cs?searchtype=author&query=Wofk%2C+D">Diana Wofk</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+M">Matthias M&#xfc;ller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We release MiDaS v3.1 for monocular depth estimation, offering a variety of
new models based on different encoder backbones. This release is motivated by
the success of transformers in computer vision, with a large variety of
pretrained vision transformers now available. We explore how using the most
promising vision transformers as image encoders impacts depth estimation
quality and runtime of the MiDaS architecture. Our investigation also includes
recent convolutional approaches that achieve comparable quality to vision
transformers in image classification tasks. While the previous release MiDaS
v3.0 solely leverages the vanilla vision transformer ViT, MiDaS v3.1 offers
additional models based on BEiT, Swin, SwinV2, Next-ViT and LeViT. These models
offer different performance-runtime tradeoffs. The best model improves the
depth estimation quality by 28% while efficient models enable downstream tasks
requiring high frame rates. We also describe the general process for
integrating new backbones. A video summarizing the work can be found at
https://youtu.be/UjaeNNFf9sE and the code is available at
https://github.com/isl-org/MiDaS.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14464" title="Abstract">arXiv:2307.14464</a> [<a href="/pdf/2307.14464" title="Download PDF">pdf</a>, <a href="/format/2307.14464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single Channel Speech Enhancement Using U-Net Spiking Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Riahi%2C+A">Abir Riahi</a>, 
<a href="/search/cs?searchtype=author&query=Plourde%2C+%C3%89">&#xc9;ric Plourde</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Speech enhancement (SE) is crucial for reliable communication devices or
robust speech recognition systems. Although conventional artificial neural
networks (ANN) have demonstrated remarkable performance in SE, they require
significant computational power, along with high energy costs. In this paper,
we propose a novel approach to SE using a spiking neural network (SNN) based on
a U-Net architecture. SNNs are suitable for processing data with a temporal
dimension, such as speech, and are known for their energy-efficient
implementation on neuromorphic hardware. As such, SNNs are thus interesting
candidates for real-time applications on devices with limited resources. The
primary objective of the current work is to develop an SNN-based model with
comparable performance to a state-of-the-art ANN model for SE. We train a deep
SNN using surrogate-gradient-based optimization and evaluate its performance
using perceptual objective tests under different signal-to-noise ratios and
real-world noise conditions. Our results demonstrate that the proposed
energy-efficient SNN model outperforms the Intel Neuromorphic Deep Noise
Suppression Challenge (Intel N-DNS Challenge) baseline solution and achieves
acceptable performance compared to an equivalent ANN model.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14465" title="Abstract">arXiv:2307.14465</a> [<a href="/pdf/2307.14465" title="Download PDF">pdf</a>, <a href="/format/2307.14465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Kinds of Contracts Do ML APIs Need?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khairunnesa%2C+S+S">Samantha Syeda Khairunnesa</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S">Shibbir Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Imtiaz%2C+S+M">Sayem Mohammad Imtiaz</a>, 
<a href="/search/cs?searchtype=author&query=Rajan%2C+H">Hridesh Rajan</a>, 
<a href="/search/cs?searchtype=author&query=Leavens%2C+G+T">Gary T. Leavens</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at EMSE (Empirical Software Engineering) Journal, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG); Programming Languages (cs.PL)

</div>
<p class="mathjax">Recent work has shown that Machine Learning (ML) programs are error-prone and
called for contracts for ML code. Contracts, as in the design by contract
methodology, help document APIs and aid API users in writing correct code. The
question is: what kinds of contracts would provide the most help to API users?
We are especially interested in what kinds of contracts help API users catch
errors at earlier stages in the ML pipeline. We describe an empirical study of
posts on Stack Overflow of the four most often-discussed ML libraries:
TensorFlow, Scikit-learn, Keras, and PyTorch. For these libraries, our study
extracted 413 informal (English) API specifications. We used these
specifications to understand the following questions. What are the root causes
and effects behind ML contract violations? Are there common patterns of ML
contract violations? When does understanding ML contracts require an advanced
level of ML software expertise? Could checking contracts at the API level help
detect the violations in early ML pipeline stages? Our key findings are that
the most commonly needed contracts for ML APIs are either checking constraints
on single arguments of an API or on the order of API calls. The software
engineering community could employ existing contract mining approaches to mine
these contracts to promote an increased understanding of ML APIs. We also noted
a need to combine behavioral and temporal contract mining approaches. We report
on categories of required ML contracts, which may help designers of contract
languages.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14469" title="Abstract">arXiv:2307.14469</a> [<a href="/pdf/2307.14469" title="Download PDF">pdf</a>, <a href="/format/2307.14469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> It&#x27;s Not Just GitHub: Identifying Data and Software Sources Included in  Publications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Escamilla%2C+E">Emily Escamilla</a>, 
<a href="/search/cs?searchtype=author&query=Salsabil%2C+L">Lamia Salsabil</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+M">Martin Klein</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Weigle%2C+M+C">Michele C. Weigle</a>, 
<a href="/search/cs?searchtype=author&query=Nelson%2C+M+L">Michael L. Nelson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures, pre-print of publication for Theory and Practice of Digital Libraries 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">Paper publications are no longer the only form of research product. Due to
recent initiatives by publication venues and funding institutions, open access
datasets and software products are increasingly considered research products
and URIs to these products are growing more prevalent in scholarly
publications. However, as with all URIs, resources found on the live Web are
not permanent. Archivists and institutions including Software Heritage,
Internet Archive, and Zenodo are working to preserve data and software products
as valuable parts of reproducibility, a cornerstone of scientific research.
While some hosting platforms are well-known and can be identified with regular
expressions, there are a vast number of smaller, more niche hosting platforms
utilized by researchers to host their data and software. If it is not feasible
to manually identify all hosting platforms used by researchers, how can we
identify URIs to open-access data and software (OADS) to aid in their
preservation? We used a hybrid classifier to classify URIs as OADS URIs and
non-OADS URIs. We found that URIs to Git hosting platforms (GHPs) including
GitHub, GitLab, SourceForge, and Bitbucket accounted for 33\% of OADS URIs.
Non-GHP OADS URIs are distributed across almost 50,000 unique hostnames. We
determined that using a hybrid classifier allows for the identification of OADS
URIs in less common hosting platforms which can benefit discoverability for
preserving datasets and software products as research products for
reproducibility.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14471" title="Abstract">arXiv:2307.14471</a> [<a href="/pdf/2307.14471" title="Download PDF">pdf</a>, <a href="/format/2307.14471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modal Abstractions for Virtualizing Memory Addresses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuru%2C+I">Ismail Kuru</a>, 
<a href="/search/cs?searchtype=author&query=Gordon%2C+C+S">Colin S. Gordon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Operating system kernels employ virtual memory management (VMM) subsystems to
virtualize the addresses of memory regions in order to to isolate untrusted
processes, ensure process isolation and implement demand-paging and
copy-on-write behaviors for performance and resource controls. Bugs in these
systems can lead to kernel crashes. VMM code is a critical piece of
general-purpose OS kernels, but their verification is challenging due to the
hardware interface (mappings are updated via writes to memory locations, using
addresses which are themselves virtualized). Prior work on VMM verification has
either only handled a single address space, trusted significant pieces of
assembly code, or resorted to direct reasoning over machine semantics rather
than exposing a clean logical interface.
<br />In this paper, we introduce a modal abstraction to describe the truth of
assertions relative to a specific virtual address space, allowing different
address spaces to refer to each other, and enabling verification of instruction
sequences manipulating multiple address spaces. Using them effectively requires
working with other assertions, such as points-to assertions in our separation
logic, as relative to a given address space. We therefore define virtual
points-to assertions, which mimic hardware address translation, relative to a
page table root. We demonstrate our approach with challenging fragments of VMM
code showing that our approach handles examples beyond what prior work can
address, including reasoning about a sequence of instructions as it changes
address spaces. All definitions and theorems mentioned in this paper including
the operational model of a RISC-like fragment of supervisor-mode x86-64, and a
logic as an instantiation of the Iris framework, are mechanized inside Coq.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14474" title="Abstract">arXiv:2307.14474</a> [<a href="/pdf/2307.14474" title="Download PDF">pdf</a>, <a href="/format/2307.14474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Limits to Reservoir Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Polloreno%2C+A+M">Anthony M. Polloreno</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In this work, we bound a machine's ability to learn based on computational
limitations implied by physicality. We start by considering the information
processing capacity (IPC), a normalized measure of the expected squared error
of a collection of signals to a complete basis of functions. We use the IPC to
measure the degradation under noise of the performance of reservoir computers,
a particular kind of recurrent network, when constrained by physical
considerations. First, we show that the IPC is at most a polynomial in the
system size $n$, even when considering the collection of $2^n$ possible
pointwise products of the $n$ output signals. Next, we argue that this
degradation implies that the family of functions represented by the reservoir
requires an exponential number of samples to learn in the presence of the
reservoir's noise. Finally, we conclude with a discussion of the performance of
the same collection of $2^n$ functions without noise when being used for binary
classification.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14476" title="Abstract">arXiv:2307.14476</a> [<a href="/pdf/2307.14476" title="Download PDF">pdf</a>, <a href="/format/2307.14476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Asynchronous and Low-Power True Random Number Generator using STT-MTJ
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perach%2C+B">Ben Perach</a>, 
<a href="/search/cs?searchtype=author&query=Kvatinsky%2C+S">Shahar Kvatinsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in: IEEE Transactions on Very Large Scale Integration (VLSI) Systems ( Volume: 27, Issue: 11, November 2019)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">The emerging Spin Transfer Torque Magnetic Tunnel Junction (STT-MTJ)
technology exhibits interesting stochastic behavior combined with small area
and low operation energy. It is, therefore, a promising technology for security
applications, specifically the generation of random numbers. In this paper,
STT-MTJ is used to construct an asynchronous true random number generator
(TRNG) with low power and a high entropy rate. The asynchronous design enables
decoupling of the random number generation from the system clock, allowing it
to be embedded in low-power devices. The proposed TRNG is evaluated by a
numerical simulation, using the Landau-Lifshitz-Gilbert (LLG) equation as the
model of the STT-MTJ devices. Design considerations, attack analysis, and
process variation are discussed and evaluated. We show that our design is
robust to process variation, achieving an entropy generating rate between
99.7Mbps and 127.8Mbps with 6-7.7 pJ per bit for 90% of the instances.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14480" title="Abstract">arXiv:2307.14480</a> [<a href="/pdf/2307.14480" title="Download PDF">pdf</a>, <a href="/format/2307.14480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PSOFuzz: Fuzzing Processors with Particle Swarm Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gohil%2C+V">Vasudev Gohil</a>, 
<a href="/search/cs?searchtype=author&query=Kande%2C+R">Rahul Kande</a>, 
<a href="/search/cs?searchtype=author&query=Sadeghi%2C+A">Ahmad-Reza Sadeghi</a>, 
<a href="/search/cs?searchtype=author&query=Rajendran%2C+J">Jeyavijayan Rajendran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the proceedings of the ICCAD, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Hardware security vulnerabilities in computing systems compromise the
security defenses of not only the hardware but also the software running on it.
Recent research has shown that hardware fuzzing is a promising technique to
efficiently detect such vulnerabilities in large-scale designs such as modern
processors. However, the current fuzzing techniques do not adjust their
strategies dynamically toward faster and higher design space exploration,
resulting in slow vulnerability detection, evident through their low design
coverage. To address this problem, we propose PSOFuzz, which uses particle
swarm optimization (PSO) to schedule the mutation operators and to generate
initial input programs dynamically with the objective of detecting
vulnerabilities quickly. Unlike traditional PSO, which finds a single optimal
solution, we use a modified PSO that dynamically computes the optimal solution
for selecting mutation operators required to explore new design regions in
hardware. We also address the challenge of inefficient initial input generation
by employing PSO-based input generation. Including these optimizations, our
final formulation outperforms fuzzers without PSO. Experiments show that
PSOFuzz achieves up to 15.25$\times$ speedup for vulnerability detection and up
to 2.22$\times$ speedup for coverage compared to the state-of-the-art
simulation-based hardware fuzzer.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14485" title="Abstract">arXiv:2307.14485</a> [<a href="/pdf/2307.14485" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The South African Software Industry as a Key Component of Economic  Development: Pipedream or Possibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mukala%2C+P">Patrick Mukala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The Information and Communication sector has undoubtedly played a pivotal
role in changing the way people live nowadays. Almost every area of our lives
is affected by the presence and the use of the new information and
communication technologies. In this regard, many researchers' attention has
been attracted by the influence or the significant impact of these technologies
on economic growth and development. Although the history of South Africa has
had some drawbacks that could constitute a big obstacle to the emergence of a
successful economic environment, the actual status of the country regarding its
economy and the role that it plays in Africa towards the rest of the African
countries is a vital example of an emerging economic force in Africa. This
paper examines the crucial role that ICT has played and is still playing in the
South African economy growth and more specifically the significance of the
economic effects of the software industry. It makes use of the framework used
by Heavin et al. (2003) to investigate the Irish software industry in order to
analyze the impact of endogenous factors -- national, enterprise and individual
-- on the software industry and its implication on the economic growth in South
Africa.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14487" title="Abstract">arXiv:2307.14487</a> [<a href="/pdf/2307.14487" title="Download PDF">pdf</a>, <a href="/format/2307.14487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Technical note: ShinyAnimalCV: open-source cloud-based web application  for object detection, segmentation, and three-dimensional visualization of  animals using computer vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+L">Lirong Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Morota%2C+G">Gota Morota</a>, 
<a href="/search/cs?searchtype=author&query=Brooks%2C+S+A">Samantha A. Brooks</a>, 
<a href="/search/cs?searchtype=author&query=Wickens%2C+C+L">Carissa L. Wickens</a>, 
<a href="/search/cs?searchtype=author&query=Miller-Cushon%2C+E+K">Emily K. Miller-Cushon</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haipeng Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Computer vision (CV), a non-intrusive and cost-effective technology, has
furthered the development of precision livestock farming by enabling optimized
decision-making through timely and individualized animal care. The availability
of affordable two- and three-dimensional camera sensors, combined with various
machine learning and deep learning algorithms, has provided a valuable
opportunity to improve livestock production systems. However, despite the
availability of various CV tools in the public domain, applying these tools to
animal data can be challenging, often requiring users to have programming and
data analysis skills, as well as access to computing resources. Moreover, the
rapid expansion of precision livestock farming is creating a growing need to
educate and train animal science students in CV. This presents educators with
the challenge of efficiently demonstrating the complex algorithms involved in
CV. Thus, the objective of this study was to develop ShinyAnimalCV, an
open-source cloud-based web application. This application provides a
user-friendly interface for performing CV tasks, including object segmentation,
detection, three-dimensional surface visualization, and extraction of two- and
three-dimensional morphological features. Nine pre-trained CV models using
top-view animal data are included in the application. ShinyAnimalCV has been
deployed online using cloud computing platforms. The source code of
ShinyAnimalCV is available on GitHub, along with detailed documentation on
training CV models using custom data and deploying ShinyAnimalCV locally to
allow users to fully leverage the capabilities of the application.
ShinyAnimalCV can contribute to CV research and teaching in the animal science
community.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14489" title="Abstract">arXiv:2307.14489</a> [<a href="/pdf/2307.14489" title="Download PDF">pdf</a>, <a href="/format/2307.14489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SuperInpaint: Learning Detail-Enhanced Attentional Implicit  Representation for Super-resolutional Image Inpainting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Canyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoguang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+R">Renjie Wan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hongkai Yu</a>, 
<a href="/search/cs?searchtype=author&query=Tsang%2C+I">Ivor Tsang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Song Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this work, we introduce a challenging image restoration task, referred to
as SuperInpaint, which aims to reconstruct missing regions in low-resolution
images and generate completed images with arbitrarily higher resolutions. We
have found that this task cannot be effectively addressed by stacking
state-of-the-art super-resolution and image inpainting methods as they amplify
each other's flaws, leading to noticeable artifacts. To overcome these
limitations, we propose the detail-enhanced attentional implicit representation
(DEAR) that can achieve SuperInpaint with a single model, resulting in
high-quality completed images with arbitrary resolutions. Specifically, we use
a deep convolutional network to extract the latent embedding of an input image
and then enhance the high-frequency components of the latent embedding via an
adaptive high-pass filter. This leads to detail-enhanced semantic embedding. We
further feed the semantic embedding into an unmask-attentional module that
suppresses embeddings from ineffective masked pixels. Additionally, we extract
a pixel-wise importance map that indicates which pixels should be used for
image reconstruction. Given the coordinates of a pixel we want to reconstruct,
we first collect its neighboring pixels in the input image and extract their
detail-enhanced semantic embeddings, unmask-attentional semantic embeddings,
importance values, and spatial distances to the desired pixel. Then, we feed
all the above terms into an implicit representation and generate the color of
the specified pixel. To evaluate our method, we extend three existing datasets
for this new task and build 18 meaningful baselines using SOTA inpainting and
super-resolution methods. Extensive experimental results demonstrate that our
method outperforms all existing methods by a significant margin on four widely
used metrics.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14490" title="Abstract">arXiv:2307.14490</a> [<a href="/pdf/2307.14490" title="Download PDF">pdf</a>, <a href="/format/2307.14490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HUGE: Huge Unsupervised Graph Embeddings with TPUs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mayer%2C+B">Brandon Mayer</a>, 
<a href="/search/cs?searchtype=author&query=Tsitsulin%2C+A">Anton Tsitsulin</a>, 
<a href="/search/cs?searchtype=author&query=Fichtenberger%2C+H">Hendrik Fichtenberger</a>, 
<a href="/search/cs?searchtype=author&query=Halcrow%2C+J">Jonathan Halcrow</a>, 
<a href="/search/cs?searchtype=author&query=Perozzi%2C+B">Bryan Perozzi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> As appeared at KDD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graphs are a representation of structured data that captures the
relationships between sets of objects. With the ubiquity of available network
data, there is increasing industrial and academic need to quickly analyze
graphs with billions of nodes and trillions of edges. A common first step for
network understanding is Graph Embedding, the process of creating a continuous
representation of nodes in a graph. A continuous representation is often more
amenable, especially at scale, for solving downstream machine learning tasks
such as classification, link prediction, and clustering. A high-performance
graph embedding architecture leveraging Tensor Processing Units (TPUs) with
configurable amounts of high-bandwidth memory is presented that simplifies the
graph embedding problem and can scale to graphs with billions of nodes and
trillions of edges. We verify the embedding space quality on real and synthetic
large-scale datasets.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14491" title="Abstract">arXiv:2307.14491</a> [<a href="/pdf/2307.14491" title="Download PDF">pdf</a>, <a href="/format/2307.14491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modality-Agnostic Audio-Visual Deepfake Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Cai Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jiahe Tian</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jiao Dai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+Y">Yesheng Chai</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jizhong Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">As AI-generated content (AIGC) thrives, Deepfakes have expanded from
single-modality falsification to cross-modal fake content creation, where
either audio or visual components can be manipulated. While using two unimodal
detectors can detect audio-visual deepfakes, cross-modal forgery clues could be
overlooked. Existing multimodal deepfake detection methods typically establish
correspondence between the audio and visual modalities for binary real/fake
classification, and require the co-occurrence of both modalities. However, in
real-world multi-modal applications, missing modality scenarios may occur where
either modality is unavailable. In such cases, audio-visual detection methods
are less practical than two independent unimodal methods. Consequently, the
detector can not always obtain the number or type of manipulated modalities
beforehand, necessitating a fake-modality-agnostic audio-visual detector. In
this work, we propose a unified fake-modality-agnostic scenarios framework that
enables the detection of multimodal deepfakes and handles missing modalities
cases, no matter the manipulation hidden in audio, video, or even cross-modal
forms. To enhance the modeling of cross-modal forgery clues, we choose
audio-visual speech recognition (AVSR) as a preceding task, which effectively
extracts speech correlation across modalities, which is difficult for deepfakes
to reproduce. Additionally, we propose a dual-label detection approach that
follows the structure of AVSR to support the independent detection of each
modality. Extensive experiments show that our scheme not only outperforms other
state-of-the-art binary detection methods across all three audio-visual
datasets but also achieves satisfying performance on detection
modality-agnostic audio/video fakes. Moreover, it even surpasses the joint use
of two unimodal methods in the presence of missing modality cases.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14492" title="Abstract">arXiv:2307.14492</a> [<a href="/pdf/2307.14492" title="Download PDF">pdf</a>, <a href="/format/2307.14492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dimension-Minimality and Primality of Counter Nets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Almagor%2C+S">Shaull Almagor</a>, 
<a href="/search/cs?searchtype=author&query=Avni%2C+G">Guy Avni</a>, 
<a href="/search/cs?searchtype=author&query=Sinclair-Banks%2C+H">Henry Sinclair-Banks</a>, 
<a href="/search/cs?searchtype=author&query=Yeshurun%2C+A">Asaf Yeshurun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">A $k$-Counter Net ($k$-CN) is a finite-state automaton equipped with $k$
integer counters that are not allowed to become negative, but do not have
explicit zero tests. This language-recognition model can be thought of as
labelled vector addition systems with states, some of which are accepting.
Certain decision problems for $k$-CNs become easier, or indeed decidable, when
the dimension $k$ is small. Yet, little is known about the effect that the
dimension $k$ has on the class of languages recognised by $k$-CNs.
Specifically, it would be useful if we could simplify algorithmic reasoning by
reducing the dimension of a given CN.
<br />To this end, we introduce the notion of dimension-primality for $k$-CN,
whereby a $k$-CN is prime if it recognises a language that cannot be decomposed
into a finite intersection of languages recognised by $d$-CNs, for some $d&lt;k$.
We show that primality is undecidable. We also study two related notions:
dimension-minimality (where we seek a single language-equivalent $d$-CN of
lower dimension) and language regularity. Additionally, we explore the
trade-offs in expressiveness between dimension and non-determinism for CN.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14494" title="Abstract">arXiv:2307.14494</a> [<a href="/pdf/2307.14494" title="Download PDF">pdf</a>, <a href="/format/2307.14494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding roots of complex analytic functions via generalized colleague  matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+H">Hanwen Zhang</a>, 
<a href="/search/math?searchtype=author&query=Rokhlin%2C+V">Vladimir Rokhlin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present a scheme for finding all roots of an analytic function in a square
domain in the complex plane. The scheme can be viewed as a generalization of
the classical approach to finding roots of a function on the real line, by
first approximating it by a polynomial in the Chebyshev basis, followed by
diagonalizing the so-called ''colleague matrices''. Our extension of the
classical approach is based on several observations that enable the
construction of polynomial bases in compact domains that satisfy three-term
recurrences and are reasonably well-conditioned. This class of polynomial bases
gives rise to ''generalized colleague matrices'', whose eigenvalues are roots
of functions expressed in these bases. In this paper, we also introduce a
special-purpose QR algorithm for finding the eigenvalues of generalized
colleague matrices, which is a straightforward extension of the recently
introduced componentwise stable QR algorithm for the classical cases (See
[Serkh]). The performance of the schemes is illustrated with several numerical
examples.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14498" title="Abstract">arXiv:2307.14498</a> [<a href="/pdf/2307.14498" title="Download PDF">pdf</a>, <a href="/format/2307.14498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving frequency response with synthetic damping available from  fleets of distributed energy resources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mavalizadeh%2C+H">Hani Mavalizadeh</a>, 
<a href="/search/eess?searchtype=author&query=Espinosa%2C+L+A+D">Luis A. Duffaut Espinosa</a>, 
<a href="/search/eess?searchtype=author&query=Almassalkhi%2C+M+R">Mads R. Almassalkhi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transactions on Power systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">With the increasing use of renewable generation in power systems, responsive
resources will be necessary to support primary frequency control in future
low-inertia/under-damped power systems. Flexible loads can provide
fast-frequency response services if coordinated effectively. However, practical
implementations of such synthetic damping services require both effective local
sensing and control at the device level and an ability to accurately estimate
online and predict the available synthetic damping from a fleet. In addition,
the inherent trade-off between a fleet being available for fast frequency
response while providing other ancillary services needs to be characterized. In
this context, the manuscript presents a novel, fully decentralized,
packet-based controller for diverse flexible loads that dynamically prioritizes
and interrupts loads to engender synthetic damping suitable for primary
frequency control. Moreover, the packet-based control methodology is shown to
accurately characterize the available synthetic damping in real-time, which is
useful to aggregators and system operators. Furthermore, spectral analysis of
historical frequency regulation data is used to produce a probabilistic bound
on the expected available synthetic damping for primary frequency control from
a fleet and the trade-off from concurrently providing secondary frequency
control services. Finally, numerical simulation on IEEE test networks
demonstrates the effectiveness of the proposed methodology.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14500" title="Abstract">arXiv:2307.14500</a> [<a href="/pdf/2307.14500" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Predictive Model of Digital Information Engagement: Forecasting User  Engagement With English Words by Incorporating Cognitive Biases,  Computational Linguistics and Natural Language Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dvir%2C+N">Nimrod Dvir</a>, 
<a href="/search/cs?searchtype=author&query=Friedman%2C+E">Elaine Friedman</a>, 
<a href="/search/cs?searchtype=author&query=Commuri%2C+S">Suraj Commuri</a>, 
<a href="/search/cs?searchtype=author&query=yang%2C+F">Fan yang</a>, 
<a href="/search/cs?searchtype=author&query=Romano%2C+J">Jennifer Romano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">This study introduces and empirically tests a novel predictive model for
digital information engagement (IE) - the READ model, an acronym for the four
pivotal attributes of engaging information: Representativeness, Ease-of-use,
Affect, and Distribution. Conceptualized within the theoretical framework of
Cumulative Prospect Theory, the model integrates key cognitive biases with
computational linguistics and natural language processing to develop a
multidimensional perspective on information engagement. A rigorous testing
protocol was implemented, involving 50 randomly selected pairs of synonymous
words (100 words in total) from the WordNet database. These words' engagement
levels were evaluated through a large-scale online survey (n = 80,500) to
derive empirical IE metrics. The READ attributes for each word were then
computed and their predictive efficacy examined. The findings affirm the READ
model's robustness, accurately predicting a word's IE level and distinguishing
the more engaging word from a pair of synonyms with an 84% accuracy rate. The
READ model's potential extends across various domains, including business,
education, government, and healthcare, where it could enhance content
engagement and inform AI language model development and generative text work.
Future research should address the model's scalability and adaptability across
different domains and languages, thereby broadening its applicability and
efficacy.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14501" title="Abstract">arXiv:2307.14501</a> [<a href="/pdf/2307.14501" title="Download PDF">pdf</a>, <a href="/format/2307.14501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Reliable Navigation under Uncertainty via Predictions Informed  by Non-Local Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arnob%2C+R+I">Raihan Islam Arnob</a>, 
<a href="/search/cs?searchtype=author&query=Stein%2C+G+J">Gregory J. Stein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We improve reliable, long-horizon, goal-directed navigation in
partially-mapped environments by using non-locally available information to
predict the goodness of temporally-extended actions that enter unseen space.
Making predictions about where to navigate in general requires non-local
information: any observations the robot has seen so far may provide information
about the goodness of a particular direction of travel. Building on recent work
in learning-augmented model-based planning under uncertainty, we present an
approach that can both rely on non-local information to make predictions (via a
graph neural network) and is reliable by design: it will always reach its goal,
even when learning does not provide accurate predictions. We conduct
experiments in three simulated environments in which non-local information is
needed to perform well. In our large scale university building environment,
generated from real-world floorplans to the scale, we demonstrate a 9.3\%
reduction in cost-to-go compared to a non-learned baseline and a 14.9\%
reduction compared to a learning-informed planner that can only use local
information to inform its predictions.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14503" title="Abstract">arXiv:2307.14503</a> [<a href="/pdf/2307.14503" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shorter and faster than Sort3AlphaDev
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neri%2C+C">Cassio Neri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Arising from: Mankowitz, D.J., Michi, A., Zhernov, A. et al. Faster sorting
algorithms discovered using deep reinforcement learning.Nature 618, 257-263
(2023). doi.org/10.1038/s41586-023-06004-9.
<br />The article cited above presents new implementations of sorting algorithms
found through deep reinforcement learning that work on a small number of
numeric inputs. For 3 numbers, the published implementation contains 17
assembly instructions, and the authors state that no shorter program exists.
This note presents two counterexamples for this claim and a straightforward
C/C++ implementation that is faster than theirs.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14505" title="Abstract">arXiv:2307.14505</a> [<a href="/pdf/2307.14505" title="Download PDF">pdf</a>, <a href="/format/2307.14505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPICE Modeling of Memcomputing Logic Gates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pershin%2C+Y+V">Y. V. Pershin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn)

</div>
<p class="mathjax">Memcomputing logic gates generalize the traditional Boolean logic gates for
operation in the reverse direction. According to the literature, this
functionality enables the efficient solution of computationally-intensive
problems including factorization and NP-complete problems. To approach the
deployment of memcomputing gates in hardware, this paper introduces SPICE
models of memcomputing logic gates following their original definition. Using
these models, we demonstrate the behavior of single gates as well as small
self-organizing circuits. We also correct some inconsistencies in the prior
literature. Importantly, the correct schematics of dynamic correction module is
reported here for the first time. Our work makes memcomputing more accessible
to those who are interested in this emerging computing technology.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14507" title="Abstract">arXiv:2307.14507</a> [<a href="/pdf/2307.14507" title="Download PDF">pdf</a>, <a href="/format/2307.14507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Systematic Transmission With Fountain Parity Checks for Erasure Channels  With Stop Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hengjie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wesel%2C+R+D">Richard D. Wesel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, double column, 4 figures; comments are welcome! arXiv admin note: substantial text overlap with <a href="/abs/2205.15399">arXiv:2205.15399</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we present new achievability bounds on the maximal achievable
rate of variable-length stop-feedback (VLSF) codes operating over a binary
erasure channel (BEC) at a fixed message size $M = 2^k$. We provide new bounds
for VLSF codes with zero error, infinite decoding times and with nonzero error,
finite decoding times. Both new achievability bounds are proved by constructing
a new VLSF code that employs systematic transmission of the first $k$ bits
followed by random linear fountain parity bits decoded with a rank decoder. For
VLSF codes with infinite decoding times, our new bound outperforms the
state-of-the-art result for BEC by Devassy \emph{et al.} in 2016. We also give
a negative answer to the open question Devassy \emph{et al.} put forward on
whether the $23.4\%$ backoff to capacity at $k = 3$ is fundamental. For VLSF
codes with finite decoding times, numerical evaluations show that the
achievable rate for VLSF codes with a moderate number of decoding times closely
approaches that for VLSF codes with infinite decoding times.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14510" title="Abstract">arXiv:2307.14510</a> [<a href="/pdf/2307.14510" title="Download PDF">pdf</a>, <a href="/format/2307.14510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention of Robot Touch: Tactile Saliency Prediction for Robust  Sim-to-Real Tactile Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yijiong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Comi%2C+M">Mauro Comi</a>, 
<a href="/search/cs?searchtype=author&query=Church%2C+A">Alex Church</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dandan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lepora%2C+N+F">Nathan F. Lepora</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">High-resolution tactile sensing can provide accurate information about local
contact in contact-rich robotic tasks. However, the deployment of such tasks in
unstructured environments remains under-investigated. To improve the robustness
of tactile robot control in unstructured environments, we propose and study a
new concept: \textit{tactile saliency} for robot touch, inspired by the human
touch attention mechanism from neuroscience and the visual saliency prediction
problem from computer vision. In analogy to visual saliency, this concept
involves identifying key information in tactile images captured by a tactile
sensor. While visual saliency datasets are commonly annotated by humans,
manually labelling tactile images is challenging due to their counterintuitive
patterns. To address this challenge, we propose a novel approach comprised of
three interrelated networks: 1) a Contact Depth Network (ConDepNet), which
generates a contact depth map to localize deformation in a real tactile image
that contains target and noise features; 2) a Tactile Saliency Network
(TacSalNet), which predicts a tactile saliency map to describe the target areas
for an input contact depth map; 3) and a Tactile Noise Generator (TacNGen),
which generates noise features to train the TacSalNet. Experimental results in
contact pose estimation and edge-following in the presence of distractors
showcase the accurate prediction of target features from real tactile images.
Overall, our tactile saliency prediction approach gives robust sim-to-real
tactile control in environments with unknown distractors. Project page:
https://sites.google.com/view/tactile-saliency/.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14511" title="Abstract">arXiv:2307.14511</a> [<a href="/pdf/2307.14511" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Words That Stick: Predicting Decision Making and Synonym Engagement  Using Cognitive Biases and Computational Linguistics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dvir%2C+N">Nimrod Dvir</a>, 
<a href="/search/cs?searchtype=author&query=Friedman%2C+E">Elaine Friedman</a>, 
<a href="/search/cs?searchtype=author&query=Commuri%2C+S">Suraj Commuri</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Romano%2C+J">Jennifer Romano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">This research draws upon cognitive psychology and information systems studies
to anticipate user engagement and decision-making on digital platforms. By
employing natural language processing (NLP) techniques and insights from
cognitive bias research, we delve into user interactions with synonyms within
digital content. Our methodology synthesizes four cognitive
biasesRepresentativeness, Ease-of-use, Affect, and Distributioninto the READ
model. Through a comprehensive user survey, we assess the model's ability to
predict user engagement, discovering that synonyms that accurately represent
core ideas, are easy to understand, elicit emotional responses, and are
commonly encountered, promote greater user engagement. Crucially, our work
offers a fresh lens on human-computer interaction, digital behaviors, and
decision-making processes. Our results highlight the promise of cognitive
biases as potent indicators of user engagement, underscoring their significance
in designing effective digital content across fields like education and
marketing.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14512" title="Abstract">arXiv:2307.14512</a> [<a href="/pdf/2307.14512" title="Download PDF">pdf</a>, <a href="/format/2307.14512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bug Characterization in Machine Learning-based Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morovati%2C+M+M">Mohammad Mehdi Morovati</a>, 
<a href="/search/cs?searchtype=author&query=Nikanjam%2C+A">Amin Nikanjam</a>, 
<a href="/search/cs?searchtype=author&query=Tambon%2C+F">Florian Tambon</a>, 
<a href="/search/cs?searchtype=author&query=Khomh%2C+F">Foutse Khomh</a>, 
<a href="/search/cs?searchtype=author&query=Ming%2C+Z">Zhen Ming</a> (Jack)
<a href="/search/cs?searchtype=author&query=Jiang">Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Rapid growth of applying Machine Learning (ML) in different domains,
especially in safety-critical areas, increases the need for reliable ML
components, i.e., a software component operating based on ML. Understanding the
bugs characteristics and maintenance challenges in ML-based systems can help
developers of these systems to identify where to focus maintenance and testing
efforts, by giving insights into the most error-prone components, most common
bugs, etc. In this paper, we investigate the characteristics of bugs in
ML-based software systems and the difference between ML and non-ML bugs from
the maintenance viewpoint. We extracted 447,948 GitHub repositories that used
one of the three most popular ML frameworks, i.e., TensorFlow, Keras, and
PyTorch. After multiple filtering steps, we select the top 300 repositories
with the highest number of closed issues. We manually investigate the extracted
repositories to exclude non-ML-based systems. Our investigation involved a
manual inspection of 386 sampled reported issues in the identified ML-based
systems to indicate whether they affect ML components or not. Our analysis
shows that nearly half of the real issues reported in ML-based systems are ML
bugs, indicating that ML components are more error-prone than non-ML
components. Next, we thoroughly examined 109 identified ML bugs to identify
their root causes, symptoms, and calculate their required fixing time. The
results also revealed that ML bugs have significantly different characteristics
compared to non-ML bugs, in terms of the complexity of bug-fixing (number of
commits, changed files, and changed lines of code). Based on our results,
fixing ML bugs are more costly and ML components are more error-prone, compared
to non-ML bugs and non-ML components respectively. Hence, paying a significant
attention to the reliability of the ML components is crucial in ML-based
systems.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14517" title="Abstract">arXiv:2307.14517</a> [<a href="/pdf/2307.14517" title="Download PDF">pdf</a>, <a href="/format/2307.14517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Co-12 Recipe for Evaluating Interpretable Part-Prototype Image  Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nauta%2C+M">Meike Nauta</a>, 
<a href="/search/cs?searchtype=author&query=Seifert%2C+C">Christin Seifert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 1 image, accepted at the 1st World Conference on eXplainable Artificial Intelligence (xAI 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Interpretable part-prototype models are computer vision models that are
explainable by design. The models learn prototypical parts and recognise these
components in an image, thereby combining classification and explanation.
Despite the recent attention for intrinsically interpretable models, there is
no comprehensive overview on evaluating the explanation quality of
interpretable part-prototype models. Based on the Co-12 properties for
explanation quality as introduced in <a href="/abs/2201.08164">arXiv:2201.08164</a> (e.g., correctness,
completeness, compactness), we review existing work that evaluates
part-prototype models, reveal research gaps and outline future approaches for
evaluation of the explanation quality of part-prototype models. This paper,
therefore, contributes to the progression and maturity of this relatively new
research field on interpretable part-prototype models. We additionally provide
a ``Co-12 cheat sheet'' that acts as a concise summary of our findings on
evaluating part-prototype models.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14521" title="Abstract">arXiv:2307.14521</a> [<a href="/pdf/2307.14521" title="Download PDF">pdf</a>, <a href="/format/2307.14521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Patterns of Vehicle Lights: Addressing Complexities in Curation and  Annotation of Camera-Based Vehicle Light Datasets and Metrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Greer%2C+R">Ross Greer</a>, 
<a href="/search/cs?searchtype=author&query=Gopalkrishnan%2C+A">Akshay Gopalkrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Keskar%2C+M">Maitrayee Keskar</a>, 
<a href="/search/cs?searchtype=author&query=Trivedi%2C+M">Mohan Trivedi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper explores the representation of vehicle lights in computer vision
and its implications for various tasks in the field of autonomous driving.
Different specifications for representing vehicle lights, including bounding
boxes, center points, corner points, and segmentation masks, are discussed in
terms of their strengths and weaknesses. Three important tasks in autonomous
driving that can benefit from vehicle light detection are identified: nighttime
vehicle detection, 3D vehicle orientation estimation, and dynamic trajectory
cues. Each task may require a different representation of the light. The
challenges of collecting and annotating large datasets for training data-driven
models are also addressed, leading to introduction of the LISA Vehicle Lights
Dataset and associated Light Visibility Model, which provides light annotations
specifically designed for downstream applications in vehicle detection, intent
and trajectory prediction, and safe path planning. A comparison of existing
vehicle light datasets is provided, highlighting the unique features and
limitations of each dataset. Overall, this paper provides insights into the
representation of vehicle lights and the importance of accurate annotations for
training effective detection models in autonomous driving applications. Our
dataset and model are made available at
https://cvrr.ucsd.edu/vehicle-lights-dataset
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14522" title="Abstract">arXiv:2307.14522</a> [<a href="/pdf/2307.14522" title="Download PDF">pdf</a>, <a href="/format/2307.14522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CliniDigest: A Case Study in Large Language Model Based Large-Scale  Summarization of Clinical Trial Descriptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=White%2C+R+D">Renee D. White</a> (1), 
<a href="/search/cs?searchtype=author&query=Peng%2C+T">Tristan Peng</a> (1), 
<a href="/search/cs?searchtype=author&query=Sripitak%2C+P">Pann Sripitak</a> (1), 
<a href="/search/cs?searchtype=author&query=Johansen%2C+A+R">Alexander Rosenberg Johansen</a> (1), 
<a href="/search/cs?searchtype=author&query=Snyder%2C+M">Michael Snyder</a> (1) (1)
<a href="/search/cs?searchtype=author&query=University%2C+S">Stanford University</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures, 3 tables, conference: ACM GoodIt 23'
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">A clinical trial is a study that evaluates new biomedical interventions. To
design new trials, researchers draw inspiration from those current and
completed. In 2022, there were on average more than 100 clinical trials
submitted to ClinicalTrials.gov every day, with each trial having a mean of
approximately 1500 words [1]. This makes it nearly impossible to keep up to
date. To mitigate this issue, we have created a batch clinical trial summarizer
called CliniDigest using GPT-3.5. CliniDigest is, to our knowledge, the first
tool able to provide real-time, truthful, and comprehensive summaries of
clinical trials. CliniDigest can reduce up to 85 clinical trial descriptions
(approximately 10,500 words) into a concise 200-word summary with references
and limited hallucinations. We have tested CliniDigest on its ability to
summarize 457 trials divided across 27 medical subdomains. For each field,
CliniDigest generates summaries of $\mu=153,\ \sigma=69 $ words, each of which
utilizes $\mu=54\%,\ \sigma=30\% $ of the sources. A more comprehensive
evaluation is planned and outlined in this paper.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14523" title="Abstract">arXiv:2307.14523</a> [<a href="/pdf/2307.14523" title="Download PDF">pdf</a>, <a href="/format/2307.14523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards multi-modal anatomical landmark detection for ultrasound-guided  brain tumor resection with contrastive learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salari%2C+S">Soorena Salari</a>, 
<a href="/search/cs?searchtype=author&query=Rasoulian%2C+A">Amirhossein Rasoulian</a>, 
<a href="/search/cs?searchtype=author&query=Rivaz%2C+H">Hassan Rivaz</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yiming Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Homologous anatomical landmarks between medical scans are instrumental in
quantitative assessment of image registration quality in various clinical
applications, such as MRI-ultrasound registration for tissue shift correction
in ultrasound-guided brain tumor resection. While manually identified landmark
pairs between MRI and ultrasound (US) have greatly facilitated the validation
of different registration algorithms for the task, the procedure requires
significant expertise, labor, and time, and can be prone to inter- and
intra-rater inconsistency. So far, many traditional and machine learning
approaches have been presented for anatomical landmark detection, but they
primarily focus on mono-modal applications. Unfortunately, despite the clinical
needs, inter-modal/contrast landmark detection has very rarely been attempted.
Therefore, we propose a novel contrastive learning framework to detect
corresponding landmarks between MRI and intra-operative US scans in
neurosurgery. Specifically, two convolutional neural networks were trained
jointly to encode image features in MRI and US scans to help match the US image
patch that contain the corresponding landmarks in the MRI. We developed and
validated the technique using the public RESECT database. With a mean landmark
detection accuracy of 5.88+-4.79 mm against 18.78+-4.77 mm with SIFT features,
the proposed method offers promising results for MRI-US landmark detection in
neurosurgical applications for the first time.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14527" title="Abstract">arXiv:2307.14527</a> [<a href="/pdf/2307.14527" title="Download PDF">pdf</a>, <a href="/format/2307.14527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open Problems in Computer Vision for Wilderness SAR and The Search for  Patricia Wu-Murad
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manzini%2C+T">Thomas Manzini</a>, 
<a href="/search/cs?searchtype=author&query=Murphy%2C+R">Robin Murphy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper details the challenges in applying two computer vision systems, an
EfficientDET supervised learning model and the unsupervised RX spectral
classifier, to 98.9 GB of drone imagery from the Wu-Murad wilderness search and
rescue (WSAR) effort in Japan and identifies 3 directions for future research.
There have been at least 19 proposed approaches and 3 datasets aimed at
locating missing persons in drone imagery, but only 3 approaches (2
unsupervised and 1 of an unknown structure) are referenced in the literature as
having been used in an actual WSAR operation. Of these proposed approaches, the
EfficientDET architecture and the unsupervised spectral RX classifier were
selected as the most appropriate for this setting. The EfficientDET model was
applied to the HERIDAL dataset and despite achieving performance that is
statistically equivalent to the state-of-the-art, the model fails to translate
to the real world in terms of false positives (e.g., identifying tree limbs and
rocks as people), and false negatives (e.g., failing to identify members of the
search team). The poor results in practice for algorithms that showed good
results on datasets suggest 3 areas of future research: more realistic datasets
for wilderness SAR, computer vision models that are capable of seamlessly
handling the variety of imagery that can be collected during actual WSAR
operations, and better alignment on performance measures.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14528" title="Abstract">arXiv:2307.14528</a> [<a href="/pdf/2307.14528" title="Download PDF">pdf</a>, <a href="/format/2307.14528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Function Value Learning: Adaptive Learning Rates Based on the Polyak  Stepsize and Function Splitting in ERM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garrigos%2C+G">Guillaume Garrigos</a>, 
<a href="/search/cs?searchtype=author&query=Gower%2C+R+M">Robert M. Gower</a>, 
<a href="/search/cs?searchtype=author&query=Schaipp%2C+F">Fabian Schaipp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Here we develop variants of SGD (stochastic gradient descent) with an
adaptive step size that make use of the sampled loss values. In particular, we
focus on solving a finite sum-of-terms problem, also known as empirical risk
minimization. We first detail an idealized adaptive method called
$\texttt{SPS}_+$ that makes use of the sampled loss values and assumes
knowledge of the sampled loss at optimality. This $\texttt{SPS}_+$ is a minor
modification of the SPS (Stochastic Polyak Stepsize) method, where the step
size is enforced to be positive. We then show that $\texttt{SPS}_+$ achieves
the best known rates of convergence for SGD in the Lipschitz non-smooth. We
then move onto to develop $\texttt{FUVAL}$, a variant of $\texttt{SPS}_+$ where
the loss values at optimality are gradually learned, as opposed to being given.
We give three viewpoints of $\texttt{FUVAL}$, as a projection based method, as
a variant of the prox-linear method, and then as a particular online SGD
method. We then present a convergence analysis of $\texttt{FUVAL}$ and
experimental results. The shortcomings of our work is that the convergence
analysis of $\texttt{FUVAL}$ shows no advantage over SGD. Another shortcomming
is that currently only the full batch version of $\texttt{FUVAL}$ shows a minor
advantages of GD (Gradient Descent) in terms of sensitivity to the step size.
The stochastic version shows no clear advantage over SGD. We conjecture that
large mini-batches are required to make $\texttt{FUVAL}$ competitive.
<br />Currently the new $\texttt{FUVAL}$ method studied in this paper does not
offer any clear theoretical or practical advantage. We have chosen to make this
draft available online nonetheless because of some of the analysis techniques
we use, such as the non-smooth analysis of $\texttt{SPS}_+$, and also to show
an apparently interesting approach that currently does not work.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14531" title="Abstract">arXiv:2307.14531</a> [<a href="/pdf/2307.14531" title="Download PDF">pdf</a>, <a href="/format/2307.14531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controlling the Inductive Bias of Wide Neural Networks by Modifying the  Kernel&#x27;s Spectrum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geifman%2C+A">Amnon Geifman</a>, 
<a href="/search/cs?searchtype=author&query=Barzilai%2C+D">Daniel Barzilai</a>, 
<a href="/search/cs?searchtype=author&query=Basri%2C+R">Ronen Basri</a>, 
<a href="/search/cs?searchtype=author&query=Galun%2C+M">Meirav Galun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Wide neural networks are biased towards learning certain functions,
influencing both the rate of convergence of gradient descent (GD) and the
functions that are reachable with GD in finite training time. As such, there is
a great need for methods that can modify this bias according to the task at
hand. To that end, we introduce Modified Spectrum Kernels (MSKs), a novel
family of constructed kernels that can be used to approximate kernels with
desired eigenvalues for which no closed form is known. We leverage the duality
between wide neural networks and Neural Tangent Kernels and propose a
preconditioned gradient descent method, which alters the trajectory of GD. As a
result, this allows for a polynomial and, in some cases, exponential training
speedup without changing the final solution. Our method is both computationally
efficient and simple to implement.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14532" title="Abstract">arXiv:2307.14532</a> [<a href="/pdf/2307.14532" title="Download PDF">pdf</a>, <a href="/ps/2307.14532" title="Download PostScript">ps</a>, <a href="/format/2307.14532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of syndrome-based iterative decoder failure of QLDPC codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morris%2C+K+D">Kirsten D. Morris</a>, 
<a href="/search/cs?searchtype=author&query=Pllaha%2C+T">Tefjol Pllaha</a>, 
<a href="/search/cs?searchtype=author&query=Kelley%2C+C+A">Christine A. Kelley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Iterative decoder failures of quantum low density parity check (QLDPC) codes
are attributed to substructures in the code's graph, known as trapping sets, as
well as degenerate errors that can arise in quantum codes. Failure inducing
sets are subsets of codeword coordinates that, when initially in error, lead to
decoding failure in a trapping set. In this paper we examine the failure
inducing sets of QLDPC codes under syndrome-based iterative decoding, and their
connecting to absorbing sets in classical LDPC codes.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14535" title="Abstract">arXiv:2307.14535</a> [<a href="/pdf/2307.14535" title="Download PDF">pdf</a>, <a href="/format/2307.14535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Up and Distilling Down: Language-Guided Robot Skill Acquisition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ha%2C+H">Huy Ha</a>, 
<a href="/search/cs?searchtype=author&query=Florence%2C+P">Pete Florence</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shuran Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 9 figures, videos and code links on website <a href="https://www.cs.columbia.edu/~huy/scalingup/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present a framework for robot skill acquisition, which 1) efficiently
scale up data generation of language-labelled robot data and 2) effectively
distills this data down into a robust multi-task language-conditioned
visuo-motor policy. For (1), we use a large language model (LLM) to guide
high-level planning, and sampling-based robot planners (e.g. motion or grasp
samplers) for generating diverse and rich manipulation trajectories. To
robustify this data-collection process, the LLM also infers a code-snippet for
the success condition of each task, simultaneously enabling the data-collection
process to detect failure and retry as well as the automatic labeling of
trajectories with success/failure. For (2), we extend the diffusion policy
single-task behavior-cloning approach to multi-task settings with language
conditioning. Finally, we propose a new multi-task benchmark with 18 tasks
across five domains to test long-horizon behavior, common-sense reasoning,
tool-use, and intuitive physics. We find that our distilled policy successfully
learned the robust retrying behavior in its data collection policy, while
improving absolute success rates by 34.8% on average across five domains. The
benchmark, code, and qualitative results are on our website
https://www.cs.columbia.edu/~huy/scalingup/
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14539" title="Abstract">arXiv:2307.14539</a> [<a href="/pdf/2307.14539" title="Download PDF">pdf</a>, <a href="/format/2307.14539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Plug and Pray: Exploiting off-the-shelf components of Multi-Modal Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shayegani%2C+E">Erfan Shayegani</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yue Dong</a>, 
<a href="/search/cs?searchtype=author&query=Abu-Ghazaleh%2C+N">Nael Abu-Ghazaleh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The rapid growth and increasing popularity of incorporating additional
modalities (e.g., vision) into large language models (LLMs) has raised
significant security concerns. This expansion of modality, akin to adding more
doors to a house, unintentionally creates multiple access points for
adversarial attacks. In this paper, by introducing adversarial embedding space
attacks, we emphasize the vulnerabilities present in multi-modal systems that
originate from incorporating off-the-shelf components like public pre-trained
encoders in a plug-and-play manner into these systems. In contrast to existing
work, our approach does not require access to the multi-modal system's weights
or parameters but instead relies on the huge under-explored embedding space of
such pre-trained encoders. Our proposed embedding space attacks involve seeking
input images that reside within the dangerous or targeted regions of the
extensive embedding space of these pre-trained components. These crafted
adversarial images pose two major threats: 'Context Contamination' and 'Hidden
Prompt Injection'-both of which can compromise multi-modal models like LLaVA
and fully change the behavior of the associated language model. Our findings
emphasize the need for a comprehensive examination of the underlying
components, particularly pre-trained encoders, before incorporating them into
systems in a plug-and-play manner to ensure robust security.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14540" title="Abstract">arXiv:2307.14540</a> [<a href="/pdf/2307.14540" title="Download PDF">pdf</a>, <a href="/format/2307.14540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lateral-Direction Localization Attack in High-Level Autonomous Driving:  Domain-Specific Defense Opportunity via Lane Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Junjie Shen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yunpeng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Ziwen Wan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q+A">Qi Alfred Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Localization in high-level Autonomous Driving (AD) systems is highly security
critical. While the popular Multi-Sensor Fusion (MSF) based design can be more
robust against single-source sensor spoofing attacks, it is found recently that
state-of-the-art MSF algorithms is vulnerable to GPS spoofing alone due to
practical factors, which can cause various road hazards such as driving off
road or onto the wrong way. In this work, we perform the first systematic
exploration of the novel usage of lane detection (LD) to defend against such
attacks. We first systematically analyze the potentials of such a
domain-specific defense opportunity, and then design a novel LD-based defense
approach, $LD^3$, that aims at not only detecting such attacks effectively in
the real time, but also safely stopping the victim in the ego lane upon
detection considering the absence of onboard human drivers.
<br />We evaluate $LD^3$ on real-world sensor traces and find that it can achieve
effective and timely detection against existing attack with 100% true positive
rates and 0% false positive rates. Results also show that $LD^3$ is robust to
diverse environmental conditions and is effective at steering the AD vehicle to
safely stop within the current traffic lane. We implement $LD^3$ on two
open-source high-level AD systems, Baidu Apollo and Autoware, and validate its
defense capability in both simulation and the physical world in end-to-end
driving. We further conduct adaptive attack evaluations and find that $LD^3$ is
effective at bounding the deviations from reaching the attack goals in stealthy
attacks and is robust to latest LD-side attack.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14541" title="Abstract">arXiv:2307.14541</a> [<a href="/pdf/2307.14541" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Novel BCI paradigm for ALS patients based on EEG and Pupillary  Accommodative Response
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%27Adamo%2C+D">Davide D&#x27;Adamo</a>, 
<a href="/search/cs?searchtype=author&query=Robert%2C+E">Emiliano Robert</a>, 
<a href="/search/cs?searchtype=author&query=Gena%2C+C">Cristina Gena</a>, 
<a href="/search/cs?searchtype=author&query=Roatta%2C+S">Silvestro Roatta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Brain-computer interfaces (BCIs) are one of the few alternatives to enable
locked-in syndrome (LIS) patients to communicate with the external world, while
they are the only solution for complete locked-in syndrome (CLIS) patients, who
lost the ability to control eye movements. However, successful usage of
endogenous electroencephalogram(EEG)-based BCI applications is often not
trivial, due to EEG variations between and within sessions and long user
training required. In this work we suggest an approach to deal with this two
main limitations of EEG-BCIs by inserting a progressive and expandable
neurofeedback training program, able to continuously tailor the classifier to
the specific user, into a multimodal BCI paradigm. We propose indeed the
integration of EEG with a non-brain signal: the pupillary accommodative
response (PAR). The PAR is a change in pupil size associated with gaze shifts
from far to close targets; it is not governed by the somatic nervous system and
is thus potentially preserved after the evolution from LIS to CLIS, which often
occurs in neurodegenerative diseases, such as amyotrophic lateral sclerosis.
Multimodal BCIs have been broadly investigated in literature, due to their
ability to yield better overall control performances, but this would be the
first attempt combining EEG and PAR. In the context of the BciPar4Sla, we are
exploiting these two signals, with the aim of developing a more reliable BCI,
adaptive to the extent of evolving together with the user's ability to elicit
the brain phenomena needed for optimal control, and providing support even in
the transition from LIS to CLIS.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14544" title="Abstract">arXiv:2307.14544</a> [<a href="/pdf/2307.14544" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speed Reading Tool Powered by Artificial Intelligence for Students with  ADHD, Dyslexia, or Short Attention Span
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kamarozaman%2C+M+I+Z+B+I+A+N+b+Y+M+H+B+A+M+M+M+B">Megat Irfan Zackry Bin Ismail Ahmad Nazran bin Yusri Muhammad Hafizzul Bin Abdul Manap Muhammad Muizzuddin Bin Kamarozaman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents a novel approach to assist students with dyslexia, ADHD,
and short attention span in digesting any text-based information more
efficiently. The proposed solution utilizes the Multilayer Perceptron (MLP)
algorithm for complex text processing and summarization tasks. The tool
leverages the T5 (Text-to-Text Transfer Transformer) model from Hugging Face,
which treats every NLP task as a text generation task. The model is fine-tuned
on specific tasks using a smaller dataset. The NLTK's Punkt Sentence Tokenizer
is used to divide a text into a list of sentences. The application is served
using Flask, a lightweight web server and framework. The tool also applies
principles from Bionic Reading to enhance readability, which includes a bolding
function and adjustments to line, word, and character spacing. The paper
discusses the methodology, implementation, and results of the AI-based speed
reading tool.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14549" title="Abstract">arXiv:2307.14549</a> [<a href="/pdf/2307.14549" title="Download PDF">pdf</a>, <a href="/format/2307.14549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Sleeping Bandit Problems with Multiple Plays: Algorithm and  Ranking Application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jianjun Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Woon%2C+W+L">Wei Lee Woon</a>, 
<a href="/search/cs?searchtype=author&query=Coba%2C+L">Ludovik Coba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by RecSys 2023 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents an efficient algorithm to solve the sleeping bandit with
multiple plays problem in the context of an online recommendation system. The
problem involves bounded, adversarial loss and unknown i.i.d. distributions for
arm availability. The proposed algorithm extends the sleeping bandit algorithm
for single arm selection and is guaranteed to achieve theoretical performance
with regret upper bounded by $\bigO(kN^2\sqrt{T\log T})$, where $k$ is the
number of arms selected per time step, $N$ is the total number of arms, and $T$
is the time horizon.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14551" title="Abstract">arXiv:2307.14551</a> [<a href="/pdf/2307.14551" title="Download PDF">pdf</a>, <a href="/ps/2307.14551" title="Download PostScript">ps</a>, <a href="/format/2307.14551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Train Your YouTube Recommender
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Alexander Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Siqi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Resnick%2C+P">Paul Resnick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">YouTube provides features for users to indicate disinterest when presented
with unwanted recommendations, such as the ``Not interested'' and ``Don\'t
recommend channel'' buttons. These buttons are purported to allow the user to
correct ``mistakes'' made by the recommendation system. Yet, relatively little
is known about the empirical efficacy of these buttons. Neither is much known
about users' awareness of and confidence in them. To address these gaps, we
simulated YouTube users with sock puppet agents. Each agent first executed a
``stain phase'', where it watched many videos of one assigned topic; then it
executed a ``scrub phase'', where it tried to remove recommendations of the
assigned topic. Each agent repeatedly applied a single scrubbing strategy,
which included disliking previously-watched videos or deleting them from watch
history, as well as clicking the ``not interested'' or ``don\'t recommend
channel'' button on newly-recommended videos. Overall, we found that the stain
phase significantly increased the fraction of the recommended videos on the
user\'s homepage dedicated to the assigned topic. For the scrub phase, using
the ``Not interested'' button worked best, significantly reducing such
recommendations in all topics tested, on average removing 88\% of them. Neither
the stain phase nor the scrub phase, however, had much effect on videopage
recommendations (those given to users while they watch a video). We also ran a
survey ($N$ =300) asking adult YouTube users in the US whether they were aware
of and used these buttons before, as well as how effective they found these
buttons to be. We found that 44\% of participants were not aware that the ``Not
interested'' button existed. However, those who were aware of this button often
used it to remove unwanted recommendations (82.8\%) and found it to be modestly
effective (3.42 out of 5).
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14556" title="Abstract">arXiv:2307.14556</a> [<a href="/pdf/2307.14556" title="Download PDF">pdf</a>, <a href="/format/2307.14556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement learning guided fuzz testing for a browser&#x27;s HTML  rendering engine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sablotny%2C+M">Martin Sablotny</a>, 
<a href="/search/cs?searchtype=author&query=Jensen%2C+B+S">Bj&#xf8;rn Sand Jensen</a>, 
<a href="/search/cs?searchtype=author&query=Singer%2C+J">Jeremy Singer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Generation-based fuzz testing can uncover various bugs and security
vulnerabilities. However, compared to mutation-based fuzz testing, it takes
much longer to develop a well-balanced generator that produces good test cases
and decides where to break the underlying structure to exercise new code paths.
We propose a novel approach to combine a trained test case generator deep
learning model with a double deep Q-network (DDQN) for the first time. The DDQN
guides test case creation based on a code coverage signal. Our approach
improves the code coverage performance of the underlying generator model by up
to 18.5\% for the Firefox HTML rendering engine compared to the baseline
grammar based fuzzer.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14557" title="Abstract">arXiv:2307.14557</a> [<a href="/pdf/2307.14557" title="Download PDF">pdf</a>, <a href="/format/2307.14557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Polynomial Modular Multiplication with Crossbar-Based  Compute-in-Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+H">Haoran Geng</a>, 
<a href="/search/cs?searchtype=author&query=Niemier%2C+M">Michael Niemier</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X+S">Xiaobo Sharon Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 42nd International Conference on Computer-Aided Design (ICCAD)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Lattice-based cryptographic algorithms built on ring learning with error
theory are gaining importance due to their potential for providing post-quantum
security. However, these algorithms involve complex polynomial operations, such
as polynomial modular multiplication (PMM), which is the most time-consuming
part of these algorithms. Accelerating PMM is crucial to make lattice-based
cryptographic algorithms widely adopted by more applications. This work
introduces a novel high-throughput and compact PMM accelerator, X-Poly, based
on the crossbar (XB)-type compute-in-memory (CIM). We identify the most
appropriate PMM algorithm for XB-CIM. We then propose a novel bit-mapping
technique to reduce the area and energy of the XB-CIM fabric, and conduct
processing engine (PE)-level optimization to increase memory utilization and
support different problem sizes with a fixed number of XB arrays. X-Poly design
achieves 3.1X10^6 PMM operations/s throughput and offers 200X latency
improvement compared to the CPU-based implementation. It also achieves 3.9X
throughput per area improvement compared with the state-of-the-art CIM
accelerators.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14565" title="Abstract">arXiv:2307.14565</a> [<a href="/pdf/2307.14565" title="Download PDF">pdf</a>, <a href="/format/2307.14565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auto-Tables: Synthesizing Multi-Step Transformations to Relationalize  Tables without Using Examples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peng Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yeye He</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+C">Cong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chauduri%2C+S">Surajit Chauduri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> full version of a paper accepted to VLDB 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Relational tables, where each row corresponds to an entity and each column
corresponds to an attribute, have been the standard for tables in relational
databases. However, such a standard cannot be taken for granted when dealing
with tables "in the wild". Our survey of real spreadsheet-tables and web-tables
shows that over 30% of such tables do not conform to the relational standard,
for which complex table-restructuring transformations are needed before these
tables can be queried easily using SQL-based analytics tools. Unfortunately,
the required transformations are non-trivial to program, which has become a
substantial pain point for technical and non-technical users alike, as
evidenced by large numbers of forum questions in places like StackOverflow and
Excel/Tableau forums.
<br />We develop an Auto-Tables system that can automatically synthesize pipelines
with multi-step transformations (in Python or other languages), to transform
non-relational tables into standard relational forms for downstream analytics,
obviating the need for users to manually program transformations. We compile an
extensive benchmark for this new task, by collecting 194 real test cases from
user spreadsheets and online forums. Our evaluation suggests that Auto-Tables
can successfully synthesize transformations for over 70% of test cases at
interactive speeds, without requiring any input from users, making this an
effective tool for both technical and non-technical users to prepare data for
analytics.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14566" title="Abstract">arXiv:2307.14566</a> [<a href="/pdf/2307.14566" title="Download PDF">pdf</a>, <a href="/ps/2307.14566" title="Download PostScript">ps</a>, <a href="/format/2307.14566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Limiting Moments of Autocorrelation Demerit Factors of Binary Sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Katz%2C+D+J">Daniel J. Katz</a>, 
<a href="/search/cs?searchtype=author&query=Ramirez%2C+M+E">Miriam E. Ramirez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Discrete Mathematics (cs.DM); Signal Processing (eess.SP); Combinatorics (math.CO); Probability (math.PR)

</div>
<p class="mathjax">An aperiodic binary sequence of length $\ell$ is written as
$f=\ldots,f_{-1},f_0,f_1,\ldots$ with $f_j \in \{-1,1\}$ when $0 \leq j &lt; \ell$
and and $f_j=0$ otherwise. Various problems in engineering and natural science
demand binary sequences that do not resemble translates of themselves. The
autocorrelation of $f$ at shift $s$ is the inner product of $f$ with the
sequence obtained by translating $f$ by $s$ places. The demerit factor of $f$
is the sum of the squares of the autocorrelations at all nonzero shifts for the
sequence obtained by normalizing $f$ to unit Euclidean norm. Low demerit factor
therefore indicates low self-similarity under translation. We endow the
$2^\ell$ binary sequences of length $\ell$ with uniform probability measure and
consider the distribution of their demerit factors. Earlier works used
combinatorial techniques to find exact formulas for the mean, variance, and
skewness of the distribution as a function of $\ell$. These revealed that for
$\ell \geq 4$, the $p$th central moment of this distribution is positive for
every $p \geq 2$. This article shows that every $p$th central moment is a
quasi-polynomial function of $\ell$ with rational coefficients divided by
$\ell^{2 p}$. It also shows that, in the limit as $\ell$ tends to infinity, the
$p$th standardized moment is the same as that of the standard normal
distribution.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14568" title="Abstract">arXiv:2307.14568</a> [<a href="/pdf/2307.14568" title="Download PDF">pdf</a>, <a href="/format/2307.14568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of Safety Constraints in Autonomous Navigation with Deep  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Angulo%2C+B">Brian Angulo</a>, 
<a href="/search/cs?searchtype=author&query=Gorbov%2C+G">Gregory Gorbov</a>, 
<a href="/search/cs?searchtype=author&query=Panov%2C+A">Aleksandr Panov</a>, 
<a href="/search/cs?searchtype=author&query=Yakovlev%2C+K">Konstantin Yakovlev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">While reinforcement learning algorithms have had great success in the field
of autonomous navigation, they cannot be straightforwardly applied to the real
autonomous systems without considering the safety constraints. The later are
crucial to avoid unsafe behaviors of the autonomous vehicle on the road. To
highlight the importance of these constraints, in this study, we compare two
learnable navigation policies: safe and unsafe. The safe policy takes the
constraints into account, while the other does not. We show that the safe
policy is able to generate trajectories with more clearance (distance to the
obstacles) and makes less collisions while training without sacrificing the
overall performance.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14570" title="Abstract">arXiv:2307.14570</a> [<a href="/pdf/2307.14570" title="Download PDF">pdf</a>, <a href="/format/2307.14570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physically Plausible 3D Human-Scene Reconstruction from Monocular RGB  Image using an Adversarial Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biswas%2C+S">Sandika Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kejie Li</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+B">Biplab Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhuri%2C+S">Subhasis Chaudhuri</a>, 
<a href="/search/cs?searchtype=author&query=Rezatofighi%2C+H">Hamid Rezatofighi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in RAL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Holistic 3D human-scene reconstruction is a crucial and emerging research
area in robot perception. A key challenge in holistic 3D human-scene
reconstruction is to generate a physically plausible 3D scene from a single
monocular RGB image. The existing research mainly proposes optimization-based
approaches for reconstructing the scene from a sequence of RGB frames with
explicitly defined physical laws and constraints between different scene
elements (humans and objects). However, it is hard to explicitly define and
model every physical law in every scenario. This paper proposes using an
implicit feature representation of the scene elements to distinguish a
physically plausible alignment of humans and objects from an implausible one.
We propose using a graph-based holistic representation with an encoded physical
representation of the scene to analyze the human-object and object-object
interactions within the scene. Using this graphical representation, we
adversarially train our model to learn the feasible alignments of the scene
elements from the training data itself without explicitly defining the laws and
constraints between them. Unlike the existing inference-time optimization-based
approaches, we use this adversarially trained model to produce a per-frame 3D
reconstruction of the scene that abides by the physical laws and constraints.
Our learning-based method achieves comparable 3D reconstruction quality to
existing optimization-based holistic human-scene reconstruction methods and
does not need inference time optimization. This makes it better suited when
compared to existing methods, for potential use in robotic applications, such
as robot navigation, etc.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14571" title="Abstract">arXiv:2307.14571</a> [<a href="/pdf/2307.14571" title="Download PDF">pdf</a>, <a href="/format/2307.14571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Detection, Assocation, and Localization of Vehicle Lights: A  Context-Based Cascaded CNN Approach and Evaluations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gopalkrishnan%2C+A">Akshay Gopalkrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Greer%2C+R">Ross Greer</a>, 
<a href="/search/cs?searchtype=author&query=Keskar%2C+M">Maitrayee Keskar</a>, 
<a href="/search/cs?searchtype=author&query=Trivedi%2C+M">Mohan Trivedi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vehicle light detection is required for important downstream safe autonomous
driving tasks, such as predicting a vehicle's light state to determine if the
vehicle is making a lane change or turning. Currently, many vehicle light
detectors use single-stage detectors which predict bounding boxes to identify a
vehicle light, in a manner decoupled from vehicle instances. In this paper, we
present a method for detecting a vehicle light given an upstream vehicle
detection and approximation of a visible light's center. Our method predicts
four approximate corners associated with each vehicle light. We experiment with
CNN architectures, data augmentation, and contextual preprocessing methods
designed to reduce surrounding-vehicle confusion. We achieve an average
distance error from the ground truth corner of 5.09 pixels, about 17.24% of the
size of the vehicle light on average. We train and evaluate our model on the
LISA Lights dataset, allowing us to thoroughly evaluate our vehicle light
corner detection model on a large variety of vehicle light shapes and lighting
conditions. We propose that this model can be integrated into a pipeline with
vehicle detection and vehicle light center detection to make a fully-formed
vehicle light detection network, valuable to identifying trajectory-informative
signals in driving scenes.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14575" title="Abstract">arXiv:2307.14575</a> [<a href="/pdf/2307.14575" title="Download PDF">pdf</a>, <a href="/format/2307.14575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Memory-Augmented Multi-Task Collaborative Framework for Unsupervised  Traffic Accident Detection in Driving Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+R">Rongqin Liang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanman Li</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+Y">Yingxin Yi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiantao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xia Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12pages,5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Identifying traffic accidents in driving videos is crucial to ensuring the
safety of autonomous driving and driver assistance systems. To address the
potential danger caused by the long-tailed distribution of driving events,
existing traffic accident detection (TAD) methods mainly rely on unsupervised
learning. However, TAD is still challenging due to the rapid movement of
cameras and dynamic scenes in driving scenarios. Existing unsupervised TAD
methods mainly rely on a single pretext task, i.e., an appearance-based or
future object localization task, to detect accidents. However, appearance-based
approaches are easily disturbed by the rapid movement of the camera and changes
in illumination, which significantly reduce the performance of traffic accident
detection. Methods based on future object localization may fail to capture
appearance changes in video frames, making it difficult to detect ego-involved
accidents (e.g., out of control of the ego-vehicle). In this paper, we propose
a novel memory-augmented multi-task collaborative framework (MAMTCF) for
unsupervised traffic accident detection in driving videos. Different from
previous approaches, our method can more accurately detect both ego-involved
and non-ego accidents by simultaneously modeling appearance changes and object
motions in video frames through the collaboration of optical flow
reconstruction and future object localization tasks. Further, we introduce a
memory-augmented motion representation mechanism to fully explore the
interrelation between different types of motion representations and exploit the
high-level features of normal traffic patterns stored in memory to augment
motion representations, thus enlarging the difference from anomalies.
Experimental results on recently published large-scale dataset demonstrate that
our method achieves better performance compared to previous state-of-the-art
approaches.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14578" title="Abstract">arXiv:2307.14578</a> [<a href="/pdf/2307.14578" title="Download PDF">pdf</a>, <a href="/format/2307.14578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GADER: GAit DEtection and Recognition in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuxiang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Cheng Peng</a>, 
<a href="/search/cs?searchtype=author&query=Prabhakar%2C+R">Ram Prabhakar</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+C+P">Chun Pong Lau</a>, 
<a href="/search/cs?searchtype=author&query=Chellappa%2C+R">Rama Chellappa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Gait recognition holds the promise of robustly identifying subjects based on
their walking patterns instead of color information. While previous approaches
have performed well for curated indoor scenes, they have significantly impeded
applicability in unconstrained situations, e.g. outdoor, long distance scenes.
We propose an end-to-end GAit DEtection and Recognition (GADER) algorithm for
human authentication in challenging outdoor scenarios. Specifically, GADER
leverages a Double Helical Signature to detect the fragment of human movement
and incorporates a novel gait recognition method, which learns representations
by distilling from an auxiliary RGB recognition model. At inference time, GADER
only uses the silhouette modality but benefits from a more robust
representation. Extensive experiments on indoor and outdoor datasets
demonstrate that the proposed method outperforms the State-of-The-Arts for gait
recognition and verification, with a significant 20.6% improvement on
unconstrained, long distance scenes.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14579" title="Abstract">arXiv:2307.14579</a> [<a href="/pdf/2307.14579" title="Download PDF">pdf</a>, <a href="/format/2307.14579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Representation-Based Method for Metal-induced Artifact Reduction  in Dental CBCT Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+H+S">Hyoung Suk Park</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+K">Kiwan Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+J+K">Jin Keun Seo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This study introduces a novel reconstruction method for dental cone-beam
computed tomography (CBCT), focusing on effectively reducing metal-induced
artifacts commonly encountered in the presence of prevalent metallic implants.
Despite significant progress in metal artifact reduction techniques, challenges
persist owing to the intricate physical interactions between polychromatic
X-ray beams and metal objects, which are further compounded by the additional
effects associated with metal-tooth interactions and factors specific to the
dental CBCT data environment. To overcome these limitations, we propose an
implicit neural network that generates two distinct and informative tomographic
images. One image represents the monochromatic attenuation distribution at a
specific energy level, whereas the other captures the nonlinear beam-hardening
factor resulting from the polychromatic nature of X-ray beams. In contrast to
existing CT reconstruction techniques, the proposed method relies exclusively
on the Beer--Lambert law, effectively preventing the generation of
metal-induced artifacts during the backprojection process commonly implemented
in conventional methods. Extensive experimental evaluations demonstrate that
the proposed method effectively reduces metal artifacts while providing
high-quality image reconstructions, thus emphasizing the significance of the
second image in capturing the nonlinear beam-hardening factor.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14580" title="Abstract">arXiv:2307.14580</a> [<a href="/pdf/2307.14580" title="Download PDF">pdf</a>, <a href="/format/2307.14580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The BARN Challenge 2023 -- Autonomous Navigation in Highly Constrained  Spaces -- Inventec Team
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mandala%2C+H">Hanjaya Mandala</a>, 
<a href="/search/cs?searchtype=author&query=Christmann%2C+G">Guilherme Christmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The BARN Challenge 2023, ICRA 2023, Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Navigation in the real-world is hard and filled with complex scenarios. The
Benchmark Autonomous Robot Navigation (BARN) Challenge is a competition that
focuses on highly constrained spaces. Teams compete using a standard platform
in a simulation and a real-world stage, with scenarios ranging from easy to
challenging. This technical report presents the system and methods employed by
the Inventec Team during the BARN Challenge 2023
(https://cs.gmu.edu/~xiao/Research/BARN_Challenge/BARN_Challenge23.html). At
its core, our method uses the baseline learning-based controller LfLH. We
developed extensions using a finite state machine to trigger recovery
behaviors, and introduced two alternatives for forward safety collision checks,
based on footprint inflation and model-predictive control. Moreover, we also
present a backtrack safety check based on costmap region-of-interest. Compared
to the original baseline, we managed a significant increase in the navigation
score, from 0.2334 to 0.2445 (4.76%). Overall, our team ranked second place
both in simulation and in the real-world stage. Our code is publicly available
at:
(https://github.com/inventec-ai-center/inventec-team-barn-challenge-2023.git)
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14591" title="Abstract">arXiv:2307.14591</a> [<a href="/pdf/2307.14591" title="Download PDF">pdf</a>, <a href="/format/2307.14591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The detection and rectification for identity-switch based on unfalsified  control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Junchao Huang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaoqi He</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sheng Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The purpose of multi-object tracking (MOT) is to continuously track and
identify objects detected in videos. Currently, most methods for multi-object
tracking model the motion information and combine it with appearance
information to determine and track objects. In this paper, unfalsified control
is employed to address the ID-switch problem in multi-object tracking. We
establish sequences of appearance information variations for the trajectories
during the tracking process and design a detection and rectification module
specifically for ID-switch detection and recovery. We also propose a simple and
effective strategy to address the issue of ambiguous matching of appearance
information during the data association process. Experimental results on
publicly available MOT datasets demonstrate that the tracker exhibits excellent
effectiveness and robustness in handling tracking errors caused by occlusions
and rapid movements.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14593" title="Abstract">arXiv:2307.14593</a> [<a href="/pdf/2307.14593" title="Download PDF">pdf</a>, <a href="/format/2307.14593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FakeTracer: Proactively Defending Against Face-swap DeepFakes via  Implanting Traces in Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+P">Pu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+H">Honggang Qi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuezun Li</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+S">Siwei Lyu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Face-swap DeepFake is an emerging AI-based face forgery technique that can
replace the original face in a video with a generated face of the target
identity while retaining consistent facial attributes such as expression and
orientation. Due to the high privacy of faces, the misuse of this technique can
raise severe social concerns, drawing tremendous attention to defend against
DeepFakes recently. In this paper, we describe a new proactive defense method
called FakeTracer to expose face-swap DeepFakes via implanting traces in
training. Compared to general face-synthesis DeepFake, the face-swap DeepFake
is more complex as it involves identity change, is subjected to the
encoding-decoding process, and is trained unsupervised, increasing the
difficulty of implanting traces into the training phase. To effectively defend
against face-swap DeepFake, we design two types of traces, sustainable trace
(STrace) and erasable trace (ETrace), to be added to training faces. During the
training, these manipulated faces affect the learning of the face-swap DeepFake
model, enabling it to generate faces that only contain sustainable traces. In
light of these two traces, our method can effectively expose DeepFakes by
identifying them. Extensive experiments are conducted on the Celeb-DF dataset,
compared with recent passive and proactive defense methods, and are studied
thoroughly regarding various factors, corroborating the efficacy of our method
on defending against face-swap DeepFake.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14596" title="Abstract">arXiv:2307.14596</a> [<a href="/pdf/2307.14596" title="Download PDF">pdf</a>, <a href="/format/2307.14596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HUTFormer: Hierarchical U-Net Transformer for Long-Term Traffic  Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Zezhi Shao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuchen Fang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+G">Guangyin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yongjun Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TKDE Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Traffic forecasting, which aims to predict traffic conditions based on
historical observations, has been an enduring research topic and is widely
recognized as an essential component of intelligent transportation. Recent
proposals on Spatial-Temporal Graph Neural Networks (STGNNs) have made
significant progress by combining sequential models with graph convolution
networks. However, due to high complexity issues, STGNNs only focus on
short-term traffic forecasting, e.g., 1-hour forecasting, while ignoring more
practical long-term forecasting. In this paper, we make the first attempt to
explore long-term traffic forecasting, e.g., 1-day forecasting. To this end, we
first reveal its unique challenges in exploiting multi-scale representations.
Then, we propose a novel Hierarchical U-net TransFormer (HUTFormer) to address
the issues of long-term traffic forecasting. HUTFormer consists of a
hierarchical encoder and decoder to jointly generate and utilize multi-scale
representations of traffic data. Specifically, for the encoder, we propose
window self-attention and segment merging to extract multi-scale
representations from long-term traffic data. For the decoder, we design a
cross-scale attention mechanism to effectively incorporate multi-scale
representations. In addition, HUTFormer employs an efficient input embedding
strategy to address the complexity issues. Extensive experiments on four
traffic datasets show that the proposed HUTFormer significantly outperforms
state-of-the-art traffic forecasting and long time series forecasting
baselines.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14605" title="Abstract">arXiv:2307.14605</a> [<a href="/pdf/2307.14605" title="Download PDF">pdf</a>, <a href="/format/2307.14605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clustering based Point Cloud Representation Learning for 3D Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+T">Tuo Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenguan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaohan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Q">Qinghua Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023; Project page: <a href="https://github.com/FengZicai/Cluster3Dseg/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Point cloud analysis (such as 3D segmentation and detection) is a challenging
task, because of not only the irregular geometries of many millions of
unordered points, but also the great variations caused by depth, viewpoint,
occlusion, etc. Current studies put much focus on the adaption of neural
networks to the complex geometries of point clouds, but are blind to a
fundamental question: how to learn an appropriate point embedding space that is
aware of both discriminative semantics and challenging variations? As a
response, we propose a clustering based supervised learning scheme for point
cloud analysis. Unlike current de-facto, scene-wise training paradigm, our
algorithm conducts within-class clustering on the point embedding space for
automatically discovering subclass patterns which are latent yet representative
across scenes. The mined patterns are, in turn, used to repaint the embedding
space, so as to respect the underlying distribution of the entire training
dataset and improve the robustness to the variations. Our algorithm is
principled and readily pluggable to modern point cloud segmentation networks
during training, without extra overhead during testing. With various 3D network
architectures (i.e., voxel-based, point-based, Transformer-based, automatically
searched), our algorithm shows notable improvements on famous point cloud
segmentation datasets (i.e.,2.0-2.6% on single-scan and 2.0-2.2% multi-scan of
SemanticKITTI, 1.8-1.9% on S3DIS, in terms of mIoU). Our algorithm also
demonstrates utility in 3D detection, showing 2.0-3.4% mAP gains on KITTI.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14609" title="Abstract">arXiv:2307.14609</a> [<a href="/pdf/2307.14609" title="Download PDF">pdf</a>, <a href="/format/2307.14609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complete and separate: Conditional separation with missing target source  attribute completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bralios%2C+D">Dimitrios Bralios</a>, 
<a href="/search/cs?searchtype=author&query=Tzinis%2C+E">Efthymios Tzinis</a>, 
<a href="/search/cs?searchtype=author&query=Smaragdis%2C+P">Paris Smaragdis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Recent approaches in source separation leverage semantic information about
their input mixtures and constituent sources that when used in conditional
separation models can achieve impressive performance. Most approaches along
these lines have focused on simple descriptions, which are not always useful
for varying types of input mixtures. In this work, we present an approach in
which a model, given an input mixture and partial semantic information about a
target source, is trained to extract additional semantic data. We then leverage
this pre-trained model to improve the separation performance of an uncoupled
multi-conditional separation network. Our experiments demonstrate that the
separation performance of this multi-conditional model is significantly
improved, approaching the performance of an oracle model with complete semantic
information. Furthermore, our approach achieves performance levels that are
comparable to those of the best performing specialized single conditional
models, thus providing an easier to use alternative.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14611" title="Abstract">arXiv:2307.14611</a> [<a href="/pdf/2307.14611" title="Download PDF">pdf</a>, <a href="/format/2307.14611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TextManiA: Enriching Visual Feature by Text-driven Manifold Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye-Bin%2C+M">Moon Ye-Bin</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jisoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hongyeob Kim</a>, 
<a href="/search/cs?searchtype=author&query=Son%2C+K">Kilho Son</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+T">Tae-Hyun Oh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent label mix-based augmentation methods have shown their effectiveness in
generalization despite their simplicity, and their favorable effects are often
attributed to semantic-level augmentation. However, we found that they are
vulnerable to highly skewed class distribution, because scarce data classes are
rarely sampled for inter-class perturbation. We propose TextManiA, a
text-driven manifold augmentation method that semantically enriches visual
feature spaces, regardless of data distribution. TextManiA augments visual data
with intra-class semantic perturbation by exploiting easy-to-understand
visually mimetic words, i.e., attributes. To this end, we bridge between the
text representation and a target visual feature space, and propose an efficient
vector augmentation. To empirically support the validity of our design, we
devise two visualization-based analyses and show the plausibility of the bridge
between two different modality spaces. Our experiments demonstrate that
TextManiA is powerful in scarce samples with class imbalance as well as even
distribution. We also show compatibility with the label mix-based approaches in
evenly distributed scarce data.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14612" title="Abstract">arXiv:2307.14612</a> [<a href="/pdf/2307.14612" title="Download PDF">pdf</a>, <a href="/format/2307.14612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GenCo: An Auxiliary Generator from Contrastive Learning for Enhanced  Few-Shot Learning in Remote Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hovakimyan%2C+N">Naira Hovakimyan</a>, 
<a href="/search/cs?searchtype=author&query=Hobbs%2C+J">Jennifer Hobbs</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> European Conference on Artificial Intelligence (ECAI), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Classifying and segmenting patterns from a limited number of examples is a
significant challenge in remote sensing and earth observation due to the
difficulty in acquiring accurately labeled data in large quantities. Previous
studies have shown that meta-learning, which involves episodic training on
query and support sets, is a promising approach. However, there has been little
attention paid to direct fine-tuning techniques. This paper repurposes
contrastive learning as a pre-training method for few-shot learning for
classification and semantic segmentation tasks. Specifically, we introduce a
generator-based contrastive learning framework (GenCo) that pre-trains
backbones and simultaneously explores variants of feature samples. In
fine-tuning, the auxiliary generator can be used to enrich limited labeled data
samples in feature space. We demonstrate the effectiveness of our method in
improving few-shot learning performance on two key remote sensing datasets:
Agriculture-Vision and EuroSAT. Empirically, our approach outperforms purely
supervised training on the nearly 95,000 images in Agriculture-Vision for both
classification and semantic segmentation tasks. Similarly, the proposed
few-shot method achieves better results on the land-cover classification task
on EuroSAT compared to the results obtained from fully supervised model
training on the dataset.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14613" title="Abstract">arXiv:2307.14613</a> [<a href="/pdf/2307.14613" title="Download PDF">pdf</a>, <a href="/format/2307.14613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Contrastive Graph Diffusion Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yixian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+K">Kun Zhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM Multimedia 2013 Accpeted
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM MM 2013
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Augmentation techniques and sampling strategies are crucial in contrastive
learning, but in most existing works, augmentation techniques require careful
design, and their sampling strategies can only capture a small amount of
intrinsic supervision information. Additionally, the existing methods require
complex designs to obtain two different representations of the data. To
overcome these limitations, we propose a novel framework called the
Self-Contrastive Graph Diffusion Network (SCGDN). Our framework consists of two
main components: the Attentional Module (AttM) and the Diffusion Module (DiFM).
AttM aggregates higher-order structure and feature information to get an
excellent embedding, while DiFM balances the state of each node in the graph
through Laplacian diffusion learning and allows the cooperative evolution of
adjacency and feature information in the graph. Unlike existing methodologies,
SCGDN is an augmentation-free approach that avoids "sampling bias" and semantic
drift, without the need for pre-training. We conduct a high-quality sampling of
samples based on structure and feature information. If two nodes are neighbors,
they are considered positive samples of each other. If two disconnected nodes
are also unrelated on $k$NN graph, they are considered negative samples for
each other. The contrastive objective reasonably uses our proposed sampling
strategies, and the redundancy reduction term minimizes redundant information
in the embedding and can well retain more discriminative information. In this
novel framework, the graph self-contrastive learning paradigm gives expression
to a powerful force. SCGDN effectively balances between preserving high-order
structure information and avoiding overfitting. The results manifest that SCGDN
can consistently generate outperformance over both the contrastive methods and
the classical methods.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14617" title="Abstract">arXiv:2307.14617</a> [<a href="/pdf/2307.14617" title="Download PDF">pdf</a>, <a href="/format/2307.14617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiscale Dynamic Graph Representation for Biometric Recognition with  Occlusions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+M">Min Ren</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunlong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuhao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kunbo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhenan Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TPAMI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Occlusion is a common problem with biometric recognition in the wild. The
generalization ability of CNNs greatly decreases due to the adverse effects of
various occlusions. To this end, we propose a novel unified framework
integrating the merits of both CNNs and graph models to overcome occlusion
problems in biometric recognition, called multiscale dynamic graph
representation (MS-DGR). More specifically, a group of deep features reflected
on certain subregions is recrafted into a feature graph (FG). Each node inside
the FG is deemed to characterize a specific local region of the input sample,
and the edges imply the co-occurrence of non-occluded regions. By analyzing the
similarities of the node representations and measuring the topological
structures stored in the adjacent matrix, the proposed framework leverages
dynamic graph matching to judiciously discard the nodes corresponding to the
occluded parts. The multiscale strategy is further incorporated to attain more
diverse nodes representing regions of various sizes. Furthermore, the proposed
framework exhibits a more illustrative and reasonable inference by showing the
paired nodes. Extensive experiments demonstrate the superiority of the proposed
framework, which boosts the accuracy in both natural and occlusion-simulated
cases by a large margin compared with that of baseline methods.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14619" title="Abstract">arXiv:2307.14619</a> [<a href="/pdf/2307.14619" title="Download PDF">pdf</a>, <a href="/format/2307.14619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imitating Complex Trajectories: Bridging Low-Level Stability and  High-Level Behavior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Block%2C+A">Adam Block</a>, 
<a href="/search/cs?searchtype=author&query=Pfrommer%2C+D">Daniel Pfrommer</a>, 
<a href="/search/cs?searchtype=author&query=Simchowitz%2C+M">Max Simchowitz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 107 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
<p class="mathjax">We propose a theoretical framework for studying the imitation of stochastic,
non-Markovian, potentially multi-modal (i.e. "complex" ) expert demonstrations
in nonlinear dynamical systems. Our framework invokes low-level controllers -
either learned or implicit in position-command control - to stabilize imitation
policies around expert demonstrations. We show that with (a) a suitable
low-level stability guarantee and (b) a stochastic continuity property of the
learned policy we call "total variation continuity" (TVC), an imitator that
accurately estimates actions on the demonstrator's state distribution closely
matches the demonstrator's distribution over entire trajectories. We then show
that TVC can be ensured with minimal degradation of accuracy by combining a
popular data-augmentation regimen with a novel algorithmic trick: adding
augmentation noise at execution time. We instantiate our guarantees for
policies parameterized by diffusion models and prove that if the learner
accurately estimates the score of the (noise-augmented) expert policy, then the
distribution of imitator trajectories is close to the demonstrator distribution
in a natural optimal transport distance. Our analysis constructs intricate
couplings between noise-augmented trajectories, a technique that may be of
independent interest. We conclude by empirically validating our algorithmic
recommendations.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14620" title="Abstract">arXiv:2307.14620</a> [<a href="/pdf/2307.14620" title="Download PDF">pdf</a>, <a href="/format/2307.14620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeRF-Det: Learning Geometry-Aware Volumetric Representation for  Multi-View 3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chenfeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bichen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Ji Hou</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+S">Sam Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruilong Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jialiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+W">Wei Zhan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zijian He</a>, 
<a href="/search/cs?searchtype=author&query=Vajda%2C+P">Peter Vajda</a>, 
<a href="/search/cs?searchtype=author&query=Keutzer%2C+K">Kurt Keutzer</a>, 
<a href="/search/cs?searchtype=author&query=Tomizuka%2C+M">Masayoshi Tomizuka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present NeRF-Det, a novel method for indoor 3D detection with posed RGB
images as input. Unlike existing indoor 3D detection methods that struggle to
model scene geometry, our method makes novel use of NeRF in an end-to-end
manner to explicitly estimate 3D geometry, thereby improving 3D detection
performance. Specifically, to avoid the significant extra latency associated
with per-scene optimization of NeRF, we introduce sufficient geometry priors to
enhance the generalizability of NeRF-MLP. Furthermore, we subtly connect the
detection and NeRF branches through a shared MLP, enabling an efficient
adaptation of NeRF to detection and yielding geometry-aware volumetric
representations for 3D detection. Our method outperforms state-of-the-arts by
3.9 mAP and 3.1 mAP on the ScanNet and ARKITScenes benchmarks, respectively. We
provide extensive analysis to shed light on how NeRF-Det works. As a result of
our joint-training design, NeRF-Det is able to generalize well to unseen scenes
for object detection, view synthesis, and depth estimation tasks without
requiring per-scene optimization. Code is available at
\url{https://github.com/facebookresearch/NeRF-Det}.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14623" title="Abstract">arXiv:2307.14623</a> [<a href="/pdf/2307.14623" title="Download PDF">pdf</a>, <a href="/format/2307.14623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BubbleML: A Multi-Physics Dataset and Benchmarks for Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hassan%2C+S+M+S">Sheikh Md Shakeel Hassan</a>, 
<a href="/search/cs?searchtype=author&query=Feeney%2C+A">Arthur Feeney</a>, 
<a href="/search/cs?searchtype=author&query=Dhruv%2C+A">Akash Dhruv</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jihoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Suh%2C+Y">Youngjoon Suh</a>, 
<a href="/search/cs?searchtype=author&query=Ryu%2C+J">Jaiyoung Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Won%2C+Y">Yoonjin Won</a>, 
<a href="/search/cs?searchtype=author&query=Chandramowlishwaran%2C+A">Aparna Chandramowlishwaran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Neurips Datasets and Benchmarks Track 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In the field of phase change phenomena, the lack of accessible and diverse
datasets suitable for machine learning (ML) training poses a significant
challenge. Existing experimental datasets are often restricted, with limited
availability and sparse ground truth data, impeding our understanding of this
complex multi-physics phenomena. To bridge this gap, we present the BubbleML
Dataset(https://github.com/HPCForge/BubbleML) which leverages physics-driven
simulations to provide accurate ground truth information for various boiling
scenarios, encompassing nucleate pool boiling, flow boiling, and sub-cooled
boiling. This extensive dataset covers a wide range of parameters, including
varying gravity conditions, flow rates, sub-cooling levels, and wall superheat,
comprising 51 simulations. BubbleML is validated against experimental
observations and trends, establishing it as an invaluable resource for ML
research. Furthermore, we showcase its potential to facilitate exploration of
diverse downstream tasks by introducing two benchmarks: (a) optical flow
analysis to capture bubble dynamics, and (b) operator networks for learning
temperature dynamics. The BubbleML dataset and its benchmarks serve as a
catalyst for advancements in ML-driven research on multi-physics phase change
phenomena, enabling the development and comparison of state-of-the-art
techniques and models.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14624" title="Abstract">arXiv:2307.14624</a> [<a href="/pdf/2307.14624" title="Download PDF">pdf</a>, <a href="/format/2307.14624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FS-Depth: Focal-and-Scale Depth Estimation from a Single Image in Unseen  Indoor Scene
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+C">Chengrui Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Meng Yang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Lei He</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+N">Nanning Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">It has long been an ill-posed problem to predict absolute depth maps from
single images in real (unseen) indoor scenes. We observe that it is essentially
due to not only the scale-ambiguous problem but also the focal-ambiguous
problem that decreases the generalization ability of monocular depth
estimation. That is, images may be captured by cameras of different focal
lengths in scenes of different scales. In this paper, we develop a
focal-and-scale depth estimation model to well learn absolute depth maps from
single images in unseen indoor scenes. First, a relative depth estimation
network is adopted to learn relative depths from single images with diverse
scales/semantics. Second, multi-scale features are generated by mapping a
single focal length value to focal length features and concatenating them with
intermediate features of different scales in relative depth estimation.
Finally, relative depths and multi-scale features are jointly fed into an
absolute depth estimation network. In addition, a new pipeline is developed to
augment the diversity of focal lengths of public datasets, which are often
captured with cameras of the same or similar focal lengths. Our model is
trained on augmented NYUDv2 and tested on three unseen datasets. Our model
considerably improves the generalization ability of depth estimation by 41%/13%
(RMSE) with/without data augmentation compared with five recent SOTAs and well
alleviates the deformation problem in 3D reconstruction. Notably, our model
well maintains the accuracy of depth estimation on original NYUDv2.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14626" title="Abstract">arXiv:2307.14626</a> [<a href="/pdf/2307.14626" title="Download PDF">pdf</a>, <a href="/format/2307.14626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Graph Reinforcement Learning based On-Demand Wireless Energy  Transfer in Multi-UAV-aided IoT Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z+Y">Ze Yu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+Y">Yueling Che</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Sheng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kaishun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Leung%2C+V+C+M">Victor C. M. Leung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by the 21th International Symposium on Modeling and Optimization in Mobile, Ad hoc, and Wireless Networks (WiOpt 2023). 8 pages, 8 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">This paper proposes a new on-demand wireless energy transfer (WET) scheme of
multiple unmanned aerial vehicles (UAVs). Unlike the existing studies that
simply pursuing the total or the minimum harvested energy maximization at the
Internet of Things (IoT) devices, where the IoT devices' own energy
requirements are barely considered, we propose a new metric called the
hungry-level of energy (HoE), which reflects the time-varying energy demand of
each IoT device based on the energy gap between its required energy and the
harvested energy from the UAVs. With the purpose to minimize the overall HoE of
the IoT devices whose energy requirements are not satisfied, we optimally
determine all the UAVs' trajectories and WET decisions over time, under the
practical mobility and energy constraints of the UAVs. Although the proposed
problem is of high complexity to solve, by excavating the UAVs' self-attentions
for their collaborative WET, we propose the multiagent graph reinforcement
learning (MAGRL) based approach. Through the offline training of the MAGRL
model, where the global training at the central controller guides the local
training at each UAV agent, each UAV then distributively determines its
trajectory and WET based on the well-trained local neural networks. Simulation
results show that the proposed MAGRL-based approach outperforms various
benchmarks for meeting the IoT devices' energy requirements.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14628" title="Abstract">arXiv:2307.14628</a> [<a href="/pdf/2307.14628" title="Download PDF">pdf</a>, <a href="/format/2307.14628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rapid and Scalable Bayesian AB Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chennu%2C+S">Srivas Chennu</a>, 
<a href="/search/cs?searchtype=author&query=Maher%2C+A">Andrew Maher</a>, 
<a href="/search/cs?searchtype=author&query=Pangerl%2C+C">Christian Pangerl</a>, 
<a href="/search/cs?searchtype=author&query=Prabanantham%2C+S">Subash Prabanantham</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+J+H">Jae Hyeon Bae</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+J">Jamie Martin</a>, 
<a href="/search/cs?searchtype=author&query=Goswami%2C+B">Bud Goswami</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 10th IEEE International Conference On Data Science And Advanced Analytics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">AB testing aids business operators with their decision making, and is
considered the gold standard method for learning from data to improve digital
user experiences. However, there is usually a gap between the requirements of
practitioners, and the constraints imposed by the statistical hypothesis
testing methodologies commonly used for analysis of AB tests. These include the
lack of statistical power in multivariate designs with many factors,
correlations between these factors, the need of sequential testing for early
stopping, and the inability to pool knowledge from past tests. Here, we propose
a solution that applies hierarchical Bayesian estimation to address the above
limitations. In comparison to current sequential AB testing methodology, we
increase statistical power by exploiting correlations between factors, enabling
sequential testing and progressive early stopping, without incurring excessive
false positive risk. We also demonstrate how this methodology can be extended
to enable the extraction of composite global learnings from past AB tests, to
accelerate future tests. We underpin our work with a solid theoretical
framework that articulates the value of hierarchical estimation. We demonstrate
its utility using both numerical simulations and a large set of real-world AB
tests. Together, these results highlight the practical value of our approach
for statistical inference in the technology industry.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14630" title="Abstract">arXiv:2307.14630</a> [<a href="/pdf/2307.14630" title="Download PDF">pdf</a>, <a href="/format/2307.14630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 360VOT: A New Benchmark Dataset for Omnidirectional Visual Object  Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huajian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yinzhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingshu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+S">Sai-Kit Yeung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023. Homepage: <a href="https://360vot.hkustvgd.com">this https URL</a> The toolkit of the benchmark is available at: <a href="https://github.com/HuajianUP/360VOT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">360{\deg} images can provide an omnidirectional field of view which is
important for stable and long-term scene perception. In this paper, we explore
360{\deg} images for visual object tracking and perceive new challenges caused
by large distortion, stitching artifacts, and other unique attributes of
360{\deg} images. To alleviate these problems, we take advantage of novel
representations of target localization, i.e., bounding field-of-view, and then
introduce a general 360 tracking framework that can adopt typical trackers for
omnidirectional tracking. More importantly, we propose a new large-scale
omnidirectional tracking benchmark dataset, 360VOT, in order to facilitate
future research. 360VOT contains 120 sequences with up to 113K high-resolution
frames in equirectangular projection. The tracking targets cover 32 categories
in diverse scenarios. Moreover, we provide 4 types of unbiased ground truth,
including (rotated) bounding boxes and (rotated) bounding field-of-views, as
well as new metrics tailored for 360{\deg} images which allow for the accurate
evaluation of omnidirectional tracking performance. Finally, we extensively
evaluated 20 state-of-the-art visual trackers and provided a new baseline for
future comparisons. Homepage: https://360vot.hkustvgd.com
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14632" title="Abstract">arXiv:2307.14632</a> [<a href="/pdf/2307.14632" title="Download PDF">pdf</a>, <a href="/format/2307.14632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metric-Based In-context Learning: A Case Study in Text Simplification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vadlamannati%2C+S">Subha Vadlamannati</a>, 
<a href="/search/cs?searchtype=author&query=%C5%9Eahin%2C+G+G">G&#xf6;zde G&#xfc;l &#x15e;ahin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to INLG
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In-context learning (ICL) for large language models has proven to be a
powerful approach for many natural language processing tasks. However,
determining the best method to select examples for ICL is nontrivial as the
results can vary greatly depending on the quality, quantity, and order of
examples used. In this paper, we conduct a case study on text simplification
(TS) to investigate how to select the best and most robust examples for ICL. We
propose Metric-Based in-context Learning (MBL) method that utilizes commonly
used TS metrics such as SARI, compression ratio, and BERT-Precision for
selection. Through an extensive set of experiments with various-sized GPT
models on standard TS benchmarks such as TurkCorpus and ASSET, we show that
examples selected by the top SARI scores perform the best on larger models such
as GPT-175B, while the compression ratio generally performs better on smaller
models such as GPT-13B and GPT-6.7B. Furthermore, we demonstrate that MBL is
generally robust to example orderings and out-of-domain test sets, and
outperforms strong baselines and state-of-the-art finetuned language models.
Finally, we show that the behaviour of large GPT models can be implicitly
controlled by the chosen metric. Our research provides a new framework for
selecting examples in ICL, and demonstrates its effectiveness in text
simplification tasks, breaking new ground for more accurate and efficient NLG
systems.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14634" title="Abstract">arXiv:2307.14634</a> [<a href="/pdf/2307.14634" title="Download PDF">pdf</a>, <a href="/format/2307.14634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fact-Checking of AI-Generated Reports
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahmood%2C+R">Razi Mahmood</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Ge Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kalra%2C+M">Mannudeep Kalra</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+P">Pingkun Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">With advances in generative artificial intelligence (AI), it is now possible
to produce realistic-looking automated reports for preliminary reads of
radiology images. This can expedite clinical workflows, improve accuracy and
reduce overall costs. However, it is also well-known that such models often
hallucinate, leading to false findings in the generated reports. In this paper,
we propose a new method of fact-checking of AI-generated reports using their
associated images. Specifically, the developed examiner differentiates real and
fake sentences in reports by learning the association between an image and
sentences describing real or potentially fake findings. To train such an
examiner, we first created a new dataset of fake reports by perturbing the
findings in the original ground truth radiology reports associated with images.
Text encodings of real and fake sentences drawn from these reports are then
paired with image encodings to learn the mapping to real/fake labels. The
utility of such an examiner is demonstrated for verifying automatically
generated reports by detecting and removing fake sentences. Future generative
AI approaches can use the resulting tool to validate their reports leading to a
more responsible use of AI in expediting clinical workflows.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14637" title="Abstract">arXiv:2307.14637</a> [<a href="/pdf/2307.14637" title="Download PDF">pdf</a>, <a href="/format/2307.14637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HTNet for micro-expression recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhifeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Wenhan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Sankaranarayana%2C+R">Ramesh Sankaranarayana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Facial expression is related to facial muscle contractions and different
muscle movements correspond to different emotional states. For micro-expression
recognition, the muscle movements are usually subtle, which has a negative
impact on the performance of current facial emotion recognition algorithms.
Most existing methods use self-attention mechanisms to capture relationships
between tokens in a sequence, but they do not take into account the inherent
spatial relationships between facial landmarks. This can result in sub-optimal
performance on micro-expression recognition tasks.Therefore, learning to
recognize facial muscle movements is a key challenge in the area of
micro-expression recognition. In this paper, we propose a Hierarchical
Transformer Network (HTNet) to identify critical areas of facial muscle
movement. HTNet includes two major components: a transformer layer that
leverages the local temporal features and an aggregation layer that extracts
local and global semantical facial features. Specifically, HTNet divides the
face into four different facial areas: left lip area, left eye area, right eye
area and right lip area. The transformer layer is used to focus on representing
local minor muscle movement with local self-attention in each area. The
aggregation layer is used to learn the interactions between eye areas and lip
areas. The experiments on four publicly available micro-expression datasets
show that the proposed approach outperforms previous methods by a large margin.
The codes and models are available at:
\url{https://github.com/wangzhifengharrison/HTNet}
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14638" title="Abstract">arXiv:2307.14638</a> [<a href="/pdf/2307.14638" title="Download PDF">pdf</a>, <a href="/format/2307.14638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EqGAN: Feature Equalization Fusion for Few-shot Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yingbo Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Z">Zhihao Yue</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yutong Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pengyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xian Wei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingsong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Due to the absence of fine structure and texture information, existing
fusion-based few-shot image generation methods suffer from unsatisfactory
generation quality and diversity. To address this problem, we propose a novel
feature Equalization fusion Generative Adversarial Network (EqGAN) for few-shot
image generation. Unlike existing fusion strategies that rely on either deep
features or local representations, we design two separate branches to fuse
structures and textures by disentangling encoded features into shallow and deep
contents. To refine image contents at all feature levels, we equalize the fused
structure and texture semantics at different scales and supplement the decoder
with richer information by skip connections. Since the fused structures and
textures may be inconsistent with each other, we devise a consistent
equalization loss between the equalized features and the intermediate output of
the decoder to further align the semantics. Comprehensive experiments on three
public datasets demonstrate that, EqGAN not only significantly improves
generation performance with FID score (by up to 32.7%) and LPIPS score (by up
to 4.19%), but also outperforms the state-of-the-arts in terms of accuracy (by
up to 1.97%) for downstream classification tasks.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14643" title="Abstract">arXiv:2307.14643</a> [<a href="/pdf/2307.14643" title="Download PDF">pdf</a>, <a href="/format/2307.14643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MVMR-FS : Non-parametric feature selection algorithm based on Maximum  inter-class Variation and Minimum Redundancy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nie%2C+H">Haitao Nie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shengbo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+B">Bin Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">How to accurately measure the relevance and redundancy of features is an
age-old challenge in the field of feature selection. However, existing
filter-based feature selection methods cannot directly measure redundancy for
continuous data. In addition, most methods rely on manually specifying the
number of features, which may introduce errors in the absence of expert
knowledge. In this paper, we propose a non-parametric feature selection
algorithm based on maximum inter-class variation and minimum redundancy,
abbreviated as MVMR-FS. We first introduce supervised and unsupervised kernel
density estimation on the features to capture their similarities and
differences in inter-class and overall distributions. Subsequently, we present
the criteria for maximum inter-class variation and minimum redundancy (MVMR),
wherein the inter-class probability distributions are employed to reflect
feature relevance and the distances between overall probability distributions
are used to quantify redundancy. Finally, we employ an AGA to search for the
feature subset that minimizes the MVMR. Compared with ten state-of-the-art
methods, MVMR-FS achieves the highest average accuracy and improves the
accuracy by 5% to 11%.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14648" title="Abstract">arXiv:2307.14648</a> [<a href="/pdf/2307.14648" title="Download PDF">pdf</a>, <a href="/format/2307.14648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial-Frequency U-Net for Denoising Diffusion Probabilistic Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhengyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kevin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zicheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lijuan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we study the denoising diffusion probabilistic model (DDPM) in
wavelet space, instead of pixel space, for visual synthesis. Considering the
wavelet transform represents the image in spatial and frequency domains, we
carefully design a novel architecture SFUNet to effectively capture the
correlation for both domains. Specifically, in the standard denoising U-Net for
pixel data, we supplement the 2D convolutions and spatial-only attention layers
with our spatial frequency-aware convolution and attention modules to jointly
model the complementary information from spatial and frequency domains in
wavelet data. Our new architecture can be used as a drop-in replacement to the
pixel-based network and is compatible with the vanilla DDPM training process.
By explicitly modeling the wavelet signals, we find our model is able to
generate images with higher quality on CIFAR-10, FFHQ, LSUN-Bedroom, and
LSUN-Church datasets, than the pixel-based counterpart.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14657" title="Abstract">arXiv:2307.14657</a> [<a href="/pdf/2307.14657" title="Download PDF">pdf</a>, <a href="/format/2307.14657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoding the Secrets of Machine Learning in Malware Classification: A  Deep Dive into Datasets, Feature Extraction, and Model Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dambra%2C+S">Savino Dambra</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yufei Han</a>, 
<a href="/search/cs?searchtype=author&query=Aonzo%2C+S">Simone Aonzo</a>, 
<a href="/search/cs?searchtype=author&query=Kotzias%2C+P">Platon Kotzias</a>, 
<a href="/search/cs?searchtype=author&query=Vitale%2C+A">Antonino Vitale</a>, 
<a href="/search/cs?searchtype=author&query=Caballero%2C+J">Juan Caballero</a>, 
<a href="/search/cs?searchtype=author&query=Balzarotti%2C+D">Davide Balzarotti</a>, 
<a href="/search/cs?searchtype=author&query=Bilge%2C+L">Leyla Bilge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Many studies have proposed machine-learning (ML) models for malware detection
and classification, reporting an almost-perfect performance. However, they
assemble ground-truth in different ways, use diverse static- and
dynamic-analysis techniques for feature extraction, and even differ on what
they consider a malware family. As a consequence, our community still lacks an
understanding of malware classification results: whether they are tied to the
nature and distribution of the collected dataset, to what extent the number of
families and samples in the training dataset influence performance, and how
well static and dynamic features complement each other.
<br />This work sheds light on those open questions. by investigating the key
factors influencing ML-based malware detection and classification. For this, we
collect the largest balanced malware dataset so far with 67K samples from 670
families (100 samples each), and train state-of-the-art models for malware
detection and family classification using our dataset. Our results reveal that
static features perform better than dynamic features, and that combining both
only provides marginal improvement over static features. We discover no
correlation between packing and classification accuracy, and that missing
behaviors in dynamically-extracted features highly penalize their performance.
We also demonstrate how a larger number of families to classify make the
classification harder, while a higher number of samples per family increases
accuracy. Finally, we find that models trained on a uniform distribution of
samples per family better generalize on unseen data.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14659" title="Abstract">arXiv:2307.14659</a> [<a href="/pdf/2307.14659" title="Download PDF">pdf</a>, <a href="/format/2307.14659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLDiffusion: Learning Degradation Representations in Diffusion Models  for Low-Light Image Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Ziqian Shao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Wenhan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Stenger%2C+B">Bjorn Stenger</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Tae-Kyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongdong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Current deep learning methods for low-light image enhancement (LLIE)
typically rely on pixel-wise mapping learned from paired data. However, these
methods often overlook the importance of considering degradation
representations, which can lead to sub-optimal outcomes. In this paper, we
address this limitation by proposing a degradation-aware learning scheme for
LLIE using diffusion models, which effectively integrates degradation and image
priors into the diffusion process, resulting in improved image enhancement. Our
proposed degradation-aware learning scheme is based on the understanding that
degradation representations play a crucial role in accurately modeling and
capturing the specific degradation patterns present in low-light images. To
this end, First, a joint learning framework for both image generation and image
enhancement is presented to learn the degradation representations. Second, to
leverage the learned degradation representations, we develop a Low-Light
Diffusion model (LLDiffusion) with a well-designed dynamic diffusion module.
This module takes into account both the color map and the latent degradation
representations to guide the diffusion process. By incorporating these
conditioning factors, the proposed LLDiffusion can effectively enhance
low-light images, considering both the inherent degradation patterns and the
desired color fidelity. Finally, we evaluate our proposed method on several
well-known benchmark datasets, including synthetic and real-world unpaired
datasets. Extensive experiments on public benchmarks demonstrate that our
LLDiffusion outperforms state-of-the-art LLIE methods both quantitatively and
qualitatively. The source code and pre-trained models are available at
https://github.com/TaoWangzj/LLDiffusion.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14660" title="Abstract">arXiv:2307.14660</a> [<a href="/pdf/2307.14660" title="Download PDF">pdf</a>, <a href="/format/2307.14660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Valued Partial Order Plans in Numeric Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Helal%2C+H">Hayyan Helal</a>, 
<a href="/search/cs?searchtype=author&query=Lakemeyer%2C+G">Gerhard Lakemeyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Many planning formalisms allow for mixing numeric with Boolean effects.
However, most of these formalisms are undecidable. In this paper, we will
analyze possible causes for this undecidability by studying the number of
different occurrences of actions, an approach that proved useful for metric
fluents before. We will start by reformulating a numeric planning problem known
as restricted tasks as a search problem. We will then show how an NP-complete
fragment of numeric planning can be found by using heuristics. To achieve this,
we will develop the idea of multi-valued partial order plans, a least
committing compact representation for (sequential and parallel) plans. Finally,
we will study optimization techniques for this representation to incorporate
soft preconditions.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14662" title="Abstract">arXiv:2307.14662</a> [<a href="/pdf/2307.14662" title="Download PDF">pdf</a>, <a href="/format/2307.14662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RIS-Aided Spatial Scattering Modulation for mmWave MIMO Transmissions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xusheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhendong Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingqing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kunlun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper investigates the reconfigurable intelligent surface (RIS) assisted
spatial scattering modulation (SSM) scheme for millimeter-wave (mmWave)
multiple-input multiple-output (MIMO) systems, in which line-of-sight (LoS) and
non-line-of-sight (NLoS) paths are respectively considered in the
transmitter-RIS and RIS-receiver channels. Based on the maximum likelihood
detector, the conditional pairwise error probability (CPEP) expression for the
RIS-SSM scheme is derived under the two cases of received beam correct and
demodulation error. Furthermore, we derive the closed-form expressions of the
unconditional pairwise error probability (UPEP) by employing two different
methods: the probability density function and the moment-generating function
expressions with a descending order of scatterer gains. To provide more useful
insights, we derive the asymptotic UPEP and the diversity gain of the RIS-SSM
scheme in the high SNR region. Depending on UPEP and the corresponding
Euclidean distance, we get the union upper bound of the average bit error
probability (ABEP). A new framework for ergodic capacity analysis is also
provided to acquire the proposed system's effective capacity. Finally, all
derivation results are validated via extensive Monte Carlo simulations,
revealing that the proposed RIS-SSM scheme outperforms the benchmarks in terms
of reliability.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14663" title="Abstract">arXiv:2307.14663</a> [<a href="/pdf/2307.14663" title="Download PDF">pdf</a>, <a href="/format/2307.14663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Unweighted and Weighted Reverse Shortest Path Problem for Disk  Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaplan%2C+H">Haim Kaplan</a>, 
<a href="/search/cs?searchtype=author&query=Katz%2C+M+J">Matthew J. Katz</a>, 
<a href="/search/cs?searchtype=author&query=Saban%2C+R">Rachel Saban</a>, 
<a href="/search/cs?searchtype=author&query=Sharir%2C+M">Micha Sharir</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A preliminary version of this paper appears in Proc. European Sympos. Algorithms (ESA), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">We study the reverse shortest path problem on disk graphs in the plane. In
this problem we consider the proximity graph of a set of $n$ disks in the plane
of arbitrary radii: In this graph two disks are connected if the distance
between them is at most some threshold parameter $r$. The case of intersection
graphs is a special case with $r=0$. We give an algorithm that, given a target
length $k$, computes the smallest value of $r$ for which there is a path of
length at most $k$ between some given pair of disks in the proximity graph. Our
algorithm runs in $O^*(n^{5/4})$ randomized expected time, which improves to
$O^*(n^{6/5})$ for unit disk graphs, where all the disks have the same radius.
Our technique is robust and can be applied to many variants of the problem. One
significant variant is the case of weighted proximity graphs, where edges are
assigned real weights equal to the distance between the disks or between their
centers, and $k$ is replaced by a target weight $w$; that is, we seek a path
whose length is at most $w$. In other variants, we want to optimize a parameter
different from $r$, such as a scale factor of the radii of the disks.
<br />The main technique for the decision version of the problem (determining
whether the graph with a given $r$ has the desired property) is based on
efficient implementations of BFS (for the unweighted case) and of Dijkstra's
algorithm (for the weighted case), using efficient data structures for
maintaining the bichromatic closest pair for certain bicliques and several
distance functions. The optimization problem is then solved by combining the
resulting decision procedure with enhanced variants of the interval shrinking
and bifurcation technique of [4].
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14666" title="Abstract">arXiv:2307.14666</a> [<a href="/pdf/2307.14666" title="Download PDF">pdf</a>, <a href="/ps/2307.14666" title="Download PostScript">ps</a>, <a href="/format/2307.14666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Natural Language Inference in Arabic using Transformer Models  and Linguistically Informed Pre-Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deen%2C+M+M+S+A">Mohammad Majd Saad Al Deen</a>, 
<a href="/search/cs?searchtype=author&query=Pielka%2C+M">Maren Pielka</a>, 
<a href="/search/cs?searchtype=author&query=Hees%2C+J">J&#xf6;rn Hees</a>, 
<a href="/search/cs?searchtype=author&query=Abdou%2C+B+S">Bouthaina Soulef Abdou</a>, 
<a href="/search/cs?searchtype=author&query=Sifa%2C+R">Rafet Sifa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE SSCI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper addresses the classification of Arabic text data in the field of
Natural Language Processing (NLP), with a particular focus on Natural Language
Inference (NLI) and Contradiction Detection (CD). Arabic is considered a
resource-poor language, meaning that there are few data sets available, which
leads to limited availability of NLP methods. To overcome this limitation, we
create a dedicated data set from publicly available resources. Subsequently,
transformer-based machine learning models are being trained and evaluated. We
find that a language-specific model (AraBERT) performs competitively with
state-of-the-art multilingual approaches, when we apply linguistically informed
pre-training methods such as Named Entity Recognition (NER). To our knowledge,
this is the first large-scale evaluation for this task in Arabic, as well as
the first application of multi-task pre-training in this context.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14668" title="Abstract">arXiv:2307.14668</a> [<a href="/pdf/2307.14668" title="Download PDF">pdf</a>, <a href="/format/2307.14668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bipartite Ranking Fairness through a Model Agnostic Ordering Adjustment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Sen Cui</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+W">Weishen Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Changshui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence. arXiv admin note: substantial text overlap with <a href="/abs/2006.08267">arXiv:2006.08267</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Algorithmic fairness has been a serious concern and received lots of interest
in machine learning community. In this paper, we focus on the bipartite ranking
scenario, where the instances come from either the positive or negative class
and the goal is to learn a ranking function that ranks positive instances
higher than negative ones. While there could be a trade-off between fairness
and performance, we propose a model agnostic post-processing framework xOrder
for achieving fairness in bipartite ranking and maintaining the algorithm
classification performance. In particular, we optimize a weighted sum of the
utility as identifying an optimal warping path across different protected
groups and solve it through a dynamic programming process. xOrder is compatible
with various classification models and ranking fairness metrics, including
supervised and unsupervised fairness metrics. In addition to binary groups,
xOrder can be applied to multiple protected groups. We evaluate our proposed
algorithm on four benchmark data sets and two real-world patient electronic
health record repositories. xOrder consistently achieves a better balance
between the algorithm utility and ranking fairness on a variety of datasets
with different metrics. From the visualization of the calibrated ranking
scores, xOrder mitigates the score distribution shifts of different groups
compared with baselines. Moreover, additional analytical results verify that
xOrder achieves a robust performance when faced with fewer samples and a bigger
difference between training and testing ranking score distributions.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14669" title="Abstract">arXiv:2307.14669</a> [<a href="/pdf/2307.14669" title="Download PDF">pdf</a>, <a href="/ps/2307.14669" title="Download PostScript">ps</a>, <a href="/format/2307.14669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fuzzy order-sorted feature logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Milanese%2C+G+C">Gian Carlo Milanese</a>, 
<a href="/search/cs?searchtype=author&query=Pasi%2C+G">Gabriella Pasi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Fuzzy Sets and Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Order-Sorted Feature (OSF) logic is a knowledge representation and reasoning
language based on function-denoting feature symbols and set-denoting sort
symbols ordered in a subsumption lattice. OSF logic allows the construction of
record-like terms that represent classes of entities and that are themselves
ordered in a subsumption relation. The unification algorithm for such
structures provides an efficient calculus of type subsumption, which has been
applied in computational linguistics and implemented in constraint logic
programming languages such as LOGIN and LIFE and automated reasoners such as
CEDAR. This work generalizes OSF logic to a fuzzy setting. We give a flexible
definition of a fuzzy subsumption relation which generalizes Zadeh's inclusion
between fuzzy sets. Based on this definition we define a fuzzy semantics of OSF
logic where sort symbols and OSF terms denote fuzzy sets. We extend the
subsumption relation to OSF terms and prove that it constitutes a fuzzy partial
order with the property that two OSF terms are subsumed by one another in the
crisp sense if and only if their subsumption degree is greater than 0. We show
how to find the greatest lower bound of two OSF terms by unifying them and how
to compute the subsumption degree between two OSF terms, and we provide the
complexity of these operations.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14671" title="Abstract">arXiv:2307.14671</a> [<a href="/pdf/2307.14671" title="Download PDF">pdf</a>, <a href="/format/2307.14671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Verified Efficient Implementation of the Weighted Path Order
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thiemann%2C+R">Ren&#xe9; Thiemann</a>, 
<a href="/search/cs?searchtype=author&query=Wenninger%2C+E">Elias Wenninger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at WST 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">The Weighted Path Order of Yamada is a powerful technique for proving
termination. It is also supported by CeTA, a certifier for checking untrusted
termination proofs. To be more precise, CeTA contains a verified function that
computes for two terms whether one of them is larger than the other for a given
WPO, i.e., where all parameters of the WPO have been fixed. The problem of this
verified function is its exponential runtime in the worst case.
<br />Therefore, in this work we develop a polynomial time implementation of WPO
that is based on memoization. It also improves upon an earlier verified
implementation of the Recursive Path Order: the RPO-implementation uses full
terms as keys for the memory, a design which simplified the soundness proofs,
but has some runtime overhead. In this work, keys are just numbers, so that the
lookup in the memory is faster. Although trivial on paper, this change
introduces some challenges for the verification task.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14675" title="Abstract">arXiv:2307.14675</a> [<a href="/pdf/2307.14675" title="Download PDF">pdf</a>, <a href="/format/2307.14675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prediction of wind turbines power with physics-informed neural networks  and evidential uncertainty quantification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gij%C3%B3n%2C+A">Alfonso Gij&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Pujana-Goitia%2C+A">Ainhoa Pujana-Goitia</a>, 
<a href="/search/cs?searchtype=author&query=Perea%2C+E">Eugenio Perea</a>, 
<a href="/search/cs?searchtype=author&query=Molina-Solana%2C+M">Miguel Molina-Solana</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez-Romero%2C+J">Juan G&#xf3;mez-Romero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The ever-growing use of wind energy makes necessary the optimization of
turbine operations through pitch angle controllers and their maintenance with
early fault detection. It is crucial to have accurate and robust models
imitating the behavior of wind turbines, especially to predict the generated
power as a function of the wind speed. Existing empirical and physics-based
models have limitations in capturing the complex relations between the input
variables and the power, aggravated by wind variability. Data-driven methods
offer new opportunities to enhance wind turbine modeling of large datasets by
improving accuracy and efficiency. In this study, we used physics-informed
neural networks to reproduce historical data coming from 4 turbines in a wind
farm, while imposing certain physical constraints to the model. The developed
models for regression of the power, torque, and power coefficient as output
variables showed great accuracy for both real data and physical equations
governing the system. Lastly, introducing an efficient evidential layer
provided uncertainty estimations of the predictions, proved to be consistent
with the absolute error, and made possible the definition of a confidence
interval in the power curve.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14676" title="Abstract">arXiv:2307.14676</a> [<a href="/pdf/2307.14676" title="Download PDF">pdf</a>, <a href="/format/2307.14676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance of RIS-Assisted Full-Duplex Space Shift Keying With  Imperfect Self-Interference Cancellation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xusheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingqing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we consider a full-duplex (FD) space shift keying (SSK)
communication system, where information exchange between two users is assisted
only by a reconfigurable intelligent surface (RIS). In particular, the impact
of loop interference (LI) between the transmit and receive antennas as well as
residual self-interference (SI) from the RIS is considered. Based on the
maximum likelihood detector, we derive the conditional pairwise error
probability and the numerical integration expression for the unconditional
pairwise error probability (UPEP). Since it is difficult to find a closed-form
solution, we perform accurate estimation by the Gauss-Chebyshev quadrature
(GCQ) method. To gain more useful insights, we derive an expression for UPEP in
the high signal-to-noise ratio region and further give the average bit error
probability (ABEP) expression. Monte Carlo simulations were performed to
validate the derived results. It is found that SI and LI have severe impacts on
system performance. Fortunately, these two disturbances can be well
counteracted by increasing the number of RIS units.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14677" title="Abstract">arXiv:2307.14677</a> [<a href="/pdf/2307.14677" title="Download PDF">pdf</a>, <a href="/format/2307.14677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curve and surface construction with moving B-splines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yang%2C+X">Xunnian Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper proposes a simple technique of curve and surface construction with
B-splines. Given a control polygon or a control mesh together with node
ordinates corresponding to all control points, a rational curve or surface is
obtained by least squares fitting of a moving constant to the control points
with weights given by uniform B-splines centered at the prescribed nodes. This
kind of curves and surfaces are natural generalizations of uniform B-spline
curves and surfaces. By choosing proper nodes, the obtained curves can have
sharp or rounded corners, partial or full straight edges while the obtained
surfaces can have sharp or rounded vertices, sharp or smoothed edges, feature
lines, etc. Except at sharp corners or sharp edges, the curves or surfaces have
the same continuity orders as the moving B-splines. Practical examples have
been given to demonstrate the effectiveness of the proposed technique for curve
and surface modeling.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14679" title="Abstract">arXiv:2307.14679</a> [<a href="/pdf/2307.14679" title="Download PDF">pdf</a>, <a href="/ps/2307.14679" title="Download PostScript">ps</a>, <a href="/format/2307.14679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LinkDID: A Privacy-Preserving, Sybil-Resistant and Key-Recoverable  Decentralized Identity Scheme
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+R">Rui Song</a>, 
<a href="/search/cs?searchtype=author&query=CC%2C+B">BB CC</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Decentralized identity mechanisms endeavor to endow users with complete
sovereignty over their digital assets within the Web3 ecosystem. Unfortunately,
this benefit frequently comes at the expense of users' credential and identity
privacy. Additionally, existing schemes fail to resist Sybil attacks that have
long plagued Web3, and lack reasonable key recovery mechanisms to regain
control of digital assets after loss. In this work, we propose LinkDID, a
privacy-preserving, Sybil-resistant, and key-recoverable decentralized identity
scheme that supports selective disclosure of credentials for arbitrary
predicates while maintaining privacy for credentials and identities. Through an
identifier association mechanism, LinkDID can privately and forcibly aggregate
users' identifiers, providing Sybil resistance without relying on any external
data or collateral from benign users. To enable key recovery, LinkDID permits
users to establish proofs of ownership for identifiers with lost keys and
request an update of corresponding keys from the decentralized ledger. We
provide a detailed theoretical analysis and security proofs of LinkDID, along
with an exhaustive performance evaluation that shows its ability to complete
interactions in less than 10 seconds on consumer-grade devices.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14680" title="Abstract">arXiv:2307.14680</a> [<a href="/pdf/2307.14680" title="Download PDF">pdf</a>, <a href="/format/2307.14680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TimeGNN: Temporal Dynamic Graph Learning for Time Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+N">Nancy Xu</a>, 
<a href="/search/cs?searchtype=author&query=Kosma%2C+C">Chrysoula Kosma</a>, 
<a href="/search/cs?searchtype=author&query=Vazirgiannis%2C+M">Michalis Vazirgiannis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Time series forecasting lies at the core of important real-world applications
in many fields of science and engineering. The abundance of large time series
datasets that consist of complex patterns and long-term dependencies has led to
the development of various neural network architectures. Graph neural network
approaches, which jointly learn a graph structure based on the correlation of
raw values of multivariate time series while forecasting, have recently seen
great success. However, such solutions are often costly to train and difficult
to scale. In this paper, we propose TimeGNN, a method that learns dynamic
temporal graph representations that can capture the evolution of inter-series
patterns along with the correlations of multiple series. TimeGNN achieves
inference times 4 to 80 times faster than other state-of-the-art graph-based
methods while achieving comparable forecasting performance
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14682" title="Abstract">arXiv:2307.14682</a> [<a href="/pdf/2307.14682" title="Download PDF">pdf</a>, <a href="/format/2307.14682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified Adversarial Patch for Visible-Infrared Cross-modal Attacks in  the Physical World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xingxing Wei</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yitong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jie Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 16 figures. arXiv admin note: substantial text overlap with <a href="/abs/2307.07859">arXiv:2307.07859</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Physical adversarial attacks have put a severe threat to DNN-based object
detectors. To enhance security, a combination of visible and infrared sensors
is deployed in various scenarios, which has proven effective in disabling
existing single-modal physical attacks. To further demonstrate the potential
risks in such cases, we design a unified adversarial patch that can perform
cross-modal physical attacks, achieving evasion in both modalities
simultaneously with a single patch. Given the different imaging mechanisms of
visible and infrared sensors, our work manipulates patches' shape features,
which can be captured in different modalities when they undergo changes. To
deal with challenges, we propose a novel boundary-limited shape optimization
approach that aims to achieve compact and smooth shapes for the adversarial
patch, making it easy to implement in the physical world. And a score-aware
iterative evaluation method is also introduced to balance the fooling degree
between visible and infrared detectors during optimization, which guides the
adversarial patch to iteratively reduce the predicted scores of the multi-modal
sensors. Furthermore, we propose an Affine-Transformation-based enhancement
strategy that makes the learnable shape robust to various angles, thus
mitigating the issue of shape deformation caused by different shooting angles
in the real world. Our method is evaluated against several state-of-the-art
object detectors, achieving an Attack Success Rate (ASR) of over 80%. We also
demonstrate the effectiveness of our approach in physical-world scenarios under
various settings, including different angles, distances, postures, and scenes
for both visible and infrared sensors.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14685" title="Abstract">arXiv:2307.14685</a> [<a href="/pdf/2307.14685" title="Download PDF">pdf</a>, <a href="/format/2307.14685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quinpi: Integrating stiff hyperbolic systems with implicit high order  finite volume schemes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Puppo%2C+G">Gabriella Puppo</a>, 
<a href="/search/math?searchtype=author&query=Semplice%2C+M">Matteo Semplice</a>, 
<a href="/search/math?searchtype=author&query=Visconti%2C+G">Giuseppe Visconti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 7 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Many interesting physical problems described by systems of hyperbolic
conservation laws are stiff, and thus impose a very small time-step because of
the restrictive CFL stability condition. In this case, one can exploit the
superior stability properties of implicit time integration which allows to
choose the time-step only from accuracy requirements, and thus avoid the use of
small time-steps. We discuss an efficient framework to devise high order
implicit schemes for stiff hyperbolic systems without tailoring it to a
specific problem. The nonlinearity of high order schemes, due to space- and
time-limiting procedures which control nonphysical oscillations, makes the
implicit time integration difficult, e.g.~because the discrete system is
nonlinear also on linear problems. This nonlinearity of the scheme is
circumvented as proposed in (Puppo et al., Comm.~Appl.~Math.~\&amp; Comput., 2023)
for scalar conservation laws, where a first order implicit predictor is
computed to freeze the nonlinear coefficients of the essentially
non-oscillatory space reconstruction, and also to achieve limiting in time. In
addition, we propose a novel conservative flux-based a-posteriori time-limiting
procedure using numerical entropy indicators to detect troubled cells. The
numerical tests involve classical and artificially devised stiff problems using
the Euler's system of gas-dynamics.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14686" title="Abstract">arXiv:2307.14686</a> [<a href="/pdf/2307.14686" title="Download PDF">pdf</a>, <a href="/format/2307.14686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Borinot: an open thrust-torque-controlled robot for research on agile  aerial-contact motion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mart%C3%AD-Saumell%2C+J">Josep Mart&#xed;-Saumell</a>, 
<a href="/search/cs?searchtype=author&query=Duarte%2C+H">Hugo Duarte</a>, 
<a href="/search/cs?searchtype=author&query=Grosch%2C+P">Patrick Grosch</a>, 
<a href="/search/cs?searchtype=author&query=Andrade-Cetto%2C+J">Juan Andrade-Cetto</a>, 
<a href="/search/cs?searchtype=author&query=Santamaria-Navarro%2C+A">Angel Santamaria-Navarro</a>, 
<a href="/search/cs?searchtype=author&query=Sol%C3%A0%2C+J">Joan Sol&#xe0;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 13 figures. See related video at <a href="https://youtu.be/Ob7IIVB6P_A">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper introduces Borinot, an open-source aerial robotic platform
designed to conduct research on hybrid agile locomotion and manipulation using
flight and contacts. This platform features an agile and powerful hexarotor
that can be outfitted with torque-actuated limbs of diverse architecture,
allowing for whole-body dynamic control. As a result, Borinot can perform agile
tasks such as aggressive or acrobatic maneuvers with the participation of the
whole-body dynamics.
<br />The limbs attached to Borinot can be utilized in various ways; during
contact, they can be used as legs to create contact-based locomotion, or as
arms to manipulate objects. In free flight, they can be used as tails to
contribute to dynamics, mimicking the movements of many animals. This allows
for any hybridization of these dynamic modes, making Borinot an ideal
open-source platform for research on hybrid aerial-contact agile motion.
<br />To demonstrate the key capabilities of Borinot in terms of agility with
hybrid motion modes, we have fitted a planar 2DoF limb and implemented a
whole-body torque-level model-predictive-control. The result is a capable and
adaptable platform that, we believe, opens up new avenues of research in the
field of agile robotics. Interesting links\footnote{Documentation:
\url{www.iri.upc.edu/borinot}}\footnote{Video:
\url{https://youtu.be/Ob7IIVB6P_A}}.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14688" title="Abstract">arXiv:2307.14688</a> [<a href="/pdf/2307.14688" title="Download PDF">pdf</a>, <a href="/format/2307.14688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Theoretical results on a block preconditioner used in ice-sheet  modeling: eigenvalue bounds for singular power-law fluids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Helanow%2C+C">Christian Helanow</a>, 
<a href="/search/math?searchtype=author&query=Ahlkrona%2C+J">Josefin Ahlkrona</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 6 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">The properties of a block preconditioner that has been successfully used in
finite element simulations of large scale ice-sheet flow is examined. The type
of preconditioner, based on approximating the Schur complement with the mass
matrix scaled by the variable viscosity, is well-known in the context of Stokes
flow and has previously been analyzed for other types of non-Newtonian fluids.
We adapt the theory to hold for the regularized constitutive (power-law)
equation for ice and derive eigenvalue bounds of the preconditioned system for
both Picard and Newton linearization using \emph{inf-sup} stable finite
elements. The eigenvalue bounds show that viscosity-scaled preconditioning
clusters the eigenvalues well with only a weak dependence on the regularization
parameter, while the eigenvalue bounds for the traditional non-viscosity-scaled
mass-matrix preconditioner are very sensitive to the same regularization
parameter. The results are verified numerically in two experiments using a
manufactured solution with low regularity and a simulation of glacier flow. The
numerical results further show that the computed eigenvalue bounds for the
viscosity-scaled preconditioner are nearly independent of the regularization
parameter. Experiments are performed using both Taylor-Hood and MINI elements,
which are the common choices for \emph{inf-sup} stable elements in ice-sheet
models. Both elements conform well to the theoretical eigenvalue bounds, with
MINI elements being more sensitive to the quality of the meshes used in glacier
simulations.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14692" title="Abstract">arXiv:2307.14692</a> [<a href="/pdf/2307.14692" title="Download PDF">pdf</a>, <a href="/format/2307.14692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backdoor Attacks for In-Context Learning with Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kandpal%2C+N">Nikhil Kandpal</a>, 
<a href="/search/cs?searchtype=author&query=Jagielski%2C+M">Matthew Jagielski</a>, 
<a href="/search/cs?searchtype=author&query=Tram%C3%A8r%2C+F">Florian Tram&#xe8;r</a>, 
<a href="/search/cs?searchtype=author&query=Carlini%2C+N">Nicholas Carlini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AdvML Frontiers Workshop 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Because state-of-the-art language models are expensive to train, most
practitioners must make use of one of the few publicly available language
models or language model APIs. This consolidation of trust increases the
potency of backdoor attacks, where an adversary tampers with a machine learning
model in order to make it perform some malicious behavior on inputs that
contain a predefined backdoor trigger. We show that the in-context learning
ability of large language models significantly complicates the question of
developing backdoor attacks, as a successful backdoor must work against various
prompting strategies and should not affect the model's general purpose
capabilities. We design a new attack for eliciting targeted misclassification
when language models are prompted to perform a particular target task and
demonstrate the feasibility of this attack by backdooring multiple large
language models ranging in size from 1.3 billion to 6 billion parameters.
Finally we study defenses to mitigate the potential harms of our attack: for
example, while in the white-box setting we show that fine-tuning models for as
few as 500 steps suffices to remove the backdoor behavior, in the black-box
setting we are unable to develop a successful defense that relies on prompt
engineering alone.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14697" title="Abstract">arXiv:2307.14697</a> [<a href="/pdf/2307.14697" title="Download PDF">pdf</a>, <a href="/ps/2307.14697" title="Download PostScript">ps</a>, <a href="/format/2307.14697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Space-Air-Ground Integrated Network (SAGIN): A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Han Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhe Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Since existing mobile communication networks may not be able to meet the low
latency and high-efficiency requirements of emerging technologies and
applications, novel network architectures need to be investigated to support
these new requirements. As a new network architecture that integrates satellite
systems, air networks and ground communication, Space-Air-Ground Integrated
Network (SAGIN) has attracted extensive attention in recent years. This paper
summarizes the recent research work on SAGIN from several aspects, with the
basic information of SAGIN first introduced, followed by the physical
characteristics. Then the drive and prospects of the current SAGIN architecture
in supporting new requirements are deeply analyzed. On this basis, the
requirements and challenges are analyzed. Finally, it summarizes the existing
solutions and prospects the future research directions.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14701" title="Abstract">arXiv:2307.14701</a> [<a href="/pdf/2307.14701" title="Download PDF">pdf</a>, <a href="/format/2307.14701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MIM-OOD: Generative Masked Image Modelling for Out-of-Distribution  Detection in Medical Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marimont%7D%2C+S+%7B">Sergio {Naval Marimont}</a>, 
<a href="/search/cs?searchtype=author&query=Siomos%2C+V">Vasilis Siomos</a>, 
<a href="/search/cs?searchtype=author&query=Tarroni%2C+G">Giacomo Tarroni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures. Accepted in DGM4MICCAI workshop @ MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unsupervised Out-of-Distribution (OOD) detection consists in identifying
anomalous regions in images leveraging only models trained on images of healthy
anatomy. An established approach is to tokenize images and model the
distribution of tokens with Auto-Regressive (AR) models. AR models are used to
1) identify anomalous tokens and 2) in-paint anomalous representations with
in-distribution tokens. However, AR models are slow at inference time and prone
to error accumulation issues which negatively affect OOD detection performance.
Our novel method, MIM-OOD, overcomes both speed and error accumulation issues
by replacing the AR model with two task-specific networks: 1) a transformer
optimized to identify anomalous tokens and 2) a transformer optimized to
in-paint anomalous tokens using masked image modelling (MIM). Our experiments
with brain MRI anomalies show that MIM-OOD substantially outperforms AR models
(DICE 0.458 vs 0.301) while achieving a nearly 25x speedup (9.5s vs 244s).
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14705" title="Abstract">arXiv:2307.14705</a> [<a href="/pdf/2307.14705" title="Download PDF">pdf</a>, <a href="/format/2307.14705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High Dynamic Range Imaging via Visual Attention Modules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Omrani%2C+A+R">Ali Reza Omrani</a>, 
<a href="/search/cs?searchtype=author&query=Moroni%2C+D">Davide Moroni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Thanks to High Dynamic Range (HDR) imaging methods, the scope of photography
has seen profound changes recently. To be more specific, such methods try to
reconstruct the lost luminosity of the real world caused by the limitation of
regular cameras from the Low Dynamic Range (LDR) images. Additionally, although
the State-Of-The-Art methods in this topic perform well, they mainly
concentrate on combining different exposures and have less attention to
extracting the informative parts of the images. Thus, this paper aims to
introduce a new model capable of incorporating information from the most
visible areas of each image extracted by a visual attention module (VAM), which
is a result of a segmentation strategy. In particular, the model, based on a
deep learning architecture, utilizes the extracted areas to produce the final
HDR image. The results demonstrate that our method outperformed most of the
State-Of-The-Art algorithms.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14707" title="Abstract">arXiv:2307.14707</a> [<a href="/pdf/2307.14707" title="Download PDF">pdf</a>, <a href="/format/2307.14707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Automata Theoretic Characterization of Weighted First-Order Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nevatia%2C+D">Dhruv Nevatia</a>, 
<a href="/search/cs?searchtype=author&query=Monmege%2C+B">Benjamin Monmege</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Since the 1970s with the work of McNaughton, Papert and Sch\"utzenberger, a
regular language is known to be definable in the first-order logic if and only
if its syntactic monoid is aperiodic. This algebraic characterisation of a
fundamental logical fragment has been extended in the quantitative case by
Droste and Gastin, dealing with polynomially ambiguous weighted automata and a
restricted fragment of weighted first-order logic. In the quantitative setting,
the full weighted first-order logic (without the restriction that Droste and
Gastin use, about the quantifier alternation) is more powerful than weighted
automata, and extensions of the automata with two-way navigation, and pebbles
or nested capabilities have been introduced to deal with it. In this work, we
characterise the fragment of these extended weighted automata that recognise
exactly the full weighted first-order logic, under the condition that automata
are polynomially ambiguous.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14709" title="Abstract">arXiv:2307.14709</a> [<a href="/pdf/2307.14709" title="Download PDF">pdf</a>, <a href="/format/2307.14709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taxonomy Adaptive Cross-Domain Adaptation in Medical Imaging via  Optimization Trajectory Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jianan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dongnan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">Hang Chang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Heng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Weidong Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The success of automated medical image analysis depends on large-scale and
expert-annotated training sets. Unsupervised domain adaptation (UDA) has been
raised as a promising approach to alleviate the burden of labeled data
collection. However, they generally operate under the closed-set adaptation
setting assuming an identical label set between the source and target domains,
which is over-restrictive in clinical practice where new classes commonly exist
across datasets due to taxonomic inconsistency. While several methods have been
presented to tackle both domain shifts and incoherent label sets, none of them
take into account the common characteristics of the two issues and consider the
learning dynamics along network training. In this work, we propose optimization
trajectory distillation, a unified approach to address the two technical
challenges from a new perspective. It exploits the low-rank nature of gradient
space and devises a dual-stream distillation algorithm to regularize the
learning dynamics of insufficiently annotated domain and classes with the
external guidance obtained from reliable sources. Our approach resolves the
issue of inadequate navigation along network optimization, which is the major
obstacle in the taxonomy adaptive cross-domain adaptation scenario. We evaluate
the proposed method extensively on several tasks towards various endpoints with
clinical and open-world significance. The results demonstrate its effectiveness
and improvements over previous methods.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14710" title="Abstract">arXiv:2307.14710</a> [<a href="/pdf/2307.14710" title="Download PDF">pdf</a>, <a href="/format/2307.14710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-training Vision Transformers with Very Limited Synthesized Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nakamura1%2C+R">Ryo Nakamura1</a>, 
<a href="/search/cs?searchtype=author&query=Kataoka%2C+H">Hirokatsu Kataoka</a>, 
<a href="/search/cs?searchtype=author&query=Takashima%2C+S">Sora Takashima</a>, 
<a href="/search/cs?searchtype=author&query=Noriega%2C+E+J+M">Edgar Josafat Martinez Noriega</a>, 
<a href="/search/cs?searchtype=author&query=Yokota%2C+R">Rio Yokota</a>, 
<a href="/search/cs?searchtype=author&query=Inoue%2C+N">Nakamasa Inoue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Formula-driven supervised learning (FDSL) is a pre-training method that
relies on synthetic images generated from mathematical formulae such as
fractals. Prior work on FDSL has shown that pre-training vision transformers on
such synthetic datasets can yield competitive accuracy on a wide range of
downstream tasks. These synthetic images are categorized according to the
parameters in the mathematical formula that generate them. In the present work,
we hypothesize that the process for generating different instances for the same
category in FDSL, can be viewed as a form of data augmentation. We validate
this hypothesis by replacing the instances with data augmentation, which means
we only need a single image per category. Our experiments shows that this
one-instance fractal database (OFDB) performs better than the original dataset
where instances were explicitly generated. We further scale up OFDB to 21,000
categories and show that it matches, or even surpasses, the model pre-trained
on ImageNet-21k in ImageNet-1k fine-tuning. The number of images in OFDB is
21k, whereas ImageNet-21k has 14M. This opens new possibilities for
pre-training vision transformers with much smaller datasets.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14712" title="Abstract">arXiv:2307.14712</a> [<a href="/pdf/2307.14712" title="Download PDF">pdf</a>, <a href="/format/2307.14712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Generative Models for Graph-to-Text Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+S">Shuzhou Yuan</a>, 
<a href="/search/cs?searchtype=author&query=F%C3%A4rber%2C+M">Michael F&#xe4;rber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as short paper in RANLP2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have been widely employed for graph-to-text
generation tasks. However, the process of finetuning LLMs requires significant
training resources and annotation work. In this paper, we explore the
capability of generative models to generate descriptive text from graph data in
a zero-shot setting. Specifically, we evaluate GPT-3 and ChatGPT on two
graph-to-text datasets and compare their performance with that of finetuned LLM
models such as T5 and BART. Our results demonstrate that generative models are
capable of generating fluent and coherent text, achieving BLEU scores of 10.57
and 11.08 for the AGENDA and WebNLG datasets, respectively. However, our error
analysis reveals that generative models still struggle with understanding the
semantic relations between entities, and they also tend to generate text with
hallucinations or irrelevant information. As a part of error analysis, we
utilize BERT to detect machine-generated text and achieve high macro-F1 scores.
We have made the text generated by generative models publicly available.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14713" title="Abstract">arXiv:2307.14713</a> [<a href="/pdf/2307.14713" title="Download PDF">pdf</a>, <a href="/format/2307.14713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GaitMorph: Transforming Gait by Optimally Transporting Discrete Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cosma%2C+A">Adrian Cosma</a>, 
<a href="/search/cs?searchtype=author&query=Radoi%2C+E">Emilian Radoi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 Tables, 6 Figures, 1 Algorithm
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Gait, the manner of walking, has been proven to be a reliable biometric with
uses in surveillance, marketing and security. A promising new direction for the
field is training gait recognition systems without explicit human annotations,
through self-supervised learning approaches. Such methods are heavily reliant
on strong augmentations for the same walking sequence to induce more data
variability and to simulate additional walking variations. Current data
augmentation schemes are heuristic and cannot provide the necessary data
variation as they are only able to provide simple temporal and spatial
distortions. In this work, we propose GaitMorph, a novel method to modify the
walking variation for an input gait sequence. Our method entails the training
of a high-compression model for gait skeleton sequences that leverages
unlabelled data to construct a discrete and interpretable latent space, which
preserves identity-related features. Furthermore, we propose a method based on
optimal transport theory to learn latent transport maps on the discrete
codebook that morph gait sequences between variations. We perform extensive
experiments and show that our method is suitable to synthesize additional views
for an input sequence.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14718" title="Abstract">arXiv:2307.14718</a> [<a href="/pdf/2307.14718" title="Download PDF">pdf</a>, <a href="/format/2307.14718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a New Interface for Music Listening: A User Experience Study on  YouTube
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+A">Ahyeon Choi</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+E">Eunsik Shin</a>, 
<a href="/search/cs?searchtype=author&query=Joung%2C+H">Haesun Joung</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Joongseek Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kyogu Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages without reference, 1 figure, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In light of the enduring success of music streaming services, it is
noteworthy that an increasing number of users are positively gravitating toward
YouTube as their preferred platform for listening to music. YouTube differs
from typical music streaming services in that they provide a diverse range of
music-related videos as well as soundtracks. However, despite the increasing
popularity of using YouTube as a platform for music consumption, there is still
a lack of comprehensive research on this phenomenon. As independent researchers
unaffiliated with YouTube, we conducted semi-structured interviews with 27
users who listen to music through YouTube more than three times a week to
investigate its usability and interface satisfaction. Our qualitative analysis
found that YouTube has five main meanings for users as a music streaming
service: 1) exploring musical diversity, 2) sharing unique playlists, 3)
providing visual satisfaction, 4) facilitating user interaction, and 5)
allowing free and easy access. We also propose wireframes of a video streaming
service for better audio-visual music listening in two stages: search and
listening. By these wireframes, we offer practical solutions to enhance user
satisfaction with YouTube for music listening. These findings have wider
implications beyond YouTube and could inform enhancements in other music
streaming services as well.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14721" title="Abstract">arXiv:2307.14721</a> [<a href="/pdf/2307.14721" title="Download PDF">pdf</a>, <a href="/format/2307.14721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Singularity Distance Computations of 3-RPR Manipulators Using Intrinsic  Metrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kapilavai%2C+A">Aditya Kapilavai</a>, 
<a href="/search/cs?searchtype=author&query=Nawratil%2C+G">Georg Nawratil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">We present an efficient algorithm for computing the closest singular
configuration to each non-singular pose of a 3-RPR planar manipulator
performing a 1-parametric motion. By considering a 3-RPR manipulator as a
planar framework, one can use methods from rigidity theory to compute the
singularity distance with respect to an intrinsic metric. There are different
design options as the platform/base can be seen as a triangular plate or as a
pin-jointed triangular bar structure. Moreover, we also allow the additional
possibility of pinning down the base/platform triangle to the fixed/moving
system thus it cannot be deformed. For the resulting nine interpretations, we
compute the corresponding intrinsic metrics based on the total elastic strain
energy density of the framework using the physical concept of Green-Lagrange
strain. The global optimization problem of finding the closest singular
configuration with respect to these metrics is solved by using tools from
numerical algebraic geometry. The proposed algorithm is demonstrated based on
an example.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14723" title="Abstract">arXiv:2307.14723</a> [<a href="/pdf/2307.14723" title="Download PDF">pdf</a>, <a href="/format/2307.14723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EFLNet: Enhancing Feature Learning for Infrared Small Target Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiahao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+D">Dongjian Tian</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jun Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mingliang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Pi%2C+Y">Yangjun Pi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Single-frame infrared small target detection is considered to be a
challenging task, due to the extreme imbalance between target and background,
bounding box regression is extremely sensitive to infrared small targets, and
small target information is easy to lose in the high-level semantic layer. In
this paper, we propose an enhancing feature learning network (EFLNet) based on
YOLOv7 framework to solve these problems. First, we notice that there is an
extremely imbalance between the target and the background in the infrared
image, which makes the model pay more attention to the background features,
resulting in missed detection. To address this problem, we propose a new
adaptive threshold focal loss function that adjusts the loss weight
automatically, compelling the model to allocate greater attention to target
features. Second, we introduce the normalized Gaussian Wasserstein distance to
alleviate the difficulty of model convergence caused by the extreme sensitivity
of the bounding box regression to infrared small targets. Finally, we
incorporate a dynamic head mechanism into the network to enable adaptive
learning of the relative importance of each semantic layer. Experimental
results demonstrate our method can achieve better performance in the detection
performance of infrared small targets compared to state-of-the-art
deep-learning based methods.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14725" title="Abstract">arXiv:2307.14725</a> [<a href="/pdf/2307.14725" title="Download PDF">pdf</a>, <a href="/format/2307.14725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> vox2vec: A Framework for Self-supervised Contrastive Learning of  Voxel-level Representations in Medical Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goncharov%2C+M">Mikhail Goncharov</a>, 
<a href="/search/cs?searchtype=author&query=Soboleva%2C+V">Vera Soboleva</a>, 
<a href="/search/cs?searchtype=author&query=Kurmukov%2C+A">Anvar Kurmukov</a>, 
<a href="/search/cs?searchtype=author&query=Pisov%2C+M">Maxim Pisov</a>, 
<a href="/search/cs?searchtype=author&query=Belyaev%2C+M">Mikhail Belyaev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper introduces vox2vec - a contrastive method for self-supervised
learning (SSL) of voxel-level representations. vox2vec representations are
modeled by a Feature Pyramid Network (FPN): a voxel representation is a
concatenation of the corresponding feature vectors from different pyramid
levels. The FPN is pre-trained to produce similar representations for the same
voxel in different augmented contexts and distinctive representations for
different voxels. This results in unified multi-scale representations that
capture both global semantics (e.g., body part) and local semantics (e.g.,
different small organs or healthy versus tumor tissue). We use vox2vec to
pre-train a FPN on more than 6500 publicly available computed tomography
images. We evaluate the pre-trained representations by attaching simple heads
on top of them and training the resulting models for 22 segmentation tasks. We
show that vox2vec outperforms existing medical imaging SSL techniques in three
evaluation setups: linear and non-linear probing and end-to-end fine-tuning.
Moreover, a non-linear head trained on top of the frozen vox2vec
representations achieves competitive performance with the FPN trained from
scratch while having 50 times fewer trainable parameters. The code is available
at https://github.com/mishgon/vox2vec .
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14726" title="Abstract">arXiv:2307.14726</a> [<a href="/pdf/2307.14726" title="Download PDF">pdf</a>, <a href="/format/2307.14726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> P2C: Self-Supervised Point Cloud Completion from Single Partial Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+R">Ruikai Cui</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+S">Shi Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Anwar%2C+S">Saeed Anwar</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiawei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+C">Chaoyue Xing</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Barnes%2C+N">Nick Barnes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Point cloud completion aims to recover the complete shape based on a partial
observation. Existing methods require either complete point clouds or multiple
partial observations of the same object for learning. In contrast to previous
approaches, we present Partial2Complete (P2C), the first self-supervised
framework that completes point cloud objects using training samples consisting
of only a single incomplete point cloud per object. Specifically, our framework
groups incomplete point clouds into local patches as input and predicts masked
patches by learning prior information from different partial objects. We also
propose Region-Aware Chamfer Distance to regularize shape mismatch without
limiting completion capability, and devise the Normal Consistency Constraint to
incorporate a local planarity assumption, encouraging the recovered shape
surface to be continuous and complete. In this way, P2C no longer needs
multiple observations or complete point clouds as ground truth. Instead,
structural cues are learned from a category-specific dataset to complete
partial point clouds of objects. We demonstrate the effectiveness of our
approach on both synthetic ShapeNet data and real-world ScanNet data, showing
that P2C produces comparable results to methods trained with complete shapes,
and outperforms methods learned with multiple partial observations. Code is
available at https://github.com/CuiRuikai/Partial2Complete.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14731" title="Abstract">arXiv:2307.14731</a> [<a href="/pdf/2307.14731" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bi-level Network Design for UAM Vertiport Allocation Using  Activity-Based Transport Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brulin%2C+S">Sebastian Brulin</a>, 
<a href="/search/cs?searchtype=author&query=Olhofer%2C+M">Markus Olhofer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6th International Electric Vehicle Technology Conference 2023 (EVTeC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">The design or the optimization of transport systems is a difficult task. This
is especially true in the case of the introduction of new transport modes in an
existing system. The main reason is, that even small additions and changes
result in the emergence of new travel patterns, likely resulting in an
adaptation of the travel behavior of multiple other agents in the system. Here
we consider the optimization of future Urban Air Mobility services under
consideration of effects induced by the new mode to an existing system. We
tackle this problem through a bi-level network design approach, in which the
discrete decisions of the network design planner are optimized based on the
evaluated dynamic demand of the user's mode choices. We solve the
activity-based network design problem (AB-NDP) using a Genetic Algorithm on a
multi-objective optimization problem while evaluating the dynamic demand with
the large-scale Multi-Agent Transport Simulation (MATSim) framework. The
proposed bi-level approach is compared against the results of a coverage
approach using a static demand method. The bi-level study shows better results
for expected UAM demand and total travel time savings across the transportation
system. Due to its generic character, the demonstrated utilization of a
bi-level method is applicable to other mobility service design questions and to
other regions.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14732" title="Abstract">arXiv:2307.14732</a> [<a href="/pdf/2307.14732" title="Download PDF">pdf</a>, <a href="/format/2307.14732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Strategic Framework for Optimal Decisions in Football 1-vs-1  Shot-Taking Situations: An Integrated Approach of Machine Learning,  Theory-Based Modeling, and Game Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeung%2C+C+C+K">Calvin C. K. Yeung</a>, 
<a href="/search/cs?searchtype=author&query=Fujii%2C+K">Keisuke Fujii</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Complex interactions between two opposing agents frequently occur in domains
of machine learning, game theory, and other application domains. Quantitatively
analyzing the strategies involved can provide an objective basis for
decision-making. One such critical scenario is shot-taking in football, where
decisions, such as whether the attacker should shoot or pass the ball and
whether the defender should attempt to block the shot, play a crucial role in
the outcome of the game. However, there are currently no effective data-driven
and/or theory-based approaches to analyzing such situations. To address this
issue, we proposed a novel framework to analyze such scenarios based on game
theory, where we estimate the expected payoff with machine learning (ML)
models, and additional features for ML models were extracted with a
theory-based shot block model. Conventionally, successes or failures (1 or 0)
are used as payoffs, while a success shot (goal) is extremely rare in football.
Therefore, we proposed the Expected Probability of Shot On Target (xSOT) metric
to evaluate players' actions even if the shot results in no goal; this allows
for effective differentiation and comparison between different shots and even
enables counterfactual shot situation analysis. In our experiments, we have
validated the framework by comparing it with baseline and ablated models.
Furthermore, we have observed a high correlation between the xSOT and existing
metrics. This alignment of information suggests that xSOT provides valuable
insights. Lastly, as an illustration, we studied optimal strategies in the
World Cup 2022 and analyzed a shot situation in EURO 2020.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14733" title="Abstract">arXiv:2307.14733</a> [<a href="/pdf/2307.14733" title="Download PDF">pdf</a>, <a href="/format/2307.14733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StubCoder: Automated Generation and Repair of Stub Code for Mock Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hengcheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+L">Lili Wei</a>, 
<a href="/search/cs?searchtype=author&query=Terragni%2C+V">Valerio Terragni</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yepang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+S">Shing-Chi Cheung</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiarong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+Q">Qin Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Lihong Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was accepted by the ACM Transactions on Software Engineering and Methodology (TOSEM) in July 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Mocking is an essential unit testing technique for isolating the class under
test (CUT) from its dependencies. Developers often leverage mocking frameworks
to develop stub code that specifies the behaviors of mock objects. However,
developing and maintaining stub code is labor-intensive and error-prone. In
this paper, we present StubCoder to automatically generate and repair stub code
for regression testing. StubCoder implements a novel evolutionary algorithm
that synthesizes test-passing stub code guided by the runtime behavior of test
cases. We evaluated our proposed approach on 59 test cases from 13 open-source
projects. Our evaluation results show that StubCoder can effectively generate
stub code for incomplete test cases without stub code and repair obsolete test
cases with broken stub code.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14735" title="Abstract">arXiv:2307.14735</a> [<a href="/pdf/2307.14735" title="Download PDF">pdf</a>, <a href="/format/2307.14735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Test Time Adaptation for Blind Image Quality Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+S">Subhadeep Roy</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+S">Shankhanil Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+S">Soma Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Soundararajan%2C+R">Rajiv Soundararajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">While the design of blind image quality assessment (IQA) algorithms has
improved significantly, the distribution shift between the training and testing
scenarios often leads to a poor performance of these methods at inference time.
This motivates the study of test time adaptation (TTA) techniques to improve
their performance at inference time. Existing auxiliary tasks and loss
functions used for TTA may not be relevant for quality-aware adaptation of the
pre-trained model. In this work, we introduce two novel quality-relevant
auxiliary tasks at the batch and sample levels to enable TTA for blind IQA. In
particular, we introduce a group contrastive loss at the batch level and a
relative rank loss at the sample level to make the model quality aware and
adapt to the target data. Our experiments reveal that even using a small batch
of images from the test distribution helps achieve significant improvement in
performance by updating the batch normalization statistics of the source model.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14740" title="Abstract">arXiv:2307.14740</a> [<a href="/pdf/2307.14740" title="Download PDF">pdf</a>, <a href="/format/2307.14740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Interaction Paradigm for Complex EDA Software Leveraging GPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Boyu Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junyu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yidong Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the rapidly growing field of electronic design automation (EDA),
professional software such as KiCad, Cadence , and Altium Designer provide
increasingly extensive design functionalities. However, the intricate command
structure and high learning curve create a barrier, particularly for novice
printed circuit board (PCB) designers. This results in difficulties in
selecting appropriate functions or plugins for varying design purposes,
compounded by the lack of intuitive learning methods beyond traditional
documentation, videos, and online forums. To address this challenge, an
artificial intelligence (AI) interaction assist plugin for EDA software named
SmartonAl is developed here, also KiCad is taken as the first example.
SmartonAI is inspired by the HuggingGPT framework and employs large language
models, such as GPT and BERT, to facilitate task planning and execution. On
receiving a designer request, SmartonAI conducts a task breakdown and
efficiently executes relevant subtasks, such as analysis of help documentation
paragraphs and execution of different plugins, along with leveraging the
built-in schematic and PCB manipulation functions in both SmartonAl itself and
software. Our preliminary results demonstrate that SmartonAI can significantly
streamline the PCB design process by simplifying complex commands into
intuitive language-based interactions. By harnessing the powerful language
capabilities of ChatGPT and the rich design functions of KiCad, the plugin
effectively bridges the gap between complex EDA software and user-friendly
interaction. Meanwhile, the new paradigm behind SmartonAI can also extend to
other complex software systems, illustrating the immense potential of
AI-assisted user interfaces in advancing digital interactions across various
domains.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14743" title="Abstract">arXiv:2307.14743</a> [<a href="/pdf/2307.14743" title="Download PDF">pdf</a>, <a href="/format/2307.14743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Turning Whisper into Real-Time Transcription System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mach%C3%A1%C4%8Dek%2C+D">Dominik Mach&#xe1;&#x10d;ek</a>, 
<a href="/search/cs?searchtype=author&query=Dabre%2C+R">Raj Dabre</a>, 
<a href="/search/cs?searchtype=author&query=Bojar%2C+O">Ond&#x159;ej Bojar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> system demonstration pre-print
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Whisper is one of the recent state-of-the-art multilingual speech recognition
and translation models, however, it is not designed for real time
transcription. In this paper, we build on top of Whisper and create
Whisper-Streaming, an implementation of real-time speech transcription and
translation of Whisper-like models. Whisper-Streaming uses local agreement
policy with self-adaptive latency to enable streaming transcription. We show
that Whisper-Streaming achieves high quality and 3.3 seconds latency on
unsegmented long-form speech transcription test set, and we demonstrate its
robustness and practical usability as a component in live transcription service
at a multilingual conference.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14744" title="Abstract">arXiv:2307.14744</a> [<a href="/pdf/2307.14744" title="Download PDF">pdf</a>, <a href="/format/2307.14744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wait-Free Updates and Range Search using Uruv
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhardwaj%2C+G">Gaurav Bhardwaj</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Abhay Jain</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+B">Bapi Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Peri%2C+S">Sathya Peri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Databases (cs.DB)

</div>
<p class="mathjax">CRUD operations, along with range queries make a highly useful abstract data
type (ADT), employed by many dynamic analytics tasks. Despite its wide
applications, to our knowledge, no fully wait-free data structure is known to
support this ADT. In this paper, we introduce Uruv, a proactive linearizable
and practical wait-free concurrent data structure that implements the ADT
mentioned above. Structurally, Uruv installs a balanced search index on the
nodes of a linked list. Uruv is the first wait-free and proactive solution for
concurrent B+tree. Experiments show that Uruv significantly outperforms
previously proposed lock-free B+trees for dictionary operations and a recently
proposed lock-free method to implement the ADT mentioned above.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14745" title="Abstract">arXiv:2307.14745</a> [<a href="/pdf/2307.14745" title="Download PDF">pdf</a>, <a href="/format/2307.14745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Multi-Agent MicroServices (MAMS) for Agent Based Modelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jagutis%2C+M">Martynas Jagutis</a>, 
<a href="/search/cs?searchtype=author&query=Russell%2C+S">Sean Russell</a>, 
<a href="/search/cs?searchtype=author&query=Collier%2C+R">Rem Collier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 page demo paper accepted at EMAS. Paper has been extended from this version and submitted for publication in the formal proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">This paper demonstrates the use of the Multi-Agent MicroServices (MAMS)
architectural style through a case study based around the development of a
prototype traffic simulation in which agents model a population of individuals
who travel from home to work and vice versa by car.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14747" title="Abstract">arXiv:2307.14747</a> [<a href="/pdf/2307.14747" title="Download PDF">pdf</a>, <a href="/format/2307.14747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Task-Space Quadratic Programming for Kinematic-Controlled Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Djeha%2C+M">Mohamed Djeha</a>, 
<a href="/search/cs?searchtype=author&query=Gergondet%2C+P">Pierre Gergondet</a>, 
<a href="/search/cs?searchtype=author&query=Kheddar%2C+A">Abderrahmane Kheddar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 24 figures, accepted for publication in IEEE Transactions on Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Task-space quadratic programming (QP) is an elegant approach for controlling
robots subject to constraints. Yet, in the case of kinematic-controlled (i.e.,
high-gains position or velocity) robots, closed-loop QP control scheme can be
prone to instability depending on how the gains related to the tasks or the
constraints are chosen.
<br />In this paper, we address such instability shortcomings. First, we highlight
the non-robustness of the closed-loop system against non-modeled dynamics, such
as those relative to joint-dynamics, flexibilities, external perturbations,
etc. Then, we propose a robust QP control formulation based on high-level
integral feedback terms in the task-space including the constraints. The
proposed method is formally proved to ensure closed-loop robust stability and
is intended to be applied to any kinematic-controlled robots under practical
assumptions. We assess our approach through experiments on a fixed-base robot
performing stable fast motions, and a floating-base humanoid robot robustly
reacting to perturbations to keep its balance.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14748" title="Abstract">arXiv:2307.14748</a> [<a href="/pdf/2307.14748" title="Download PDF">pdf</a>, <a href="/format/2307.14748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Image Completion and Enhancement using GANs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saxena%2C+P">Priyansh Saxena</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+R">Raahat Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Maheshwari%2C+A">Akshat Maheshwari</a>, 
<a href="/search/cs?searchtype=author&query=Maheshwari%2C+S">Saumil Maheshwari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is part of 'High-Performance Vision Intelligence'; Part of the Studies in Computational Intelligence book series (SCI, volume 913) and can be accessed at: <a href="https://link.springer.com/chapter/10.1007/978-981-15-6844-2_11.">this https URL</a> arXiv admin note: substantial text overlap with <a href="/abs/1911.02222">arXiv:1911.02222</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Semantic inpainting or image completion alludes to the task of inferring
arbitrary large missing regions in images based on image semantics. Since the
prediction of image pixels requires an indication of high-level context, this
makes it significantly tougher than image completion, which is often more
concerned with correcting data corruption and removing entire objects from the
input image. On the other hand, image enhancement attempts to eliminate
unwanted noise and blur from the image, along with sustaining most of the image
details. Efficient image completion and enhancement model should be able to
recover the corrupted and masked regions in images and then refine the image
further to increase the quality of the output image. Generative Adversarial
Networks (GAN), have turned out to be helpful in picture completion tasks. In
this chapter, we will discuss the underlying GAN architecture and how they can
be used used for image completion tasks.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14749" title="Abstract">arXiv:2307.14749</a> [<a href="/pdf/2307.14749" title="Download PDF">pdf</a>, <a href="/format/2307.14749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Gameplay Videos for Detecting Issues in Video Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guglielmi%2C+E">Emanuela Guglielmi</a>, 
<a href="/search/cs?searchtype=author&query=Scalabrino%2C+S">Simone Scalabrino</a>, 
<a href="/search/cs?searchtype=author&query=Bavota%2C+G">Gabriele Bavota</a>, 
<a href="/search/cs?searchtype=author&query=Oliveto%2C+R">Rocco Oliveto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Empirical Software Engineering journal (EMSE). arXiv admin note: text overlap with <a href="/abs/2204.04182">arXiv:2204.04182</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Context. The game industry is increasingly growing in recent years. Every
day, millions of people play video games, not only as a hobby, but also for
professional competitions (e.g., e-sports or speed-running) or for making
business by entertaining others (e.g., streamers). The latter daily produce a
large amount of gameplay videos in which they also comment live what they
experience. But no software and, thus, no video game is perfect: Streamers may
encounter several problems (such as bugs, glitches, or performance issues)
while they play. Also, it is unlikely that they explicitly report such issues
to developers. The identified problems may negatively impact the user's gaming
experience and, in turn, can harm the reputation of the game and of the
producer. Objective. In this paper, we propose and empirically evaluate GELID,
an approach for automatically extracting relevant information from gameplay
videos by (i) identifying video segments in which streamers experienced
anomalies; (ii) categorizing them based on their type (e.g., logic or
presentation); clustering them based on (iii) the context in which appear
(e.g., level or game area) and (iv) on the specific issue type (e.g., game
crashes). Method. We manually defined a training set for step 2 of GELID
(categorization) and a test set for validating in isolation the four components
of GELID. In total, we manually segmented, labeled, and clustered 170 videos
related to 3 video games, defining a dataset containing 604 segments. Results.
While in steps 1 (segmentation) and 4 (specific issue clustering) GELID
achieves satisfactory results, it shows limitations on step 3 (game context
clustering) and, above all, step 2 (categorization).
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14750" title="Abstract">arXiv:2307.14750</a> [<a href="/pdf/2307.14750" title="Download PDF">pdf</a>, <a href="/format/2307.14750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Annotation-free Image Captioning with Retrieval-augmented  Pseudo Sentence Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dongnan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Heng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chaoyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Weidong Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Training an image captioner without annotated image-sentence pairs has gained
traction in recent years. Previous approaches can be categorized into two
strategies: crawling sentences from mismatching corpora and aligning them with
the given images as pseudo annotations, or pre-training the captioner using
external image-text pairs. However, the aligning setting seems to reach its
performance limit due to the quality problem of pairs, and pre-training
requires significant computational resources. To address these challenges, we
propose a new strategy ``LPM + retrieval-augmented learning" where the prior
knowledge from large pre-trained models (LPMs) is leveraged as supervision, and
a retrieval process is integrated to further reinforce its effectiveness.
Specifically, we introduce Retrieval-augmented Pseudo Sentence Generation
(RaPSG), which adopts an efficient approach to retrieve highly relevant short
region descriptions from the mismatching corpora and use them to generate a
variety of pseudo sentences with distinct representations as well as high
quality via LPMs. In addition, a fluency filter and a CLIP-guided training
objective are further introduced to facilitate model optimization. Experimental
results demonstrate that our method surpasses the SOTA pre-training model
(Flamingo3B) by achieving a CIDEr score of 78.1 (+5.1) while utilizing only
0.3% of its trainable parameters (1.3B VS 33M). Importantly, our approach
eliminates the need of computationally expensive pre-training processes on
external datasets (e.g., the requirement of 312M image-text pairs for
Flamingo3B). We further show that with a simple extension, the generated pseudo
sentences can be deployed as weak supervision to boost the 1% semi-supervised
image caption benchmark up to 93.4 CIDEr score (+8.9) which showcases the
versatility and effectiveness of our approach.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14751" title="Abstract">arXiv:2307.14751</a> [<a href="/pdf/2307.14751" title="Download PDF">pdf</a>, <a href="/format/2307.14751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FLARE: Fingerprinting Deep Reinforcement Learning Agents using Universal  Adversarial Masks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tekgul%2C+B+G+A">Buse G. A. Tekgul</a>, 
<a href="/search/cs?searchtype=author&query=Asokan%2C+N">N. Asokan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">We propose FLARE, the first fingerprinting mechanism to verify whether a
suspected Deep Reinforcement Learning (DRL) policy is an illegitimate copy of
another (victim) policy. We first show that it is possible to find
non-transferable, universal adversarial masks, i.e., perturbations, to generate
adversarial examples that can successfully transfer from a victim policy to its
modified versions but not to independently trained policies. FLARE employs
these masks as fingerprints to verify the true ownership of stolen DRL policies
by measuring an action agreement value over states perturbed via such masks.
Our empirical evaluations show that FLARE is effective (100% action agreement
on stolen copies) and does not falsely accuse independent policies (no false
positives). FLARE is also robust to model modification attacks and cannot be
easily evaded by more informed adversaries without negatively impacting agent
performance. We also show that not all universal adversarial masks are suitable
candidates for fingerprints due to the inherent characteristics of DRL
policies. The spatio-temporal dynamics of DRL problems and sequential
decision-making process make characterizing the decision boundary of DRL
policies more difficult, as well as searching for universal masks that capture
the geometry of it.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14754" title="Abstract">arXiv:2307.14754</a> [<a href="/pdf/2307.14754" title="Download PDF">pdf</a>, <a href="/format/2307.14754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Machine Unlearning: Data Removal while Mitigating Disparities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oesterling%2C+A">Alex Oesterling</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jiaqi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Calmon%2C+F+P">Flavio P. Calmon</a>, 
<a href="/search/cs?searchtype=author&query=Lakkaraju%2C+H">Hima Lakkaraju</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 3 figures, accepted to ICML 2023 DMLR Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As public consciousness regarding the collection and use of personal
information by corporations grows, it is of increasing importance that
consumers be active participants in the curation of corporate datasets. In
light of this, data governance frameworks such as the General Data Protection
Regulation (GDPR) have outlined the right to be forgotten as a key principle
allowing individuals to request that their personal data be deleted from the
databases and models used by organizations. To achieve forgetting in practice,
several machine unlearning methods have been proposed to address the
computational inefficiencies of retraining a model from scratch with each
unlearning request. While efficient online alternatives to retraining, it is
unclear how these methods impact other properties critical to real-world
applications, such as fairness. In this work, we propose the first fair machine
unlearning method that can provably and efficiently unlearn data instances
while preserving group fairness. We derive theoretical results which
demonstrate that our method can provably unlearn data instances while
maintaining fairness objectives. Extensive experimentation with real-world
datasets highlight the efficacy of our method at unlearning data instances
while preserving fairness.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14757" title="Abstract">arXiv:2307.14757</a> [<a href="/pdf/2307.14757" title="Download PDF">pdf</a>, <a href="/format/2307.14757" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEV-Step: A Single-Stepping Framework for AMD-SEV
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wilke%2C+L">Luca Wilke</a>, 
<a href="/search/cs?searchtype=author&query=Wichelmann%2C+J">Jan Wichelmann</a>, 
<a href="/search/cs?searchtype=author&query=Rabich%2C+A">Anja Rabich</a>, 
<a href="/search/cs?searchtype=author&query=Eisenbarth%2C+T">Thomas Eisenbarth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The ever increasing popularity and availability of Trusted Execution
Environments (TEEs) had a stark influence on microarchitectural attack research
in academia, as their strong attacker model both boosts existing attack vectors
and introduces several new ones. While many works have focused on Intel SGX,
other TEEs like AMD SEV have recently also started to receive more attention. A
common technique when attacking SGX enclaves is single-stepping, where the
system's APIC timer is used to interrupt the enclave after every instruction.
Single-stepping increases the temporal resolution of subsequent
microarchitectural attacks to a maximum. A key driver in the proliferation of
this complex attack technique was the SGX-Step framework, which offered a
stable reference implementation for single-stepping and a relatively easy
setup. In this paper, we demonstrate that SEV VMs can also be reliably
single-stepped. To lay the foundation for further microarchitectural attack
research against SEV, we introduce the reusable SEV-Step framework. Besides
reliable single-stepping, SEV-Step provides easy access to common attack
primitives like page fault tracking and cache attacks against SEV. All features
can be used interactively from user space. We demonstrate SEV-Step's
capabilities by carrying out an end-to-end cache attack against SEV that leaks
the volume key of a LUKS2-encrypted disk. Finally, we show for the first time
that SEV is vulnerable to Nemesis-style attacks, which allow to extract
information about the type and operands of single-stepped instructions from
SEV-protected VMs.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14758" title="Abstract">arXiv:2307.14758</a> [<a href="/pdf/2307.14758" title="Download PDF">pdf</a>, <a href="/format/2307.14758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Practicable Sequential Shift Detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cobb%2C+O">Oliver Cobb</a>, 
<a href="/search/cs?searchtype=author&query=Van+Looveren%2C+A">Arnaud Van Looveren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICML 2022 Workshop on Principles of Distribution Shift (PODS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">There is a growing awareness of the harmful effects of distribution shift on
the performance of deployed machine learning models. Consequently, there is a
growing interest in detecting these shifts before associated costs have time to
accumulate. However, desiderata of crucial importance to the practicable
deployment of sequential shift detectors are typically overlooked by existing
works, precluding their widespread adoption. We identify three such desiderata,
highlight existing works relevant to their satisfaction, and recommend
impactful directions for future research.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14761" title="Abstract">arXiv:2307.14761</a> [<a href="/pdf/2307.14761" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Literature Survey on how to cluster and define Living Labs, Real World  Laboratories and similar research infrastructures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luu%2C+T+G">Troung Giang Luu</a>, 
<a href="/search/cs?searchtype=author&query=Zylowski%2C+T">Tanja Zylowski</a>, 
<a href="/search/cs?searchtype=author&query=Alpers%2C+S">Sascha Alpers</a>, 
<a href="/search/cs?searchtype=author&query=Oberweis%2C+A">Andreas Oberweis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">In today's world, where societal challenges in the areas of digitalization,
demographic change and sustainability are becoming increasingly complex, new
innovation structures are needed to meet these challenges. Living Labs or also
Real World Laboratories prove to be such. Through their applied methods such as
co-creation, they integrate users into research, making it more user-centric.
Which other research infrastructures exist and how they can be differentiated
is presented in this paper on the basis of a systematic literature research.
Furthermore, methods for user integration are examined and provided in the form
of an overview.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14768" title="Abstract">arXiv:2307.14768</a> [<a href="/pdf/2307.14768" title="Download PDF">pdf</a>, <a href="/format/2307.14768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gloss-free Sign Language Translation: Improving from Visual-Language  Pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Benjia Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhigang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Clap%C3%A9s%2C+A">Albert Clap&#xe9;s</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+J">Jun Wan</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yanyan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Escalera%2C+S">Sergio Escalera</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Z">Zhen Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Du Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Sign Language Translation (SLT) is a challenging task due to its cross-domain
nature, involving the translation of visual-gestural language to text. Many
previous methods employ an intermediate representation, i.e., gloss sequences,
to facilitate SLT, thus transforming it into a two-stage task of sign language
recognition (SLR) followed by sign language translation (SLT). However, the
scarcity of gloss-annotated sign language data, combined with the information
bottleneck in the mid-level gloss representation, has hindered the further
development of the SLT task. To address this challenge, we propose a novel
Gloss-Free SLT based on Visual-Language Pretraining (GFSLT-VLP), which improves
SLT by inheriting language-oriented prior knowledge from pre-trained models,
without any gloss annotation assistance. Our approach involves two stages: (i)
integrating Contrastive Language-Image Pre-training (CLIP) with masked
self-supervised learning to create pre-tasks that bridge the semantic gap
between visual and textual representations and restore masked sentences, and
(ii) constructing an end-to-end architecture with an encoder-decoder-like
structure that inherits the parameters of the pre-trained Visual Encoder and
Text Decoder from the first stage. The seamless combination of these novel
designs forms a robust sign language representation and significantly improves
gloss-free sign language translation. In particular, we have achieved
unprecedented improvements in terms of BLEU-4 score on the PHOENIX14T dataset
(&gt;+5) and the CSL-Daily dataset (&gt;+3) compared to state-of-the-art gloss-free
SLT methods. Furthermore, our approach also achieves competitive results on the
PHOENIX14T dataset when compared with most of the gloss-based methods. Our code
is available at https://github.com/zhoubenjia/GFSLT-VLP.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14770" title="Abstract">arXiv:2307.14770</a> [<a href="/pdf/2307.14770" title="Download PDF">pdf</a>, <a href="/format/2307.14770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Full-Head 3D GANs from a Single-View Portrait Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yiqian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiangjun Tang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Hongbo Fu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xiaogang Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">33D-aware face generators are commonly trained on 2D real-life face image
datasets. Nevertheless, existing facial recognition methods often struggle to
extract face data captured from various camera angles. Furthermore, in-the-wild
images with diverse body poses introduce a high-dimensional challenge for
3D-aware generators, making it difficult to utilize data that contains complete
neck and shoulder regions. Consequently, these face image datasets often
contain only near-frontal face data, which poses challenges for 3D-aware face
generators to construct \textit{full-head} 3D portraits. To this end, we first
create the dataset {$\it{360}^{\circ}$}-\textit{Portrait}-\textit{HQ}
(\textit{$\it{360}^{\circ}$PHQ}), which consists of high-quality single-view
real portraits annotated with a variety of camera parameters {(the yaw angles
span the entire $360^{\circ}$ range)} and body poses. We then propose
\textit{3DPortraitGAN}, the first 3D-aware full-head portrait generator that
learns a canonical 3D avatar distribution from the body-pose-various
\textit{$\it{360}^{\circ}$PHQ} dataset with body pose self-learning. Our model
can generate view-consistent portrait images from all camera angles
(${360}^{\circ}$) with a full-head 3D representation. We incorporate a
mesh-guided deformation field into volumetric rendering to produce deformed
results to generate portrait images that conform to the body pose distribution
of the dataset using our canonical generator. We integrate two pose predictors
into our framework to predict more accurate body poses to address the issue of
inaccurately estimated body poses in our dataset. Our experiments show that the
proposed framework can generate view-consistent, realistic portrait images with
complete geometry from all camera angles and accurately predict portrait body
pose.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14773" title="Abstract">arXiv:2307.14773</a> [<a href="/pdf/2307.14773" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smart Contract Migration: Security Analysis and Recommendations from  Ethereum to Arbitrum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xueyan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Lingzhi Shi</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+A">Alan Lai</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yuying Du</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jing Deng</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jialu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiayi Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages,23 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">This research aims to explore the security risks posed by compatibility and
protocol differences in smart contract migration, using the migration of smart
contracts from Ethereum to Arbitrum as a case study. Through literature review,
online data collection, expert participation, and analysis of smart contract
vulnerability cases, this paper conducts an in-depth research of the
differences between Ethereum and Arbitrum in areas such as Messaging, Block
Properties, Contract Address Alias, and Gas Fees. The research findings
indicate the presence of certain security issues during the migration process
from Ethereum to Arbitrum, such as abnormal operation of the sequencer
resulting in outdated off-chain data retrieval, time-based logical errors,
failed permission checks, DOS attacks, and gas loss due to L1-to-L2 transaction
failures. To address these security issues, this paper proposes corresponding
solutions and recommendations to ensure the security and meet the requirements
of the migration process. Additionally, this research emphasizes the continued
attention and support for the security issues of smart contract migration
through the case of smart contract migration from Ethereum to Arbitrum. It is
worth noting that this research is the first in-depth research of smart
contract security migration from Ethereum to Arbitrum.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14774" title="Abstract">arXiv:2307.14774</a> [<a href="/pdf/2307.14774" title="Download PDF">pdf</a>, <a href="/format/2307.14774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPC5: an efficient SpMV framework vectorized using ARM SVE and x86  AVX-512
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Regnault%2C+E">Evann Regnault</a>, 
<a href="/search/cs?searchtype=author&query=Bramas%2C+B">Berenger Bramas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://gitlab.inria.fr/bramas/spc5">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The sparse matrix/vector product (SpMV) is a fundamental operation in
scientific computing. Having access to an efficient SpMV implementation is
therefore critical, if not mandatory, to solve challenging numerical problems.
The ARM-based AFX64 CPU is a modern hardware component that equips one of the
fastest supercomputers in the world. This CPU supports the Scalable Vector
Extension (SVE) vectorization technology, which has been less investigated than
the classic x86 instruction set architectures. In this paper, we describe how
we ported the SPC5 SpMV framework on AFX64 by converting AVX512 kernels to SVE.
In addition, we present performance results by comparing our kernels against a
standard CSR kernel for both Intel-AVX512 and Fujitsu-ARM-SVE architectures.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14775" title="Abstract">arXiv:2307.14775</a> [<a href="/pdf/2307.14775" title="Download PDF">pdf</a>, <a href="/format/2307.14775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Convex Visual Foothold Adaptation for Quadrupedal Locomotion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Omar%2C+S">Shafeef Omar</a>, 
<a href="/search/cs?searchtype=author&query=Amatucci%2C+L">Lorenzo Amatucci</a>, 
<a href="/search/cs?searchtype=author&query=Turrisi%2C+G">Giulio Turrisi</a>, 
<a href="/search/cs?searchtype=author&query=Barasuol%2C+V">Victor Barasuol</a>, 
<a href="/search/cs?searchtype=author&query=Semini%2C+C">Claudio Semini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This extended abstract provides a short introduction on our recently
developed perception-based controller for quadrupedal locomotion. Compared to
our previous approach based on Visual Foothold Adaptation (VFA) and Model
Predictive Control (MPC), our new framework combines a fast approximation of
the safe foothold regions based on Neural Network regression, followed by a
convex decomposition routine in order to generate safe landing areas where the
controller can freely optimize the footholds location. The aforementioned
framework, which combines prediction, convex decomposition, and MPC solution,
is tested in simulation on our 140kg hydraulic quadruped robot (HyQReal).
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14777" title="Abstract">arXiv:2307.14777</a> [<a href="/pdf/2307.14777" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> pCTFusion: Point Convolution-Transformer Fusion with Semantic Aware Loss  for Outdoor LiDAR Point Cloud Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuriyal%2C+A">Abhishek Kuriyal</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vaibhav Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Lohani%2C+B">Bharat Lohani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 8 Figures, 5 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">LiDAR-generated point clouds are crucial for perceiving outdoor environments.
The segmentation of point clouds is also essential for many applications.
Previous research has focused on using self-attention and convolution (local
attention) mechanisms individually in semantic segmentation architectures.
However, there is limited work on combining the learned representations of
these attention mechanisms to improve performance. Additionally, existing
research that combines convolution with self-attention relies on global
attention, which is not practical for processing large point clouds. To address
these challenges, this study proposes a new architecture, pCTFusion, which
combines kernel-based convolutions and self-attention mechanisms for better
feature learning and capturing local and global dependencies in segmentation.
The proposed architecture employs two types of self-attention mechanisms, local
and global, based on the hierarchical positions of the encoder blocks.
Furthermore, the existing loss functions do not consider the semantic and
position-wise importance of the points, resulting in reduced accuracy,
particularly at sharp class boundaries. To overcome this, the study models a
novel attention-based loss function called Pointwise Geometric Anisotropy
(PGA), which assigns weights based on the semantic distribution of points in a
neighborhood. The proposed architecture is evaluated on SemanticKITTI outdoor
dataset and showed a 5-7% improvement in performance compared to the
state-of-the-art architectures. The results are particularly encouraging for
minor classes, often misclassified due to class imbalance, lack of space, and
neighbor-aware feature encoding. These developed methods can be leveraged for
the segmentation of complex datasets and can drive real-world applications of
LiDAR point cloud.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14778" title="Abstract">arXiv:2307.14778</a> [<a href="/pdf/2307.14778" title="Download PDF">pdf</a>, <a href="/format/2307.14778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MATNilm: Multi-appliance-task Non-intrusive Load Monitoring with Limited  Labeled Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+J">Jing Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+T">Tianqi Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongbo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Non-intrusive load monitoring (NILM) identifies the status and power
consumption of various household appliances by disaggregating the total power
usage signal of an entire house. Efficient and accurate load monitoring
facilitates user profile establishment, intelligent household energy
management, and peak load shifting. This is beneficial for both the end-users
and utilities by improving the overall efficiency of a power distribution
network. Existing approaches mainly focus on developing an individual model for
each appliance. Those approaches typically rely on a large amount of
household-labeled data which is hard to collect. In this paper, we propose a
multi-appliance-task framework with a training-efficient sample augmentation
(SA) scheme that boosts the disaggregation performance with limited labeled
data. For each appliance, we develop a shared-hierarchical split structure for
its regression and classification tasks. In addition, we also propose a
two-dimensional attention mechanism in order to capture spatio-temporal
correlations among all appliances. With only one-day training data and limited
appliance operation profiles, the proposed SA algorithm can achieve comparable
test performance to the case of training with the full dataset. Finally,
simulation results show that our proposed approach features a significantly
improved performance over many baseline models. The relative errors can be
reduced by more than 50\% on average. The codes of this work are available at
https://github.com/jxiong22/MATNilm
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14781" title="Abstract">arXiv:2307.14781</a> [<a href="/pdf/2307.14781" title="Download PDF">pdf</a>, <a href="/format/2307.14781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Knowledge Amalgamation for Unsupervised Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shangde Gao</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yichao Fu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Ke Liu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yuqiang Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2112.07327">arXiv:2112.07327</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Knowledge amalgamation (KA) aims to learn a compact student model to handle
the joint objective from multiple teacher models that are are specialized for
their own tasks respectively. Current methods focus on coarsely aligning
teachers and students in the common representation space, making it difficult
for the student to learn the proper decision boundaries from a set of
heterogeneous teachers. Besides, the KL divergence in previous works only
minimizes the probability distribution difference between teachers and the
student, ignoring the intrinsic characteristics of teachers. Therefore, we
propose a novel Contrastive Knowledge Amalgamation (CKA) framework, which
introduces contrastive losses and an alignment loss to achieve intra-class
cohesion and inter-class separation.Contrastive losses intra- and inter- models
are designed to widen the distance between representations of different
classes. The alignment loss is introduced to minimize the sample-level
distribution differences of teacher-student models in the common representation
space.Furthermore, the student learns heterogeneous unsupervised classification
tasks through soft targets efficiently and flexibly in the task-level
amalgamation. Extensive experiments on benchmarks demonstrate the
generalization capability of CKA in the amalgamation of specific task as well
as multiple tasks. Comprehensive ablation studies provide a further insight
into our CKA.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14785" title="Abstract">arXiv:2307.14785</a> [<a href="/pdf/2307.14785" title="Download PDF">pdf</a>, <a href="/format/2307.14785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Aspect-Based Sentiment with End-to-End Semantic Role Labeling  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=P%C5%99ib%C3%A1%C5%88%2C+P">Pavel P&#x159;ib&#xe1;&#x148;</a>, 
<a href="/search/cs?searchtype=author&query=Pra%C5%BE%C3%A1k%2C+O">Ond&#x159;ej Pra&#x17e;&#xe1;k</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to RANLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper presents a series of approaches aimed at enhancing the performance
of Aspect-Based Sentiment Analysis (ABSA) by utilizing extracted semantic
information from a Semantic Role Labeling (SRL) model. We propose a novel
end-to-end Semantic Role Labeling model that effectively captures most of the
structured semantic information within the Transformer hidden state. We believe
that this end-to-end model is well-suited for our newly proposed models that
incorporate semantic information. We evaluate the proposed models in two
languages, English and Czech, employing ELECTRA-small models. Our combined
models improve ABSA performance in both languages. Moreover, we achieved new
state-of-the-art results on the Czech ABSA.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14786" title="Abstract">arXiv:2307.14786</a> [<a href="/pdf/2307.14786" title="Download PDF">pdf</a>, <a href="/format/2307.14786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Deeply Unified Depth-aware Panoptic Segmentation with  Bi-directional Guidance Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junwen He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lijun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Huchuan Lu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jun-Yan He</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+J">Jin-Peng Lan</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+Y">Yifeng Geng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuansong Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to be published in ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Depth-aware panoptic segmentation is an emerging topic in computer vision
which combines semantic and geometric understanding for more robust scene
interpretation. Recent works pursue unified frameworks to tackle this challenge
but mostly still treat it as two individual learning tasks, which limits their
potential for exploring cross-domain information. We propose a deeply unified
framework for depth-aware panoptic segmentation, which performs joint
segmentation and depth estimation both in a per-segment manner with identical
object queries. To narrow the gap between the two tasks, we further design a
geometric query enhancement method, which is able to integrate scene geometry
into object queries using latent representations. In addition, we propose a
bi-directional guidance learning approach to facilitate cross-task feature
learning by taking advantage of their mutual relations. Our method sets the new
state of the art for depth-aware panoptic segmentation on both Cityscapes-DVPS
and SemKITTI-DVPS datasets. Moreover, our guidance learning approach is shown
to deliver performance improvement even under incomplete supervision labels.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14788" title="Abstract">arXiv:2307.14788</a> [<a href="/pdf/2307.14788" title="Download PDF">pdf</a>, <a href="/format/2307.14788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Likely, Light, and Accurate Context-Free Clusters-based Trajectory  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Almeida%2C+T+R">Tiago Rodrigues de Almeida</a>, 
<a href="/search/cs?searchtype=author&query=Mozos%2C+O+M">Oscar Martinez Mozos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted to the 26th IEEE International Conference on Intelligent Transportation Systems (ITSC 2023), which will be held in Bilbao, Spain on September 24-28, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Autonomous systems in the road transportation network require intelligent
mechanisms that cope with uncertainty to foresee the future. In this paper, we
propose a multi-stage probabilistic approach for trajectory forecasting:
trajectory transformation to displacement space, clustering of displacement
time series, trajectory proposals, and ranking proposals. We introduce a new
deep feature clustering method, underlying self-conditioned GAN, which copes
better with distribution shifts than traditional methods. Additionally, we
propose novel distance-based ranking proposals to assign probabilities to the
generated trajectories that are more efficient yet accurate than an auxiliary
neural network. The overall system surpasses context-free deep generative
models in human and road agents trajectory data while performing similarly to
point estimators when comparing the most probable trajectory.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14791" title="Abstract">arXiv:2307.14791</a> [<a href="/pdf/2307.14791" title="Download PDF">pdf</a>, <a href="/format/2307.14791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Parallelization of Software Network Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pereira%2C+F">Francisco Pereira</a>, 
<a href="/search/cs?searchtype=author&query=Ramos%2C+F+M+V">Fernando M. V. Ramos</a>, 
<a href="/search/cs?searchtype=author&query=Pedrosa%2C+L">Luis Pedrosa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 11 figures, to be published in NSDI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Software network functions (NFs) trade-off flexibility and ease of deployment
for an increased challenge of performance. The traditional way to increase NF
performance is by distributing traffic to multiple CPU cores, but this poses a
significant challenge: how to parallelize an NF without breaking its semantics?
We propose Maestro, a tool that analyzes a sequential implementation of an NF
and automatically generates an enhanced parallel version that carefully
configures the NIC's Receive Side Scaling mechanism to distribute traffic
across cores, while preserving semantics. When possible, Maestro orchestrates a
shared-nothing architecture, with each core operating independently without
shared memory coordination, maximizing performance. Otherwise, Maestro
choreographs a fine-grained read-write locking mechanism that optimizes
operation for typical Internet traffic. We parallelized 8 software NFs and show
that they generally scale-up linearly until bottlenecked by PCIe when using
small packets or by 100Gbps line-rate with typical Internet traffic. Maestro
further outperforms modern hardware-based transactional memory mechanisms, even
for challenging parallel-unfriendly workloads.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14799" title="Abstract">arXiv:2307.14799</a> [<a href="/pdf/2307.14799" title="Download PDF">pdf</a>, <a href="/format/2307.14799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid ASP-based multi-objective scheduling of semiconductor  manufacturing processes (Extended version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=El-Kholany%2C+M+M+S">Mohammed M. S. El-Kholany</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+R">Ramsha Ali</a>, 
<a href="/search/cs?searchtype=author&query=Gebser%2C+M">Martin Gebser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 1 figure, 4 listings, 1 table; a short version of this paper is presented at the 18th European Conference on Logics in Artificial Intelligence (JELIA 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Modern semiconductor manufacturing involves intricate production processes
consisting of hundreds of operations, which can take several months from lot
release to completion. The high-tech machines used in these processes are
diverse, operate on individual wafers, lots, or batches in multiple stages, and
necessitate product-specific setups and specialized maintenance procedures.
This situation is different from traditional job-shop scheduling scenarios,
which have less complex production processes and machines, and mainly focus on
solving highly combinatorial but abstract scheduling problems. In this work, we
address the scheduling of realistic semiconductor manufacturing processes by
modeling their specific requirements using hybrid Answer Set Programming with
difference logic, incorporating flexible machine processing, setup, batching
and maintenance operations. Unlike existing methods that schedule semiconductor
manufacturing processes locally with greedy heuristics or by independently
optimizing specific machine group allocations, we examine the potentials of
large-scale scheduling subject to multiple optimization objectives.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14801" title="Abstract">arXiv:2307.14801</a> [<a href="/pdf/2307.14801" title="Download PDF">pdf</a>, <a href="/format/2307.14801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-stabilizing Byzantine-tolerant Recycling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Georgiou%2C+C">Chryssis Georgiou</a>, 
<a href="/search/cs?searchtype=author&query=Raynal%2C+M">Michel Raynal</a>, 
<a href="/search/cs?searchtype=author&query=Schiller%2C+E+M">Elad M. Schiller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A complementary technical report version of an extended abstract that is to appear in the proceedings of the 25th International Symposium on Stabilization, Safety, and Security of Distributed Systems (SSS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Numerous distributed applications, such as cloud computing and distributed
ledgers, necessitate the system to invoke asynchronous consensus objects an
unbounded number of times, where the completion of one consensus instance is
followed by the invocation of another. With only a constant number of objects
available, object reuse becomes vital.
<br />We investigate the challenge of object recycling in the presence of Byzantine
processes, which can deviate from the algorithm code in any manner. Our
solution must also be self-stabilizing, as it is a powerful notion of fault
tolerance. Self-stabilizing systems can recover automatically after the
occurrence of arbitrary transient faults, in addition to tolerating
communication and (Byzantine or crash) process failures, provided the algorithm
code remains intact.
<br />We provide a recycling mechanism for asynchronous objects that enables their
reuse once their task has ended, and all non-faulty processes have retrieved
the decided values. This mechanism relies on synchrony assumptions and builds
on a new self-stabilizing Byzantine-tolerant synchronous multivalued consensus
algorithm, along with a novel composition of existing techniques.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14805" title="Abstract">arXiv:2307.14805</a> [<a href="/pdf/2307.14805" title="Download PDF">pdf</a>, <a href="/format/2307.14805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear Termination over N is Undecidable
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mitterwallner%2C+F">Fabian Mitterwallner</a>, 
<a href="/search/cs?searchtype=author&query=Middeldorp%2C+A">Aart Middeldorp</a>, 
<a href="/search/cs?searchtype=author&query=Thiemann%2C+R">Ren&#xe9; Thiemann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at WST 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Recently it was shown that it is undecidable whether a term rewrite system
can be proved terminating by a polynomial interpretation in the natural
numbers. In this paper we show that this is also the case when restricting the
interpretations to linear polynomials, as is often done in tools, and when only
considering single-rule rewrite systems. What is more, the new undecidability
proof is simpler than the previous one. We further show that polynomial
termination over the rationals/reals is undecidable.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14810" title="Abstract">arXiv:2307.14810</a> [<a href="/pdf/2307.14810" title="Download PDF">pdf</a>, <a href="/ps/2307.14810" title="Download PostScript">ps</a>, <a href="/format/2307.14810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Differential Datalog Interpreter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stephenson%2C+M">Matthew Stephenson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">The core reasoning task for datalog engines is materialization, the
evaluation of a datalog program over a database alongside its physical
incorporation into the database itself. The de-facto method of computing it, is
through the recursive application of inference rules. Due to it being a costly
operation, it is a must for datalog engines to provide incremental
materialization, that is, to adjust the computation to new data, instead of
restarting from scratch. One of the major caveats, is that deleting data is
notoriously more involved than adding, since one has to take into account all
possible data that has been entailed from what is being deleted. Differential
Dataflow is a computational model that provides efficient incremental
maintenance, notoriously with equal performance between additions and
deletions, and work distribution, of iterative dataflows. In this paper we
investigate the performance of materialization with three reference datalog
implementations, out of which one is built on top of a lightweight relational
engine, and the two others are differential-dataflow and non-differential
versions of the same rewrite algorithm, with the same optimizations.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14817" title="Abstract">arXiv:2307.14817</a> [<a href="/pdf/2307.14817" title="Download PDF">pdf</a>, <a href="/format/2307.14817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Models of reference production: How do they withstand the test of time?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Same%2C+F">Fahime Same</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guanyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=van+Deemter%2C+K">Kees van Deemter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to INLG 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In recent years, many NLP studies have focused solely on performance
improvement. In this work, we focus on the linguistic and scientific aspects of
NLP. We use the task of generating referring expressions in context
(REG-in-context) as a case study and start our analysis from GREC, a
comprehensive set of shared tasks in English that addressed this topic over a
decade ago. We ask what the performance of models would be if we assessed them
(1) on more realistic datasets, and (2) using more advanced methods. We test
the models using different evaluation metrics and feature selection
experiments. We conclude that GREC can no longer be regarded as offering a
reliable assessment of models' ability to mimic human reference production,
because the results are highly impacted by the choice of corpus and evaluation
metrics. Our results also suggest that pre-trained language models are less
dependent on the choice of corpus than classic Machine Learning models, and
therefore make more robust class predictions.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14818" title="Abstract">arXiv:2307.14818</a> [<a href="/pdf/2307.14818" title="Download PDF">pdf</a>, <a href="/format/2307.14818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Makes a Good Paraphrase: Do Automated Evaluations Work?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moskvina%2C+A">Anna Moskvina</a>, 
<a href="/search/cs?searchtype=author&query=Kotnis%2C+B">Bhushan Kotnis</a>, 
<a href="/search/cs?searchtype=author&query=Catacata%2C+C">Chris Catacata</a>, 
<a href="/search/cs?searchtype=author&query=Janz%2C+M">Michael Janz</a>, 
<a href="/search/cs?searchtype=author&query=Saef%2C+N">Nasrin Saef</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended Abstract for Konvens2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Paraphrasing is the task of expressing an essential idea or meaning in
different words. But how different should the words be in order to be
considered an acceptable paraphrase? And can we exclusively use automated
metrics to evaluate the quality of a paraphrase? We attempt to answer these
questions by conducting experiments on a German data set and performing
automatic and expert linguistic evaluation.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14823" title="Abstract">arXiv:2307.14823</a> [<a href="/pdf/2307.14823" title="Download PDF">pdf</a>, <a href="/format/2307.14823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fading memory as inductive bias in residual recurrent networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dubinin%2C+I">Igor Dubinin</a>, 
<a href="/search/cs?searchtype=author&query=Effenberger%2C+F">Felix Effenberger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Residual connections have been proposed as architecture-based inductive bias
to mitigate the problem of exploding and vanishing gradients and increase task
performance in both feed-forward and recurrent networks (RNNs) when trained
with the backpropagation algorithm. Yet, little is known about how residual
connections in RNNs influence their dynamics and fading memory properties.
Here, we introduce weakly coupled residual recurrent networks (WCRNNs) in which
residual connections result in well-defined Lyapunov exponents and allow for
studying properties of fading memory. We investigate how the residual
connections of WCRNNs influence their performance, network dynamics, and memory
properties on a set of benchmark tasks. We show that several distinct forms of
residual connections yield effective inductive biases that result in increased
network expressivity. In particular, residual connections that (i) result in
network dynamics at the proximity of the edge of chaos, (ii) allow networks to
capitalize on characteristic spectral properties of the data, and (iii) result
in heterogeneous memory properties are shown to increase practical
expressivity. In addition, we demonstrate how our results can be extended to
non-linear residuals and introduce a weakly coupled residual initialization
scheme that can be used for Elman RNNs
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14825" title="Abstract">arXiv:2307.14825</a> [<a href="/pdf/2307.14825" title="Download PDF">pdf</a>, <a href="/format/2307.14825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simplified Concrete Dropout -- Improving the Generation of Attribution  Masks for Fine-grained Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Korsch%2C+D">Dimitri Korsch</a>, 
<a href="/search/cs?searchtype=author&query=Shadaydeh%2C+M">Maha Shadaydeh</a>, 
<a href="/search/cs?searchtype=author&query=Denzler%2C+J">Joachim Denzler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the German Conference on Pattern Recognition 2023 (GCPR 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Fine-grained classification is a particular case of a classification problem,
aiming to classify objects that share the visual appearance and can only be
distinguished by subtle differences. Fine-grained classification models are
often deployed to determine animal species or individuals in automated animal
monitoring systems. Precise visual explanations of the model's decision are
crucial to analyze systematic errors. Attention- or gradient-based methods are
commonly used to identify regions in the image that contribute the most to the
classification decision. These methods deliver either too coarse or too noisy
explanations, unsuitable for identifying subtle visual differences reliably.
However, perturbation-based methods can precisely identify pixels causally
responsible for the classification result. Fill-in of the dropout (FIDO)
algorithm is one of those methods. It utilizes the concrete dropout (CD) to
sample a set of attribution masks and updates the sampling parameters based on
the output of the classification model. A known problem of the algorithm is a
high variance in the gradient estimates, which the authors have mitigated until
now by mini-batch updates of the sampling parameters. This paper presents a
solution to circumvent these computational instabilities by simplifying the CD
sampling and reducing reliance on large mini-batch sizes. First, it allows
estimating the parameters with smaller mini-batch sizes without losing the
quality of the estimates but with a reduced computational effort. Furthermore,
our solution produces finer and more coherent attribution masks. Finally, we
use the resulting attribution masks to improve the classification performance
of a trained model without additional fine-tuning of the model.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14826" title="Abstract">arXiv:2307.14826</a> [<a href="/pdf/2307.14826" title="Download PDF">pdf</a>, <a href="/format/2307.14826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graded Semantics and Graded Logics for Eilenberg-Moore Coalgebras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Forster%2C+J">Jonas Forster</a>, 
<a href="/search/cs?searchtype=author&query=Schr%C3%B6der%2C+L">Lutz Schr&#xf6;der</a>, 
<a href="/search/cs?searchtype=author&query=Wild%2C+P">Paul Wild</a>, 
<a href="/search/cs?searchtype=author&query=Beohar%2C+H">Harsh Beohar</a>, 
<a href="/search/cs?searchtype=author&query=Gurke%2C+S">Sebastian Gurke</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6nig%2C+B">Barbara K&#xf6;nig</a>, 
<a href="/search/cs?searchtype=author&query=Messing%2C+K">Karla Messing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Coalgebra, as the abstract study of state-based systems, comes naturally
equipped with a notion of behavioural equivalence that identifies states
exhibiting the same behaviour. In many cases, however, this equivalence is
finer than the intended semantics. Particularly in automata theory, behavioural
equivalence of nondeterministic automata is essentially bisimilarity, and thus
does not coincide with language equivalence. Language equivalence can be
captured as behavioural equivalence on the determinization, which is obtained
via the standard powerset construction. This construction can be lifted to
coalgebraic generality, assuming a so-called Eilenberg-Moore distributive law
between the functor determining the type of accepted structure (e.g.\ word
languages) and a monad capturing the branching type (e.g. nondeterministic,
weighted, probabilistic). Eilenberg-Moore-style coalgebraic semantics in this
sense has been shown to be essentially subsumed by the more general framework
of graded semantics, which is centrally based on graded monads. Graded
semantics comes with a range of generic results, in particular regarding
invariance and, under suitable conditions, expressiveness of dedicated modal
logics for a given semantics; notably, these logics are evaluated on the
original state space. We show that the instantiation of such graded logics to
the case of Eilenberg-Moore-style semantics works extremely smoothly, and
yields expressive modal logics in essentially all cases of interest. We
additionally parametrize the framework over a quantale of truth values, thus in
particular covering both the two-valued notions of equivalence and quantitative
ones, i.e. behavioural distances.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14834" title="Abstract">arXiv:2307.14834</a> [<a href="/pdf/2307.14834" title="Download PDF">pdf</a>, <a href="/format/2307.14834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disturbance Preview for Nonlinear Model Predictive Trajectory Tracking  of Underwater Vehicles in Wave Dominated Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Walker%2C+K+L">Kyle L. Walker</a>, 
<a href="/search/cs?searchtype=author&query=Giorgio-Serchi%2C+F">Francesco Giorgio-Serchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be presented at IROS 2023, Detroit, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Operating in the near-vicinity of marine energy devices poses significant
challenges to the control of underwater vehicles, predominantly due to the
presence of large magnitude wave disturbances causing hazardous state
perturbations. Approaches to tackle this problem have varied, but one promising
solution is to adopt predictive control methods. Given the predictable nature
of ocean waves, the potential exists to incorporate disturbance estimations
directly within the plant model; this requires inclusion of a wave predictor to
provide online preview information. To this end, this paper presents a
Nonlinear Model Predictive Controller with an integrated Deterministic Sea Wave
Predictor for trajectory tracking of underwater vehicles. State information is
obtained through an Extended Kalman Filter, forming a complete closed-loop
strategy and facilitating online wave load estimations. The strategy is
compared to a similar feed-forward disturbance mitigation scheme, showing mean
performance improvements of 51% in positional error and 44.5% in attitude
error. The preliminary results presented here provide strong evidence of the
proposed method's high potential to effectively mitigate disturbances,
facilitating accurate tracking performance even in the presence of high wave
loading.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14837" title="Abstract">arXiv:2307.14837</a> [<a href="/pdf/2307.14837" title="Download PDF">pdf</a>, <a href="/format/2307.14837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DNN-MG: A Hybrid Neural Network/Finite Element Method with Applications  to 3D Simulations of the Navier-Stokes Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Margenberg%2C+N">Nils Margenberg</a>, 
<a href="/search/math?searchtype=author&query=Jendersie%2C+R">Robert Jendersie</a>, 
<a href="/search/math?searchtype=author&query=Lessig%2C+C">Christian Lessig</a>, 
<a href="/search/math?searchtype=author&query=Richter%2C+T">Thomas Richter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 20 figures, 9 tables. Submitted to Computer Methods in Applied Mechanics and Engineering
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">We extend and analyze the deep neural network multigrid solver (DNN-MG) for
the Navier-Stokes equations in three dimensions. The idea of the method is to
augment of finite element simulations on coarse grids with fine scale
information obtained using deep neural networks.
<br />This network operates locally on small patches of grid elements. The local
approach proves to be highly efficient, since the network can be kept
(relatively) small and since it can be applied in parallel on all grid patches.
However, the main advantage of the local approach is the inherent good
generalizability of the method. Since the network is only ever trained on small
sub-areas, it never ``sees'' the global problem and thus does not learn a false
bias.
<br />We describe the method with a focus on the interplay between finite element
method and deep neural networks. Further, we demonstrate with numerical
examples the excellent efficiency of the hybrid approach, which allows us to
achieve very high accuracies on coarse grids and thus reduce the computation
time by orders of magnitude.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14841" title="Abstract">arXiv:2307.14841</a> [<a href="/pdf/2307.14841" title="Download PDF">pdf</a>, <a href="/format/2307.14841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Suitability of Hugging Face Hub for Empirical Studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ait%2C+A">Adem Ait</a>, 
<a href="/search/cs?searchtype=author&query=Izquierdo%2C+J+L+C">Javier Luis C&#xe1;novas Izquierdo</a>, 
<a href="/search/cs?searchtype=author&query=Cabot%2C+J">Jordi Cabot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted registered report at the 17th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Background. The development of empirical studies in software engineering
mainly relies on the data available on code hosting platforms, being GitHub the
most representative. Nevertheless, in the last years, the emergence of Machine
Learning (ML) has led to the development of platforms specifically designed for
developing ML-based projects, being Hugging Face Hub (HFH) the most popular
one. With over 250k repositories, and growing fast, HFH is becoming a promising
ecosystem of ML artifacts and therefore a potential source of data for
empirical studies. However, so far there have been no studies evaluating the
potential of HFH for such studies. Objective. In this proposal for a registered
report, we aim at performing an exploratory study of the current state of HFH
in order to investigate its suitability to be used as a source platform for
empirical studies. Method. We conduct a qualitative and quantitative analysis
of HFH for empirical studies. The former will be performed by comparing the
features of HFH with those of other code hosting platforms, such as GitHub and
GitLab. The latter will be performed by analyzing the data available in HFH.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14846" title="Abstract">arXiv:2307.14846</a> [<a href="/pdf/2307.14846" title="Download PDF">pdf</a>, <a href="/format/2307.14846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Grant-Free Orthogonal Multiple Access with Partial-Information for  Short Packet Transmissions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rech%2C+A">Alberto Rech</a>, 
<a href="/search/cs?searchtype=author&query=Tomasin%2C+S">Stefano Tomasin</a>, 
<a href="/search/cs?searchtype=author&query=Vangelista%2C+L">Lorenzo Vangelista</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+C">Cristina Costa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Journal paper, 11 pages, 8 figures. arXiv admin note: text overlap with <a href="/abs/2304.12057">arXiv:2304.12057</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Next-generation internet-of-things (IoT) networks require extremely low
latency, complexity, and collision probability. We introduce the novel
partial-information multiple access (PIMA) scheme, a semi-grant-free (GF)
coordinated random access (RA) protocol for short packet transmission, with the
aim of reducing the latency and packet loss of traditional multiple access
schemes, as well as more recent preamble-based schemes. With PIMA, the base
station (BS) acquires partial information on instantaneous traffic conditions
in the partial information acquisition (PIA) sub-frame, estimating the number
of active devices, i.e., having packets waiting for transmission in their
queue. Based on this estimate, the BS chooses both the total number of slots to
be allocated in the data transmission (DT) sub-frame and the respective
user-to-slot assignment. Although collisions may still occur due to multiple
users assigned to the same slot, they are drastically reduced with respect to
the slotted ALOHA (SALOHA) scheme, while achieving lower latency than both
time-division multiple-access (TDMA) and preamble-based protocols, due to the
extremely reduced overhead of the PIA sub-frame. Finally, we analyze and assess
the performance of PIMA under various activation statistics, proving the
robustness of the proposed solution to the intensity of traffic, also with
burst traffic.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14849" title="Abstract">arXiv:2307.14849</a> [<a href="/pdf/2307.14849" title="Download PDF">pdf</a>, <a href="/format/2307.14849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counterfactual Explanations for Graph Classification Through the Lenses  of Density
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abrate%2C+C">Carlo Abrate</a>, 
<a href="/search/cs?searchtype=author&query=Preti%2C+G">Giulia Preti</a>, 
<a href="/search/cs?searchtype=author&query=Bonchi%2C+F">Francesco Bonchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Counterfactual examples have emerged as an effective approach to produce
simple and understandable post-hoc explanations. In the context of graph
classification, previous work has focused on generating counterfactual
explanations by manipulating the most elementary units of a graph, i.e.,
removing an existing edge, or adding a non-existing one. In this paper, we
claim that such language of explanation might be too fine-grained, and turn our
attention to some of the main characterizing features of real-world complex
networks, such as the tendency to close triangles, the existence of recurring
motifs, and the organization into dense modules. We thus define a general
density-based counterfactual search framework to generate instance-level
counterfactual explanations for graph classifiers, which can be instantiated
with different notions of dense substructures. In particular, we show two
specific instantiations of this general framework: a method that searches for
counterfactual graphs by opening or closing triangles, and a method driven by
maximal cliques. We also discuss how the general method can be instantiated to
exploit any other notion of dense substructures, including, for instance, a
given taxonomy of nodes. We evaluate the effectiveness of our approaches in 7
brain network datasets and compare the counterfactual statements generated
according to several widely-used metrics. Results confirm that adopting a
semantic-relevant unit of change like density is essential to define versatile
and interpretable counterfactual explanation methods.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14850" title="Abstract">arXiv:2307.14850</a> [<a href="/pdf/2307.14850" title="Download PDF">pdf</a>, <a href="/format/2307.14850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Turkish Native Language Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uluslu%2C+A+Y">Ahmet Yavuz Uluslu</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+G">Gerold Schneider</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this paper, we present the first application of Native Language
Identification (NLI) for the Turkish language. NLI involves predicting the
writer's first language by analysing their writing in different languages.
While most NLI research has focused on English, our study extends its scope to
Turkish. We used the recently constructed Turkish Learner Corpus and employed a
combination of three syntactic features (CFG production rules, part-of-speech
n-grams and function words) with L2 texts to demonstrate their effectiveness in
this task.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14852" title="Abstract">arXiv:2307.14852</a> [<a href="/pdf/2307.14852" title="Download PDF">pdf</a>, <a href="/format/2307.14852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ArcGPT: A Large Language Model Tailored for Real-world Archival  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shitou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Jingrui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Siyuan Peng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zuchao Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qibiao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Ping Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Archives play a crucial role in preserving information and knowledge, and the
exponential growth of such data necessitates efficient and automated tools for
managing and utilizing archive information resources. Archival applications
involve managing massive data that are challenging to process and analyze.
Although LLMs have made remarkable progress in diverse domains, there are no
publicly available archives tailored LLM. Addressing this gap, we introduce
ArcGPT, to our knowledge, the first general-purpose LLM tailored to the
archival field. To enhance model performance on real-world archival tasks,
ArcGPT has been pre-trained on massive and extensive archival domain data.
Alongside ArcGPT, we release AMBLE, a benchmark comprising four real-world
archival tasks. Evaluation on AMBLE shows that ArcGPT outperforms existing
state-of-the-art models, marking a substantial step forward in effective
archival data management. Ultimately, ArcGPT aims to better serve the archival
community, aiding archivists in their crucial role of preserving and harnessing
our collective information and knowledge.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14854" title="Abstract">arXiv:2307.14854</a> [<a href="/pdf/2307.14854" title="Download PDF">pdf</a>, <a href="/format/2307.14854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MatrixWorld: A pursuit-evasion platform for safe multi-agent  coordination and autocurricula
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lijun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yu-Cheng Chang</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+C">Chao Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chin-Teng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yuhui Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">Multi-agent reinforcement learning (MARL) has achieved encouraging
performance in solving complex multi-agent tasks. However, the safety of MARL
policies is one critical concern that impedes their real-world applications.
Furthermore, popular multi-agent benchmarks provide limited safety support for
safe MARL research, where negative rewards for collisions are insufficient for
guaranteeing the safety of MARL policies. Therefore, in this work, we propose a
new safety-constrained multi-agent environment: MatrixWorld, based on the
general pursuit-evasion game. In particular, a safety-constrained multi-agent
action execution model is proposed for the software implementation of safe
multi-agent environments. In addition, MatrixWorld is a lightweight
co-evolution framework for the learning of pursuit tasks, evasion tasks, or
both, where more pursuit-evasion variants are designed based on different
practical meanings of safety. As a brief survey, we review and analyze the
co-evolution mechanism in the multi-agent setting, which clearly reveals its
relationships with autocurricula, self-play, arms races, and adversarial
learning. Thus, we argue that MatrixWorld can serve as the first environment
for autocurriculum research, where ideas can be quickly verified and well
understood. Finally, based on the above problems concerning safe MARL and
autocurricula, our experiments show the difficulties of general MARL in
guaranteeing safe multi-agent coordination with only negative rewards for
collisions and the potential of MatrixWorld in autocurriculum learning, where
practical suggestions for successful multi-agent adversarial learning and arms
races are given.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14855" title="Abstract">arXiv:2307.14855</a> [<a href="/pdf/2307.14855" title="Download PDF">pdf</a>, <a href="/ps/2307.14855" title="Download PostScript">ps</a>, <a href="/format/2307.14855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automata in toposes, and general Myhill-Nerode theorems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Iwaniack%2C+V">Victor Iwaniack</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages with appendix. Any comments welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Category Theory (math.CT)

</div>
<p class="mathjax">We extend the functorial approach to automata by Colcombet and Petri\c{s}an
[<a href="/abs/1712.07121">arXiv:1712.07121</a>] from the category of sets to any elementary topos with a
natural number object and establish general Myhill-Nerode theorems in our
setting. As a special case we recover the result of Boja\'nczyk, Klin and
Lasota [<a href="/abs/1402.0897">arXiv:1402.0897</a>] for orbit-finite nominal automata by considering
automata in the Myhill-Schanuel topos of nominal sets.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14856" title="Abstract">arXiv:2307.14856</a> [<a href="/pdf/2307.14856" title="Download PDF">pdf</a>, <a href="/format/2307.14856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting the Potential of Seq2Seq Models as Robust Few-Shot Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jihyeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dain Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+D">Doohae Jung</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Boseop Kim</a>, 
<a href="/search/cs?searchtype=author&query=On%2C+K">Kyoung-Woon On</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In-context learning, which offers substantial advantages over fine-tuning, is
predominantly observed in decoder-only models, while encoder-decoder (i.e.,
seq2seq) models excel in methods that rely on weight updates. Recently, a few
studies have demonstrated the feasibility of few-shot learning with seq2seq
models; however, this has been limited to tasks that align well with the
seq2seq architecture, such as summarization and translation. Inspired by these
initial studies, we provide a first-ever extensive experiment comparing the
in-context few-shot learning capabilities of decoder-only and encoder-decoder
models on a broad range of tasks. Furthermore, we propose two methods to more
effectively elicit in-context learning ability in seq2seq models:
objective-aligned prompting and a fusion-based approach. Remarkably, our
approach outperforms a decoder-only model that is six times larger and exhibits
significant performance improvements compared to conventional seq2seq models
across a variety of settings. We posit that, with the right configuration and
prompt design, seq2seq models can be highly effective few-shot learners for a
wide spectrum of applications.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14858" title="Abstract">arXiv:2307.14858</a> [<a href="/pdf/2307.14858" title="Download PDF">pdf</a>, <a href="/ps/2307.14858" title="Download PostScript">ps</a>, <a href="/format/2307.14858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Commande rapproch&#xe9;e d&#x27;un IGBT pour l&#x27;att&#xe9;nuation des perturbations  &#xe9;lectromagn&#xe9;tiques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Martinez-Padron%2C+D+S">Daniel Sting Martinez-Padron</a>, 
<a href="/search/eess?searchtype=author&query=Patin%2C+N">Nicolas Patin</a>, 
<a href="/search/eess?searchtype=author&query=Monmasson%2C+E">Eric Monmasson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in French language, SYMPOSIUM DE GENIE ELECTRIQUE (SGE 2023), 5 - 7 JUILLET 2023, LILLE, FRANCE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Power transistors such as IGBTs and MOSFETs are a source of electromagnetic
interference (EMI) during switching due to rapid voltage/current variations.
Increasing the switching time can reduce the generation of EMI but increases
losses. Several driving methods to reduce EMI have been proposed in the
literature. In this work, a driving method based on the control of a grid
current profile, made possible by new drivers available on the market, is
proposed. This is based on the gate-source voltage of transistor as as a
function of the charge injected into the gate. In order to demonstrate the
performance of this method, it is evaluated by SPICE simulation using a figure
of merit that enables it to be compared quantitatively with a reference method
known as CATS (Commande autour de la Tension de Seuil).
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14859" title="Abstract">arXiv:2307.14859</a> [<a href="/pdf/2307.14859" title="Download PDF">pdf</a>, <a href="/format/2307.14859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Evaluation of Digital and Analog Chest Radiographs to  Identify Tuberculosis using Deep Learning Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chattoraj%2C+S">Subhankar Chattoraj</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+B">Bhargava Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Tadepalli%2C+M">Manoj Tadepalli</a>, 
<a href="/search/cs?searchtype=author&query=Putha%2C+P">Preetham Putha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Purpose:Chest X-ray (CXR) is an essential tool and one of the most prescribed
imaging to detect pulmonary abnormalities, with a yearly estimate of over 2
billion imaging performed worldwide. However, the accurate and timely diagnosis
of TB remains an unmet goal. The prevalence of TB is highest in
low-middle-income countries, and the requirement of a portable, automated, and
reliable solution is required. In this study, we compared the performance of
DL-based devices on digital and analog CXR. The evaluated DL-based device can
be used in resource-constraint settings. Methods: A total of 10,000 CXR
DICOMs(.dcm) and printed photos of the films acquired with three different
cellular phones - Samsung S8, iPhone 8, and iPhone XS along with their
radiological report were retrospectively collected from various sites across
India from April 2020 to March 2021. Results: 10,000 chest X-rays were utilized
to evaluate the DL-based device in identifying radiological signs of TB. The
AUC of qXR for detecting signs of tuberculosis on the original DICOMs dataset
was 0.928 with a sensitivity of 0.841 at a specificity of 0.806. At an optimal
threshold, the difference in the AUC of three cellular smartphones with the
original DICOMs is 0.024 (2.55%), 0.048 (5.10%), and 0.038 (1.91%). The minimum
difference demonstrates the robustness of the DL-based device in identifying
radiological signs of TB in both digital and analog CXR.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14860" title="Abstract">arXiv:2307.14860</a> [<a href="/pdf/2307.14860" title="Download PDF">pdf</a>, <a href="/format/2307.14860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Computer Simulations at Warp Speed: Assessing the Impact of GPU  Acceleration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Faj%2C+J">Jennifer Faj</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+I">Ivy Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wahlgren%2C+J">Jacob Wahlgren</a>, 
<a href="/search/cs?searchtype=author&query=Markidis%2C+S">Stefano Markidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>

</div>
<p class="mathjax">Quantum computer simulators are crucial for the development of quantum
computing. In this work, we investigate the suitability and performance impact
of GPU and multi-GPU systems on a widely used simulation tool - the state
vector simulator Qiskit Aer. In particular, we evaluate the performance of both
Qiskit's default Nvidia Thrust backend and the recent Nvidia cuQuantum backend
on Nvidia A100 GPUs. We provide a benchmark suite of representative quantum
applications for characterization. For simulations with a large number of
qubits, the two GPU backends can provide up to 14x speedup over the CPU
backend, with Nvidia cuQuantum providing further 1.5-3x speedup over the
default Thrust backend. Our evaluation on a single GPU identifies the most
important functions in Nvidia Thrust and cuQuantum for different quantum
applications and their compute and memory bottlenecks. We also evaluate the
gate fusion and cache-blocking optimizations on different quantum applications.
Finally, we evaluate large-number qubit quantum applications on multi-GPU and
identify data movement between host and GPU as the limiting factor for the
performance.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14863" title="Abstract">arXiv:2307.14863</a> [<a href="/pdf/2307.14863" title="Download PDF">pdf</a>, <a href="/format/2307.14863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IML-ViT: Image Manipulation Localization by Vision Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaochen Ma</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+B">Bo Du</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianggen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hammadi%2C+A+Y+A">Ahmed Y. Al Hammadi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jizhe Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Advanced image tampering techniques are increasingly challenging the
trustworthiness of multimedia, leading to the development of Image Manipulation
Localization (IML). But what makes a good IML model? The answer lies in the way
to capture artifacts. Exploiting artifacts requires the model to extract
non-semantic discrepancies between the manipulated and authentic regions, which
needs to compare differences between these two areas explicitly. With the
self-attention mechanism, naturally, the Transformer is the best candidate.
Besides, artifacts are sensitive to image resolution, amplified under
multi-scale features, and massive at the manipulation border. Therefore, we
formulate the answer to the former question as building a ViT with
high-resolution capacity, multi-scale feature extraction capability, and
manipulation edge supervision. We term this simple but effective ViT paradigm
as the IML-ViT, which has great potential to become a new benchmark for IML.
Extensive experiments on five benchmark datasets verified our model outperforms
the state-of-the-art manipulation localization methods. Code and models are
available at \url{https://github.com/SunnyHaze/IML-ViT}
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14866" title="Abstract">arXiv:2307.14866</a> [<a href="/pdf/2307.14866" title="Download PDF">pdf</a>, <a href="/format/2307.14866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample Less, Learn More: Efficient Action Recognition via Frame Feature  Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Harry Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yangyang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+L">Liqiang Nie</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhiyong Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Kankanhalli%2C+M">Mohan Kankanhalli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages. Code and pretrained weight will be released at <a href="https://github.com/xaCheng1996/SLLM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Training an effective video action recognition model poses significant
computational challenges, particularly under limited resource budgets. Current
methods primarily aim to either reduce model size or utilize pre-trained
models, limiting their adaptability to various backbone architectures. This
paper investigates the issue of over-sampled frames, a prevalent problem in
many approaches yet it has received relatively little attention. Despite the
use of fewer frames being a potential solution, this approach often results in
a substantial decline in performance. To address this issue, we propose a novel
method to restore the intermediate features for two sparsely sampled and
adjacent video frames. This feature restoration technique brings a negligible
increase in computational requirements compared to resource-intensive image
encoders, such as ViT. To evaluate the effectiveness of our method, we conduct
extensive experiments on four public datasets, including Kinetics-400,
ActivityNet, UCF-101, and HMDB-51. With the integration of our method, the
efficiency of three commonly used baselines has been improved by over 50%, with
a mere 0.5% reduction in recognition accuracy. In addition, our method also
surprisingly helps improve the generalization ability of the models under
zero-shot settings.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14870" title="Abstract">arXiv:2307.14870</a> [<a href="/pdf/2307.14870" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditional Handover Modelling for Increased Contention Free Resource  Use in 5G-Advanced
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stanczak%2C+J">Jedrzej Stanczak</a>, 
<a href="/search/cs?searchtype=author&query=Karabulut%2C+U">Umur Karabulut</a>, 
<a href="/search/cs?searchtype=author&query=Awada%2C+A">Ahmad Awada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 7 figures. Accepted for presentation at the 2023 Annual IEEE International Symposium on Personal, Indoor and Mobile Radio Communications (IEEE PIMRC 2023), to be held in Toronto, Canada
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">This paper elaborates on Conditional Handover (CHO) modelling, aimed at
maximizing the use of contention free random access (CFRA) during mobility.
This is a desirable behavior as CFRA increases the chance of fast and
successful handover. In CHO this may be especially challenging as the time
between the preparation and the actual cell change can be significantly longer
in comparison to non-conditional handover. Thus, new means to mitigate this
issue need to be defined. We present the scheme where beam-specific measurement
reporting can lead to CFRA resource updating prior to CHO execution. We have
run system level simulations to confirm that the proposed solution increases
the ratio of CFRA attempts during CHO. In the best-case scenario, we observe a
gain exceeding 13%. We also show how the average delay of completing the
handover is reduced. To provide the entire perspective, we present at what
expense these gains can be achieved by analyzing the increased signaling
overhead for updating the random access resources. The study has been conducted
for various network settings and considering higher frequency ranges at which
the user communicates with the network. Finally, we provide an outlook on
future extensions of the investigated solution.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14872" title="Abstract">arXiv:2307.14872</a> [<a href="/pdf/2307.14872" title="Download PDF">pdf</a>, <a href="/ps/2307.14872" title="Download PostScript">ps</a>, <a href="/format/2307.14872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correlation decay up to the sampling threshold in the local lemma regime
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chunyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yitong Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Probability (math.PR)

</div>
<p class="mathjax">We study the decay of correlation between locally constrained independent
random variables in the local lemma regimes. the distribution defined by
constraint satisfaction problems (CSPs) in the local lemma regime. For
atomically constrained independent random variables of sufficiently large
domains, we show that a decay of correlation property holds up to the local
lemma condition $pD^{2+o(1)}\lesssim 1$, asymptotically matching the sampling
threshold for constraint satisfaction solutions [BGG+19,GGW22]. This provides
evidence for the conjectured $pD^2\lesssim 1$ threshold for the "sampling
Lov\'{a}sz local lemma".
<br />We use a recursively-constructed coupling to bound the correlation decay. Our
approach completely dispenses with the "freezing" paradigm originated from Beck
[Bec91], which was commonly used to deal with the non-self-reducibility of the
local lemma regimes, and hence can bypass the current technical barriers due to
the use of $\{2,3\}$-trees.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14874" title="Abstract">arXiv:2307.14874</a> [<a href="/pdf/2307.14874" title="Download PDF">pdf</a>, <a href="/ps/2307.14874" title="Download PostScript">ps</a>, <a href="/format/2307.14874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lookahead data-gathering strategies for online adaptive model reduction  of transport-dominated problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Singh%2C+R">Rodrigo Singh</a>, 
<a href="/search/math?searchtype=author&query=Uy%2C+W+I+T">Wayne Isaac Tan Uy</a>, 
<a href="/search/math?searchtype=author&query=Peherstorfer%2C+B">Benjamin Peherstorfer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Online adaptive model reduction efficiently reduces numerical models of
transport-dominated problems by updating reduced spaces over time, which leads
to nonlinear approximations on latent manifolds that can achieve a faster error
decay than classical linear model reduction methods that keep reduced spaces
fixed. Critical for online adaptive model reduction is coupling the full and
reduced model to judiciously gather data from the full model for adapting the
reduced spaces so that accurate approximations of the evolving full-model
solution fields can be maintained. In this work, we introduce lookahead
data-gathering strategies that predict the next state of the full model for
adapting reduced spaces towards dynamics that are likely to be seen in the
immediate future. Numerical experiments demonstrate that the proposed lookahead
strategies lead to accurate reduced models even for problems where previously
introduced data-gathering strategies that look back in time fail to provide
predictive models. The proposed lookahead strategies also improve the
robustness and stability of online adaptive reduced models.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14876" title="Abstract">arXiv:2307.14876</a> [<a href="/pdf/2307.14876" title="Download PDF">pdf</a>, <a href="/ps/2307.14876" title="Download PostScript">ps</a>, <a href="/format/2307.14876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single machine rescheduling for new orders: properties and complexity  results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rener%2C+E">Elena Rener</a>, 
<a href="/search/cs?searchtype=author&query=Salassa%2C+F">Fabio Salassa</a>, 
<a href="/search/cs?searchtype=author&query=T%27kindt%2C+V">Vincent T&#x27;kindt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">Rescheduling problems arise in a variety of situations where a previously
planned schedule needs to be adjusted to deal with unforeseen events. A common
problem is the arrival of new orders, i.e. jobs, which have to be integrated
into the schedule of the so-called old jobs. The maximum and total absolute
time deviations of the completion times of these jobs are modeled as a
disruption constraint to limit the change in the original schedule. Disruption
constraints affect the shape of an optimal schedule, particularly with respect
to the sequencing of old jobs and the insertion of idle time. We therefore give
a classification into idle and no-idle problems for a set of single-machine
rescheduling problems with different objective functions. We then prove the
complexity of five rescheduling problems that have been left open in the
literature.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14878" title="Abstract">arXiv:2307.14878</a> [<a href="/pdf/2307.14878" title="Download PDF">pdf</a>, <a href="/format/2307.14878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MESED: A Multi-modal Entity Set Expansion Dataset with Fine-grained  Semantic Classes and Hard Negative Entities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yangning Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tingwei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tianyu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shulin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hai-Tao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jun Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The Entity Set Expansion (ESE) task aims to expand a handful of seed entities
with new entities belonging to the same semantic class. Conventional ESE
methods are based on mono-modality (i.e., literal modality), which struggle to
deal with complex entities in the real world such as: (1) Negative entities
with fine-grained semantic differences. (2) Synonymous entities. (3) Polysemous
entities. (4) Long-tailed entities. These challenges prompt us to propose
Multi-modal Entity Set Expansion (MESE), where models integrate information
from multiple modalities to represent entities. Intuitively, the benefits of
multi-modal information for ESE are threefold: (1) Different modalities can
provide complementary information. (2) Multi-modal information provides a
unified signal via common visual properties for the same semantic class or
entity. (3) Multi-modal information offers robust alignment signal for
synonymous entities. To assess the performance of model in MESE and facilitate
further research, we constructed the MESED dataset which is the first
multi-modal dataset for ESE with large-scale and elaborate manual calibration.
A powerful multi-modal model MultiExpan is proposed which is pre-trained on
four multimodal pre-training tasks. The extensive experiments and analyses on
MESED demonstrate the high quality of the dataset and the effectiveness of our
MultiExpan, as well as pointing the direction for future research.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14879" title="Abstract">arXiv:2307.14879</a> [<a href="/pdf/2307.14879" title="Download PDF">pdf</a>, <a href="/format/2307.14879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Don&#x27;t Shoot the Messenger: Localization Prevention of Satellite Internet  Users
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koisser%2C+D">David Koisser</a>, 
<a href="/search/cs?searchtype=author&query=Mitev%2C+R">Richard Mitev</a>, 
<a href="/search/cs?searchtype=author&query=Chilese%2C+M">Marco Chilese</a>, 
<a href="/search/cs?searchtype=author&query=Sadeghi%2C+A">Ahmad-Reza Sadeghi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Satellite Internet plays an increasingly important role in geopolitical
conflicts. This notion was affirmed in the Ukrainian conflict escalating at the
beginning of 2022, with the large-scale deployment of the Starlink satellite
Internet service which consequently demonstrated the strategic importance of a
free flow of information. Aside from military use, many citizens publish
sensitive information on social media platforms to influence the public
narrative. However, the use of satellite communication has proven to be
dangerous, as the signals can be monitored by other satellites and used to
triangulate the source on the ground. Unfortunately, the targeted killings of
journalists have shown this threat to be effective. While the increasing
deployment of satellite Internet systems gives citizens an unprecedented
mouthpiece in conflicts, protecting them against localization is an unaddressed
problem.
<br />To address this threat, we present AnonSat, a novel scheme to protect
satellite Internet users from triangulation. AnonSat works with cheap
off-the-shelf devices, leveraging long-range wireless communication to span a
local network among satellite base stations. This allows rerouting users'
communication to other satellite base stations, some distance away from each
user, thus, preventing their localization. AnonSat is designed for easy
deployment and usability, which we demonstrate with a prototype implementation.
Our large-scale network simulations using real-world data sets show the
effectiveness of AnonSat in various practical settings.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14882" title="Abstract">arXiv:2307.14882</a> [<a href="/pdf/2307.14882" title="Download PDF">pdf</a>, <a href="/format/2307.14882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knot Theory and Error-Correcting Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kilic%2C+A+B">Altan B. Kilic</a>, 
<a href="/search/cs?searchtype=author&query=Nijsten%2C+A">Anne Nijsten</a>, 
<a href="/search/cs?searchtype=author&query=Pellikaan%2C+R">Ruud Pellikaan</a>, 
<a href="/search/cs?searchtype=author&query=Ravagnani%2C+A">Alberto Ravagnani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Algebraic Topology (math.AT); General Topology (math.GN)

</div>
<p class="mathjax">This paper builds a novel bridge between algebraic coding theory and
mathematical knot theory, with applications in both directions. We give methods
to construct error-correcting codes starting from the colorings of a knot,
describing through a series of results how the properties of the knot translate
into code parameters. We show that knots can be used to obtain error-correcting
codes with prescribed parameters and an efficient decoding algorithm.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14883" title="Abstract">arXiv:2307.14883</a> [<a href="/pdf/2307.14883" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Flight Plan Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=de+Oliveira%2C+%C3%8D+R">&#xcd;talo Romani de Oliveira</a>, 
<a href="/search/eess?searchtype=author&query=Altus%2C+S">Steve Altus</a>, 
<a href="/search/eess?searchtype=author&query=Tiourine%2C+S">Sergey Tiourine</a>, 
<a href="/search/eess?searchtype=author&query=Neto%2C+E+C+P">Euclides C. Pinto Neto</a>, 
<a href="/search/eess?searchtype=author&query=Leite%2C+A">Alexandre Leite</a>, 
<a href="/search/eess?searchtype=author&query=de+Azevedo%2C+F+C+F">Felipe C. F. de Azevedo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint to the 2023 IEEE/AIAA Digital Aviation Systems Conference, October 1-5, 2023, Barcelona, Spain
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Airline operations are subject to many uncertainties, such as weather,
varying demand, maintenance events, congestion, etc. Large amounts of
information are currently ignored due to difficulties in processing big data
sets. We explore the use of ensemble weather forecast, which presents several
distinct weather predictions for the same time horizon. So far, ensemble
forecasts have been very little exploited for flight planning purposes.
<br />Currently, airlines already carry out lots of statistical analyses on past
data, and devise effective policies for how much fuel and payload an aircraft
should carry and how much of time buffer should be used in the schedule. But
these buffers can be further reduced by doing forward-looking stochastic
optimization. The use of ensemble forecast allows to select a trajectory that
optimizes the expected outcome of a flight for an array of scenarios, instead
of optimizing for a single one. Besides, aircraft payload is another
considerable source of uncertainty.
<br />We tested stochastic optimization, first with the objective of optimizing
single flights, then with the objective of optimizing whole schedules. In one
of the experiments, it was observed that, in 55.8% of the cases, stochastic
optimization outperforms conventional optimization in terms of fuel
consumption; in only 0.4% of the cases, conventional optimization wins; and, in
the remaining 43.8% of the cases, they achieve equal results. The experiments
with stochastic payload demonstrated that the use of payload uncertainty can
squeeze a bit more fuel savings from the flight plan outcomes. But the use of
this technology is not driven only by reducing overall fuel consumption. One
optimization criterion can be the minimization of diversions or fuel
emergencies, that is, choosing the candidate that minimizes the maximum fuel
consumption (minimax).
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14889" title="Abstract">arXiv:2307.14889</a> [<a href="/pdf/2307.14889" title="Download PDF">pdf</a>, <a href="/format/2307.14889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly Supervised Multi-Modal 3D Human Body Pose Estimation for  Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bauer%2C+P">Peter Bauer</a>, 
<a href="/search/cs?searchtype=author&query=Bouazizi%2C+A">Arij Bouazizi</a>, 
<a href="/search/cs?searchtype=author&query=Kressel%2C+U">Ulrich Kressel</a>, 
<a href="/search/cs?searchtype=author&query=Flohr%2C+F+B">Fabian B. Flohr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, Accepted at IEEE-IV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Accurate 3D human pose estimation (3D HPE) is crucial for enabling autonomous
vehicles (AVs) to make informed decisions and respond proactively in critical
road scenarios. Promising results of 3D HPE have been gained in several domains
such as human-computer interaction, robotics, sports and medical analytics,
often based on data collected in well-controlled laboratory environments.
Nevertheless, the transfer of 3D HPE methods to AVs has received limited
research attention, due to the challenges posed by obtaining accurate 3D pose
annotations and the limited suitability of data from other domains.
<br />We present a simple yet efficient weakly supervised approach for 3D HPE in
the AV context by employing a high-level sensor fusion between camera and LiDAR
data. The weakly supervised setting enables training on the target datasets
without any 2D/3D keypoint labels by using an off-the-shelf 2D joint extractor
and pseudo labels generated from LiDAR to image projections. Our approach
outperforms state-of-the-art results by up to $\sim$ 13% on the Waymo Open
Dataset in the weakly supervised setting and achieves state-of-the-art results
in the supervised setting.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14893" title="Abstract">arXiv:2307.14893</a> [<a href="/pdf/2307.14893" title="Download PDF">pdf</a>, <a href="/ps/2307.14893" title="Download PostScript">ps</a>, <a href="/format/2307.14893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Base-based Model Checking for Multi-Agent Only Believing (long version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Lima%2C+T">Tiago de Lima</a>, 
<a href="/search/cs?searchtype=author&query=Lorini%2C+E">Emiliano Lorini</a>, 
<a href="/search/cs?searchtype=author&query=Schwarzentruber%2C+F">Fran&#xe7;ois Schwarzentruber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">We present a novel semantics for the language of multi-agent only believing
exploiting belief bases, and show how to use it for automatically checking
formulas of this language and of its dynamic extension with private belief
expansion operators. We provide a PSPACE algorithm for model checking relying
on a reduction to QBF and alternative dedicated algorithm relying on the
exploration of the state space. We present an implementation of the QBF-based
algorithm and some experimental results on computation time in a concrete
example.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14894" title="Abstract">arXiv:2307.14894</a> [<a href="/pdf/2307.14894" title="Download PDF">pdf</a>, <a href="/format/2307.14894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing the Closed-Loop Performance of Detect-And-Avoid Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=de+Oliveira%2C+%C3%8D+R">&#xcd;talo Romani de Oliveira</a>, 
<a href="/search/eess?searchtype=author&query=Matsumoto%2C+T">Thiago Matsumoto</a>, 
<a href="/search/eess?searchtype=author&query=Mayne%2C+A">Aaron Mayne</a>, 
<a href="/search/eess?searchtype=author&query=Berna%2C+A+G">Antonio Gracia Berna</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint submitted to the 2023 IEEE Conference on Intelligent Transportation Systems (ITSC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Detect-And-Avoid (DAA) algorithms for unmanned air vehicles have industry
standards called Minimum Operational Performance Standards (MOPS), establishing
criteria to check whether they can ensure safe separation for all plausible
operational conditions. However, these MOPS ensure performance for the
avoidance maneuvers, which are open-loop, but not for the maneuvers that bring
the air vehicles back to their intended courses, closing the control loop of
the missions. In this paper, we analyze the closed-loop performance of existing
DAA algorithms, by experimenting large numbers of traffic configurations with 4
aircraft in a delimited airspace.
<br />We measure and analyze their rates of loss of separation and timeout events,
the latter happening when a chain of maneuvers exceeds the maximum supply of
energy in a vehicle. We also analyze the efficiency of the closed-loop logic,
expressed as the excess fuel rate, and study the relationship between safety
and efficiency in these scenarios. Our results show that the inefficiency
caused by DAA algorithms is very significant in dense airspaces and that it
offers ample space for improvement.
<br />Performing the simulations of the closed-loop mission management logic can be
highly time consuming. Despite there being Neural Network approximations of DAA
logic that alleviate the computational load, none of those that we found
available can properly handle cases with more than one intruder in the ownship
surveillance range. Therefore, in an attempt to overcome the high computational
cost of analyzing the closed-loop performance of DAA algorithms, we study the
correlation between inefficiency and safety of closed-loop scenarios, and some
indicators from the corresponding open-loop scenarios, such as angle of
deviation and number of deviations per flight time.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14897" title="Abstract">arXiv:2307.14897</a> [<a href="/pdf/2307.14897" title="Download PDF">pdf</a>, <a href="/format/2307.14897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixture of Self-Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruslim%2C+A+R">Aristo Renaldo Ruslim</a>, 
<a href="/search/cs?searchtype=author&query=Yudistira%2C+N">Novanto Yudistira</a>, 
<a href="/search/cs?searchtype=author&query=Setiawan%2C+B+D">Budi Darma Setiawan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Self-supervised learning is popular method because of its ability to learn
features in images without using its labels and is able to overcome limited
labeled datasets used in supervised learning. Self-supervised learning works by
using a pretext task which will be trained on the model before being applied to
a specific task. There are some examples of pretext tasks used in
self-supervised learning in the field of image recognition, namely rotation
prediction, solving jigsaw puzzles, and predicting relative positions on image.
Previous studies have only used one type of transformation as a pretext task.
This raises the question of how it affects if more than one pretext task is
used and to use a gating network to combine all pretext tasks. Therefore, we
propose the Gated Self-Supervised Learning method to improve image
classification which use more than one transformation as pretext task and uses
the Mixture of Expert architecture as a gating network in combining each
pretext task so that the model automatically can study and focus more on the
most useful augmentations for classification. We test performance of the
proposed method in several scenarios, namely CIFAR imbalance dataset
classification, adversarial perturbations, Tiny-Imagenet dataset
classification, and semi-supervised learning. Moreover, there are Grad-CAM and
T-SNE analysis that are used to see the proposed method for identifying
important features that influence image classification and representing data
for each class and separating different classes properly. Our code is in
https://github.com/aristorenaldo/G-SSL
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14899" title="Abstract">arXiv:2307.14899</a> [<a href="/pdf/2307.14899" title="Download PDF">pdf</a>, <a href="/format/2307.14899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval-based Text Selection for Addressing Class-Imbalanced Data in  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmadi%2C+S">Sareh Ahmadi</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Aditya Shah</a>, 
<a href="/search/cs?searchtype=author&query=Fox%2C+E">Edward Fox</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper addresses the problem of selecting of a set of texts for
annotation in text classification using retrieval methods when there are limits
on the number of annotations due to constraints on human resources. An
additional challenge addressed is dealing with binary categories that have a
small number of positive instances, reflecting severe class imbalance. In our
situation, where annotation occurs over a long time period, the selection of
texts to be annotated can be made in batches, with previous annotations guiding
the choice of the next set. To address these challenges, the paper proposes
leveraging SHAP to construct a quality set of queries for Elasticsearch and
semantic search, to try to identify optimal sets of texts for annotation that
will help with class imbalance. The approach is tested on sets of cue texts
describing possible future events, constructed by participants involved in
studies aimed to help with the management of obesity and diabetes. We introduce
an effective method for selecting a small set of texts for annotation and
building high-quality classifiers. We integrate vector search, semantic search,
and machine learning classifiers to yield a good solution. Our experiments
demonstrate improved F1 scores for the minority classes in binary
classification.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14901" title="Abstract">arXiv:2307.14901</a> [<a href="/pdf/2307.14901" title="Download PDF">pdf</a>, <a href="/format/2307.14901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text-guided Foundation Model Adaptation for Pathological Image  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunkun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaosong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaoting Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dequan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to MICCAI2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The recent surge of foundation models in computer vision and natural language
processing opens up perspectives in utilizing multi-modal clinical data to
train large models with strong generalizability. Yet pathological image
datasets often lack biomedical text annotation and enrichment. Guiding
data-efficient image diagnosis from the use of biomedical text knowledge
becomes a substantial interest. In this paper, we propose to Connect Image and
Text Embeddings (CITE) to enhance pathological image classification. CITE
injects text insights gained from language models pre-trained with a broad
range of biomedical texts, leading to adapt foundation models towards
pathological image understanding. Through extensive experiments on the
PatchGastric stomach tumor pathological image dataset, we demonstrate that CITE
achieves leading performance compared with various baselines especially when
training data is scarce. CITE offers insights into leveraging in-domain text
knowledge to reinforce data-efficient pathological image classification. Code
is available at https://github.com/Yunkun-Zhang/CITE.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14902" title="Abstract">arXiv:2307.14902</a> [<a href="/pdf/2307.14902" title="Download PDF">pdf</a>, <a href="/format/2307.14902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CodeLens: An Interactive Tool for Visualizing Code Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuejun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Bettaieb%2C+S">Seifeddine Bettaieb</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Traon%2C+Y+L">Yves Le Traon</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Q">Qiang Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Representing source code in a generic input format is crucial to automate
software engineering tasks, e.g., applying machine learning algorithms to
extract information. Visualizing code representations can further enable human
experts to gain an intuitive insight into the code. Unfortunately, as of today,
there is no universal tool that can simultaneously visualise different types of
code representations. In this paper, we introduce a tool, CodeLens, which
provides a visual interaction environment that supports various representation
methods and helps developers understand and explore them. CodeLens is designed
to support multiple programming languages, such as Java, Python, and
JavaScript, and four types of code representations, including sequence of
tokens, abstract syntax tree (AST), data flow graph (DFG), and control flow
graph (CFG). By using CodeLens, developers can quickly visualize the specific
code representation and also obtain the represented inputs for models of code.
The Web-based interface of CodeLens is available at <a href="http://www.codelens.org.">this http URL</a>
The demonstration video can be found at <a href="http://www.codelens.org/demo.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14906" title="Abstract">arXiv:2307.14906</a> [<a href="/pdf/2307.14906" title="Download PDF">pdf</a>, <a href="/format/2307.14906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Session-Based Transformer Recommendations using Optimized  Negative Sampling and Loss Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wilm%2C+T">Timo Wilm</a>, 
<a href="/search/cs?searchtype=author&query=Normann%2C+P">Philipp Normann</a>, 
<a href="/search/cs?searchtype=author&query=Baumeister%2C+S">Sophie Baumeister</a>, 
<a href="/search/cs?searchtype=author&query=Kobow%2C+P">Paul-Vincent Kobow</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the Seventeenth ACM Conference on Recommender Systems (RecSys '23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This work introduces TRON, a scalable session-based Transformer Recommender
using Optimized Negative-sampling. Motivated by the scalability and performance
limitations of prevailing models such as SASRec and GRU4Rec+, TRON integrates
top-k negative sampling and listwise loss functions to enhance its
recommendation accuracy. Evaluations on relevant large-scale e-commerce
datasets show that TRON improves upon the recommendation quality of current
methods while maintaining training speeds similar to SASRec. A live A/B test
yielded an 18.14% increase in click-through rate over SASRec, highlighting the
potential of TRON in practical settings. For further research, we provide
access to our source code at https://github.com/otto-de/TRON and an anonymized
dataset at https://github.com/otto-de/recsys-dataset.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14909" title="Abstract">arXiv:2307.14909</a> [<a href="/pdf/2307.14909" title="Download PDF">pdf</a>, <a href="/format/2307.14909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Targeted Static Analysis for OCaml C Stubs: eliminating gremlins from  the code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=T%C3%B6r%C3%B6k%2C+E">Edwin T&#xf6;r&#xf6;k</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to the OCaml 2023 workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Migration to OCaml 5 requires updating a lot of C bindings due to the removal
of naked pointer support. Writing OCaml user-defined primitives in C is a
necessity, but is unsafe and error-prone. It does not benefit from either
OCaml's or C's type checking, and existing C static analysers are not aware of
the OCaml GC safety rules, and cannot infer them from existing macros alone.The
alternative is automatically generating C stubs, which requires correctly
managing value lifetimes. Having a static analyser for OCaml to C interfaces is
useful outside the OCaml 5 porting effort too.
<br />After some motivating examples of real bugs in C bindings a static analyser
is presented that finds these known classes of bugs. The tool works on the
OCaml abstract parse and typed trees, and generates a header file and a caller
model. Together with a simplified model of the OCaml runtime this is used as
input to a static analysis framework, Goblint. An analysis is developed that
tracks dereferences of OCaml values, and together with the existing framework
reports incorrect dereferences. An example is shown how to extend the analysis
to cover more safety properties.
<br />The tools and runtime models are generic and could be reused with other
static analysis tools.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14910" title="Abstract">arXiv:2307.14910</a> [<a href="/pdf/2307.14910" title="Download PDF">pdf</a>, <a href="/format/2307.14910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Latency Massive Access with Multicast Wake Up Radio
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+A+A">Anay Ajit Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Chiariotti%2C+F">Federico Chiariotti</a>, 
<a href="/search/cs?searchtype=author&query=Zanella%2C+A">Andrea Zanella</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 21st Mediterranean Communication and Computer Networking Conference (MedComNet)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The use of Wake-Up Radio (WUR) in Internet of Things (IoT) networks can
significantly improve their energy efficiency: battery-powered sensors can
remain in a low-power (sleep) mode while listening for wake-up messages using
their WUR and reactivate only when polled, saving energy. However,
polling-based Time Division Multiple Access (TDMA) may significantly increase
data transmission delay if packets are generated sporadically, as nodes with no
information still need to be polled. In this paper, we examine the effect of
multicast polling for WUR-enabled wireless nodes. The idea is to assign nodes
to multicast groups so that all nodes in the same group can be solicited by a
multicast polling message. This may cause collisions, which can be solved by
requesting retransmissions from the involved nodes. We analyze the performance
of different multicast polling and retransmission strategies, showing that the
optimal approach can significantly reduce the delay over TDMA and ALOHA in
low-traffic scenarios while keeping good energy efficiency.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14912" title="Abstract">arXiv:2307.14912</a> [<a href="/pdf/2307.14912" title="Download PDF">pdf</a>, <a href="/format/2307.14912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ARC-NLP at PAN 2023: Hierarchical Long Text Classification for Trigger  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sahin%2C+U">Umitcan Sahin</a>, 
<a href="/search/cs?searchtype=author&query=Kucukkaya%2C+I+E">Izzet Emre Kucukkaya</a>, 
<a href="/search/cs?searchtype=author&query=Toraman%2C+C">Cagri Toraman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by PAN at CLEF 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Fanfiction, a popular form of creative writing set within established
fictional universes, has gained a substantial online following. However,
ensuring the well-being and safety of participants has become a critical
concern in this community. The detection of triggering content, material that
may cause emotional distress or trauma to readers, poses a significant
challenge. In this paper, we describe our approach for the Trigger Detection
shared task at PAN CLEF 2023, where we want to detect multiple triggering
content in a given Fanfiction document. For this, we build a hierarchical model
that uses recurrence over Transformer-based language models. In our approach,
we first split long documents into smaller sized segments and use them to
fine-tune a Transformer model. Then, we extract feature embeddings from the
fine-tuned Transformer model, which are used as input in the training of
multiple LSTM models for trigger detection in a multi-label setting. Our model
achieves an F1-macro score of 0.372 and F1-micro score of 0.736 on the
validation set, which are higher than the baseline results shared at PAN CLEF
2023.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14913" title="Abstract">arXiv:2307.14913</a> [<a href="/pdf/2307.14913" title="Download PDF">pdf</a>, <a href="/format/2307.14913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ARC-NLP at PAN 2023: Transition-Focused Natural Language Inference for  Writing Style Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kucukkaya%2C+I+E">Izzet Emre Kucukkaya</a>, 
<a href="/search/cs?searchtype=author&query=Sahin%2C+U">Umitcan Sahin</a>, 
<a href="/search/cs?searchtype=author&query=Toraman%2C+C">Cagri Toraman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by PAN at CLEF 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The task of multi-author writing style detection aims at finding any
positions of writing style change in a given text document. We formulate the
task as a natural language inference problem where two consecutive paragraphs
are paired. Our approach focuses on transitions between paragraphs while
truncating input tokens for the task. As backbone models, we employ different
Transformer-based encoders with warmup phase during training. We submit the
model version that outperforms baselines and other proposed model versions in
our experiments. For the easy and medium setups, we submit transition-focused
natural language inference based on DeBERTa with warmup training, and the same
model without transition for the hard setup.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14917" title="Abstract">arXiv:2307.14917</a> [<a href="/pdf/2307.14917" title="Download PDF">pdf</a>, <a href="/format/2307.14917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NSA: Naturalistic Support Artifact to Boost Network Confidence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Abhijith Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Munz%2C+P">Phil Munz</a>, 
<a href="/search/cs?searchtype=author&query=Narayan%2C+A">Apurva Narayan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Visual AI systems are vulnerable to natural and synthetic physical corruption
in the real-world. Such corruption often arises unexpectedly and alters the
model's performance. In recent years, the primary focus has been on adversarial
attacks. However, natural corruptions (e.g., snow, fog, dust) are an
omnipresent threat to visual AI systems and should be considered equally
important. Many existing works propose interesting solutions to train robust
models against natural corruption. These works either leverage image
augmentations, which come with the additional cost of model training, or place
suspicious patches in the scene to design unadversarial examples. In this work,
we propose the idea of naturalistic support artifacts (NSA) for robust
prediction. The NSAs are shown to be beneficial in scenarios where model
parameters are inaccessible and adding artifacts in the scene is feasible. The
NSAs are natural looking objects generated through artifact training using
DC-GAN to have high visual fidelity in the scene. We test against natural
corruptions on the Imagenette dataset and observe the improvement in prediction
confidence score by four times. We also demonstrate NSA's capability to
increase adversarial accuracy by 8\% on average. Lastly, we qualitatively
analyze NSAs using saliency maps to understand how they help improve prediction
confidence.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14918" title="Abstract">arXiv:2307.14918</a> [<a href="/pdf/2307.14918" title="Download PDF">pdf</a>, <a href="/format/2307.14918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GET3D--: Learning GET3D from Unconstrained Image Collections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Fanghua Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xintao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zheyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yan-Pei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+C">Chao Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The demand for efficient 3D model generation techniques has grown
exponentially, as manual creation of 3D models is time-consuming and requires
specialized expertise. While generative models have shown potential in creating
3D textured shapes from 2D images, their applicability in 3D industries is
limited due to the lack of a well-defined camera distribution in real-world
scenarios, resulting in low-quality shapes. To overcome this limitation, we
propose GET3D--, the first method that directly generates textured 3D shapes
from 2D images with unknown pose and scale. GET3D-- comprises a 3D shape
generator and a learnable camera sampler that captures the 6D external changes
on the camera. In addition, We propose a novel training schedule to stably
optimize both the shape generator and camera sampler in a unified framework. By
controlling external variations using the learnable camera sampler, our method
can generate aligned shapes with clear textures. Extensive experiments
demonstrate the efficacy of GET3D--, which precisely fits the 6D camera pose
distribution and generates high-quality shapes on both synthetic and realistic
unconstrained datasets.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14921" title="Abstract">arXiv:2307.14921</a> [<a href="/pdf/2307.14921" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Performance of Deep Learning Model for Material  Segmentation on Two HPC Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Williams%2C+W+R">Warren R. Williams</a>, 
<a href="/search/cs?searchtype=author&query=Glandon%2C+S+R">S. Ross Glandon</a>, 
<a href="/search/cs?searchtype=author&query=Morris%2C+L+L">Luke L. Morris</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J+C">Jing-Ru C. Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Performance Benchmarking of HPC systems is an ongoing effort that seeks to
provide information that will allow for increased performance and improve the
job schedulers that manage these systems. We develop a benchmarking tool that
utilizes machine learning models and gathers performance data on
GPU-accelerated nodes while they perform material segmentation analysis. The
benchmark uses a ML model that has been converted from Caffe to PyTorch using
the MMdnn toolkit and the MINC-2500 dataset. Performance data is gathered on
two ERDC DSRC systems, Onyx and Vulcanite. The data reveals that while
Vulcanite has faster model times in a large number of benchmarks, and it is
also more subject to some environmental factors that can cause performances
slower than Onyx. In contrast the model times from Onyx are consistent across
benchmarks.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14927" title="Abstract">arXiv:2307.14927</a> [<a href="/pdf/2307.14927" title="Download PDF">pdf</a>, <a href="/format/2307.14927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cascaded Code Distributed Computing With Low Complexity and Improved  Flexibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Youlong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+M">Minquan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Dianhua Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Coded distributed computing, proposed by Li et al., offers significant
potential for reducing the communication load in MapReduce computing systems.
In the setting of the \emph{cascaded} coded distributed computing that
consisting of $K$ nodes, $N$ input files, and $Q$ output functions, the
objective is to compute each output function through $s\geq 1$ nodes with a
computation load $r\geq 1$, enabling the application of coding techniques
during the Shuffle phase to achieve minimum communication load. However, for
most existing coded distributed computing schemes, a major limitation lies in
their demand for splitting the original data into an exponentially growing
number of input files in terms of $N/\binom{K}{r} \in\mathbb{N}$ and requiring
an exponentially large number of output functions $Q/\binom{K}{s}
\in\mathbb{N}$, which imposes stringent requirements for implementation and
results in significant coding complexity when $K$ is large. In this paper, we
focus on the cascaded case of $K/s\in\mathbb{N} $, deliberately designing the
strategy of input files store and output functions assignment based on a
grouping method, such that a low-complexity two-round Shuffle phase is
available. The main advantages of our proposed scheme contains: 1) the
communication load is quilt close to or surprisingly better than the optimal
state-of-the-art scheme proposed by Li et al.; 2) our scheme requires
significantly less number of input files and output functions; 3) all the
operations are implemented over the minimum binary field $\mathbb{F}_2$.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14928" title="Abstract">arXiv:2307.14928</a> [<a href="/pdf/2307.14928" title="Download PDF">pdf</a>, <a href="/format/2307.14928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph-based Polyphonic Multitrack Music Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cosenza%2C+E">Emanuele Cosenza</a>, 
<a href="/search/cs?searchtype=author&query=Valenti%2C+A">Andrea Valenti</a>, 
<a href="/search/cs?searchtype=author&query=Bacciu%2C+D">Davide Bacciu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Graphs can be leveraged to model polyphonic multitrack symbolic music, where
notes, chords and entire sections may be linked at different levels of the
musical hierarchy by tonal and rhythmic relationships. Nonetheless, there is a
lack of works that consider graph representations in the context of deep
learning systems for music generation. This paper bridges this gap by
introducing a novel graph representation for music and a deep Variational
Autoencoder that generates the structure and the content of musical graphs
separately, one after the other, with a hierarchical architecture that matches
the structural priors of music. By separating the structure and content of
musical graphs, it is possible to condition generation by specifying which
instruments are played at certain times. This opens the door to a new form of
human-computer interaction in the context of music co-creation. After training
the model on existing MIDI datasets, the experiments show that the model is
able to generate appealing short and long musical sequences and to
realistically interpolate between them, producing music that is tonally and
rhythmically consistent. Finally, the visualization of the embeddings shows
that the model is able to organize its latent space in accordance with known
musical concepts.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14930" title="Abstract">arXiv:2307.14930</a> [<a href="/pdf/2307.14930" title="Download PDF">pdf</a>, <a href="/format/2307.14930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Regular Path Queries on Compressed Adjacency Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arroyuelo%2C+D">Diego Arroyuelo</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez-Brand%C3%B3n%2C+A">Adri&#xe1;n G&#xf3;mez-Brand&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Navarro%2C+G">Gonzalo Navarro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Databases (cs.DB)

</div>
<p class="mathjax">Regular Path Queries (RPQs), which are essentially regular expressions to be
matched against the labels of paths in labeled graphs, are at the core of graph
database query languages like SPARQL. A way to solve RPQs is to translate them
into a sequence of operations on the adjacency matrices of each label. We
design and implement a Boolean algebra on sparse matrix representations and, as
an application, use them to handle RPQs. Our baseline representation uses the
same space as the previously most compact index for RPQs and excels in handling
the hardest types of queries. Our more succinct structure, based on
$k^2$-trees, is 4 times smaller and still solves complex RPQs in reasonable
time.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14935" title="Abstract">arXiv:2307.14935</a> [<a href="/pdf/2307.14935" title="Download PDF">pdf</a>, <a href="/ps/2307.14935" title="Download PostScript">ps</a>, <a href="/format/2307.14935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Data Quality Problems with Desbordante: a Demo
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chernishev%2C+G">George Chernishev</a>, 
<a href="/search/cs?searchtype=author&query=Polyntsov%2C+M">Michael Polyntsov</a>, 
<a href="/search/cs?searchtype=author&query=Chizhov%2C+A">Anton Chizhov</a>, 
<a href="/search/cs?searchtype=author&query=Stupakov%2C+K">Kirill Stupakov</a>, 
<a href="/search/cs?searchtype=author&query=Shchuckin%2C+I">Ilya Shchuckin</a>, 
<a href="/search/cs?searchtype=author&query=Smirnov%2C+A">Alexander Smirnov</a>, 
<a href="/search/cs?searchtype=author&query=Strutovsky%2C+M">Maxim Strutovsky</a>, 
<a href="/search/cs?searchtype=author&query=Shlyonskikh%2C+A">Alexey Shlyonskikh</a>, 
<a href="/search/cs?searchtype=author&query=Firsov%2C+M">Mikhail Firsov</a>, 
<a href="/search/cs?searchtype=author&query=Manannikov%2C+S">Stepan Manannikov</a>, 
<a href="/search/cs?searchtype=author&query=Bobrov%2C+N">Nikita Bobrov</a>, 
<a href="/search/cs?searchtype=author&query=Goncharov%2C+D">Daniil Goncharov</a>, 
<a href="/search/cs?searchtype=author&query=Barutkin%2C+I">Ilia Barutkin</a>, 
<a href="/search/cs?searchtype=author&query=Shalnev%2C+V">Vladislav Shalnev</a>, 
<a href="/search/cs?searchtype=author&query=Muraviev%2C+K">Kirill Muraviev</a>, 
<a href="/search/cs?searchtype=author&query=Rakhmukova%2C+A">Anna Rakhmukova</a>, 
<a href="/search/cs?searchtype=author&query=Shcheka%2C+D">Dmitriy Shcheka</a>, 
<a href="/search/cs?searchtype=author&query=Chernikov%2C+A">Anton Chernikov</a>, 
<a href="/search/cs?searchtype=author&query=Vyrodov%2C+M">Mikhail Vyrodov</a>, 
<a href="/search/cs?searchtype=author&query=Yaroslav%2C+K">Kurbatov Yaroslav</a>, 
<a href="/search/cs?searchtype=author&query=Fofanov%2C+M">Maxim Fofanov</a>, 
<a href="/search/cs?searchtype=author&query=Sergei%2C+B">Belokonnyi Sergei</a>, 
<a href="/search/cs?searchtype=author&query=Pavel%2C+A">Anosov Pavel</a>, 
<a href="/search/cs?searchtype=author&query=Saliou%2C+A">Arthur Saliou</a>, 
<a href="/search/cs?searchtype=author&query=Gaisin%2C+E">Eduard Gaisin</a>, 
<a href="/search/cs?searchtype=author&query=Smirnov%2C+K">Kirill Smirnov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
<p class="mathjax">Data profiling is an essential process in modern data-driven industries. One
of its critical components is the discovery and validation of complex
statistics, including functional dependencies, data constraints, association
rules, and others.
<br />However, most existing data profiling systems that focus on complex
statistics do not provide proper integration with the tools used by
contemporary data scientists. This creates a significant barrier to the
adoption of these tools in the industry. Moreover, existing systems were not
created with industrial-grade workloads in mind. Finally, they do not aim to
provide descriptive explanations, i.e. why a given pattern is not found. It is
a significant issue as it is essential to understand the underlying reasons for
a specific pattern's absence to make informed decisions based on the data.
<br />Because of that, these patterns are effectively rest in thin air: their
application scope is rather limited, they are rarely used by the broader
public. At the same time, as we are going to demonstrate in this presentation,
complex statistics can be efficiently used to solve many classic data quality
problems.
<br />Desbordante is an open-source data profiler that aims to close this gap. It
is built with emphasis on industrial application: it is efficient, scalable,
resilient to crashes, and provides explanations. Furthermore, it provides
seamless Python integration by offloading various costly operations to the C++
core, not only mining.
<br />In this demonstration, we show several scenarios that allow end users to
solve different data quality problems. Namely, we showcase typo detection, data
deduplication, and data anomaly detection scenarios.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14936" title="Abstract">arXiv:2307.14936</a> [<a href="/pdf/2307.14936" title="Download PDF">pdf</a>, <a href="/format/2307.14936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PanGu-Coder2: Boosting Large Language Models for Code with Ranking  Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+B">Bo Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Taihong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zan%2C+D">Daoguang Zan</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+B">Bing Geng</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+A">An Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+M">Muhan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+A">Ailun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Jichuan Ji</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jingyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuenan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qianxiang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Programming Languages (cs.PL); Software Engineering (cs.SE)

</div>
<p class="mathjax">Large Language Models for Code (Code LLM) are flourishing. New and powerful
models are released on a weekly basis, demonstrating remarkable performance on
the code generation task. Various approaches have been proposed to boost the
code generation performance of pre-trained Code LLMs, such as supervised
fine-tuning, instruction tuning, reinforcement learning, etc. In this paper, we
propose a novel RRTF (Rank Responses to align Test&amp;Teacher Feedback) framework,
which can effectively and efficiently boost pre-trained large language models
for code generation. Under this framework, we present PanGu-Coder2, which
achieves 62.20% pass@1 on the OpenAI HumanEval benchmark. Furthermore, through
an extensive evaluation on CoderEval and LeetCode benchmarks, we show that
PanGu-Coder2 consistently outperforms all previous Code LLMs.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14938" title="Abstract">arXiv:2307.14938</a> [<a href="/pdf/2307.14938" title="Download PDF">pdf</a>, <a href="/format/2307.14938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Interaction-Aware Interval Analysis of Neural Network Feedback  Loops
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jafarpour%2C+S">Saber Jafarpour</a>, 
<a href="/search/eess?searchtype=author&query=Harapanahalli%2C+A">Akash Harapanahalli</a>, 
<a href="/search/eess?searchtype=author&query=Coogan%2C+S">Samuel Coogan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">In this paper, we propose a computationally efficient framework for interval
reachability of neural network controlled systems. Our approach builds upon
inclusion functions for the neural network controller and the open-loop system.
We observe that many state-of-the-art neural network verifiers can produce
inclusion functions for neural networks. We introduce and analyze a new class
of inclusion functions for the open-loop dynamics based on bounds of the
function Jacobian that is particularly suitable for capturing the interactions
between systems and neural network controllers. Next, for any dynamical system,
we use inclusion functions to construct an embedding system with twice the
number of states as the original system. We show that a single trajectory of
this embedding system provides hyper-rectangular over-approximations of
reachable sets. We then propose two approaches for constructing a closed-loop
embedding system for a neural network controlled dynamical system that accounts
for the interaction between the system and the controller in different ways.
The interconnection-based approach accounts for the worst-case evolution of
each coordinate separately by substituting the neural network inclusion
function into the open-loop embedding system. The interaction-based approach
uses the newly introduced class of Jacobian-based inclusion functions to fully
capture first-order interactions between the system and the controller.
Finally, we implement our approach in a Python framework called
\texttt{ReachMM} and show that on several existing benchmarks, our methods
outperform the existing approaches in the literature. We also demonstrate the
scalability of our method on a vehicle platooning example with up to $200$
states.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14940" title="Abstract">arXiv:2307.14940</a> [<a href="/pdf/2307.14940" title="Download PDF">pdf</a>, <a href="/format/2307.14940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Self-Adaptive Penalty Method for Integrating Prior Knowledge  Constraints into Neural ODEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coelho%2C+C">C. Coelho</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+M+F+P">M. Fernanda P. Costa</a>, 
<a href="/search/cs?searchtype=author&query=Ferr%C3%A1s%2C+L+L">L. L. Ferr&#xe1;s</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">The continuous dynamics of natural systems has been effectively modelled
using Neural Ordinary Differential Equations (Neural ODEs). However, for
accurate and meaningful predictions, it is crucial that the models follow the
underlying rules or laws that govern these systems. In this work, we propose a
self-adaptive penalty algorithm for Neural ODEs to enable modelling of
constrained natural systems. The proposed self-adaptive penalty function can
dynamically adjust the penalty parameters. The explicit introduction of prior
knowledge helps to increase the interpretability of Neural ODE -based models.
We validate the proposed approach by modelling three natural systems with prior
knowledge constraints: population growth, chemical reaction evolution, and
damped harmonic oscillator motion. The numerical experiments and a comparison
with other penalty Neural ODE approaches and \emph{vanilla} Neural ODE,
demonstrate the effectiveness of the proposed self-adaptive penalty algorithm
for Neural ODEs in modelling constrained natural systems. Moreover, the
self-adaptive penalty approach provides more accurate and robust models with
reliable and meaningful predictions.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14949" title="Abstract">arXiv:2307.14949</a> [<a href="/pdf/2307.14949" title="Download PDF">pdf</a>, <a href="/format/2307.14949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Analysis of Displacement Processes in Porous Media using  Spatio-Temporal Flow Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Straub%2C+A">Alexander Straub</a>, 
<a href="/search/cs?searchtype=author&query=Karadimitriou%2C+N">Nikolaos Karadimitriou</a>, 
<a href="/search/cs?searchtype=author&query=Reina%2C+G">Guido Reina</a>, 
<a href="/search/cs?searchtype=author&query=Frey%2C+S">Steffen Frey</a>, 
<a href="/search/cs?searchtype=author&query=Steeb%2C+H">Holger Steeb</a>, 
<a href="/search/cs?searchtype=author&query=Ertl%2C+T">Thomas Ertl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in a special issue of TVCG for the IEEE VIS 2023 conference proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">We developed a new approach comprised of different visualizations for the
comparative spatio-temporal analysis of displacement processes in porous media.
We aim to analyze and compare ensemble datasets from experiments to gain
insight into the influence of different parameters on fluid flow. To capture
the displacement of a defending fluid by an invading fluid, we first condense
an input image series to a single time map. From this map, we generate a
spatio-temporal flow graph covering the whole process. This graph is further
simplified to only reflect topological changes in the movement of the invading
fluid. Our interactive tools allow the visual analysis of these processes by
visualizing the graph structure and the context of the experimental setup, as
well as by providing charts for multiple metrics. We apply our approach to
analyze and compare ensemble datasets jointly with domain experts, where we
vary either fluid properties or the solid structure of the porous medium. We
finally report the generated insights from the domain experts and discuss our
contribution's advantages, generality, and limitations.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14951" title="Abstract">arXiv:2307.14951</a> [<a href="/pdf/2307.14951" title="Download PDF">pdf</a>, <a href="/format/2307.14951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Widespread Flaws in Offline Evaluation of Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hidasi%2C+B">Bal&#xe1;zs Hidasi</a>, 
<a href="/search/cs?searchtype=author&query=Czapp%2C+%C3%81+T">&#xc1;d&#xe1;m Tibor Czapp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appearing in the Proceedings of the 17th ACM Conference on Recommender Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Even though offline evaluation is just an imperfect proxy of online
performance -- due to the interactive nature of recommenders -- it will
probably remain the primary way of evaluation in recommender systems research
for the foreseeable future, since the proprietary nature of production
recommenders prevents independent validation of A/B test setups and
verification of online results. Therefore, it is imperative that offline
evaluation setups are as realistic and as flawless as they can be.
Unfortunately, evaluation flaws are quite common in recommender systems
research nowadays, due to later works copying flawed evaluation setups from
their predecessors without questioning their validity. In the hope of improving
the quality of offline evaluation of recommender systems, we discuss four of
these widespread flaws and why researchers should avoid them.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14952" title="Abstract">arXiv:2307.14952</a> [<a href="/pdf/2307.14952" title="Download PDF">pdf</a>, <a href="/format/2307.14952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Network Fault-tolerant and Byzantine-resilient Social Learning via  Collaborative Hierarchical Non-Bayesian Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mclaughlin%2C+C">Connor Mclaughlin</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Matthew Ding</a>, 
<a href="/search/cs?searchtype=author&query=Edogmus%2C+D">Denis Edogmus</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+L">Lili Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">As the network scale increases, existing fully distributed solutions start to
lag behind the real-world challenges such as (1) slow information propagation,
(2) network communication failures, and (3) external adversarial attacks. In
this paper, we focus on hierarchical system architecture and address the
problem of non-Bayesian learning over networks that are vulnerable to
communication failures and adversarial attacks. On network communication, we
consider packet-dropping link failures.
<br />We first propose a hierarchical robust push-sum algorithm that can achieve
average consensus despite frequent packet-dropping link failures. We provide a
sparse information fusion rule between the parameter server and arbitrarily
selected network representatives. Then, interleaving the consensus update step
with a dual averaging update with Kullback-Leibler (KL) divergence as the
proximal function, we obtain a packet-dropping fault-tolerant non-Bayesian
learning algorithm with provable convergence guarantees.
<br />On external adversarial attacks, we consider Byzantine attacks in which the
compromised agents can send maliciously calibrated messages to others
(including both the agents and the parameter server). To avoid the curse of
dimensionality of Byzantine consensus, we solve the non-Bayesian learning
problem via running multiple dynamics, each of which only involves Byzantine
consensus with scalar inputs. To facilitate resilient information propagation
across sub-networks, we use a novel Byzantine-resilient gossiping-type rule at
the parameter server.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14953" title="Abstract">arXiv:2307.14953</a> [<a href="/pdf/2307.14953" title="Download PDF">pdf</a>, <a href="/format/2307.14953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Source Domain Adaptation through Dataset Dictionary Learning in  Wasserstein Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Montesuma%2C+E+F">Eduardo Fernandes Montesuma</a>, 
<a href="/search/cs?searchtype=author&query=Mboula%2C+F+N">Fred Ngol&#xe8; Mboula</a>, 
<a href="/search/cs?searchtype=author&query=Souloumiac%2C+A">Antoine Souloumiac</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages,9 figures,Accepted as a conference paper at the 26th European Conference on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper seeks to solve Multi-Source Domain Adaptation (MSDA), which aims
to mitigate data distribution shifts when transferring knowledge from multiple
labeled source domains to an unlabeled target domain. We propose a novel MSDA
framework based on dictionary learning and optimal transport. We interpret each
domain in MSDA as an empirical distribution. As such, we express each domain as
a Wasserstein barycenter of dictionary atoms, which are empirical
distributions. We propose a novel algorithm, DaDiL, for learning via
mini-batches: (i) atom distributions; (ii) a matrix of barycentric coordinates.
Based on our dictionary, we propose two novel methods for MSDA: DaDil-R, based
on the reconstruction of labeled samples in the target domain, and DaDiL-E,
based on the ensembling of classifiers learned on atom distributions. We
evaluate our methods in 3 benchmarks: Caltech-Office, Office 31, and CRWU,
where we improved previous state-of-the-art by 3.15%, 2.29%, and 7.71% in
classification performance. Finally, we show that interpolations in the
Wasserstein hull of learned atoms provide data that can generalize to the
target domain.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14956" title="Abstract">arXiv:2307.14956</a> [<a href="/pdf/2307.14956" title="Download PDF">pdf</a>, <a href="/ps/2307.14956" title="Download PostScript">ps</a>, <a href="/format/2307.14956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Effect of Third Party Implementations on Reproducibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hidasi%2C+B">Bal&#xe1;zs Hidasi</a>, 
<a href="/search/cs?searchtype=author&query=Czapp%2C+%C3%81+T">&#xc1;d&#xe1;m Tibor Czapp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appearing in the Proceedings of the 17th ACM Conference on Recommender Systems (RecSys'23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Reproducibility of recommender systems research has come under scrutiny
during recent years. Along with works focusing on repeating experiments with
certain algorithms, the research community has also started discussing various
aspects of evaluation and how these affect reproducibility. We add a novel
angle to this discussion by examining how unofficial third-party
implementations could benefit or hinder reproducibility. Besides giving a
general overview, we thoroughly examine six third-party implementations of a
popular recommender algorithm and compare them to the official version on five
public datasets. In the light of our alarming findings we aim to draw the
attention of the research community to this neglected aspect of
reproducibility.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14959" title="Abstract">arXiv:2307.14959</a> [<a href="/pdf/2307.14959" title="Download PDF">pdf</a>, <a href="/format/2307.14959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Model Aggregation via Self-Supervised Priors for Highly  Imbalanced Medical Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elbatel%2C+M">Marawan Elbatel</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hualiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%AD%2C+R">Robert Mart&#xed;</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Huazhu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaomeng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the medical field, federated learning commonly deals with highly
imbalanced datasets, including skin lesions and gastrointestinal images.
Existing federated methods under highly imbalanced datasets primarily focus on
optimizing a global model without incorporating the intra-class variations that
can arise in medical imaging due to different populations, findings, and
scanners. In this paper, we study the inter-client intra-class variations with
publicly available self-supervised auxiliary networks. Specifically, we find
that employing a shared auxiliary pre-trained model, like MoCo-V2, locally on
every client yields consistent divergence measurements. Based on these
findings, we derive a dynamic balanced model aggregation via self-supervised
priors (MAS) to guide the global model optimization. Fed-MAS can be utilized
with different local learning methods for effective model aggregation toward a
highly robust and unbiased global model. Our code is available at
\url{https://github.com/xmed-lab/Fed-MAS}.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14961" title="Abstract">arXiv:2307.14961</a> [<a href="/pdf/2307.14961" title="Download PDF">pdf</a>, <a href="/format/2307.14961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A localized orthogonal decomposition strategy for hybrid discontinuous  Galerkin methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lu%2C+P">Peipei Lu</a>, 
<a href="/search/math?searchtype=author&query=Maier%2C+R">Roland Maier</a>, 
<a href="/search/math?searchtype=author&query=Rupp%2C+A">Andreas Rupp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We formulate and analyze a multiscale method for an elliptic problem with an
oscillatory coefficient based on a skeletal (hybrid) formulation. More
precisely, we employ hybrid discontinuous Galerkin approaches and combine them
with the localized orthogonal decomposition methodology to obtain a
coarse-scale skeletal method that effectively includes fine-scale information.
This work is a first step to reliably merge hybrid skeletal formulations and
localized orthogonal decomposition and unite the advantages of both strategies.
Numerical experiments are presented to illustrate the theoretical findings.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14971" title="Abstract">arXiv:2307.14971</a> [<a href="/pdf/2307.14971" title="Download PDF">pdf</a>, <a href="/format/2307.14971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Take-A-Photo: 3D-to-2D Generative Pre-training of Point Cloud Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xumin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+Y">Yongming Rao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiwen Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023, project page: <a href="https://tap.ivg-research.xyz">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">With the overwhelming trend of mask image modeling led by MAE, generative
pre-training has shown a remarkable potential to boost the performance of
fundamental models in 2D vision. However, in 3D vision, the over-reliance on
Transformer-based backbones and the unordered nature of point clouds have
restricted the further development of generative pre-training. In this paper,
we propose a novel 3D-to-2D generative pre-training method that is adaptable to
any point cloud model. We propose to generate view images from different
instructed poses via the cross-attention mechanism as the pre-training scheme.
Generating view images has more precise supervision than its point cloud
counterpart, thus assisting 3D backbones to have a finer comprehension of the
geometrical structure and stereoscopic relations of the point cloud.
Experimental results have proved the superiority of our proposed 3D-to-2D
generative pre-training over previous pre-training methods. Our method is also
effective in boosting the performance of architecture-oriented approaches,
achieving state-of-the-art performance when fine-tuning on ScanObjectNN
classification and ShapeNetPart segmentation tasks. Code is available at
https://github.com/wangzy22/TAP.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14980" title="Abstract">arXiv:2307.14980</a> [<a href="/pdf/2307.14980" title="Download PDF">pdf</a>, <a href="/format/2307.14980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aligning rTWT with 802.1Qbv: a Network Calculus Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barroso-Fern%C3%A1ndez%2C+C">Carlos Barroso-Fern&#xe1;ndez</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADn-P%C3%A9rez%2C+J">Jorge Mart&#xed;n-P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Ayimba%2C+C">Constantine Ayimba</a>, 
<a href="/search/cs?searchtype=author&query=de+la+Oliva%2C+A">Antonio de la Oliva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages, 3 figures, workshop submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Industry 4.0 applications impose the challenging demand of delivering packets
with bounded latencies via a wireless network. This is further complicated if
the network is not dedicated to the time critical application. In this paper we
use network calculus analysis to derive closed form expressions of latency
bounds for time critical traffic when 802.11 Target Wake Time (TWT) and
802.1Qbv work together in a shared 802.11 network.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14981" title="Abstract">arXiv:2307.14981</a> [<a href="/pdf/2307.14981" title="Download PDF">pdf</a>, <a href="/format/2307.14981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MapNeRF: Incorporating Map Priors into Neural Radiance Fields for  Driving View Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiadai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zhelun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liangjun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Simulating camera sensors is a crucial task in autonomous driving. Although
neural radiance fields are exceptional at synthesizing photorealistic views in
driving simulations, they still fail in generating extrapolated views. This
paper proposes to incorporate map priors into neural radiance fields to
synthesize out-of-trajectory driving views with semantic road consistency. The
key insight is that map information can be utilized as a prior to guide the
training of the radiance fields with uncertainty. Specifically, we utilize the
coarse ground surface as uncertain information to supervise the density field
and warp depth with uncertainty from unknown camera poses to ensure multi-view
consistency. Experimental results demonstrate that our approach can produce
semantic consistency in deviated views for vehicle camera simulation.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14984" title="Abstract">arXiv:2307.14984</a> [<a href="/pdf/2307.14984" title="Download PDF">pdf</a>, <a href="/format/2307.14984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> S$^3$: Social-network Simulation System with Large Language  Model-Empowered Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chen Gao</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+X">Xiaochong Lan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhihong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+J">Jinzhu Mao</a>, 
<a href="/search/cs?searchtype=author&query=Piao%2C+J">Jinghua Piao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huandong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+D">Depeng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Social network simulation plays a crucial role in addressing various
challenges within social science. It offers extensive applications such as
state prediction, phenomena explanation, and policy-making support, among
others. In this work, we harness the formidable human-like capabilities
exhibited by large language models (LLMs) in sensing, reasoning, and behaving,
and utilize these qualities to construct the S$^3$ system (short for
$\textbf{S}$ocial network $\textbf{S}$imulation $\textbf{S}$ystem). Adhering to
the widely employed agent-based simulation paradigm, we employ prompt
engineering and prompt tuning techniques to ensure that the agent's behavior
closely emulates that of a genuine human within the social network.
Specifically, we simulate three pivotal aspects: emotion, attitude, and
interaction behaviors. By endowing the agent in the system with the ability to
perceive the informational environment and emulate human actions, we observe
the emergence of population-level phenomena, including the propagation of
information, attitudes, and emotions. We conduct an evaluation encompassing two
levels of simulation, employing real-world social network data. Encouragingly,
the results demonstrate promising accuracy. This work represents an initial
step in the realm of social network simulation empowered by LLM-based agents.
We anticipate that our endeavors will serve as a source of inspiration for the
development of simulation systems within, but not limited to, social science.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14988" title="Abstract">arXiv:2307.14988</a> [<a href="/pdf/2307.14988" title="Download PDF">pdf</a>, <a href="/format/2307.14988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incrementally-Computable Neural Networks: Efficient Inference for  Dynamic Inputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharir%2C+O">Or Sharir</a>, 
<a href="/search/cs?searchtype=author&query=Anandkumar%2C+A">Anima Anandkumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
<p class="mathjax">Deep learning often faces the challenge of efficiently processing dynamic
inputs, such as sensor data or user inputs. For example, an AI writing
assistant is required to update its suggestions in real time as a document is
edited. Re-running the model each time is expensive, even with compression
techniques like knowledge distillation, pruning, or quantization. Instead, we
take an incremental computing approach, looking to reuse calculations as the
inputs change. However, the dense connectivity of conventional architectures
poses a major obstacle to incremental computation, as even minor input changes
cascade through the network and restrict information reuse. To address this, we
use vector quantization to discretize intermediate values in the network, which
filters out noisy and unnecessary modifications to hidden neurons, facilitating
the reuse of their values. We apply this approach to the transformers
architecture, creating an efficient incremental inference algorithm with
complexity proportional to the fraction of the modified inputs. Our experiments
with adapting the OPT-125M pre-trained language model demonstrate comparable
accuracy on document classification while requiring 12.1X (median) fewer
operations for processing sequences of atomic edits.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14991" title="Abstract">arXiv:2307.14991</a> [<a href="/pdf/2307.14991" title="Download PDF">pdf</a>, <a href="/format/2307.14991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilingual Code Co-Evolution Using Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+P">Pengyu Nie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J+J">Junyi Jessy Li</a>, 
<a href="/search/cs?searchtype=author&query=Gligoric%2C+M">Milos Gligoric</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to FSE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Many software projects implement APIs and algorithms in multiple programming
languages. Maintaining such projects is tiresome, as developers have to ensure
that any change (e.g., a bug fix or a new feature) is being propagated, timely
and without errors, to implementations in other programming languages. In the
world of ever-changing software, using rule-based translation tools (i.e.,
transpilers) or machine learning models for translating code from one language
to another provides limited value. Translating each time the entire codebase
from one language to another is not the way developers work. In this paper, we
target a novel task: translating code changes from one programming language to
another using large language models (LLMs). We design and implement the first
LLM, dubbed Codeditor, to tackle this task. Codeditor explicitly models code
changes as edit sequences and learns to correlate changes across programming
languages. To evaluate Codeditor, we collect a corpus of 6,613 aligned code
changes from 8 pairs of open-source software projects implementing similar
functionalities in two programming languages (Java and C#). Results show that
Codeditor outperforms the state-of-the-art approaches by a large margin on all
commonly used automatic metrics. Our work also reveals that Codeditor is
complementary to the existing generation-based models, and their combination
ensures even greater performance.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14993" title="Abstract">arXiv:2307.14993</a> [<a href="/pdf/2307.14993" title="Download PDF">pdf</a>, <a href="/format/2307.14993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Thinker: Learning to Plan and Act
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chung%2C+S">Stephen Chung</a>, 
<a href="/search/cs?searchtype=author&query=Anokhin%2C+I">Ivan Anokhin</a>, 
<a href="/search/cs?searchtype=author&query=Krueger%2C+D">David Krueger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose the Thinker algorithm, a novel approach that enables reinforcement
learning agents to autonomously interact with and utilize a learned world
model. The Thinker algorithm wraps the environment with a world model and
introduces new actions designed for interacting with the world model. These
model-interaction actions enable agents to perform planning by proposing
alternative plans to the world model before selecting a final action to execute
in the environment. This approach eliminates the need for hand-crafted planning
algorithms by enabling the agent to learn how to plan autonomously and allows
for easy interpretation of the agent's plan with visualization. We demonstrate
the algorithm's effectiveness through experimental results in the game of
Sokoban and the Atari 2600 benchmark, where the Thinker algorithm achieves
state-of-the-art performance and competitive results, respectively.
Visualizations of agents trained with the Thinker algorithm demonstrate that
they have learned to plan effectively with the world model to select better
actions. The algorithm's generality opens a new research direction on how a
world model can be used in reinforcement learning and how planning can be
seamlessly integrated into an agent's decision-making process.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14995" title="Abstract">arXiv:2307.14995</a> [<a href="/pdf/2307.14995" title="Download PDF">pdf</a>, <a href="/format/2307.14995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling TransNormer to 175 Billion Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhen Qin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dong Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weigao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weixuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xuyang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaodong Han</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yunshen Wei</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+B">Baohong Lv</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+F">Fei Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yiran Zhong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report. Yiran Zhong is the corresponding author. Zhen Qin, Dong Li, Weigao Sun, Weixuan Sun, Xuyang Shen contribute equally to this paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present TransNormerLLM, the first linear attention-based Large Language
Model (LLM) that outperforms conventional softmax attention-based models in
terms of both accuracy and efficiency. TransNormerLLM evolves from the previous
linear attention architecture TransNormer by making advanced modifications that
include positional embedding, linear attention acceleration, gating mechanism,
tensor normalization, inference acceleration and stabilization. Specifically,
we use LRPE together with an exponential decay to avoid attention dilution
issues while allowing the model to retain global interactions between tokens.
Additionally, we propose Lightning Attention, a cutting-edge technique that
accelerates linear attention by more than twice in runtime and reduces memory
usage by a remarkable four times. To further enhance the performance of
TransNormer, we leverage a gating mechanism to smooth training and a new tensor
normalization scheme to accelerate the model, resulting in an impressive
acceleration of over 20%. Furthermore, we have developed a robust inference
algorithm that ensures numerical stability and consistent inference speed,
regardless of the sequence length, showcasing superior efficiency during both
training and inference stages. Scalability is at the heart of our model's
design, enabling seamless deployment on large-scale clusters and facilitating
expansion to even more extensive models, all while maintaining outstanding
performance metrics. Rigorous validation of our model design is achieved
through a series of comprehensive experiments on our self-collected corpus,
boasting a size exceeding 6TB and containing over 2 trillion tokens. To ensure
data quality and relevance, we implement a new self-cleaning strategy to filter
our collected data. Our pre-trained models will be released to foster community
advancements in efficient LLMs.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14998" title="Abstract">arXiv:2307.14998</a> [<a href="/pdf/2307.14998" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-domain Channel Property Feedback in 5G-Advanced and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ernstr%C3%B6m%2C+P">Per Ernstr&#xf6;m</a>, 
<a href="/search/cs?searchtype=author&query=Muruganathan%2C+S+D">Siva D. Muruganathan</a>, 
<a href="/search/cs?searchtype=author&query=Nagalapur%2C+K+K">Keerthi Kumar Nagalapur</a>, 
<a href="/search/cs?searchtype=author&query=Athley%2C+F">Fredrik Athley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">The availability of time-variability information of a channel between a
network node and a user equipment at the network side allows a 5G network to
optimally configure its parameters to maximize both user and system
performance. In the Release 18 enhancements of 5G-Advanced, a time-domain
channel property (TDCP) feedback that indicates the degree of time-variability
of the channel is being standardized. In this article, we describe the
standardized TDCP feedback and its applications. The benefit of the feedback is
further illustrated through numerical evaluations.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15002" title="Abstract">arXiv:2307.15002</a> [<a href="/pdf/2307.15002" title="Download PDF">pdf</a>, <a href="/format/2307.15002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gzip versus bag-of-words for text classification with KNN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Opitz%2C+J">Juri Opitz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The effectiveness of compression distance in KNN-based text classification
('gzip') has recently garnered lots of attention. In this note, we show that
similar or better effectiveness can be achieved with simpler means, and text
compression may not be necessary. Indeed, we find that a simple 'bag-of-words'
matching can achieve similar or better accuracy, and is more efficient.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15005" title="Abstract">arXiv:2307.15005</a> [<a href="/pdf/2307.15005" title="Download PDF">pdf</a>, <a href="/format/2307.15005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FLiCR: A Fast and Lightweight LiDAR Point Cloud Compression Based on  Lossy RI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heo%2C+J">Jin Heo</a>, 
<a href="/search/cs?searchtype=author&query=Phillips%2C+C">Christopher Phillips</a>, 
<a href="/search/cs?searchtype=author&query=Gavrilovska%2C+A">Ada Gavrilovska</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 11 figures, conference paper
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In 2022 IEEE/ACM 7th Symposium on Edge Computing (SEC) (pp.
  54-67). IEEE 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Light detection and ranging (LiDAR) sensors are becoming available on modern
mobile devices and provide a 3D sensing capability. This new capability is
beneficial for perceptions in various use cases, but it is challenging for
resource-constrained mobile devices to use the perceptions in real-time because
of their high computational complexity. In this context, edge computing can be
used to enable LiDAR online perceptions, but offloading the perceptions on the
edge server requires a low-latency, lightweight, and efficient compression due
to the large volume of LiDAR point clouds data.
<br />This paper presents FLiCR, a fast and lightweight LiDAR point cloud
compression method for enabling edge-assisted online perceptions. FLiCR is
based on range images (RI) as an intermediate representation (IR), and
dictionary coding for compressing RIs. FLiCR achieves its benefits by
leveraging lossy RIs, and we show the efficiency of bytestream compression is
largely improved with quantization and subsampling. In addition, we identify
the limitation of current quality metrics for presenting the entropy of a point
cloud, and introduce a new metric that reflects both point-wise and
entropy-wise qualities for lossy IRs. The evaluation results show FLiCR is more
suitable for edge-assisted real-time perceptions than the existing LiDAR
compressions, and we demonstrate the effectiveness of our compression and
metric with the evaluations on 3D object detection and LiDAR SLAM.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15007" title="Abstract">arXiv:2307.15007</a> [<a href="/pdf/2307.15007" title="Download PDF">pdf</a>, <a href="/format/2307.15007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verifiable Feature Attributions: A Bridge between Post Hoc  Explainability and Inherent Interpretability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhalla%2C+U">Usha Bhalla</a>, 
<a href="/search/cs?searchtype=author&query=Srinivas%2C+S">Suraj Srinivas</a>, 
<a href="/search/cs?searchtype=author&query=Lakkaraju%2C+H">Himabindu Lakkaraju</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">With the increased deployment of machine learning models in various
real-world applications, researchers and practitioners alike have emphasized
the need for explanations of model behaviour. To this end, two broad strategies
have been outlined in prior literature to explain models. Post hoc explanation
methods explain the behaviour of complex black-box models by highlighting
features that are critical to model predictions; however, prior work has shown
that these explanations may not be faithful, and even more concerning is our
inability to verify them. Specifically, it is nontrivial to evaluate if a given
attribution is correct with respect to the underlying model. Inherently
interpretable models, on the other hand, circumvent these issues by explicitly
encoding explanations into model architecture, meaning their explanations are
naturally faithful and verifiable, but they often exhibit poor predictive
performance due to their limited expressive power. In this work, we aim to
bridge the gap between the aforementioned strategies by proposing Verifiability
Tuning (VerT), a method that transforms black-box models into models that
naturally yield faithful and verifiable feature attributions. We begin by
introducing a formal theoretical framework to understand verifiability and show
that attributions produced by standard models cannot be verified. We then
leverage this framework to propose a method to build verifiable models and
feature attributions out of fully trained black-box models. Finally, we perform
extensive experiments on semi-synthetic and real-world datasets, and show that
VerT produces models that (1) yield explanations that are correct and
verifiable and (2) are faithful to the original black-box models they are meant
to explain.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15008" title="Abstract">arXiv:2307.15008</a> [<a href="/pdf/2307.15008" title="Download PDF">pdf</a>, <a href="/format/2307.15008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A LLM Assisted Exploitation of AI-Guardian
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carlini%2C+N">Nicholas Carlini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) are now highly capable at a diverse range of
tasks. This paper studies whether or not GPT-4, one such LLM, is capable of
assisting researchers in the field of adversarial machine learning. As a case
study, we evaluate the robustness of AI-Guardian, a recent defense to
adversarial examples published at IEEE S&amp;P 2023, a top computer security
conference. We completely break this defense: the proposed scheme does not
increase robustness compared to an undefended baseline.
<br />We write none of the code to attack this model, and instead prompt GPT-4 to
implement all attack algorithms following our instructions and guidance. This
process was surprisingly effective and efficient, with the language model at
times producing code from ambiguous instructions faster than the author of this
paper could have done. We conclude by discussing (1) the warning signs present
in the evaluation that suggested to us AI-Guardian would be broken, and (2) our
experience with designing attacks and performing novel research using the most
recent advances in language modeling.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15016" title="Abstract">arXiv:2307.15016</a> [<a href="/pdf/2307.15016" title="Download PDF">pdf</a>, <a href="/format/2307.15016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Good is Google Bard&#x27;s Visual Understanding? An Empirical Study on  Open Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Haotong Qin</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+G">Ge-Peng Ji</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Salman Khan</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+D">Deng-Ping Fan</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+F+S">Fahad Shahbaz Khan</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Google's Bard has emerged as a formidable competitor to OpenAI's ChatGPT in
the field of conversational AI. Notably, Bard has recently been updated to
handle visual inputs alongside text prompts during conversations. Given Bard's
impressive track record in handling textual inputs, we explore its capabilities
in understanding and interpreting visual data (images) conditioned by text
questions. This exploration holds the potential to unveil new insights and
challenges for Bard and other forthcoming multi-modal Generative models,
especially in addressing complex computer vision problems that demand accurate
visual and language understanding. Specifically, in this study, we focus on 15
diverse task scenarios encompassing regular, camouflaged, medical, under-water
and remote sensing data to comprehensively evaluate Bard's performance. Our
primary finding indicates that Bard still struggles in these vision scenarios,
highlighting the significant gap in vision-based understanding that needs to be
bridged in future developments. We expect that this empirical study will prove
valuable in advancing future models, leading to enhanced capabilities in
comprehending and interpreting fine-grained visual data. Our project is
released on https://github.com/htqin/GoogleBard-VisUnderstand
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15017" title="Abstract">arXiv:2307.15017</a> [<a href="/pdf/2307.15017" title="Download PDF">pdf</a>, <a href="/format/2307.15017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Samplable Anonymous Aggregation for Private Federated Data Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Talwar%2C+K">Kunal Talwar</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shan Wang</a>, 
<a href="/search/cs?searchtype=author&query=McMillan%2C+A">Audra McMillan</a>, 
<a href="/search/cs?searchtype=author&query=Jina%2C+V">Vojta Jina</a>, 
<a href="/search/cs?searchtype=author&query=Feldman%2C+V">Vitaly Feldman</a>, 
<a href="/search/cs?searchtype=author&query=Basile%2C+B">Bailey Basile</a>, 
<a href="/search/cs?searchtype=author&query=Cahill%2C+A">Aine Cahill</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+Y+S">Yi Sheng Chan</a>, 
<a href="/search/cs?searchtype=author&query=Chatzidakis%2C+M">Mike Chatzidakis</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junye Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chick%2C+O">Oliver Chick</a>, 
<a href="/search/cs?searchtype=author&query=Chitnis%2C+M">Mona Chitnis</a>, 
<a href="/search/cs?searchtype=author&query=Ganta%2C+S">Suman Ganta</a>, 
<a href="/search/cs?searchtype=author&query=Goren%2C+Y">Yusuf Goren</a>, 
<a href="/search/cs?searchtype=author&query=Granqvist%2C+F">Filip Granqvist</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+K">Kristine Guo</a>, 
<a href="/search/cs?searchtype=author&query=Jacobs%2C+F">Frederic Jacobs</a>, 
<a href="/search/cs?searchtype=author&query=Javidbakht%2C+O">Omid Javidbakht</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Albert Liu</a>, 
<a href="/search/cs?searchtype=author&query=Low%2C+R">Richard Low</a>, 
<a href="/search/cs?searchtype=author&query=Mascenik%2C+D">Dan Mascenik</a>, 
<a href="/search/cs?searchtype=author&query=Myers%2C+S">Steve Myers</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+D">David Park</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+W">Wonhee Park</a>, 
<a href="/search/cs?searchtype=author&query=Parsa%2C+G">Gianni Parsa</a>, 
<a href="/search/cs?searchtype=author&query=Pauly%2C+T">Tommy Pauly</a>, 
<a href="/search/cs?searchtype=author&query=Priebe%2C+C">Christian Priebe</a>, 
<a href="/search/cs?searchtype=author&query=Rishi%2C+R">Rehan Rishi</a>, 
<a href="/search/cs?searchtype=author&query=Rothblum%2C+G">Guy Rothblum</a>, 
<a href="/search/cs?searchtype=author&query=Scaria%2C+M">Michael Scaria</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Linmao Song</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+C">Congzheng Song</a>, 
<a href="/search/cs?searchtype=author&query=Tarbe%2C+K">Karl Tarbe</a>, 
<a href="/search/cs?searchtype=author&query=Vogt%2C+S">Sebastian Vogt</a>, 
<a href="/search/cs?searchtype=author&query=Winstrom%2C+L">Luke Winstrom</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shundong Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We revisit the problem of designing scalable protocols for private statistics
and private federated learning when each device holds its private data. Our
first contribution is to propose a simple primitive that allows for efficient
implementation of several commonly used algorithms, and allows for privacy
accounting that is close to that in the central setting without requiring the
strong trust assumptions it entails. Second, we propose a system architecture
that implements this primitive and perform a security analysis of the proposed
system.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15019" title="Abstract">arXiv:2307.15019</a> [<a href="/pdf/2307.15019" title="Download PDF">pdf</a>, <a href="/format/2307.15019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Graph Transformer for Deepfake Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khormali%2C+A">Aminollah Khormali</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jiann-Shiun Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deepfake detection methods have shown promising results in recognizing
forgeries within a given dataset, where training and testing take place on the
in-distribution dataset. However, their performance deteriorates significantly
when presented with unseen samples. As a result, a reliable deepfake detection
system must remain impartial to forgery types, appearance, and quality for
guaranteed generalizable detection performance. Despite various attempts to
enhance cross-dataset generalization, the problem remains challenging,
particularly when testing against common post-processing perturbations, such as
video compression or blur. Hence, this study introduces a deepfake detection
framework, leveraging a self-supervised pre-training model that delivers
exceptional generalization ability, withstanding common corruptions and
enabling feature explainability. The framework comprises three key components:
a feature extractor based on vision Transformer architecture that is
pre-trained via self-supervised contrastive learning methodology, a graph
convolution network coupled with a Transformer discriminator, and a graph
Transformer relevancy map that provides a better understanding of manipulated
regions and further explains the model's decision. To assess the effectiveness
of the proposed framework, several challenging experiments are conducted,
including in-data distribution performance, cross-dataset, cross-manipulation
generalization, and robustness against common post-production perturbations.
The results achieved demonstrate the remarkable effectiveness of the proposed
deepfake detection framework, surpassing the current state-of-the-art
approaches.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15020" title="Abstract">arXiv:2307.15020</a> [<a href="/pdf/2307.15020" title="Download PDF">pdf</a>, <a href="/format/2307.15020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Liang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Anqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Hang Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Changtai Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kangkang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">Haonan He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuanwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Q">Qiyue Kang</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Z">Zhenzhong Lan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 12 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have shown the potential to be integrated into
human daily lives. Therefore, user preference is the most critical criterion
for assessing LLMs' performance in real-world scenarios. However, existing
benchmarks mainly focus on measuring models' accuracy using multi-choice
questions, which limits the understanding of their capabilities in real
applications. We fill this gap by proposing a comprehensive Chinese benchmark
SuperCLUE, named after another popular Chinese LLM benchmark CLUE. SuperCLUE
encompasses three sub-tasks: actual users' queries and ratings derived from an
LLM battle platform (CArena), open-ended questions with single and
multiple-turn dialogues (OPEN), and closed-ended questions with the same stems
as open-ended single-turn ones (CLOSE). Our study shows that accuracy on
closed-ended questions is insufficient to reflect human preferences achieved on
open-ended ones. At the same time, they can complement each other to predict
actual user preferences. We also demonstrate that GPT-4 is a reliable judge to
automatically evaluate human preferences on open-ended questions in a Chinese
context. Our benchmark will be released at https://www.CLUEbenchmarks.com
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15023" title="Abstract">arXiv:2307.15023</a> [<a href="/pdf/2307.15023" title="Download PDF">pdf</a>, <a href="/ps/2307.15023" title="Download PostScript">ps</a>, <a href="/format/2307.15023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revealing the Impact of Beamforming in ISAC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+C">Chongjun Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingqi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This letter proposes advanced beamforming design and analyzes its influence
on the sensing and communications (S&amp;C) performance for a multiple-antenna
integrated S&amp;C (ISAC) system with a single communication user and a single
target. Novel closed-form beamformers are derived for three typical scenarios,
including the sensing-centric design, communications-centric design, and Pareto
optimal design. Regarding each scenario, the outage probability, ergodic
communication rate (CR), and sensing rate (SR) are analyzed to derive the
diversity orders and high signal-to-noise ratio slopes. Numerical results are
provided to demonstrate that i) beamforming design can affect the high-SNR
power offset and diversity order but does not influence the high-SNR slope; ii)
ISAC exhibits larger high-SNR slopes and a more extensive SR-CR region than
conventional frequency-division S&amp;C (FDSAC) techniques.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15027" title="Abstract">arXiv:2307.15027</a> [<a href="/pdf/2307.15027" title="Download PDF">pdf</a>, <a href="/format/2307.15027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring Centralization of Online Platforms Through Size and  Interconnection of Communities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Trujillo%2C+M+Z">Milo Z. Trujillo</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%A9bert-Dufresne%2C+L">Laurent H&#xe9;bert-Dufresne</a>, 
<a href="/search/cs?searchtype=author&query=Bagrow%2C+J">James Bagrow</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures, 6 pages and 9 figures of supplemental material
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Decentralized architecture offers a robust and flexible structure for online
platforms, since centralized moderation and computation can be easy to disrupt
with targeted attacks. However, a platform offering a decentralized
architecture does not guarantee that users will use it in a decentralized way,
and measuring the centralization of socio-technical networks is not an easy
task. In this paper we introduce a method of characterizing community influence
in terms of how many edges between communities would be disrupted by a
community's removal. Our approach provides a careful definition of
"centralization" appropriate in bipartite user-community socio-technical
networks, and demonstrates the inadequacy of more trivial methods for
interrogating centralization such as examining the distribution of community
sizes. We use this method to compare the structure of multiple socio-technical
platforms -- Mastodon, git code hosting servers, BitChute, Usenet, and Voat --
and find a range of structures, from interconnected but decentralized git
servers to an effectively centralized use of Mastodon servers, as well as
multiscale hybrid network structures of disconnected Voat subverses. As the
ecosystem of socio-technical platforms diversifies, it becomes critical to not
solely focus on the underlying technologies but also consider the structure of
how users interact through the technical infrastructure.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15029" title="Abstract">arXiv:2307.15029</a> [<a href="/pdf/2307.15029" title="Download PDF">pdf</a>, <a href="/format/2307.15029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Segmentation Network for Scene Text Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+G">Guiqin Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Inspired by deep convolution segmentation algorithms, scene text detectors
break the performance ceiling of datasets steadily. However, these methods
often encounter threshold selection bottlenecks and have poor performance on
text instances with extreme aspect ratios. In this paper, we propose to
automatically learn the discriminate segmentation threshold, which
distinguishes text pixels from background pixels for segmentation-based scene
text detectors and then further reduces the time-consuming manual parameter
adjustment. Besides, we design a Global-information Enhanced Feature Pyramid
Network (GE-FPN) for capturing text instances with macro size and extreme
aspect ratios. Following the GE-FPN, we introduce a cascade optimization
structure to further refine the text instances. Finally, together with the
proposed threshold learning strategy and text detection structure, we design an
Adaptive Segmentation Network (ASNet) for scene text detection. Extensive
experiments are carried out to demonstrate that the proposed ASNet can achieve
the state-of-the-art performance on four text detection benchmarks, i.e., ICDAR
2015, MSRA-TD500, ICDAR 2017 MLT and CTW1500. The ablation experiments also
verify the effectiveness of our contributions.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15033" title="Abstract">arXiv:2307.15033</a> [<a href="/pdf/2307.15033" title="Download PDF">pdf</a>, <a href="/format/2307.15033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diverse Inpainting and Editing with GAN Inversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yildirim%2C+A+B">Ahmet Burak Yildirim</a>, 
<a href="/search/cs?searchtype=author&query=Pehlivan%2C+H">Hamza Pehlivan</a>, 
<a href="/search/cs?searchtype=author&query=Bilecen%2C+B+B">Bahri Batuhan Bilecen</a>, 
<a href="/search/cs?searchtype=author&query=Dundar%2C+A">Aysegul Dundar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent inversion methods have shown that real images can be inverted into
StyleGAN's latent space and numerous edits can be achieved on those images
thanks to the semantically rich feature representations of well-trained GAN
models. However, extensive research has also shown that image inversion is
challenging due to the trade-off between high-fidelity reconstruction and
editability. In this paper, we tackle an even more difficult task, inverting
erased images into GAN's latent space for realistic inpaintings and editings.
Furthermore, by augmenting inverted latent codes with different latent samples,
we achieve diverse inpaintings. Specifically, we propose to learn an encoder
and mixing network to combine encoded features from erased images with
StyleGAN's mapped features from random samples. To encourage the mixing network
to utilize both inputs, we train the networks with generated data via a novel
set-up. We also utilize higher-rate features to prevent color inconsistencies
between the inpainted and unerased parts. We run extensive experiments and
compare our method with state-of-the-art inversion and inpainting methods.
Qualitative metrics and visual comparisons show significant improvements.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15034" title="Abstract">arXiv:2307.15034</a> [<a href="/pdf/2307.15034" title="Download PDF">pdf</a>, <a href="/format/2307.15034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speeding up Fourier Neural Operators via Mixed Precision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=White%2C+C">Colin White</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+R">Renbo Tu</a>, 
<a href="/search/cs?searchtype=author&query=Kossaifi%2C+J">Jean Kossaifi</a>, 
<a href="/search/cs?searchtype=author&query=Pekhimenko%2C+G">Gennady Pekhimenko</a>, 
<a href="/search/cs?searchtype=author&query=Azizzadenesheli%2C+K">Kamyar Azizzadenesheli</a>, 
<a href="/search/cs?searchtype=author&query=Anandkumar%2C+A">Anima Anandkumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">The Fourier neural operator (FNO) is a powerful technique for learning
surrogate maps for partial differential equation (PDE) solution operators. For
many real-world applications, which often require high-resolution data points,
training time and memory usage are significant bottlenecks. While there are
mixed-precision training techniques for standard neural networks, those work
for real-valued datatypes on finite dimensions and therefore cannot be directly
applied to FNO, which crucially operates in the (complex-valued) Fourier domain
and in function spaces. On the other hand, since the Fourier transform is
already an approximation (due to discretization error), we do not need to
perform the operation at full precision. In this work, we (i) profile memory
and runtime for FNO with full and mixed-precision training, (ii) conduct a
study on the numerical stability of mixed-precision training of FNO, and (iii)
devise a training routine which substantially decreases training time and
memory usage (up to 34%), with little or no reduction in accuracy, on the
Navier-Stokes and Darcy flow equations. Combined with the recently proposed
tensorized FNO (Kossaifi et al., 2023), the resulting model has far better
performance while also being significantly faster than the original FNO.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15036" title="Abstract">arXiv:2307.15036</a> [<a href="/pdf/2307.15036" title="Download PDF">pdf</a>, <a href="/ps/2307.15036" title="Download PostScript">ps</a>, <a href="/format/2307.15036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3-Coloring $C_4$ or $C_3$-free Diameter Two Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klimo%C5%A1ov%C3%A1%2C+T">Tereza Klimo&#x161;ov&#xe1;</a>, 
<a href="/search/cs?searchtype=author&query=Sahlot%2C+V">Vibha Sahlot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages. Revised version accepted to 18th Algorithms and Data Structures Symposium (WADS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">The question of whether 3-Coloring can be solved in polynomial-time for the
diameter two graphs is a well-known open problem in the area of algorithmic
graph theory. We study the problem restricted to graph classes that avoid
cycles of given lengths as induced subgraphs. Martin et. al. [CIAC 2021] showed
that the problem is polynomial-time solvable for $C_5$-free or $C_6$-free
graphs, and, $(C_4,C_s)$-free graphs where $s \in \{3,7,8,9\}$. We extend their
result proving that it is polynomial-time solvable for $(C_4,C_s)$-free graphs,
for any constant $s$, and for $(C_3,C_7)$-free graphs. Our results also hold
for the more general problem List 3-Colouring.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15039" title="Abstract">arXiv:2307.15039</a> [<a href="/pdf/2307.15039" title="Download PDF">pdf</a>, <a href="/format/2307.15039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autocalibrating Gaze Tracking: A Demonstration through Gaze Typing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saran%2C+A">Akanksha Saran</a>, 
<a href="/search/cs?searchtype=author&query=Alber%2C+J">Jacob Alber</a>, 
<a href="/search/cs?searchtype=author&query=Bragg%2C+D">Danielle Bragg</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cyril Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Langford%2C+J">John Langford</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Miscalibration of gaze tracking devices and the resulting need for repeat
calibration are a significant barrier to use. As devices miscalibrate, people
tend to auto-correct by gazing at neighboring targets, which makes it difficult
to detect miscalibration from eye signals. To address this problem, we provide
a novel and simple insight for autocalibrating eye trackers during gaze typing:
the eyes are used as both input (i.e. typing) and output (i.e. reading)
signals, but auto-correction by users only occurs when eye gaze is functioning
as input. Thus, output eye gaze signals during reading can help systems detect
the miscalibration offset and enable autocalibration. To demonstrate the
potential for this type of approach, we designed and built an auto-calibration
system for gaze typing and ran a user study with 15 able-bodied participants.
Results from our user study suggest that such an implicit approach to
autocalibration can significantly improve typing speed and overall user
experience for gaze typing interfaces. Insights from our work are applicable to
a broad set of gaze tracking technologies and may help create more seamless
user experiences in a variety of domains.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15040" title="Abstract">arXiv:2307.15040</a> [<a href="/pdf/2307.15040" title="Download PDF">pdf</a>, <a href="/format/2307.15040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Sparse Quantized Hopfield Network for Online-Continual Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alonso%2C+N">Nick Alonso</a>, 
<a href="/search/cs?searchtype=author&query=Krichmar%2C+J">Jeff Krichmar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">An important difference between brains and deep neural networks is the way
they learn. Nervous systems learn online where a stream of noisy data points
are presented in a non-independent, identically distributed (non-i.i.d.) way.
Further, synaptic plasticity in the brain depends only on information local to
synapses. Deep networks, on the other hand, typically use non-local learning
algorithms and are trained in an offline, non-noisy, i.i.d. setting.
Understanding how neural networks learn under the same constraints as the brain
is an open problem for neuroscience and neuromorphic computing. A standard
approach to this problem has yet to be established. In this paper, we propose
that discrete graphical models that learn via an online maximum a posteriori
learning algorithm could provide such an approach. We implement this kind of
model in a novel neural network called the Sparse Quantized Hopfield Network
(SQHN). We show that SQHNs outperform state-of-the-art neural networks on
associative memory tasks, outperform these models in online, non-i.i.d.
settings, learn efficiently with noisy inputs, and are better than baselines on
a novel episodic memory task.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15042" title="Abstract">arXiv:2307.15042</a> [<a href="/pdf/2307.15042" title="Download PDF">pdf</a>, <a href="/format/2307.15042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TEDi: Temporally-Entangled Diffusion for Long-Term Motion Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zihan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Richard Liu</a>, 
<a href="/search/cs?searchtype=author&query=Aberman%2C+K">Kfir Aberman</a>, 
<a href="/search/cs?searchtype=author&query=Hanocka%2C+R">Rana Hanocka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://threedle.github.io/TEDi/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">The gradual nature of a diffusion process that synthesizes samples in small
increments constitutes a key ingredient of Denoising Diffusion Probabilistic
Models (DDPM), which have presented unprecedented quality in image synthesis
and been recently explored in the motion domain. In this work, we propose to
adapt the gradual diffusion concept (operating along a diffusion time-axis)
into the temporal-axis of the motion sequence. Our key idea is to extend the
DDPM framework to support temporally varying denoising, thereby entangling the
two axes. Using our special formulation, we iteratively denoise a motion buffer
that contains a set of increasingly-noised poses, which auto-regressively
produces an arbitrarily long stream of frames. With a stationary diffusion
time-axis, in each diffusion step we increment only the temporal-axis of the
motion such that the framework produces a new, clean frame which is removed
from the beginning of the buffer, followed by a newly drawn noise vector that
is appended to it. This new mechanism paves the way towards a new framework for
long-term motion synthesis with applications to character animation and other
domains.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15043" title="Abstract">arXiv:2307.15043</a> [<a href="/pdf/2307.15043" title="Download PDF">pdf</a>, <a href="/format/2307.15043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal and Transferable Adversarial Attacks on Aligned Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+A">Andy Zou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kolter%2C+J+Z">J. Zico Kolter</a>, 
<a href="/search/cs?searchtype=author&query=Fredrikson%2C+M">Matt Fredrikson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Because "out-of-the-box" large language models are capable of generating a
great deal of objectionable content, recent work has focused on aligning these
models in an attempt to prevent undesirable generation. While there has been
some success at circumventing these measures -- so-called "jailbreaks" against
LLMs -- these attacks have required significant human ingenuity and are brittle
in practice. In this paper, we propose a simple and effective attack method
that causes aligned language models to generate objectionable behaviors.
Specifically, our approach finds a suffix that, when attached to a wide range
of queries for an LLM to produce objectionable content, aims to maximize the
probability that the model produces an affirmative response (rather than
refusing to answer). However, instead of relying on manual engineering, our
approach automatically produces these adversarial suffixes by a combination of
greedy and gradient-based search techniques, and also improves over past
automatic prompt generation methods.
<br />Surprisingly, we find that the adversarial prompts generated by our approach
are quite transferable, including to black-box, publicly released LLMs.
Specifically, we train an adversarial attack suffix on multiple prompts (i.e.,
queries asking for many different types of objectionable content), as well as
multiple models (in our case, Vicuna-7B and 13B). When doing so, the resulting
attack suffix is able to induce objectionable content in the public interfaces
to ChatGPT, Bard, and Claude, as well as open source LLMs such as LLaMA-2-Chat,
Pythia, Falcon, and others. In total, this work significantly advances the
state-of-the-art in adversarial attacks against aligned language models,
raising important questions about how such systems can be prevented from
producing objectionable information. Code is available at
github.com/llm-attacks/llm-attacks.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15045" title="Abstract">arXiv:2307.15045</a> [<a href="/pdf/2307.15045" title="Download PDF">pdf</a>, <a href="/format/2307.15045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Transformer-based Approach for Arabic Offline Handwritten Text  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Momeni%2C+S">Saleh Momeni</a>, 
<a href="/search/cs?searchtype=author&query=BabaAli%2C+B">Bagher BabaAli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Handwriting recognition is a challenging and critical problem in the fields
of pattern recognition and machine learning, with applications spanning a wide
range of domains. In this paper, we focus on the specific issue of recognizing
offline Arabic handwritten text. Existing approaches typically utilize a
combination of convolutional neural networks for image feature extraction and
recurrent neural networks for temporal modeling, with connectionist temporal
classification used for text generation. However, these methods suffer from a
lack of parallelization due to the sequential nature of recurrent neural
networks. Furthermore, these models cannot account for linguistic rules,
necessitating the use of an external language model in the post-processing
stage to boost accuracy. To overcome these issues, we introduce two alternative
architectures, namely the Transformer Transducer and the standard
sequence-to-sequence Transformer, and compare their performance in terms of
accuracy and speed. Our approach can model language dependencies and relies
only on the attention mechanism, thereby making it more parallelizable and less
complex. We employ pre-trained Transformers for both image understanding and
language modeling. Our evaluation on the Arabic KHATT dataset demonstrates that
our proposed method outperforms the current state-of-the-art approaches for
recognizing offline Arabic handwritten text.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15049" title="Abstract">arXiv:2307.15049</a> [<a href="/pdf/2307.15049" title="Download PDF">pdf</a>, <a href="/format/2307.15049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regularized Mask Tuning: Uncovering Hidden Knowledge in Pre-trained  Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+K">Kecheng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+R">Ruili Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Kai Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiawei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Deli Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+Z">Zheng-Jun Zha</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yujun Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Prompt tuning and adapter tuning have shown great potential in transferring
pre-trained vision-language models (VLMs) to various downstream tasks. In this
work, we design a new type of tuning method, termed as regularized mask tuning,
which masks the network parameters through a learnable selection. Inspired by
neural pathways, we argue that the knowledge required by a downstream task
already exists in the pre-trained weights but just gets concealed in the
upstream pre-training stage. To bring the useful knowledge back into light, we
first identify a set of parameters that are important to a given downstream
task, then attach a binary mask to each parameter, and finally optimize these
masks on the downstream data with the parameters frozen. When updating the
mask, we introduce a novel gradient dropout strategy to regularize the
parameter selection, in order to prevent the model from forgetting old
knowledge and overfitting the downstream data. Experimental results on 11
datasets demonstrate the consistent superiority of our method over previous
alternatives. It is noteworthy that we manage to deliver 18.73% performance
improvement compared to the zero-shot CLIP via masking an average of only 2.56%
parameters. Furthermore, our method is synergistic with most existing
parameter-efficient tuning methods and can boost the performance on top of
them. Project page can be found here (https://wuw2019.github.io/RMT/).
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15051" title="Abstract">arXiv:2307.15051</a> [<a href="/pdf/2307.15051" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matching Patients to Clinical Trials with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+Q">Qiao Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zifeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Floudas%2C+C+S">Charalampos S. Floudas</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jimeng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhiyong Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Clinical trials are vital in advancing drug development and evidence-based
medicine, but their success is often hindered by challenges in patient
recruitment. In this work, we investigate the potential of large language
models (LLMs) to assist individual patients and referral physicians in
identifying suitable clinical trials from an extensive selection. Specifically,
we introduce TrialGPT, a novel architecture employing LLMs to predict
criterion-level eligibility with detailed explanations, which are then
aggregated for ranking and excluding candidate clinical trials based on
free-text patient notes. We evaluate TrialGPT on three publicly available
cohorts of 184 patients and 18,238 annotated clinical trials. The experimental
results demonstrate several key findings: First, TrialGPT achieves high
criterion-level prediction accuracy with faithful explanations. Second, the
aggregated trial-level TrialGPT scores are highly correlated with expert
eligibility annotations. Third, these scores prove effective in ranking
clinical trials and exclude ineligible candidates. Our error analysis suggests
that current LLMs still make some mistakes due to limited medical knowledge and
domain-specific context understanding. Nonetheless, we believe the explanatory
capabilities of LLMs are highly valuable. Future research is warranted on how
such AI assistants can be integrated into the routine trial matching workflow
in real-world settings to improve its efficiency.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15052" title="Abstract">arXiv:2307.15052</a> [<a href="/pdf/2307.15052" title="Download PDF">pdf</a>, <a href="/format/2307.15052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Depth Estimation for Transparent and Mirror Surfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Costanzino%2C+A">Alex Costanzino</a>, 
<a href="/search/cs?searchtype=author&query=Ramirez%2C+P+Z">Pierluigi Zama Ramirez</a>, 
<a href="/search/cs?searchtype=author&query=Poggi%2C+M">Matteo Poggi</a>, 
<a href="/search/cs?searchtype=author&query=Tosi%2C+F">Fabio Tosi</a>, 
<a href="/search/cs?searchtype=author&query=Mattoccia%2C+S">Stefano Mattoccia</a>, 
<a href="/search/cs?searchtype=author&query=Di+Stefano%2C+L">Luigi Di Stefano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023. Project Page: <a href="https://cvlab-unibo.github.io/Depth4ToM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Inferring the depth of transparent or mirror (ToM) surfaces represents a hard
challenge for either sensors, algorithms, or deep networks. We propose a simple
pipeline for learning to estimate depth properly for such surfaces with neural
networks, without requiring any ground-truth annotation. We unveil how to
obtain reliable pseudo labels by in-painting ToM objects in images and
processing them with a monocular depth estimation model. These labels can be
used to fine-tune existing monocular or stereo networks, to let them learn how
to deal with ToM surfaces. Experimental results on the Booster dataset show the
dramatic improvements enabled by our remarkably simple proposal.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15053" title="Abstract">arXiv:2307.15053</a> [<a href="/pdf/2307.15053" title="Download PDF">pdf</a>, <a href="/format/2307.15053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On (Normalised) Discounted Cumulative Gain as an Offline Evaluation  Metric for Top-$n$ Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeunen%2C+O">Olivier Jeunen</a>, 
<a href="/search/cs?searchtype=author&query=Potapov%2C+I">Ivan Potapov</a>, 
<a href="/search/cs?searchtype=author&query=Ustimenko%2C+A">Aleksei Ustimenko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Approaches to recommendation are typically evaluated in one of two ways: (1)
via a (simulated) online experiment, often seen as the gold standard, or (2)
via some offline evaluation procedure, where the goal is to approximate the
outcome of an online experiment. Several offline evaluation metrics have been
adopted in the literature, inspired by ranking metrics prevalent in the field
of Information Retrieval. (Normalised) Discounted Cumulative Gain (nDCG) is one
such metric that has seen widespread adoption in empirical studies, and higher
(n)DCG values have been used to present new methods as the state-of-the-art in
top-$n$ recommendation for many years.
<br />Our work takes a critical look at this approach, and investigates when we can
expect such metrics to approximate the gold standard outcome of an online
experiment. We formally present the assumptions that are necessary to consider
DCG an unbiased estimator of online reward and provide a derivation for this
metric from first principles, highlighting where we deviate from its
traditional uses in IR. Importantly, we show that normalising the metric
renders it inconsistent, in that even when DCG is unbiased, ranking competing
methods by their normalised DCG can invert their relative order. Through a
correlation analysis between off- and on-line experiments conducted on a
large-scale recommendation platform, we show that our unbiased DCG estimates
strongly correlate with online reward, even when some of the metric's inherent
assumptions are violated. This statement no longer holds for its normalised
variant, suggesting that nDCG's practical utility may be limited.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15054" title="Abstract">arXiv:2307.15054</a> [<a href="/pdf/2307.15054" title="Download PDF">pdf</a>, <a href="/format/2307.15054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Geometric Notion of Causal Probing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guerner%2C+C">Cl&#xe9;ment Guerner</a>, 
<a href="/search/cs?searchtype=author&query=Svete%2C+A">Anej Svete</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Warstadt%2C+A">Alexander Warstadt</a>, 
<a href="/search/cs?searchtype=author&query=Cotterell%2C+R">Ryan Cotterell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models rely on real-valued representations of text to make
their predictions. These representations contain information learned from the
data that the model has trained on, including knowledge of linguistic
properties and forms of demographic bias, e.g., based on gender. A growing body
of work has considered information about concepts such as these using
orthogonal projections onto subspaces of the representation space. We
contribute to this body of work by proposing a formal definition of intrinsic
information in a subspace of a language model's representation space. We
propose a counterfactual approach that avoids the failure mode of spurious
correlations (Kumar et al., 2022) by treating components in the subspace and
its orthogonal complement independently. We show that our counterfactual notion
of information in a subspace is optimizing by an causal concept subspace.
Furthermore, this intervention allows us to attempt concept controlled
generation by manipulating the value of the conceptual component of a
representation. Empirically, we find that R-LACE (Ravfogel et al., 2022)
returns a one-dimensional subspace containing roughly half of total concept
information under our framework. Our causal controlled intervention shows that,
for at least one model, the subspace returned by R-LACE can be used to
manipulate the concept value of the generated word with precision.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15055" title="Abstract">arXiv:2307.15055</a> [<a href="/pdf/2307.15055" title="Download PDF">pdf</a>, <a href="/format/2307.15055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PointOdyssey: A Large-Scale Synthetic Dataset for Long-Term Point  Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Harley%2C+A+W">Adam W. Harley</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+B">Bokui Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wetzstein%2C+G">Gordon Wetzstein</a>, 
<a href="/search/cs?searchtype=author&query=Guibas%2C+L+J">Leonidas J. Guibas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce PointOdyssey, a large-scale synthetic dataset, and data
generation framework, for the training and evaluation of long-term fine-grained
tracking algorithms. Our goal is to advance the state-of-the-art by placing
emphasis on long videos with naturalistic motion. Toward the goal of
naturalism, we animate deformable characters using real-world motion capture
data, we build 3D scenes to match the motion capture environments, and we
render camera viewpoints using trajectories mined via structure-from-motion on
real videos. We create combinatorial diversity by randomizing character
appearance, motion profiles, materials, lighting, 3D assets, and atmospheric
effects. Our dataset currently includes 104 videos, averaging 2,000 frames
long, with orders of magnitude more correspondence annotations than prior work.
We show that existing methods can be trained from scratch in our dataset and
outperform the published variants. Finally, we introduce modifications to the
PIPs point tracking method, greatly widening its temporal receptive field,
which improves its performance on PointOdyssey as well as on two real-world
benchmarks. Our data and code are publicly available at:
https://pointodyssey.com
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15057" title="Abstract">arXiv:2307.15057</a> [<a href="/pdf/2307.15057" title="Download PDF">pdf</a>, <a href="/format/2307.15057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IPv6 Hitlists at Scale: Be Careful What You Wish For
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rye%2C+E">Erik Rye</a>, 
<a href="/search/cs?searchtype=author&query=Levin%2C+D">Dave Levin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ACM SIGCOMM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Today's network measurements rely heavily on Internet-wide scanning,
employing tools like ZMap that are capable of quickly iterating over the entire
IPv4 address space. Unfortunately, IPv6's vast address space poses an
existential threat for Internet-wide scans and traditional network measurement
techniques. To address this reality, efforts are underway to develop
``hitlists'' of known-active IPv6 addresses to reduce the search space for
would-be scanners. As a result, there is an inexorable push for constructing as
large and complete a hitlist as possible.
<br />This paper asks: what are the potential benefits and harms when IPv6 hitlists
grow larger? To answer this question, we obtain the largest IPv6 active-address
list to date: 7.9 billion addresses, 898 times larger than the current
state-of-the-art hitlist. Although our list is not comprehensive, it is a
significant step forward and provides a glimpse into the type of analyses
possible with more complete hitlists.
<br />We compare our dataset to prior IPv6 hitlists and show both benefits and
dangers. The benefits include improved insight into client devices (prior
datasets consist primarily of routers), outage detection, IPv6 roll-out,
previously unknown aliased networks, and address assignment strategies. The
dangers, unfortunately, are severe: we expose widespread instances of addresses
that permit user tracking and device geolocation, and a dearth of firewalls in
home networks. We discuss ethics and security guidelines to ensure a safe path
towards more complete hitlists.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15058" title="Abstract">arXiv:2307.15058</a> [<a href="/pdf/2307.15058" title="Download PDF">pdf</a>, <a href="/format/2307.15058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MARS: An Instance-aware, Modular and Realistic Simulator for Autonomous  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zirui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Liyi Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zhide Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianteng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+H">Hongmin Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+C">Chao Hou</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+H">Haozhe Lou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuantao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Runyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuxin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xiaoyu Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zike Yan</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yongliang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yiyi Liao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hao Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CICAI 2023, project page with code: <a href="https://open-air-sun.github.io/mars/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Nowadays, autonomous cars can drive smoothly in ordinary cases, and it is
widely recognized that realistic sensor simulation will play a critical role in
solving remaining corner cases by simulating them. To this end, we propose an
autonomous driving simulator based upon neural radiance fields (NeRFs).
Compared with existing works, ours has three notable features: (1)
Instance-aware. Our simulator models the foreground instances and background
environments separately with independent networks so that the static (e.g.,
size and appearance) and dynamic (e.g., trajectory) properties of instances can
be controlled separately. (2) Modular. Our simulator allows flexible switching
between different modern NeRF-related backbones, sampling strategies, input
modalities, etc. We expect this modular design to boost academic progress and
industrial deployment of NeRF-based autonomous driving simulation. (3)
Realistic. Our simulator set new state-of-the-art photo-realism results given
the best module selection. Our simulator will be open-sourced while most of our
counterparts are not. Project page: https://open-air-sun.github.io/mars/.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15061" title="Abstract">arXiv:2307.15061</a> [<a href="/pdf/2307.15061" title="Download PDF">pdf</a>, <a href="/format/2307.15061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The RoboDepth Challenge: Methods and Advancements Towards Robust Depth  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lingdong Kong</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yaru Niu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shaoyuan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hanjiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+L+X">Lai Xing Ng</a>, 
<a href="/search/cs?searchtype=author&query=Cottereau%2C+B+R">Benoit R. Cottereau</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Ding Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liangjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hesheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ooi%2C+W+T">Wei Tsang Ooi</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+R">Ruijie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Ziyang Song</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Li Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianzhu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+M">Mohan Jing</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pengwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xiaohua Qi</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Cheng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingfeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Jie Hou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kan%2C+Z">Zhen Kan</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+Q">Qiang Ling</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+L">Liang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Minglei Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Di Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Changpeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuanqi Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Gang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Kuai%2C+J">Jian Kuai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Junjun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiamian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Baojun Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiale Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ao%2C+S">Sun Ao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Runze Chen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haiyong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Fang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jingze Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report; 65 pages, 34 figures, 24 tables; Code at <a href="https://github.com/ldkong1205/RoboDepth">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Accurate depth estimation under out-of-distribution (OoD) scenarios, such as
adverse weather conditions, sensor failure, and noise contamination, is
desirable for safety-critical applications. Existing depth estimation systems,
however, suffer inevitably from real-world corruptions and perturbations and
are struggled to provide reliable depth predictions under such cases. In this
paper, we summarize the winning solutions from the RoboDepth Challenge -- an
academic competition designed to facilitate and advance robust OoD depth
estimation. This challenge was developed based on the newly established KITTI-C
and NYUDepth2-C benchmarks. We hosted two stand-alone tracks, with an emphasis
on robust self-supervised and robust fully-supervised depth estimation,
respectively. Out of more than two hundred participants, nine unique and
top-performing solutions have appeared, with novel designs ranging from the
following aspects: spatial- and frequency-domain augmentations, masked image
modeling, image restoration and super-resolution, adversarial training,
diffusion-based noise suppression, vision-language pre-training, learned model
ensembling, and hierarchical feature enhancement. Extensive experimental
analyses along with insightful observations are drawn to better understand the
rationale behind each design. We hope this challenge could lay a solid
foundation for future research on robust and reliable depth estimation and
beyond. The datasets, competition toolkit, workshop recordings, and source code
from the winning teams are publicly available on the challenge website.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15063" title="Abstract">arXiv:2307.15063</a> [<a href="/pdf/2307.15063" title="Download PDF">pdf</a>, <a href="/format/2307.15063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To Adapt or Not to Adapt? Real-Time Adaptation for Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Colomer%2C+M+B">Marc Botet Colomer</a>, 
<a href="/search/cs?searchtype=author&query=Dovesi%2C+P+L">Pier Luigi Dovesi</a>, 
<a href="/search/cs?searchtype=author&query=Panagiotakopoulos%2C+T">Theodoros Panagiotakopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Carvalho%2C+J+F">Joao Frederico Carvalho</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%A4renstam-Nielsen%2C+L">Linus H&#xe4;renstam-Nielsen</a>, 
<a href="/search/cs?searchtype=author&query=Azizpour%2C+H">Hossein Azizpour</a>, 
<a href="/search/cs?searchtype=author&query=Kjellstr%C3%B6m%2C+H">Hedvig Kjellstr&#xf6;m</a>, 
<a href="/search/cs?searchtype=author&query=Cremers%2C+D">Daniel Cremers</a>, 
<a href="/search/cs?searchtype=author&query=Poggi%2C+M">Matteo Poggi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023. The first two authors contributed equally. Project page: <a href="https://marcbotet.github.io/hamlet-web/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The goal of Online Domain Adaptation for semantic segmentation is to handle
unforeseeable domain changes that occur during deployment, like sudden weather
events. However, the high computational costs associated with brute-force
adaptation make this paradigm unfeasible for real-world applications. In this
paper we propose HAMLET, a Hardware-Aware Modular Least Expensive Training
framework for real-time domain adaptation. Our approach includes a
hardware-aware back-propagation orchestration agent (HAMT) and a dedicated
domain-shift detector that enables active control over when and how the model
is adapted (LT). Thanks to these advancements, our approach is capable of
performing semantic segmentation while simultaneously adapting at more than
29FPS on a single consumer-grade GPU. Our framework's encouraging accuracy and
speed trade-off is demonstrated on OnDA and SHIFT benchmarks through
experimental results.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15064" title="Abstract">arXiv:2307.15064</a> [<a href="/pdf/2307.15064" title="Download PDF">pdf</a>, <a href="/format/2307.15064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Visual Acoustic Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Somayazulu%2C+A">Arjun Somayazulu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Changan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Grauman%2C+K">Kristen Grauman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Computer Vision and Pattern Recognition (cs.CV); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Acoustic matching aims to re-synthesize an audio clip to sound as if it were
recorded in a target acoustic environment. Existing methods assume access to
paired training data, where the audio is observed in both source and target
environments, but this limits the diversity of training data or requires the
use of simulated data or heuristics to create paired samples. We propose a
self-supervised approach to visual acoustic matching where training samples
include only the target scene image and audio -- without acoustically
mismatched source audio for reference. Our approach jointly learns to
disentangle room acoustics and re-synthesize audio into the target environment,
via a conditional GAN framework and a novel metric that quantifies the level of
residual acoustic information in the de-biased audio. Training with either
in-the-wild web data or simulated data, we demonstrate it outperforms the
state-of-the-art on multiple challenging datasets and a wide variety of
real-world audio and environments.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Fri, 28 Jul 23</h3>
<dl>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.01462" title="Abstract">arXiv:2205.01462</a> (cross-list from quant-ph) [<a href="/pdf/2205.01462" title="Download PDF">pdf</a>, <a href="/format/2205.01462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep learning of quantum entanglement from incomplete measurements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Koutn%C3%BD%2C+D">Dominik Koutn&#xfd;</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gin%C3%A9s%2C+L">Laia Gin&#xe9;s</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mocza%C5%82a-Dusanowska%2C+M">Magdalena Mocza&#x142;a-Dusanowska</a>, 
<a href="/search/quant-ph?searchtype=author&query=H%C3%B6fling%2C+S">Sven H&#xf6;fling</a>, 
<a href="/search/quant-ph?searchtype=author&query=Schneider%2C+C">Christian Schneider</a>, 
<a href="/search/quant-ph?searchtype=author&query=Predojevi%C4%87%2C+A">Ana Predojevi&#x107;</a>, 
<a href="/search/quant-ph?searchtype=author&query=Je%C5%BEek%2C+M">Miroslav Je&#x17e;ek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, 1 table
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sci. Adv. 9, eadd7131 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The quantification of the entanglement present in a physical system is of
para\-mount importance for fundamental research and many cutting-edge
applications. Currently, achieving this goal requires either a priori knowledge
on the system or very demanding experimental procedures such as full state
tomography or collective measurements. Here, we demonstrate that by employing
neural networks we can quantify the degree of entanglement without needing to
know the full description of the quantum state. Our method allows for direct
quantification of the quantum correlations using an incomplete set of local
measurements. Despite using undersampled measurements, we achieve a
quantification error of up to an order of magnitude lower than the
state-of-the-art quantum tomography. Furthermore, we achieve this result
employing networks trained using exclusively simulated data. Finally, we derive
a method based on a convolutional network input that can accept data from
various measurement scenarios and perform, to some extent, independently of the
measurement device.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14314" title="Abstract">arXiv:2307.14314</a> (cross-list from quant-ph) [<a href="/pdf/2307.14314" title="Download PDF">pdf</a>, <a href="/format/2307.14314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SQUWALS: A Szegedy QUantum WALks Simulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Ortega%2C+S+A">Sergio A. Ortega</a>, 
<a href="/search/quant-ph?searchtype=author&query=Martin-Delgado%2C+M+A">Miguel A. Martin-Delgado</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> RevTex 4.2, 16 pages, 9 color figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Szegedy's quantum walk is an algorithm for quantizing a general Markov chain.
It has plenty of applications such as many variants of optimizations. In order
to check its properties in an error-free environment, it is important to have a
classical simulator. However, the current simulation algorithms require a great
deal of memory due to the particular formulation of this quantum walk. In this
paper we propose a memory-saving algorithm that scales as $\mathcal{O}(N^2)$
with the size $N$ of the graph. We provide additional procedures for simulating
Szegedy's quantum walk over mixed states and also the Semiclassical Szegedy
walk. With these techniques we have built a classical simulator in Python
called SQUWALS. We show that our simulator scales as $\mathcal{O}(N^2)$ in both
time and memory resources. This package provides some high-level applications
for algorithms based on Szegedy's quantum walk, as for example the quantum
PageRank.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14344" title="Abstract">arXiv:2307.14344</a> (cross-list from math.OC) [<a href="/pdf/2307.14344" title="Download PDF">pdf</a>, <a href="/format/2307.14344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strictly Low Rank Constraint Optimization -- An Asymptotically  $\mathcal{O}(\frac{1}{t^2})$ Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+M">Mengyuan Zhang</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+K">Kai Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Workshop SODS on ICML'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We study a class of non-convex and non-smooth problems with \textit{rank}
regularization to promote sparsity in optimal solution. We propose to apply the
proximal gradient descent method to solve the problem and accelerate the
process with a novel support set projection operation on the singular values of
the intermediate update. We show that our algorithms are able to achieve a
convergence rate of $O(\frac{1}{t^2})$, which is exactly same as Nesterov's
optimal convergence rate for first-order methods on smooth and convex problems.
Strict sparsity can be expected and the support set of singular values during
each update is monotonically shrinking, which to our best knowledge, is novel
in momentum-based algorithms.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14359" title="Abstract">arXiv:2307.14359</a> (cross-list from math.OC) [<a href="/pdf/2307.14359" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new derivative-free optimization method: Gaussian Crunching Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wong%2C+B">Benny Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Optimization methods are essential in solving complex problems across various
domains. In this research paper, we introduce a novel optimization method
called Gaussian Crunching Search (GCS). Inspired by the behaviour of particles
in a Gaussian distribution, GCS aims to efficiently explore the solution space
and converge towards the global optimum. We present a comprehensive analysis of
GCS, including its working mechanism, and potential applications. Through
experimental evaluations and comparisons with existing optimization methods, we
highlight the advantages and strengths of GCS. This research paper serves as a
valuable resource for researchers, practitioners, and students interested in
optimization, providing insights into the development and potential of Gaussian
Crunching Search as a new and promising approach.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14361" title="Abstract">arXiv:2307.14361</a> (cross-list from q-bio.QM) [<a href="/pdf/2307.14361" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hybrid Machine Learning Model for Classifying Gene Mutations in Cancer  using LSTM, BiLSTM, CNN, GRU, and GloVe
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Aburass%2C+S">Sanad Aburass</a>, 
<a href="/search/q-bio?searchtype=author&query=Dorgham%2C+O">Osama Dorgham</a>, 
<a href="/search/q-bio?searchtype=author&query=Shaqsi%2C+J+A">Jamil Al Shaqsi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 7 figures and 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">This study presents an ensemble model combining LSTM, BiLSTM, CNN, GRU, and
GloVe to classify gene mutations using Kaggle's Personalized Medicine:
Redefining Cancer Treatment dataset. The results were compared against
well-known transformers like as BERT, Electra, Roberta, XLNet, Distilbert, and
their LSTM ensembles. Our model outperformed all other models in terms of
accuracy, precision, recall, F1 score, and Mean Squared Error. Surprisingly, it
also needed less training time, resulting in a perfect combination of
performance and efficiency. This study demonstrates the utility of ensemble
models for difficult tasks such as gene mutation classification.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14362" title="Abstract">arXiv:2307.14362</a> (cross-list from astro-ph.IM) [<a href="/pdf/2307.14362" title="Download PDF">pdf</a>, <a href="/format/2307.14362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learnable wavelet neural networks for cosmological inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Pedersen%2C+C">Christian Pedersen</a>, 
<a href="/search/astro-ph?searchtype=author&query=Eickenberg%2C+M">Michael Eickenberg</a>, 
<a href="/search/astro-ph?searchtype=author&query=Ho%2C+S">Shirley Ho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICML 2022 Workshop on Machine Learning for Astrophysics, Baltimore, Maryland, USA, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Cosmology and Nongalactic Astrophysics (astro-ph.CO); Machine Learning (cs.LG)

</div>
<p class="mathjax">Convolutional neural networks (CNNs) have been shown to both extract more
information than the traditional two-point statistics from cosmological fields,
and marginalise over astrophysical effects extremely well. However, CNNs
require large amounts of training data, which is potentially problematic in the
domain of expensive cosmological simulations, and it is difficult to interpret
the network. In this work we apply the learnable scattering transform, a kind
of convolutional neural network that uses trainable wavelets as filters, to the
problem of cosmological inference and marginalisation over astrophysical
effects. We present two models based on the scattering transform, one
constructed for performance, and one constructed for interpretability, and
perform a comparison with a CNN. We find that scattering architectures are able
to outperform a CNN, significantly in the case of small training data samples.
Additionally we present a lightweight scattering network that is highly
interpretable.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14363" title="Abstract">arXiv:2307.14363</a> (cross-list from eess.IV) [<a href="/pdf/2307.14363" title="Download PDF">pdf</a>, <a href="/format/2307.14363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised reconstruction of accelerated cardiac cine MRI using Neural  Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Catal%C3%A1n%2C+T">Tabita Catal&#xe1;n</a>, 
<a href="/search/eess?searchtype=author&query=Courdurier%2C+M">Mat&#xed;as Courdurier</a>, 
<a href="/search/eess?searchtype=author&query=Osses%2C+A">Axel Osses</a>, 
<a href="/search/eess?searchtype=author&query=Botnar%2C+R">Ren&#xe9; Botnar</a>, 
<a href="/search/eess?searchtype=author&query=Costabal%2C+F+S">Francisco Sahli Costabal</a>, 
<a href="/search/eess?searchtype=author&query=Prieto%2C+C">Claudia Prieto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Cardiac cine MRI is the gold standard for cardiac functional assessment, but
the inherently slow acquisition process creates the necessity of reconstruction
approaches for accelerated undersampled acquisitions. Several regularization
approaches that exploit spatial-temporal redundancy have been proposed to
reconstruct undersampled cardiac cine MRI. More recently, methods based on
supervised deep learning have been also proposed to further accelerate
acquisition and reconstruction. However, these techniques rely on usually large
dataset for training, which are not always available. In this work, we propose
an unsupervised approach based on implicit neural field representations for
cardiac cine MRI (so called NF-cMRI). The proposed method was evaluated in
in-vivo undersampled golden-angle radial multi-coil acquisitions for
undersampling factors of 26x and 52x, achieving good image quality, and
comparable spatial and improved temporal depiction than a state-of-the-art
reconstruction technique.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14364" title="Abstract">arXiv:2307.14364</a> (cross-list from math.OC) [<a href="/pdf/2307.14364" title="Download PDF">pdf</a>, <a href="/format/2307.14364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Distributionally Robust Optimization with Non-Convex  Objectives: Algorithm and Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jiao%2C+Y">Yang Jiao</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+K">Kai Yang</a>, 
<a href="/search/math?searchtype=author&query=Song%2C+D">Dongjin Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2210.07588">arXiv:2210.07588</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Distributionally Robust Optimization (DRO), which aims to find an optimal
decision that minimizes the worst case cost over the ambiguity set of
probability distribution, has been widely applied in diverse applications,
e.g., network behavior analysis, risk management, etc. However, existing DRO
techniques face three key challenges: 1) how to deal with the asynchronous
updating in a distributed environment; 2) how to leverage the prior
distribution effectively; 3) how to properly adjust the degree of robustness
according to different scenarios. To this end, we propose an asynchronous
distributed algorithm, named Asynchronous Single-looP alternatIve gRadient
projEction (ASPIRE) algorithm with the itErative Active SEt method (EASE) to
tackle the federated distributionally robust optimization (FDRO) problem.
Furthermore, a new uncertainty set, i.e., constrained D-norm uncertainty set,
is developed to effectively leverage the prior distribution and flexibly
control the degree of robustness. Finally, our theoretical analysis elucidates
that the proposed algorithm is guaranteed to converge and the iteration
complexity is also analyzed. Extensive empirical studies on real-world datasets
demonstrate that the proposed method can not only achieve fast convergence, and
remain robust against data heterogeneity as well as malicious attacks, but also
tradeoff robustness with performance.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14367" title="Abstract">arXiv:2307.14367</a> (cross-list from q-bio.QM) [<a href="/pdf/2307.14367" title="Download PDF">pdf</a>, <a href="/format/2307.14367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prot2Text: Multimodal Protein&#x27;s Function Generation with GNNs and  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Abdine%2C+H">Hadi Abdine</a>, 
<a href="/search/q-bio?searchtype=author&query=Chatzianastasis%2C+M">Michail Chatzianastasis</a>, 
<a href="/search/q-bio?searchtype=author&query=Bouyioukos%2C+C">Costas Bouyioukos</a>, 
<a href="/search/q-bio?searchtype=author&query=Vazirgiannis%2C+M">Michalis Vazirgiannis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">The complex nature of big biological systems pushed some scientists to
classify its understanding under the inconceivable missions. Different leveled
challenges complicated this task, one of is the prediction of a protein's
function. In recent years, significant progress has been made in this field
through the development of various machine learning approaches. However, most
existing methods formulate the task as a multi-classification problem, i.e
assigning predefined labels to proteins. In this work, we propose a novel
approach, \textbf{Prot2Text}, which predicts a protein function's in a free
text style, moving beyond the conventional binary or categorical
classifications. By combining Graph Neural Networks(GNNs) and Large Language
Models(LLMs), in an encoder-decoder framework, our model effectively integrates
diverse data types including proteins' sequences, structures, and textual
annotations. This multimodal approach allows for a holistic representation of
proteins' functions, enabling the generation of detailed and accurate
descriptions. To evaluate our model, we extracted a multimodal protein dataset
from SwissProt, and demonstrate empirically the effectiveness of Prot2Text.
These results highlight the transformative impact of multimodal models,
specifically the fusion of GNNs and LLMs, empowering researchers with powerful
tools for more accurate prediction of proteins' functions. The code, the models
and a demo will be publicly released.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14389" title="Abstract">arXiv:2307.14389</a> (cross-list from eess.AS) [<a href="/pdf/2307.14389" title="Download PDF">pdf</a>, <a href="/format/2307.14389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diff-E: Diffusion-based Learning for Decoding Imagined Speech EEG
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kim%2C+S">Soowon Kim</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+Y">Young-Eun Lee</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+S">Seo-Hyun Lee</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+S">Seong-Whan Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Interspeech 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Decoding EEG signals for imagined speech is a challenging task due to the
high-dimensional nature of the data and low signal-to-noise ratio. In recent
years, denoising diffusion probabilistic models (DDPMs) have emerged as
promising approaches for representation learning in various domains. Our study
proposes a novel method for decoding EEG signals for imagined speech using
DDPMs and a conditional autoencoder named Diff-E. Results indicate that Diff-E
significantly improves the accuracy of decoding EEG signals for imagined speech
compared to traditional machine learning techniques and baseline models. Our
findings suggest that DDPMs can be an effective tool for EEG signal decoding,
with potential implications for the development of brain-computer interfaces
that enable communication through imagined speech.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14398" title="Abstract">arXiv:2307.14398</a> (cross-list from eess.IV) [<a href="/pdf/2307.14398" title="Download PDF">pdf</a>, <a href="/format/2307.14398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Linear Self Augmentation Deep Pipeline for Cancer Treatment outcome  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rundo%2C+F">Francesco Rundo</a>, 
<a href="/search/eess?searchtype=author&query=Spampinato%2C+C">Concetto Spampinato</a>, 
<a href="/search/eess?searchtype=author&query=Rundo%2C+M">Michael Rundo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Immunotherapy emerges as promising approach for treating cancer. Encouraging
findings have validated the efficacy of immunotherapy medications in addressing
tumors, resulting in prolonged survival rates and notable reductions in
toxicity compared to conventional chemotherapy methods. However, the pool of
eligible patients for immunotherapy remains relatively small, indicating a lack
of comprehensive understanding regarding the physiological mechanisms
responsible for favorable treatment response in certain individuals while
others experience limited benefits. To tackle this issue, the authors present
an innovative strategy that harnesses a non-linear cellular architecture in
conjunction with a deep downstream classifier. This approach aims to carefully
select and enhance 2D features extracted from chest-abdomen CT images, thereby
improving the prediction of treatment outcomes. The proposed pipeline has been
meticulously designed to seamlessly integrate with an advanced embedded Point
of Care system. In this context, the authors present a compelling case study
focused on Metastatic Urothelial Carcinoma (mUC), a particularly aggressive
form of cancer. Performance evaluation of the proposed approach underscores its
effectiveness, with an impressive overall accuracy of approximately 93%
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14403" title="Abstract">arXiv:2307.14403</a> (cross-list from eess.IV) [<a href="/pdf/2307.14403" title="Download PDF">pdf</a>, <a href="/format/2307.14403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Deep Learning-based Pansharpening with Jointly-Enhanced  Spectral and Spatial Fidelity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ciotola%2C+M">Matteo Ciotola</a>, 
<a href="/search/eess?searchtype=author&query=Poggi%2C+G">Giovanni Poggi</a>, 
<a href="/search/eess?searchtype=author&query=Scarpa%2C+G">Giuseppe Scarpa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">In latest years, deep learning has gained a leading role in the pansharpening
of multiresolution images. Given the lack of ground truth data, most deep
learning-based methods carry out supervised training in a reduced-resolution
domain. However, models trained on downsized images tend to perform poorly on
high-resolution target images. For this reason, several research groups are now
turning to unsupervised training in the full-resolution domain, through the
definition of appropriate loss functions and training paradigms. In this
context, we have recently proposed a full-resolution training framework which
can be applied to many existing architectures.
<br />Here, we propose a new deep learning-based pansharpening model that fully
exploits the potential of this approach and provides cutting-edge performance.
Besides architectural improvements with respect to previous work, such as the
use of residual attention modules, the proposed model features a novel loss
function that jointly promotes the spectral and spatial quality of the
pansharpened data. In addition, thanks to a new fine-tuning strategy, it
improves inference-time adaptation to target images. Experiments on a large
variety of test images, performed in challenging scenarios, demonstrate that
the proposed method compares favorably with the state of the art both in terms
of numerical results and visual output. Code is available online at
https://github.com/matciotola/Lambda-PNN.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14409" title="Abstract">arXiv:2307.14409</a> (cross-list from q-fin.ST) [<a href="/pdf/2307.14409" title="Download PDF">pdf</a>, <a href="/format/2307.14409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Bitcoin Mesoscale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Vallarano%2C+N">Nicol&#xf2; Vallarano</a>, 
<a href="/search/q-fin?searchtype=author&query=Squartini%2C+T">Tiziano Squartini</a>, 
<a href="/search/q-fin?searchtype=author&query=Tessone%2C+C+J">Claudio J. Tessone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Cryptography and Security (cs.CR); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">The open availability of the entire history of the Bitcoin transactions opens
up the possibility to study this system at an unprecedented level of detail.
This contribution is devoted to the analysis of the mesoscale structural
properties of the Bitcoin User Network (BUN), across its entire history (i.e.
from 2009 to 2017). What emerges from our analysis is that the BUN is
characterized by a core-periphery structure a deeper analysis of which reveals
a certain degree of bow-tieness (i.e. the presence of a Strongly-Connected
Component, an IN- and an OUT-component together with some tendrils attached to
the IN-component). Interestingly, the evolution of the BUN structural
organization experiences fluctuations that seem to be correlated with the
presence of bubbles, i.e. periods of price surge and decline observed
throughout the entire Bitcoin history: our results, thus, further confirm the
interplay between structural quantities and price movements observed in
previous analyses.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14424" title="Abstract">arXiv:2307.14424</a> (cross-list from quant-ph) [<a href="/pdf/2307.14424" title="Download PDF">pdf</a>, <a href="/format/2307.14424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verifiable measurement-based quantum random sampling with trapped ions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Ringbauer%2C+M">Martin Ringbauer</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hinsche%2C+M">Marcel Hinsche</a>, 
<a href="/search/quant-ph?searchtype=author&query=Feldker%2C+T">Thomas Feldker</a>, 
<a href="/search/quant-ph?searchtype=author&query=Faehrmann%2C+P+K">Paul K. Faehrmann</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bermejo-Vega%2C+J">Juani Bermejo-Vega</a>, 
<a href="/search/quant-ph?searchtype=author&query=Edmunds%2C+C">Claire Edmunds</a>, 
<a href="/search/quant-ph?searchtype=author&query=Postler%2C+L">Lukas Postler</a>, 
<a href="/search/quant-ph?searchtype=author&query=Stricker%2C+R">Roman Stricker</a>, 
<a href="/search/quant-ph?searchtype=author&query=Marciniak%2C+C+D">Christian D. Marciniak</a>, 
<a href="/search/quant-ph?searchtype=author&query=Meth%2C+M">Michael Meth</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pogorelov%2C+I">Ivan Pogorelov</a>, 
<a href="/search/quant-ph?searchtype=author&query=Blatt%2C+R">Rainer Blatt</a>, 
<a href="/search/quant-ph?searchtype=author&query=Schindler%2C+P">Philipp Schindler</a>, 
<a href="/search/quant-ph?searchtype=author&query=Eisert%2C+J">Jens Eisert</a>, 
<a href="/search/quant-ph?searchtype=author&query=Monz%2C+T">Thomas Monz</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hangleiter%2C+D">Dominik Hangleiter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10+15 pages. Comments welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">Quantum computers are now on the brink of outperforming their classical
counterparts. One way to demonstrate the advantage of quantum computation is
through quantum random sampling performed on quantum computing devices.
However, existing tools for verifying that a quantum device indeed performed
the classically intractable sampling task are either impractical or not
scalable to the quantum advantage regime. The verification problem thus remains
an outstanding challenge. Here, we experimentally demonstrate efficiently
verifiable quantum random sampling in the measurement-based model of quantum
computation on a trapped-ion quantum processor. We create random cluster
states, which are at the heart of measurement-based computing, up to a size of
4 x 4 qubits. Moreover, by exploiting the structure of these states, we are
able to recycle qubits during the computation to sample from entangled cluster
states that are larger than the qubit register. We then efficiently estimate
the fidelity to verify the prepared states--in single instances and on
average--and compare our results to cross-entropy benchmarking. Finally, we
study the effect of experimental noise on the certificates. Our results and
techniques provide a feasible path toward a verified demonstration of a quantum
advantage.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14436" title="Abstract">arXiv:2307.14436</a> (cross-list from eess.IV) [<a href="/pdf/2307.14436" title="Download PDF">pdf</a>, <a href="/format/2307.14436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phenotype-preserving metric design for high-content image reconstruction  by generative inpainting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sharma%2C+V">Vaibhav Sharma</a>, 
<a href="/search/eess?searchtype=author&query=Yakimovich%2C+A">Artur Yakimovich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures, conference proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">In the past decades, automated high-content microscopy demonstrated its
ability to deliver large quantities of image-based data powering the
versatility of phenotypic drug screening and systems biology applications.
However, as the sizes of image-based datasets grew, it became infeasible for
humans to control, avoid and overcome the presence of imaging and sample
preparation artefacts in the images. While novel techniques like machine
learning and deep learning may address these shortcomings through generative
image inpainting, when applied to sensitive research data this may come at the
cost of undesired image manipulation. Undesired manipulation may be caused by
phenomena such as neural hallucinations, to which some artificial neural
networks are prone. To address this, here we evaluate the state-of-the-art
inpainting methods for image restoration in a high-content fluorescence
microscopy dataset of cultured cells with labelled nuclei. We show that
architectures like DeepFill V2 and Edge Connect can faithfully restore
microscopy images upon fine-tuning with relatively little data. Our results
demonstrate that the area of the region to be restored is of higher importance
than shape. Furthermore, to control for the quality of restoration, we propose
a novel phenotype-preserving metric design strategy. In this strategy, the size
and count of the restored biological phenotypes like cell nuclei are quantified
to penalise undesirable manipulation. We argue that the design principles of
our approach may also generalise to other applications.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14441" title="Abstract">arXiv:2307.14441</a> (cross-list from quant-ph) [<a href="/pdf/2307.14441" title="Download PDF">pdf</a>, <a href="/ps/2307.14441" title="Download PostScript">ps</a>, <a href="/format/2307.14441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dense outputs from quantum simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+J">Jin-Peng Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lin%2C+L">Lin Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">The quantum dense output problem is the process of evaluating
time-accumulated observables from time-dependent quantum dynamics using quantum
computers. This problem arises frequently in applications such as quantum
control and spectroscopic computation. We present a range of algorithms
designed to operate on both early and fully fault-tolerant quantum platforms.
These methodologies draw upon techniques like amplitude estimation, Hamiltonian
simulation, quantum linear Ordinary Differential Equation (ODE) solvers, and
quantum Carleman linearization. We provide a comprehensive complexity analysis
with respect to the evolution time $T$ and error tolerance $\epsilon$. Our
results demonstrate that the linearization approach can nearly achieve optimal
complexity $\mathcal{O}(T/\epsilon)$ for a certain type of low-rank dense
outputs. Moreover, we provide a linearization of the dense output problem that
yields an exact and finite-dimensional closure which encompasses the original
states. This formulation is related to the Koopman Invariant Subspace theory
and may be of independent interest in nonlinear control and scientific machine
learning.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14459" title="Abstract">arXiv:2307.14459</a> (cross-list from quant-ph) [<a href="/pdf/2307.14459" title="Download PDF">pdf</a>, <a href="/format/2307.14459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training Quantum Boltzmann Machines with Coresets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Viszlai%2C+J">Joshua Viszlai</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tomesh%2C+T">Teague Tomesh</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gokhale%2C+P">Pranav Gokhale</a>, 
<a href="/search/quant-ph?searchtype=author&query=Anschuetz%2C+E">Eric Anschuetz</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chong%2C+F+T">Frederic T. Chong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appeared in IEEE International Conference on Quantum Computing and Engineering (QCE22) in September 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent work has proposed and explored using coreset techniques for quantum
algorithms that operate on classical data sets to accelerate the applicability
of these algorithms on near-term quantum devices. We apply these ideas to
Quantum Boltzmann Machines (QBM) where gradient-based steps which require Gibbs
state sampling are the main computational bottleneck during training. By using
a coreset in place of the full data set, we try to minimize the number of steps
needed and accelerate the overall training time. In a regime where
computational time on quantum computers is a precious resource, we propose this
might lead to substantial practical savings. We evaluate this approach on 6x6
binary images from an augmented bars and stripes data set using a QBM with 36
visible units and 8 hidden units. Using an Inception score inspired metric, we
compare QBM training times with and without using coresets.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14461" title="Abstract">arXiv:2307.14461</a> (cross-list from math.CT) [<a href="/pdf/2307.14461" title="Download PDF">pdf</a>, <a href="/ps/2307.14461" title="Download PostScript">ps</a>, <a href="/format/2307.14461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Obstructions to Compositionality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Puca%2C+C">Caterina Puca</a>, 
<a href="/search/math?searchtype=author&query=Hadzihasanovic%2C+A">Amar Hadzihasanovic</a>, 
<a href="/search/math?searchtype=author&query=Genovese%2C+F">Fabrizio Genovese</a>, 
<a href="/search/math?searchtype=author&query=Coecke%2C+B">Bob Coecke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages + appendix. Accepted for ACT 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Compositionality is at the heart of computer science and several other areas
of applied category theory such as computational linguistics, categorical
quantum mechanics, interpretable AI, dynamical systems, compositional game
theory, and Petri nets. However, the meaning of the term seems to vary across
the many different applications. This work contributes to understanding, and in
particular qualifying, different kinds of compositionality. Formally, we
introduce invariants of categories that we call zeroth and first homotopy
posets, generalising in a precise sense the $\pi_0$ and $\pi_1$ of a groupoid.
These posets can be used to obtain a qualitative description of how far an
object is from being terminal and a morphism is from being iso. In the context
of applied category theory, this formal machinery gives us a way to
qualitatively describe the "failures of compositionality", seen as failures of
certain (op)lax functors to be strong, by classifying obstructions to the
(op)laxators being isomorphisms. Failure of compositionality, for example for
the interpretation of a categorical syntax in a semantic universe, can both be
a bad thing and a good thing, which we illustrate by respective examples in
graph theory and quantum theory.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14482" title="Abstract">arXiv:2307.14482</a> (cross-list from eess.IV) [<a href="/pdf/2307.14482" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Role of Image Acquisition and Patient Phenotype Variations in Automatic  Segmentation Model Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kline%2C+T+L">Timothy L. Kline</a>, 
<a href="/search/eess?searchtype=author&query=Ramanathan%2C+S">Sumana Ramanathan</a>, 
<a href="/search/eess?searchtype=author&query=Gottlich%2C+H+C">Harrison C. Gottlich</a>, 
<a href="/search/eess?searchtype=author&query=Korfiatis%2C+P">Panagiotis Korfiatis</a>, 
<a href="/search/eess?searchtype=author&query=Gregory%2C+A+V">Adriana V. Gregory</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Purpose: This study evaluated the out-of-domain performance and
generalization capabilities of automated medical image segmentation models,
with a particular focus on adaptation to new image acquisitions and disease
type.
<br />Materials: Datasets from both non-contrast and contrast-enhanced abdominal CT
scans of healthy patients and those with polycystic kidney disease (PKD) were
used. A total of 400 images (100 non-contrast controls, 100 contrast controls,
100 non-contrast PKD, 100 contrast PKD) were utilized for training/validation
of models to segment kidneys, livers, and spleens, and the final models were
then tested on 100 non-contrast CT images of patients affected by PKD.
Performance was evaluated using Dice, Jaccard, TPR, and Precision.
<br />Results: Models trained on a diverse range of data showed no worse
performance than models trained exclusively on in-domain data when tested on
in-domain data. For instance, the Dice similarity of the model trained on 25%
from each dataset was found to be non-inferior to the model trained purely on
in-domain data.
<br />Conclusions: The results indicate that broader training examples
significantly enhances model generalization and out-of-domain performance,
thereby improving automated segmentation tools' applicability in clinical
settings. The study's findings provide a roadmap for future research to adopt a
data-centric approach in medical image AI model development.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14502" title="Abstract">arXiv:2307.14502</a> (cross-list from eess.AS) [<a href="/pdf/2307.14502" title="Download PDF">pdf</a>, <a href="/ps/2307.14502" title="Download PostScript">ps</a>, <a href="/format/2307.14502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Effect of Spoken Language on Speech Enhancement using  Self-Supervised Speech Representation Loss Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Close%2C+G">George Close</a>, 
<a href="/search/eess?searchtype=author&query=Hain%2C+T">Thomas Hain</a>, 
<a href="/search/eess?searchtype=author&query=Goetze%2C+S">Stefan Goetze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WASPAA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">Recent work in the field of speech enhancement (SE) has involved the use of
self-supervised speech representations (SSSRs) as feature transformations in
loss functions. However, in prior work, very little attention has been paid to
the relationship between the language of the audio used to train the
self-supervised representation and that used to train the SE system.
Enhancement models trained using a loss function which incorporates a
self-supervised representation that shares exactly the language of the noisy
data used to train the SE system show better performance than those which do
not match exactly. This may lead to enhancement systems which are language
specific and as such do not generalise well to unseen languages, unlike models
trained using traditional spectrogram or time domain loss functions. In this
work, SE models are trained and tested on a number of different languages, with
self-supervised representations which themselves are trained using different
language combinations and with differing network structures as loss function
representations. These models are then tested across unseen languages and their
performances are analysed. It is found that the training language of the
self-supervised representation appears to have a minor effect on enhancement
performance, the amount of training data of a particular language, however,
greatly affects performance.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14520" title="Abstract">arXiv:2307.14520</a> (cross-list from eess.IV) [<a href="/pdf/2307.14520" title="Download PDF">pdf</a>, <a href="/format/2307.14520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FocalErrorNet: Uncertainty-aware focal modulation network for  inter-modal registration error estimation in ultrasound-guided neurosurgery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Salari%2C+S">Soorena Salari</a>, 
<a href="/search/eess?searchtype=author&query=Rasoulian%2C+A">Amirhossein Rasoulian</a>, 
<a href="/search/eess?searchtype=author&query=Rivaz%2C+H">Hassan Rivaz</a>, 
<a href="/search/eess?searchtype=author&query=Xiao%2C+Y">Yiming Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In brain tumor resection, accurate removal of cancerous tissues while
preserving eloquent regions is crucial to the safety and outcomes of the
treatment. However, intra-operative tissue deformation (called brain shift) can
move the surgical target and render the pre-surgical plan invalid.
Intra-operative ultrasound (iUS) has been adopted to provide real-time images
to track brain shift, and inter-modal (i.e., MRI-iUS) registration is often
required to update the pre-surgical plan. Quality control for the registration
results during surgery is important to avoid adverse outcomes, but manual
verification faces great challenges due to difficult 3D visualization and the
low contrast of iUS. Automatic algorithms are urgently needed to address this
issue, but the problem was rarely attempted. Therefore, we propose a novel deep
learning technique based on 3D focal modulation in conjunction with uncertainty
estimation to accurately assess MRI-iUS registration errors for brain tumor
surgery. Developed and validated with the public RESECT clinical database, the
resulting algorithm can achieve an estimation error of 0.59+-0.57 mm.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14530" title="Abstract">arXiv:2307.14530</a> (cross-list from stat.ML) [<a href="/pdf/2307.14530" title="Download PDF">pdf</a>, <a href="/format/2307.14530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Estimation in Mixed-Membership Stochastic Block Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Noskov%2C+F">Fedor Noskov</a>, 
<a href="/search/stat?searchtype=author&query=Panov%2C+M">Maxim Panov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Community detection is one of the most critical problems in modern network
science. Its applications can be found in various fields, from protein modeling
to social network analysis. Recently, many papers appeared studying the problem
of overlapping community detection, where each node of a network may belong to
several communities. In this work, we consider Mixed-Membership Stochastic
Block Model (MMSB) first proposed by Airoldi et al. (2008). MMSB provides quite
a general setting for modeling overlapping community structure in graphs. The
central question of this paper is to reconstruct relations between communities
given an observed network. We compare different approaches and establish the
minimax lower bound on the estimation error. Then, we propose a new estimator
that matches this lower bound. Theoretical results are proved under fairly
general conditions on the considered model. Finally, we illustrate the theory
in a series of experiments.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14547" title="Abstract">arXiv:2307.14547</a> (cross-list from eess.AS) [<a href="/pdf/2307.14547" title="Download PDF">pdf</a>, <a href="/format/2307.14547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Cross-Database Differences for Learning Unified HRTF  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wen%2C+Y">Yutong Wen</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">You Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Duan%2C+Z">Zhiyao Duan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, accepted by IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Individualized head-related transfer functions (HRTFs) are crucial for
accurate sound positioning in virtual auditory displays. As the acoustic
measurement of HRTFs is resource-intensive, predicting individualized HRTFs
using machine learning models is a promising approach at scale. Training such
models require a unified HRTF representation across multiple databases to
utilize their respectively limited samples. However, in addition to differences
on the spatial sampling locations, recent studies have shown that, even for the
common location, HRTFs across databases manifest consistent differences that
make it trivial to tell which databases they come from. This poses a
significant challenge for learning a unified HRTF representation across
databases. In this work, we first identify the possible causes of these
cross-database differences, attributing them to variations in the measurement
setup. Then, we propose a novel approach to normalize the frequency responses
of HRTFs across databases. We show that HRTFs from different databases cannot
be classified by their database after normalization. We further show that these
normalized HRTFs can be used to learn a more unified HRTF representation across
databases than the prior art. We believe that this normalization approach paves
the road to many data-intensive tasks on HRTF modeling.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14567" title="Abstract">arXiv:2307.14567</a> (cross-list from quant-ph) [<a href="/pdf/2307.14567" title="Download PDF">pdf</a>, <a href="/format/2307.14567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A quantum ticking self-oscillator using delayed feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+Y">Yanan Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Munro%2C+W+J">William J. Munro</a>, 
<a href="/search/quant-ph?searchtype=author&query=Twamley%2C+J">Jason Twamley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Self-sustained oscillators (SSOs) is a commonly used method to generate
classical clock signals and SSOs using delayed feedback have been developed
commercially which possess ultra-low phase noise and drift. Research into the
development of quantum self-oscillation, where one can also have a periodic and
regular output {\em tick}, that can be used to control quantum and classical
devices has received much interest and quantum SSOs so far studied suffer from
phase diffusion which leads to the smearing out of the quantum oscillator over
the entire limit cycle in phase space seriously degrading the system's ability
to perform as a self-oscillation. In this paper, we explore quantum versions of
time-delayed SSOs, which has the potentials to develop a ticking quantum clock.
We first design a linear quantum SSO which exhibits perfect oscillation without
phase diffusion. We then explore a nonlinear delayed quantum SSO but find it
exhibits dephasing similar to previously studied non-delayed systems.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14581" title="Abstract">arXiv:2307.14581</a> (cross-list from q-bio.QM) [<a href="/pdf/2307.14581" title="Download PDF">pdf</a>, <a href="/format/2307.14581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Techniques for Analyzing Flow Cytometry Cell Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Kowarsch%2C+F">Florian Kowarsch</a>, 
<a href="/search/q-bio?searchtype=author&query=Weijler%2C+L">Lisa Weijler</a>, 
<a href="/search/q-bio?searchtype=author&query=Kleber%2C+F">FLorian Kleber</a>, 
<a href="/search/q-bio?searchtype=author&query=W%C3%B6dlinger%2C+M">Matthias W&#xf6;dlinger</a>, 
<a href="/search/q-bio?searchtype=author&query=Reiter%2C+M">Michael Reiter</a>, 
<a href="/search/q-bio?searchtype=author&query=Maurer-Granofszky%2C+M">Margarita Maurer-Granofszky</a>, 
<a href="/search/q-bio?searchtype=author&query=Dworzak%2C+M">Michael Dworzak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Explainability for Deep Learning Models is especially important for clinical
applications, where decisions of automated systems have far-reaching
consequences.
<br />While various post-hoc explainable methods, such as attention visualization
and saliency maps, already exist for common data modalities, including natural
language and images, little work has been done to adapt them to the modality of
Flow CytoMetry (FCM) data.
<br />In this work, we evaluate the usage of a transformer architecture called
ReluFormer that ease attention visualization as well as we propose a gradient-
and an attention-based visualization technique tailored for FCM. We
qualitatively evaluate the visualization techniques for cell classification and
polygon regression on pediatric Acute Lymphoblastic Leukemia (ALL) FCM samples.
The results outline the model's decision process and demonstrate how to utilize
the proposed techniques to inspect the trained model. The gradient-based
visualization not only identifies cells that are most significant for a
particular prediction but also indicates the directions in the FCM feature
space in which changes have the most impact on the prediction. The attention
visualization provides insights on the transformer's decision process when
handling FCM data. We show that different attention heads specialize by
attending to different biologically meaningful sub-populations in the data,
even though the model retrieved solely supervised binary classification signals
during training.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14583" title="Abstract">arXiv:2307.14583</a> (cross-list from quant-ph) [<a href="/pdf/2307.14583" title="Download PDF">pdf</a>, <a href="/ps/2307.14583" title="Download PostScript">ps</a>, <a href="/format/2307.14583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fault-tolerant $H^\infty$ control for optical parametric oscillators  with pumping fluctuations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+Y">Yanan Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dong%2C+D">Daoyi Dong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Petersen%2C+I+R">Ian R. Petersen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yonezaw%2C+H">Hidehiro Yonezaw</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Automatica 140 (2022): 110236
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Optical Parametric Oscillators (OPOs) have wide applications in quantum
optics for generating squeezed states and developing advanced technologies.
When the phase or/and the amplitude of the pumping field for an OPO have
fluctuations due to fault signals, time-varying uncertainties will be
introduced in the dynamic parameters of the system. In this paper, we
investigate how to design a fault-tolerant $H^\infty$ controller for an OPO
with a disturbance input and time-varying uncertainties, which can achieve the
required $H^\infty$ performance of the quantum system. We apply robust
$H^\infty$ control theory to a quantum system, and design a passive controller
and an active controller based on the solutions to two Riccati equations. The
passive controller has a simple structure and is easy to be implemented by
using only passive optical components, while the active quantum controller may
achieve improved performance. The control performance of the proposed two
controllers and one controller that was designed without consideration of
system uncertainties is compared by numerical simulations in a specific OPO,
and the results show that the designed controllers work effectively for
fluctuations in both the phase and amplitude of the pumping field.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14588" title="Abstract">arXiv:2307.14588</a> (cross-list from eess.IV) [<a href="/pdf/2307.14588" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MCPA: Multi-scale Cross Perceptron Attention Network for 2D Medical  Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+L">Liang Xu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+M">Mingxiao Chen</a>, 
<a href="/search/eess?searchtype=author&query=Cheng%2C+Y">Yi Cheng</a>, 
<a href="/search/eess?searchtype=author&query=Shao%2C+P">Pengfei Shao</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+S">Shuwei Shen</a>, 
<a href="/search/eess?searchtype=author&query=Yao%2C+P">Peng Yao</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+R+X">Ronald X.Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The UNet architecture, based on Convolutional Neural Networks (CNN), has
demonstrated its remarkable performance in medical image analysis. However, it
faces challenges in capturing long-range dependencies due to the limited
receptive fields and inherent bias of convolutional operations. Recently,
numerous transformer-based techniques have been incorporated into the UNet
architecture to overcome this limitation by effectively capturing global
feature correlations. However, the integration of the Transformer modules may
result in the loss of local contextual information during the global feature
fusion process. To overcome these challenges, we propose a 2D medical image
segmentation model called Multi-scale Cross Perceptron Attention Network
(MCPA). The MCPA consists of three main components: an encoder, a decoder, and
a Cross Perceptron. The Cross Perceptron first captures the local correlations
using multiple Multi-scale Cross Perceptron modules, facilitating the fusion of
features across scales. The resulting multi-scale feature vectors are then
spatially unfolded, concatenated, and fed through a Global Perceptron module to
model global dependencies. Furthermore, we introduce a Progressive Dual-branch
Structure to address the semantic segmentation of the image involving finer
tissue structures. This structure gradually shifts the segmentation focus of
MCPA network training from large-scale structural features to more
sophisticated pixel-level features. We evaluate our proposed MCPA model on
several publicly available medical image datasets from different tasks and
devices, including the open large-scale dataset of CT (Synapse), MRI (ACDC),
fundus camera (DRIVE, CHASE_DB1, HRF), and OCTA (ROSE). The experimental
results show that our MCPA model achieves state-of-the-art performance. The
code is available at
https://github.com/simonustc/MCPA-for-2D-Medical-Image-Segmentation.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14599" title="Abstract">arXiv:2307.14599</a> (cross-list from quant-ph) [<a href="/pdf/2307.14599" title="Download PDF">pdf</a>, <a href="/ps/2307.14599" title="Download PostScript">ps</a>, <a href="/format/2307.14599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-step feedback preparation of entanglement for qubit systems with  time delay
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+Y">Yanan Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dong%2C+D">Daoyi Dong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kuang%2C+S">Sen Kuang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Petersen%2C+I+R">Ian R. Petersen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yonezawa%2C+H">Hidehiro Yonezawa</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Automatica 125 (2021): 109174
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Quantum entanglement plays a fundamental role in quantum computation and
quantum communication. Feedback control has been widely used in stochastic
quantum systems to generate given entangled states since it has good
robustness, where the time required to compute filter states and conduct filter
based control usually cannot be ignored in many practical applications. This
paper designed two control strategies based on the Lyapunov method to prepare a
class of entangled states for qubit systems with a constant delay time. The
first one is bang bang like control strategy, which has a simple form with
switching between a constant value and zero, the stability of which is proved.
Another control strategy is switching Lyapunov control, where a constant delay
time is introduced in the filter-based feedback control law to compensate for
the computation time. Numerical results on a two qubit system illustrate the
effectiveness of these two proposed control strategies.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14603" title="Abstract">arXiv:2307.14603</a> (cross-list from eess.IV) [<a href="/pdf/2307.14603" title="Download PDF">pdf</a>, <a href="/format/2307.14603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Weakly Supervised Segmentation Network Embedding Cross-scale Attention  Guidance and Noise-sensitive Constraint for Detecting Tertiary Lymphoid  Structures of Pancreatic Tumors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+B">Bingxue Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zou%2C+L">Liwen Zou</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jun Chen</a>, 
<a href="/search/eess?searchtype=author&query=Cao%2C+Y">Yingying Cao</a>, 
<a href="/search/eess?searchtype=author&query=Cai%2C+Z">Zhenghua Cai</a>, 
<a href="/search/eess?searchtype=author&query=Qiu%2C+Y">Yudong Qiu</a>, 
<a href="/search/eess?searchtype=author&query=Mao%2C+L">Liang Mao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zhongqiu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jingya Chen</a>, 
<a href="/search/eess?searchtype=author&query=Gui%2C+L">Luying Gui</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+X">Xiaoping Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The presence of tertiary lymphoid structures (TLSs) on pancreatic
pathological images is an important prognostic indicator of pancreatic tumors.
Therefore, TLSs detection on pancreatic pathological images plays a crucial
role in diagnosis and treatment for patients with pancreatic tumors. However,
fully supervised detection algorithms based on deep learning usually require a
large number of manual annotations, which is time-consuming and
labor-intensive. In this paper, we aim to detect the TLSs in a manner of
few-shot learning by proposing a weakly supervised segmentation network. We
firstly obtain the lymphocyte density maps by combining a pretrained model for
nuclei segmentation and a domain adversarial network for lymphocyte nuclei
recognition. Then, we establish a cross-scale attention guidance mechanism by
jointly learning the coarse-scale features from the original histopathology
images and fine-scale features from our designed lymphocyte density attention.
A noise-sensitive constraint is introduced by an embedding signed distance
function loss in the training procedure to reduce tiny prediction errors.
Experimental results on two collected datasets demonstrate that our proposed
method significantly outperforms the state-of-the-art segmentation-based
algorithms in terms of TLSs detection accuracy. Additionally, we apply our
method to study the congruent relationship between the density of TLSs and
peripancreatic vascular invasion and obtain some clinically statistical
results.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14642" title="Abstract">arXiv:2307.14642</a> (cross-list from stat.ML) [<a href="/pdf/2307.14642" title="Download PDF">pdf</a>, <a href="/ps/2307.14642" title="Download PostScript">ps</a>, <a href="/format/2307.14642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear Convergence of Black-Box Variational Inference: Should We Stick  the Landing?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kim%2C+K">Kyurae Kim</a>, 
<a href="/search/stat?searchtype=author&query=Ma%2C+Y">Yian Ma</a>, 
<a href="/search/stat?searchtype=author&query=Gardner%2C+J+R">Jacob R. Gardner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Computation (stat.CO)

</div>
<p class="mathjax">We prove that black-box variational inference (BBVI) with control variates,
particularly the sticking-the-landing (STL) estimator, converges at a geometric
(traditionally called "linear") rate under perfect variational family
specification. In particular, we prove a quadratic bound on the gradient
variance of the STL estimator, one which encompasses misspecified variational
families. Combined with previous works on the quadratic variance condition,
this directly implies convergence of BBVI with the use of projected stochastic
gradient descent. We also improve existing analysis on the regular closed-form
entropy gradient estimators, which enables comparison against the STL estimator
and provides explicit non-asymptotic complexity guarantees for both.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14653" title="Abstract">arXiv:2307.14653</a> (cross-list from stat.ML) [<a href="/pdf/2307.14653" title="Download PDF">pdf</a>, <a href="/format/2307.14653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speed Limits for Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Seroussi%2C+I">Inbar Seroussi</a>, 
<a href="/search/stat?searchtype=author&query=Alemi%2C+A+A">Alexander A. Alemi</a>, 
<a href="/search/stat?searchtype=author&query=Helias%2C+M">Moritz Helias</a>, 
<a href="/search/stat?searchtype=author&query=Ringel%2C+Z">Zohar Ringel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (cs.LG)

</div>
<p class="mathjax">State-of-the-art neural networks require extreme computational power to
train. It is therefore natural to wonder whether they are optimally trained.
Here we apply a recent advancement in stochastic thermodynamics which allows
bounding the speed at which one can go from the initial weight distribution to
the final distribution of the fully trained network, based on the ratio of
their Wasserstein-2 distance and the entropy production rate of the dynamical
process connecting them. Considering both gradient-flow and Langevin training
dynamics, we provide analytical expressions for these speed limits for linear
and linearizable neural networks e.g. Neural Tangent Kernel (NTK). Remarkably,
given some plausible scaling assumptions on the NTK spectra and spectral
decomposition of the labels -- learning is optimal in a scaling sense. Our
results are consistent with small-scale experiments with Convolutional Neural
Networks (CNNs) and Fully Connected Neural networks (FCNs) on CIFAR-10, showing
a short highly non-optimal regime followed by a longer optimal regime.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14654" title="Abstract">arXiv:2307.14654</a> (cross-list from physics.ao-ph) [<a href="/pdf/2307.14654" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning based Parameter Sensitivity of Regional Climate Models  -- A Case Study of the WRF Model for Heat Extremes over Southeast Australia
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Reddy%2C+P+J">P. Jyoteeshkumar Reddy</a>, 
<a href="/search/physics?searchtype=author&query=Chinta%2C+S">Sandeep Chinta</a>, 
<a href="/search/physics?searchtype=author&query=Matear%2C+R">Richard Matear</a>, 
<a href="/search/physics?searchtype=author&query=Taylor%2C+J">John Taylor</a>, 
<a href="/search/physics?searchtype=author&query=Baki%2C+H">Harish Baki</a>, 
<a href="/search/physics?searchtype=author&query=Thatcher%2C+M">Marcus Thatcher</a>, 
<a href="/search/physics?searchtype=author&query=Kala%2C+J">Jatin Kala</a>, 
<a href="/search/physics?searchtype=author&query=Sharples%2C+J">Jason Sharples</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Heatwaves and bushfires cause substantial impacts on society and ecosystems
across the globe. Accurate information of heat extremes is needed to support
the development of actionable mitigation and adaptation strategies. Regional
climate models are commonly used to better understand the dynamics of these
events. These models have very large input parameter sets, and the parameters
within the physics schemes substantially influence the model's performance.
However, parameter sensitivity analysis (SA) of regional models for heat
extremes is largely unexplored. Here, we focus on the southeast Australian
region, one of the global hotspots of heat extremes. In southeast Australia
Weather Research and Forecasting (WRF) model is the widely used regional model
to simulate extreme weather events across the region. Hence in this study, we
focus on the sensitivity of WRF model parameters to surface meteorological
variables such as temperature, relative humidity, and wind speed during two
extreme heat events over southeast Australia. Due to the presence of multiple
parameters and their complex relationship with output variables, a machine
learning (ML) surrogate-based global sensitivity analysis method is considered
for the SA. The ML surrogate-based Sobol SA is used to identify the sensitivity
of 24 adjustable parameters in seven different physics schemes of the WRF
model. Results show that out of these 24, only three parameters, namely the
scattering tuning parameter, multiplier of saturated soil water content, and
profile shape exponent in the momentum diffusivity coefficient, are important
for the considered meteorological variables. These SA results are consistent
for the two different extreme heat events. Further, we investigated the
physical significance of sensitive parameters. This study's results will help
in further optimising WRF parameters to improve model simulation.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14703" title="Abstract">arXiv:2307.14703</a> (cross-list from quant-ph) [<a href="/pdf/2307.14703" title="Download PDF">pdf</a>, <a href="/format/2307.14703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Quantum Computing Improve Uniform Random Sampling of Large  Configuration Spaces? (Preprint)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Ammermann%2C+J">Joshua Ammermann</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bittner%2C+T">Tim Bittner</a>, 
<a href="/search/quant-ph?searchtype=author&query=Eichhorn%2C+D">Domenik Eichhorn</a>, 
<a href="/search/quant-ph?searchtype=author&query=Schaefer%2C+I">Ina Schaefer</a>, 
<a href="/search/quant-ph?searchtype=author&query=Seidl%2C+C">Christoph Seidl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, 2 tables, accepted at Q-SE 2023 (ICSE workshop) and to be published in ICSE-Companion, this is a preprint version before submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">A software product line models the variability of highly configurable
systems. Complete exploration of all valid configurations (the configuration
space) is infeasible as it grows exponentially with the number of features in
the worst case. In practice, few representative configurations are sampled
instead, which may be used for software testing or hardware verification.
Pseudo-randomness of modern computers introduces statistical bias into these
samples. Quantum computing enables truly random, uniform configuration sampling
based on inherently random quantum physical effects. We propose a method to
encode the entire configuration space in a superposition and then measure one
random sample. We show the method's uniformity over multiple samples and
investigate its scale for different feature models. We discuss the
possibilities and limitations of quantum computing for uniform random sampling
regarding current and future quantum hardware.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14729" title="Abstract">arXiv:2307.14729</a> (cross-list from eess.IV) [<a href="/pdf/2307.14729" title="Download PDF">pdf</a>, <a href="/format/2307.14729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Silent Failures in Medical Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bungert%2C+T+J">Till J. Bungert</a>, 
<a href="/search/eess?searchtype=author&query=Kobelke%2C+L">Levin Kobelke</a>, 
<a href="/search/eess?searchtype=author&query=Jaeger%2C+P+F">Paul F. Jaeger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at MICCAI 23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">To ensure the reliable use of classification systems in medical applications,
it is crucial to prevent silent failures. This can be achieved by either
designing classifiers that are robust enough to avoid failures in the first
place, or by detecting remaining failures using confidence scoring functions
(CSFs). A predominant source of failures in image classification is
distribution shifts between training data and deployment data. To understand
the current state of silent failure prevention in medical imaging, we conduct
the first comprehensive analysis comparing various CSFs in four biomedical
tasks and a diverse range of distribution shifts. Based on the result that none
of the benchmarked CSFs can reliably prevent silent failures, we conclude that
a deeper understanding of the root causes of failures in the data is required.
To facilitate this, we introduce SF-Visuals, an interactive analysis tool that
uses latent space clustering to visualize shifts and failures. On the basis of
various examples, we demonstrate how this tool can help researchers gain
insight into the requirements for safe application of classification systems in
the medical domain. The open-source benchmark and tool are at:
https://github.com/IML-DKFZ/sf-visuals.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14783" title="Abstract">arXiv:2307.14783</a> (cross-list from eess.AS) [<a href="/pdf/2307.14783" title="Download PDF">pdf</a>, <a href="/format/2307.14783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emotion4MIDI: a Lyrics-based Emotion-Labeled Symbolic Music Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sulun%2C+S">Serkan Sulun</a>, 
<a href="/search/eess?searchtype=author&query=Oliveira%2C+P">Pedro Oliveira</a>, 
<a href="/search/eess?searchtype=author&query=Viana%2C+P">Paula Viana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to 22nd EPIA Conference on Artificial Intelligence (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">We present a new large-scale emotion-labeled symbolic music dataset
consisting of 12k MIDI songs. To create this dataset, we first trained emotion
classification models on the GoEmotions dataset, achieving state-of-the-art
results with a model half the size of the baseline. We then applied these
models to lyrics from two large-scale MIDI datasets. Our dataset covers a wide
range of fine-grained emotions, providing a valuable resource to explore the
connection between music and emotions and, especially, to develop models that
can generate music based on specific emotions. Our code for inference, trained
models, and datasets are available online.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14804" title="Abstract">arXiv:2307.14804</a> (cross-list from nlin.AO) [<a href="/pdf/2307.14804" title="Download PDF">pdf</a>, <a href="/format/2307.14804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collective behavior from surprise minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/nlin?searchtype=author&query=Heins%2C+C">Conor Heins</a>, 
<a href="/search/nlin?searchtype=author&query=Millidge%2C+B">Beren Millidge</a>, 
<a href="/search/nlin?searchtype=author&query=da+Costa%2C+L">Lancelot da Costa</a>, 
<a href="/search/nlin?searchtype=author&query=Mann%2C+R">Richard Mann</a>, 
<a href="/search/nlin?searchtype=author&query=Friston%2C+K">Karl Friston</a>, 
<a href="/search/nlin?searchtype=author&query=Couzin%2C+I">Iain Couzin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages (main text), 15 pages (supplemental appendices), 4 figures, 5 movies
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Adaptation and Self-Organizing Systems (nlin.AO)</span>; Multiagent Systems (cs.MA); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Collective motion is ubiquitous in nature; groups of animals, such as fish,
birds, and ungulates appear to move as a whole, exhibiting a rich behavioral
repertoire that ranges from directed movement to milling to disordered
swarming. Typically, such macroscopic patterns arise from decentralized, local
interactions among constituent components (e.g., individual fish in a school).
Preeminent models of this process describe individuals as self-propelled
particles, subject to self-generated motion and `social forces' such as
short-range repulsion and long-range attraction or alignment. However,
organisms are not particles; they are probabilistic decision-makers. Here, we
introduce an approach to modelling collective behavior based on active
inference. This cognitive framework casts behavior as the consequence of a
single imperative: to minimize surprise. We demonstrate that many
empirically-observed collective phenomena, including cohesion, milling and
directed motion, emerge naturally when considering behavior as driven by active
Bayesian inference -- without explicitly building behavioral rules or goals
into individual agents. Furthermore, we show that active inference can recover
and generalize the classical notion of social forces as agents attempt to
suppress prediction errors that conflict with their expectations. By exploring
the parameter space of the belief-based model, we reveal non-trivial
relationships between the individual beliefs and group properties like
polarization and the tendency to visit different collective states. We also
explore how individual beliefs about uncertainty determine collective
decision-making accuracy. Finally, we show how agents can update their
generative model over time, resulting in groups that are collectively more
sensitive to external fluctuations and encode information more robustly.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14839" title="Abstract">arXiv:2307.14839</a> (cross-list from stat.ML) [<a href="/pdf/2307.14839" title="Download PDF">pdf</a>, <a href="/format/2307.14839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kernelised Normalising Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=English%2C+E">Eshant English</a>, 
<a href="/search/stat?searchtype=author&query=Kirchler%2C+M">Matthias Kirchler</a>, 
<a href="/search/stat?searchtype=author&query=Lippert%2C+C">Christoph Lippert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Normalising Flows are generative models characterised by their invertible
architecture. However, the requirement of invertibility imposes constraints on
their expressiveness, necessitating a large number of parameters and innovative
architectural designs to achieve satisfactory outcomes. Whilst flow-based
models predominantly rely on neural-network-based transformations for
expressive designs, alternative transformation methods have received limited
attention. In this work, we present Ferumal flow, a novel kernelised
normalising flow paradigm that integrates kernels into the framework. Our
results demonstrate that a kernelised flow can yield competitive or superior
results compared to neural network-based flows whilst maintaining parameter
efficiency. Kernelised flows excel especially in the low-data regime, enabling
flexible non-parametric density estimation in applications with sparse data
availability.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14848" title="Abstract">arXiv:2307.14848</a> (cross-list from eess.SP) [<a href="/pdf/2307.14848" title="Download PDF">pdf</a>, <a href="/format/2307.14848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Interference for the Coexistence of 6G Networks and Passive  Sensing Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Testolina%2C+P">Paolo Testolina</a>, 
<a href="/search/eess?searchtype=author&query=Polese%2C+M">Michele Polese</a>, 
<a href="/search/eess?searchtype=author&query=Jornet%2C+J+M">Josep M. Jornet</a>, 
<a href="/search/eess?searchtype=author&query=Melodia%2C+T">Tommaso Melodia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Future wireless networks and sensing systems will benefit from access to
large chunks of spectrum above 100 GHz, to achieve terabit-per-second data
rates in 6th Generation (6G) cellular systems and improve accuracy and reach of
Earth exploration and sensing and radio astronomy applications. These are
extremely sensitive to interference from artificial signals, thus the spectrum
above 100~GHz features several bands which are protected from active
transmissions under current spectrum regulations. To provide more agile access
to the spectrum for both services, active and passive users will have to
coexist without harming passive sensing operations. In this paper, we provide
the first, fundamental analysis of Radio Frequency Interference (RFI) that
large-scale terrestrial deployments introduce in different satellite sensing
systems now orbiting the Earth. We develop a geometry-based analysis and extend
it into a data-driven model which accounts for realistic propagation, building
obstruction, ground reflection, for network topology with up to $10^5$ nodes in
more than $85$ km$^2$. We show that the presence of harmful RFI depends on
several factors, including network load, density and topology, satellite
orientation, and building density. The results and methodology provide the
foundation for the development of coexistence solutions and spectrum policy
towards 6G.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14857" title="Abstract">arXiv:2307.14857</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2307.14857" title="Download PDF">pdf</a>, <a href="/format/2307.14857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative convective parametrization of dry atmospheric boundary layer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Heyder%2C+F">Florian Heyder</a>, 
<a href="/search/physics?searchtype=author&query=Mellado%2C+J+P">Juan Pedro Mellado</a>, 
<a href="/search/physics?searchtype=author&query=Schumacher%2C+J">J&#xf6;rg Schumacher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Machine Learning (cs.LG); Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">Turbulence parametrizations will remain a necessary building block in
kilometer-scale Earth system models. In convective boundary layers, where the
mean vertical gradients of conserved properties such as potential temperature
and moisture are approximately zero, the standard ansatz which relates
turbulent fluxes to mean vertical gradients via an eddy diffusivity has to be
extended by mass flux parametrizations for the typically asymmetric up- and
downdrafts in the atmospheric boundary layer. In this work, we present a
parametrization for a dry convective boundary layer based on a generative
adversarial network. The model incorporates the physics of self-similar layer
growth following from the classical mixed layer theory by Deardorff. This
enhances the training data base of the generative machine learning algorithm
and thus significantly improves the predicted statistics of the synthetically
generated turbulence fields at different heights inside the boundary layer. The
algorithm training is based on fully three-dimensional direct numerical
simulation data. Differently to stochastic parametrizations, our model is able
to predict the highly non-Gaussian transient statistics of buoyancy
fluctuations, vertical velocity, and buoyancy flux at different heights thus
also capturing the fastest thermals penetrating into the stabilized top region.
The results of our generative algorithm agree with standard two-equation or
multi-plume stochastic mass-flux schemes. The present parametrization provides
additionally the granule-type horizontal organization of the turbulent
convection which cannot be obtained in any of the other model closures. Our
work paves the way to efficient data-driven convective parametrizations in
other natural flows, such as moist convection, upper ocean mixing, or
convection in stellar interiors.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14864" title="Abstract">arXiv:2307.14864</a> (cross-list from eess.IV) [<a href="/pdf/2307.14864" title="Download PDF">pdf</a>, <a href="/format/2307.14864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A full-resolution training framework for Sentinel-2 image fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ciotola%2C+M">Matteo Ciotola</a>, 
<a href="/search/eess?searchtype=author&query=Ragosta%2C+M">Mario Ragosta</a>, 
<a href="/search/eess?searchtype=author&query=Poggi%2C+G">Giovanni Poggi</a>, 
<a href="/search/eess?searchtype=author&query=Scarpa%2C+G">Giuseppe Scarpa</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2021 IEEE International Geoscience and Remote Sensing Symposium
  IGARSS, Brussels, Belgium, 2021, pp. 1260-1263
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This work presents a new unsupervised framework for training deep learning
models for super-resolution of Sentinel-2 images by fusion of its 10-m and 20-m
bands. The proposed scheme avoids the resolution downgrade process needed to
generate training data in the supervised case. On the other hand, a proper loss
that accounts for cycle-consistency between the network prediction and the
input components to be fused is proposed. Despite its unsupervised nature, in
our preliminary experiments the proposed scheme has shown promising results in
comparison to the supervised approach. Besides, by construction of the proposed
loss, the resulting trained network can be ascribed to the class of
multi-resolution analysis methods.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14898" title="Abstract">arXiv:2307.14898</a> (cross-list from math.OC) [<a href="/pdf/2307.14898" title="Download PDF">pdf</a>, <a href="/ps/2307.14898" title="Download PostScript">ps</a>, <a href="/format/2307.14898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feedback and Open-Loop Nash Equilibria for LQ Infinite-Horizon  Discrete-Time Dynamic Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Monti%2C+A">A. Monti</a>, 
<a href="/search/math?searchtype=author&query=Nortmann%2C+B">B. Nortmann</a>, 
<a href="/search/math?searchtype=author&query=Mylvaganam%2C+T">T. Mylvaganam</a>, 
<a href="/search/math?searchtype=author&query=Sassano%2C+M">M. Sassano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We consider dynamic games defined over an infinite horizon, characterized by
linear, discrete-time dynamics and quadratic cost functionals. Considering such
linear-quadratic (LQ) dynamic games, we focus on their solutions in terms Nash
equilibrium strategies. Both Feedback (F-NE) and Open-Loop (OL-NE) Nash
equilibrium solutions are considered. The contributions of the paper are
threefold. First, our detailed study reveals some interesting structural
insights in relation to F-NE solutions. Second, as a stepping stone towards our
consideration of OL-NE strategies, we consider a specific infinite-horizon
discrete-time (single-player) optimal control problem, wherein the dynamics are
influenced by a known exogenous input and draw connections between its solution
obtained via Dynamic Programming and Pontryagin's Minimum Principle. Finally,
we exploit the latter result to provide a characterization of OL-NE strategies
of the class of infinite-horizon dynamic games. The results and key
observations made throughout the paper are illustrated via a numerical example.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14907" title="Abstract">arXiv:2307.14907</a> (cross-list from eess.IV) [<a href="/pdf/2307.14907" title="Download PDF">pdf</a>, <a href="/format/2307.14907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly Supervised AI for Efficient Analysis of 3D Pathology Samples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Song%2C+A+H">Andrew H. Song</a>, 
<a href="/search/eess?searchtype=author&query=Williams%2C+M">Mane Williams</a>, 
<a href="/search/eess?searchtype=author&query=Williamson%2C+D+F+K">Drew F.K. Williamson</a>, 
<a href="/search/eess?searchtype=author&query=Jaume%2C+G">Guillaume Jaume</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+A">Andrew Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+B">Bowen Chen</a>, 
<a href="/search/eess?searchtype=author&query=Serafin%2C+R">Robert Serafin</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+J+T+C">Jonathan T.C. Liu</a>, 
<a href="/search/eess?searchtype=author&query=Baras%2C+A">Alex Baras</a>, 
<a href="/search/eess?searchtype=author&query=Parwani%2C+A+V">Anil V. Parwani</a>, 
<a href="/search/eess?searchtype=author&query=Mahmood%2C+F">Faisal Mahmood</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Human tissue and its constituent cells form a microenvironment that is
fundamentally three-dimensional (3D). However, the standard-of-care in
pathologic diagnosis involves selecting a few two-dimensional (2D) sections for
microscopic evaluation, risking sampling bias and misdiagnosis. Diverse methods
for capturing 3D tissue morphologies have been developed, but they have yet had
little translation to clinical practice; manual and computational evaluations
of such large 3D data have so far been impractical and/or unable to provide
patient-level clinical insights. Here we present Modality-Agnostic Multiple
instance learning for volumetric Block Analysis (MAMBA), a deep-learning-based
platform for processing 3D tissue images from diverse imaging modalities and
predicting patient outcomes. Archived prostate cancer specimens were imaged
with open-top light-sheet microscopy or microcomputed tomography and the
resulting 3D datasets were used to train risk-stratification networks based on
5-year biochemical recurrence outcomes via MAMBA. With the 3D block-based
approach, MAMBA achieves an area under the receiver operating characteristic
curve (AUC) of 0.86 and 0.74, superior to 2D traditional single-slice-based
prognostication (AUC of 0.79 and 0.57), suggesting superior prognostication
with 3D morphological features. Further analyses reveal that the incorporation
of greater tissue volume improves prognostic performance and mitigates risk
prediction variability from sampling bias, suggesting the value of capturing
larger extents of heterogeneous 3D morphology. With the rapid growth and
adoption of 3D spatial biology and pathology techniques by researchers and
clinicians, MAMBA provides a general and efficient framework for 3D weakly
supervised learning for clinical decision support and can help to reveal novel
3D morphological biomarkers for prognosis and therapeutic response.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14929" title="Abstract">arXiv:2307.14929</a> (cross-list from q-bio.QM) [<a href="/pdf/2307.14929" title="Download PDF">pdf</a>, <a href="/ps/2307.14929" title="Download PostScript">ps</a>, <a href="/format/2307.14929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The channel capacity of the ribosome
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Inafuku%2C+D+A">Daniel A. Inafuku</a>, 
<a href="/search/q-bio?searchtype=author&query=Kirkpatrick%2C+K+L">Kay L. Kirkpatrick</a>, 
<a href="/search/q-bio?searchtype=author&query=Osuagwu%2C+O">Onyema Osuagwu</a>, 
<a href="/search/q-bio?searchtype=author&query=An%2C+Q">Qier An</a>, 
<a href="/search/q-bio?searchtype=author&query=Brewster%2C+D+A">David A. Brewster</a>, 
<a href="/search/q-bio?searchtype=author&query=Nakib%2C+M+Z">Mayisha Zeb Nakib</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Translation is one of the most fundamental processes in the biological cell.
Because of the central role that translation plays across all domains of life,
the enzyme that carries out this process, the ribosome, is required to process
information with high accuracy. This accuracy often approaches values near
unity experimentally. In this paper, we model the ribosome as an information
channel and demonstrate mathematically that this biological machine has
information-processing capabilities that have not been recognized previously.
In particular, we calculate bounds on the ribosome's theoretical Shannon
capacity and numerically approximate this capacity. Finally, by incorporating
estimates on the ribosome's operation time, we show that the ribosome operates
at speeds safely below its capacity, allowing the ribosome to process
information with an arbitrary degree of error. Our results show that the
ribosome achieves a high accuracy in line with purely information-theoretic
means.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14932" title="Abstract">arXiv:2307.14932</a> (cross-list from quant-ph) [<a href="/pdf/2307.14932" title="Download PDF">pdf</a>, <a href="/format/2307.14932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wave Matrix Lindbladization I: Quantum Programs for Simulating Markovian  Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Patel%2C+D">Dhrumil Patel</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wilde%2C+M+M">Mark M. Wilde</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 7 figures, published in the journal special issue dedicated to the memory of G\"oran Lindblad
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Open Systems &amp; Information Dynamics, Vol. 30, No. 02, page 2350010
  (July 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Statistical Mechanics (cond-mat.stat-mech); Data Structures and Algorithms (cs.DS); Mathematical Physics (math-ph)

</div>
<p class="mathjax">Density Matrix Exponentiation is a technique for simulating Hamiltonian
dynamics when the Hamiltonian to be simulated is available as a quantum state.
In this paper, we present a natural analogue to this technique, for simulating
Markovian dynamics governed by the well known Lindblad master equation. For
this purpose, we first propose an input model in which a Lindblad operator $L$
is encoded into a quantum state $\psi$. Then, given access to $n$ copies of the
state $\psi$, the task is to simulate the corresponding Markovian dynamics for
time $t$. We propose a quantum algorithm for this task, called Wave Matrix
Lindbladization, and we also investigate its sample complexity. We show that
our algorithm uses $n = O(t^2/\varepsilon)$ samples of $\psi$ to achieve the
target dynamics, with an approximation error of $O(\varepsilon)$.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14970" title="Abstract">arXiv:2307.14970</a> (cross-list from cond-mat.soft) [<a href="/pdf/2307.14970" title="Download PDF">pdf</a>, <a href="/format/2307.14970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning locally dominant force balances in active particle systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Sturm%2C+D">Dominik Sturm</a>, 
<a href="/search/cond-mat?searchtype=author&query=Maddu%2C+S">Suryanarayana Maddu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Sbalzarini%2C+I+F">Ivo F. Sbalzarini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Soft Condensed Matter (cond-mat.soft)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We use a combination of unsupervised clustering and sparsity-promoting
inference algorithms to learn locally dominant force balances that explain
macroscopic pattern formation in self-organized active particle systems. The
self-organized emergence of macroscopic patterns from microscopic interactions
between self-propelled particles can be widely observed nature. Although
hydrodynamic theories help us better understand the physical basis of this
phenomenon, identifying a sufficient set of local interactions that shape,
regulate, and sustain self-organized structures in active particle systems
remains challenging. We investigate a classic hydrodynamic model of
self-propelled particles that produces a wide variety of patterns, like asters
and moving density bands. Our data-driven analysis shows that propagating bands
are formed by local alignment interactions driven by density gradients, while
steady-state asters are shaped by a mechanism of splay-induced negative
compressibility arising from strong particle interactions. Our method also
reveals analogous physical principles of pattern formation in a system where
the speed of the particle is influenced by local density. This demonstrates the
ability of our method to reveal physical commonalities across models. The
physical mechanisms inferred from the data are in excellent agreement with
analytical scaling arguments and experimental observations.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14985" title="Abstract">arXiv:2307.14985</a> (cross-list from eess.SP) [<a href="/pdf/2307.14985" title="Download PDF">pdf</a>, <a href="/format/2307.14985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Practical Implementation of RIS-Aided Spectrum Sensing: A Deep  Learning-Based Solution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kayraklik%2C+S">Sefa Kayraklik</a>, 
<a href="/search/eess?searchtype=author&query=Yildirim%2C+I">Ibrahim Yildirim</a>, 
<a href="/search/eess?searchtype=author&query=Basar%2C+E">Ertugrul Basar</a>, 
<a href="/search/eess?searchtype=author&query=Hokelek%2C+I">Ibrahim Hokelek</a>, 
<a href="/search/eess?searchtype=author&query=Gorcin%2C+A">Ali Gorcin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">This paper presents reconfigurable intelligent surface (RIS)-aided deep
learning (DL)-based spectrum sensing for next-generation cognitive radios. To
that end, the secondary user (SU) monitors the primary transmitter (PT) signal,
where the RIS plays a pivotal role in increasing the strength of the PT signal
at the SU. The spectrograms of the synthesized dataset, including the 4G LTE
and 5G NR signals, are mapped to images utilized for training the state-of-art
object detection approaches, namely Detectron2 and YOLOv7. By conducting
extensive experiments using a real RIS prototype, we demonstrate that the RIS
can consistently and significantly improve the performance of the DL detectors
to identify the PT signal type along with its time and frequency utilization.
This study also paves the way for optimizing spectrum utilization through
RIS-assisted CR application in next-generation wireless communication systems.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14996" title="Abstract">arXiv:2307.14996</a> (cross-list from quant-ph) [<a href="/pdf/2307.14996" title="Download PDF">pdf</a>, <a href="/format/2307.14996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decomposing and Routing Quantum Circuits Under Constraints for Neutral  Atom Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Nottingham%2C+N">Natalia Nottingham</a>, 
<a href="/search/quant-ph?searchtype=author&query=Perlin%2C+M+A">Michael A. Perlin</a>, 
<a href="/search/quant-ph?searchtype=author&query=White%2C+R">Ryan White</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bernien%2C+H">Hannes Bernien</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chong%2C+F+T">Frederic T. Chong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Baker%2C+J+M">Jonathan M. Baker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Hardware Architecture (cs.AR); Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Quantum computing is in an era defined by rapidly evolving quantum hardware
technologies, combined with persisting high gate error rates, large amounts of
noise, and short coherence times. Overcoming these limitations requires
systems-level approaches that account for the strengths and weaknesses of the
underlying hardware technology. Yet few hardware-aware compiler techniques
exist for neutral atom devices, with no prior work on compiling to the neutral
atom native gate set. In particular, current neutral atom hardware does not
support certain single-qubit rotations via local addressing, which often
requires the circuit to be decomposed into a large number of gates, leading to
long circuit durations and low overall fidelities.
<br />We propose the first compiler designed to overcome the challenges of limited
local addressibility in neutral atom quantum computers. We present algorithms
to decompose circuits into the neutral atom native gate set, with emphasis on
optimizing total pulse area of global gates, which dominate gate execution
costs in several current architectures. Furthermore, we explore atom movement
as an alternative to expensive gate decompositions, gaining immense speedup
with routing, which remains a huge overhead for many quantum circuits. Our
decomposition optimizations result in up to ~3.5x and ~2.9x speedup in time
spent executing global gates and time spent executing single-qubit gates,
respectively. When combined with our atom movement routing algorithms, our
compiler achieves up to ~10x reduction in circuit duration, with over ~2x
improvement in fidelity. We show that our compiler strategies can be adapted
for a variety of hardware-level parameters as neutral atom technology continues
to develop.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15010" title="Abstract">arXiv:2307.15010</a> (cross-list from cond-mat.soft) [<a href="/pdf/2307.15010" title="Download PDF">pdf</a>, <a href="/format/2307.15010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing Synthetic Active Particles for Physical Reservoir Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Wang%2C+X">Xiangzun Wang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Cichos%2C+F">Frank Cichos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Soft Condensed Matter (cond-mat.soft)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (cs.LG)

</div>
<p class="mathjax">The processing of information is an indispensable property of living systems
realized by networks of active processes with enormous complexity. They have
inspired many variants of modern machine learning one of them being reservoir
computing, in which stimulating a network of nodes with fading memory enables
computations and complex predictions. Reservoirs are implemented on computer
hardware, but also on unconventional physical substrates such as mechanical
oscillators, spins, or bacteria often summarized as physical reservoir
computing. Here we demonstrate physical reservoir computing with a synthetic
active microparticle system that self-organizes from an active and passive
component into inherently noisy nonlinear dynamical units. The
self-organization and dynamical response of the unit is the result of a delayed
propulsion of the microswimmer to a passive target. A reservoir of such units
with a self-coupling via the delayed response can perform predictive tasks
despite the strong noise resulting from Brownian motion of the microswimmers.
To achieve efficient noise suppression, we introduce a special architecture
that uses historical reservoir states for output. Our results pave the way for
the study of information processing in synthetic self-organized active particle
systems.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Fri, 28 Jul 23</h3>
<dl>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1604.02833" title="Abstract">arXiv:1604.02833</a> (replaced) [<a href="/pdf/1604.02833" title="Download PDF">pdf</a>, <a href="/format/1604.02833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficiently Enumerating Minimal Triangulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Carmeli%2C+N">Nofar Carmeli</a>, 
<a href="/search/cs?searchtype=author&query=Kenig%2C+B">Batya Kenig</a>, 
<a href="/search/cs?searchtype=author&query=Kimelfeld%2C+B">Benny Kimelfeld</a>, 
<a href="/search/cs?searchtype=author&query=Kr%C3%B6ll%2C+M">Markus Kr&#xf6;ll</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2004.07861" title="Abstract">arXiv:2004.07861</a> (replaced) [<a href="/pdf/2004.07861" title="Download PDF">pdf</a>, <a href="/format/2004.07861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Co-Production of Service: Modeling Services in Contact Centers Using  Hawkes Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daw%2C+A">Andrew Daw</a>, 
<a href="/search/cs?searchtype=author&query=Castellanos%2C+A">Antonio Castellanos</a>, 
<a href="/search/cs?searchtype=author&query=Yom-Tov%2C+G+B">Galit B. Yom-Tov</a>, 
<a href="/search/cs?searchtype=author&query=Pender%2C+J">Jamol Pender</a>, 
<a href="/search/cs?searchtype=author&query=Gruendlinger%2C+L">Leor Gruendlinger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2005.00695" title="Abstract">arXiv:2005.00695</a> (replaced) [<a href="/pdf/2005.00695" title="Download PDF">pdf</a>, <a href="/format/2005.00695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Generalization Effects of Linear Transformations in Data  Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Sen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H+R">Hongyang R. Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Valiant%2C+G">Gregory Valiant</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%A9%2C+C">Christopher R&#xe9;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages. Appeared in ICML 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2005.01586" title="Abstract">arXiv:2005.01586</a> (replaced) [<a href="/pdf/2005.01586" title="Download PDF">pdf</a>, <a href="/format/2005.01586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Do Our Choices Say About Our Preferences?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grining%2C+K">Krzysztof Grining</a>, 
<a href="/search/cs?searchtype=author&query=Klonowski%2C+M">Marek Klonowski</a>, 
<a href="/search/cs?searchtype=author&query=Sulkowska%2C+M">Ma&#x142;gorzata Sulkowska</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2008.10275" title="Abstract">arXiv:2008.10275</a> (replaced) [<a href="/pdf/2008.10275" title="Download PDF">pdf</a>, <a href="/format/2008.10275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Low-rank Method for Parameter-dependent Fluid-structure Interaction  Discretizations With Hyperelasticity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Benner%2C+P">Peter Benner</a>, 
<a href="/search/math?searchtype=author&query=Richter%2C+T">Thomas Richter</a>, 
<a href="/search/math?searchtype=author&query=Weinhandl%2C+R">Roman Weinhandl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2011.08960" title="Abstract">arXiv:2011.08960</a> (replaced) [<a href="/pdf/2011.08960" title="Download PDF">pdf</a>, <a href="/format/2011.08960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Serial Number: Computational Watermarking for DNN Intellectual  Property Protection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruixiang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+M">Mengnan Du</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xia Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2011.09246" title="Abstract">arXiv:2011.09246</a> (replaced) [<a href="/pdf/2011.09246" title="Download PDF">pdf</a>, <a href="/format/2011.09246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimental Study on Reinforcement Learning-based Control of an Acrobot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dostal%2C+L">Leo Dostal</a>, 
<a href="/search/cs?searchtype=author&query=Bespalko%2C+A">Alexej Bespalko</a>, 
<a href="/search/cs?searchtype=author&query=Duecker%2C+D+A">Daniel A. Duecker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.00041" title="Abstract">arXiv:2103.00041</a> (replaced) [<a href="/pdf/2103.00041" title="Download PDF">pdf</a>, <a href="/format/2103.00041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How do exponential size solutions arise in semidefinite programming?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pataki%2C+G">G&#xe1;bor Pataki</a>, 
<a href="/search/math?searchtype=author&query=Touzov%2C+A">Aleksandr Touzov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear, SIAM Journal on Optimization. Many minor points were clarified compared to v1. We also added a lot more detail to the proof of the most technical lemma, Lemma 5
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.10206" title="Abstract">arXiv:2103.10206</a> (replaced) [<a href="/pdf/2103.10206" title="Download PDF">pdf</a>, <a href="/format/2103.10206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DanceFormer: Music Conditioned 3D Dance Generation with Parametric  Motion Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Buyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yongchi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhelun Shi</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+L">Lu Sheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the version accepted by AAAI-22
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.02626" title="Abstract">arXiv:2106.02626</a> (replaced) [<a href="/pdf/2106.02626" title="Download PDF">pdf</a>, <a href="/format/2106.02626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamics of specialization in neural modules under resource constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=B%C3%A9na%2C+G">Gabriel B&#xe9;na</a>, 
<a href="/search/q-bio?searchtype=author&query=Goodman%2C+D+F+M">Dan F. M. Goodman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.03328" title="Abstract">arXiv:2106.03328</a> (replaced) [<a href="/pdf/2106.03328" title="Download PDF">pdf</a>, <a href="/format/2106.03328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Securing Secure Aggregation: Mitigating Multi-Round Privacy Leakage in  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=So%2C+J">Jinhyun So</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+R+E">Ramy E. Ali</a>, 
<a href="/search/cs?searchtype=author&query=Guler%2C+B">Basak Guler</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+J">Jiantao Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Avestimehr%2C+S">Salman Avestimehr</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> AAAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC); Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.05638" title="Abstract">arXiv:2106.05638</a> (replaced) [<a href="/pdf/2106.05638" title="Download PDF">pdf</a>, <a href="/format/2106.05638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Instance-optimal Algorithm for Bichromatic Rectangular Visibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cardinal%2C+J">Jean Cardinal</a>, 
<a href="/search/cs?searchtype=author&query=Dallant%2C+J">Justin Dallant</a>, 
<a href="/search/cs?searchtype=author&query=Iacono%2C+J">John Iacono</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In the previous version, the proofs of Lemma 32 and Theorem 33 were mixed up. A conference version was presented at ESA 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.11264" title="Abstract">arXiv:2106.11264</a> (replaced) [<a href="/pdf/2106.11264" title="Download PDF">pdf</a>, <a href="/format/2106.11264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional federated learning: Applications in distributionally  robust averaging and meta learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Feihu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junyi Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.13723" title="Abstract">arXiv:2106.13723</a> (replaced) [<a href="/pdf/2106.13723" title="Download PDF">pdf</a>, <a href="/format/2106.13723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scale-invariant multilevel Monte Carlo method and application to linear  elasticity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shivanand%2C+S+K">Sharana Kumar Shivanand</a>, 
<a href="/search/math?searchtype=author&query=Rosi%C4%87%2C+B">Bojana Rosi&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.03722" title="Abstract">arXiv:2107.03722</a> (replaced) [<a href="/pdf/2107.03722" title="Download PDF">pdf</a>, <a href="/format/2107.03722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Full-Body Torque-Level Non-linear Model Predictive Control for Aerial  Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mart%C3%AD-Saumell%2C+J">Josep Mart&#xed;-Saumell</a>, 
<a href="/search/cs?searchtype=author&query=Sol%C3%A0%2C+J">Joan Sol&#xe0;</a>, 
<a href="/search/cs?searchtype=author&query=Santamaria-Navarro%2C+A">Angel Santamaria-Navarro</a>, 
<a href="/search/cs?searchtype=author&query=Andrade-Cetto%2C+J">Juan Andrade-Cetto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.07061" title="Abstract">arXiv:2107.07061</a> (replaced) [<a href="/pdf/2107.07061" title="Download PDF">pdf</a>, <a href="/format/2107.07061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Dual Subgradient Methods with Averaging and Applications to  Grid Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bose%2C+S">Subhonmesh Bose</a>, 
<a href="/search/math?searchtype=author&query=Nguyen%2C+H+D">Hoa Dinh Nguyen</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+H">Haitian Liu</a>, 
<a href="/search/math?searchtype=author&query=Guo%2C+Y">Ye Guo</a>, 
<a href="/search/math?searchtype=author&query=Doan%2C+T+T">Thinh T. Doan</a>, 
<a href="/search/math?searchtype=author&query=Beck%2C+C+L">Carolyn L. Beck</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.11277" title="Abstract">arXiv:2107.11277</a> (replaced) [<a href="/pdf/2107.11277" title="Download PDF">pdf</a>, <a href="/format/2107.11277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning with a Reject Option: A survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hendrickx%2C+K">Kilian Hendrickx</a>, 
<a href="/search/cs?searchtype=author&query=Perini%2C+L">Lorenzo Perini</a>, 
<a href="/search/cs?searchtype=author&query=Van+der+Plas%2C+D">Dries Van der Plas</a>, 
<a href="/search/cs?searchtype=author&query=Meert%2C+W">Wannes Meert</a>, 
<a href="/search/cs?searchtype=author&query=Davis%2C+J">Jesse Davis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.04657" title="Abstract">arXiv:2108.04657</a> (replaced) [<a href="/pdf/2108.04657" title="Download PDF">pdf</a>, <a href="/format/2108.04657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Subset Pruning of Transformer Heads
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaoda Li</a>, 
<a href="/search/cs?searchtype=author&query=Cotterell%2C+R">Ryan Cotterell</a>, 
<a href="/search/cs?searchtype=author&query=Sachan%2C+M">Mrinmaya Sachan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> TACL 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.13624" title="Abstract">arXiv:2108.13624</a> (replaced) [<a href="/pdf/2108.13624" title="Download PDF">pdf</a>, <a href="/format/2108.13624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Out-Of-Distribution Generalization: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiashuo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zheyan Shen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yue He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Renzhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Han Yu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+P">Peng Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 51 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.07907" title="Abstract">arXiv:2110.07907</a> (replaced) [<a href="/pdf/2110.07907" title="Download PDF">pdf</a>, <a href="/format/2110.07907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Construction of $C^2$ cubic splines on arbitrary triangulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lyche%2C+T">Tom Lyche</a>, 
<a href="/search/math?searchtype=author&query=Manni%2C+C">Carla Manni</a>, 
<a href="/search/math?searchtype=author&query=Speleers%2C+H">Hendrik Speleers</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Foundations of Computational Mathematics 22(5), 1309-1350 (2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.03132" title="Abstract">arXiv:2111.03132</a> (replaced) [<a href="/pdf/2111.03132" title="Download PDF">pdf</a>, <a href="/format/2111.03132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-rank quantum state preparation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Araujo%2C+I+F">Israel F. Araujo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Blank%2C+C">Carsten Blank</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ara%C3%BAjo%2C+I+C+S">Ismael C. S. Ara&#xfa;jo</a>, 
<a href="/search/quant-ph?searchtype=author&query=da+Silva%2C+A+J">Adenilton J. da Silva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.00394" title="Abstract">arXiv:2112.00394</a> (replaced) [<a href="/pdf/2112.00394" title="Download PDF">pdf</a>, <a href="/ps/2112.00394" title="Download PostScript">ps</a>, <a href="/format/2112.00394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wiretap Secret Key Agreement Via Secure Omniscience
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vippathalla%2C+P+K">Praneeth Kumar Vippathalla</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+C">Chung Chan</a>, 
<a href="/search/cs?searchtype=author&query=Kashyap%2C+N">Navin Kashyap</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qiaoqiao Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 46 pages, 8 figures, submitted to the IEEE Transactions on Information Theory. arXiv admin note: text overlap with <a href="/abs/2102.01771">arXiv:2102.01771</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.13934" title="Abstract">arXiv:2112.13934</a> (replaced) [<a href="/pdf/2112.13934" title="Download PDF">pdf</a>, <a href="/format/2112.13934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RELDEC: Reinforcement Learning-Based Decoding of Moderate Length LDPC  Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Habib%2C+S">Salman Habib</a>, 
<a href="/search/cs?searchtype=author&query=Beemer%2C+A">Allison Beemer</a>, 
<a href="/search/cs?searchtype=author&query=Kliewer%2C+J">Joerg Kliewer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in IEEE Transactions on Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.03622" title="Abstract">arXiv:2201.03622</a> (replaced) [<a href="/pdf/2201.03622" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph-Based Recommendation System Enhanced with Community Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shokrzadeh%2C+Z">Zeinab Shokrzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Feizi-Derakhshi%2C+M">Mohammad-Reza Feizi-Derakhshi</a>, 
<a href="/search/cs?searchtype=author&query=Balafar%2C+M">Mohammad-Ali Balafar</a>, 
<a href="/search/cs?searchtype=author&query=Bagherzadeh-Mohasefi%2C+J">Jamshid Bagherzadeh-Mohasefi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a preprint of an article published in "Scientific Programming"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.06527" title="Abstract">arXiv:2201.06527</a> (replaced) [<a href="/pdf/2201.06527" title="Download PDF">pdf</a>, <a href="/format/2201.06527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COVID-19 is linked to changes in the time-space dimension of human  mobility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Santana%2C+C">Clodomir Santana</a>, 
<a href="/search/physics?searchtype=author&query=Botta%2C+F">Federico Botta</a>, 
<a href="/search/physics?searchtype=author&query=Barbosa%2C+H">Hugo Barbosa</a>, 
<a href="/search/physics?searchtype=author&query=Privitera%2C+F">Filippo Privitera</a>, 
<a href="/search/physics?searchtype=author&query=Menezes%2C+R">Ronaldo Menezes</a>, 
<a href="/search/physics?searchtype=author&query=Di+Clemente%2C+R">Riccardo Di Clemente</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 14 figures. Peer-revied version: Santana, C., Botta, F., Barbosa, H. et al. COVID-19 is linked to changes in the time-space dimension of human mobility. Nat Hum Behav (2023)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Nat.Hum.Behav. (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.06693" title="Abstract">arXiv:2202.06693</a> (replaced) [<a href="/pdf/2202.06693" title="Download PDF">pdf</a>, <a href="/format/2202.06693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Payment Channels in Asynchronous Money Transfer Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naor%2C+O">Oded Naor</a>, 
<a href="/search/cs?searchtype=author&query=Keidar%2C+I">Idit Keidar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.13387" title="Abstract">arXiv:2202.13387</a> (replaced) [<a href="/pdf/2202.13387" title="Download PDF">pdf</a>, <a href="/ps/2202.13387" title="Download PostScript">ps</a>, <a href="/format/2202.13387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New efficient algorithms for computing Gr&#xf6;bner bases of saturation  ideals (F4SAT) and colon ideals (Sparse-FGLM-colon)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berthomieu%2C+J">J&#xe9;r&#xe9;my Berthomieu</a>, 
<a href="/search/cs?searchtype=author&query=Eder%2C+C">Christian Eder</a>, 
<a href="/search/cs?searchtype=author&query=Din%2C+M+S+E">Mohab Safey El Din</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Commutative Algebra (math.AC)

</div>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.06970" title="Abstract">arXiv:2203.06970</a> (replaced) [<a href="/pdf/2203.06970" title="Download PDF">pdf</a>, <a href="/ps/2203.06970" title="Download PostScript">ps</a>, <a href="/format/2203.06970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing a Group Action from the Class Field Theory of Imaginary  Hyperelliptic Function Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leudi%C3%A8re%2C+A">Antoine Leudi&#xe8;re</a>, 
<a href="/search/cs?searchtype=author&query=Spaenlehauer%2C+P">Pierre-Jean Spaenlehauer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is a rewrite of <a href="/abs/2203.06970">arXiv:2203.06970v2</a>. It takes into account the recent attack of Wesolowski on the cryptographic applications (<a href="https://eprint.iacr.org/2022/438">this https URL</a>). We removed cryptographic applications, and the introduction and experimental results have been widely rewritten. Complexity results have been added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Cryptography and Security (cs.CR); Number Theory (math.NT)

</div>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.06039" title="Abstract">arXiv:2205.06039</a> (replaced) [<a href="/pdf/2205.06039" title="Download PDF">pdf</a>, <a href="/format/2205.06039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reactive Synthesis of Smart Contract Control Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Finkbeiner%2C+B">Bernd Finkbeiner</a>, 
<a href="/search/cs?searchtype=author&query=Hofmann%2C+J">Jana Hofmann</a>, 
<a href="/search/cs?searchtype=author&query=Kohn%2C+F">Florian Kohn</a>, 
<a href="/search/cs?searchtype=author&query=Passing%2C+N">Noemi Passing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Cryptography and Security (cs.CR); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.14704" title="Abstract">arXiv:2205.14704</a> (replaced) [<a href="/pdf/2205.14704" title="Download PDF">pdf</a>, <a href="/format/2205.14704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoupling Knowledge from Memorization: Retrieval-augmented Prompt  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ningyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaozhuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+S">Shumin Deng</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Chuanqi Tan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+L">Luo Si</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huajun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2022 (Spotlight)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.08660" title="Abstract">arXiv:2206.08660</a> (replaced) [<a href="/pdf/2206.08660" title="Download PDF">pdf</a>, <a href="/format/2206.08660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Raycasting of Volumetric Depth Images for Remote Visualization  of Large Volumes at High Frame Rates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Aryaman Gupta</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCnther%2C+U">Ulrik G&#xfc;nther</a>, 
<a href="/search/cs?searchtype=author&query=Incardona%2C+P">Pietro Incardona</a>, 
<a href="/search/cs?searchtype=author&query=Reina%2C+G">Guido Reina</a>, 
<a href="/search/cs?searchtype=author&query=Frey%2C+S">Steffen Frey</a>, 
<a href="/search/cs?searchtype=author&query=Gumhold%2C+S">Stefan Gumhold</a>, 
<a href="/search/cs?searchtype=author&query=Sbalzarini%2C+I+F">Ivo F. Sbalzarini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 10 figures. Version as published in PacificVis 2023 proceedings
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE 16th Pacific Visualization Symposium (PacificVis),
  Seoul, Korea, Republic of, 2023, pp. 61-70
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.10291" title="Abstract">arXiv:2206.10291</a> (replaced) [<a href="/pdf/2206.10291" title="Download PDF">pdf</a>, <a href="/format/2206.10291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithmic Gaussianization through Sketching: Converting Data into  Sub-gaussian Random Designs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Derezi%C5%84ski%2C+M">Micha&#x142; Derezi&#x144;ski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.12481" title="Abstract">arXiv:2206.12481</a> (replaced) [<a href="/pdf/2206.12481" title="Download PDF">pdf</a>, <a href="/format/2206.12481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Explainer Robustness via Lipschitzness of Prediction Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+Z">Zulqarnain Khan</a>, 
<a href="/search/cs?searchtype=author&query=Hill%2C+D">Davin Hill</a>, 
<a href="/search/cs?searchtype=author&query=Masoomi%2C+A">Aria Masoomi</a>, 
<a href="/search/cs?searchtype=author&query=Bone%2C+J">Joshua Bone</a>, 
<a href="/search/cs?searchtype=author&query=Dy%2C+J">Jennifer Dy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.12672" title="Abstract">arXiv:2206.12672</a> (replaced) [<a href="/pdf/2206.12672" title="Download PDF">pdf</a>, <a href="/format/2206.12672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trace Recovery from Stochastically Known Logs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bogdanov%2C+E">Eli Bogdanov</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+I">Izack Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Gal%2C+A">Avigdor Gal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted version -- Accepted to the 5th International Conference on Process Mining (ICPM), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.14118" title="Abstract">arXiv:2206.14118</a> (replaced) [<a href="/pdf/2206.14118" title="Download PDF">pdf</a>, <a href="/format/2206.14118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GitHub Actions: The Impact on the Pull Request Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wessel%2C+M">Mairieli Wessel</a>, 
<a href="/search/cs?searchtype=author&query=Vargovich%2C+J">Joseph Vargovich</a>, 
<a href="/search/cs?searchtype=author&query=Gerosa%2C+M+A">Marco A. Gerosa</a>, 
<a href="/search/cs?searchtype=author&query=Treude%2C+C">Christoph Treude</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2103.12224">arXiv:2103.12224</a>, <a href="/abs/2103.13547">arXiv:2103.13547</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Empirical Software Engineering (EMSE 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.00052" title="Abstract">arXiv:2207.00052</a> (replaced) [<a href="/pdf/2207.00052" title="Download PDF">pdf</a>, <a href="/format/2207.00052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Pre-training for Navigation: What Can We Learn from Noise?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ko%2C+C">Ching-Yun Ko</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+P">Pulkit Agrawal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.04045" title="Abstract">arXiv:2207.04045</a> (replaced) [<a href="/pdf/2207.04045" title="Download PDF">pdf</a>, <a href="/format/2207.04045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Runtime Analysis for Permutation-based Evolutionary Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doerr%2C+B">Benjamin Doerr</a>, 
<a href="/search/cs?searchtype=author&query=Ghannane%2C+Y">Yassine Ghannane</a>, 
<a href="/search/cs?searchtype=author&query=Brahim%2C+M+I">Marouane Ibn Brahim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Journal version of our paper at GECCO 2022, to appear in Algorithmica. 51 pages. arXiv admin note: substantial text overlap with <a href="/abs/2204.07637">arXiv:2204.07637</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.11860" title="Abstract">arXiv:2207.11860</a> (replaced) [<a href="/pdf/2207.11860" title="Download PDF">pdf</a>, <a href="/format/2207.11860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Behind Every Domain There is a Shift: Adapting Distortion-aware Vision  Transformers for Panoramic Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kailun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Hao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Rei%C3%9F%2C+S">Simon Rei&#xdf;</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+K">Kunyu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chaoxiang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Haodong Fu</a>, 
<a href="/search/cs?searchtype=author&query=Torr%2C+P+H+S">Philip H. S. Torr</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kaiwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Stiefelhagen%2C+R">Rainer Stiefelhagen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of CVPR 2022 paper <a href="/abs/2203.01452">arXiv:2203.01452</a>. Code is available at <a href="https://github.com/jamycheung/Trans4PASS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.13981" title="Abstract">arXiv:2207.13981</a> (replaced) [<a href="/pdf/2207.13981" title="Download PDF">pdf</a>, <a href="/format/2207.13981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gotham Testbed: a Reproducible IoT Testbed for Security Experiments and  Dataset Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%C3%A1ez-de-C%C3%A1mara%2C+X">Xabier S&#xe1;ez-de-C&#xe1;mara</a>, 
<a href="/search/cs?searchtype=author&query=Flores%2C+J+L">Jose Luis Flores</a>, 
<a href="/search/cs?searchtype=author&query=Arellano%2C+C">Crist&#xf3;bal Arellano</a>, 
<a href="/search/cs?searchtype=author&query=Urbieta%2C+A">Aitor Urbieta</a>, 
<a href="/search/cs?searchtype=author&query=Zurutuza%2C+U">Urko Zurutuza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in IEEE Transactions on Dependable and Secure Computing. Accepted version first online: Feb 22 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.05776" title="Abstract">arXiv:2208.05776</a> (replaced) [<a href="/pdf/2208.05776" title="Download PDF">pdf</a>, <a href="/format/2208.05776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Networks for Scalar Input and Functional Output
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Wu%2C+S">Sidi Wu</a>, 
<a href="/search/stat?searchtype=author&query=Beaulac%2C+C">C&#xe9;dric Beaulac</a>, 
<a href="/search/stat?searchtype=author&query=Cao%2C+J">Jiguo Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.10255" title="Abstract">arXiv:2208.10255</a> (replaced) [<a href="/pdf/2208.10255" title="Download PDF">pdf</a>, <a href="/ps/2208.10255" title="Download PostScript">ps</a>, <a href="/format/2208.10255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the non-efficient PAC learnability of conjunctive queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cate%2C+B+t">Balder ten Cate</a>, 
<a href="/search/cs?searchtype=author&query=Funk%2C+M">Maurice Funk</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+J+C">Jean Christoph Jung</a>, 
<a href="/search/cs?searchtype=author&query=Lutz%2C+C">Carsten Lutz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in Information Processing Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.11838" title="Abstract">arXiv:2208.11838</a> (replaced) [<a href="/pdf/2208.11838" title="Download PDF">pdf</a>, <a href="/format/2208.11838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Task Automata for Reinforcement Learning using Hidden Markov  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abate%2C+A">Alessandro Abate</a> (1), 
<a href="/search/cs?searchtype=author&query=Almulla%2C+Y">Yousif Almulla</a> (1), 
<a href="/search/cs?searchtype=author&query=Fox%2C+J">James Fox</a> (1), 
<a href="/search/cs?searchtype=author&query=Hyland%2C+D">David Hyland</a> (1), 
<a href="/search/cs?searchtype=author&query=Wooldridge%2C+M">Michael Wooldridge</a> (1) ((1) University of Oxford)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures, Accepted to the 26th European Conference on Artificial Intelligence (ECAI 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.12300" title="Abstract">arXiv:2208.12300</a> (replaced) [<a href="/pdf/2208.12300" title="Download PDF">pdf</a>, <a href="/format/2208.12300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Deep Perceptual Measure for Lens and Camera Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hold-Geoffroy%2C+Y">Yannick Hold-Geoffroy</a>, 
<a href="/search/cs?searchtype=author&query=Pich%C3%A9-Meunier%2C+D">Dominique Pich&#xe9;-Meunier</a>, 
<a href="/search/cs?searchtype=author&query=Sunkavalli%2C+K">Kalyan Sunkavalli</a>, 
<a href="/search/cs?searchtype=author&query=Bazin%2C+J">Jean-Charles Bazin</a>, 
<a href="/search/cs?searchtype=author&query=Rameau%2C+F">Fran&#xe7;ois Rameau</a>, 
<a href="/search/cs?searchtype=author&query=Lalonde%2C+J">Jean-Fran&#xe7;ois Lalonde</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 12 figures, project page (including live demo) available at <a href="https://lvsn.github.io/deepcalib.">this https URL</a> arXiv admin note: text overlap with <a href="/abs/1712.01259">arXiv:1712.01259</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.06589" title="Abstract">arXiv:2209.06589</a> (replaced) [<a href="/pdf/2209.06589" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Better Generalization with Flexible Representation of  Multi-Module Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hyungeun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+K">Kijung Yoon</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transactions on Machine Learning Research (TMLR) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.07436" title="Abstract">arXiv:2209.07436</a> (replaced) [<a href="/pdf/2209.07436" title="Download PDF">pdf</a>, <a href="/format/2209.07436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical process monitoring of artificial neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Malinovskaya%2C+A">Anna Malinovskaya</a>, 
<a href="/search/stat?searchtype=author&query=Mozharovskyi%2C+P">Pavlo Mozharovskyi</a>, 
<a href="/search/stat?searchtype=author&query=Otto%2C+P">Philipp Otto</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Technometrics, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Applications (stat.AP); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.10825" title="Abstract">arXiv:2209.10825</a> (replaced) [<a href="/pdf/2209.10825" title="Download PDF">pdf</a>, <a href="/format/2209.10825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonsmooth Nonconvex-Nonconcave Minimax Optimization: Primal-Dual  Balancing and Iteration Complexity Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+J">Jiajin Li</a>, 
<a href="/search/math?searchtype=author&query=Zhu%2C+L">Linglingzhi Zhu</a>, 
<a href="/search/math?searchtype=author&query=So%2C+A+M">Anthony Man-Cho So</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.11405" title="Abstract">arXiv:2209.11405</a> (replaced) [<a href="/pdf/2209.11405" title="Download PDF">pdf</a>, <a href="/ps/2209.11405" title="Download PostScript">ps</a>, <a href="/format/2209.11405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Locally Testable Code with Constant Soundness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cross%2C+A">Andrew Cross</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhiyang He</a>, 
<a href="/search/cs?searchtype=author&query=Natarajan%2C+A">Anand Natarajan</a>, 
<a href="/search/cs?searchtype=author&query=Szegedy%2C+M">Mario Szegedy</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+G">Guanyu Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated presentation of the manuscript
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.03124" title="Abstract">arXiv:2210.03124</a> (replaced) [<a href="/pdf/2210.03124" title="Download PDF">pdf</a>, <a href="/format/2210.03124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Transfer Operators by Kernel Density Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Surasinghe%2C+S">Sudam Surasinghe</a>, 
<a href="/search/cs?searchtype=author&query=Fish%2C+J">Jeremie Fish</a>, 
<a href="/search/cs?searchtype=author&query=Bollt%2C+E+M">Erik M. Bollt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Dynamical Systems (math.DS); Statistics Theory (math.ST); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.09924" title="Abstract">arXiv:2210.09924</a> (replaced) [<a href="/pdf/2210.09924" title="Download PDF">pdf</a>, <a href="/format/2210.09924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Winning Regions in Parity Games via Graph Neural Networks  (Extended Abstract)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hecking%2C+T">Tobias Hecking</a>, 
<a href="/search/cs?searchtype=author&query=Muthukrishnan%2C+S">Swathy Muthukrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Weinert%2C+A">Alexander Weinert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, extended abstract. Presented at DAV'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.17403" title="Abstract">arXiv:2210.17403</a> (replaced) [<a href="/pdf/2210.17403" title="Download PDF">pdf</a>, <a href="/format/2210.17403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random Walk-based Community Key-members Search over Large Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaoliang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianxing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+X">Xiangyu Ke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01699" title="Abstract">arXiv:2211.01699</a> (replaced) [<a href="/pdf/2211.01699" title="Download PDF">pdf</a>, <a href="/format/2211.01699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Round and Bipartize for Vertex Cover Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kashaev%2C+D">Danish Kashaev</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%A4fer%2C+G">Guido Sch&#xe4;fer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in APPROX 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08321" title="Abstract">arXiv:2211.08321</a> (replaced) [<a href="/pdf/2211.08321" title="Download PDF">pdf</a>, <a href="/format/2211.08321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulated Mental Imagery for Robotic Task Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shijia Li</a>, 
<a href="/search/cs?searchtype=author&query=Kulvicius%2C+T">Tomas Kulvicius</a>, 
<a href="/search/cs?searchtype=author&query=Tamosiunaite%2C+M">Minija Tamosiunaite</a>, 
<a href="/search/cs?searchtype=author&query=W%C3%B6rg%C3%B6tter%2C+F">Florentin W&#xf6;rg&#xf6;tter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08411" title="Abstract">arXiv:2211.08411</a> (replaced) [<a href="/pdf/2211.08411" title="Download PDF">pdf</a>, <a href="/format/2211.08411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models Struggle to Learn Long-Tail Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kandpal%2C+N">Nikhil Kandpal</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+H">Haikang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Roberts%2C+A">Adam Roberts</a>, 
<a href="/search/cs?searchtype=author&query=Wallace%2C+E">Eric Wallace</a>, 
<a href="/search/cs?searchtype=author&query=Raffel%2C+C">Colin Raffel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICML 2023 Camera Ready Version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08944" title="Abstract">arXiv:2211.08944</a> (replaced) [<a href="/pdf/2211.08944" title="Download PDF">pdf</a>, <a href="/format/2211.08944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reasons for the Superiority of Stochastic Estimators over Deterministic  Ones: Robustness, Consistency and Perceptual Quality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ohayon%2C+G">Guy Ohayon</a>, 
<a href="/search/eess?searchtype=author&query=Adrai%2C+T">Theo Adrai</a>, 
<a href="/search/eess?searchtype=author&query=Elad%2C+M">Michael Elad</a>, 
<a href="/search/eess?searchtype=author&query=Michaeli%2C+T">Tomer Michaeli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.11220" title="Abstract">arXiv:2211.11220</a> (replaced) [<a href="/pdf/2211.11220" title="Download PDF">pdf</a>, <a href="/format/2211.11220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STGlow: A Flow-based Generative Framework with Dual Graphormer for  Pedestrian Trajectory Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+R">Rongqin Liang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanman Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jiantao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xia Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.12292" title="Abstract">arXiv:2211.12292</a> (replaced) [<a href="/pdf/2211.12292" title="Download PDF">pdf</a>, <a href="/format/2211.12292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exemplar-free Continual Learning of Vision Transformers via Gated  Class-Attention and Cascaded Feature Drift Compensation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cotogni%2C+M">Marco Cotogni</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cusano%2C+C">Claudio Cusano</a>, 
<a href="/search/cs?searchtype=author&query=Bagdanov%2C+A+D">Andrew D. Bagdanov</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Weijer%2C+J">Joost van de Weijer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.16762" title="Abstract">arXiv:2211.16762</a> (replaced) [<a href="/pdf/2211.16762" title="Download PDF">pdf</a>, <a href="/format/2211.16762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GeoUDF: Surface Reconstruction from 3D Point Clouds via Geometry-guided  Distance Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Siyu Ren</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Junhui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaodong Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Ying He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01127" title="Abstract">arXiv:2212.01127</a> (replaced) [<a href="/pdf/2212.01127" title="Download PDF">pdf</a>, <a href="/ps/2212.01127" title="Download PostScript">ps</a>, <a href="/format/2212.01127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Randomized low-rank approximation for symmetric indefinite matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Park%2C+T">Taejun Park</a>, 
<a href="/search/math?searchtype=author&query=Nakatsukasa%2C+Y">Yuji Nakatsukasa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01555" title="Abstract">arXiv:2212.01555</a> (replaced) [<a href="/pdf/2212.01555" title="Download PDF">pdf</a>, <a href="/format/2212.01555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Domain Adaptation for Time-Series via Temporal Mixup
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eldele%2C+E">Emadeldeen Eldele</a>, 
<a href="/search/cs?searchtype=author&query=Ragab%2C+M">Mohamed Ragab</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenghua Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Min Wu</a>, 
<a href="/search/cs?searchtype=author&query=Kwoh%2C+C">Chee-Keong Kwoh</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoli Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the IEEE Transactions on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07959" title="Abstract">arXiv:2212.07959</a> (replaced) [<a href="/pdf/2212.07959" title="Download PDF">pdf</a>, <a href="/format/2212.07959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Bayesian Uncertainty Quantification for Neural Network  Potentials: Promise and Pitfalls
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Thaler%2C+S">Stephan Thaler</a>, 
<a href="/search/physics?searchtype=author&query=Doehner%2C+G">Gregor Doehner</a>, 
<a href="/search/physics?searchtype=author&query=Zavadlav%2C+J">Julija Zavadlav</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a post-peer-review, pre-copyedit version of an article published in the Journal of Chemical Theory and Computation
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J. Chem. Theory Comput. 19, 14, 4520-4532 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.13381" title="Abstract">arXiv:2212.13381</a> (replaced) [<a href="/pdf/2212.13381" title="Download PDF">pdf</a>, <a href="/format/2212.13381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MixupE: Understanding and Improving Mixup from Directional Derivative  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+Y">Yingtian Zou</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+V">Vikas Verma</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+S">Sarthak Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+W+H">Wai Hoh Tang</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+H">Hieu Pham</a>, 
<a href="/search/cs?searchtype=author&query=Kannala%2C+J">Juho Kannala</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>, 
<a href="/search/cs?searchtype=author&query=Solin%2C+A">Arno Solin</a>, 
<a href="/search/cs?searchtype=author&query=Kawaguchi%2C+K">Kenji Kawaguchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, UAI 2023 oral presentation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.13504" title="Abstract">arXiv:2212.13504</a> (replaced) [<a href="/pdf/2212.13504" title="Download PDF">pdf</a>, <a href="/format/2212.13504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DAE-Former: Dual Attention-guided Efficient Transformer for Medical  Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azad%2C+R">Reza Azad</a>, 
<a href="/search/cs?searchtype=author&query=Arimond%2C+R">Ren&#xe9; Arimond</a>, 
<a href="/search/cs?searchtype=author&query=Aghdam%2C+E+K">Ehsan Khodapanah Aghdam</a>, 
<a href="/search/cs?searchtype=author&query=Kazerouni%2C+A">Amirhossein Kazerouni</a>, 
<a href="/search/cs?searchtype=author&query=Merhof%2C+D">Dorit Merhof</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MICCAI 2023 PRIME workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.01913" title="Abstract">arXiv:2301.01913</a> (replaced) [<a href="/pdf/2301.01913" title="Download PDF">pdf</a>, <a href="/format/2301.01913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning a Generic Value-Selection Heuristic Inside a Constraint  Programming Solver
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marty%2C+T">Tom Marty</a>, 
<a href="/search/cs?searchtype=author&query=Fran%C3%A7ois%2C+T">Tristan Fran&#xe7;ois</a>, 
<a href="/search/cs?searchtype=author&query=Tessier%2C+P">Pierre Tessier</a>, 
<a href="/search/cs?searchtype=author&query=Gauthier%2C+L">Louis Gauthier</a>, 
<a href="/search/cs?searchtype=author&query=Rousseau%2C+L">Louis-Martin Rousseau</a>, 
<a href="/search/cs?searchtype=author&query=Cappart%2C+Q">Quentin Cappart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03915" title="Abstract">arXiv:2301.03915</a> (replaced) [<a href="/pdf/2301.03915" title="Download PDF">pdf</a>, <a href="/format/2301.03915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning nonlinear hybrid automata from input--output time-series data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gurung%2C+A">Amit Gurung</a>, 
<a href="/search/cs?searchtype=author&query=Waga%2C+M">Masaki Waga</a>, 
<a href="/search/cs?searchtype=author&query=Suenaga%2C+K">Kohei Suenaga</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 22 figures; including appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11596" title="Abstract">arXiv:2301.11596</a> (replaced) [<a href="/pdf/2301.11596" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ThoughtSource: A central hub for large language model reasoning data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ott%2C+S">Simon Ott</a>, 
<a href="/search/cs?searchtype=author&query=Hebenstreit%2C+K">Konstantin Hebenstreit</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%A9vin%2C+V">Valentin Li&#xe9;vin</a>, 
<a href="/search/cs?searchtype=author&query=Hother%2C+C+E">Christoffer Egeberg Hother</a>, 
<a href="/search/cs?searchtype=author&query=Moradi%2C+M">Milad Moradi</a>, 
<a href="/search/cs?searchtype=author&query=Mayrhauser%2C+M">Maximilian Mayrhauser</a>, 
<a href="/search/cs?searchtype=author&query=Praas%2C+R">Robert Praas</a>, 
<a href="/search/cs?searchtype=author&query=Winther%2C+O">Ole Winther</a>, 
<a href="/search/cs?searchtype=author&query=Samwald%2C+M">Matthias Samwald</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revision: added datasets, formatting
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00083" title="Abstract">arXiv:2302.00083</a> (replaced) [<a href="/pdf/2302.00083" title="Download PDF">pdf</a>, <a href="/format/2302.00083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Context Retrieval-Augmented Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ram%2C+O">Ori Ram</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+Y">Yoav Levine</a>, 
<a href="/search/cs?searchtype=author&query=Dalmedigos%2C+I">Itay Dalmedigos</a>, 
<a href="/search/cs?searchtype=author&query=Muhlgay%2C+D">Dor Muhlgay</a>, 
<a href="/search/cs?searchtype=author&query=Shashua%2C+A">Amnon Shashua</a>, 
<a href="/search/cs?searchtype=author&query=Leyton-Brown%2C+K">Kevin Leyton-Brown</a>, 
<a href="/search/cs?searchtype=author&query=Shoham%2C+Y">Yoav Shoham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Transactions of the Association for Computational Linguistics (TACL). pre-MIT Press publication version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01198" title="Abstract">arXiv:2302.01198</a> (replaced) [<a href="/pdf/2302.01198" title="Download PDF">pdf</a>, <a href="/format/2302.01198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Lifting and Link Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cotta%2C+L">Leonardo Cotta</a>, 
<a href="/search/cs?searchtype=author&query=Bevilacqua%2C+B">Beatrice Bevilacqua</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+N">Nesreen Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+B">Bruno Ribeiro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01226" title="Abstract">arXiv:2302.01226</a> (replaced) [<a href="/pdf/2302.01226" title="Download PDF">pdf</a>, <a href="/format/2302.01226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Factor Fields: A Unified Framework for Neural Fields and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Anpei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zexiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xinyue Wei</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Siyu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hao Su</a>, 
<a href="/search/cs?searchtype=author&query=Geiger%2C+A">Andreas Geiger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures; Project Page: <a href="https://apchenstu.github.io/FactorFields/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05755" title="Abstract">arXiv:2302.05755</a> (replaced) [<a href="/pdf/2302.05755" title="Download PDF">pdf</a>, <a href="/ps/2302.05755" title="Download PostScript">ps</a>, <a href="/format/2302.05755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coherence by Normalization for Linear Multicategorical Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Olimpieri%2C+F">Federico Olimpieri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08278" title="Abstract">arXiv:2302.08278</a> (replaced) [<a href="/pdf/2302.08278" title="Download PDF">pdf</a>, <a href="/format/2302.08278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $C^1$-smooth isogeometric spline functions of general degree over planar  mixed meshes: The case of two quadratic mesh elements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gro%C5%A1elj%2C+J">Jan Gro&#x161;elj</a>, 
<a href="/search/math?searchtype=author&query=Kapl%2C+M">Mario Kapl</a>, 
<a href="/search/math?searchtype=author&query=Knez%2C+M">Marjeta Knez</a>, 
<a href="/search/math?searchtype=author&query=Takacs%2C+T">Thomas Takacs</a>, 
<a href="/search/math?searchtype=author&query=Vitrih%2C+V">Vito Vitrih</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08424" title="Abstract">arXiv:2302.08424</a> (replaced) [<a href="/pdf/2302.08424" title="Download PDF">pdf</a>, <a href="/ps/2302.08424" title="Download PostScript">ps</a>, <a href="/format/2302.08424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Contextual Data to Newsvendor Decisions: On the Actual Performance  of Data-Driven Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Besbes%2C+O">Omar Besbes</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Will Ma</a>, 
<a href="/search/cs?searchtype=author&query=Mouchtaki%2C+O">Omar Mouchtaki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08720" title="Abstract">arXiv:2302.08720</a> (replaced) [<a href="/pdf/2302.08720" title="Download PDF">pdf</a>, <a href="/format/2302.08720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithmic Hallucinations of Near-Surface Winds: Statistical  Downscaling with Generative Adversarial Networks to Convection-Permitting  Scales
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Annau%2C+N+J">Nicolaas J. Annau</a>, 
<a href="/search/physics?searchtype=author&query=Cannon%2C+A+J">Alex J. Cannon</a>, 
<a href="/search/physics?searchtype=author&query=Monahan%2C+A+H">Adam H. Monahan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages, including 11 main figures, and 16 supplemental figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12012" title="Abstract">arXiv:2302.12012</a> (replaced) [<a href="/pdf/2302.12012" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empirical analysis of Different Dimensionality Reduction and  classification Techniques for Epileptic Seizure detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guharoy%2C+R">Rabel Guharoy</a>, 
<a href="/search/cs?searchtype=author&query=Jana%2C+N+D">Nanda Dulal Jana</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+S">Suparna Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+L">Lalit Garg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12806" title="Abstract">arXiv:2302.12806</a> (replaced) [<a href="/pdf/2302.12806" title="Download PDF">pdf</a>, <a href="/format/2302.12806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Morality in the mundane: Categorizing moral reasoning in real-life  social situations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xi%2C+R">Ruijie Xi</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+M+P">Munindar P. Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by THE 18TH INTERNATIONAL AAAI CONFERENCE ON WEB AND SOCIAL MEDIA (ICWSM2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01669" title="Abstract">arXiv:2303.01669</a> (replaced) [<a href="/pdf/2303.01669" title="Download PDF">pdf</a>, <a href="/format/2303.01669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Common Rationale to Improve Self-Supervised Representation for  Fine-Grained Visual Recognition Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shu%2C+Y">Yangyang Shu</a>, 
<a href="/search/cs?searchtype=author&query=van+den+Hengel%2C+A">Anton van den Hengel</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingqiao Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02060" title="Abstract">arXiv:2303.02060</a> (replaced) [<a href="/pdf/2303.02060" title="Download PDF">pdf</a>, <a href="/format/2303.02060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral learning of Bernoulli linear dynamical systems models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Stone%2C+I+R">Iris R. Stone</a>, 
<a href="/search/stat?searchtype=author&query=Sagiv%2C+Y">Yotam Sagiv</a>, 
<a href="/search/stat?searchtype=author&query=Park%2C+I+M">Il Memming Park</a>, 
<a href="/search/stat?searchtype=author&query=Pillow%2C+J+W">Jonathan W. Pillow</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Transactions on Machine Learning Research (<a href="https://jmlr.org/tmlr/papers/">this https URL</a>)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transactions on Machine Learning Research (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05229" title="Abstract">arXiv:2303.05229</a> (replaced) [<a href="/pdf/2303.05229" title="Download PDF">pdf</a>, <a href="/format/2303.05229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Spectral Inversion for Inverse Medium Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gleichmann%2C+Y+G">Yannik G. Gleichmann</a>, 
<a href="/search/math?searchtype=author&query=Grote%2C+M+J">Marcus J. Grote</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10135" title="Abstract">arXiv:2303.10135</a> (replaced) [<a href="/pdf/2303.10135" title="Download PDF">pdf</a>, <a href="/format/2303.10135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient and Feasible Robotic Assembly Sequence Planning via Graph  Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atad%2C+M">Matan Atad</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jianxiang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Rodr%C3%ADguez%2C+I">Ismael Rodr&#xed;guez</a>, 
<a href="/search/cs?searchtype=author&query=Durner%2C+M">Maximilian Durner</a>, 
<a href="/search/cs?searchtype=author&query=Triebel%2C+R">Rudolph Triebel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IROS 2023. First two authors share equal contribution
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11463" title="Abstract">arXiv:2303.11463</a> (replaced) [<a href="/pdf/2303.11463" title="Download PDF">pdf</a>, <a href="/format/2303.11463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital twin in virtual reality for human-vehicle interactions in the  context of autonomous driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Serrano%2C+S+M">Sergio Mart&#xed;n Serrano</a>, 
<a href="/search/cs?searchtype=author&query=Izquierdo%2C+R">Rub&#xe9;n Izquierdo</a>, 
<a href="/search/cs?searchtype=author&query=Daza%2C+I+G">Iv&#xe1;n Garc&#xed;a Daza</a>, 
<a href="/search/cs?searchtype=author&query=Sotelo%2C+M+%C3%81">Miguel &#xc1;ngel Sotelo</a>, 
<a href="/search/cs?searchtype=author&query=Llorca%2C+D+F">David Fern&#xe1;ndez Llorca</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26th IEEE International Conference on Intelligent Transportation Systems ITSC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15986" title="Abstract">arXiv:2303.15986</a> (replaced) [<a href="/pdf/2303.15986" title="Download PDF">pdf</a>, <a href="/format/2303.15986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clustered Federated Learning Architecture for Network Anomaly Detection  in Large Scale Heterogeneous IoT Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%C3%A1ez-de-C%C3%A1mara%2C+X">Xabier S&#xe1;ez-de-C&#xe1;mara</a>, 
<a href="/search/cs?searchtype=author&query=Flores%2C+J+L">Jose Luis Flores</a>, 
<a href="/search/cs?searchtype=author&query=Arellano%2C+C">Crist&#xf3;bal Arellano</a>, 
<a href="/search/cs?searchtype=author&query=Urbieta%2C+A">Aitor Urbieta</a>, 
<a href="/search/cs?searchtype=author&query=Zurutuza%2C+U">Urko Zurutuza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Computers &amp; Security
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16746" title="Abstract">arXiv:2303.16746</a> (replaced) [<a href="/pdf/2303.16746" title="Download PDF">pdf</a>, <a href="/format/2303.16746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FATROP : A Fast Constrained Optimal Control Problem Solver for Robot  Trajectory Optimization and Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Vanroye%2C+L">Lander Vanroye</a>, 
<a href="/search/math?searchtype=author&query=Sathya%2C+A">Ajay Sathya</a>, 
<a href="/search/math?searchtype=author&query=De+Schutter%2C+J">Joris De Schutter</a>, 
<a href="/search/math?searchtype=author&query=Decr%C3%A9%2C+W">Wilm Decr&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17519" title="Abstract">arXiv:2303.17519</a> (replaced) [<a href="/pdf/2303.17519" title="Download PDF">pdf</a>, <a href="/format/2303.17519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Infinite Horizon Privacy in Networked Control Systems: Utility/Privacy  Tradeoffs and Design Tools
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hayati%2C+H">Haleh Hayati</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Wouw%2C+N">Nathan van de Wouw</a>, 
<a href="/search/cs?searchtype=author&query=Murguia%2C+C">Carlos Murguia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Information Theory (cs.IT); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00570" title="Abstract">arXiv:2304.00570</a> (replaced) [<a href="/pdf/2304.00570" title="Download PDF">pdf</a>, <a href="/format/2304.00570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedFTN: Personalized Federated Learning with Deep Feature Transformation  Network for Multi-institutional Low-count PET Denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+B">Bo Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+H">Huidong Xie</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Q">Qiong Liu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xiongchao Chen</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+X">Xueqi Guo</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+Z">Zhicheng Feng</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+S+K">S. Kevin Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+B">Biao Li</a>, 
<a href="/search/eess?searchtype=author&query=Rominger%2C+A">Axel Rominger</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+K">Kuangyu Shi</a>, 
<a href="/search/eess?searchtype=author&query=Duncan%2C+J+S">James S. Duncan</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+C">Chi Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01986" title="Abstract">arXiv:2304.01986</a> (replaced) [<a href="/pdf/2304.01986" title="Download PDF">pdf</a>, <a href="/format/2304.01986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> USTC FLICAR: A Sensors Fusion Dataset of LiDAR-Inertial-Camera for  Heavy-duty Autonomous Aerial Work Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yujiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yifan Duan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingchen Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinran Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Jianmin Ji</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+E">Erbao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanyong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 34 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02825" title="Abstract">arXiv:2304.02825</a> (replaced) [<a href="/pdf/2304.02825" title="Download PDF">pdf</a>, <a href="/ps/2304.02825" title="Download PostScript">ps</a>, <a href="/format/2304.02825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mind the $\tilde{\mathcal{O}}$: Asymptotically Better, but Still  Impractical, Quantum Distributed Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Kerger%2C+P+A">Phillip A. Kerger</a>, 
<a href="/search/quant-ph?searchtype=author&query=Neira%2C+D+E+B">David E. Bernal Neira</a>, 
<a href="/search/quant-ph?searchtype=author&query=Izquierdo%2C+Z+G">Zoe Gonzalez Izquierdo</a>, 
<a href="/search/quant-ph?searchtype=author&query=Rieffel%2C+E+G">Eleanor G. Rieffel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 0 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06848" title="Abstract">arXiv:2304.06848</a> (replaced) [<a href="/pdf/2304.06848" title="Download PDF">pdf</a>, <a href="/format/2304.06848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAR-DESPOT: Causally-Informed Online POMDP Planning for Robots in  Confounded Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cannizzaro%2C+R">Ricardo Cannizzaro</a>, 
<a href="/search/cs?searchtype=author&query=Kunze%2C+L">Lars Kunze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures, accepted to 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07260" title="Abstract">arXiv:2304.07260</a> (replaced) [<a href="/pdf/2304.07260" title="Download PDF">pdf</a>, <a href="/format/2304.07260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Open Source Design Optimization Toolbox Evaluated on a Soft Finger
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Navarro%2C+S+E">Stefan Escaida Navarro</a>, 
<a href="/search/cs?searchtype=author&query=Navez%2C+T">Tanguy Navez</a>, 
<a href="/search/cs?searchtype=author&query=Goury%2C+O">Olivier Goury</a>, 
<a href="/search/cs?searchtype=author&query=Molina%2C+L">Luis Molina</a>, 
<a href="/search/cs?searchtype=author&query=Duriez%2C+C">Christian Duriez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13037" title="Abstract">arXiv:2304.13037</a> (replaced) [<a href="/pdf/2304.13037" title="Download PDF">pdf</a>, <a href="/format/2304.13037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VeML: An End-to-End Machine Learning Lifecycle for Large-scale and  High-dimensional Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+V">Van-Duc Le</a>, 
<a href="/search/cs?searchtype=author&query=Bui%2C+C">Cuong-Tien Bui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wen-Syan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The updated version of this paper, titled "Efficient ML Lifecycle Transferring for Large-scale and High-dimensional Data via Core Set-based Dataset Similarity," has been accepted for publication in IEEE Access
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Access, vol. 11, pp. 73823-73838, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Databases (cs.DB); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14031" title="Abstract">arXiv:2304.14031</a> (replaced) [<a href="/pdf/2304.14031" title="Download PDF">pdf</a>, <a href="/format/2304.14031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Big Brother: Attacking Search Engines with Encodings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boucher%2C+N">Nicholas Boucher</a>, 
<a href="/search/cs?searchtype=author&query=Pajola%2C+L">Luca Pajola</a>, 
<a href="/search/cs?searchtype=author&query=Shumailov%2C+I">Ilia Shumailov</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+R">Ross Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Conti%2C+M">Mauro Conti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the 26th Symposium on Research in Attacks, Intrusions and Defenses (RAID). Revisions: Adds table summarizing attacks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14379" title="Abstract">arXiv:2304.14379</a> (replaced) [<a href="/pdf/2304.14379" title="Download PDF">pdf</a>, <a href="/ps/2304.14379" title="Download PostScript">ps</a>, <a href="/format/2304.14379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Automorphisms of Channel Codes: Properties, Code Design, and  a Decoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mandelbaum%2C+J">Jonathan Mandelbaum</a>, 
<a href="/search/cs?searchtype=author&query=J%C3%A4kel%2C+H">Holger J&#xe4;kel</a>, 
<a href="/search/cs?searchtype=author&query=Schmalen%2C+L">Laurent Schmalen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at International Symposium on Topics in Coding 2023 Included reviews: Changed naming of automorphism groups; Corrected typo in def. of GAUT; Preprocessing no longer as theorem; Smaller formatting changes; Results unchanged
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02109" title="Abstract">arXiv:2305.02109</a> (replaced) [<a href="/pdf/2305.02109" title="Download PDF">pdf</a>, <a href="/format/2305.02109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synergies Between Federated Learning and O-RAN: Towards an Elastic  Virtualized Architecture for Multiple Distributed Machine Learning Services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdisarabshali%2C+P">Payam Abdisarabshali</a>, 
<a href="/search/cs?searchtype=author&query=Accurso%2C+N">Nicholas Accurso</a>, 
<a href="/search/cs?searchtype=author&query=Malandra%2C+F">Filippo Malandra</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+W">Weifeng Su</a>, 
<a href="/search/cs?searchtype=author&query=Hosseinalipour%2C+S">Seyyedali Hosseinalipour</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04186" title="Abstract">arXiv:2305.04186</a> (replaced) [<a href="/pdf/2305.04186" title="Download PDF">pdf</a>, <a href="/format/2305.04186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video-Specific Query-Key Attention Modeling for Weakly-Supervised  Temporal Action Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xijun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Katsaggelos%2C+A+K">Aggelos K. Katsaggelos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05077" title="Abstract">arXiv:2305.05077</a> (replaced) [<a href="/pdf/2305.05077" title="Download PDF">pdf</a>, <a href="/format/2305.05077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Atmospheric Turbulence Correction via Variational Deep Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xijun Wang</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez-Tapia%2C+S">Santiago L&#xf3;pez-Tapia</a>, 
<a href="/search/cs?searchtype=author&query=Katsaggelos%2C+A+K">Aggelos K. Katsaggelos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been accepted to the 2023 IEEE 6th International Conference on Multimedia Information Processing and Retrieval (MIPR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06716" title="Abstract">arXiv:2305.06716</a> (replaced) [<a href="/pdf/2305.06716" title="Download PDF">pdf</a>, <a href="/format/2305.06716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distracting Downpour: Adversarial Weather Attacks for Motion Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schmalfuss%2C+J">Jenny Schmalfuss</a>, 
<a href="/search/cs?searchtype=author&query=Mehl%2C+L">Lukas Mehl</a>, 
<a href="/search/cs?searchtype=author&query=Bruhn%2C+A">Andr&#xe9;s Bruhn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Acepted by ICCV 2023. This work is a direct extension of our extended abstract from <a href="/abs/2210.11242">arXiv:2210.11242</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08234" title="Abstract">arXiv:2305.08234</a> (replaced) [<a href="/pdf/2305.08234" title="Download PDF">pdf</a>, <a href="/format/2305.08234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Introducing Tales of Tribute AI Competition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kowalski%2C+J">Jakub Kowalski</a>, 
<a href="/search/cs?searchtype=author&query=Miernik%2C+R">Rados&#x142;aw Miernik</a>, 
<a href="/search/cs?searchtype=author&query=Polak%2C+K">Katarzyna Polak</a>, 
<a href="/search/cs?searchtype=author&query=Budzki%2C+D">Dominik Budzki</a>, 
<a href="/search/cs?searchtype=author&query=Kowalik%2C+D">Damian Kowalik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08890" title="Abstract">arXiv:2305.08890</a> (replaced) [<a href="/pdf/2305.08890" title="Download PDF">pdf</a>, <a href="/format/2305.08890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differential Convolutional Fuzzy Time Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+T">Tianxiang Zhan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuanpeng He</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yong Deng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhen Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09160" title="Abstract">arXiv:2305.09160</a> (replaced) [<a href="/pdf/2305.09160" title="Download PDF">pdf</a>, <a href="/format/2305.09160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SUG: Single-dataset Unified Generalization for 3D Point Cloud  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Siyuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Botian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Peng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yikang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongsheng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM MM-2023, and our code is available at <a href="https://github.com/SiyuanHuang95/SUG">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10132" title="Abstract">arXiv:2305.10132</a> (replaced) [<a href="/pdf/2305.10132" title="Download PDF">pdf</a>, <a href="/format/2305.10132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic 3D Registration of Dental CBCT and Face Scan Data using 2D  Projection Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+H+S">Hyoung Suk Park</a>, 
<a href="/search/cs?searchtype=author&query=Hyun%2C+C+M">Chang Min Hyun</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sang-Hwy Lee</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+J+K">Jin Keun Seo</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+K">Kiwan Jeon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12485" title="Abstract">arXiv:2305.12485</a> (replaced) [<a href="/pdf/2305.12485" title="Download PDF">pdf</a>, <a href="/format/2305.12485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Confidence-based Partial Label Learning Model for Crowd-Annotated  Named Entity Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+L">Limao Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qunxi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuanbin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+T">Tao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13106" title="Abstract">arXiv:2305.13106</a> (replaced) [<a href="/pdf/2305.13106" title="Download PDF">pdf</a>, <a href="/format/2305.13106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Learning the Tail Quantiles of Driving Behavior Distributions via  Quantile Regression and Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tee%2C+J+Y">Jia Yu Tee</a>, 
<a href="/search/cs?searchtype=author&query=De+Candido%2C+O">Oliver De Candido</a>, 
<a href="/search/cs?searchtype=author&query=Utschick%2C+W">Wolfgang Utschick</a>, 
<a href="/search/cs?searchtype=author&query=Geiger%2C+P">Philipp Geiger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13849" title="Abstract">arXiv:2305.13849</a> (replaced) [<a href="/pdf/2305.13849" title="Download PDF">pdf</a>, <a href="/format/2305.13849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Latent Representations for Uncertainty Estimation using  Mahalanobis Distance in Deep Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Venkataramanan%2C+A">Aishwarya Venkataramanan</a>, 
<a href="/search/cs?searchtype=author&query=Benbihi%2C+A">Assia Benbihi</a>, 
<a href="/search/cs?searchtype=author&query=Laviale%2C+M">Martin Laviale</a>, 
<a href="/search/cs?searchtype=author&query=Pradalier%2C+C">Cedric Pradalier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages including supplementary material
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15299" title="Abstract">arXiv:2305.15299</a> (replaced) [<a href="/pdf/2305.15299" title="Download PDF">pdf</a>, <a href="/format/2305.15299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Science in the Era of ChatGPT, Large Language Models and Generative AI:  Challenges for Research Ethics and How to Respond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pournaras%2C+E">Evangelos Pournaras</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16406" title="Abstract">arXiv:2305.16406</a> (replaced) [<a href="/pdf/2305.16406" title="Download PDF">pdf</a>, <a href="/format/2305.16406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-aware attention layers coupled with optimal transport domain  adaptation and multimodal fusion methods for recognizing dementia from  spontaneous speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ilias%2C+L">Loukas Ilias</a>, 
<a href="/search/cs?searchtype=author&query=Askounis%2C+D">Dimitris Askounis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Knowledge-Based Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16573" title="Abstract">arXiv:2305.16573</a> (replaced) [<a href="/pdf/2305.16573" title="Download PDF">pdf</a>, <a href="/format/2305.16573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Weight Balancing on Long-Tailed Recognition Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hasegawa%2C+N">Naoya Hasegawa</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+I">Issei Sato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16731" title="Abstract">arXiv:2305.16731</a> (replaced) [<a href="/pdf/2305.16731" title="Download PDF">pdf</a>, <a href="/format/2305.16731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Emotion Experiencer Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wegge%2C+M">Maximilian Wegge</a>, 
<a href="/search/cs?searchtype=author&query=Klinger%2C+R">Roman Klinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to the CPSS workshop at KONVENS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18772" title="Abstract">arXiv:2305.18772</a> (replaced) [<a href="/pdf/2305.18772" title="Download PDF">pdf</a>, <a href="/ps/2305.18772" title="Download PostScript">ps</a>, <a href="/format/2305.18772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Remarks on Yablo Like Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Schlechta%2C+K">Karl Schlechta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">History and Overview (math.HO)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18785" title="Abstract">arXiv:2305.18785</a> (replaced) [<a href="/pdf/2305.18785" title="Download PDF">pdf</a>, <a href="/format/2305.18785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Dynamic Subset Sampling: Theory and Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+L">Lu Yi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhewei Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM SIGKDD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19472" title="Abstract">arXiv:2305.19472</a> (replaced) [<a href="/pdf/2305.19472" title="Download PDF">pdf</a>, <a href="/format/2305.19472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PlaSma: Making Small Language Models Better Procedural Knowledge Models  for (Counterfactual) Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brahman%2C+F">Faeze Brahman</a>, 
<a href="/search/cs?searchtype=author&query=Bhagavatula%2C+C">Chandra Bhagavatula</a>, 
<a href="/search/cs?searchtype=author&query=Pyatkin%2C+V">Valentina Pyatkin</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J+D">Jena D. Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X+L">Xiang Lorraine Li</a>, 
<a href="/search/cs?searchtype=author&query=Arai%2C+H+J">Hirona J. Arai</a>, 
<a href="/search/cs?searchtype=author&query=Sanyal%2C+S">Soumya Sanyal</a>, 
<a href="/search/cs?searchtype=author&query=Sakaguchi%2C+K">Keisuke Sakaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yejin Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> cited new paper, 27 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00017" title="Abstract">arXiv:2306.00017</a> (replaced) [<a href="/pdf/2306.00017" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Explainable and Language-Agnostic LLMs: Symbolic Reverse  Engineering of Language at Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saba%2C+W+S">Walid S. Saba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Draft, preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00615" title="Abstract">arXiv:2306.00615</a> (replaced) [<a href="/pdf/2306.00615" title="Download PDF">pdf</a>, <a href="/ps/2306.00615" title="Download PostScript">ps</a>, <a href="/format/2306.00615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Better Depth Lower Bounds: A KRW-like theorem for Strong  Composition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meir%2C+O">Or Meir</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02082" title="Abstract">arXiv:2306.02082</a> (replaced) [<a href="/pdf/2306.02082" title="Download PDF">pdf</a>, <a href="/format/2306.02082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Low Light Image Enhancement Using SNR-Aware Swin  Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhijian Luo</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiahui Tang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yueen Hou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zihan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yanzeng Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03753" title="Abstract">arXiv:2306.03753</a> (replaced) [<a href="/pdf/2306.03753" title="Download PDF">pdf</a>, <a href="/format/2306.03753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Art Curation: Re-imagining the city of Helsinki in occasion of its  Biennial
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schaerf%2C+L">Ludovica Schaerf</a>, 
<a href="/search/cs?searchtype=author&query=Ballesteros%2C+P">Pepe Ballesteros</a>, 
<a href="/search/cs?searchtype=author&query=Bernasconi%2C+V">Valentine Bernasconi</a>, 
<a href="/search/cs?searchtype=author&query=Neri%2C+I">Iacopo Neri</a>, 
<a href="/search/cs?searchtype=author&query=del+Castillo%2C+D+N">Dario Negueruela del Castillo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04169" title="Abstract">arXiv:2306.04169</a> (replaced) [<a href="/pdf/2306.04169" title="Download PDF">pdf</a>, <a href="/ps/2306.04169" title="Download PostScript">ps</a>, <a href="/format/2306.04169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Alternating Minimization with Applications to Weighted Low  Rank Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhao Song</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+M">Mingquan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Junze Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lichen Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04515" title="Abstract">arXiv:2306.04515</a> (replaced) [<a href="/pdf/2306.04515" title="Download PDF">pdf</a>, <a href="/format/2306.04515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Reconfigurable Intelligent Surface for the Millimeter-Wave  Frequency Band: Design and Measurement Results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Radpour%2C+H">Hamed Radpour</a>, 
<a href="/search/eess?searchtype=author&query=Hofer%2C+M">Markus Hofer</a>, 
<a href="/search/eess?searchtype=author&query=Mayer%2C+L+W">Lukas Walter Mayer</a>, 
<a href="/search/eess?searchtype=author&query=Hofmann%2C+A">Andreas Hofmann</a>, 
<a href="/search/eess?searchtype=author&query=Schiefer%2C+M">Martin Schiefer</a>, 
<a href="/search/eess?searchtype=author&query=Zemen%2C+T">Thomas Zemen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Wireless Communications and Networking Conference, Dubai, United Arab Emirates, April 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05697" title="Abstract">arXiv:2306.05697</a> (replaced) [<a href="/pdf/2306.05697" title="Download PDF">pdf</a>, <a href="/format/2306.05697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Group Equivariant Fourier Neural Operators for Partial Differential  Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Helwig%2C+J">Jacob Helwig</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Cong Fu</a>, 
<a href="/search/cs?searchtype=author&query=Kurtin%2C+J">Jerry Kurtin</a>, 
<a href="/search/cs?searchtype=author&query=Wojtowytsch%2C+S">Stephan Wojtowytsch</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shuiwang Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 40th International Conference on Machine Learning <a href="https://icml.cc/virtual/2023/poster/23875">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05965" title="Abstract">arXiv:2306.05965</a> (replaced) [<a href="/pdf/2306.05965" title="Download PDF">pdf</a>, <a href="/format/2306.05965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automating Model Comparison in Factor Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Erp%2C+B">Bart van Erp</a>, 
<a href="/search/cs?searchtype=author&query=Nuijten%2C+W+W+L">Wouter W. L. Nuijten</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Laar%2C+T">Thijs van de Laar</a>, 
<a href="/search/cs?searchtype=author&query=de+Vries%2C+B">Bert de Vries</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08541" title="Abstract">arXiv:2306.08541</a> (replaced) [<a href="/pdf/2306.08541" title="Download PDF">pdf</a>, <a href="/format/2306.08541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Tuned but Zero-Shot 3D Shape Sketch View Similarity and Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berardi%2C+G">Gianluca Berardi</a>, 
<a href="/search/cs?searchtype=author&query=Gryaditskaya%2C+Y">Yulia Gryaditskaya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09060" title="Abstract">arXiv:2306.09060</a> (replaced) [<a href="/pdf/2306.09060" title="Download PDF">pdf</a>, <a href="/format/2306.09060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast and Examination-agnostic Reciprocal Recommendation in Matching  Markets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tomita%2C+Y">Yoji Tomita</a>, 
<a href="/search/cs?searchtype=author&query=Togashi%2C+R">Riku Togashi</a>, 
<a href="/search/cs?searchtype=author&query=Hashizume%2C+Y">Yuriko Hashizume</a>, 
<a href="/search/cs?searchtype=author&query=Ohsaka%2C+N">Naoto Ohsaka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09831" title="Abstract">arXiv:2306.09831</a> (replaced) [<a href="/pdf/2306.09831" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Addressing Societal Issues in Interactive Digital Narratives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Silva%2C+C">Claudia Silva</a>, 
<a href="/search/cs?searchtype=author&query=Aguado%2C+J+M">Juan Miguel Aguado</a>, 
<a href="/search/cs?searchtype=author&query=Gerguri%2C+D">Dren Gerguri</a>, 
<a href="/search/cs?searchtype=author&query=Kazazi%2C+L">Ledia Kazazi</a>, 
<a href="/search/cs?searchtype=author&query=Marklund%2C+B+B">Bjorn Berg Marklund</a>, 
<a href="/search/cs?searchtype=author&query=Medina%2C+R+Z">Rocio Zamora Medina</a>, 
<a href="/search/cs?searchtype=author&query=Fahmy%2C+S+S">Shahira S. Fahmy</a>, 
<a href="/search/cs?searchtype=author&query=Vivo%2C+J+M+N">Jose Manuel Noguera Vivo</a>, 
<a href="/search/cs?searchtype=author&query=Bettocchi%2C+E">Eliane Bettocchi</a>, 
<a href="/search/cs?searchtype=author&query=Papaioannou%2C+T">Tao Papaioannou</a>, 
<a href="/search/cs?searchtype=author&query=Gil%2C+M">Maite Gil</a>, 
<a href="/search/cs?searchtype=author&query=Holloway-Attaway%2C+L">Lissa Holloway-Attaway</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10127" title="Abstract">arXiv:2306.10127</a> (replaced) [<a href="/pdf/2306.10127" title="Download PDF">pdf</a>, <a href="/format/2306.10127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Deep Learning Guided Autonomous Eye Surgery Using Microscope and  iOCT Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J+W">Ji Woong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Shuwen Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peiyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gehlbach%2C+P">Peter Gehlbach</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J+U">Jin U. Kang</a>, 
<a href="/search/cs?searchtype=author&query=Iordachita%2C+I">Iulian Iordachita</a>, 
<a href="/search/cs?searchtype=author&query=Kobilarov%2C+M">Marin Kobilarov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> pending submission to a journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10473" title="Abstract">arXiv:2306.10473</a> (replaced) [<a href="/pdf/2306.10473" title="Download PDF">pdf</a>, <a href="/format/2306.10473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 2D-Shapley: A Framework for Fragmented Data Valuation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhihong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Just%2C+H+A">Hoang Anh Just</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiangyu Chang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+R">Ruoxi Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 13 figures, ICML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16271" title="Abstract">arXiv:2306.16271</a> (replaced) [<a href="/pdf/2306.16271" title="Download PDF">pdf</a>, <a href="/format/2306.16271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Time-and Event-Triggered Scheduling in the Linux Kernel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gala%2C+G">Gautam Gala</a>, 
<a href="/search/cs?searchtype=author&query=Kadusale%2C+I">Isser Kadusale</a>, 
<a href="/search/cs?searchtype=author&query=Fohler%2C+G">Gerhard Fohler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 17th annual workshop on Operating Systems Platforms for Embedded Real-Time applications (OSPERT) workshop 2023 co-hosted with 35th Euromicro conference on Real-time systems. OSPERT proceedings: <a href="https://www.ecrts.org/wp-content/uploads/2023/07/ospert23-proceedings.pdf">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Operating Systems (cs.OS)</span>

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16958" title="Abstract">arXiv:2306.16958</a> (replaced) [<a href="/pdf/2306.16958" title="Download PDF">pdf</a>, <a href="/format/2306.16958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifiability of direct effects from summary causal graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferreira%2C+S">Simon Ferreira</a>, 
<a href="/search/cs?searchtype=author&query=Assaad%2C+C+K">Charles K. Assaad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00610" title="Abstract">arXiv:2307.00610</a> (replaced) [<a href="/pdf/2307.00610" title="Download PDF">pdf</a>, <a href="/format/2307.00610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fraunhofer SIT at CheckThat! 2023: Mixing Single-Modal Classifiers to  Estimate the Check-Worthiness of Multi-Modal Tweets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frick%2C+R">Raphael Frick</a>, 
<a href="/search/cs?searchtype=author&query=Vogel%2C+I">Inna Vogel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> CLEF 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00866" title="Abstract">arXiv:2307.00866</a> (replaced) [<a href="/pdf/2307.00866" title="Download PDF">pdf</a>, <a href="/format/2307.00866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mining Clues from Incomplete Utterance: A Query-enhanced Network for  Incomplete Utterance Rewriting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Si%2C+S">Shuzheng Si</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+S">Shuang Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+B">Baobao Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NAACL 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01524" title="Abstract">arXiv:2307.01524</a> (replaced) [<a href="/pdf/2307.01524" title="Download PDF">pdf</a>, <a href="/format/2307.01524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Richness of Learned Compressed Representation of Images for  Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kakaiya%2C+R">Ravi Kakaiya</a>, 
<a href="/search/cs?searchtype=author&query=Sathish%2C+R">Rakshith Sathish</a>, 
<a href="/search/cs?searchtype=author&query=Sethuraman%2C+R">Ramanathan Sethuraman</a>, 
<a href="/search/cs?searchtype=author&query=Sheet%2C+D">Debdoot Sheet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICME 2023 (Industry Track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01918" title="Abstract">arXiv:2307.01918</a> (replaced) [<a href="/pdf/2307.01918" title="Download PDF">pdf</a>, <a href="/format/2307.01918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational Reproducibility in Computational Social Science
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schoch%2C+D">David Schoch</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+C">Chung-hong Chan</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+C">Claudia Wagner</a>, 
<a href="/search/cs?searchtype=author&query=Bleier%2C+A">Arnim Bleier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Working Paper; fixed missing citation in text; fixed some minor errors and formatting
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02377" title="Abstract">arXiv:2307.02377</a> (replaced) [<a href="/pdf/2307.02377" title="Download PDF">pdf</a>, <a href="/format/2307.02377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fraunhofer SIT at CheckThat! 2023: Tackling Classification Uncertainty  Using Model Souping on the Example of Check-Worthiness Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frick%2C+R">Raphael Frick</a>, 
<a href="/search/cs?searchtype=author&query=Vogel%2C+I">Inna Vogel</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jeong-Eun Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> CLEF 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03430" title="Abstract">arXiv:2307.03430</a> (replaced) [<a href="/pdf/2307.03430" title="Download PDF">pdf</a>, <a href="/ps/2307.03430" title="Download PostScript">ps</a>, <a href="/format/2307.03430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differential Privacy for Clustering Under Continual Observation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=la+Tour%2C+M+D">Max Dupr&#xe9; la Tour</a>, 
<a href="/search/cs?searchtype=author&query=Henzinger%2C+M">Monika Henzinger</a>, 
<a href="/search/cs?searchtype=author&query=Saulpic%2C+D">David Saulpic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03811" title="Abstract">arXiv:2307.03811</a> (replaced) [<a href="/pdf/2307.03811" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formulation Graphs for Mapping Structure-Composition of Battery  Electrolytes to Device Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Sharma%2C+V">Vidushi Sharma</a>, 
<a href="/search/cond-mat?searchtype=author&query=Giammona%2C+M">Maxwell Giammona</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zubarev%2C+D">Dmitry Zubarev</a>, 
<a href="/search/cond-mat?searchtype=author&query=Tek%2C+A">Andy Tek</a>, 
<a href="/search/cond-mat?searchtype=author&query=Nugyuen%2C+K">Khanh Nugyuen</a>, 
<a href="/search/cond-mat?searchtype=author&query=Sundberg%2C+L">Linda Sundberg</a>, 
<a href="/search/cond-mat?searchtype=author&query=Congiu%2C+D">Daniele Congiu</a>, 
<a href="/search/cond-mat?searchtype=author&query=La%2C+Y">Young-Hye La</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03952" title="Abstract">arXiv:2307.03952</a> (replaced) [<a href="/pdf/2307.03952" title="Download PDF">pdf</a>, <a href="/format/2307.03952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is ChatGPT a Good Personality Recognizer? A Preliminary Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+Y">Yu Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Liang He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 13 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04019" title="Abstract">arXiv:2307.04019</a> (replaced) [<a href="/pdf/2307.04019" title="Download PDF">pdf</a>, <a href="/format/2307.04019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GP-guided MPPI for Efficient Navigation in Complex Unknown Cluttered  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohamed%2C+I+S">Ihab S. Mohamed</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+M">Mahmoud Ali</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lantao Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has 8 pages, 6 figures, 2 tables. It has been accepted for publication at the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, Michigan, USA, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05924" title="Abstract">arXiv:2307.05924</a> (replaced) [<a href="/pdf/2307.05924" title="Download PDF">pdf</a>, <a href="/format/2307.05924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applying SDN to Mobile Networks: A New Perspective for 6G Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yadav%2C+R">Rashmi Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Kamran%2C+R">Rashmi Kamran</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+P">Pranav Jha</a>, 
<a href="/search/cs?searchtype=author&query=Karandikar%2C+A">Abhay Karandikar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05946" title="Abstract">arXiv:2307.05946</a> (replaced) [<a href="/pdf/2307.05946" title="Download PDF">pdf</a>, <a href="/format/2307.05946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Bayesian approach to quantifying uncertainties and improving  generalizability in traffic prediction models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+A">Agnimitra Sengupta</a>, 
<a href="/search/cs?searchtype=author&query=Mondal%2C+S">Sudeepta Mondal</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Adway Das</a>, 
<a href="/search/cs?searchtype=author&query=Guler%2C+S+I">S. Ilgin Guler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06732" title="Abstract">arXiv:2307.06732</a> (replaced) [<a href="/pdf/2307.06732" title="Download PDF">pdf</a>, <a href="/format/2307.06732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning fixed points of recurrent neural networks by reparameterizing  the network model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Zhu%2C+V">Vicky Zhu</a>, 
<a href="/search/q-bio?searchtype=author&query=Rosenbaum%2C+R">Robert Rosenbaum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07133" title="Abstract">arXiv:2307.07133</a> (replaced) [<a href="/pdf/2307.07133" title="Download PDF">pdf</a>, <a href="/format/2307.07133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Step-GRAND: A Low Latency Universal Soft-input Decoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Abbas%2C+S+M">Syed Mohsin Abbas</a>, 
<a href="/search/eess?searchtype=author&query=Jalaleddine%2C+M">Marwan Jalaleddine</a>, 
<a href="/search/eess?searchtype=author&query=Tsui%2C+C">Chi-Ying Tsui</a>, 
<a href="/search/eess?searchtype=author&query=Gross%2C+W+J">Warren J. Gross</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to 2023 IEEE Globecom Workshops
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Hardware Architecture (cs.AR); Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07515" title="Abstract">arXiv:2307.07515</a> (replaced) [<a href="/pdf/2307.07515" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Artificial intelligence is algorithmic mimicry: why artificial &quot;agents&quot;  are not (and won&#x27;t be) proper agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jaeger%2C+J">Johannes Jaeger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09715" title="Abstract">arXiv:2307.09715</a> (replaced) [<a href="/pdf/2307.09715" title="Download PDF">pdf</a>, <a href="/format/2307.09715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic-Aware Dual Contrastive Learning for Multi-label Image  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Leilei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Dengdi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haifeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bin Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, accepted by European Conference on Artificial Intelligence (2023 ECAI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09751" title="Abstract">arXiv:2307.09751</a> (replaced) [<a href="/pdf/2307.09751" title="Download PDF">pdf</a>, <a href="/format/2307.09751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information Retrieval Meets Large Language Models: A Strategic Report  from Chinese IR Community
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ai%2C+Q">Qingyao Ai</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+T">Ting Bai</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhao Cao</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+Y">Yi Chang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiawei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhumin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhiyong Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+S">Shoubin Dong</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Z">Zhicheng Dou</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fuli Feng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shen Gao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiafeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiangnan He</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yanyan Lan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiqun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Z">Ziyu Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Weizhi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhaochun Ren</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+P">Pengjie Ren</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mingwen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Le Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+X">Xin Xin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Dawei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaofei Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09916" title="Abstract">arXiv:2307.09916</a> (replaced) [<a href="/pdf/2307.09916" title="Download PDF">pdf</a>, <a href="/format/2307.09916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TimeTuner: Diagnosing Time Representations for Time-Series Forecasting  with Counterfactual Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jianing Hao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Q">Qing Shi</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yilin Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Wei Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 9 figures, this paper has been accepted by IEEE VIS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10249" title="Abstract">arXiv:2307.10249</a> (replaced) [<a href="/pdf/2307.10249" title="Download PDF">pdf</a>, <a href="/format/2307.10249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RCM-Fusion: Radar-Camera Multi-Level Fusion for 3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jisong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Seong%2C+M">Minjae Seong</a>, 
<a href="/search/cs?searchtype=author&query=Bang%2C+G">Geonho Bang</a>, 
<a href="/search/cs?searchtype=author&query=Kum%2C+D">Dongsuk Kum</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J+W">Jun Won Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10513" title="Abstract">arXiv:2307.10513</a> (replaced) [<a href="/pdf/2307.10513" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Technology in Association With Mental Health: Meta-ethnography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohammed%2C+H">Hamza Mohammed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Nine-page Meta-ethnography on technology's association with mental health
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10705" title="Abstract">arXiv:2307.10705</a> (replaced) [<a href="/pdf/2307.10705" title="Download PDF">pdf</a>, <a href="/format/2307.10705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TwinLiteNet: An Efficient and Lightweight Model for Driveable Area and  Lane Segmentation in Self-Driving Cars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Che%2C+Q+H">Quang Huy Che</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+P">Dinh Phuc Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+M+Q">Minh Quan Pham</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+D+K">Duc Khai Lam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been submitted to the Conference on Multimedia Analysis and Pattern Recognition (MAPR), which will be held in held in Quy Nhon on October 5-6, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10853" title="Abstract">arXiv:2307.10853</a> (replaced) [<a href="/pdf/2307.10853" title="Download PDF">pdf</a>, <a href="/format/2307.10853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Effective Priors and Efficient Models for Weakly-Supervised  Change Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhenghui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ru%2C+L">Lixiang Ru</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chen Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transactions on Pattern Analysis and Machine Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11411" title="Abstract">arXiv:2307.11411</a> (replaced) [<a href="/pdf/2307.11411" title="Download PDF">pdf</a>, <a href="/format/2307.11411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Directly-Trained Spiking Neural Networks for Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+Q">Qiaoyi Su</a>, 
<a href="/search/cs?searchtype=author&query=Chou%2C+Y">Yuhong Chou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yifan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianing Li</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+S">Shijie Mei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guoqi Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11575" title="Abstract">arXiv:2307.11575</a> (replaced) [<a href="/pdf/2307.11575" title="Download PDF">pdf</a>, <a href="/ps/2307.11575" title="Download PostScript">ps</a>, <a href="/format/2307.11575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diurnal Patterns in the Spread of COVID-19 Misinformation on Twitter  within Italy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stockinger%2C+E">Elisabeth Stockinger</a>, 
<a href="/search/cs?searchtype=author&query=Gallotti%2C+R">Riccardo Gallotti</a>, 
<a href="/search/cs?searchtype=author&query=Hausladen%2C+C+I">Carina I. Hausladen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11679" title="Abstract">arXiv:2307.11679</a> (replaced) [<a href="/pdf/2307.11679" title="Download PDF">pdf</a>, <a href="/ps/2307.11679" title="Download PostScript">ps</a>, <a href="/format/2307.11679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weighted analytic regularity for the integral fractional Laplacian in  polyhedra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Faustmann%2C+M">Markus Faustmann</a>, 
<a href="/search/math?searchtype=author&query=Marcati%2C+C">Carlo Marcati</a>, 
<a href="/search/math?searchtype=author&query=Melenk%2C+J+M">Jens Markus Melenk</a>, 
<a href="/search/math?searchtype=author&query=Schwab%2C+C">Christoph Schwab</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2112.08151">arXiv:2112.08151</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11892" title="Abstract">arXiv:2307.11892</a> (replaced) [<a href="/pdf/2307.11892" title="Download PDF">pdf</a>, <a href="/ps/2307.11892" title="Download PostScript">ps</a>, <a href="/format/2307.11892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Vulnerability of Fairness Constrained Learning to Malicious Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blum%2C+A">Avrim Blum</a>, 
<a href="/search/cs?searchtype=author&query=Okoroafor%2C+P">Princewill Okoroafor</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+A">Aadirupa Saha</a>, 
<a href="/search/cs?searchtype=author&query=Stangl%2C+K">Kevin Stangl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11934" title="Abstract">arXiv:2307.11934</a> (replaced) [<a href="/pdf/2307.11934" title="Download PDF">pdf</a>, <a href="/format/2307.11934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LAMP: Leveraging Language Prompts for Multi-person Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shengnan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Ce Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zixiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sukthankar%2C+G">Gita Sukthankar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12162" title="Abstract">arXiv:2307.12162</a> (replaced) [<a href="/pdf/2307.12162" title="Download PDF">pdf</a>, <a href="/ps/2307.12162" title="Download PostScript">ps</a>, <a href="/format/2307.12162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Refinement of Expurgation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cocco%2C+G">Giuseppe Cocco</a>, 
<a href="/search/cs?searchtype=author&query=F%C3%A0bregas%2C+A+G+i">Albert Guill&#xe9;n i F&#xe0;bregas</a>, 
<a href="/search/cs?searchtype=author&query=Font-Segura%2C+J">Josep Font-Segura</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12328" title="Abstract">arXiv:2307.12328</a> (replaced) [<a href="/pdf/2307.12328" title="Download PDF">pdf</a>, <a href="/format/2307.12328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A First Look at On-device Models in iOS Apps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Han Hu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yujin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qiuyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+T+Y">Terry Yue Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chunyang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 7 pages, journal paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12602" title="Abstract">arXiv:2307.12602</a> (replaced) [<a href="/pdf/2307.12602" title="Download PDF">pdf</a>, <a href="/ps/2307.12602" title="Download PostScript">ps</a>, <a href="/format/2307.12602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shortest two disjoint paths in conservative graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schlotter%2C+I">Ildik&#xf3; Schlotter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12798" title="Abstract">arXiv:2307.12798</a> (replaced) [<a href="/pdf/2307.12798" title="Download PDF">pdf</a>, <a href="/format/2307.12798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RRAML: Reinforced Retrieval Augmented Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bacciu%2C+A">Andrea Bacciu</a>, 
<a href="/search/cs?searchtype=author&query=Cuconasu%2C+F">Florin Cuconasu</a>, 
<a href="/search/cs?searchtype=author&query=Siciliano%2C+F">Federico Siciliano</a>, 
<a href="/search/cs?searchtype=author&query=Silvestri%2C+F">Fabrizio Silvestri</a>, 
<a href="/search/cs?searchtype=author&query=Tonellotto%2C+N">Nicola Tonellotto</a>, 
<a href="/search/cs?searchtype=author&query=Trappolini%2C+G">Giovanni Trappolini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12882" title="Abstract">arXiv:2307.12882</a> (replaced) [<a href="/pdf/2307.12882" title="Download PDF">pdf</a>, <a href="/format/2307.12882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FoodWise: Food Waste Reduction and Behavior Change on Campus with Data  Visualization and Gamification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+S">Sophia Yi</a>, 
<a href="/search/cs?searchtype=author&query=Nan%2C+X">Xi Nan</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+L+Y">Leo Yu-Ho Lo</a>, 
<a href="/search/cs?searchtype=author&query=Shigyo%2C+K">Kento Shigyo</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Liwenhan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wicaksana%2C+J">Jeffry Wicaksana</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+K">Kwang-Ting Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+H">Huamin Qu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ACM SIGCAS/SIGCHI Conference on Computing and Sustainable Societies (COMPASS) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13365" title="Abstract">arXiv:2307.13365</a> (replaced) [<a href="/pdf/2307.13365" title="Download PDF">pdf</a>, <a href="/format/2307.13365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empower Your Model with Longer and Better Context Comprehension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yifei Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Jun Fang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Longhua Hu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jun Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> LLM for long context comprehension
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13423" title="Abstract">arXiv:2307.13423</a> (replaced) [<a href="/pdf/2307.13423" title="Download PDF">pdf</a>, <a href="/format/2307.13423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non Intrusive Intelligibility Predictor for Hearing Impaired Individuals  using Self Supervised Speech Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Close%2C+G">George Close</a>, 
<a href="/search/cs?searchtype=author&query=Hain%2C+T">Thomas Hain</a>, 
<a href="/search/cs?searchtype=author&query=Goetze%2C+S">Stefan Goetze</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13494" title="Abstract">arXiv:2307.13494</a> (replaced) [<a href="/pdf/2307.13494" title="Download PDF">pdf</a>, <a href="/format/2307.13494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Duet: efficient and scalable hybriD neUral rElation undersTanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaixin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yabin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+C">Chang Shu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Donghua Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13660" title="Abstract">arXiv:2307.13660</a> (replaced) [<a href="/pdf/2307.13660" title="Download PDF">pdf</a>, <a href="/format/2307.13660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing the Gromov--Hausdorff distance using first-order methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oles%2C+V">Vladyslav Oles</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Metric Geometry (math.MG)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13693" title="Abstract">arXiv:2307.13693</a> (replaced) [<a href="/pdf/2307.13693" title="Download PDF">pdf</a>, <a href="/format/2307.13693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Large Language Models for Radiology Natural Language  Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+T">Tianyang Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yutong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yi Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zihao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+P">Peixin Dong</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+C">Chao Cao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuxiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+P">Peng Shu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yaonai Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zihao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Mengyue Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zuowei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunlin Li</a>, 
<a href="/search/cs?searchtype=author&query=Holmes%2C+J">Jason Holmes</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shaochen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Haixing Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuanhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+P">Pingkun Yan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+B">Bao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Dajiang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xiaoyan Cai</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xintao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tuo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shijie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Quanzheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hongtu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+D">Dinggang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianming Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13709" title="Abstract">arXiv:2307.13709</a> (replaced) [<a href="/pdf/2307.13709" title="Download PDF">pdf</a>, <a href="/ps/2307.13709" title="Download PostScript">ps</a>, <a href="/format/2307.13709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Bradley-Terry Rating: Estimate Properties Without Metric of Unseen  Items
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fujii%2C+S">Satoru Fujii</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13717" title="Abstract">arXiv:2307.13717</a> (replaced) [<a href="/pdf/2307.13717" title="Download PDF">pdf</a>, <a href="/ps/2307.13717" title="Download PostScript">ps</a>, <a href="/format/2307.13717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Analysis on the Leakage of Fuzzy Matchers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Durbet%2C+A">Axel Durbet</a>, 
<a href="/search/cs?searchtype=author&query=Grollemund%2C+P">Paul-Marie Grollemund</a>, 
<a href="/search/cs?searchtype=author&query=Thiry-Atighehchi%2C+K">Kevin Thiry-Atighehchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13813" title="Abstract">arXiv:2307.13813</a> (replaced) [<a href="/pdf/2307.13813" title="Download PDF">pdf</a>, <a href="/format/2307.13813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Scale Your EMA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Busbridge%2C+D">Dan Busbridge</a>, 
<a href="/search/stat?searchtype=author&query=Ramapuram%2C+J">Jason Ramapuram</a>, 
<a href="/search/stat?searchtype=author&query=Ablin%2C+P">Pierre Ablin</a>, 
<a href="/search/stat?searchtype=author&query=Likhomanenko%2C+T">Tatiana Likhomanenko</a>, 
<a href="/search/stat?searchtype=author&query=Dhekane%2C+E+G">Eeshan Gunesh Dhekane</a>, 
<a href="/search/stat?searchtype=author&query=Suau%2C+X">Xavier Suau</a>, 
<a href="/search/stat?searchtype=author&query=Webb%2C+R">Russ Webb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 51 pages, 28 figures, 15 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13925" title="Abstract">arXiv:2307.13925</a> (replaced) [<a href="/pdf/2307.13925" title="Download PDF">pdf</a>, <a href="/format/2307.13925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EasyNet: An Easy Network for 3D Industrial Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruitao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+G">Guoyang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinbao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Ziqi Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinfan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+F">Feng Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13957" title="Abstract">arXiv:2307.13957</a> (replaced) [<a href="/pdf/2307.13957" title="Download PDF">pdf</a>, <a href="/format/2307.13957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heterogeneous Embodied Multi-Agent Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinzhu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Di Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huaping Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14016" title="Abstract">arXiv:2307.14016</a> (replaced) [<a href="/pdf/2307.14016" title="Download PDF">pdf</a>, <a href="/format/2307.14016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RPG-Palm: Realistic Pseudo-data Generation for Palmprint Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Lei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jianlong Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruixin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huaen Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingyun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+S">Shouhong Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+W">Wei Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages,8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14051" title="Abstract">arXiv:2307.14051</a> (replaced) [<a href="/pdf/2307.14051" title="Download PDF">pdf</a>, <a href="/format/2307.14051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Semantic Subspace Traverser: Empowering 3D Generative Model with  Shape Editing Capability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruowei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+P">Pei Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qijun Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in ICCV 2023. Code: <a href="https://github.com/TrepangCat/3D_Semantic_Subspace_Traverser">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14066" title="Abstract">arXiv:2307.14066</a> (replaced) [<a href="/pdf/2307.14066" title="Download PDF">pdf</a>, <a href="/format/2307.14066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-Training with Diffusion models for Dental Radiography segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rousseau%2C+J">J&#xe9;r&#xe9;my Rousseau</a>, 
<a href="/search/cs?searchtype=author&query=Alaka%2C+C">Christian Alaka</a>, 
<a href="/search/cs?searchtype=author&query=Covili%2C+E">Emma Covili</a>, 
<a href="/search/cs?searchtype=author&query=Mayard%2C+H">Hippolyte Mayard</a>, 
<a href="/search/cs?searchtype=author&query=Misrachi%2C+L">Laura Misrachi</a>, 
<a href="/search/cs?searchtype=author&query=Au%2C+W">Willy Au</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14127" title="Abstract">arXiv:2307.14127</a> (replaced) [<a href="/pdf/2307.14127" title="Download PDF">pdf</a>, <a href="/format/2307.14127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Creative Birds: Self-Supervised Single-View 3D Style Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Renke Wang</a>, 
<a href="/search/cs?searchtype=author&query=Que%2C+G">Guimin Que</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14132" title="Abstract">arXiv:2307.14132</a> (replaced) [<a href="/pdf/2307.14132" title="Download PDF">pdf</a>, <a href="/format/2307.14132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Say Goodbye to RNN-T Loss: A Novel CIF-based Transducer Architecture for  Automatic Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tian-Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Dinghao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+G">Guiping Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Baoxiang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item274">Cross-lists</a></li>
<li><a href="#item322">Replacements</a></li>
</ul>
<small>[ total of 490 entries:  <b>1-490</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2307">2307</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
