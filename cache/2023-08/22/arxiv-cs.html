<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Fri 18 Aug 23  to  Mon 21 Aug 23, announced Tue, 22 Aug 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item573">Cross-lists</a></li>
<li><a href="#item641">Replacements</a></li>
</ul>
<small>[ total of 1008 entries:  <b>1-1008</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Tue, 22 Aug 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09719" title="Abstract">arXiv:2308.09719</a> [<a href="/pdf/2308.09719" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CIRO: COVID-19 infection risk ontology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Egami%2C+S">Shusaku Egami</a>, 
<a href="/search/cs?searchtype=author&query=Yamamoto%2C+Y">Yasunori Yamamoto</a>, 
<a href="/search/cs?searchtype=author&query=Ohmukai%2C+I">Ikki Ohmukai</a>, 
<a href="/search/cs?searchtype=author&query=Okumura%2C+T">Takashi Okumura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 8 figures, and this paper has been accepted by PLOS ONE
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> PLoS One, 18(3), e0282291, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Public health authorities perform contact tracing for highly contagious
agents to identify close contacts with the infected cases. However, during the
pandemic caused by coronavirus disease 2019 (COVID-19), this operation was not
employed in countries with high patient volumes. Meanwhile, the Japanese
government conducted this operation, thereby contributing to the control of
infections, at the cost of arduous manual labor by public health officials. To
ease the burden of the officials, this study attempted to automate the
assessment of each person's infection risk through an ontology, called COVID-19
Infection Risk Ontology (CIRO). This ontology expresses infection risks of
COVID-19 formulated by the Japanese government, toward automated assessment of
infection risks of individuals, using Resource Description Framework (RDF) and
SPARQL (SPARQL Protocol and RDF Query Language) queries. For evaluation, we
demonstrated that the knowledge graph built could infer the risks, formulated
by the government. Moreover, we conducted reasoning experiments to analyze the
computational efficiency. The experiments demonstrated usefulness of the
knowledge processing, and identified issues left for deployment.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09720" title="Abstract">arXiv:2308.09720</a> [<a href="/pdf/2308.09720" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Unexpected Abilities of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nolfi%2C+S">Stefano Nolfi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models are capable of displaying a wide range of abilities
that are not directly connected with the task for which they are trained:
predicting the next words of human-written texts. In this article, I discuss
the nature of this indirect acquisition process and its relation to other known
indirect processes. I argue that an important side effect of such indirect
acquisition is the development of integrated abilities. I discuss the extent to
which the abilities developed by large language models are predictable.
Finally, I briefly discuss the relation between the cognitive skills acquired
by these systems and human cognition.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09721" title="Abstract">arXiv:2308.09721</a> [<a href="/pdf/2308.09721" title="Download PDF">pdf</a>, <a href="/format/2308.09721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new solution and concrete implementation steps for Artificial General  Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yongcong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+T">Ting Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 2 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">At present, the mainstream artificial intelligence generally adopts the
technical path of "attention mechanism + deep learning" + "reinforcement
learning". It has made great progress in the field of AIGC (Artificial
Intelligence Generated Content), setting off the technical wave of big models[
2][13 ]. But in areas that need to interact with the actual environment, such
as elderly care, home nanny, agricultural production, and vehicle driving,
trial and error are expensive and a reinforcement learning process that
requires much trial and error is difficult to achieve. Therefore, in order to
achieve Artificial General Intelligence(AGI) that can be applied to any field,
we need to use both existing technologies and solve the defects of existing
technologies, so as to further develop the technological wave of artificial
intelligence. In this paper, we analyze the limitations of the technical route
of large models, and by addressing these limitations, we propose solutions,
thus solving the inherent defects of large models. In this paper, we will
reveal how to achieve true AGI step by step.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09722" title="Abstract">arXiv:2308.09722</a> [<a href="/pdf/2308.09722" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Trustable LSTM-Autoencoder Network for Cyberbullying Detection on  Social Media Using Synthetic Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akter%2C+M+S">Mst Shapna Akter</a>, 
<a href="/search/cs?searchtype=author&query=Shahriar%2C+H">Hossain Shahriar</a>, 
<a href="/search/cs?searchtype=author&query=Cuzzocrea%2C+A">Alfredo Cuzzocrea</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2303.07484">arXiv:2303.07484</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Social media cyberbullying has a detrimental effect on human life. As online
social networking grows daily, the amount of hate speech also increases. Such
terrible content can cause depression and actions related to suicide. This
paper proposes a trustable LSTM-Autoencoder Network for cyberbullying detection
on social media using synthetic data. We have demonstrated a cutting-edge
method to address data availability difficulties by producing
machine-translated data. However, several languages such as Hindi and Bangla
still lack adequate investigations due to a lack of datasets. We carried out
experimental identification of aggressive comments on Hindi, Bangla, and
English datasets using the proposed model and traditional models, including
Long Short-Term Memory (LSTM), Bidirectional Long Short-Term Memory (BiLSTM),
LSTM-Autoencoder, Word2vec, Bidirectional Encoder Representations from
Transformers (BERT), and Generative Pre-trained Transformer 2 (GPT-2) models.
We employed evaluation metrics such as f1-score, accuracy, precision, and
recall to assess the models performance. Our proposed model outperformed all
the models on all datasets, achieving the highest accuracy of 95%. Our model
achieves state-of-the-art results among all the previous works on the dataset
we used in this paper.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09723" title="Abstract">arXiv:2308.09723</a> [<a href="/pdf/2308.09723" title="Download PDF">pdf</a>, <a href="/format/2308.09723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FineQuant: Unlocking Efficiency with Fine-Grained Weight-Only  Quantization for LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y+J">Young Jin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Henry%2C+R">Rawn Henry</a>, 
<a href="/search/cs?searchtype=author&query=Fahim%2C+R">Raffy Fahim</a>, 
<a href="/search/cs?searchtype=author&query=Awadalla%2C+H+H">Hany Hassan Awadalla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large Language Models (LLMs) have achieved state-of-the-art performance
across various language tasks but pose challenges for practical deployment due
to their substantial memory requirements. Furthermore, the latest generative
models suffer from high inference costs caused by the memory bandwidth
bottleneck in the auto-regressive decoding process. To address these issues, we
propose an efficient weight-only quantization method that reduces memory
consumption and accelerates inference for LLMs. To ensure minimal quality
degradation, we introduce a simple and effective heuristic approach that
utilizes only the model weights of a pre-trained model. This approach is
applicable to both Mixture-of-Experts (MoE) and dense models without requiring
additional fine-tuning. To demonstrate the effectiveness of our proposed
method, we first analyze the challenges and issues associated with LLM
quantization. Subsequently, we present our heuristic approach, which adaptively
finds the granularity of quantization, effectively addressing these problems.
Furthermore, we implement highly efficient GPU GEMMs that perform on-the-fly
matrix multiplication and dequantization, supporting the multiplication of fp16
or bf16 activations with int8 or int4 weights. We evaluate our approach on
large-scale open source models such as OPT-175B and internal MoE models,
showcasing minimal accuracy loss while achieving up to 3.65 times higher
throughput on the same number of GPUs.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09724" title="Abstract">arXiv:2308.09724</a> [<a href="/pdf/2308.09724" title="Download PDF">pdf</a>, <a href="/format/2308.09724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge-inspired Subdomain Adaptation for Cross-Domain Knowledge  Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liyue Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Linian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jinyu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenbiao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qiyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Leye Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by CIKM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Most state-of-the-art deep domain adaptation techniques align source and
target samples in a global fashion. That is, after alignment, each source
sample is expected to become similar to any target sample. However, global
alignment may not always be optimal or necessary in practice. For example,
consider cross-domain fraud detection, where there are two types of
transactions: credit and non-credit. Aligning credit and non-credit
transactions separately may yield better performance than global alignment, as
credit transactions are unlikely to exhibit patterns similar to non-credit
transactions. To enable such fine-grained domain adaption, we propose a novel
Knowledge-Inspired Subdomain Adaptation (KISA) framework. In particular, (1) We
provide the theoretical insight that KISA minimizes the shared expected loss
which is the premise for the success of domain adaptation methods. (2) We
propose the knowledge-inspired subdomain division problem that plays a crucial
role in fine-grained domain adaption. (3) We design a knowledge fusion network
to exploit diverse domain knowledge. Extensive experiments demonstrate that
KISA achieves remarkable results on fraud detection and traffic demand
prediction tasks.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09726" title="Abstract">arXiv:2308.09726</a> [<a href="/pdf/2308.09726" title="Download PDF">pdf</a>, <a href="/format/2308.09726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Equitable Restless Multi-Armed Bandits: A General Framework Inspired By  Digital Health
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Killian%2C+J+A">Jackson A. Killian</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+M">Manish Jain</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yugang Jia</a>, 
<a href="/search/cs?searchtype=author&query=Amar%2C+J">Jonathan Amar</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+E">Erich Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tambe%2C+M">Milind Tambe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 8 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Restless multi-armed bandits (RMABs) are a popular framework for algorithmic
decision making in sequential settings with limited resources. RMABs are
increasingly being used for sensitive decisions such as in public health,
treatment scheduling, anti-poaching, and -- the motivation for this work --
digital health. For such high stakes settings, decisions must both improve
outcomes and prevent disparities between groups (e.g., ensure health equity).
We study equitable objectives for RMABs (ERMABs) for the first time. We
consider two equity-aligned objectives from the fairness literature, minimax
reward and max Nash welfare. We develop efficient algorithms for solving each
-- a water filling algorithm for the former, and a greedy algorithm with
theoretically motivated nuance to balance disparate group sizes for the latter.
Finally, we demonstrate across three simulation domains, including a new
digital health model, that our approaches can be multiple times more equitable
than the current state of the art without drastic sacrifices to utility. Our
findings underscore our work's urgency as RMABs permeate into systems that
impact human and wildlife outcomes. Code is available at
https://github.com/google-research/socialgood/tree/equitable-rmab
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09727" title="Abstract">arXiv:2308.09727</a> [<a href="/pdf/2308.09727" title="Download PDF">pdf</a>, <a href="/format/2308.09727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-city Few-Shot Traffic Forecasting via Traffic Pattern Bank
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhanyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+G">Guanjie Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yanwei Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CIKM2023 (Long Paper)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Traffic forecasting is a critical service in Intelligent Transportation
Systems (ITS). Utilizing deep models to tackle this task relies heavily on data
from traffic sensors or vehicle devices, while some cities might lack device
support and thus have few available data. So, it is necessary to learn from
data-rich cities and transfer the knowledge to data-scarce cities in order to
improve the performance of traffic forecasting. To address this problem, we
propose a cross-city few-shot traffic forecasting framework via Traffic Pattern
Bank (TPB) due to that the traffic patterns are similar across cities. TPB
utilizes a pre-trained traffic patch encoder to project raw traffic data from
data-rich cities into high-dimensional space, from which a traffic pattern bank
is generated through clustering. Then, the traffic data of the data-scarce city
could query the traffic pattern bank and explicit relations between them are
constructed. The metaknowledge is aggregated based on these relations and an
adjacency matrix is constructed to guide a downstream spatial-temporal model in
forecasting future traffic. The frequently used meta-training framework Reptile
is adapted to find a better initial parameter for the learnable modules.
Experiments on real-world traffic datasets show that TPB outperforms existing
methods and demonstrates the effectiveness of our approach in cross-city
few-shot traffic forecasting.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09728" title="Abstract">arXiv:2308.09728</a> [<a href="/pdf/2308.09728" title="Download PDF">pdf</a>, <a href="/ps/2308.09728" title="Download PostScript">ps</a>, <a href="/format/2308.09728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning representations by forward-propagating errors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jang%2C+R">Ryoungwoo Jang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Back-propagation (BP) is widely used learning algorithm for neural network
optimization. However, BP requires enormous computation cost and is too slow to
train in central processing unit (CPU). Therefore current neural network
optimizaiton is performed in graphical processing unit (GPU) with compute
unified device architecture (CUDA) programming. In this paper, we propose a
light, fast learning algorithm on CPU that is fast as CUDA acceleration on GPU.
This algorithm is based on forward-propagating method, using concept of dual
number in algebraic geometry.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09729" title="Abstract">arXiv:2308.09729</a> [<a href="/pdf/2308.09729" title="Download PDF">pdf</a>, <a href="/format/2308.09729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yilin Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zifeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jimeng Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">LLMs usually exhibit limitations in their ability to incorporate new
knowledge, the generation of hallucinations, and the transparency of their
decision-making process. In this paper, we explore how to prompt LLMs with
knowledge graphs (KG), working as a remedy to engage LLMs with up-to-date
knowledge and elicit the reasoning pathways from LLMs. Specifically, we build a
prompting pipeline that endows LLMs with the capability of comprehending KG
inputs and inferring with a combined implicit knowledge and the retrieved
external knowledge. In addition, we investigate eliciting the mind map on which
LLMs perform the reasoning and generate the answers. It is identified that the
produced mind map exhibits the reasoning pathways of LLMs grounded on the
ontology of knowledge, hence bringing the prospects of probing and gauging LLM
inference in production. The experiments on three question &amp; answering datasets
also show that MindMap prompting leads to a striking empirical gain. For
instance, prompting a GPT-3.5 with MindMap yields an overwhelming performance
over GPT-4 consistently. We also demonstrate that with structured facts
retrieved from KG, MindMap can outperform a series of
prompting-with-document-retrieval methods, benefiting from more accurate,
concise, and comprehensive knowledge from KGs.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09731" title="Abstract">arXiv:2308.09731</a> [<a href="/pdf/2308.09731" title="Download PDF">pdf</a>, <a href="/format/2308.09731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT-HealthPrompt. Harnessing the Power of XAI in Prompt-Based  Healthcare Decision Support using ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nazary%2C+F">Fatemeh Nazary</a>, 
<a href="/search/cs?searchtype=author&query=Deldjoo%2C+Y">Yashar Deldjoo</a>, 
<a href="/search/cs?searchtype=author&query=Di+Noia%2C+T">Tommaso Di Noia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">This study presents an innovative approach to the application of large
language models (LLMs) in clinical decision-making, focusing on OpenAI's
ChatGPT. Our approach introduces the use of contextual prompts-strategically
designed to include task description, feature description, and crucially,
integration of domain knowledge-for high-quality binary classification tasks
even in data-scarce scenarios. The novelty of our work lies in the utilization
of domain knowledge, obtained from high-performing interpretable ML models, and
its seamless incorporation into prompt design. By viewing these ML models as
medical experts, we extract key insights on feature importance to aid in
decision-making processes. This interplay of domain knowledge and AI holds
significant promise in creating a more insightful diagnostic tool.
<br />Additionally, our research explores the dynamics of zero-shot and few-shot
prompt learning based on LLMs. By comparing the performance of OpenAI's ChatGPT
with traditional supervised ML models in different data conditions, we aim to
provide insights into the effectiveness of prompt engineering strategies under
varied data availability. In essence, this paper bridges the gap between AI and
healthcare, proposing a novel methodology for LLMs application in clinical
decision support systems. It highlights the transformative potential of
effective prompt design, domain knowledge integration, and flexible learning
approaches in enhancing automated decision-making.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09732" title="Abstract">arXiv:2308.09732</a> [<a href="/pdf/2308.09732" title="Download PDF">pdf</a>, <a href="/format/2308.09732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Baird Counterexample Is Solved: with an example of How to Debug a  Two-time-scale Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Hengshuai Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Baird counterexample was proposed by Leemon Baird in 1995, first used to show
that the Temporal Difference (TD(0)) algorithm diverges on this example. Since
then, it is often used to test and compare off-policy learning algorithms.
Gradient TD algorithms solved the divergence issue of TD on Baird
counterexample. However, their convergence on this example is still very slow,
and the nature of the slowness is not well understood, e.g., see (Sutton and
Barto 2018).
<br />This note is to understand in particular, why TDC is slow on this example,
and provide debugging analysis to understand this behavior. Our debugging
technique can be used to study the convergence behavior of two-time-scale
stochastic approximation algorithms. We also provide empirical results of the
recent Impression GTD algorithm on this example, showing the convergence is
very fast, in fact, in a linear rate. We conclude that Baird counterexample is
solved, by an algorithm with convergence guarantee to the TD solution in
general and a fast convergence rate.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09733" title="Abstract">arXiv:2308.09733</a> [<a href="/pdf/2308.09733" title="Download PDF">pdf</a>, <a href="/format/2308.09733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intrinsically Motivated Hierarchical Policy Learning in Multi-objective  Markov Decision Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdelfattah%2C+S">Sherif Abdelfattah</a>, 
<a href="/search/cs?searchtype=author&query=Merrick%2C+K">Kathryn Merrick</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jiankun Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Multi-objective Markov decision processes are sequential decision-making
problems that involve multiple conflicting reward functions that cannot be
optimized simultaneously without a compromise. This type of problems cannot be
solved by a single optimal policy as in the conventional case. Alternatively,
multi-objective reinforcement learning methods evolve a coverage set of optimal
policies that can satisfy all possible preferences in solving the problem.
However, many of these methods cannot generalize their coverage sets to work in
non-stationary environments. In these environments, the parameters of the state
transition and reward distribution vary over time. This limitation results in
significant performance degradation for the evolved policy sets. In order to
overcome this limitation, there is a need to learn a generic skill set that can
bootstrap the evolution of the policy coverage set for each shift in the
environment dynamics therefore, it can facilitate a continuous learning
process. In this work, intrinsically motivated reinforcement learning has been
successfully deployed to evolve generic skill sets for learning hierarchical
policies to solve multi-objective Markov decision processes. We propose a novel
dual-phase intrinsically motivated reinforcement learning method to address
this limitation. In the first phase, a generic set of skills is learned. While
in the second phase, this set is used to bootstrap policy coverage sets for
each shift in the environment dynamics. We show experimentally that the
proposed method significantly outperforms state-of-the-art multi-objective
reinforcement methods in a dynamic robotics environment.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09734" title="Abstract">arXiv:2308.09734</a> [<a href="/pdf/2308.09734" title="Download PDF">pdf</a>, <a href="/format/2308.09734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Robust Policy Bootstrapping Algorithm for Multi-objective  Reinforcement Learning in Non-stationary Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdelfattah%2C+S">Sherif Abdelfattah</a>, 
<a href="/search/cs?searchtype=author&query=Kasmarik%2C+K">Kathryn Kasmarik</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jiankun Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Multi-objective Markov decision processes are a special kind of
multi-objective optimization problem that involves sequential decision making
while satisfying the Markov property of stochastic processes. Multi-objective
reinforcement learning methods address this problem by fusing the reinforcement
learning paradigm with multi-objective optimization techniques. One major
drawback of these methods is the lack of adaptability to non-stationary
dynamics in the environment. This is because they adopt optimization procedures
that assume stationarity to evolve a coverage set of policies that can solve
the problem. This paper introduces a developmental optimization approach that
can evolve the policy coverage set while exploring the preference space over
the defined objectives in an online manner. We propose a novel multi-objective
reinforcement learning algorithm that can robustly evolve a convex coverage set
of policies in an online manner in non-stationary environments. We compare the
proposed algorithm with two state-of-the-art multi-objective reinforcement
learning algorithms in stationary and non-stationary environments. Results
showed that the proposed algorithm significantly outperforms the existing
algorithms in non-stationary environments while achieving comparable results in
stationary environments.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09735" title="Abstract">arXiv:2308.09735</a> [<a href="/pdf/2308.09735" title="Download PDF">pdf</a>, <a href="/format/2308.09735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Interpretable Progression Trajectory Analysis of Chronic Disease
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhoujian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenzhuo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhengxing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+N">Nai Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 5 tables, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Chronic disease is the leading cause of death, emphasizing the need for
accurate prediction of disease progression trajectories and informed clinical
decision-making. Machine learning (ML) models have shown promise in this domain
by capturing non-linear patterns within patient features. However, existing
ML-based models lack the ability to provide causal interpretable predictions
and estimate treatment effects, limiting their decision-assisting perspective.
In this study, we propose a novel model called causal trajectory prediction
(CTP) to tackle the limitation. The CTP model combines trajectory prediction
and causal discovery to enable accurate prediction of disease progression
trajectories and uncovering causal relationships between features. By
incorporating a causal graph into the prediction process, CTP ensures that
ancestor features are not influenced by treatment on descendant features,
thereby enhancing the interpretability of the model. By estimating the bounds
of treatment effects, even in the presence of unmeasured confounders, the CTP
provides valuable insights for clinical decision-making. We evaluate the
performance of the CTP using simulated and real medical datasets. Experimental
results demonstrate that our model achieves satisfactory performance,
highlighting its potential to assist clinical decisions.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09764" title="Abstract">arXiv:2308.09764</a> [<a href="/pdf/2308.09764" title="Download PDF">pdf</a>, <a href="/format/2308.09764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Background Removal on Performance of Neural Networks for  Fashion Image Classification and Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Junhui Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Ying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Vlassov%2C+V">Vladimir Vlassov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Fashion understanding is a hot topic in computer vision, with many
applications having great business value in the market. Fashion understanding
remains a difficult challenge for computer vision due to the immense diversity
of garments and various scenes and backgrounds. In this work, we try removing
the background from fashion images to boost data quality and increase model
performance. Having fashion images of evident persons in fully visible
garments, we can utilize Salient Object Detection to achieve the background
removal of fashion data to our expectations. A fashion image with the
background removed is claimed as the "rembg" image, contrasting with the
original one in the fashion dataset. We conducted extensive comparative
experiments with these two types of images on multiple aspects of model
training, including model architectures, model initialization, compatibility
with other training tricks and data augmentations, and target task types. Our
experiments show that background removal can effectively work for fashion data
in simple and shallow networks that are not susceptible to overfitting. It can
improve model accuracy by up to 5% in the classification on the FashionStyle14
dataset when training models from scratch. However, background removal does not
perform well in deep neural networks due to incompatibility with other
regularization techniques like batch normalization, pre-trained initialization,
and data augmentations introducing randomness. The loss of background pixels
invalidates many existing training tricks in the model training, adding the
risk of overfitting for deep models.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09765" title="Abstract">arXiv:2308.09765</a> [<a href="/pdf/2308.09765" title="Download PDF">pdf</a>, <a href="/format/2308.09765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taken by Surprise: Contrast effect for Similarity Scores
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bachlechner%2C+h+C">homas C. Bachlechner</a>, 
<a href="/search/cs?searchtype=author&query=Martone%2C+M">Mario Martone</a>, 
<a href="/search/cs?searchtype=author&query=Schillo%2C+M">Marjorie Schillo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 2 figures and 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Accurately evaluating the similarity of object vector embeddings is of
critical importance for natural language processing, information retrieval and
classification tasks. Popular similarity scores (e.g cosine similarity) are
based on pairs of embedding vectors and disregard the distribution of the
ensemble from which objects are drawn. Human perception of object similarity
significantly depends on the context in which the objects appear. In this work
we propose the \emph{surprise score}, an ensemble-normalized similarity metric
that encapsulates the contrast effect of human perception and significantly
improves the classification performance on zero- and few-shot document
classification tasks. This score quantifies the surprise to find a given
similarity between two elements relative to the pairwise ensemble similarities.
We evaluate this metric on zero/few shot classification and clustering tasks
and typically find 10-15\% better performance compared to raw cosine
similarity. Our code is available at
https://github.com/MeetElise/surprise-similarity.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09766" title="Abstract">arXiv:2308.09766</a> [<a href="/pdf/2308.09766" title="Download PDF">pdf</a>, <a href="/format/2308.09766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time Series Predictions in Unmonitored Sites: A Survey of Machine  Learning Techniques in Water Resources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Willard%2C+J+D">Jared D. Willard</a>, 
<a href="/search/cs?searchtype=author&query=Varadharajan%2C+C">Charuleka Varadharajan</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiaowei Jia</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vipin Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 4 figures, 1 table, submitted to Environmental Data Science
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Prediction of dynamic environmental variables in unmonitored sites remains a
long-standing challenge for water resources science. The majority of the
world's freshwater resources have inadequate monitoring of critical
environmental variables needed for management. Yet, the need to have widespread
predictions of hydrological variables such as river flow and water quality has
become increasingly urgent due to climate and land use change over the past
decades, and their associated impacts on water resources. Modern machine
learning methods increasingly outperform their process-based and empirical
model counterparts for hydrologic time series prediction with their ability to
extract information from large, diverse data sets. We review relevant
state-of-the art applications of machine learning for streamflow, water
quality, and other water resources prediction and discuss opportunities to
improve the use of machine learning with emerging methods for incorporating
watershed characteristics into deep learning models, transfer learning, and
incorporating process knowledge into machine learning models. The analysis here
suggests most prior efforts have been focused on deep learning learning
frameworks built on many sites for predictions at daily time scales in the
United States, but that comparisons between different classes of machine
learning methods are few and inadequate. We identify several open questions for
time series predictions in unmonitored sites that include incorporating dynamic
inputs and site characteristics, mechanistic understanding and spatial context,
and explainable AI techniques in modern machine learning frameworks.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09767" title="Abstract">arXiv:2308.09767</a> [<a href="/pdf/2308.09767" title="Download PDF">pdf</a>, <a href="/ps/2308.09767" title="Download PostScript">ps</a>, <a href="/format/2308.09767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Stochastic Rewards Reduce to Deterministic Rewards in Online  Bipartite Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Udwani%2C+R">Rajan Udwani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study the problem of vertex-weighted online bipartite matching with
stochastic rewards where matches may fail with some known probability and the
decision maker has to adapt to the sequential realization of these outcomes.
Recent works have studied several special cases of this problem and it was
known that the (randomized) Perturbed Greedy algorithm due to Aggarwal et al.
(SODA, 2011) achieves the best possible competitive ratio guarantee of
$(1-1/e)$ in some cases. We give a simple proof of these results by reducing
(special cases of) the stochastic rewards problem to the deterministic setting
of online bipartite matching (Karp, Vazirani, Vazirani (STOC, 1990)). More
broadly, our approach gives conditions under which it suffices to analyze the
competitive ratio of an algorithm for the simpler setting of deterministic
rewards in order to obtain a competitive ratio guarantee for stochastic
rewards. The simplicity of our approach reveals that the Perturbed Greedy
algorithm has a competitive ratio of $(1-1/e)$ even in certain settings with
correlated rewards, where no results were previously known. Finally, we show
that without any special assumptions, the Perturbed Greedy algorithm has a
competitive ratio strictly less than $(1-1/e)$ for vertex-weighted online
matching with stochastic rewards.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09768" title="Abstract">arXiv:2308.09768</a> [<a href="/pdf/2308.09768" title="Download PDF">pdf</a>, <a href="/format/2308.09768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> YORC: Yoruba Reading Comprehension dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aremu%2C+A">Anuoluwapo Aremu</a>, 
<a href="/search/cs?searchtype=author&query=Alabi%2C+J+O">Jesujoba O. Alabi</a>, 
<a href="/search/cs?searchtype=author&query=Adelani%2C+D+I">David Ifeoluwa Adelani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this paper, we create YORC: a new multi-choice Yoruba Reading
Comprehension dataset that is based on Yoruba high-school reading comprehension
examination. We provide baseline results by performing cross-lingual transfer
using existing English RACE dataset based on a pre-trained encoder-only model.
Additionally, we provide results by prompting large language models (LLMs) like
GPT-4.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09775" title="Abstract">arXiv:2308.09775</a> [<a href="/pdf/2308.09775" title="Download PDF">pdf</a>, <a href="/format/2308.09775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long-range Multimodal Pretraining for Movie Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Argaw%2C+D+M">Dawit Mureja Argaw</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Joon-Young Lee</a>, 
<a href="/search/cs?searchtype=author&query=Woodson%2C+M">Markus Woodson</a>, 
<a href="/search/cs?searchtype=author&query=Kweon%2C+I+S">In So Kweon</a>, 
<a href="/search/cs?searchtype=author&query=Heilbron%2C+F+C">Fabian Caba Heilbron</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learning computer vision models from (and for) movies has a long-standing
history. While great progress has been attained, there is still a need for a
pretrained multimodal model that can perform well in the ever-growing set of
movie understanding tasks the community has been establishing. In this work, we
introduce Long-range Multimodal Pretraining, a strategy, and a model that
leverages movie data to train transferable multimodal and cross-modal encoders.
Our key idea is to learn from all modalities in a movie by observing and
extracting relationships over a long-range. After pretraining, we run ablation
studies on the LVU benchmark and validate our modeling choices and the
importance of learning from long-range time spans. Our model achieves
state-of-the-art on several LVU tasks while being much more data efficient than
previous works. Finally, we evaluate our model's transferability by setting a
new state-of-the-art in five different benchmarks.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09778" title="Abstract">arXiv:2308.09778</a> [<a href="/pdf/2308.09778" title="Download PDF">pdf</a>, <a href="/format/2308.09778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Grounded Visual Spatial Reasoning in Multi-Modal Vision Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajabi%2C+N">Navid Rajabi</a>, 
<a href="/search/cs?searchtype=author&query=Kosecka%2C+J">Jana Kosecka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">With the advances in large scale vision-and-language models (VLMs) it is of
interest to assess their performance on various visual reasoning tasks such as
counting, referring expressions and general visual question answering. The
focus of this work is to study the ability of these models to understanding
spatial relations. Previously, this has been tackled using image-text matching
(Liu, Emerson, and Collier 2022) or visual question answering task, both
showing poor performance and a large gap compared to human performance. To
better understand the gap, we present fine-grained compositional grounding of
spatial relationships and propose a bottom up approach for ranking spatial
clauses and evaluating the performance of spatial relationship reasoning task.
We propose to combine the evidence from grounding noun phrases corresponding to
objects and their locations to compute the final rank of the spatial clause. We
demonstrate the approach on representative vision-language models (Tan and
Bansal 2019; Gupta et al. 2022; Kamath et al. 2021) and compare and highlight
their abilities to reason about spatial relationships.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09779" title="Abstract">arXiv:2308.09779</a> [<a href="/pdf/2308.09779" title="Download PDF">pdf</a>, <a href="/format/2308.09779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EAVL: Explicitly Align Vision and Language for Referring Image  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yichen Yan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xingjian He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sihan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Referring image segmentation aims to segment an object mentioned in natural
language from an image. A main challenge is language-related localization,
which means locating the object with the relevant language. Previous approaches
mainly focus on the fusion of vision and language features without fully
addressing language-related localization. In previous approaches, fused
vision-language features are directly fed into a decoder and pass through a
convolution with a fixed kernel to obtain the result, which follows a similar
pattern as traditional image segmentation. This approach does not explicitly
align language and vision features in the segmentation stage, resulting in a
suboptimal language-related localization. Different from previous methods, we
propose Explicitly Align the Vision and Language for Referring Image
Segmentation (EAVL). Instead of using a fixed convolution kernel, we propose an
Aligner which explicitly aligns the vision and language features in the
segmentation stage. Specifically, a series of unfixed convolution kernels are
generated based on the input l, and then are use to explicitly align the vision
and language features. To achieve this, We generate multiple queries that
represent different emphases of the language expression. These queries are
transformed into a series of query-based convolution kernels. Then, we utilize
these kernels to do convolutions in the segmentation stage and obtain a series
of segmentation masks. The final result is obtained through the aggregation of
all masks. Our method can not only fuse vision and language features
effectively but also exploit their potential in the segmentation stage. And
most importantly, we explicitly align language features of different emphases
with the image features to achieve language-related localization. Our method
surpasses previous state-of-the-art methods on RefCOCO, RefCOCO+, and G-Ref by
large margins.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09780" title="Abstract">arXiv:2308.09780</a> [<a href="/pdf/2308.09780" title="Download PDF">pdf</a>, <a href="/format/2308.09780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Event-based Dynamic Graph Representation Learning for Patent Application  Trend Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+T">Tao Zou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Le Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Leilei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+B">Bowen Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Deqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+F">Fuzhen Zhuang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Accurate prediction of what types of patents that companies will apply for in
the next period of time can figure out their development strategies and help
them discover potential partners or competitors in advance. Although important,
this problem has been rarely studied in previous research due to the challenges
in modelling companies' continuously evolving preferences and capturing the
semantic correlations of classification codes. To fill in this gap, we propose
an event-based dynamic graph learning framework for patent application trend
prediction. In particular, our method is founded on the memorable
representations of both companies and patent classification codes. When a new
patent is observed, the representations of the related companies and
classification codes are updated according to the historical memories and the
currently encoded messages. Moreover, a hierarchical message passing mechanism
is provided to capture the semantic proximities of patent classification codes
by updating their representations along the hierarchical taxonomy. Finally, the
patent application trend is predicted by aggregating the representations of the
target company and classification codes from static, dynamic, and hierarchical
perspectives. Experiments on real-world data demonstrate the effectiveness of
our approach under various experimental conditions, and also reveal the
abilities of our method in learning semantics of classification codes and
tracking technology developing trajectories of companies.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09788" title="Abstract">arXiv:2308.09788</a> [<a href="/pdf/2308.09788" title="Download PDF">pdf</a>, <a href="/ps/2308.09788" title="Download PostScript">ps</a>, <a href="/format/2308.09788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Optimization of IRS Deployment and Passive Beamforming to Enhance  the Received Power
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rani%2C+J">Jyotsna Rani</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+D">Deepak Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Prasad%2C+G">Ganesh Prasad</a>, 
<a href="/search/cs?searchtype=author&query=Hossain%2C+A">Ashraf Hossain</a>, 
<a href="/search/cs?searchtype=author&query=De%2C+S">Swades De</a>, 
<a href="/search/cs?searchtype=author&query=Deka%2C+K">Kuntal Deka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Intelligent reflecting surface (IRS) has recently emerged as a promising
technology for beyond fifth-generation (B5G) and 6G networks conceived from
metamaterials that smartly tunes the signal reflections via a large number of
low-cost passive reflecting elements. However, the IRS-assisted communication
model and the optimization of available resources needs to be improved further
for more efficient communications. This paper investigates the enhancement of
received power at the user end in an IRS assisted wireless communication by
jointly optimizing the phase shifts at the IRS elements and its location.
Employing the conventional Friss transmission model, the relationship between
the transmitted power and reflected power is established. The expression of
received power incorporates the free space loss, reflection loss factor,
physical dimension of the IRS panel, and radiation pattern of the transmit
signal. Also, the expression of reflection coefficient of IRS panel is obtained
by exploiting the existing data of radar communications. Initially exploring a
single IRS element within a two-ray reflection model, we extend it to a more
complex multi-ray reflection model with multiple IRS elements in 3D Cartesian
space. The received power expression is derived in a more tractable form, then,
it is maximized by jointly optimizing the underlying underlying variables, the
IRS location and the phase shifts. To realize the joint optimization of
underlying variables, first, the phase shifts of the IRS elements are optimized
to achieve constructive interference of received signal components at the user.
Subsequently, the location of the IRS is optimized at the obtained optimal
phase shifts. Numerical insights and performance comparison reveal that joint
optimization leads to a substantial 37% enhancement in received power compared
to the closest competitive benchmark scheme.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09791" title="Abstract">arXiv:2308.09791</a> [<a href="/pdf/2308.09791" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient High-Dimensional Gene Selection Approach based on Binary  Horse Herd Optimization Algorithm for Biological Data Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehrabi%2C+N">Niloufar Mehrabi</a>, 
<a href="/search/cs?searchtype=author&query=Boroujeni%2C+S+P+H">Sayed Pedram Haeri Boroujeni</a>, 
<a href="/search/cs?searchtype=author&query=Pashaei%2C+E">Elnaz Pashaei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The Horse Herd Optimization Algorithm (HOA) is a new meta-heuristic algorithm
based on the behaviors of horses at different ages. The HOA was introduced
recently to solve complex and high-dimensional problems. This paper proposes a
binary version of the Horse Herd Optimization Algorithm (BHOA) in order to
solve discrete problems and select prominent feature subsets. Moreover, this
study provides a novel hybrid feature selection framework based on the BHOA and
a minimum Redundancy Maximum Relevance (MRMR) filter method. This hybrid
feature selection, which is more computationally efficient, produces a
beneficial subset of relevant and informative features. Since feature selection
is a binary problem, we have applied a new Transfer Function (TF), called
X-shape TF, which transforms continuous problems into binary search spaces.
Furthermore, the Support Vector Machine (SVM) is utilized to examine the
efficiency of the proposed method on ten microarray datasets, namely Lymphoma,
Prostate, Brain-1, DLBCL, SRBCT, Leukemia, Ovarian, Colon, Lung, and MLL. In
comparison to other state-of-the-art, such as the Gray Wolf (GW), Particle
Swarm Optimization (PSO), and Genetic Algorithm (GA), the proposed hybrid
method (MRMR-BHOA) demonstrates superior performance in terms of accuracy and
minimum selected features. Also, experimental results prove that the X-Shaped
BHOA approach outperforms others methods.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09793" title="Abstract">arXiv:2308.09793</a> [<a href="/pdf/2308.09793" title="Download PDF">pdf</a>, <a href="/format/2308.09793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Modular Architecture for Science Factories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vescovi%2C+R">Rafael Vescovi</a>, 
<a href="/search/cs?searchtype=author&query=Ginsburg%2C+T">Tobias Ginsburg</a>, 
<a href="/search/cs?searchtype=author&query=Hippe%2C+K">Kyle Hippe</a>, 
<a href="/search/cs?searchtype=author&query=Ozgulbas%2C+D">Doga Ozgulbas</a>, 
<a href="/search/cs?searchtype=author&query=Stone%2C+C">Casey Stone</a>, 
<a href="/search/cs?searchtype=author&query=Stroka%2C+A">Abraham Stroka</a>, 
<a href="/search/cs?searchtype=author&query=Butler%2C+R">Rory Butler</a>, 
<a href="/search/cs?searchtype=author&query=Blaiszik%2C+B">Ben Blaiszik</a>, 
<a href="/search/cs?searchtype=author&query=Brettin%2C+T">Tom Brettin</a>, 
<a href="/search/cs?searchtype=author&query=Chard%2C+K">Kyle Chard</a>, 
<a href="/search/cs?searchtype=author&query=Hereld%2C+M">Mark Hereld</a>, 
<a href="/search/cs?searchtype=author&query=Ramanathan%2C+A">Arvind Ramanathan</a>, 
<a href="/search/cs?searchtype=author&query=Stevens%2C+R">Rick Stevens</a>, 
<a href="/search/cs?searchtype=author&query=Vriza%2C+A">Aikaterini Vriza</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingteng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Foster%2C+I">Ian Foster</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Advances in robotic automation, high-performance computing (HPC), and
artificial intelligence (AI) encourage us to conceive of science factories:
large, general-purpose computation- and AI-enabled self-driving laboratories
(SDLs) with the generality and scale needed both to tackle large discovery
problems and to support thousands of scientists. Science factories require
modular hardware and software that can be replicated for scale and
(re)configured to support many applications. To this end, we propose a
prototype modular science factory architecture in which reconfigurable modules
encapsulating scientific instruments are linked with manipulators to form
workcells, that can themselves be combined to form larger assemblages, and
linked with distributed computing for simulation, AI model training and
inference, and related tasks. Workflows that perform sets of actions on modules
can be specified, and various applications, comprising workflows plus
associated computational and data manipulation steps, can be run concurrently.
We report on our experiences prototyping this architecture and applying it in
experiments involving 15 different robotic apparatus, five applications (one in
education, two in biology, two in materials), and a variety of workflows,
across four laboratories. We describe the reuse of modules, workcells, and
workflows in different applications, the migration of applications between
workcells, and the use of digital twins, and suggest directions for future work
aimed at yet more generality and scalability. Code and data are available at
https://ad-sdl.github.io/wei2023 and in the Supplementary Information
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09798" title="Abstract">arXiv:2308.09798</a> [<a href="/pdf/2308.09798" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling the Collaborative Patterns of Artificial Intelligence  Applications in Human Resource Management: A Social Network Analysis Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maghsoudi%2C+M">Mehrdad Maghsoudi</a>, 
<a href="/search/cs?searchtype=author&query=Shahri%2C+M+K">Motahareh Kamrani Shahri</a>, 
<a href="/search/cs?searchtype=author&query=Kermani%2C+M+A+M+A">Mehrdad Agha Mohammad Ali Kermani</a>, 
<a href="/search/cs?searchtype=author&query=Khanizad%2C+R">Rahim Khanizad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">The integration of artificial intelligence (AI) into human resource
management (HRM) strategies has become increasingly common due to technological
advancements. This has spurred a new field of research focused on evaluating
the impact of AI adoption on business and individual outcomes, as well as how
to evaluate AI-enabled HRM practices. However, there is limited
cross-disciplinary research in this area, causing a fragmented body of
knowledge. To address this issue, social network analysis has been recognized
as a tool for analyzing and researching large-scale social phenomena in HRM.
The study of scientific co-authorship networks is one application of social
network analysis that can help identify the main components and trends in this
field. Using social network analysis indicators, the current study examined the
AI&amp;HRM co-authorship network, which consists of 43,789 members and 81,891
scientific collaborations. The study analyzed articles related to AI&amp;HRM
published between 2000 and 2023 extracted from the WOS citation database.
Through centrality measures, the most important members of the "AI&amp;HRM"
co-authorship network were identified using the TOPSIS method, which identified
twenty prominent researchers in this field. The study also examined the
keywords "AI&amp;HRM" and the scientific cooperation network of nations,
universities, and communities. Overall, this study highlights the importance of
cross-disciplinary research and social network analysis in understanding the
implications of AI adoption in HRM.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09802" title="Abstract">arXiv:2308.09802</a> [<a href="/pdf/2308.09802" title="Download PDF">pdf</a>, <a href="/format/2308.09802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WHATSNEXT: Guidance-enriched Exploratory Data Analysis with Interactive,  Low-Code Notebooks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hoffswell%2C+J">Jane Hoffswell</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Shunan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+R">Ryan Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+Y">Yeuk-Yin Chan</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+F">Fan Du</a>, 
<a href="/search/cs?searchtype=author&query=Koh%2C+E">Eunyee Koh</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhicheng Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to appear in VL/HCC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Computational notebooks such as Jupyter are popular for exploratory data
analysis and insight finding. Despite the module-based structure, notebooks
visually appear as a single thread of interleaved cells containing text, code,
visualizations, and tables, which can be unorganized and obscure users' data
analysis workflow. Furthermore, users with limited coding expertise may
struggle to quickly engage in the analysis process. In this work, we design and
implement an interactive notebook framework, WHATSNEXT, with the goal of
supporting low-code visual data exploration with insight-based user guidance.
In particular, we (1) re-design a standard notebook cell to include a
recommendation panel that suggests possible next-step exploration questions or
analysis actions to take, and (2) create an interactive, dynamic tree
visualization that reflects the analytic dependencies between notebook cells to
make it easy for users to see the structure of the data exploration threads and
trace back to previous steps.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09804" title="Abstract">arXiv:2308.09804</a> [<a href="/pdf/2308.09804" title="Download PDF">pdf</a>, <a href="/format/2308.09804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VL-PET: Vision-and-Language Parameter-Efficient Tuning via Granularity  Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zi-Yuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+M+R">Michael R. Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liwei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 (17 pages, 6 figures, 22 tables)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">As the model size of pre-trained language models (PLMs) grows rapidly, full
fine-tuning becomes prohibitively expensive for model training and storage. In
vision-and-language (VL), parameter-efficient tuning (PET) techniques are
proposed to integrate modular modifications (e.g., Adapter and LoRA) into
encoder-decoder PLMs. By tuning a small set of trainable parameters, these
techniques perform on par with full fine-tuning. However, excessive modular
modifications and neglecting the functionality gap between the encoders and
decoders can lead to performance degradation, while existing PET techniques
(e.g., VL-Adapter) overlook these critical issues. In this paper, we propose a
Vision-and-Language Parameter-Efficient Tuning (VL-PET) framework to impose
effective control over modular modifications via a novel granularity-controlled
mechanism. Considering different granularity-controlled matrices generated by
this mechanism, a variety of model-agnostic VL-PET modules can be instantiated
from our framework for better efficiency and effectiveness trade-offs. We
further propose lightweight PET module designs to enhance VL alignment and
modeling for the encoders and maintain text generation for the decoders.
Extensive experiments conducted on four image-text tasks and four video-text
tasks demonstrate the efficiency, effectiveness and transferability of our
VL-PET framework. In particular, our VL-PET-large with lightweight PET module
designs significantly outperforms VL-Adapter by 2.92% (3.41%) and LoRA by 3.37%
(7.03%) with BART-base (T5-base) on image-text tasks. Furthermore, we validate
the enhanced effect of employing our VL-PET designs on existing PET techniques,
enabling them to achieve significant performance improvements. Our code is
available at https://github.com/HenryHZY/VL-PET.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09809" title="Abstract">arXiv:2308.09809</a> [<a href="/pdf/2308.09809" title="Download PDF">pdf</a>, <a href="/format/2308.09809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Timers and Buffer Optimization for Layer-2 Protocols in 5G  Non-Terrestrial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sheemar%2C+C+K">Chandan Kumar Sheemar</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sumit Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Querol%2C+J">Jorge Querol</a>, 
<a href="/search/cs?searchtype=author&query=Chatzinotas%2C+S">Symeon Chatzinotas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Interest in the integration of Terrestrial Networks (TN) and Non-Terrestrial
Networks (NTN); primarily satellites; has been rekindled due to the potential
of NTN to provide ubiquitous coverage. Especially with the peculiar and
flexible physical layer properties of 5G-NR, now direct access to 5G services
through satellites could become possible. However, the large Round-Trip Delays
(RTD) in NTNs require a re-evaluation of the design of RLC and PDCP layers
timers ( and associated buffers), in particular for the regenerative payload
satellites which have limited computational resources, and hence need to be
optimally utilized. Our aim in this work is to initiate a new line of research
for emerging NTNs with limited resources from a higher-layer perspective. To
this end, we propose a novel and efficient method for optimally designing the
RLC and PDCP layers' buffers and timers without the need for intensive
computations. This approach is relevant for low-cost satellites, which have
limited computational and energy resources. The simulation results show that
the proposed methods can significantly improve the performance in terms of
resource utilization and delays.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09810" title="Abstract">arXiv:2308.09810</a> [<a href="/pdf/2308.09810" title="Download PDF">pdf</a>, <a href="/format/2308.09810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Image is Worth a Thousand Toxic Words: A Metamorphic Testing  Framework for Content Moderation Software
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jingyuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jen-tse Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiazhen Gu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+P">Pinjia He</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+M+R">Michael R. Lyu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ASE 2023. arXiv admin note: substantial text overlap with <a href="/abs/2302.05706">arXiv:2302.05706</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The exponential growth of social media platforms has brought about a
revolution in communication and content dissemination in human society.
Nevertheless, these platforms are being increasingly misused to spread toxic
content, including hate speech, malicious advertising, and pornography, leading
to severe negative consequences such as harm to teenagers' mental health.
Despite tremendous efforts in developing and deploying textual and image
content moderation methods, malicious users can evade moderation by embedding
texts into images, such as screenshots of the text, usually with some
interference. We find that modern content moderation software's performance
against such malicious inputs remains underexplored. In this work, we propose
OASIS, a metamorphic testing framework for content moderation software. OASIS
employs 21 transform rules summarized from our pilot study on 5,000 real-world
toxic contents collected from 4 popular social media applications, including
Twitter, Instagram, Sina Weibo, and Baidu Tieba. Given toxic textual contents,
OASIS can generate image test cases, which preserve the toxicity yet are likely
to bypass moderation. In the evaluation, we employ OASIS to test five
commercial textual content moderation software from famous companies (i.e.,
Google Cloud, Microsoft Azure, Baidu Cloud, Alibaba Cloud and Tencent Cloud),
as well as a state-of-the-art moderation research model. The results show that
OASIS achieves up to 100% error finding rates. Moreover, through retraining the
models with the test cases generated by OASIS, the robustness of the moderation
model can be improved without performance degradation.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09811" title="Abstract">arXiv:2308.09811</a> [<a href="/pdf/2308.09811" title="Download PDF">pdf</a>, <a href="/format/2308.09811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DoCRL: Double Critic Deep Reinforcement Learning for Mapless Navigation  of a Hybrid Aerial Underwater Vehicle with Medium Transition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grando%2C+R+B">Ricardo B. Grando</a>, 
<a href="/search/cs?searchtype=author&query=de+Jesus%2C+J+C">Junior C. de Jesus</a>, 
<a href="/search/cs?searchtype=author&query=Kich%2C+V+A">Victor A. Kich</a>, 
<a href="/search/cs?searchtype=author&query=Kolling%2C+A+H">Alisson H. Kolling</a>, 
<a href="/search/cs?searchtype=author&query=Guerra%2C+R+S">Rodrigo S. Guerra</a>, 
<a href="/search/cs?searchtype=author&query=J.%2C+P+L">Paulo L. J. Drews-Jr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the Latin American Symposium 2023. arXiv admin note: substantial text overlap with <a href="/abs/2209.06332">arXiv:2209.06332</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Deep Reinforcement Learning (Deep-RL) techniques for motion control have been
continuously used to deal with decision-making problems for a wide variety of
robots. Previous works showed that Deep-RL can be applied to perform mapless
navigation, including the medium transition of Hybrid Unmanned Aerial
Underwater Vehicles (HUAUVs). These are robots that can operate in both air and
water media, with future potential for rescue tasks in robotics. This paper
presents new approaches based on the state-of-the-art Double Critic
Actor-Critic algorithms to address the navigation and medium transition
problems for a HUAUV. We show that double-critic Deep-RL with Recurrent Neural
Networks using range data and relative localization solely improves the
navigation performance of HUAUVs. Our DoCRL approaches achieved better
navigation and transitioning capability, outperforming previous approaches.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09812" title="Abstract">arXiv:2308.09812</a> [<a href="/pdf/2308.09812" title="Download PDF">pdf</a>, <a href="/format/2308.09812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reliability and Delay Analysis of 3-Dimensional Networks with  Multi-Connectivity: Satellite, HAPs, and Cellular Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Salehi%2C+F">Fateme Salehi</a>, 
<a href="/search/eess?searchtype=author&query=Ozger%2C+M">Mustafa Ozger</a>, 
<a href="/search/eess?searchtype=author&query=Cavdar%2C+C">Cicek Cavdar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 10 figures, accepted to be published in IEEE TNSM journal. arXiv admin note: text overlap with <a href="/abs/2205.06046">arXiv:2205.06046</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Aerial vehicles (AVs) such as electric vertical take-off and landing (eVTOL)
aircraft make aerial passenger transportation a reality in urban environments.
However, their communication connectivity is still under research to realize
their safe and full-scale operation. This paper envisages a multi-connectivity
(MC) enabled aerial network to provide ubiquitous and reliable service to AVs.
Vertical heterogeneous networks with direct air-to-ground (DA2G) and air-to-air
(A2A) communication, high altitude platforms (HAPs), and low Earth orbit (LEO)
satellites are considered. We evaluate the end-to-end (E2E) multi-hop
reliability and network availability of the downlink of AVs for remote piloting
scenarios, and control/telemetry traffic. Command and control (C2) connectivity
service requires ultra-reliable and low-latency communication (URLLC),
therefore we analyse E2E reliability and latency under the finite blocklength
(FBL) regime. We explore how different MC options satisfy the demanding E2E
connectivity requirements taking into account antenna radiation patterns and
unreliable backhaul links. Since providing seamless connectivity to AVs is very
challenging due to the line-of-sight (LoS) interference and reduced gains of
downtilt ground base station (BS) antennas, we use coordinated multi-point
(CoMP) among ground BSs to alleviate the inter-cell interference. Furthermore,
we solve an optimization problem to select the best MC path under the quality
of service (QoS) constraints. We maximize spectral efficiency (SE) to specify
the optimum MC path with the minimum number of required links. Based on the
simulation results, we find out that even with very efficient interference
mitigation, MC is the key enabler for safe remote piloting operations.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09813" title="Abstract">arXiv:2308.09813</a> [<a href="/pdf/2308.09813" title="Download PDF">pdf</a>, <a href="/format/2308.09813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reach For the Spheres: Tangency-Aware Surface Reconstruction of SDFs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sell%C3%A1n%2C+S">Silvia Sell&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Batty%2C+C">Christopher Batty</a>, 
<a href="/search/cs?searchtype=author&query=Stein%2C+O">Oded Stein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://odedstein.com/projects/reach-for-the-spheres/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">Signed distance fields (SDFs) are a widely used implicit surface
representation, with broad applications in computer graphics, computer vision,
and applied mathematics. To reconstruct an explicit triangle mesh surface
corresponding to an SDF, traditional isosurfacing methods, such as Marching
Cubes and and its variants, are typically used. However, these methods overlook
fundamental properties of SDFs, resulting in reconstructions that exhibit
severe oversmoothing and feature loss. To address this shortcoming, we propose
a novel method based on a key insight: each SDF sample corresponds to a
spherical region that must lie fully inside or outside the surface, depending
on its sign, and that must be tangent to the surface at some point. Leveraging
this understanding, we formulate an energy that gauges the degree of violation
of tangency constraints by a proposed surface. We then employ a gradient flow
that minimizes our energy, starting from an initial triangle mesh that
encapsulates the surface. This algorithm yields superior reconstructions to
previous methods, even with sparsely sampled SDFs. Our approach provides a more
nuanced understanding of SDFs and offers significant improvements in surface
reconstruction.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09829" title="Abstract">arXiv:2308.09829</a> [<a href="/pdf/2308.09829" title="Download PDF">pdf</a>, <a href="/format/2308.09829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning from A Single Graph is All You Need for Near-Shortest Path  Routing in Wireless Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yung-Fu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Sen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+A">Anish Arora</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">We propose a learning algorithm for local routing policies that needs only a
few data samples obtained from a single graph while generalizing to all random
graphs in a standard model of wireless networks. We thus solve the all-pairs
near-shortest path problem by training deep neural networks (DNNs) that
efficiently and scalably learn routing policies that are local, i.e., they only
consider node states and the states of neighboring nodes. Remarkably, one of
these DNNs we train learns a policy that exactly matches the performance of
greedy forwarding; another generally outperforms greedy forwarding. Our
algorithm design exploits network domain knowledge in several ways: First, in
the selection of input features and, second, in the selection of a ``seed
graph'' and subsamples from its shortest paths. The leverage of domain
knowledge provides theoretical explainability of why the seed graph and node
subsampling suffice for learning that is efficient, scalable, and
generalizable. Simulation-based results on uniform random graphs with diverse
sizes and densities empirically corroborate that using samples generated from a
few routing paths in a modest-sized seed graph quickly learns a model that is
generalizable across (almost) all random graphs in the wireless network model.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09830" title="Abstract">arXiv:2308.09830</a> [<a href="/pdf/2308.09830" title="Download PDF">pdf</a>, <a href="/format/2308.09830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synergistic Integration of Large Language Models and Cognitive  Architectures for Robust AI: An Exploratory Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Romero%2C+O+J">Oscar J. Romero</a>, 
<a href="/search/cs?searchtype=author&query=Zimmerman%2C+J">John Zimmerman</a>, 
<a href="/search/cs?searchtype=author&query=Steinfeld%2C+A">Aaron Steinfeld</a>, 
<a href="/search/cs?searchtype=author&query=Tomasic%2C+A">Anthony Tomasic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2023 Fall Symposium
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This paper explores alternatives for integrating two subdisciplines of AI in
the construction of artificial agents that exhibit intelligent behavior: Large
Language Models (LLMs) and Cognitive Architectures (CAs). Guided by theoretical
models and supported by preliminary empirical data, we hypothesize how diverse
synergistic approaches can mutually compensate for their respective weaknesses
and limitations, ultimately fostering more robust and sophisticated artificial
intelligence systems. Additionally, we discuss the tradeoffs and challenges
associated with each approach.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09835" title="Abstract">arXiv:2308.09835</a> [<a href="/pdf/2308.09835" title="Download PDF">pdf</a>, <a href="/format/2308.09835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Microscopy Image Segmentation via Point and Shape Regularized Data  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shijie Li</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+M">Mengwei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Ach%2C+T">Thomas Ach</a>, 
<a href="/search/cs?searchtype=author&query=Gerig%2C+G">Guido Gerig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by The 3rd MICCAI Workshop on Data Augmentation, Labeling, and Imperfections
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Current deep learning-based approaches for the segmentation of microscopy
images heavily rely on large amount of training data with dense annotation,
which is highly costly and laborious in practice. Compared to full annotation
where the complete contour of objects is depicted, point annotations,
specifically object centroids, are much easier to acquire and still provide
crucial information about the objects for subsequent segmentation. In this
paper, we assume access to point annotations only during training and develop a
unified pipeline for microscopy image segmentation using synthetically
generated training data. Our framework includes three stages: (1) it takes
point annotations and samples a pseudo dense segmentation mask constrained with
shape priors; (2) with an image generative model trained in an unpaired manner,
it translates the mask to a realistic microscopy image regularized by object
level consistency; (3) the pseudo masks along with the synthetic images then
constitute a pairwise dataset for training an ad-hoc segmentation model. On the
public MoNuSeg dataset, our synthesis pipeline produces more diverse and
realistic images than baseline models while maintaining high coherence between
input masks and generated images. When using the identical segmentation
backbones, the models trained on our synthetic dataset significantly outperform
those trained with pseudo-labels or baseline-generated images. Moreover, our
framework achieves comparable results to models trained on authentic microscopy
images with dense labels, demonstrating its potential as a reliable and highly
efficient alternative to labor-intensive manual pixel-wise annotations in
microscopy image segmentation. The code is available.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09836" title="Abstract">arXiv:2308.09836</a> [<a href="/pdf/2308.09836" title="Download PDF">pdf</a>, <a href="/format/2308.09836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wheeler maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bal%C3%A1z%2C+A">Andrej Bal&#xe1;z</a>, 
<a href="/search/cs?searchtype=author&query=Gagie%2C+T">Travis Gagie</a>, 
<a href="/search/cs?searchtype=author&query=Goga%2C+A">Adri&#xe1;n Goga</a>, 
<a href="/search/cs?searchtype=author&query=Heumos%2C+S">Simon Heumos</a>, 
<a href="/search/cs?searchtype=author&query=Navarro%2C+G">Gonzalo Navarro</a>, 
<a href="/search/cs?searchtype=author&query=Petescia%2C+A">Alessia Petescia</a>, 
<a href="/search/cs?searchtype=author&query=Sir%C3%A9n%2C+J">Jouni Sir&#xe9;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Motivated by challenges in pangenomic read alignment, we propose a
generalization of Wheeler graphs that we call Wheeler maps. A Wheeler map
stores a text $T[1..n]$ and an assignment of tags to the characters of $T$ such
that we can preprocess a pattern $P[1..m]$ and then, given $i$ and $j$, quickly
return all the distinct tags labeling the first characters of the occurrences
of $P[i..j]$ in $T$. For the applications that most interest us, characters
with long common contexts are likely to have the same tag, so we consider the
number $t$ of runs in the list of tags sorted by their characters' positions in
the Burrows-Wheeler Transform (BWT) of $T$. We show how, given a straight-line
program with $g$ rules for $T$, we can build an $O(g + r + t)$-space Wheeler
map, where $r$ is the number of runs in the BWT of $T$, with which we can
preprocess a pattern $P[1..m]$ in $O(m \log n)$ time and then return the $k$
distinct tags for $P[i..j]$ in optimal $O(k)$ time for any given $i$ and $j$.
We show various further results related to prioritizing the most frequent tags.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09837" title="Abstract">arXiv:2308.09837</a> [<a href="/pdf/2308.09837" title="Download PDF">pdf</a>, <a href="/ps/2308.09837" title="Download PostScript">ps</a>, <a href="/format/2308.09837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Field theory with the Maxima computer algebra system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Toth%2C+V+T">Viktor T. Toth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; General Relativity and Quantum Cosmology (gr-qc); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">The Maxima computer algebra system, the open-source successor to MACSYMA, the
first general-purpose computer algebra system that was initially developed at
the Massachusetts Institute of Technology in the late 1960s and later
distributed by the United States Department of Energy, has some remarkable
capabilities, some of which are implemented in the form of add-on, "share"
packages that are distributed along with the core Maxima system. One such share
package is itensor, for indicial tensor manipulation. One of the more
remarkable features of itensor is functional differentiation. Through this, it
is possible to use itensor to develop a Lagrangian field theory and derive the
corresponding field equations. In the present note, we demonstrate this
capability by deriving Maxwell's equations from the Maxwell Lagrangian, and
exploring the properties of the system, including current conservation.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09839" title="Abstract">arXiv:2308.09839</a> [<a href="/pdf/2308.09839" title="Download PDF">pdf</a>, <a href="/format/2308.09839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performant low-order matrix-free finite element kernels on GPU  architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Settgast%2C+R+R">Randolph R. Settgast</a>, 
<a href="/search/math?searchtype=author&query=Dudouit%2C+Y">Yohann Dudouit</a>, 
<a href="/search/math?searchtype=author&query=Castelletto%2C+N">Nicola Castelletto</a>, 
<a href="/search/math?searchtype=author&query=Tobin%2C+W+R">William R. Tobin</a>, 
<a href="/search/math?searchtype=author&query=Corbett%2C+B+C">Benjamin C. Corbett</a>, 
<a href="/search/math?searchtype=author&query=Klevtsov%2C+S">Sergey Klevtsov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Software (cs.MS)

</div>
<p class="mathjax">Numerical methods such as the Finite Element Method (FEM) have been
successfully adapted to utilize the computational power of GPU accelerators.
However, much of the effort around applying FEM to GPU's has been focused on
high-order FEM due to higher arithmetic intensity and order of accuracy. For
applications such as the simulation of subsurface processes, high levels of
heterogeneity results in high-resolution grids characterized by highly
discontinuous (cell-wise) material property fields. Moreover, due to the
significant uncertainties in the characterization of the domain of interest,
e.g. geologic reservoirs, the benefits of high order accuracy are reduced, and
low-order methods are typically employed. In this study, we present a strategy
for implementing highly performant low-order matrix-free FEM operator kernels
in the context of the conjugate gradient (CG) method. Performance results of
matrix-free Laplace and isotropic elasticity operator kernels are presented and
are shown to compare favorably to matrix-based SpMV operators on V100, A100,
and MI250X GPUs.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09840" title="Abstract">arXiv:2308.09840</a> [<a href="/pdf/2308.09840" title="Download PDF">pdf</a>, <a href="/format/2308.09840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High Aspect Ratio Multi-stage Ducted Electroaerodynamic Thrusters for  Micro Air Vehicle Propulsion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nelson%2C+C+L">C. Luke Nelson</a>, 
<a href="/search/cs?searchtype=author&query=Drew%2C+D+S">Daniel S. Drew</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Electroaerodynamic propulsion, where force is produced through collisions
between electrostatically accelerated ions and neutral air molecules, is an
attractive alternative to propeller- and flapping wing-based methods for micro
air vehicle (MAV) flight due to its silent and solid-state nature. One major
barrier to adoption is its limited thrust efficiency at useful disk loading
levels. Ducted actuators comprising multiple serially-integrated acceleration
stages are a potential solution, allowing individual stages to operate at
higher efficiency while maintaining a useful total thrust, and potentially
improving efficiency through various aerodynamic and fluid dynamic mechanisms.
In this work, we investigate the effects of duct and emitter electrode
geometries on actuator performance, then show how a combination of increasing
cross-sectional aspect ratio and serial integration of multiple stages can be
used to produce overall thrust densities comparable to commercial propulsors.
An optimized five-stage device attains a thrust density of about 18 N/m$^2$ at
a thrust efficiency of about 2 mN/W, among the highest values ever measured at
this scale. We further show how this type of thruster can be integrated under
the wings of a MAV-scale fixed wing platform, pointing towards future use as a
distributed propulsion system.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09842" title="Abstract">arXiv:2308.09842</a> [<a href="/pdf/2308.09842" title="Download PDF">pdf</a>, <a href="/format/2308.09842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enumerating Safe Regions in Deep Neural Networks with Provable  Probabilistic Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marzari%2C+L">Luca Marzari</a>, 
<a href="/search/cs?searchtype=author&query=Corsi%2C+D">Davide Corsi</a>, 
<a href="/search/cs?searchtype=author&query=Marchesini%2C+E">Enrico Marchesini</a>, 
<a href="/search/cs?searchtype=author&query=Farinelli%2C+A">Alessandro Farinelli</a>, 
<a href="/search/cs?searchtype=author&query=Cicalese%2C+F">Ferdinando Cicalese</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Identifying safe areas is a key point to guarantee trust for systems that are
based on Deep Neural Networks (DNNs). To this end, we introduce the
AllDNN-Verification problem: given a safety property and a DNN, enumerate the
set of all the regions of the property input domain which are safe, i.e., where
the property does hold. Due to the #P-hardness of the problem, we propose an
efficient approximation method called epsilon-ProVe. Our approach exploits a
controllable underestimation of the output reachable sets obtained via
statistical prediction of tolerance limits, and can provide a tight (with
provable probabilistic guarantees) lower estimate of the safe areas. Our
empirical evaluation on different standard benchmarks shows the scalability and
effectiveness of our method, offering valuable insights for this new type of
verification of DNNs.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09847" title="Abstract">arXiv:2308.09847</a> [<a href="/pdf/2308.09847" title="Download PDF">pdf</a>, <a href="/format/2308.09847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing End-to-End Determinism and Reliability in 6TiSCH networks with  disjoint leaf-based MPLS-like tunnels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aimaretto%2C+L">Lucas Aimaretto</a>, 
<a href="/search/cs?searchtype=author&query=Dujovne%2C+D">Diego Dujovne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to Elsevier for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Industrial multi-hop Internet of Things (IIoT) have strict reliability
requirements and they are expected to have deterministic behavior. Reliability
is associated with the network's ability to provide the best goodput possible
to the destination from the source application, while deterministic behavior
implies that the packets must also arrive at the destination before the maximum
allowable deadline defined by the application expires. Although a relevant
number of proposals have arisen in recent years, none of them achieve both
restrictions simultaneously. In this work, we propose a cross-layer approach to
solve this problem, by combining three strategies: (i) the use of the preferred
parents (PP) and alternative parents (AP) together with the PRE (Packet
Replication and Elimination) technique at the routing level; (ii) the use of
MPLS tunnels from the leafNode, improving the Data Plane, to control the energy
consumption and (iii) the use of the BDPC (Bounded Delay Packet Control)
algorithm. The combination of the former strategies show that the behavior of
the packet flows improves the end-to-end Packet Delivery Rate of the packets
arriving before the deadline by 2.04 times with respect to standard Minimum
Scheduling Function reference network while simultaneously increasing the
minimum average network lifetime by 1.5 times, with respect to the hop by hop
uncontrolled usage of PRE.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09850" title="Abstract">arXiv:2308.09850</a> [<a href="/pdf/2308.09850" title="Download PDF">pdf</a>, <a href="/format/2308.09850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backdoor Mitigation by Correcting the Distribution of Neural Activations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xi Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Z">Zhen Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+D+J">David J. Miller</a>, 
<a href="/search/cs?searchtype=author&query=Kesidis%2C+G">George Kesidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Backdoor (Trojan) attacks are an important type of adversarial exploit
against deep neural networks (DNNs), wherein a test instance is (mis)classified
to the attacker's target class whenever the attacker's backdoor trigger is
present. In this paper, we reveal and analyze an important property of backdoor
attacks: a successful attack causes an alteration in the distribution of
internal layer activations for backdoor-trigger instances, compared to that for
clean instances. Even more importantly, we find that instances with the
backdoor trigger will be correctly classified to their original source classes
if this distribution alteration is corrected. Based on our observations, we
propose an efficient and effective method that achieves post-training backdoor
mitigation by correcting the distribution alteration using reverse-engineered
triggers. Notably, our method does not change any trainable parameters of the
DNN, but achieves generally better mitigation performance than existing methods
that do require intensive DNN parameter tuning. It also efficiently detects
test instances with the trigger, which may help to catch adversarial entities
in the act of exploiting the backdoor.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09852" title="Abstract">arXiv:2308.09852</a> [<a href="/pdf/2308.09852" title="Download PDF">pdf</a>, <a href="/format/2308.09852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SICO: Simulation for Infection Control Operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pine%2C+K">Karleigh Pine</a>, 
<a href="/search/cs?searchtype=author&query=Veliche%2C+R">Razvan Veliche</a>, 
<a href="/search/cs?searchtype=author&query=Bennett%2C+J">Jared Bennett</a>, 
<a href="/search/cs?searchtype=author&query=Klipfel%2C+J">Joel Klipfel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">In response to the COVID-19 pandemic and the potential threat of future
epidemics caused by novel viruses, we developed a flexible framework for
modeling disease intervention effects. This tool is intended to aid decision
makers at multiple levels as they compare possible responses to emerging
epidemiological threats for optimal control and reduction of harm. The
framework is specifically designed to be both scalable and modular, allowing it
to model a variety of population levels, viruses, testing methods and
strategies--including pooled testing--and intervention strategies. In this
paper, we provide an overview of this framework and examine the impact of
different intervention strategies and their impact on infection dynamics.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09853" title="Abstract">arXiv:2308.09853</a> [<a href="/pdf/2308.09853" title="Download PDF">pdf</a>, <a href="/format/2308.09853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How susceptible are LLMs to Logical Fallacies?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Payandeh%2C+A">Amirreza Payandeh</a>, 
<a href="/search/cs?searchtype=author&query=Pluth%2C+D">Dan Pluth</a>, 
<a href="/search/cs?searchtype=author&query=Hosier%2C+J">Jordan Hosier</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xuesu Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Gurbani%2C+V+K">Vijay K. Gurbani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper investigates the rational thinking capability of Large Language
Models (LLMs) in multi-round argumentative debates by exploring the impact of
fallacious arguments on their logical reasoning performance. More specifically,
we present Logic Competence Measurement Benchmark (LOGICOM), a diagnostic
benchmark to assess the robustness of LLMs against logical fallacies. LOGICOM
involves two agents: a persuader and a debater engaging in a multi-round debate
on a controversial topic, where the persuader tries to convince the debater of
the correctness of its claim. First, LOGICOM assesses the potential of LLMs to
change their opinions through reasoning. Then, it evaluates the debater's
performance in logical reasoning by contrasting the scenario where the
persuader employs logical fallacies against one where logical reasoning is
used. We use this benchmark to evaluate the performance of GPT-3.5 and GPT-4
using a dataset containing controversial topics, claims, and reasons supporting
them. Our findings indicate that both GPT-3.5 and GPT-4 can adjust their
opinion through reasoning. However, when presented with logical fallacies,
GPT-3.5 and GPT-4 are erroneously convinced 41% and 69% more often,
respectively, compared to when logical reasoning is used. Finally, we introduce
a new dataset containing over 5k pairs of logical vs. fallacious arguments. The
source code and dataset of this work are made publicly available.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09857" title="Abstract">arXiv:2308.09857</a> [<a href="/pdf/2308.09857" title="Download PDF">pdf</a>, <a href="/format/2308.09857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffCharge: Generating EV Charging Scenarios via a Denoising Diffusion  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Siyang Li</a>, 
<a href="/search/eess?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yize Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 14 figures, in submission; Code available at <a href="https://github.com/LSY-Cython/DiffCharge">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Recent proliferation of electric vehicle (EV) charging events has brought
prominent stress over power grid operation. Due to the stochastic and volatile
EV charging behaviors, the induced charging loads are extremely uncertain,
posing modeling and control challenges for grid operators and charging
management. Generating EV charging scenarios would aid via synthesizing a
myriad of realistic charging scenarios. To this end, we propose a novel
denoising Diffusion-based Charging scenario generation model DiffCharge, which
is capable of generating a broad variety of realistic EV charging profiles with
distinctive temporal properties. It is able to progressively convert the simply
known Gaussian noise to genuine charging time-series data, by learning a
parameterized reversal of a forward diffusion process. Besides, we leverage the
multi-head self-attention and prior conditions to capture the temporal
correlations and unique information associated with EV or charging station
types in real charging profiles. Moreover, We demonstrate the superiority of
DiffCharge on extensive real-world charging datasets, as well as the efficacy
on EV integration in power distribution grids.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09858" title="Abstract">arXiv:2308.09858</a> [<a href="/pdf/2308.09858" title="Download PDF">pdf</a>, <a href="/format/2308.09858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tensor-Compressed Back-Propagation-Free Training for (Physics-Informed)  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yequan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xinling Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhixiong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziyue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sijia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Backward propagation (BP) is widely used to compute the gradients in neural
network training. However, it is hard to implement BP on edge devices due to
the lack of hardware and software resources to support automatic
differentiation. This has tremendously increased the design complexity and
time-to-market of on-device training accelerators. This paper presents a
completely BP-free framework that only requires forward propagation to train
realistic neural networks. Our technical contributions are three-fold. Firstly,
we present a tensor-compressed variance reduction approach to greatly improve
the scalability of zeroth-order (ZO) optimization, making it feasible to handle
a network size that is beyond the capability of previous ZO approaches.
Secondly, we present a hybrid gradient evaluation approach to improve the
efficiency of ZO training. Finally, we extend our BP-free training framework to
physics-informed neural networks (PINNs) by proposing a sparse-grid approach to
estimate the derivatives in the loss function without using BP. Our BP-free
training only loses little accuracy on the MNIST dataset compared with standard
first-order training. We also demonstrate successful results in training a PINN
for solving a 20-dim Hamiltonian-Jacobi-Bellman PDE. This memory-efficient and
BP-free approach may serve as a foundation for the near-future on-device
training on many resource-constraint platforms (e.g., FPGA, ASIC,
micro-controllers, and photonic chips).
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09861" title="Abstract">arXiv:2308.09861</a> [<a href="/pdf/2308.09861" title="Download PDF">pdf</a>, <a href="/format/2308.09861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Black-box Adversarial Attacks against Dense Retrieval Models: A  Multi-view Contrastive Learning Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu-An Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiafeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=de+Rijke%2C+M">Maarten de Rijke</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yixing Fan</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accept by CIKM2023, 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Neural ranking models (NRMs) and dense retrieval (DR) models have given rise
to substantial improvements in overall retrieval performance. In addition to
their effectiveness, and motivated by the proven lack of robustness of deep
learning-based approaches in other areas, there is growing interest in the
robustness of deep learning-based approaches to the core retrieval problem.
Adversarial attack methods that have so far been developed mainly focus on
attacking NRMs, with very little attention being paid to the robustness of DR
models. In this paper, we introduce the adversarial retrieval attack (AREA)
task. The AREA task is meant to trick DR models into retrieving a target
document that is outside the initial set of candidate documents retrieved by
the DR model in response to a query. We consider the decision-based black-box
adversarial setting, which is realistic in real-world search engines. To
address the AREA task, we first employ existing adversarial attack methods
designed for NRMs. We find that the promising results that have previously been
reported on attacking NRMs, do not generalize to DR models: these methods
underperform a simple term spamming method. We attribute the observed lack of
generalizability to the interaction-focused architecture of NRMs, which
emphasizes fine-grained relevance matching. DR models follow a different
representation-focused architecture that prioritizes coarse-grained
representations. We propose to formalize attacks on DR models as a contrastive
learning problem in a multi-view representation space. The core idea is to
encourage the consistency between each view representation of the target
document and its corresponding viewer via view-wise supervision signals.
Experimental results demonstrate that the proposed method can significantly
outperform existing attack strategies in misleading the DR model with small
indiscernible text perturbations.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09862" title="Abstract">arXiv:2308.09862</a> [<a href="/pdf/2308.09862" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breaking Language Barriers: A Question Answering Dataset for Hindi and  Marathi
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sabane%2C+M">Maithili Sabane</a>, 
<a href="/search/cs?searchtype=author&query=Litake%2C+O">Onkar Litake</a>, 
<a href="/search/cs?searchtype=author&query=Chadha%2C+A">Aman Chadha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The recent advances in deep-learning have led to the development of highly
sophisticated systems with an unquenchable appetite for data. On the other
hand, building good deep-learning models for low-resource languages remains a
challenging task. This paper focuses on developing a Question Answering dataset
for two such languages- Hindi and Marathi. Despite Hindi being the 3rd most
spoken language worldwide, with 345 million speakers, and Marathi being the
11th most spoken language globally, with 83.2 million speakers, both languages
face limited resources for building efficient Question Answering systems. To
tackle the challenge of data scarcity, we have developed a novel approach for
translating the SQuAD 2.0 dataset into Hindi and Marathi. We release the
largest Question-Answering dataset available for these languages, with each
dataset containing 28,000 samples. We evaluate the dataset on various
architectures and release the best-performing models for both Hindi and
Marathi, which will facilitate further research in these languages. Leveraging
similarity tools, our method holds the potential to create datasets in diverse
languages, thereby enhancing the understanding of natural language across
varied linguistic contexts. Our fine-tuned models, code, and dataset will be
made publicly available.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09863" title="Abstract">arXiv:2308.09863</a> [<a href="/pdf/2308.09863" title="Download PDF">pdf</a>, <a href="/format/2308.09863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StROL: Stabilized and Robust Online Learning from Humans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehta%2C+S+A">Shaunak A. Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Forrest Meng</a>, 
<a href="/search/cs?searchtype=author&query=Bajcsy%2C+A">Andrea Bajcsy</a>, 
<a href="/search/cs?searchtype=author&query=Losey%2C+D+P">Dylan P. Losey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Today's robots can learn the human's reward function online, during the
current interaction. This real-time learning requires fast but approximate
learning rules; when the human's behavior is noisy or suboptimal, today's
approximations can result in unstable robot learning. Accordingly, in this
paper we seek to enhance the robustness and convergence properties of gradient
descent learning rules when inferring the human's reward parameters. We model
the robot's learning algorithm as a dynamical system over the human preference
parameters, where the human's true (but unknown) preferences are the
equilibrium point. This enables us to perform Lyapunov stability analysis to
derive the conditions under which the robot's learning dynamics converge. Our
proposed algorithm (StROL) takes advantage of these stability conditions
offline to modify the original learning dynamics: we introduce a corrective
term that expands the basins of attraction around likely human rewards. In
practice, our modified learning rule can correctly infer what the human is
trying to convey, even when the human is noisy, biased, and suboptimal. Across
simulations and a user study we find that StROL results in a more accurate
estimate and less regret than state-of-the-art approaches for online reward
learning. See videos here: https://youtu.be/uDGpkvJnY8g
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09864" title="Abstract">arXiv:2308.09864</a> [<a href="/pdf/2308.09864" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A novel reduced basis method for adjoint sensitivity analysis of dynamic  topology optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+S">Shuhao Li</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+H">Hu Wang</a>, 
<a href="/search/math?searchtype=author&query=Yin%2C+J">Jichao Yin</a>, 
<a href="/search/math?searchtype=author&query=Jiang%2C+X">Xinchao Jiang</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Y">Yaya Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In gradient-based time domain topology optimization, design sensitivity
analysis (DSA) of the dynamic response is essential, and requires high
computational cost to directly differentiate, especially for high-order dynamic
system. To address this issue, this study develops an efficient reduced basis
method (RBM)-based discrete adjoint sensitivity analysis method, which on the
one hand significantly improves the efficiency of sensitivity analysis and on
the other hand avoids the consistency errors caused by the continuum method. In
this algorithm, the basis functions of the adjoint problem are constructed in
the offline phase based on the greedy-POD method, and a novel model-based
estimation is developed to facilitate the acceleration of this process. Based
on these basis functions, a fast and reasonably accurate model is then built by
Galerkin projection for sensitivity analysis in each dynamic topology
optimization iteration. Finally, the effectiveness of the error measures, the
efficiency and the accuracy of the presented reduced-order method are verified
by 2D and 3D dynamic structure studies.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09865" title="Abstract">arXiv:2308.09865</a> [<a href="/pdf/2308.09865" title="Download PDF">pdf</a>, <a href="/format/2308.09865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Theory of Topological Derivatives for Inverse Rendering of Geometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehta%2C+I">Ishit Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Chandraker%2C+M">Manmohan Chandraker</a>, 
<a href="/search/cs?searchtype=author&query=Ramamoorthi%2C+R">Ravi Ramamoorthi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 23; Project Page at <a href="https://ishit.github.io/td/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We introduce a theoretical framework for differentiable surface evolution
that allows discrete topology changes through the use of topological
derivatives for variational optimization of image functionals. While prior
methods for inverse rendering of geometry rely on silhouette gradients for
topology changes, such signals are sparse. In contrast, our theory derives
topological derivatives that relate the introduction of vanishing holes and
phases to changes in image intensity. As a result, we enable differentiable
shape perturbations in the form of hole or phase nucleation. We validate the
proposed theory with optimization of closed curves in 2D and surfaces in 3D to
lend insights into limitations of current methods and enable improved
applications such as image vectorization, vector-graphics generation from text
prompts, single-image reconstruction of shape ambigrams and multi-view 3D
reconstruction.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09866" title="Abstract">arXiv:2308.09866</a> [<a href="/pdf/2308.09866" title="Download PDF">pdf</a>, <a href="/format/2308.09866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimizing Carbon Footprint for Timely E-Truck Transportation: Hardness  and Approximation Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Junyan Su</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qiulin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Minghua Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+H">Haibo Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Carbon footprint optimization (CFO) is important for sustainable heavy-duty
e-truck transportation. We consider the CFO problem for timely transportation
of e-trucks, where the truck travels from an origin to a destination across a
national highway network subject to a deadline. The goal is to minimize the
carbon footprint by orchestrating path planning, speed planning, and
intermediary charging planning. We first show that it is NP-hard even just to
find a feasible CFO solution. We then develop a $(1+\epsilon_F,
1+\epsilon_\beta)$ bi-criteria approximation algorithm that achieves a carbon
footprint within a ratio of $(1+\epsilon_F)$ to the minimum with no deadline
violation and at most a ratio of $(1+\epsilon_\beta)$ battery capacity
violation (for any positive $\epsilon_F$ and $\epsilon_\beta$). Its time
complexity is polynomial in the size of the highway network, $1/\epsilon_F$,
and $1/\epsilon_\beta$. Such algorithmic results are among the best possible
unless P=NP. Simulation results based on real-world traces show that our scheme
reduces up to 11\% carbon footprint as compared to baseline alternatives
considering only energy consumption but not carbon footprint.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09868" title="Abstract">arXiv:2308.09868</a> [<a href="/pdf/2308.09868" title="Download PDF">pdf</a>, <a href="/format/2308.09868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Soft Robot Dynamics using Differentiable Kalman Filters and  Spatio-Temporal Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ikemoto%2C+S">Shuhei Ikemoto</a>, 
<a href="/search/cs?searchtype=author&query=Yoshimitsu%2C+Y">Yuhei Yoshimitsu</a>, 
<a href="/search/cs?searchtype=author&query=Amor%2C+H+B">Heni Ben Amor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 9 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper introduces a novel approach for modeling the dynamics of soft
robots, utilizing a differentiable filter architecture. The proposed approach
enables end-to-end training to learn system dynamics, noise characteristics,
and temporal behavior of the robot. A novel spatio-temporal embedding process
is discussed to handle observations with varying sensor placements and sampling
frequencies. The efficacy of this approach is demonstrated on a tensegrity
robot arm by learning end-effector dynamics from demonstrations with complex
bending motions. The model is proven to be robust against missing modalities,
diverse sensor placement, and varying sampling rates. Additionally, the
proposed framework is shown to identify physical interactions with humans
during motion. The utilization of a differentiable filter presents a novel
solution to the difficulties of modeling soft robot dynamics. Our approach
shows substantial improvement in accuracy compared to state-of-the-art
filtering methods, with at least a 24% reduction in mean absolute error (MAE)
observed. Furthermore, the predicted end-effector positions show an average MAE
of 25.77mm from the ground truth, highlighting the advantage of our approach.
The code is available at https://github.com/ir-lab/soft_robot_DEnKF.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09870" title="Abstract">arXiv:2308.09870</a> [<a href="/pdf/2308.09870" title="Download PDF">pdf</a>, <a href="/format/2308.09870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing State Estimation in Robots: A Data-Driven Approach with  Differentiable Ensemble Kalman Filters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+G">Geoffrey Clark</a>, 
<a href="/search/cs?searchtype=author&query=Campbell%2C+J">Joseph Campbell</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yifan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Amor%2C+H+B">Heni Ben Amor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper introduces a novel state estimation framework for robots using
differentiable ensemble Kalman filters (DEnKF). DEnKF is a reformulation of the
traditional ensemble Kalman filter that employs stochastic neural networks to
model the process noise implicitly. Our work is an extension of previous
research on differentiable filters, which has provided a strong foundation for
our modular and end-to-end differentiable framework. This framework enables
each component of the system to function independently, leading to improved
flexibility and versatility in implementation. Through a series of experiments,
we demonstrate the flexibility of this model across a diverse set of real-world
tracking tasks, including visual odometry and robot manipulation. Moreover, we
show that our model effectively handles noisy observations, is robust in the
absence of observations, and outperforms state-of-the-art differentiable
filters in terms of error metrics. Specifically, we observe a significant
improvement of at least 59% in translational error when using DEnKF with noisy
observations. Our results underscore the potential of DEnKF in advancing state
estimation for robotics. Code for DEnKF is available at
https://github.com/ir-lab/DEnKF
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09871" title="Abstract">arXiv:2308.09871</a> [<a href="/pdf/2308.09871" title="Download PDF">pdf</a>, <a href="/format/2308.09871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Projecting Robot Intentions Through Visual Cues: Static vs. Dynamic  Signaling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sonawani%2C+S">Shubham Sonawani</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yifan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Amor%2C+H+B">Heni Ben Amor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, Conference: IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Augmented and mixed-reality techniques harbor a great potential for improving
human-robot collaboration. Visual signals and cues may be projected to a human
partner in order to explicitly communicate robot intentions and goals. However,
it is unclear what type of signals support such a process and whether signals
can be combined without adding additional cognitive stress to the partner. This
paper focuses on identifying the effective types of visual signals and quantify
their impact through empirical evaluations. In particular, the study compares
static and dynamic visual signals within a collaborative object sorting task
and assesses their ability to shape human behavior. Furthermore, an
information-theoretic analysis is performed to numerically quantify the degree
of information transfer between visual signals and human behavior. The results
of a human subject experiment show that there are significant advantages to
combining multiple visual signals within a single task, i.e., increased task
efficiency and reduced cognitive load.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09872" title="Abstract">arXiv:2308.09872</a> [<a href="/pdf/2308.09872" title="Download PDF">pdf</a>, <a href="/format/2308.09872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Observer-Based Reinforcement Learning Solution for Model-Following  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Abouheaf%2C+M+I">Mohammed I. Abouheaf</a>, 
<a href="/search/eess?searchtype=author&query=Vamvoudakis%2C+K+G">Kyriakos G. Vamvoudakis</a>, 
<a href="/search/eess?searchtype=author&query=Mayyas%2C+M+A">Mohammad A. Mayyas</a>, 
<a href="/search/eess?searchtype=author&query=Hashim%2C+H+A">Hashim A. Hashim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 62nd IEEE Conference on Decision and Control (CDC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, a multi-objective model-following control problem is solved
using an observer-based adaptive learning scheme. The overall goal is to
regulate the model-following error dynamics along with optimizing the dynamic
variables of a process in a model-free fashion. This solution employs an
integral reinforcement learning approach to adapt three strategies. The first
strategy observes the states of desired process dynamics, while the second one
stabilizes and optimizes the closed-loop system. The third strategy allows the
process to follow a desired reference-trajectory. The adaptive learning scheme
is implemented using an approximate projection estimation approach under mild
conditions about the learning parameters.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09873" title="Abstract">arXiv:2308.09873</a> [<a href="/pdf/2308.09873" title="Download PDF">pdf</a>, <a href="/format/2308.09873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Skill Transformer: A Monolithic Policy for Mobile Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaoyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Batra%2C+D">Dhruv Batra</a>, 
<a href="/search/cs?searchtype=author&query=Rai%2C+A">Akshara Rai</a>, 
<a href="/search/cs?searchtype=author&query=Szot%2C+A">Andrew Szot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We present Skill Transformer, an approach for solving long-horizon robotic
tasks by combining conditional sequence modeling and skill modularity.
Conditioned on egocentric and proprioceptive observations of a robot, Skill
Transformer is trained end-to-end to predict both a high-level skill (e.g.,
navigation, picking, placing), and a whole-body low-level action (e.g., base
and arm motion), using a transformer architecture and demonstration
trajectories that solve the full task. It retains the composability and
modularity of the overall task through a skill predictor module while reasoning
about low-level actions and avoiding hand-off errors, common in modular
approaches. We test Skill Transformer on an embodied rearrangement benchmark
and find it performs robust task planning and low-level control in new
scenarios, achieving a 2.5x higher success rate than baselines in hard
rearrangement problems.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09876" title="Abstract">arXiv:2308.09876</a> [<a href="/pdf/2308.09876" title="Download PDF">pdf</a>, <a href="/format/2308.09876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing Usability Issue Discussions in OSS Projects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanei%2C+A">Arghavan Sanei</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jinghui Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 2 figures, submitted to CSCW2024 Supplementary material available at: <a href="https://github.com/HCDLab/UsabilityIssuesSupplementaryMaterial">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Usability is a crucial factor but one of the most neglected concerns in open
source software (OSS). While far from an ideal approach, a common practice that
OSS communities adopt to collaboratively address usability is through
discussions on issue tracking systems (ITSs). However, there is little
knowledge about the extent to which OSS community members engage in usability
issue discussions, the aspects of usability they frequently target, and the
characteristics of their collaboration around usability issue discussions. This
knowledge is important for providing practical recommendations and research
directions to better support OSS communities in addressing this important topic
and improve OSS usability in general. To help achieve this goal, we performed
an extensive empirical study on issues discussed in five popular OSS
applications: three data science notebook projects (Jupyter Lab, Google Colab,
and CoCalc) and two code editor projects (VSCode and Atom). Our results
indicated that while usability issues are extensively discussed in the OSS
projects, their scope tended to be limited to efficiency and aesthetics.
Additionally, these issues are more frequently posted by experienced community
members and display distinguishable characteristics, such as involving more
visual communication and more participants. Our results provide important
implications that can inform the OSS practitioners to better engage the
community in usability issue discussion and shed light on future research
efforts toward collaboration techniques and tools for discussing niche topics
in diverse communities, such as the usability issues in the OSS context.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09877" title="Abstract">arXiv:2308.09877</a> [<a href="/pdf/2308.09877" title="Download PDF">pdf</a>, <a href="/format/2308.09877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User-centric AIGC products: Explainable Artificial Intelligence and AIGC  products
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hanjie Yu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yan Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qiong Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Generative AI tools, such as ChatGPT and Midjourney, are transforming
artistic creation as AI-art integration advances. However, Artificial
Intelligence Generated Content (AIGC) tools face user experience challenges,
necessitating a human-centric design approach. This paper offers a brief
overview of research on explainable AI (XAI) and user experience, examining
factors leading to suboptimal experiences with AIGC tools. Our proposed
solution integrates interpretable AI methodologies into the input and
adjustment feedback stages of AIGC products. We underscore XAI's potential to
enhance the user experience for ordinary users and present a conceptual
framework for improving AIGC user experience.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09878" title="Abstract">arXiv:2308.09878</a> [<a href="/pdf/2308.09878" title="Download PDF">pdf</a>, <a href="/format/2308.09878" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DatasetEquity: Are All Samples Created Equal? In The Quest For Equity  Within Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+S">Shubham Shrivastava</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xianling Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nagesh%2C+S">Sushruth Nagesh</a>, 
<a href="/search/cs?searchtype=author&query=Parchami%2C+A">Armin Parchami</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Data imbalance is a well-known issue in the field of machine learning,
attributable to the cost of data collection, the difficulty of labeling, and
the geographical distribution of the data. In computer vision, bias in data
distribution caused by image appearance remains highly unexplored. Compared to
categorical distributions using class labels, image appearance reveals complex
relationships between objects beyond what class labels provide. Clustering deep
perceptual features extracted from raw pixels gives a richer representation of
the data. This paper presents a novel method for addressing data imbalance in
machine learning. The method computes sample likelihoods based on image
appearance using deep perceptual embeddings and clustering. It then uses these
likelihoods to weigh samples differently during training with a proposed
\textbf{Generalized Focal Loss} function. This loss can be easily integrated
with deep learning algorithms. Experiments validate the method's effectiveness
across autonomous driving vision datasets including KITTI and nuScenes. The
loss function improves state-of-the-art 3D object detection methods, achieving
over $200\%$ AP gains on under-represented classes (Cyclist) in the KITTI
dataset. The results demonstrate the method is generalizable, complements
existing techniques, and is particularly beneficial for smaller datasets and
rare classes. Code is available at:
$\texttt{https://github.com/towardsautonomy/DatasetEquity}$
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09880" title="Abstract">arXiv:2308.09880</a> [<a href="/pdf/2308.09880" title="Download PDF">pdf</a>, <a href="/format/2308.09880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Laminar Matroid Secretary: Greedy Strikes Back
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhiyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Parsaeian%2C+Z">Zahra Parsaeian</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zixuan Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">We show that a simple greedy algorithm is $4.75$ probability-competitive for
the Laminar Matroid Secretary Problem, improving the $3\sqrt{3} \approx
5.17$-competitive algorithm based on the forbidden sets technique (Soto,
Turkieltaub, and Verdugo, 2018).
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09881" title="Abstract">arXiv:2308.09881</a> [<a href="/pdf/2308.09881" title="Download PDF">pdf</a>, <a href="/format/2308.09881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Adversarial Networks Unlearning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hui Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+T">Tianqing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+W">Wenhan Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wanlei Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">As machine learning continues to develop, and data misuse scandals become
more prevalent, individuals are becoming increasingly concerned about their
personal information and are advocating for the right to remove their data.
Machine unlearning has emerged as a solution to erase training data from
trained machine learning models. Despite its success in classifiers, research
on Generative Adversarial Networks (GANs) is limited due to their unique
architecture, including a generator and a discriminator. One challenge pertains
to generator unlearning, as the process could potentially disrupt the
continuity and completeness of the latent space. This disruption might
consequently diminish the model's effectiveness after unlearning. Another
challenge is how to define a criterion that the discriminator should perform
for the unlearning images. In this paper, we introduce a substitution mechanism
and define a fake label to effectively mitigate these challenges. Based on the
substitution mechanism and fake label, we propose a cascaded unlearning
approach for both item and class unlearning within GAN models, in which the
unlearning and learning processes run in a cascaded manner. We conducted a
comprehensive evaluation of the cascaded unlearning technique using the MNIST
and CIFAR-10 datasets. Experimental results demonstrate that this approach
achieves significantly improved item and class unlearning efficiency, reducing
the required time by up to 185x and 284x for the MNIST and CIFAR-10 datasets,
respectively, in comparison to retraining from scratch. Notably, although the
model's performance experiences minor degradation after unlearning, this
reduction is negligible when dealing with a minimal number of images (e.g., 64)
and has no adverse effects on downstream tasks such as classification.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09882" title="Abstract">arXiv:2308.09882</a> [<a href="/pdf/2308.09882" title="Download PDF">pdf</a>, <a href="/format/2308.09882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forecast-MAE: Self-supervised Pre-training for Motion Forecasting with  Masked Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jie Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+X">Xiaodong Mei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Ming Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This study explores the application of self-supervised learning (SSL) to the
task of motion forecasting, an area that has not yet been extensively
investigated despite the widespread success of SSL in computer vision and
natural language processing. To address this gap, we introduce Forecast-MAE, an
extension of the mask autoencoders framework that is specifically designed for
self-supervised learning of the motion forecasting task. Our approach includes
a novel masking strategy that leverages the strong interconnections between
agents' trajectories and road networks, involving complementary masking of
agents' future or history trajectories and random masking of lane segments. Our
experiments on the challenging Argoverse 2 motion forecasting benchmark show
that Forecast-MAE, which utilizes standard Transformer blocks with minimal
inductive bias, achieves competitive performance compared to state-of-the-art
methods that rely on supervised learning and sophisticated designs. Moreover,
it outperforms the previous self-supervised learning method by a significant
margin. Code is available at https://github.com/jchengai/forecast-mae.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09883" title="Abstract">arXiv:2308.09883</a> [<a href="/pdf/2308.09883" title="Download PDF">pdf</a>, <a href="/format/2308.09883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flamingo: Multi-Round Single-Server Secure Aggregation with Applications  to Private Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yiping Ma</a>, 
<a href="/search/cs?searchtype=author&query=Woods%2C+J">Jess Woods</a>, 
<a href="/search/cs?searchtype=author&query=Angel%2C+S">Sebastian Angel</a>, 
<a href="/search/cs?searchtype=author&query=Polychroniadou%2C+A">Antigoni Polychroniadou</a>, 
<a href="/search/cs?searchtype=author&query=Rabin%2C+T">Tal Rabin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper introduces Flamingo, a system for secure aggregation of data
across a large set of clients. In secure aggregation, a server sums up the
private inputs of clients and obtains the result without learning anything
about the individual inputs beyond what is implied by the final sum. Flamingo
focuses on the multi-round setting found in federated learning in which many
consecutive summations (averages) of model weights are performed to derive a
good model. Previous protocols, such as Bell et al. (CCS '20), have been
designed for a single round and are adapted to the federated learning setting
by repeating the protocol multiple times. Flamingo eliminates the need for the
per-round setup of previous protocols, and has a new lightweight dropout
resilience protocol to ensure that if clients leave in the middle of a sum the
server can still obtain a meaningful result. Furthermore, Flamingo introduces a
new way to locally choose the so-called client neighborhood introduced by Bell
et al. These techniques help Flamingo reduce the number of interactions between
clients and the server, resulting in a significant reduction in the end-to-end
runtime for a full training session over prior work. We implement and evaluate
Flamingo and show that it can securely train a neural network on the (Extended)
MNIST and CIFAR-100 datasets, and the model converges without a loss in
accuracy, compared to a non-private federated learning system.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09884" title="Abstract">arXiv:2308.09884</a> [<a href="/pdf/2308.09884" title="Download PDF">pdf</a>, <a href="/format/2308.09884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Transformer-based Framework For Multi-variate Time Series: A Remaining  Useful Life Prediction Use Case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ogunfowora%2C+O">Oluwaseyi Ogunfowora</a>, 
<a href="/search/cs?searchtype=author&query=Najjaran%2C+H">Homayoun Najjaran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In recent times, Large Language Models (LLMs) have captured a global
spotlight and revolutionized the field of Natural Language Processing. One of
the factors attributed to the effectiveness of LLMs is the model architecture
used for training, transformers. Transformer models excel at capturing
contextual features in sequential data since time series data are sequential,
transformer models can be leveraged for more efficient time series data
prediction. The field of prognostics is vital to system health management and
proper maintenance planning. A reliable estimation of the remaining useful life
(RUL) of machines holds the potential for substantial cost savings. This
includes avoiding abrupt machine failures, maximizing equipment usage, and
serving as a decision support system (DSS). This work proposed an
encoder-transformer architecture-based framework for multivariate time series
prediction for a prognostics use case. We validated the effectiveness of the
proposed framework on all four sets of the C-MAPPS benchmark dataset for the
remaining useful life prediction task. To effectively transfer the knowledge
and application of transformers from the natural language domain to time
series, three model-specific experiments were conducted. Also, to enable the
model awareness of the initial stages of the machine life and its degradation
path, a novel expanding window method was proposed for the first time in this
work, it was compared with the sliding window method, and it led to a large
improvement in the performance of the encoder transformer model. Finally, the
performance of the proposed encoder-transformer model was evaluated on the test
dataset and compared with the results from 13 other state-of-the-art (SOTA)
models in the literature and it outperformed them all with an average
performance increase of 137.65% over the next best model across all the
datasets.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09886" title="Abstract">arXiv:2308.09886</a> [<a href="/pdf/2308.09886" title="Download PDF">pdf</a>, <a href="/format/2308.09886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flow-Based Energy Services Composition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abusafia%2C+A">Amani Abusafia</a>, 
<a href="/search/cs?searchtype=author&query=Lakhdari%2C+A">Abdallah Lakhdari</a>, 
<a href="/search/cs?searchtype=author&query=Bouguettaya%2C+A">Athman Bouguettaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 19 Figures, This is an accepted paper in the IEEE Transactions on Services Computing (IEEE TSC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">We propose a novel spatio-temporal service composition framework for
crowdsourcing multiple IoT energy services to cater to multiple energy
requests. We define a new energy service model to leverage the wearable-based
energy and wireless power transfer technologies. We reformulate the problem of
spatio-temporal service composition to provision multiple energy requests as a
matching problem. We leverage the fragmented nature of energy to offer partial
services to maximize the utilization of energy services. We propose
EnergyFlowComp, a modified Maximum Flow matching algorithm that efficiently
provisions IoT energy services to accommodate multiple energy requests.
Moreover, we propose PartialFlowComp, an extension of the EnergyFlowComp
approach that considers the partial-temporal overlap between services and
requests in provisioning. We conduct an extensive set of experiments to assess
the effectiveness and efficiency of the proposed framework.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09887" title="Abstract">arXiv:2308.09887</a> [<a href="/pdf/2308.09887" title="Download PDF">pdf</a>, <a href="/format/2308.09887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calibrating Uncertainty for Semi-Supervised Crowd Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaoling Hu</a>, 
<a href="/search/cs?searchtype=author&query=Abousamra%2C+S">Shahira Abousamra</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Semi-supervised crowd counting is an important yet challenging task. A
popular approach is to iteratively generate pseudo-labels for unlabeled data
and add them to the training set. The key is to use uncertainty to select
reliable pseudo-labels. In this paper, we propose a novel method to calibrate
model uncertainty for crowd counting. Our method takes a supervised uncertainty
estimation strategy to train the model through a surrogate function. This
ensures the uncertainty is well controlled throughout the training. We propose
a matching-based patch-wise surrogate function to better approximate
uncertainty for crowd counting tasks. The proposed method pays a sufficient
amount of attention to details, while maintaining a proper granularity.
Altogether our method is able to generate reliable uncertainty estimation, high
quality pseudolabels, and achieve state-of-the-art performance in
semisupervised crowd counting.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09889" title="Abstract">arXiv:2308.09889</a> [<a href="/pdf/2308.09889" title="Download PDF">pdf</a>, <a href="/format/2308.09889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DUAW: Data-free Universal Adversarial Watermark against Stable Diffusion  Customization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+X">Xiaoyu Ye</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hao Huang</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+J">Jiaqi An</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongtao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Stable Diffusion (SD) customization approaches enable users to personalize SD
model outputs, greatly enhancing the flexibility and diversity of AI art.
However, they also allow individuals to plagiarize specific styles or subjects
from copyrighted images, which raises significant concerns about potential
copyright infringement. To address this issue, we propose an invisible
data-free universal adversarial watermark (DUAW), aiming to protect a myriad of
copyrighted images from different customization approaches across various
versions of SD models. First, DUAW is designed to disrupt the variational
autoencoder during SD customization. Second, DUAW operates in a data-free
context, where it is trained on synthetic images produced by a Large Language
Model (LLM) and a pretrained SD model. This approach circumvents the necessity
of directly handling copyrighted images, thereby preserving their
confidentiality. Once crafted, DUAW can be imperceptibly integrated into
massive copyrighted images, serving as a protective measure by inducing
significant distortions in the images generated by customized SD models.
Experimental results demonstrate that DUAW can effectively distort the outputs
of fine-tuned SD models, rendering them discernible to both human observers and
a simple classifier.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09890" title="Abstract">arXiv:2308.09890</a> [<a href="/pdf/2308.09890" title="Download PDF">pdf</a>, <a href="/format/2308.09890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inductive-bias Learning: Generating Code Models with Large Language  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+T">Toma Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Emoto%2C+N">Naofumi Emoto</a>, 
<a href="/search/cs?searchtype=author&query=Yumibayashi%2C+T">Tsukasa Yumibayashi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large Language Models(LLMs) have been attracting attention due to a ability
called in-context learning(ICL). ICL, without updating the parameters of a LLM,
it is possible to achieve highly accurate inference based on rules ``in the
context'' by merely inputting a training data into the prompt. Although ICL is
a developing field with many unanswered questions, LLMs themselves serves as a
inference model, seemingly realizing inference without explicitly indicate
``inductive bias''. On the other hand, a code generation is also a highlighted
application of LLMs. The accuracy of code generation has dramatically improved,
enabling even non-engineers to generate code to perform the desired tasks by
crafting appropriate prompts. In this paper, we propose a novel ``learning''
method called an ``Inductive-Bias Learning (IBL)'', which combines the
techniques of ICL and code generation. An idea of IBL is straightforward. Like
ICL, IBL inputs a training data into the prompt and outputs a code with a
necessary structure for inference (we referred to as ``Code Model'') from a
``contextual understanding''. Despite being a seemingly simple approach, IBL
encompasses both a ``property of inference without explicit inductive bias''
inherent in ICL and a ``readability and explainability'' of the code
generation. Surprisingly, generated Code Models have been found to achieve
predictive accuracy comparable to, and in some cases surpassing, ICL and
representative machine learning models. Our IBL code is open source:
https://github.com/fuyu-quant/IBLM
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09891" title="Abstract">arXiv:2308.09891</a> [<a href="/pdf/2308.09891" title="Download PDF">pdf</a>, <a href="/format/2308.09891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SwinLSTM:Improving Spatiotemporal Prediction Accuracy using Swin  Transformer and LSTM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Song Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">RongNian Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Integrating CNNs and RNNs to capture spatiotemporal dependencies is a
prevalent strategy for spatiotemporal prediction tasks. However, the property
of CNNs to learn local spatial information decreases their efficiency in
capturing spatiotemporal dependencies, thereby limiting their prediction
accuracy. In this paper, we propose a new recurrent cell, SwinLSTM, which
integrates Swin Transformer blocks and the simplified LSTM, an extension that
replaces the convolutional structure in ConvLSTM with the self-attention
mechanism. Furthermore, we construct a network with SwinLSTM cell as the core
for spatiotemporal prediction. Without using unique tricks, SwinLSTM
outperforms state-of-the-art methods on Moving MNIST, Human3.6m, TaxiBJ, and
KTH datasets. In particular, it exhibits a significant improvement in
prediction accuracy compared to ConvLSTM. Our competitive experimental results
demonstrate that learning global spatial dependencies is more advantageous for
models to capture spatiotemporal dependencies. We hope that SwinLSTM can serve
as a solid baseline to promote the advancement of spatiotemporal prediction
accuracy. The codes are publicly available at
https://github.com/SongTang-x/SwinLSTM.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09892" title="Abstract">arXiv:2308.09892</a> [<a href="/pdf/2308.09892" title="Download PDF">pdf</a>, <a href="/format/2308.09892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utilizing Semantic Textual Similarity for Clinical Survey Data Feature  Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Warner%2C+B+C">Benjamin C. Warner</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Ziqi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Haroutounian%2C+S">Simon Haroutounian</a>, 
<a href="/search/cs?searchtype=author&query=Kannampallil%2C+T">Thomas Kannampallil</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chenyang Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Survey data can contain a high number of features while having a
comparatively low quantity of examples. Machine learning models that attempt to
predict outcomes from survey data under these conditions can overfit and result
in poor generalizability. One remedy to this issue is feature selection, which
attempts to select an optimal subset of features to learn upon. A relatively
unexplored source of information in the feature selection process is the usage
of textual names of features, which may be semantically indicative of which
features are relevant to a target outcome. The relationships between feature
names and target names can be evaluated using language models (LMs) to produce
semantic textual similarity (STS) scores, which can then be used to select
features. We examine the performance using STS to select features directly and
in the minimal-redundancy-maximal-relevance (mRMR) algorithm. The performance
of STS as a feature selection metric is evaluated against preliminary survey
data collected as a part of a clinical study on persistent post-surgical pain
(PPSP). The results suggest that features selected with STS can result in
higher performance models compared to traditional feature selection algorithms.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09894" title="Abstract">arXiv:2308.09894</a> [<a href="/pdf/2308.09894" title="Download PDF">pdf</a>, <a href="/format/2308.09894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic-Human: Neural Rendering of Humans from Monocular Video with  Human Parsing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+P">Pengcheng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Z">Zaiwang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yiyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The neural rendering of humans is a topic of great research significance.
However, previous works mostly focus on achieving photorealistic details,
neglecting the exploration of human parsing. Additionally, classical semantic
work are all limited in their ability to efficiently represent fine results in
complex motions. Human parsing is inherently related to radiance
reconstruction, as similar appearance and geometry often correspond to similar
semantic part. Furthermore, previous works often design a motion field that
maps from the observation space to the canonical space, while it tends to
exhibit either underfitting or overfitting, resulting in limited
generalization. In this paper, we present Semantic-Human, a novel method that
achieves both photorealistic details and viewpoint-consistent human parsing for
the neural rendering of humans. Specifically, we extend neural radiance fields
(NeRF) to jointly encode semantics, appearance and geometry to achieve accurate
2D semantic labels using noisy pseudo-label supervision. Leveraging the
inherent consistency and smoothness properties of NeRF, Semantic-Human achieves
consistent human parsing in both continuous and novel views. We also introduce
constraints derived from the SMPL surface for the motion field and
regularization for the recovered volumetric geometry. We have evaluated the
model using the ZJU-MoCap dataset, and the obtained highly competitive results
demonstrate the effectiveness of our proposed Semantic-Human. We also showcase
various compelling applications, including label denoising, label synthesis and
image editing, and empirically validate its advantageous properties.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09895" title="Abstract">arXiv:2308.09895</a> [<a href="/pdf/2308.09895" title="Download PDF">pdf</a>, <a href="/format/2308.09895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Transfer from High-Resource to Low-Resource Programming  Languages for Code LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cassano%2C+F">Federico Cassano</a>, 
<a href="/search/cs?searchtype=author&query=Gouwar%2C+J">John Gouwar</a>, 
<a href="/search/cs?searchtype=author&query=Lucchetti%2C+F">Francesca Lucchetti</a>, 
<a href="/search/cs?searchtype=author&query=Schlesinger%2C+C">Claire Schlesinger</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+C+J">Carolyn Jane Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Greenberg%2C+M">Michael Greenberg</a>, 
<a href="/search/cs?searchtype=author&query=Jangda%2C+A">Abhinav Jangda</a>, 
<a href="/search/cs?searchtype=author&query=Guha%2C+A">Arjun Guha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Over the past few years, Large Language Models of Code (Code LLMs) have
started to have a significant impact on programming practice. Code LLMs are
also emerging as a building block for research in programming languages and
software engineering. However, the quality of code produced by a Code LLM
varies significantly by programming languages. Code LLMs produce impressive
results on programming languages that are well represented in their training
data (e.g., Java, Python, or JavaScript), but struggle with low-resource
languages, like OCaml and Racket.
<br />This paper presents an effective approach for boosting the performance of
Code LLMs on low-resource languages using semi-synthetic data. Our approach
generates high-quality datasets for low-resource languages, which can then be
used to fine-tune any pretrained Code LLM. Our approach, called MultiPL-T,
translates training data from high-resource languages into training data for
low-resource languages. We apply our approach to generate tens of thousands of
new, validated training items for Racket, OCaml, and Lua from Python. Moreover,
we use an open dataset (The Stack) and model (StarCoderBase), which allow us to
decontaminate benchmarks and train models on this data without violating the
model license.
<br />With MultiPL-T generated data, we present fine-tuned versions of
StarCoderBase that achieve state-of-the-art performance for Racket, OCaml, and
Lua on benchmark problems. For Lua, our fine-tuned model achieves the same
performance as StarCoderBase as Python -- a very high-resource language -- on
the MultiPL-E benchmarks. For Racket and OCaml, we double their performance on
MultiPL-E, bringing their performance close to higher-resource languages such
as Ruby and C#.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09896" title="Abstract">arXiv:2308.09896</a> [<a href="/pdf/2308.09896" title="Download PDF">pdf</a>, <a href="/format/2308.09896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Learning-based Imputation-Prediction Networks for  In-hospital Mortality Risk Modeling using EHRs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuxi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+S">Shaowen Qin</a>, 
<a href="/search/cs?searchtype=author&query=Salim%2C+F+D">Flora D. Salim</a>, 
<a href="/search/cs?searchtype=author&query=Yepes%2C+A+J">Antonio Jimeno Yepes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 2 figures, accepted at ECML PKDD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Predicting the risk of in-hospital mortality from electronic health records
(EHRs) has received considerable attention. Such predictions will provide early
warning of a patient's health condition to healthcare professionals so that
timely interventions can be taken. This prediction task is challenging since
EHR data are intrinsically irregular, with not only many missing values but
also varying time intervals between medical records. Existing approaches focus
on exploiting the variable correlations in patient medical records to impute
missing values and establishing time-decay mechanisms to deal with such
irregularity. This paper presents a novel contrastive learning-based
imputation-prediction network for predicting in-hospital mortality risks using
EHR data. Our approach introduces graph analysis-based patient stratification
modeling in the imputation process to group similar patients. This allows
information of similar patients only to be used, in addition to personal
contextual information, for missing value imputation. Moreover, our approach
can integrate contrastive learning into the proposed network architecture to
enhance patient representation learning and predictive performance on the
classification task. Experiments on two real-world EHR datasets show that our
approach outperforms the state-of-the-art approaches in both imputation and
prediction tasks.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09897" title="Abstract">arXiv:2308.09897</a> [<a href="/pdf/2308.09897" title="Download PDF">pdf</a>, <a href="/format/2308.09897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial-Temporal Alignment Network for Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jinhui Ye</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Junwei Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Introducing viewpoint invariant feature representations in Action Recognition. arXiv admin note: text overlap with <a href="/abs/2012.02426">arXiv:2012.02426</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper studies introducing viewpoint invariant feature representations in
existing action recognition architecture. Despite significant progress in
action recognition, efficiently handling geometric variations in large-scale
datasets remains challenging. To tackle this problem, we propose a novel
Spatial-Temporal Alignment Network (STAN), which explicitly learns geometric
invariant representations for action recognition. Notably, the STAN model is
light-weighted and generic, which could be plugged into existing action
recognition models (e.g., MViTv2) with a low extra computational cost. We test
our STAN model on widely-used datasets like UCF101 and HMDB51. The experimental
results show that the STAN model can consistently improve the state-of-the-art
models in action recognition tasks in trained-from-scratch settings.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09899" title="Abstract">arXiv:2308.09899</a> [<a href="/pdf/2308.09899" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a High-Performance Object Detector: Insights from Drone  Detection Using ViT and CNN-based Deep Learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junyang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 23 figures, IEEE Xplore, 2023 International Conference on Computer Vision and Robotics Science
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Accurate drone detection is strongly desired in drone collision avoidance,
drone defense and autonomous Unmanned Aerial Vehicle (UAV) self-landing. With
the recent emergence of the Vision Transformer (ViT), this critical task is
reassessed in this paper using a UAV dataset composed of 1359 drone photos. We
construct various CNN and ViT-based models, demonstrating that for single-drone
detection, a basic ViT can achieve performance 4.6 times more robust than our
best CNN-based transfer learning models. By implementing the state-of-the-art
You Only Look Once (YOLO v7, 200 epochs) and the experimental ViT-based You
Only Look At One Sequence (YOLOS, 20 epochs) in multi-drone detection, we
attain impressive 98% and 96% mAP values, respectively. We find that ViT
outperforms CNN at the same epoch, but also requires more training data,
computational power, and sophisticated, performance-oriented designs to fully
surpass the capabilities of cutting-edge CNN detectors. We summarize the
distinct characteristics of ViT and CNN models to aid future researchers in
developing more efficient deep learning models.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09902" title="Abstract">arXiv:2308.09902</a> [<a href="/pdf/2308.09902" title="Download PDF">pdf</a>, <a href="/format/2308.09902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DPMAC: Differentially Private Communication for Cooperative Multi-Agent  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Canzhe Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ze%2C+Y">Yanjie Ze</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jing Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Baoxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuai Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version; Accepted in IJCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Communication lays the foundation for cooperation in human society and in
multi-agent reinforcement learning (MARL). Humans also desire to maintain their
privacy when communicating with others, yet such privacy concern has not been
considered in existing works in MARL. To this end, we propose the
\textit{differentially private multi-agent communication} (DPMAC) algorithm,
which protects the sensitive information of individual agents by equipping each
agent with a local message sender with rigorous $(\epsilon,
\delta)$-differential privacy (DP) guarantee. In contrast to directly
perturbing the messages with predefined DP noise as commonly done in
privacy-preserving scenarios, we adopt a stochastic message sender for each
agent respectively and incorporate the DP requirement into the sender, which
automatically adjusts the learned message distribution to alleviate the
instability caused by DP noise. Further, we prove the existence of a Nash
equilibrium in cooperative MARL with privacy-preserving communication, which
suggests that this problem is game-theoretically learnable. Extensive
experiments demonstrate a clear advantage of DPMAC over baseline methods in
privacy-preserving scenarios.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09903" title="Abstract">arXiv:2308.09903</a> [<a href="/pdf/2308.09903" title="Download PDF">pdf</a>, <a href="/format/2308.09903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Video Object Segmentation with Simplified Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qiangqiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tianyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=WU%2C+W">Wei WU</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+A">Antoni Chan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The current popular methods for video object segmentation (VOS) implement
feature matching through several hand-crafted modules that separately perform
feature extraction and matching. However, the above hand-crafted designs
empirically cause insufficient target interaction, thus limiting the dynamic
target-aware feature learning in VOS. To tackle these limitations, this paper
presents a scalable Simplified VOS (SimVOS) framework to perform joint feature
extraction and matching by leveraging a single transformer backbone.
Specifically, SimVOS employs a scalable ViT backbone for simultaneous feature
extraction and matching between query and reference features. This design
enables SimVOS to learn better target-ware features for accurate mask
prediction. More importantly, SimVOS could directly apply well-pretrained ViT
backbones (e.g., MAE) for VOS, which bridges the gap between VOS and
large-scale self-supervised pre-training. To achieve a better performance-speed
trade-off, we further explore within-frame attention and propose a new token
refinement module to improve the running speed and save computational cost.
Experimentally, our SimVOS achieves state-of-the-art results on popular video
object segmentation benchmarks, i.e., DAVIS-2017 (88.0% J&amp;F), DAVIS-2016 (92.9%
J&amp;F) and YouTube-VOS 2019 (84.2% J&amp;F), without applying any synthetic video or
BL30K pre-training used in previous VOS approaches.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09904" title="Abstract">arXiv:2308.09904</a> [<a href="/pdf/2308.09904" title="Download PDF">pdf</a>, <a href="/format/2308.09904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RAH! RecSys-Assistant-Human: A Human-Central Recommendation Framework  with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shu%2C+Y">Yubo Shu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hansu Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haonan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tun Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+N">Ning Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The recommendation ecosystem involves interactions between recommender
systems(Computer) and users(Human). Orthogonal to the perspective of
recommender systems, we attempt to utilize LLMs from the perspective of users
and propose a more human-central recommendation framework named RAH, which
consists of Recommender system, Assistant and Human. The assistant is a
LLM-based and personal proxy for a human to achieve user satisfaction. The
assistant plays a non-invasion role and the RAH framework can adapt to
different recommender systems and user groups. Subsequently, we implement and
evaluate the RAH framework for learning user personalities and proxy human
feedback. The experiment shows that (1) using learn-action-critic and
reflection mechanisms can lead more aligned personality and (2) our assistant
can effectively proxy human feedback and help adjust recommender systems.
Finally, we discuss further strategies in the RAH framework to address
human-central concerns including user control, privacy and fairness.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09905" title="Abstract">arXiv:2308.09905</a> [<a href="/pdf/2308.09905" title="Download PDF">pdf</a>, <a href="/format/2308.09905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffusionTrack: Diffusion Model For Multi-Object Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+R">Run Luo</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zikai Song</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lintao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jinlin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Min Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-object tracking (MOT) is a challenging vision task that aims to detect
individual objects within a single frame and associate them across multiple
frames. Recent MOT approaches can be categorized into two-stage
tracking-by-detection (TBD) methods and one-stage joint detection and tracking
(JDT) methods. Despite the success of these approaches, they also suffer from
common problems, such as harmful global or local inconsistency, poor trade-off
between robustness and model complexity, and lack of flexibility in different
scenes within the same video. In this paper we propose a simple but robust
framework that formulates object detection and association jointly as a
consistent denoising diffusion process from paired noise boxes to paired
ground-truth boxes. This novel progressive denoising diffusion strategy
substantially augments the tracker's effectiveness, enabling it to discriminate
between various objects. During the training stage, paired object boxes diffuse
from paired ground-truth boxes to random distribution, and the model learns
detection and tracking simultaneously by reversing this noising process. In
inference, the model refines a set of paired randomly generated boxes to the
detection and tracking results in a flexible one-step or multi-step denoising
diffusion process. Extensive experiments on three widely used MOT benchmarks,
including MOT17, MOT20, and Dancetrack, demonstrate that our approach achieves
competitive performance compared to the current state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09906" title="Abstract">arXiv:2308.09906</a> [<a href="/pdf/2308.09906" title="Download PDF">pdf</a>, <a href="/ps/2308.09906" title="Download PostScript">ps</a>, <a href="/format/2308.09906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the physical layer security capabilities of reconfigurable  intelligent surface empowered wireless systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boulogeorgos%2C+A+A">Alexandros--Apostolos A. Boulogeorgos</a>, 
<a href="/search/cs?searchtype=author&query=Alexiou%2C+A">Angeliki Alexiou</a>, 
<a href="/search/cs?searchtype=author&query=Michalas%2C+A">Angelos Michalas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we investigate the physical layer security capabilities of
reconfigurable intelligent surface (RIS) empowered wireless systems. In more
detail, we consider a general system model, in which the links between the
transmitter (TX) and the RIS as well as the links between the RIS and the
legitimate receiver are modeled as mixture Gamma (MG) random variables (RVs).
Moreover, the link between the TX and eavesdropper is also modeled as a MG RV.
Building upon this system model, we derive the probability of zero-secrecy
capacity as well as the probability of information leakage. Finally, we extract
the average secrecy rate for both cases of TX having full and partial channel
state information knowledge.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09907" title="Abstract">arXiv:2308.09907</a> [<a href="/pdf/2308.09907" title="Download PDF">pdf</a>, <a href="/format/2308.09907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imputing Brain Measurements Across Data Sets via Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yixin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wei Peng</a>, 
<a href="/search/cs?searchtype=author&query=Tapert%2C+S+F">Susan F. Tapert</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qingyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Pohl%2C+K+M">Kilian M. Pohl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 6th workshop on PRedictive Intelligence in Medicine (PRIME 2023) - MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Publicly available data sets of structural MRIs might not contain specific
measurements of brain Regions of Interests (ROIs) that are important for
training machine learning models. For example, the curvature scores computed by
Freesurfer are not released by the Adolescent Brain Cognitive Development
(ABCD) Study. One can address this issue by simply reapplying Freesurfer to the
data set. However, this approach is generally computationally and labor
intensive (e.g., requiring quality control). An alternative is to impute the
missing measurements via a deep learning approach. However, the
state-of-the-art is designed to estimate randomly missing values rather than
entire measurements. We therefore propose to re-frame the imputation problem as
a prediction task on another (public) data set that contains the missing
measurements and shares some ROI measurements with the data sets of interest. A
deep learning model is then trained to predict the missing measurements from
the shared ones and afterwards is applied to the other data sets. Our proposed
algorithm models the dependencies between ROI measurements via a graph neural
network (GNN) and accounts for demographic differences in brain measurements
(e.g. sex) by feeding the graph encoding into a parallel architecture. The
architecture simultaneously optimizes a graph decoder to impute values and a
classifier in predicting demographic factors. We test the approach, called
Demographic Aware Graph-based Imputation (DAGI), on imputing those missing
Freesurfer measurements of ABCD (N=3760) by training the predictor on those
publicly released by the National Consortium on Alcohol and Neurodevelopment in
Adolescence (NCANDA, N=540)...
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09908" title="Abstract">arXiv:2308.09908</a> [<a href="/pdf/2308.09908" title="Download PDF">pdf</a>, <a href="/format/2308.09908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LEGO: Learning and Graph-Optimized Modular Tracker for Online  Multi-Object Tracking with Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenrong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yuxuan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Q">Qing-Long Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongbin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Online multi-object tracking (MOT) plays a pivotal role in autonomous
systems. The state-of-the-art approaches usually employ a tracking-by-detection
method, and data association plays a critical role. This paper proposes a
learning and graph-optimized (LEGO) modular tracker to improve data association
performance in the existing literature. The proposed LEGO tracker integrates
graph optimization and self-attention mechanisms, which efficiently formulate
the association score map, facilitating the accurate and efficient matching of
objects across time frames. To further enhance the state update process, the
Kalman filter is added to ensure consistent tracking by incorporating temporal
coherence in the object states. Our proposed method utilizing LiDAR alone has
shown exceptional performance compared to other online tracking approaches,
including LiDAR-based and LiDAR-camera fusion-based methods. LEGO ranked 1st at
the time of submitting results to KITTI object tracking evaluation ranking
board and remains 2nd at the time of submitting this paper, among all online
trackers in the KITTI MOT benchmark for cars1
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09909" title="Abstract">arXiv:2308.09909</a> [<a href="/pdf/2308.09909" title="Download PDF">pdf</a>, <a href="/format/2308.09909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Never Explore Repeatedly in Multi-Agent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenghao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tonghan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chongjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qianchuan Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">In the realm of multi-agent reinforcement learning, intrinsic motivations
have emerged as a pivotal tool for exploration. While the computation of many
intrinsic rewards relies on estimating variational posteriors using neural
network approximators, a notable challenge has surfaced due to the limited
expressive capability of these neural statistics approximators. We pinpoint
this challenge as the "revisitation" issue, where agents recurrently explore
confined areas of the task space. To combat this, we propose a dynamic reward
scaling approach. This method is crafted to stabilize the significant
fluctuations in intrinsic rewards in previously explored areas and promote
broader exploration, effectively curbing the revisitation phenomenon. Our
experimental findings underscore the efficacy of our approach, showcasing
enhanced performance in demanding environments like Google Research Football
and StarCraft II micromanagement tasks, especially in sparse reward settings.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09910" title="Abstract">arXiv:2308.09910</a> [<a href="/pdf/2308.09910" title="Download PDF">pdf</a>, <a href="/format/2308.09910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Guided Human Motion Capture with Pose Probability Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ju%2C+J">Jingyi Ju</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Buzhen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhihao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yangang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by IJCAI2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Incorporating physics in human motion capture to avoid artifacts like
floating, foot sliding, and ground penetration is a promising direction.
Existing solutions always adopt kinematic results as reference motions, and the
physics is treated as a post-processing module. However, due to the depth
ambiguity, monocular motion capture inevitably suffers from noises, and the
noisy reference often leads to failure for physics-based tracking. To address
the obstacles, our key-idea is to employ physics as denoising guidance in the
reverse diffusion process to reconstruct physically plausible human motion from
a modeled pose probability distribution. Specifically, we first train a latent
gaussian model that encodes the uncertainty of 2D-to-3D lifting to facilitate
reverse diffusion. Then, a physics module is constructed to track the motion
sampled from the distribution. The discrepancies between the tracked motion and
image observation are used to provide explicit guidance for the reverse
diffusion model to refine the motion. With several iterations, the
physics-based tracking and kinematic denoising promote each other to generate a
physically plausible human motion. Experimental results show that our method
outperforms previous physics-based methods in both joint accuracy and success
rate. More information can be found at
\url{https://github.com/Me-Ditto/Physics-Guided-Mocap}.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09911" title="Abstract">arXiv:2308.09911</a> [<a href="/pdf/2308.09911" title="Download PDF">pdf</a>, <a href="/format/2308.09911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noisy-Correspondence Learning for Text-to-Image Person Re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yang Qin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingke Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+D">Dezhong Peng</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xi Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J+T">Joey Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+P">Peng Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Text-to-image person re-identification (TIReID) is a compelling topic in the
cross-modal community, which aims to retrieve the target person based on a
textual query. Although numerous TIReID methods have been proposed and achieved
promising performance, they implicitly assume the training image-text pairs are
correctly aligned, which is not always the case in real-world scenarios. In
practice, the image-text pairs inevitably exist under-correlated or even
false-correlated, a.k.a noisy correspondence (NC), due to the low quality of
the images and annotation errors. To address this problem, we propose a novel
Robust Dual Embedding method (RDE) that can learn robust visual-semantic
associations even with NC. Specifically, RDE consists of two main components:
1) A Confident Consensus Division (CCD) module that leverages the dual-grained
decisions of dual embedding modules to obtain a consensus set of clean training
data, which enables the model to learn correct and reliable visual-semantic
associations. 2) A Triplet-Alignment Loss (TAL) relaxes the conventional
triplet-ranking loss with hardest negatives, which tends to rapidly overfit NC,
to a log-exponential upper bound over all negatives, thus preventing the model
from overemphasizing false image-text pairs. We conduct extensive experiments
on three public benchmarks, namely CUHK-PEDES, ICFG-PEDES, and RSTPReID, to
evaluate the performance and robustness of our RDE. Our method achieves
state-of-the-art results both with and without synthetic noisy correspondences
on all three datasets.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09915" title="Abstract">arXiv:2308.09915</a> [<a href="/pdf/2308.09915" title="Download PDF">pdf</a>, <a href="/format/2308.09915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EGANS: Evolutionary Generative Adversarial Network Search for Zero-Shot  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shiming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shihuang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+W">Wenjin Hou</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Weiping Ding</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+X">Xinge You</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to TEVC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Zero-shot learning (ZSL) aims to recognize the novel classes which cannot be
collected for training a prediction model. Accordingly, generative models
(e.g., generative adversarial network (GAN)) are typically used to synthesize
the visual samples conditioned by the class semantic vectors and achieve
remarkable progress for ZSL. However, existing GAN-based generative ZSL methods
are based on hand-crafted models, which cannot adapt to various
datasets/scenarios and fails to model instability. To alleviate these
challenges, we propose evolutionary generative adversarial network search
(termed EGANS) to automatically design the generative network with good
adaptation and stability, enabling reliable visual feature sample synthesis for
advancing ZSL. Specifically, we adopt cooperative dual evolution to conduct a
neural architecture search for both generator and discriminator under a unified
evolutionary adversarial framework. EGANS is learned by two stages: evolution
generator architecture search and evolution discriminator architecture search.
During the evolution generator architecture search, we adopt a many-to-one
adversarial training strategy to evolutionarily search for the optimal
generator. Then the optimal generator is further applied to search for the
optimal discriminator in the evolution discriminator architecture search with a
similar evolution search algorithm. Once the optimal generator and
discriminator are searched, we entail them into various generative ZSL
baselines for ZSL classification. Extensive experiments show that EGANS
consistently improve existing generative ZSL methods on the standard CUB, SUN,
AWA2 and FLO datasets. The significant performance gains indicate that the
evolutionary neural architecture search explores a virgin field in ZSL.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09916" title="Abstract">arXiv:2308.09916</a> [<a href="/pdf/2308.09916" title="Download PDF">pdf</a>, <a href="/format/2308.09916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VI-Net: Boosting Category-level 6D Object Pose Estimation via Learning  Decoupled Rotations on the Spherical Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jiehong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zewei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yabin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+K">Kui Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV2023. Project Page: <a href="https://github.com/JiehongLin/VI-Net">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Rotation estimation of high precision from an RGB-D object observation is a
huge challenge in 6D object pose estimation, due to the difficulty of learning
in the non-linear space of SO(3). In this paper, we propose a novel rotation
estimation network, termed as VI-Net, to make the task easier by decoupling the
rotation as the combination of a viewpoint rotation and an in-plane rotation.
More specifically, VI-Net bases the feature learning on the sphere with two
individual branches for the estimates of two factorized rotations, where a
V-Branch is employed to learn the viewpoint rotation via binary classification
on the spherical signals, while another I-Branch is used to estimate the
in-plane rotation by transforming the signals to view from the zenith
direction. To process the spherical signals, a Spherical Feature Pyramid
Network is constructed based on a novel design of SPAtial Spherical Convolution
(SPA-SConv), which settles the boundary problem of spherical signals via
feature padding and realizesviewpoint-equivariant feature extraction by
symmetric convolutional operations. We apply the proposed VI-Net to the
challenging task of category-level 6D object pose estimation for predicting the
poses of unknown objects without available CAD models; experiments on the
benchmarking datasets confirm the efficacy of our method, which outperforms the
existing ones with a large margin in the regime of high precision.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09917" title="Abstract">arXiv:2308.09917</a> [<a href="/pdf/2308.09917" title="Download PDF">pdf</a>, <a href="/format/2308.09917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Multiscale Consistency for Self-supervised Electron Microscopy  Instance Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yinda Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zhiwei Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Instance segmentation in electron microscopy (EM) volumes poses a significant
challenge due to the complex morphology of instances and insufficient
annotations. Self-supervised learning has recently emerged as a promising
solution, enabling the acquisition of prior knowledge of cellular tissue
structures that are essential for EM instance segmentation. However, existing
pretraining methods often lack the ability to capture complex visual patterns
and relationships between voxels, which results in the acquired prior knowledge
being insufficient for downstream EM analysis tasks. In this paper, we propose
a novel pretraining framework that leverages multiscale visual representations
to capture both voxel-level and feature-level consistency in EM volumes.
Specifically, our framework enforces voxel-level consistency between the
outputs of a Siamese network by a reconstruction function, and incorporates a
cross-attention mechanism for soft feature matching to achieve fine-grained
feature-level consistency. Moreover, we propose a contrastive learning scheme
on the feature pyramid to extract discriminative features across multiple
scales. We extensively pretrain our method on four large-scale EM datasets,
achieving promising performance improvements in representative tasks of neuron
and mitochondria instance segmentation.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09920" title="Abstract">arXiv:2308.09920</a> [<a href="/pdf/2308.09920" title="Download PDF">pdf</a>, <a href="/format/2308.09920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph4J -- A computationally efficient Java library for graph algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fr%C4%83sinaru%2C+C">Cristian Fr&#x103;sinaru</a>, 
<a href="/search/cs?searchtype=author&query=Olariu%2C+E+F">Emanuel Florentin Olariu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Software (cs.MS)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Graph algorithms play an important role in many computer science areas. In
order to solve problems that can be modeled using graphs, it is necessary to
use a data structure that can represent those graphs in an efficient manner. On
top of this, an infrastructure should be build that will assist in implementing
common algorithms or developing specialized ones. Here, a new Java library is
introduced, called Graph4J, that uses a different approach when compared to
existing, well-known Java libraries such as JGraphT, JUNG and Guava Graph.
Instead of using object-oriented data structures for graph representation, a
lower-level model based on arrays of primitive values is utilized, that
drastically reduces the required memory and the running times of the algorithm
implementations. The design of the library, the space complexity of the graph
structures and the time complexity of the most common graph operations are
presented in detail, along with an experimental study that evaluates its
performance, when compared to the other libraries. Emphasis is given to
infrastructure related aspects, that is graph creation, inspection, alteration
and traversal. The improvements obtained for other implemented algorithms are
also analyzed and it is shown that the proposed library significantly
outperforms the existing ones.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09921" title="Abstract">arXiv:2308.09921</a> [<a href="/pdf/2308.09921" title="Download PDF">pdf</a>, <a href="/format/2308.09921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recap: Detecting Deepfake Video with Unpredictable Tampered Traces via  Recovering Faces and Mapping Recovered Faces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Juan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+X">Xin Liao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+D">Difei Gao</a>, 
<a href="/search/cs?searchtype=author&query=Tsutsui%2C+S">Satoshi Tsutsui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zheng Qin</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2305.05943">arXiv:2305.05943</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The exploitation of Deepfake techniques for malicious intentions has driven
significant research interest in Deepfake detection. Deepfake manipulations
frequently introduce random tampered traces, leading to unpredictable outcomes
in different facial regions. However, existing detection methods heavily rely
on specific forgery indicators, and as the forgery mode improves, these traces
become increasingly randomized, resulting in a decline in the detection
performance of methods reliant on specific forgery traces. To address the
limitation, we propose Recap, a novel Deepfake detection model that exposes
unspecific facial part inconsistencies by recovering faces and enlarges the
differences between real and fake by mapping recovered faces. In the recovering
stage, the model focuses on randomly masking regions of interest (ROIs) and
reconstructing real faces without unpredictable tampered traces, resulting in a
relatively good recovery effect for real faces while a poor recovery effect for
fake faces. In the mapping stage, the output of the recovery phase serves as
supervision to guide the facial mapping process. This mapping process
strategically emphasizes the mapping of fake faces with poor recovery, leading
to a further deterioration in their representation, while enhancing and
refining the mapping of real faces with good representation. As a result, this
approach significantly amplifies the discrepancies between real and fake
videos. Our extensive experiments on standard benchmarks demonstrate that Recap
is effective in multiple scenarios.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09922" title="Abstract">arXiv:2308.09922</a> [<a href="/pdf/2308.09922" title="Download PDF">pdf</a>, <a href="/format/2308.09922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MDCS: More Diverse Experts with Consistency Self-distillation for  Long-tailed Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qihao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV2023 Accept. 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, multi-expert methods have led to significant improvements in
long-tail recognition (LTR). We summarize two aspects that need further
enhancement to contribute to LTR boosting: (1) More diverse experts; (2) Lower
model variance. However, the previous methods didn't handle them well. To this
end, we propose More Diverse experts with Consistency Self-distillation (MDCS)
to bridge the gap left by earlier methods. Our MDCS approach consists of two
core components: Diversity Loss (DL) and Consistency Self-distillation (CS). In
detail, DL promotes diversity among experts by controlling their focus on
different categories. To reduce the model variance, we employ KL divergence to
distill the richer knowledge of weakly augmented instances for the experts'
self-distillation. In particular, we design Confident Instance Sampling (CIS)
to select the correctly classified instances for CS to avoid biased/noisy
knowledge. In the analysis and ablation study, we demonstrate that our method
compared with previous work can effectively increase the diversity of experts,
significantly reduce the variance of the model, and improve recognition
accuracy. Moreover, the roles of our DL and CS are mutually reinforcing and
coupled: the diversity of experts benefits from the CS, and the CS cannot
achieve remarkable results without the DL. Experiments show our MDCS
outperforms the state-of-the-art by 1% $\sim$ 2% on five popular long-tailed
benchmarks, including CIFAR10-LT, CIFAR100-LT, ImageNet-LT, Places-LT, and
iNaturalist 2018. The code is available at https://github.com/fistyee/MDCS.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09923" title="Abstract">arXiv:2308.09923</a> [<a href="/pdf/2308.09923" title="Download PDF">pdf</a>, <a href="/format/2308.09923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> East: Efficient and Accurate Secure Transformer Framework for Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yuanchao Ding</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hua Guo</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Y">Yewei Guan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weixin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+J">Jiarong Huo</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Z">Zhenyu Guan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiyong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Transformer has been successfully used in practical applications, such as
ChatGPT, due to its powerful advantages. However, users' input is leaked to the
model provider during the service. With people's attention to privacy,
privacy-preserving Transformer inference is on the demand of such services.
Secure protocols for non-linear functions are crucial in privacy-preserving
Transformer inference, which are not well studied. Thus, designing practical
secure protocols for non-linear functions is hard but significant to model
performance. In this work, we propose a framework \emph{East} to enable
efficient and accurate secure Transformer inference. Firstly, we propose a new
oblivious piecewise polynomial evaluation algorithm and apply it to the
activation functions, which reduces the runtime and communication of GELU by
over 1.5$\times$ and 2.5$\times$, compared to prior arts. Secondly, the secure
protocols for softmax and layer normalization are carefully designed to
faithfully maintain the desired functionality. Thirdly, several optimizations
are conducted in detail to enhance the overall efficiency. We applied
\emph{East} to BERT and the results show that the inference accuracy remains
consistent with the plaintext inference without fine-tuning. Compared to Iron,
we achieve about 1.8$\times$ lower communication within 1.2$\times$ lower
runtime.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09924" title="Abstract">arXiv:2308.09924</a> [<a href="/pdf/2308.09924" title="Download PDF">pdf</a>, <a href="/format/2308.09924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Autoethnographic Case Study of Generative Artificial Intelligence&#x27;s  Utility for Accessibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Glazko%2C+K+S">Kate S Glazko</a>, 
<a href="/search/cs?searchtype=author&query=Yamagami%2C+M">Momona Yamagami</a>, 
<a href="/search/cs?searchtype=author&query=Desai%2C+A">Aashaka Desai</a>, 
<a href="/search/cs?searchtype=author&query=Mack%2C+K+A">Kelly Avery Mack</a>, 
<a href="/search/cs?searchtype=author&query=Potluri%2C+V">Venkatesh Potluri</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xuhai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Mankoff%2C+J">Jennifer Mankoff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">With the recent rapid rise in Generative Artificial Intelligence (GAI) tools,
it is imperative that we understand their impact on people with disabilities,
both positive and negative. However, although we know that AI in general poses
both risks and opportunities for people with disabilities, little is known
specifically about GAI in particular. To address this, we conducted a
three-month autoethnography of our use of GAI to meet personal and professional
needs as a team of researchers with and without disabilities. Our findings
demonstrate a wide variety of potential accessibility-related uses for GAI
while also highlighting concerns around verifiability, training data, ableism,
and false promises.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09926" title="Abstract">arXiv:2308.09926</a> [<a href="/pdf/2308.09926" title="Download PDF">pdf</a>, <a href="/format/2308.09926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Train-to-Train Transmission Scheduling in mmWave Band for High  Speed Train Communication Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yunhan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yong Niu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+S">Shiwen Mao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhu Han</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ruisi He</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zhangdui Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Ning Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+B">Bo Ai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Demands for data traffic in high-speed railway (HSR) has increased
drastically. The increasing entertainment needs of passengers, safety control
information exchanges of trains, etc., make train-to-train (T2T) communications
face the challenge of achieving high-capacity and high-quality data
transmissions. In order to greatly increase the communication capacity, it is
urgent to introduce millimeter wave (mmWave) technology. Faced with the problem
that mmWave link is easy to be blocked, this paper leverages the existing
equipment to assist relay, and proposes an effective transmission scheduling
scheme to improve the robustness of T2T communication systems. First of all, we
formulate a mixed integer nonlinear programming (MINLP) optimization problem
the transmission scheduling in T2T communication systems where mobile relays
(MRs) are all working in the full-duplex (FD) mode. Then we propose a low
complexity heuristic algorithm to solve the optimization problem, which
consists of three components: relay selection, transmission mode selection, and
transmission scheduling. The simulation results show that the proposed
algorithm can greatly improve the number of completed flows and system
throughput. Finally, we analyze the influence of different design parameters on
the system performance. The results show that the proposed algorithm can
achieve more data flows and system throughput within a reasonable communication
distance threshold in T2T communication with obstacles in different orbits. It
can balance the computational complexity and system performance to achieve an
efficient and robust data transmission.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09931" title="Abstract">arXiv:2308.09931</a> [<a href="/pdf/2308.09931" title="Download PDF">pdf</a>, <a href="/format/2308.09931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TDG: Text-guided Domain Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Geng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8pages,3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Domain generalization (DG) attempts to generalize a model trained on single
or multiple source domains to the unseen target domain. Benefiting from the
success of Visual-and-Language Pre-trained models in recent years, we argue
that it is crucial for domain generalization by introducing extra text
information. In this paper, we develop a novel Text-guided Domain
Generalization (TDG) paradigm for domain generalization, which includes three
following aspects. Specifically, we first devise an automatic words generation
method to extend the description of current domains with novel domain-relevant
words. Then, we embed the generated domain information into the text feature
space, by the proposed prompt learning-based text feature generation method,
which shares a common representation space with the image feature. Finally, we
utilize both input image features and generated text features to train a
specially designed classifier that generalizes well on unseen target domains,
while the image encoder is also updated under the supervision of gradients back
propagated from the classifier. Our experimental results show that the
techniques incorporated by TDG contribute to the performance in an easy
implementation manner. Experimental results on several domain generalization
benchmarks show that our proposed framework achieves superior performance by
effectively leveraging generated text information in domain generalization.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09932" title="Abstract">arXiv:2308.09932</a> [<a href="/pdf/2308.09932" title="Download PDF">pdf</a>, <a href="/format/2308.09932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Do Code Models Memorize? An Empirical Study on Large Language  Models of Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhou Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhipeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jieke Shi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dongsun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+D">DongGyun Han</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The availability of large-scale datasets, advanced architectures, and
powerful computational resources have led to effective code models that
automate diverse software engineering activities. The datasets usually consist
of billions of lines of code from both open-source and private repositories. A
code model memorizes and produces source code verbatim, which potentially
contains vulnerabilities, sensitive information, or code with strict licenses,
leading to potential security and privacy issues.
<br />This paper investigates an important problem: to what extent do code models
memorize their training data? We conduct an empirical study to explore
memorization in large pre-trained code models. Our study highlights that simply
extracting 20,000 outputs (each having 512 tokens) from a code model can
produce over 40,125 code snippets that are memorized from the training data. To
provide a better understanding, we build a taxonomy of memorized contents with
3 categories and 14 subcategories. The results show that the prompts sent to
the code models affect the distribution of memorized contents. We identify
several key factors of memorization. Specifically, given the same architecture,
larger models suffer more from memorization problems. A code model produces
more memorization when it is allowed to generate longer outputs. We also find a
strong positive correlation between the number of an output's occurrences in
the training data and that in the generated outputs, which indicates that a
potential way to reduce memorization is to remove duplicates in the training
data. We then identify effective metrics that infer whether an output contains
memorization accurately. We also make some suggestions regarding dealing with
memorization in code models.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09934" title="Abstract">arXiv:2308.09934</a> [<a href="/pdf/2308.09934" title="Download PDF">pdf</a>, <a href="/format/2308.09934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint User Association and Transmission Scheduling in Integrated mmWave  Access and Terahertz Backhaul Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+B">Bo Ai</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yong Niu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Haiyan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+S">Shiwen Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zhangdui Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Ning Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Terahertz wireless backhaul is expected to meet the high-speed backhaul
requirements of future ultra-dense networks using millimeter-wave (mmWave) base
stations (BSs). In order to achieve higher network capacity with limited
resources and meet the quality of service (QoS) requirements of more users in
the integrated mmWave access and terahertz backhaul network, this paper
formulates a problem of maximizing the number of users successfully served in
both the access and backhaul links. Since the problem is a non-linear integer
optimization problem, a minimum rate ratio user association and transmission
scheduling algorithm is proposed to obtain a suboptimal solution. The proposed
algorithm takes the minimum rate ratio as the user association criterion and
schedules first the users with fewer backhaul transmission slots. In addition,
the algorithm will update the number of access transmission slots allocated to
users and the access scheduling results after the backhaul scheduling phase.
Numerical results show that the proposed algorithm outperforms several
benchmark algorithms in terms of the number of served users and system
throughput, and it can cope with a large number of bursty user requests.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09936" title="Abstract">arXiv:2308.09936</a> [<a href="/pdf/2308.09936" title="Download PDF">pdf</a>, <a href="/format/2308.09936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich Visual  Questions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wenbo Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yifan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+L">Li Yi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weiyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zeyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhuowen Tu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Vision Language Models (VLMs), which extend Large Language Models (LLM) by
incorporating visual understanding capability, have demonstrated significant
advancements in addressing open-ended visual question-answering (VQA) tasks.
However, these models cannot accurately interpret images infused with text, a
common occurrence in real-world scenarios. Standard procedures for extracting
information from images often involve learning a fixed set of query embeddings.
These embeddings are designed to encapsulate image contexts and are later used
as soft prompt inputs in LLMs. Yet, this process is limited to the token count,
potentially curtailing the recognition of scenes with text-rich context. To
improve upon them, the present study introduces BLIVA: an augmented version of
InstructBLIP with Visual Assistant. BLIVA incorporates the query embeddings
from InstructBLIP and also directly projects encoded patch embeddings into the
LLM, a technique inspired by LLaVA. This approach assists the model to capture
intricate details potentially missed during the query decoding process.
Empirical evidence demonstrates that our model, BLIVA, significantly enhances
performance in processing text-rich VQA benchmarks (up to 17.76\% in OCR-VQA
benchmark) and in undertaking typical VQA benchmarks (up to 7.9\% in Visual
Spatial Reasoning benchmark), comparing to our baseline InstructBLIP. BLIVA
demonstrates significant capability in decoding real-world images, irrespective
of text presence. To demonstrate the broad industry applications enabled by
BLIVA, we evaluate the model using a new dataset comprising YouTube thumbnails
paired with question-answer sets across 13 diverse categories. For researchers
interested in further exploration, our code and models are freely accessible at
https://github.com/mlpc-ucsd/BLIVA.git
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09937" title="Abstract">arXiv:2308.09937</a> [<a href="/pdf/2308.09937" title="Download PDF">pdf</a>, <a href="/format/2308.09937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Practical Anomaly Detection over Multivariate Monitoring Metrics for  Online Services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tianyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuangbin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yuxin Su</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Cong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zengyin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+M+R">Michael R. Lyu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by the 34th IEEE International Symposium on Software Reliability Engineering (ISSRE'2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">As modern software systems continue to grow in terms of complexity and
volume, anomaly detection on multivariate monitoring metrics, which profile
systems' health status, becomes more and more critical and challenging. In
particular, the dependency between different metrics and their historical
patterns plays a critical role in pursuing prompt and accurate anomaly
detection. Existing approaches fall short of industrial needs for being unable
to capture such information efficiently. To fill this significant gap, in this
paper, we propose CMAnomaly, an anomaly detection framework on multivariate
monitoring metrics based on collaborative machine. The proposed collaborative
machine is a mechanism to capture the pairwise interactions along with feature
and temporal dimensions with linear time complexity. Cost-effective models can
then be employed to leverage both the dependency between monitoring metrics and
their historical patterns for anomaly detection. The proposed framework is
extensively evaluated with both public data and industrial data collected from
a large-scale online service system of Huawei Cloud. The experimental results
demonstrate that compared with state-of-the-art baseline models, CMAnomaly
achieves an average F1 score of 0.9494, outperforming baselines by 6.77% to
10.68%, and runs 10X to 20X faster. Furthermore, we also share our experience
of deploying CMAnomaly in Huawei Cloud.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09939" title="Abstract">arXiv:2308.09939</a> [<a href="/pdf/2308.09939" title="Download PDF">pdf</a>, <a href="/format/2308.09939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Self-attention Mechanism via Dynamical System Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhongzhan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+M">Mingfu Liang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jinghui Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+S">Shanshan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Liang Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The self-attention mechanism (SAM) is widely used in various fields of
artificial intelligence and has successfully boosted the performance of
different models. However, current explanations of this mechanism are mainly
based on intuitions and experiences, while there still lacks direct modeling
for how the SAM helps performance. To mitigate this issue, in this paper, based
on the dynamical system perspective of the residual neural network, we first
show that the intrinsic stiffness phenomenon (SP) in the high-precision
solution of ordinary differential equations (ODEs) also widely exists in
high-performance neural networks (NN). Thus the ability of NN to measure SP at
the feature level is necessary to obtain high performance and is an important
factor in the difficulty of training NN. Similar to the adaptive step-size
method which is effective in solving stiff ODEs, we show that the SAM is also a
stiffness-aware step size adaptor that can enhance the model's representational
ability to measure intrinsic SP by refining the estimation of stiffness
information and generating adaptive attention values, which provides a new
understanding about why and how the SAM can benefit the model performance. This
novel perspective can also explain the lottery ticket hypothesis in SAM, design
new quantitative metrics of representational ability, and inspire a new
theoretic-inspired approach, StepNet. Extensive experiments on several popular
benchmarks demonstrate that StepNet can extract fine-grained stiffness
information and measure SP accurately, leading to significant improvements in
various visual tasks.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09940" title="Abstract">arXiv:2308.09940</a> [<a href="/pdf/2308.09940" title="Download PDF">pdf</a>, <a href="/format/2308.09940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Transfer Learning for Simplifying GitHub READMEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Haoyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Treude%2C+C">Christoph Treude</a>, 
<a href="/search/cs?searchtype=author&query=Zahedi%2C+M">Mansooreh Zahedi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ESEC/FSE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Software documentation captures detailed knowledge about a software product,
e.g., code, technologies, and design. It plays an important role in the
coordination of development teams and in conveying ideas to various
stakeholders. However, software documentation can be hard to comprehend if it
is written with jargon and complicated sentence structure. In this study, we
explored the potential of text simplification techniques in the domain of
software engineering to automatically simplify GitHub README files. We
collected software-related pairs of GitHub README files consisting of 14,588
entries, aligned difficult sentences with their simplified counterparts, and
trained a Transformer-based model to automatically simplify difficult versions.
To mitigate the sparse and noisy nature of the software-related simplification
dataset, we applied general text simplification knowledge to this field. Since
many general-domain difficult-to-simple Wikipedia document pairs are already
publicly available, we explored the potential of transfer learning by first
training the model on the Wikipedia data and then fine-tuning it on the README
data. Using automated BLEU scores and human evaluation, we compared the
performance of different transfer learning schemes and the baseline models
without transfer learning. The transfer learning model using the best
checkpoint trained on a general topic corpus achieved the best performance of
34.68 BLEU score and statistically significantly higher human annotation scores
compared to the rest of the schemes and baselines. We conclude that using
transfer learning is a promising direction to circumvent the lack of data and
drift style problem in software README files simplification and achieved a
better trade-off between simplification and preservation of meaning.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09942" title="Abstract">arXiv:2308.09942</a> [<a href="/pdf/2308.09942" title="Download PDF">pdf</a>, <a href="/format/2308.09942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Robustness of Open-World Test-Time Training: Self-Training with  Dynamic Prototype Expansion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yushu Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yongyi Su</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+K">Kui Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Generalizing deep learning models to unknown target domain distribution with
low latency has motivated research into test-time training/adaptation
(TTT/TTA). Existing approaches often focus on improving test-time training
performance under well-curated target domain data. As figured out in this work,
many state-of-the-art methods fail to maintain the performance when the target
domain is contaminated with strong out-of-distribution (OOD) data, a.k.a.
open-world test-time training (OWTTT). The failure is mainly due to the
inability to distinguish strong OOD samples from regular weak OOD samples. To
improve the robustness of OWTTT we first develop an adaptive strong OOD pruning
which improves the efficacy of the self-training TTT method. We further propose
a way to dynamically expand the prototypes to represent strong OOD samples for
an improved weak/strong OOD data separation. Finally, we regularize
self-training with distribution alignment and the combination yields the
state-of-the-art performance on 5 OWTTT benchmarks. The code is available at
https://github.com/Yushu-Li/OWTTT.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09943" title="Abstract">arXiv:2308.09943</a> [<a href="/pdf/2308.09943" title="Download PDF">pdf</a>, <a href="/format/2308.09943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> printf: Preference Modeling Based on User Reviews with Item Images and  Textual Information via Graph Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hao-Lun Lin</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jyun-Yu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Juan%2C+M">Ming-Hao Juan</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Pu-Jen Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of The 32nd ACM International Conference on Information and Knowledge Management (CIKM '23), ACM, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Nowadays, modern recommender systems usually leverage textual and visual
contents as auxiliary information to predict user preference. For textual
information, review texts are one of the most popular contents to model user
behaviors. Nevertheless, reviews usually lose their shine when it comes to
top-N recommender systems because those that solely utilize textual reviews as
features struggle to adequately capture the interaction relationships between
users and items. For visual one, it is usually modeled with naive convolutional
networks and also hard to capture high-order relationships between users and
items. Moreover, previous works did not collaboratively use both texts and
images in a proper way. In this paper, we propose printf, preference modeling
based on user reviews with item images and textual information via graph
learning, to address the above challenges. Specifically, the dimension-based
attention mechanism directs relations between user reviews and interacted
items, allowing each dimension to contribute different importance weights to
derive user representations. Extensive experiments are conducted on three
publicly available datasets. The experimental results demonstrate that our
proposed printf consistently outperforms baseline methods with the relative
improvements for NDCG@5 of 26.80%, 48.65%, and 25.74% on Amazon-Grocery,
Amazon-Tools, and Amazon-Electronics datasets, respectively. The in-depth
analysis also indicates the dimensions of review representations definitely
have different topics and aspects, assisting the validity of our model design.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09944" title="Abstract">arXiv:2308.09944</a> [<a href="/pdf/2308.09944" title="Download PDF">pdf</a>, <a href="/format/2308.09944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial Reconstructed Local Attention Res2Net with F0 Subband for Fake  Speech Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Cunhang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+J">Jun Xue</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+J">Jianhua Tao</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jiangyan Yi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenglong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chengshi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Z">Zhao Lv</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The rhythm of synthetic speech is usually too smooth, which causes that the
fundamental frequency (F0) of synthetic speech is significantly different from
that of real speech. It is expected that the F0 feature contains the
discriminative information for the fake speech detection (FSD) task. In this
paper, we propose a novel F0 subband for FSD. In addition, to effectively model
the F0 subband so as to improve the performance of FSD, the spatial
reconstructed local attention Res2Net (SR-LA Res2Net) is proposed.
Specifically, Res2Net is used as a backbone network to obtain multiscale
information, and enhanced with a spatial reconstruction mechanism to avoid
losing important information when the channel group is constantly superimposed.
In addition, local attention is designed to make the model focus on the local
information of the F0 subband. Experimental results on the ASVspoof 2019 LA
dataset show that our proposed method obtains an equal error rate (EER) of
0.47% and a minimum tandem detection cost function (min t-DCF) of 0.0159,
achieving the state-of-the-art performance among all of the single systems.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09946" title="Abstract">arXiv:2308.09946</a> [<a href="/pdf/2308.09946" title="Download PDF">pdf</a>, <a href="/format/2308.09946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly-Supervised Action Localization by Hierarchically-structured  Latent Attention Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guiqin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Peng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Cong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shusen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jie Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Leng%2C+L">Luziwei Leng</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+J">Jianxing Liao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qinghai Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Weakly-supervised action localization aims to recognize and localize action
instancese in untrimmed videos with only video-level labels. Most existing
models rely on multiple instance learning(MIL), where the predictions of
unlabeled instances are supervised by classifying labeled bags. The MIL-based
methods are relatively well studied with cogent performance achieved on
classification but not on localization. Generally, they locate temporal regions
by the video-level classification but overlook the temporal variations of
feature semantics. To address this problem, we propose a novel attention-based
hierarchically-structured latent model to learn the temporal variations of
feature semantics. Specifically, our model entails two components, the first is
an unsupervised change-points detection module that detects change-points by
learning the latent representations of video features in a temporal hierarchy
based on their rates of change, and the second is an attention-based
classification model that selects the change-points of the foreground as the
boundaries. To evaluate the effectiveness of our model, we conduct extensive
experiments on two benchmark datasets, THUMOS-14 and ActivityNet-v1.3. The
experiments show that our method outperforms current state-of-the-art methods,
and even achieves comparable performance with fully-supervised methods.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09947" title="Abstract">arXiv:2308.09947</a> [<a href="/pdf/2308.09947" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Study on the effectiveness of AutoML in detecting cardiovascular disease
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Afanasieva%2C+T+V">T.V. Afanasieva</a>, 
<a href="/search/cs?searchtype=author&query=Kuzlyakin%2C+A+P">A.P. Kuzlyakin</a>, 
<a href="/search/cs?searchtype=author&query=Komolov%2C+A+V">A.V. Komolov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Cardiovascular diseases are widespread among patients with chronic
noncommunicable diseases and are one of the leading causes of death, including
in the working age. The article presents the relevance of the development and
application of patient-oriented systems, in which machine learning (ML) is a
promising technology that allows predicting cardiovascular diseases. Automated
machine learning (AutoML) makes it possible to simplify and speed up the
process of developing AI/ML applications, which is key in the development of
patient-oriented systems by application users, in particular medical
specialists. The authors propose a framework for the application of automatic
machine learning and three scenarios that allowed for data combining five data
sets of cardiovascular disease indicators from the UCI Machine Learning
Repository to investigate the effectiveness in detecting this class of
diseases. The study investigated one AutoML model that used and optimized the
hyperparameters of thirteen basic ML models (KNeighborsUnif, KNeighborsDist,
LightGBMXT, LightGBM, RandomForestGini, RandomForestEntr, CatBoost,
ExtraTreesGini, ExtraTreesEntr, NeuralNetFastA, XGBoost, NeuralNetTorch,
LightGBMLarge) and included the most accurate models in the weighted ensemble.
The results of the study showed that the structure of the AutoML model for
detecting cardiovascular diseases depends not only on the efficiency and
accuracy of the basic models used, but also on the scenarios for preprocessing
the initial data, in particular, on the technique of data normalization. The
comparative analysis showed that the accuracy of the AutoML model in detecting
cardiovascular disease varied in the range from 87.41% to 92.3%, and the
maximum accuracy was obtained when normalizing the source data into binary
values, and the minimum was obtained when using the built-in AutoML technique.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09948" title="Abstract">arXiv:2308.09948</a> [<a href="/pdf/2308.09948" title="Download PDF">pdf</a>, <a href="/format/2308.09948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bamboo: Boosting Training Efficiency for Real-Time Video Streaming via  Online Grouped Federated Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Q">Qianyuan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhan Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper will be presented at Apnet 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">Most of the learning-based algorithms for bitrate adaptation are limited to
offline learning, which inevitably suffers from the simulation-to-reality gap.
Online learning can better adapt to dynamic real-time communication scenes but
still face the challenge of lengthy training convergence time. In this paper,
we propose a novel online grouped federated transfer learning framework named
Bamboo to accelerate training efficiency. The preliminary experiments validate
that our method remarkably improves online training efficiency by up to 302%
compared to other reinforcement learning algorithms in various network
conditions while ensuring the quality of experience (QoE) of real-time video
communication.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09949" title="Abstract">arXiv:2308.09949</a> [<a href="/pdf/2308.09949" title="Download PDF">pdf</a>, <a href="/format/2308.09949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scene-Aware Feature Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiaoyong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yaping Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+T">Tong Wei</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S">Songlin Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Current feature matching methods focus on point-level matching, pursuing
better representation learning of individual features, but lacking further
understanding of the scene. This results in significant performance degradation
when handling challenging scenes such as scenes with large viewpoint and
illumination changes. To tackle this problem, we propose a novel model named
SAM, which applies attentional grouping to guide Scene-Aware feature Matching.
SAM handles multi-level features, i.e., image tokens and group tokens, with
attention layers, and groups the image tokens with the proposed token grouping
module. Our model can be trained by ground-truth matches only and produce
reasonable grouping results. With the sense-aware grouping guidance, SAM is not
only more accurate and robust but also more interpretable than conventional
feature matching models. Sufficient experiments on various applications,
including homography estimation, pose estimation, and image matching,
demonstrate that our model achieves state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09951" title="Abstract">arXiv:2308.09951</a> [<a href="/pdf/2308.09951" title="Download PDF">pdf</a>, <a href="/format/2308.09951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantics Meets Temporal Correspondence: Self-supervised Object-centric  Learning in Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+R">Rui Qian</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+S">Shuangrui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Self-supervised methods have shown remarkable progress in learning high-level
semantics and low-level temporal correspondence. Building on these results, we
take one step further and explore the possibility of integrating these two
features to enhance object-centric representations. Our preliminary experiments
indicate that query slot attention can extract different semantic components
from the RGB feature map, while random sampling based slot attention can
exploit temporal correspondence cues between frames to assist instance
identification. Motivated by this, we propose a novel semantic-aware masked
slot attention on top of the fused semantic features and correspondence maps.
It comprises two slot attention stages with a set of shared learnable Gaussian
distributions. In the first stage, we use the mean vectors as slot
initialization to decompose potential semantics and generate semantic
segmentation masks through iterative attention. In the second stage, for each
semantics, we randomly sample slots from the corresponding Gaussian
distribution and perform masked feature aggregation within the semantic area to
exploit temporal correspondence patterns for instance identification. We adopt
semantic- and instance-level temporal consistency as self-supervision to
encourage temporally coherent object-centric representations. Our model
effectively identifies multiple object instances with semantic structure,
reaching promising results on unsupervised video object discovery. Furthermore,
we achieve state-of-the-art performance on dense label propagation tasks,
demonstrating the potential for object-centric analysis. The code is released
at https://github.com/shvdiwnkozbw/SMTC.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09953" title="Abstract">arXiv:2308.09953</a> [<a href="/pdf/2308.09953" title="Download PDF">pdf</a>, <a href="/format/2308.09953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniAP: Towards Universal Animal Perception in Vision via Few-shot  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Meiqi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhonghan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+W">Wenhao Chai</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Hanjun Luo</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Shidong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanting Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jenq-Neng Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gaoang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Animal visual perception is an important technique for automatically
monitoring animal health, understanding animal behaviors, and assisting
animal-related research. However, it is challenging to design a deep
learning-based perception model that can freely adapt to different animals
across various perception tasks, due to the varying poses of a large diversity
of animals, lacking data on rare species, and the semantic inconsistency of
different tasks. We introduce UniAP, a novel Universal Animal Perception model
that leverages few-shot learning to enable cross-species perception among
various visual tasks. Our proposed model takes support images and labels as
prompt guidance for a query image. Images and labels are processed through a
Transformer-based encoder and a lightweight label encoder, respectively. Then a
matching module is designed for aggregating information between prompt guidance
and the query image, followed by a multi-head label decoder to generate outputs
for various tasks. By capitalizing on the shared visual characteristics among
different animals and tasks, UniAP enables the transfer of knowledge from
well-studied species to those with limited labeled data or even unseen species.
We demonstrate the effectiveness of UniAP through comprehensive experiments in
pose estimation, segmentation, and classification tasks on diverse animal
species, showcasing its ability to generalize and adapt to new classes with
minimal labeled examples.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09954" title="Abstract">arXiv:2308.09954</a> [<a href="/pdf/2308.09954" title="Download PDF">pdf</a>, <a href="/format/2308.09954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eva-KELLM: A New Benchmark for Evaluating Knowledge Editing of LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Suhang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+M">Minlong Peng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yue Chen</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Jinsong Su</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mingming Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) possess a wealth of knowledge encoded in their
parameters. However, this knowledge may become outdated or unsuitable over
time. As a result, there has been a growing interest in knowledge editing for
LLMs and evaluating its effectiveness. Existing studies primarily focus on
knowledge editing using factual triplets, which not only incur high costs for
collection but also struggle to express complex facts. Furthermore, these
studies are often limited in their evaluation perspectives. In this paper, we
propose Eva-KELLM, a new benchmark for evaluating knowledge editing of LLMs.
This benchmark includes an evaluation framework and a corresponding dataset.
Under our framework, we first ask the LLM to perform knowledge editing using
raw documents, which provides a more convenient and universal approach compared
to using factual triplets. We then evaluate the updated LLM from multiple
perspectives. In addition to assessing the effectiveness of knowledge editing
and the retention of unrelated knowledge from conventional studies, we further
test the LLM's ability in two aspects: 1) Reasoning with the altered knowledge,
aiming for the LLM to genuinely learn the altered knowledge instead of simply
memorizing it. 2) Cross-lingual knowledge transfer, where the LLM updated with
raw documents in one language should be capable of handling queries from
another language. To facilitate further research, we construct and release the
corresponding dataset. Using this benchmark, we investigate the effectiveness
of several commonly-used knowledge editing methods. Experimental results
indicate that the current methods for knowledge editing using raw documents are
not effective in yielding satisfactory results, particularly when it comes to
reasoning with altered knowledge and cross-lingual knowledge transfer.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09955" title="Abstract">arXiv:2308.09955</a> [<a href="/pdf/2308.09955" title="Download PDF">pdf</a>, <a href="/format/2308.09955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To prune or not to prune : A chaos-causality approach to principled  pruning of dense neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sahu%2C+R">Rajan Sahu</a>, 
<a href="/search/cs?searchtype=author&query=Chadha%2C+S">Shivam Chadha</a>, 
<a href="/search/cs?searchtype=author&query=Nagaraj%2C+N">Nithin Nagaraj</a>, 
<a href="/search/cs?searchtype=author&query=Mathur%2C+A">Archana Mathur</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+S">Snehanshu Saha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Reducing the size of a neural network (pruning) by removing weights without
impacting its performance is an important problem for resource-constrained
devices. In the past, pruning was typically accomplished by ranking or
penalizing weights based on criteria like magnitude and removing low-ranked
weights before retraining the remaining ones. Pruning strategies may also
involve removing neurons from the network in order to achieve the desired
reduction in network size. We formulate pruning as an optimization problem with
the objective of minimizing misclassifications by selecting specific weights.
To accomplish this, we have introduced the concept of chaos in learning
(Lyapunov exponents) via weight updates and exploiting causality to identify
the causal weights responsible for misclassification. Such a pruned network
maintains the original performance and retains feature explainability.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09956" title="Abstract">arXiv:2308.09956</a> [<a href="/pdf/2308.09956" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FEM-PIKFNNs for underwater acoustic propagation induced by structural  vibrations in different ocean environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Xi%2C+Q">Qiang Xi</a>, 
<a href="/search/math?searchtype=author&query=Fu%2C+Z">Zhuojia Fu</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+W">Wenzhi Xu</a>, 
<a href="/search/math?searchtype=author&query=Xue%2C+M">Mi-An Xue</a>, 
<a href="/search/math?searchtype=author&query=Zheng%2C+J">Jinhai Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, a novel hybrid method based on the finite element method (FEM)
and physics-informed kernel function neural networks (PIKFNNs) is proposed and
applied to the prediction of underwater acoustic propagation induced by
structural vibrations in the unbounded ocean, deep ocean and shallow ocean. In
the hybrid method, PIKFNNs are a class of improved shallow physics-informed
neural networks (PINNs) that replace the activation functions in PINNs with the
physics-informed kernel functions (PIKFs), thereby integrating prior physical
information into the neural network model. Moreover, this neural network
circumvents the step of embedding the governing equations into the loss
function in PINNs, and requires only training on boundary data. By using the
Green's functions as the PIKFs and the structural-acoustic coupling response
information obtained from the FEM as boundary training data, the PIKFNNs can
inherently capture the Sommerfeld radiation condition at infinity, which is
naturally suitable for predicting ocean acoustic propagation. Numerical
experiments demonstrate the accuracy and feasibility of the FEM-PIKFNNs in
comparison with the true solutions and finite element results.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09957" title="Abstract">arXiv:2308.09957</a> [<a href="/pdf/2308.09957" title="Download PDF">pdf</a>, <a href="/format/2308.09957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-to-text Generation for Severely Under-Resourced Languages with  GPT-3.5: A Bit of Help Needed from Google Translate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lorandi%2C+M">Michela Lorandi</a>, 
<a href="/search/cs?searchtype=author&query=Belz%2C+A">Anya Belz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">LLMs like GPT are great at tasks involving English which dominates in their
training data. In this paper, we look at how they cope with tasks involving
languages that are severely under-represented in their training data, in the
context of data-to-text generation for Irish, Maltese, Welsh and Breton. During
the prompt-engineering phase we tested a range of prompt types and formats on
GPT-3.5 and~4 with a small sample of example input/output pairs. We then fully
evaluated the two most promising prompts in two scenarios: (i) direct
generation into the under-resourced language, and (ii) generation into English
followed by translation into the under-resourced language. We find that
few-shot prompting works better for direct generation into under-resourced
languages, but that the difference disappears when pivoting via English. The
few-shot + translation system variants were submitted to the WebNLG 2023 shared
task where they outperformed competitor systems by substantial margins in all
languages on all metrics. We conclude that good performance on under-resourced
languages can be achieved out-of-the box with state-of-the-art LLMs. However,
our best results (for Welsh) remain well below the lowest ranked English system
at WebNLG'20.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09958" title="Abstract">arXiv:2308.09958</a> [<a href="/pdf/2308.09958" title="Download PDF">pdf</a>, <a href="/format/2308.09958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparison of Adversarial Learning Techniques for Malware Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Louth%C3%A1nov%C3%A1%2C+P">Pavla Louth&#xe1;nov&#xe1;</a>, 
<a href="/search/cs?searchtype=author&query=Koz%C3%A1k%2C+M">Matou&#x161; Koz&#xe1;k</a>, 
<a href="/search/cs?searchtype=author&query=Jure%C4%8Dek%2C+M">Martin Jure&#x10d;ek</a>, 
<a href="/search/cs?searchtype=author&query=Stamp%2C+M">Mark Stamp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine learning has proven to be a useful tool for automated malware
detection, but machine learning models have also been shown to be vulnerable to
adversarial attacks. This article addresses the problem of generating
adversarial malware samples, specifically malicious Windows Portable Executable
files. We summarize and compare work that has focused on adversarial machine
learning for malware detection. We use gradient-based, evolutionary
algorithm-based, and reinforcement-based methods to generate adversarial
samples, and then test the generated samples against selected antivirus
products. We compare the selected methods in terms of accuracy and practical
applicability. The results show that applying optimized modifications to
previously detected malware can lead to incorrect classification of the file as
benign. It is also known that generated malware samples can be successfully
used against detection models other than those used to generate them and that
using combinations of generators can create new samples that evade detection.
Experiments show that the Gym-malware generator, which uses a reinforcement
learning approach, has the greatest practical potential. This generator
achieved an average sample generation time of 5.73 seconds and the highest
average evasion rate of 44.11%. Using the Gym-malware generator in combination
with itself improved the evasion rate to 58.35%.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09959" title="Abstract">arXiv:2308.09959</a> [<a href="/pdf/2308.09959" title="Download PDF">pdf</a>, <a href="/format/2308.09959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hummingbird: A Flexible and Lightweight Inter-Domain  Bandwidth-Reservation System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Giuliari%2C+G">Giacomo Giuliari</a>, 
<a href="/search/cs?searchtype=author&query=Legner%2C+M">Markus Legner</a>, 
<a href="/search/cs?searchtype=author&query=Perrig%2C+A">Adrian Perrig</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+J">Jean-Pierre Smith</a>, 
<a href="/search/cs?searchtype=author&query=W%C3%BCst%2C+K">Karl W&#xfc;st</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The current Internet lacks a bandwidth-reservation infrastructure that
enables fine-grained inter-domain reservations for end hosts. This is hindering
the provisioning of quality-of-service guarantees for real-time applications
like video calls and gaming, cloud-based systems, financial transactions,
telesurgery, and other remote applications that benefit from reliable
communication. This paper introduces Hummingbird, a novel lightweight
inter-domain bandwidth-reservation system that addresses several shortcomings
of previous designs.
<br />Hummingbird supports flexible and composable reservations and enables
end-to-end guarantees without requiring autonomous systems to manage
reservations for their endhosts. Previous systems tied reservations to
autonomous-system numbers or network addresses, which limits the flexibility of
reservations. In contrast, our system decouples reservations from network
identities and, as a result, the control plane from the data plane. This design
choice facilitates multiple co-existing control-plane mechanisms and enables
innovative approaches, such as a control plane based on blockchain smart
contracts that offers tradeable bandwidth-reservation assets and end-to-end
guarantees. The data-plane design ensures simplicity for efficient processing
on border routers, which streamlines implementation, deployment, and traffic
policing while maintaining robust security properties.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09960" title="Abstract">arXiv:2308.09960</a> [<a href="/pdf/2308.09960" title="Download PDF">pdf</a>, <a href="/format/2308.09960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Self-Adaptive Machine Learning-Enabled Systems Through QoS-Aware  Model Switching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+S">Shubham Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Marda%2C+A">Arya Marda</a>, 
<a href="/search/cs?searchtype=author&query=Vaidhyanathan%2C+K">Karthik Vaidhyanathan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in 38th IEEE/ACM International Conference on Automated Software Engineering (ASE 2023) in New Ideas and Emerging Results (NIER) track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine Learning (ML), particularly deep learning, has seen vast
advancements, leading to the rise of Machine Learning-Enabled Systems (MLS).
However, numerous software engineering challenges persist in propelling these
MLS into production, largely due to various run-time uncertainties that impact
the overall Quality of Service (QoS). These uncertainties emanate from ML
models, software components, and environmental factors. Self-adaptation
techniques present potential in managing run-time uncertainties, but their
application in MLS remains largely unexplored. As a solution, we propose the
concept of a Machine Learning Model Balancer, focusing on managing
uncertainties related to ML models by using multiple models. Subsequently, we
introduce AdaMLS, a novel self-adaptation approach that leverages this concept
and extends the traditional MAPE-K loop for continuous MLS adaptation. AdaMLS
employs lightweight unsupervised learning for dynamic model switching, thereby
ensuring consistent QoS. Through a self-adaptive object detection system
prototype, we demonstrate AdaMLS's effectiveness in balancing system and model
performance. Preliminary results suggest AdaMLS surpasses naive and single
state-of-the-art models in QoS guarantees, heralding the advancement towards
self-adaptive MLS with optimal QoS in dynamic environments.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09963" title="Abstract">arXiv:2308.09963</a> [<a href="/pdf/2308.09963" title="Download PDF">pdf</a>, <a href="/format/2308.09963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeutrEx: A 3D Quality Component Measure on Facial Expression Neutrality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grimmer%2C+M">Marcel Grimmer</a>, 
<a href="/search/cs?searchtype=author&query=Rathgeb%2C+C">Christian Rathgeb</a>, 
<a href="/search/cs?searchtype=author&query=Veldhuis%2C+R">Raymond Veldhuis</a>, 
<a href="/search/cs?searchtype=author&query=Busch%2C+C">Christoph Busch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Accurate face recognition systems are increasingly important in sensitive
applications like border control or migration management. Therefore, it becomes
crucial to quantify the quality of facial images to ensure that low-quality
images are not affecting recognition accuracy. In this context, the current
draft of ISO/IEC 29794-5 introduces the concept of component quality to
estimate how single factors of variation affect recognition outcomes. In this
study, we propose a quality measure (NeutrEx) based on the accumulated
distances of a 3D face reconstruction to a neutral expression anchor. Our
evaluations demonstrate the superiority of our proposed method compared to
baseline approaches obtained by training Support Vector Machines on face
embeddings extracted from a pre-trained Convolutional Neural Network for facial
expression classification. Furthermore, we highlight the explainable nature of
our NeutrEx measures by computing per-vertex distances to unveil the most
impactful face regions and allow operators to give actionable feedback to
subjects.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09964" title="Abstract">arXiv:2308.09964</a> [<a href="/pdf/2308.09964" title="Download PDF">pdf</a>, <a href="/ps/2308.09964" title="Download PostScript">ps</a>, <a href="/format/2308.09964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bilateral Trade with Correlated Values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dobzinski%2C+S">Shahar Dobzinski</a>, 
<a href="/search/cs?searchtype=author&query=Shaulker%2C+A">Ariel Shaulker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We study the bilateral trade problem where a seller owns a single indivisible
item, and a potential buyer seeks to purchase it. Previous mechanisms for this
problem only considered the case where the values of the buyer and the seller
are drawn from independent distributions. In this paper, we study bilateral
trade mechanisms when the values are drawn from a joint distribution.
<br />We prove that the buyer-offering mechanism guarantees an approximation ratio
of $\frac e {e-1} \approx 1.582$ to the social welfare even if the values are
drawn from a joint distribution. The buyer-offering mechanism is Bayesian
incentive compatible, but the seller has a dominant strategy. We prove the
buyer-offering mechanism is optimal in the sense that no Bayesian mechanism
where one of the players has a dominant strategy can obtain an approximation
ratio better than $\frac e {e-1}$. We also show that no mechanism in which both
sides have a dominant strategy can provide any constant approximation to the
social welfare when the values are drawn from a joint distribution.
<br />Finally, we prove some impossibility results on the power of general Bayesian
incentive compatible mechanisms. In particular, we show that no deterministic
Bayesian incentive-compatible mechanism can provide an approximation ratio
better than $1+\frac {\ln 2} 2\approx 1.346$.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09965" title="Abstract">arXiv:2308.09965</a> [<a href="/pdf/2308.09965" title="Download PDF">pdf</a>, <a href="/format/2308.09965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anomaly-Aware Semantic Segmentation via Style-Aligned OoD Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sakmann%2C+K">Kaspar Sakmann</a>, 
<a href="/search/cs?searchtype=author&query=Beluch%2C+W">William Beluch</a>, 
<a href="/search/cs?searchtype=author&query=Hutmacher%2C+R">Robin Hutmacher</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yumeng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV2023 Workshop on Robustness and Reliability of Autonomous Vehicles in the Open-world (BRAVO)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Within the context of autonomous driving, encountering unknown objects
becomes inevitable during deployment in the open world. Therefore, it is
crucial to equip standard semantic segmentation models with anomaly awareness.
Many previous approaches have utilized synthetic out-of-distribution (OoD) data
augmentation to tackle this problem. In this work, we advance the OoD synthesis
process by reducing the domain gap between the OoD data and driving scenes,
effectively mitigating the style difference that might otherwise act as an
obvious shortcut during training. Additionally, we propose a simple fine-tuning
loss that effectively induces a pre-trained semantic segmentation model to
generate a ``none of the given classes" prediction, leveraging per-pixel OoD
scores for anomaly segmentation. With minimal fine-tuning effort, our pipeline
enables the use of pre-trained models for anomaly segmentation while
maintaining the performance on the original task.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09966" title="Abstract">arXiv:2308.09966</a> [<a href="/pdf/2308.09966" title="Download PDF">pdf</a>, <a href="/format/2308.09966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-aligned Exposure-enhanced Model for Click-Through Rate Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hengyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+C">Chang Meng</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Wei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Huifeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jieming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+G">Guangpeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruiming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiu Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Click-Through Rate (CTR) prediction, crucial in applications like recommender
systems and online advertising, involves ranking items based on the likelihood
of user clicks. User behavior sequence modeling has marked progress in CTR
prediction, which extracts users' latent interests from their historical
behavior sequences to facilitate accurate CTR prediction. Recent research
explores using implicit feedback sequences, like unclicked records, to extract
diverse user interests. However, these methods encounter key challenges: 1)
temporal misalignment due to disparate sequence time ranges and 2) the lack of
fine-grained interaction among feedback sequences. To address these challenges,
we propose a novel framework called TEM4CTR, which ensures temporal alignment
among sequences while leveraging auxiliary feedback information to enhance
click behavior at the item level through a representation projection mechanism.
Moreover, this projection-based information transfer module can effectively
alleviate the negative impact of irrelevant or even potentially detrimental
components of the auxiliary feedback information on the learning process of
click behavior. Comprehensive experiments on public and industrial datasets
confirm the superiority and effectiveness of TEM4CTR, showcasing the
significance of temporal alignment in multi-feedback modeling.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09969" title="Abstract">arXiv:2308.09969</a> [<a href="/pdf/2308.09969" title="Download PDF">pdf</a>, <a href="/format/2308.09969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On-the-fly Improving Performance of Deep Code Models via Input Denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangyu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ASE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Deep learning has been widely adopted to tackle various code-based tasks by
building deep code models based on a large amount of code snippets. While these
deep code models have achieved great success, even state-of-the-art models
suffer from noise present in inputs leading to erroneous predictions. While it
is possible to enhance models through retraining/fine-tuning, this is not a
once-and-for-all approach and incurs significant overhead. In particular, these
techniques cannot on-the-fly improve performance of (deployed) models. There
are currently some techniques for input denoising in other domains (such as
image processing), but since code input is discrete and must strictly abide by
complex syntactic and semantic constraints, input denoising techniques in other
fields are almost not applicable. In this work, we propose the first input
denoising technique (i.e., CodeDenoise) for deep code models. Its key idea is
to localize noisy identifiers in (likely) mispredicted inputs, and denoise such
inputs by cleansing the located identifiers. It does not need to retrain or
reconstruct the model, but only needs to cleanse inputs on-the-fly to improve
performance. Our experiments on 18 deep code models (i.e., three pre-trained
models with six code-based datasets) demonstrate the effectiveness and
efficiency of CodeDenoise. For example, on average, CodeDenoise successfully
denoises 21.91% of mispredicted inputs and improves the original models by
2.04% in terms of the model accuracy across all the subjects in an average of
0.48 second spent on each input, substantially outperforming the widely-used
fine-tuning strategy.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09970" title="Abstract">arXiv:2308.09970</a> [<a href="/pdf/2308.09970" title="Download PDF">pdf</a>, <a href="/format/2308.09970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tackling Vision Language Tasks Through Learning Inner Monologues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Diji Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kezhen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+J">Jinmeng Rao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiaoyuan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yawen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Visual language tasks require AI models to comprehend and reason with both
visual and textual content. Driven by the power of Large Language Models
(LLMs), two prominent methods have emerged: (1) the hybrid integration between
LLMs and Vision-Language Models (VLMs), where visual inputs are firstly
converted into language descriptions by VLMs, serving as inputs for LLMs to
generate final answer(s); (2) visual feature alignment in language space, where
visual inputs are encoded as embeddings and projected to LLMs' language space
via further supervised fine-tuning. The first approach provides light training
costs and interpretability but is hard to be optimized in an end-to-end
fashion. The second approach presents decent performance, but feature alignment
usually requires large amounts of training data and lacks interpretability. To
tackle this dilemma, we propose a novel approach, Inner Monologue Multi-Modal
Optimization (IMMO), to solve complex vision language problems by simulating
inner monologue processes, a cognitive process in which an individual engages
in silent verbal communication with themselves. We enable LLMs and VLMs to
interact through natural language conversation and propose to use a two-stage
training process to learn how to do the inner monologue (self-asking questions
and answering questions). IMMO is evaluated on two popular tasks and the
results suggest by emulating the cognitive phenomenon of internal dialogue, our
approach can enhance reasoning and explanation abilities, contributing to the
more effective fusion of vision and language models. More importantly, instead
of using predefined human-crafted monologues, IMMO learns this process within
the deep learning models, promising wider applicability to many different AI
problems beyond vision language tasks.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09971" title="Abstract">arXiv:2308.09971</a> [<a href="/pdf/2308.09971" title="Download PDF">pdf</a>, <a href="/format/2308.09971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disposable Transfer Learning for Selective Source Task Unlearning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koh%2C+S">Seunghee Koh</a>, 
<a href="/search/cs?searchtype=author&query=Shon%2C+H">Hyounguk Shon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Janghyeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+H+G">Hyeong Gwon Hong</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Junmo Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Transfer learning is widely used for training deep neural networks (DNN) for
building a powerful representation. Even after the pre-trained model is adapted
for the target task, the representation performance of the feature extractor is
retained to some extent. As the performance of the pre-trained model can be
considered the private property of the owner, it is natural to seek the
exclusive right of the generalized performance of the pre-trained weight. To
address this issue, we suggest a new paradigm of transfer learning called
disposable transfer learning (DTL), which disposes of only the source task
without degrading the performance of the target task. To achieve knowledge
disposal, we propose a novel loss named Gradient Collision loss (GC loss). GC
loss selectively unlearns the source knowledge by leading the gradient vectors
of mini-batches in different directions. Whether the model successfully
unlearns the source task is measured by piggyback learning accuracy (PL
accuracy). PL accuracy estimates the vulnerability of knowledge leakage by
retraining the scrubbed model on a subset of source data or new downstream
data. We demonstrate that GC loss is an effective approach to the DTL problem
by showing that the model trained with GC loss retains the performance on the
target task with a significantly reduced PL accuracy.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09972" title="Abstract">arXiv:2308.09972</a> [<a href="/pdf/2308.09972" title="Download PDF">pdf</a>, <a href="/format/2308.09972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DESOBAv2: Towards Large-scale Real-world Dataset for Shadow Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qingyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianting Wang</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+L">Li Niu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2306.17358">arXiv:2306.17358</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image composition refers to inserting a foreground object into a background
image to obtain a composite image. In this work, we focus on generating
plausible shadow for the inserted foreground object to make the composite image
more realistic. To supplement the existing small-scale dataset DESOBA, we
create a large-scale dataset called DESOBAv2 by using object-shadow detection
and inpainting techniques. Specifically, we collect a large number of outdoor
scene images with object-shadow pairs. Then, we use pretrained inpainting model
to inpaint the shadow region, resulting in the deshadowed images. Based on real
images and deshadowed images, we can construct pairs of synthetic composite
images and ground-truth target images. Dataset is available at
https://github.com/bcmi/Object-Shadow-Generation-Dataset-DESOBAv2.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09975" title="Abstract">arXiv:2308.09975</a> [<a href="/pdf/2308.09975" title="Download PDF">pdf</a>, <a href="/format/2308.09975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FinEval: A Chinese Financial Domain Knowledge Evaluation Benchmark for  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Weige Cai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhaowei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+W">Wei Dai</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yujie Liao</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Q">Qianru Qin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yifei Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xingyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiqiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhoufan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+A">Anbo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yun Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated exceptional performance in
various natural language processing tasks, yet their efficacy in more
challenging and domain-specific tasks remains largely unexplored. This paper
presents FinEval, a benchmark specifically designed for the financial domain
knowledge in the LLMs. FinEval is a collection of high-quality multiple-choice
questions covering Finance, Economy, Accounting, and Certificate. It includes
4,661 questions spanning 34 different academic subjects. To ensure a
comprehensive model performance evaluation, FinEval employs a range of prompt
types, including zero-shot and few-shot prompts, as well as answer-only and
chain-of-thought prompts. Evaluating state-of-the-art Chinese and English LLMs
on FinEval, the results show that only GPT-4 achieved an accuracy close to 70%
in different prompt settings, indicating significant growth potential for LLMs
in the financial domain knowledge. Our work offers a more comprehensive
financial knowledge evaluation benchmark, utilizing data of mock exams and
covering a wide range of evaluated LLMs.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09976" title="Abstract">arXiv:2308.09976</a> [<a href="/pdf/2308.09976" title="Download PDF">pdf</a>, <a href="/format/2308.09976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explicit Time Embedding Based Cascade Attention Network for Information  Popularity Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xigang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingya Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Ling Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wenqi Wei</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Inf. Process. Manag. 60(3): 103278 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Predicting information cascade popularity is a fundamental problem in social
networks. Capturing temporal attributes and cascade role information (e.g.,
cascade graphs and cascade sequences) is necessary for understanding the
information cascade. Current methods rarely focus on unifying this information
for popularity predictions, which prevents them from effectively modeling the
full properties of cascades to achieve satisfactory prediction performances. In
this paper, we propose an explicit Time embedding based Cascade Attention
Network (TCAN) as a novel popularity prediction architecture for large-scale
information networks. TCAN integrates temporal attributes (i.e., periodicity,
linearity, and non-linear scaling) into node features via a general time
embedding approach (TE), and then employs a cascade graph attention encoder
(CGAT) and a cascade sequence attention encoder (CSAT) to fully learn the
representation of cascade graphs and cascade sequences. We use two real-world
datasets (i.e., Weibo and APS) with tens of thousands of cascade samples to
validate our methods. Experimental results show that TCAN obtains mean
logarithm squared errors of 2.007 and 1.201 and running times of 1.76 hours and
0.15 hours on both datasets, respectively. Furthermore, TCAN outperforms other
representative baselines by 10.4%, 3.8%, and 10.4% in terms of MSLE, MAE, and
R-squared on average while maintaining good interpretability.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09977" title="Abstract">arXiv:2308.09977</a> [<a href="/pdf/2308.09977" title="Download PDF">pdf</a>, <a href="/format/2308.09977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Whether you can locate or not? Interactive Referring Expression  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+F">Fulong Ye</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+Y">Yuxing Long</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fangxiang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaojie Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 papges, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Referring Expression Generation (REG) aims to generate unambiguous Referring
Expressions (REs) for objects in a visual scene, with a dual task of Referring
Expression Comprehension (REC) to locate the referred object. Existing methods
construct REG models independently by using only the REs as ground truth for
model training, without considering the potential interaction between REG and
REC models. In this paper, we propose an Interactive REG (IREG) model that can
interact with a real REC model, utilizing signals indicating whether the object
is located and the visual region located by the REC model to gradually modify
REs. Our experimental results on three RE benchmark datasets, RefCOCO,
RefCOCO+, and RefCOCOg show that IREG outperforms previous state-of-the-art
methods on popular evaluation metrics. Furthermore, a human evaluation shows
that IREG generates better REs with the capability of interaction.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09978" title="Abstract">arXiv:2308.09978</a> [<a href="/pdf/2308.09978" title="Download PDF">pdf</a>, <a href="/format/2308.09978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Software Architecture in Practice: Challenges and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Zhiyuan Wan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint of Full Research Paper, the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE '23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Software architecture has been an active research field for nearly four
decades, in which previous studies make significant progress such as creating
methods and techniques and building tools to support software architecture
practice. Despite past efforts, we have little understanding of how
practitioners perform software architecture related activities, and what
challenges they face. Through interviews with 32 practitioners from 21
organizations across three continents, we identified challenges that
practitioners face in software architecture practice during software
development and maintenance. We reported on common software architecture
activities at software requirements, design, construction and testing, and
maintenance stages, as well as corresponding challenges. Our study uncovers
that most of these challenges center around management, documentation, tooling
and process, and collects recommendations to address these challenges.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09979" title="Abstract">arXiv:2308.09979</a> [<a href="/pdf/2308.09979" title="Download PDF">pdf</a>, <a href="/ps/2308.09979" title="Download PostScript">ps</a>, <a href="/format/2308.09979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Artificial Intelligence across Europe: A Study on Awareness, Attitude  and Trust
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scantamburlo%2C+T">Teresa Scantamburlo</a>, 
<a href="/search/cs?searchtype=author&query=Cort%C3%A9s%2C+A">Atia Cort&#xe9;s</a>, 
<a href="/search/cs?searchtype=author&query=Foffano%2C+F">Francesca Foffano</a>, 
<a href="/search/cs?searchtype=author&query=Barru%C3%A9%2C+C">Cristian Barru&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Distefano%2C+V">Veronica Distefano</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+L">Long Pham</a>, 
<a href="/search/cs?searchtype=author&query=Fabris%2C+A">Alessandro Fabris</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents the results of an extensive study investigating the
opinions on Artificial Intelligence (AI) of a sample of 4,006 European citizens
from eight distinct countries (France, Germany, Italy, Netherlands, Poland,
Romania, Spain, and Sweden). The aim of the study is to gain a better
understanding of people's views and perceptions within the European context,
which is already marked by important policy actions and regulatory processes.
To survey the perceptions of the citizens of Europe we design and validate a
new questionnaire (PAICE) structured around three dimensions: people's
awareness, attitude, and trust. We observe that while awareness is
characterized by a low level of self-assessed competency, the attitude toward
AI is very positive for more than half of the population. Reflecting upon the
collected results, we highlight implicit contradictions and identify trends
that may interfere with the creation of an ecosystem of trust and the
development of inclusive AI policies. The introduction of rules that ensure
legal and ethical standards, along with the activity of high-level educational
entities, and the promotion of AI literacy are identified as key factors in
supporting a trustworthy AI ecosystem. We make some recommendations for AI
governance focused on the European context and conclude with suggestions for
future work.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09980" title="Abstract">arXiv:2308.09980</a> [<a href="/pdf/2308.09980" title="Download PDF">pdf</a>, <a href="/format/2308.09980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breast Lesion Diagnosis Using Static Images and Dynamic Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yunwen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hongyu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Ying Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yi Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ISBI2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep learning based Computer Aided Diagnosis (CAD) systems have been
developed to treat breast ultrasound. Most of them focus on a single ultrasound
imaging modality, either using representative static images or the dynamic
video of a real-time scan. In fact, these two image modalities are
complementary for lesion diagnosis. Dynamic videos provide detailed
three-dimensional information about the lesion, while static images capture the
typical sections of the lesion. In this work, we propose a multi-modality
breast tumor diagnosis model to imitate the diagnosing process of radiologists,
which learns the features of both static images and dynamic video and explores
the potential relationship between the two modalities. Considering that static
images are carefully selected by professional radiologists, we propose to
aggregate dynamic video features under the guidance of domain knowledge from
static images before fusing multi-modality features. Our work is validated on a
breast ultrasound dataset composed of 897 sets of ultrasound images and videos.
Experimental results show that our model boosts the performance of
Benign/Malignant classification, achieving 90.0% in AUC and 81.7% in accuracy.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09983" title="Abstract">arXiv:2308.09983</a> [<a href="/pdf/2308.09983" title="Download PDF">pdf</a>, <a href="/format/2308.09983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prototypical Cross-domain Knowledge Transfer for Cervical Dysplasia  Visual Inspection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yichen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yifang Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ying Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenguang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zimmermann%2C+R">Roger Zimmermann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted in ACM Multimedia 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Early detection of dysplasia of the cervix is critical for cervical cancer
treatment. However, automatic cervical dysplasia diagnosis via visual
inspection, which is more appropriate in low-resource settings, remains a
challenging problem. Though promising results have been obtained by recent deep
learning models, their performance is significantly hindered by the limited
scale of the available cervix datasets. Distinct from previous methods that
learn from a single dataset, we propose to leverage cross-domain cervical
images that were collected in different but related clinical studies to improve
the model's performance on the targeted cervix dataset. To robustly learn the
transferable information across datasets, we propose a novel prototype-based
knowledge filtering method to estimate the transferability of cross-domain
samples. We further optimize the shared feature space by aligning the
cross-domain image representations simultaneously on domain level with early
alignment and class level with supervised contrastive learning, which endows
model training and knowledge transfer with stronger robustness. The empirical
results on three real-world benchmark cervical image datasets show that our
proposed method outperforms the state-of-the-art cervical dysplasia visual
inspection by an absolute improvement of 4.7% in top-1 accuracy, 7.0% in
precision, 1.4% in recall, 4.6% in F1 score, and 0.05 in ROC-AUC.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09985" title="Abstract">arXiv:2308.09985</a> [<a href="/pdf/2308.09985" title="Download PDF">pdf</a>, <a href="/format/2308.09985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HICL: Hashtag-Driven In-Context Learning for Social Media Natural  Language Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+H">Hanzhuo Tan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chunpu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jing Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuqun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zeyang Fang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zeyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+B">Baohua Lai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://github.com/albertan017/HICL">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Natural language understanding (NLU) is integral to various social media
applications. However, existing NLU models rely heavily on context for semantic
learning, resulting in compromised performance when faced with short and noisy
social media content. To address this issue, we leverage in-context learning
(ICL), wherein language models learn to make inferences by conditioning on a
handful of demonstrations to enrich the context and propose a novel
hashtag-driven in-context learning (HICL) framework. Concretely, we pre-train a
model #Encoder, which employs #hashtags (user-annotated topic labels) to drive
BERT-based pre-training through contrastive learning. Our objective here is to
enable #Encoder to gain the ability to incorporate topic-related semantic
information, which allows it to retrieve topic-related posts to enrich contexts
and enhance social media NLU with noisy contexts. To further integrate the
retrieved context with the source text, we employ a gradient-based method to
identify trigger terms useful in fusing information from both sources. For
empirical studies, we collected 45M tweets to set up an in-context NLU
benchmark, and the experimental results on seven downstream tasks show that
HICL substantially advances the previous state-of-the-art results. Furthermore,
we conducted extensive analyzes and found that: (1) combining source input with
a top-retrieved post from #Encoder is more effective than using semantically
similar posts; (2) trigger words can largely benefit in merging context from
the source and retrieved posts.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09987" title="Abstract">arXiv:2308.09987</a> [<a href="/pdf/2308.09987" title="Download PDF">pdf</a>, <a href="/format/2308.09987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClothesNet: An Information-Rich 3D Garment Model Repository with  Simulated Clothes Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bingyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Haoyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+T">Tianhai Liang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qiaojun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Siheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yuwei Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+J">Jun Lv</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Siyuan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiancai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xinyuan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haonan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+L">Lin Shao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE/CVF International Conference on Computer Vision (ICCV) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We present ClothesNet: a large-scale dataset of 3D clothes objects with
information-rich annotations. Our dataset consists of around 4400 models
covering 11 categories annotated with clothes features, boundary lines, and
keypoints. ClothesNet can be used to facilitate a variety of computer vision
and robot interaction tasks. Using our dataset, we establish benchmark tasks
for clothes perception, including classification, boundary line segmentation,
and keypoint detection, and develop simulated clothes environments for robotic
interaction tasks, including rearranging, folding, hanging, and dressing. We
also demonstrate the efficacy of our ClothesNet in real-world experiments.
Supplemental materials and dataset are available on our project webpage.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09990" title="Abstract">arXiv:2308.09990</a> [<a href="/pdf/2308.09990" title="Download PDF">pdf</a>, <a href="/format/2308.09990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TSAR-MVS: Textureless-aware Segmentation and Correlative Refinement  Guided Multi-View Stereo
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhenlong Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiakai Cao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaoqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhaoxin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The reconstruction of textureless areas has long been a challenging problem
in MVS due to lack of reliable pixel correspondences between images. In this
paper, we propose the Textureless-aware Segmentation And Correlative Refinement
guided Multi-View Stereo (TSAR-MVS), a novel method that effectively tackles
challenges posed by textureless areas in 3D reconstruction through filtering,
refinement and segmentation. First, we implement joint hypothesis filtering, a
technique that merges a confidence estimator with a disparity discontinuity
detector to eliminate incorrect depth estimations. Second, to spread the pixels
with confident depth, we introduce a iterative correlation refinement strategy
that leverages RANSAC to generate superpixels, succeeded by a median filter for
broadening the influence of accurately determined pixels.Finally, we present a
textureless-aware segmentation method that leverages edge detection and line
detection for accurately identify large textureless regions to be fitted using
3D planes. Experiments on extensive datasets demonstrate that our method
significantly outperforms most non-learning methods and exhibits robustness to
textureless areas while preserving fine details.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09991" title="Abstract">arXiv:2308.09991</a> [<a href="/pdf/2308.09991" title="Download PDF">pdf</a>, <a href="/format/2308.09991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AltDiffusion: A Multilingual Text-to-Image Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+F">Fulong Ye</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xinya Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Ledell Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages; 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large Text-to-Image(T2I) diffusion models have shown a remarkable capability
to produce photorealistic and diverse images based on text inputs. However,
existing works only support limited language input, e.g., English, Chinese, and
Japanese, leaving users beyond these languages underserved and blocking the
global expansion of T2I models. Therefore, this paper presents AltDiffusion, a
novel multilingual T2I diffusion model that supports eighteen different
languages. Specifically, we first train a multilingual text encoder based on
the knowledge distillation. Then we plug it into a pretrained English-only
diffusion model and train the model with a two-stage schema to enhance the
multilingual capability, including concept alignment and quality improvement
stage on a large-scale multilingual dataset. Furthermore, we introduce a new
benchmark, which includes Multilingual-General-18(MG-18) and
Multilingual-Cultural-18(MC-18) datasets, to evaluate the capabilities of T2I
diffusion models for generating high-quality images and capturing
culture-specific concepts in different languages. Experimental results on both
MG-18 and MC-18 demonstrate that AltDiffusion outperforms current
state-of-the-art T2I models, e.g., Stable Diffusion in multilingual
understanding, especially with respect to culture-specific concepts, while
still having comparable capability for generating high-quality images.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09993" title="Abstract">arXiv:2308.09993</a> [<a href="/pdf/2308.09993" title="Download PDF">pdf</a>, <a href="/format/2308.09993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TTPOINT: A Tensorized Point Cloud Network for Lightweight Action  Recognition with Event Cameras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Hongwei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yue Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Haotian Fu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yulong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Renjing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+B">Bojun Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Event cameras have gained popularity in computer vision due to their data
sparsity, high dynamic range, and low latency. As a bio-inspired sensor, event
cameras generate sparse and asynchronous data, which is inherently incompatible
with the traditional frame-based method. Alternatively, the point-based method
can avoid additional modality transformation and naturally adapt to the
sparsity of events. Still, it typically cannot reach a comparable accuracy as
the frame-based method. We propose a lightweight and generalized point cloud
network called TTPOINT which achieves competitive results even compared to the
state-of-the-art (SOTA) frame-based method in action recognition tasks while
only using 1.5 % of the computational resources. The model is adept at
abstracting local and global geometry by hierarchy structure. By leveraging
tensor-train compressed feature extractors, TTPOINT can be designed with
minimal parameters and computational complexity. Additionally, we developed a
straightforward downsampling algorithm to maintain the spatio-temporal feature.
In the experiment, TTPOINT emerged as the SOTA method on three datasets while
also attaining SOTA among point cloud methods on all five datasets. Moreover,
by using the tensor-train decomposition method, the accuracy of the proposed
TTPOINT is almost unaffected while compressing the parameter size by 55 % in
all five datasets.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09994" title="Abstract">arXiv:2308.09994</a> [<a href="/pdf/2308.09994" title="Download PDF">pdf</a>, <a href="/format/2308.09994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The extension of Weyl-type relative perturbation bounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ma%2C+H">Haoyuan Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Relative perturbation theory for eigenvalues of Hermitian positive definite
matrices has been well-studied, and the major results were later derived
analogously for Hermitian non-singular matrices. In this dissertation we extend
several relative perturbation results to Hermitian matrices that are
potentially singular, and also develop a general class of relative bounds for
Hermitian matrices. As a result, corresponding relative bounds for singular
values of rank-deficient $m\times n$ matrices are also obtained using related
Jordan-Wielandt matrices. We also discuss a comparison between the main
relative bound derived and the Weyl's absolute perturbation bound in terms of
their sharpness and derivation in practice.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09997" title="Abstract">arXiv:2308.09997</a> [<a href="/pdf/2308.09997" title="Download PDF">pdf</a>, <a href="/format/2308.09997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Additive Schwarz methods for semilinear elliptic problems with convex  energy functionals: Convergence rate independent of nonlinearity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Park%2C+J">Jongho Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 1 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We investigate additive Schwarz methods for semilinear elliptic problems with
convex energy functionals, which have wide scientific applications. A key
observation is that the convergence rates of both one- and two-level additive
Schwarz methods have bounds independent of the nonlinear term in the problem.
That is, the convergence rates do not deteriorate by the presence of
nonlinearity, so that solving a semilinear problem requires no more iterations
than a linear problem. Moreover, the two-level method is scalable in the sense
that the convergence rate of the method depends on $H/h$ and $H/\delta$ only,
where $h$ and $H$ are the typical diameters of an element and a subdomain,
respectively, and $\delta$ measures the overlap among the subdomains. Numerical
results are provided to support our theoretical findings.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10001" title="Abstract">arXiv:2308.10001</a> [<a href="/pdf/2308.10001" title="Download PDF">pdf</a>, <a href="/format/2308.10001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AltNeRF: Learning Robust Neural Radiance Field via Alternating  Depth-Pose Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhiqiang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Huang Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural Radiance Fields (NeRF) have shown promise in generating realistic
novel views from sparse scene images. However, existing NeRF approaches often
encounter challenges due to the lack of explicit 3D supervision and imprecise
camera poses, resulting in suboptimal outcomes. To tackle these issues, we
propose AltNeRF -- a novel framework designed to create resilient NeRF
representations using self-supervised monocular depth estimation (SMDE) from
monocular videos, without relying on known camera poses. SMDE in AltNeRF
masterfully learns depth and pose priors to regulate NeRF training. The depth
prior enriches NeRF's capacity for precise scene geometry depiction, while the
pose prior provides a robust starting point for subsequent pose refinement.
Moreover, we introduce an alternating algorithm that harmoniously melds NeRF
outputs into SMDE through a consistence-driven mechanism, thus enhancing the
integrity of depth priors. This alternation empowers AltNeRF to progressively
refine NeRF representations, yielding the synthesis of realistic novel views.
Additionally, we curate a distinctive dataset comprising indoor videos captured
via mobile devices. Extensive experiments showcase the compelling capabilities
of AltNeRF in generating high-fidelity and robust novel views that closely
resemble reality.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10003" title="Abstract">arXiv:2308.10003</a> [<a href="/pdf/2308.10003" title="Download PDF">pdf</a>, <a href="/format/2308.10003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Multi-View Inverse Rendering Using a Hybrid Differentiable  Rendering Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiangyang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yiling Pan</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+B">Bailin Deng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IJCAI2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Recovering the shape and appearance of real-world objects from natural 2D
images is a long-standing and challenging inverse rendering problem. In this
paper, we introduce a novel hybrid differentiable rendering method to
efficiently reconstruct the 3D geometry and reflectance of a scene from
multi-view images captured by conventional hand-held cameras. Our method
follows an analysis-by-synthesis approach and consists of two phases. In the
initialization phase, we use traditional SfM and MVS methods to reconstruct a
virtual scene roughly matching the real scene. Then in the optimization phase,
we adopt a hybrid approach to refine the geometry and reflectance, where the
geometry is first optimized using an approximate differentiable rendering
method, and the reflectance is optimized afterward using a physically-based
differentiable rendering method. Our hybrid approach combines the efficiency of
approximate methods with the high-quality results of physically-based methods.
Extensive experiments on synthetic and real data demonstrate that our method
can produce reconstructions with similar or higher quality than
state-of-the-art methods while being more efficient.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10005" title="Abstract">arXiv:2308.10005</a> [<a href="/pdf/2308.10005" title="Download PDF">pdf</a>, <a href="/format/2308.10005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Partition-and-Debias: Agnostic Biases Mitigation via A Mixture of  Biases-Specific Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Vo%2C+D+M">Duc Minh Vo</a>, 
<a href="/search/cs?searchtype=author&query=Nakayama%2C+H">Hideki Nakayama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Bias mitigation in image classification has been widely researched, and
existing methods have yielded notable results. However, most of these methods
implicitly assume that a given image contains only one type of known or unknown
bias, failing to consider the complexities of real-world biases. We introduce a
more challenging scenario, agnostic biases mitigation, aiming at bias removal
regardless of whether the type of bias or the number of types is unknown in the
datasets. To address this difficult task, we present the Partition-and-Debias
(PnD) method that uses a mixture of biases-specific experts to implicitly
divide the bias space into multiple subspaces and a gating module to find a
consensus among experts to achieve debiased classification. Experiments on both
public and constructed benchmarks demonstrated the efficacy of the PnD. Code is
available at: https://github.com/Jiaxuan-Li/PnD.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10007" title="Abstract">arXiv:2308.10007</a> [<a href="/pdf/2308.10007" title="Download PDF">pdf</a>, <a href="/ps/2308.10007" title="Download PostScript">ps</a>, <a href="/format/2308.10007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verification of Sometimes Termination of Lazy-Bounded Declarative  Distributed Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di+Cosmo%2C+F">Francesco Di Cosmo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in the online proceedings of the ESSLLI 2021 Student Session
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Declarative Distributed Systems (DDSs) are distributed systems grounded in
logic programming. Although DDS model-checking is undecidable in general, we
detect decidable cases by tweaking the data-source bounds, the message
expressiveness, and the channel type.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10008" title="Abstract">arXiv:2308.10008</a> [<a href="/pdf/2308.10008" title="Download PDF">pdf</a>, <a href="/ps/2308.10008" title="Download PostScript">ps</a>, <a href="/format/2308.10008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What is the Impact of Releasing Code with Publications? Statistics from  the Machine Learning, Robotics, and Control Communities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+S">Siqi Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Brunke%2C+L">Lukas Brunke</a>, 
<a href="/search/eess?searchtype=author&query=Tao%2C+A">Allen Tao</a>, 
<a href="/search/eess?searchtype=author&query=Hall%2C+A+W">Adam W. Hall</a>, 
<a href="/search/eess?searchtype=author&query=Bejarano%2C+F+P">Federico Pizarro Bejarano</a>, 
<a href="/search/eess?searchtype=author&query=Panerati%2C+J">Jacopo Panerati</a>, 
<a href="/search/eess?searchtype=author&query=Schoellig%2C+A+P">Angela P. Schoellig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Open-sourcing research publications is a key enabler for the reproducibility
of studies and the collective scientific progress of a research community. As
all fields of science develop more advanced algorithms, we become more
dependent on complex computational toolboxes -- sharing research ideas solely
through equations and proofs is no longer sufficient to communicate scientific
developments. Over the past years, several efforts have highlighted the
importance and challenges of transparent and reproducible research; code
sharing is one of the key necessities in such efforts. In this article, we
study the impact of code release on scientific research and present statistics
from three research communities: machine learning, robotics, and control. We
found that, over a six-year period (2016-2021), the percentages of papers with
code at major machine learning, robotics, and control conferences have at least
doubled. Moreover, high-impact papers were generally supported by open-source
codes. As an example, the top 1% of most cited papers at the Conference on
Neural Information Processing Systems (NeurIPS) consistently included
open-source codes. In addition, our analysis shows that popular code
repositories generally come with high paper citations, which further highlights
the coupling between code sharing and the impact of scientific research. While
the trends are encouraging, we would like to continue to promote and increase
our efforts toward transparent, reproducible research that accelerates
innovation -- releasing code with our papers is a clear first step.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10015" title="Abstract">arXiv:2308.10015</a> [<a href="/pdf/2308.10015" title="Download PDF">pdf</a>, <a href="/format/2308.10015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DyFFPAD: Dynamic Fusion of Convolutional and Handcrafted Features for  Fingerprint Presentation Attack Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rai%2C+A">Anuj Rai</a>, 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+P+K">Parsheel Kumar Tiwari</a>, 
<a href="/search/cs?searchtype=author&query=Baishya%2C+J">Jyotishna Baishya</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+R+P">Ram Prakash Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+S">Somnath Dey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2305.09397">arXiv:2305.09397</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Automatic fingerprint recognition systems suffer from the threat of
presentation attacks due to their wide range of applications in areas including
national borders and commercial applications. Presentation attacks can be
performed by fabricating the fake fingerprint of a user with or without the
intention of the subject. This paper presents a dynamic ensemble of deep
learning and handcrafted features to detect presentation attacks in
known-material and unknown-material protocols. The proposed model is a dynamic
ensemble of deep CNN and handcrafted features empowered deep neural networks
both of which learn their parameters together. The proposed presentation attack
detection model, in this way, utilizes the capabilities of both classification
techniques and exhibits better performance than their individual results. The
proposed model's performance is validated using benchmark LivDet 2015, 2017,
and 2019 databases, with an overall accuracy of 96.10\%, 96.49\%, and 95.99\%
attained on them, respectively. The proposed model outperforms state-of-the-art
methods in benchmark protocols of presentation attack detection in terms of
classification accuracy.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10016" title="Abstract">arXiv:2308.10016</a> [<a href="/pdf/2308.10016" title="Download PDF">pdf</a>, <a href="/format/2308.10016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pseudo Flow Consistency for Self-Supervised 6D Object Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hai%2C+Y">Yang Hai</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+R">Rui Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaojiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Ferstl%2C+D">David Ferstl</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yinlin Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Most self-supervised 6D object pose estimation methods can only work with
additional depth information or rely on the accurate annotation of 2D
segmentation masks, limiting their application range. In this paper, we propose
a 6D object pose estimation method that can be trained with pure RGB images
without any auxiliary information. We first obtain a rough pose initialization
from networks trained on synthetic images rendered from the target's 3D mesh.
Then, we introduce a refinement strategy leveraging the geometry constraint in
synthetic-to-real image pairs from multiple different views. We formulate this
geometry constraint as pixel-level flow consistency between the training images
with dynamically generated pseudo labels. We evaluate our method on three
challenging datasets and demonstrate that it outperforms state-of-the-art
self-supervised methods significantly, with neither 2D annotations nor
additional depth images.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10019" title="Abstract">arXiv:2308.10019</a> [<a href="/pdf/2308.10019" title="Download PDF">pdf</a>, <a href="/format/2308.10019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretation on Multi-modal Visual Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Haoran Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yongjian Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This version was under review since 2023/3/9
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we present an analytical framework and a novel metric to shed
light on the interpretation of the multimodal vision community. Our approach
involves measuring the proposed semantic variance and feature similarity across
modalities and levels, and conducting semantic and quantitative analyses
through comprehensive experiments. Specifically, we investigate the consistency
and speciality of representations across modalities, evolution rules within
each modality, and the collaboration logic used when optimizing a
multi-modality model. Our studies reveal several important findings, such as
the discrepancy in cross-modal features and the hybrid multi-modal cooperation
rule, which highlights consistency and speciality simultaneously for
complementary inference. Through our dissection and findings on multi-modal
fusion, we facilitate a rethinking of the reasonability and necessity of
popular multi-modal vision fusion strategies. Furthermore, our work lays the
foundation for designing a trustworthy and universal multi-modal fusion model
for a variety of tasks in the future.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10020" title="Abstract">arXiv:2308.10020</a> [<a href="/pdf/2308.10020" title="Download PDF">pdf</a>, <a href="/format/2308.10020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing SCF with Privacy-Preserving and Splitting-Enabled E-Bills on  Blockchain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhili Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+H">Haifeng Qian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Electronic Bill (E-Bill) is a rucial negotiable instrument in the form of
data messages, relying on the Electronic Bill System (EB System). Blockchain
technology offers inherent data sharing capabilities, so it is increasingly
being adopted by small and medium-sized enterprises (SMEs) in the supply chain
to build EB systems. However, the blockchain-based E-Bill still face
significant challenges: the E-Bill is difficult to split, like non-fungible
tokens (NFTs), and sensitive information such as amounts always be exposed on
the blockchain. Therefore, to address these issues, we propose a novel data
structure called Reverse-HashTree for Re-storing transactions in blockchain. In
addition, we employ a variant of the Paillier public-key cryptosystem to ensure
transaction validity without decryption, thus preserving privacy. Building upon
these innovations, we designed BillChain, an EB system that enhances supply
chain finance by providing privacy-preserving and splitting-enabled E-Bills on
the blockchain. This work offers a comprehensive and innovative solution to the
challenges faced by E-Bills applied in blockchain in the context of supply
chain finance.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10022" title="Abstract">arXiv:2308.10022</a> [<a href="/pdf/2308.10022" title="Download PDF">pdf</a>, <a href="/format/2308.10022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cupid: Leveraging ChatGPT for More Accurate Duplicate Bug Report  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Ting Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Irsan%2C+I+C">Ivana Clairine Irsan</a>, 
<a href="/search/cs?searchtype=author&query=Thung%2C+F">Ferdian Thung</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Duplicate bug report detection (DBRD) is a long-standing challenge in both
academia and industry. Over the past decades, researchers have proposed various
approaches to detect duplicate bug reports more accurately. With the recent
advancement of deep learning, researchers have also proposed several approaches
that leverage deep learning models to detect duplicate bug reports. A recent
benchmarking study on DBRD also reveals that the performance of deep
learning-based approaches is not always better than the traditional approaches.
However, traditional approaches have limitations, e.g., they are usually based
on the bag-of-words model, which cannot capture the semantics of bug reports.
To address these aforementioned challenges, we seek to leverage
state-of-the-art large language model to improve the performance of the
traditional DBRD approach.
<br />In this paper, we propose an approach called Cupid, which combines the
best-performing traditional DBRD approach REP with the state-of-the-art large
language model ChatGPT. Specifically, we first leverage ChatGPT under the
zero-shot setting to get essential information on bug reports. We then use the
essential information as the input of REP to detect duplicate bug reports. We
conducted an evaluation on comparing Cupid with three existing approaches on
three datasets. The experimental results show that Cupid achieves new
state-of-the-art results, reaching Recall Rate@10 scores ranging from 0.59 to
0.67 across all the datasets analyzed. Our work highlights the potential of
combining large language models to improve the performance of software
engineering tasks.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10024" title="Abstract">arXiv:2308.10024</a> [<a href="/pdf/2308.10024" title="Download PDF">pdf</a>, <a href="/ps/2308.10024" title="Download PostScript">ps</a>, <a href="/format/2308.10024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Weight Distribution of Weights Less than $2w_{\min}$ in Polar  Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zicheng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huazi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+G">Guiying Yan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhiming Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The number of low-weight codewords is critical to the performance of
error-correcting codes. In 1970, Kasami and Tokura characterized the codewords
of Reed-Muller (RM) codes whose weights are less than $2w_{\min}$, where
$w_{\min}$ represents the minimum weight. In this paper, we extend their
results to decreasing polar codes. We present the closed-form expressions for
the number of codewords in decreasing polar codes with weights less than
$2w_{\min}$. Moreover, the proposed enumeration algorithm runs in polynomial
time with respect to the code length.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10025" title="Abstract">arXiv:2308.10025</a> [<a href="/pdf/2308.10025" title="Download PDF">pdf</a>, <a href="/format/2308.10025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ControlRetriever: Harnessing the Power of Instructions for Controllable  Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+K">Kaihang Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juncheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hongye Song</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+H">Hao Fei</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+W">Wei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jun Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaozhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Siliang Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent studies have shown that dense retrieval models, lacking dedicated
training data, struggle to perform well across diverse retrieval tasks, as
different retrieval tasks often entail distinct search intents. To address this
challenge, in this work we introduce ControlRetriever, a generic and efficient
approach with a parameter isolated architecture, capable of controlling dense
retrieval models to directly perform varied retrieval tasks, harnessing the
power of instructions that explicitly describe retrieval intents in natural
language. Leveraging the foundation of ControlNet, which has proven powerful in
text-to-image generation, ControlRetriever imbues different retrieval models
with the new capacity of controllable retrieval, all while being guided by
task-specific instructions. Furthermore, we propose a novel LLM guided
Instruction Synthesizing and Iterative Training strategy, which iteratively
tunes ControlRetriever based on extensive automatically-generated retrieval
data with diverse instructions by capitalizing the advancement of large
language models. Extensive experiments show that in the BEIR benchmark, with
only natural language descriptions of specific retrieval intent for each task,
ControlRetriever, as a unified multi-task retrieval system without
task-specific tuning, significantly outperforms baseline methods designed with
task-specific retrievers and also achieves state-of-the-art zero-shot
performance.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10027" title="Abstract">arXiv:2308.10027</a> [<a href="/pdf/2308.10027" title="Download PDF">pdf</a>, <a href="/format/2308.10027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single Image Reflection Separation via Component Synergy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Q">Qiming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiaojie Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The reflection superposition phenomenon is complex and widely distributed in
the real world, which derives various simplified linear and nonlinear
formulations of the problem. In this paper, based on the investigation of the
weaknesses of existing models, we propose a more general form of the
superposition model by introducing a learnable residue term, which can
effectively capture residual information during decomposition, guiding the
separated layers to be complete. In order to fully capitalize on its
advantages, we further design the network structure elaborately, including a
novel dual-stream interaction mechanism and a powerful decomposition network
with a semantic pyramid encoder. Extensive experiments and ablation studies are
conducted to verify our superiority over state-of-the-art approaches on
multiple real-world benchmark datasets. Our code is publicly available at
https://github.com/mingcv/DSRNet.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10028" title="Abstract">arXiv:2308.10028</a> [<a href="/pdf/2308.10028" title="Download PDF">pdf</a>, <a href="/format/2308.10028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Voucher Abuse Detection with Prompt-based Fine-tuning on Graph Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Z">Zhihao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yihan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+S">Shuji Hao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, Accepted by CIKM23 Applied Research Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Voucher abuse detection is an important anomaly detection problem in
E-commerce. While many GNN-based solutions have emerged, the supervised
paradigm depends on a large quantity of labeled data. A popular alternative is
to adopt self-supervised pre-training using label-free data, and further
fine-tune on a downstream task with limited labels. Nevertheless, the
"pre-train, fine-tune" paradigm is often plagued by the objective gap between
pre-training and downstream tasks. Hence, we propose VPGNN, a prompt-based
fine-tuning framework on GNNs for voucher abuse detection. We design a novel
graph prompting function to reformulate the downstream task into a similar
template as the pretext task in pre-training, thereby narrowing the objective
gap. Extensive experiments on both proprietary and public datasets demonstrate
the strength of VPGNN in both few-shot and semi-supervised scenarios. Moreover,
an online deployment of VPGNN in a production environment shows a 23.4%
improvement over two existing deployed models.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10031" title="Abstract">arXiv:2308.10031</a> [<a href="/pdf/2308.10031" title="Download PDF">pdf</a>, <a href="/ps/2308.10031" title="Download PostScript">ps</a>, <a href="/format/2308.10031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Circle Formation by Asynchronous Opaque Fat Robots on an Infinite Grid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goswami%2C+P">Pritam Goswami</a>, 
<a href="/search/cs?searchtype=author&query=Kundu%2C+M+K">Manash Kumar Kundu</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Satakshi Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Sau%2C+B">Buddhadeb Sau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">This study addresses the problem of "Circle Formation on an Infinite Grid by
Fat Robots" ($CF\_FAT\_GRID$). Unlike prior work focused solely on point robots
in discrete domain, it introduces fat robots to circle formation on an infinite
grid, aligning with practicality as even small robots inherently possess
dimensions. The algorithm, named $CIRCLE\_FG$, resolves the $CF\_FAT\_GRID$
problem using a swarm of fat luminous robots. Operating under an asynchronous
scheduler, it achieves this with five distinct colors and by leveraging
one-axis agreement among the robots.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10032" title="Abstract">arXiv:2308.10032</a> [<a href="/pdf/2308.10032" title="Download PDF">pdf</a>, <a href="/format/2308.10032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GameEval: Evaluating LLMs on Conversational Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiao%2C+D">Dan Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenfei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yaobo Liang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juntao Li</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+N">Nan Duan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The rapid advancements in large language models (LLMs) have presented
challenges in evaluating those models. Existing evaluation methods are either
reference-based or preference based, which inevitably need human intervention
or introduce test bias caused by evaluator models. In this paper, we propose
GameEval, a novel approach to evaluating LLMs through goal-driven
conversational games, overcoming the limitations of previous methods. GameEval
treats LLMs as game players and assigns them distinct roles with specific goals
achieved by launching conversations of various forms, including discussion,
question answering, and voting. We design three unique games with cooperative
or adversarial objectives, accompanied by corresponding evaluation metrics, to
show how this new paradigm comprehensively evaluates model performance.Through
extensive experiments, we show that GameEval can effectively differentiate the
capabilities of various LLMs, providing a comprehensive assessment of their
integrated abilities to solve complex problems. Our public anonymous code is
available at https://github.com/GameEval/GameEval.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10036" title="Abstract">arXiv:2308.10036</a> [<a href="/pdf/2308.10036" title="Download PDF">pdf</a>, <a href="/format/2308.10036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Supervised Anomaly Detection for the Determination of Vehicle  Hijacking Tweets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patel%2C+T+A">Taahir Aiyoob Patel</a>, 
<a href="/search/cs?searchtype=author&query=Nyirenda%2C+C+N">Clement N. Nyirenda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In South Africa, there is an ever-growing issue of vehicle hijackings. This
leads to travellers constantly being in fear of becoming a victim to such an
incident. This work presents a new semi-supervised approach to using tweets to
identify hijacking incidents by using unsupervised anomaly detection
algorithms. Tweets consisting of the keyword "hijacking" are obtained, stored,
and processed using the term frequency-inverse document frequency (TF-IDF) and
further analyzed by using two anomaly detection algorithms: 1) K-Nearest
Neighbour (KNN); 2) Cluster Based Outlier Factor (CBLOF). The comparative
evaluation showed that the KNN method produced an accuracy of 89%, whereas the
CBLOF produced an accuracy of 90%. The CBLOF method was also able to obtain a
F1-Score of 0.8, whereas the KNN produced a 0.78. Therefore, there is a slight
difference between the two approaches, in favour of CBLOF, which has been
selected as a preferred unsupervised method for the determination of relevant
hijacking tweets. In future, a comparison will be done between supervised
learning methods and the unsupervised methods presented in this work on larger
dataset. Optimisation mechanisms will also be employed in order to increase the
overall performance.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10037" title="Abstract">arXiv:2308.10037</a> [<a href="/pdf/2308.10037" title="Download PDF">pdf</a>, <a href="/format/2308.10037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High Performance Computing Applied to Logistic Regression: A CPU and GPU  Implementation Comparison
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohammed%2C+N">Nechba Mohammed</a>, 
<a href="/search/cs?searchtype=author&query=Mohamed%2C+M">Mouhajir Mohamed</a>, 
<a href="/search/cs?searchtype=author&query=Yassine%2C+S">Sedjari Yassine</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We present a versatile GPU-based parallel version of Logistic Regression
(LR), aiming to address the increasing demand for faster algorithms in binary
classification due to large data sets. Our implementation is a direct
translation of the parallel Gradient Descent Logistic Regression algorithm
proposed by X. Zou et al. [12]. Our experiments demonstrate that our GPU-based
LR outperforms existing CPU-based implementations in terms of execution time
while maintaining comparable f1 score. The significant acceleration of
processing large datasets makes our method particularly advantageous for
real-time prediction applications like image recognition, spam detection, and
fraud detection. Our algorithm is implemented in a ready-to-use Python library
available at : https://github.com/NechbaMohammed/SwiftLogisticReg
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10038" title="Abstract">arXiv:2308.10038</a> [<a href="/pdf/2308.10038" title="Download PDF">pdf</a>, <a href="/format/2308.10038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-guided training of GAN to improve accuracy in airfoil design  synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wada%2C+K">Kazunari Wada</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+K">Katsuyuki Suzuki</a>, 
<a href="/search/cs?searchtype=author&query=Yonekura%2C+K">Kazuo Yonekura</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Generative adversarial networks (GAN) have recently been used for a design
synthesis of mechanical shapes. A GAN sometimes outputs physically unreasonable
shapes. For example, when a GAN model is trained to output airfoil shapes that
indicate required aerodynamic performance, significant errors occur in the
performance values. This is because the GAN model only considers data but does
not consider the aerodynamic equations that lie under the data. This paper
proposes the physics-guided training of the GAN model to guide the model to
learn physical validity. Physical validity is computed using general-purpose
software located outside the neural network model. Such general-purpose
software cannot be used in physics-informed neural network frameworks, because
physical equations must be implemented inside the neural network models.
Additionally, a limitation of generative models is that the output data are
similar to the training data and cannot generate completely new shapes.
However, because the proposed model is guided by a physical model and does not
use a training dataset, it can generate completely new shapes. Numerical
experiments show that the proposed model drastically improves the accuracy.
Moreover, the output shapes differ from those of the training dataset but still
satisfy the physical validity, overcoming the limitations of existing GAN
models.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10040" title="Abstract">arXiv:2308.10040</a> [<a href="/pdf/2308.10040" title="Download PDF">pdf</a>, <a href="/format/2308.10040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ControlCom: Controllable Image Composition using Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yuxuan Duan</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+J">Jun Lan</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yan Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Huijia Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+L">Li Niu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image composition targets at synthesizing a realistic composite image from a
pair of foreground and background images. Recently, generative composition
methods are built on large pretrained diffusion models to generate composite
images, considering their great potential in image generation. However, they
suffer from lack of controllability on foreground attributes and poor
preservation of foreground identity. To address these challenges, we propose a
controllable image composition method that unifies four tasks in one diffusion
model: image blending, image harmonization, view synthesis, and generative
composition. Meanwhile, we design a self-supervised training framework coupled
with a tailored pipeline of training data preparation. Moreover, we propose a
local enhancement module to enhance the foreground details in the diffusion
model, improving the foreground fidelity of composite images. The proposed
method is evaluated on both public benchmark and real-world data, which
demonstrates that our method can generate more faithful and controllable
composite images than existing approaches. The code and model will be available
at https://github.com/bcmi/ControlCom-Image-Composition.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10041" title="Abstract">arXiv:2308.10041</a> [<a href="/pdf/2308.10041" title="Download PDF">pdf</a>, <a href="/format/2308.10041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing the Vapnik Chervonenkis Dimension for Non-Discrete Settings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nechba%2C+M">Mohammed Nechba</a>, 
<a href="/search/cs?searchtype=author&query=Mohamed%2C+M">Mouhajir Mohamed</a>, 
<a href="/search/cs?searchtype=author&query=Yassine%2C+S">Sedjari Yassine</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC); Machine Learning (cs.LG)

</div>
<p class="mathjax">In 1984, Valiant [ 7 ] introduced the Probably Approximately Correct (PAC)
learning framework for boolean function classes. Blumer et al. [ 2] extended
this model in 1989 by introducing the VC dimension as a tool to characterize
the learnability of PAC. The VC dimension was based on the work of Vapnik and
Chervonenkis in 1971 [8 ], who introduced a tool called the growth function to
characterize the shattering property. Researchers have since determined the VC
dimension for specific classes, and efforts have been made to develop an
algorithm that can calculate the VC dimension for any concept class. In 1991,
Linial, Mansour, and Rivest [4] presented an algorithm for computing the VC
dimension in the discrete setting, assuming that both the concept class and
domain set were finite. However, no attempts had been made to design an
algorithm that could compute the VC dimension in the general setting.Therefore,
our work focuses on developing a method to approximately compute the VC
dimension without constraints on the concept classes or their domain set. Our
approach is based on our finding that the Empirical Risk Minimization (ERM)
learning paradigm can be used as a new tool to characterize the shattering
property of a concept class.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10045" title="Abstract">arXiv:2308.10045</a> [<a href="/pdf/2308.10045" title="Download PDF">pdf</a>, <a href="/format/2308.10045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Study of CLIP for Text-based Person Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+M">Min Cao</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yang Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Ziyin Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+M">Mang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 fiugres and 17 tables. Code is available at <a href="https://github.com/Flame-Chasers/TBPS-CLIP">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Text-based Person Search (TBPS) aims to retrieve the person images using
natural language descriptions. Recently, Contrastive Language Image Pretraining
(CLIP), a universal large cross-modal vision-language pre-training model, has
remarkably performed over various cross-modal downstream tasks due to its
powerful cross-modal semantic learning capacity. TPBS, as a fine-grained
cross-modal retrieval task, is also facing the rise of research on the
CLIP-based TBPS. In order to explore the potential of the visual-language
pre-training model for downstream TBPS tasks, this paper makes the first
attempt to conduct a comprehensive empirical study of CLIP for TBPS and thus
contribute a straightforward, incremental, yet strong TBPS-CLIP baseline to the
TBPS community. We revisit critical design considerations under CLIP, including
data augmentation and loss function. The model, with the aforementioned designs
and practical training tricks, can attain satisfactory performance without any
sophisticated modules. Also, we conduct the probing experiments of TBPS-CLIP in
model generalization and model compression, demonstrating the effectiveness of
TBPS-CLIP from various aspects. This work is expected to provide empirical
insights and highlight future CLIP-based TBPS research.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10047" title="Abstract">arXiv:2308.10047</a> [<a href="/pdf/2308.10047" title="Download PDF">pdf</a>, <a href="/format/2308.10047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Probabilistic Causal Discovery, Inference &amp; Explanations for  Autonomous Drones in Mine Surveying Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cannizzaro%2C+R">Ricardo Cannizzaro</a>, 
<a href="/search/cs?searchtype=author&query=Howard%2C+R">Rhys Howard</a>, 
<a href="/search/cs?searchtype=author&query=Lewinska%2C+P">Paulina Lewinska</a>, 
<a href="/search/cs?searchtype=author&query=Kunze%2C+L">Lars Kunze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 Pages, 1 Figure, To be published in the Proceedings of the "Causality for Robotics: Answering the Question of Why" workshop at the 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Adjusted initial submission version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Causal modelling offers great potential to provide autonomous agents the
ability to understand the data-generation process that governs their
interactions with the world. Such models capture formal knowledge as well as
probabilistic representations of noise and uncertainty typically encountered by
autonomous robots in real-world environments. Thus, causality can aid
autonomous agents in making decisions and explaining outcomes, but deploying
causality in such a manner introduces new challenges. Here we identify
challenges relating to causality in the context of a drone system operating in
a salt mine. Such environments are challenging for autonomous agents because of
the presence of confounders, non-stationarity, and a difficulty in building
complete causal models ahead of time. To address these issues, we propose a
probabilistic causal framework consisting of: causally-informed POMDP planning,
online SCM adaptation, and post-hoc counterfactual explanations. Further, we
outline planned experimentation to evaluate the framework integrated with a
drone system in simulated mine environments and on a real-world mine dataset.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10049" title="Abstract">arXiv:2308.10049</a> [<a href="/pdf/2308.10049" title="Download PDF">pdf</a>, <a href="/format/2308.10049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clothoid Curve-based Emergency-Stopping Path Planning with Adaptive  Potential Field for Autonomous Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+P">Pengfei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Javanmardi%2C+E">Ehsan Javanmardi</a>, 
<a href="/search/cs?searchtype=author&query=Tsukada%2C+M">Manabu Tsukada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 20 figures, journal paper in submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The Potential Field (PF)-based path planning method is widely adopted for
autonomous vehicles (AVs) due to its real-time efficiency and simplicity. PF
often creates a rigid road boundary, and while this ensures that the ego
vehicle consistently operates within the confines of the road, it also brings a
lurking peril in emergency scenarios. If nearby vehicles suddenly switch lanes,
the AV has to veer off and brake to evade a collision, leading to the "blind
alley" effect. In such a situation, the vehicle can become trapped or confused
by the conflicting forces from the obstacle vehicle PF and road boundary PF,
often resulting in indecision or erratic behavior, even crashes. To address the
above-mentioned challenges, this research introduces an Emergency-Stopping Path
Planning (ESPP) that incorporates an adaptive PF (APF) and a clothoid curve for
urgent evasion. First, we design an emergency triggering estimation to detect
the "blind alley" problem by analyzing the PF distribution. Second, we
regionalize the driving scene to search the optimal breach point on the road PF
and the final stopping point for the vehicle by considering the possible motion
range of the obstacle. Finally, we use the optimized clothoid curve to fit
these calculated points under vehicle dynamics constraints to generate a smooth
emergency avoidance path. The proposed ESPP-based APF method was evaluated by
conducting the co-simulation between MATLAB/Simulink and CarSim Simulator in a
freeway scene. The simulation results reveal that the proposed method shows
increased performance in emergency collision avoidance and renders the vehicle
safer, in which the duration of wheel slip is 61.9% shorter, and the maximum
steering angle amplitude is 76.9% lower than other potential field-based
methods.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10051" title="Abstract">arXiv:2308.10051</a> [<a href="/pdf/2308.10051" title="Download PDF">pdf</a>, <a href="/format/2308.10051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Snowflake Hypothesis: Training Deep GNN with One Node One Receptive  field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guohao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guibin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yang You</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xiaojiang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuxuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite Graph Neural Networks demonstrating considerable promise in graph
representation learning tasks, GNNs predominantly face significant issues with
over-fitting and over-smoothing as they go deeper as models of computer vision
realm. In this work, we conduct a systematic study of deeper GNN research
trajectories. Our findings indicate that the current success of deep GNNs
primarily stems from (I) the adoption of innovations from CNNs, such as
residual/skip connections, or (II) the tailor-made aggregation algorithms like
DropEdge. However, these algorithms often lack intrinsic interpretability and
indiscriminately treat all nodes within a given layer in a similar manner,
thereby failing to capture the nuanced differences among various nodes. To this
end, we introduce the Snowflake Hypothesis -- a novel paradigm underpinning the
concept of ``one node, one receptive field''. The hypothesis draws inspiration
from the unique and individualistic patterns of each snowflake, proposing a
corresponding uniqueness in the receptive fields of nodes in the GNNs.
<br />We employ the simplest gradient and node-level cosine distance as guiding
principles to regulate the aggregation depth for each node, and conduct
comprehensive experiments including: (1) different training schemes; (2)
various shallow and deep GNN backbones, and (3) various numbers of layers (8,
16, 32, 64) on multiple benchmarks (six graphs including dense graphs with
millions of nodes); (4) compare with different aggregation strategies. The
observational results demonstrate that our hypothesis can serve as a universal
operator for a range of tasks, and it displays tremendous potential on deep
GNNs. It can be applied to various GNN frameworks, enhancing its effectiveness
when operating in-depth, and guiding the selection of the optimal network depth
in an explainable and generalizable way.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10053" title="Abstract">arXiv:2308.10053</a> [<a href="/pdf/2308.10053" title="Download PDF">pdf</a>, <a href="/format/2308.10053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models as Zero-Shot Conversational Recommenders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhankui He</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhouhang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+R">Rahul Jha</a>, 
<a href="/search/cs?searchtype=author&query=Steck%2C+H">Harald Steck</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+D">Dawen Liang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yesu Feng</a>, 
<a href="/search/cs?searchtype=author&query=Majumder%2C+B+P">Bodhisattwa Prasad Majumder</a>, 
<a href="/search/cs?searchtype=author&query=Kallus%2C+N">Nathan Kallus</a>, 
<a href="/search/cs?searchtype=author&query=McAuley%2C+J">Julian McAuley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as CIKM 2023 long paper. Longer version is coming soon (e.g., more details about dataset)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we present empirical studies on conversational recommendation
tasks using representative large language models in a zero-shot setting with
three primary contributions. (1) Data: To gain insights into model behavior in
"in-the-wild" conversational recommendation scenarios, we construct a new
dataset of recommendation-related conversations by scraping a popular
discussion website. This is the largest public real-world conversational
recommendation dataset to date. (2) Evaluation: On the new dataset and two
existing conversational recommendation datasets, we observe that even without
fine-tuning, large language models can outperform existing fine-tuned
conversational recommendation models. (3) Analysis: We propose various probing
tasks to investigate the mechanisms behind the remarkable performance of large
language models in conversational recommendation. We analyze both the large
language models' behaviors and the characteristics of the datasets, providing a
holistic understanding of the models' effectiveness, limitations and suggesting
directions for the design of future conversational recommenders
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10055" title="Abstract">arXiv:2308.10055</a> [<a href="/pdf/2308.10055" title="Download PDF">pdf</a>, <a href="/format/2308.10055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Fraud Detection via Supervised Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S.%2C+V+M">Vinay M.S.</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+S">Shuhan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xintao Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 5 figures, and 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep learning models have recently become popular for detecting malicious
user activity sessions in computing platforms. In many real-world scenarios,
only a few labeled malicious and a large amount of normal sessions are
available. These few labeled malicious sessions usually do not cover the entire
diversity of all possible malicious sessions. In many scenarios, possible
malicious sessions can be highly diverse. As a consequence, learned session
representations of deep learning models can become ineffective in achieving a
good generalization performance for unseen malicious sessions. To tackle this
open-set fraud detection challenge, we propose a robust supervised contrastive
learning based framework called ConRo, which specifically operates in the
scenario where only a few malicious sessions having limited diversity is
available. ConRo applies an effective data augmentation strategy to generate
diverse potential malicious sessions. By employing these generated and
available training set sessions, ConRo derives separable representations w.r.t
open-set fraud detection task by leveraging supervised contrastive learning. We
empirically evaluate our ConRo framework and other state-of-the-art baselines
on benchmark datasets. Our ConRo framework demonstrates noticeable performance
improvement over state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10058" title="Abstract">arXiv:2308.10058</a> [<a href="/pdf/2308.10058" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> R-C-P Method: An Autonomous Volume Calculation Method Using Image  Processing and Machine Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muktadir%2C+M">MA Muktadir</a>, 
<a href="/search/cs?searchtype=author&query=Parker%2C+S">Sydney Parker</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+S">Sun Yi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Machine vision and image processing are often used with sensors for situation
awareness in autonomous systems, from industrial robots to self-driving cars.
The 3D depth sensors, such as LiDAR (Light Detection and Ranging), Radar, are
great invention for autonomous systems. Due to the complexity of the setup,
LiDAR may not be suitable for some operational environments, for example, a
space environment. This study was motivated by a desire to get real-time
volumetric and change information with multiple 2D cameras instead of a depth
camera. Two cameras were used to measure the dimensions of a rectangular object
in real-time. The R-C-P (row-column-pixel) method is developed using image
processing and edge detection. In addition to the surface areas, the R-C-P
method also detects discontinuous edges or volumes. Lastly, experimental work
is presented for illustration of the R-C-P method, which provides the equations
for calculating surface area dimensions. Using the equations with given
distance information between the object and the camera, the vision system
provides the dimensions of actual objects.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10061" title="Abstract">arXiv:2308.10061</a> [<a href="/pdf/2308.10061" title="Download PDF">pdf</a>, <a href="/format/2308.10061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DPL: Decoupled Prompt Learning for Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuhan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guozhen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Haocheng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yixuan Liao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Gangshan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Limin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Prompt learning has emerged as an efficient and effective approach for
transferring foundational Vision-Language Models (e.g., CLIP) to downstream
tasks. However, current methods tend to overfit to seen categories, thereby
limiting their generalization ability for unseen classes. In this paper, we
propose a new method, Decoupled Prompt Learning (DPL), which reformulates the
attention in prompt learning to alleviate this problem. Specifically, we
theoretically investigate the collaborative process between prompts and
instances (i.e., image patches/text tokens) by reformulating the original
self-attention into four separate sub-processes. Through detailed analysis, we
observe that certain sub-processes can be strengthened to bolster robustness
and generalizability by some approximation techniques. Furthermore, we
introduce language-conditioned textual prompting based on decoupled attention
to naturally preserve the generalization of text input. Our approach is
flexible for both visual and textual modalities, making it easily extendable to
multi-modal prompt learning. By combining the proposed techniques, our approach
achieves state-of-the-art performance on three representative benchmarks
encompassing 15 image recognition datasets, while maintaining
parameter-efficient. Moreover, our DPL does not rely on any auxiliary
regularization task or extra training data, further demonstrating its
remarkable generalization ability.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10062" title="Abstract">arXiv:2308.10062</a> [<a href="/pdf/2308.10062" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revitalising the Single Batch Environment: A &#x27;Quest&#x27; to Achieve Fairness  and Efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manna%2C+S">Supriya Manna</a>, 
<a href="/search/cs?searchtype=author&query=Mudigonda%2C+K+S+P">Krishna Siva Prasad Mudigonda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Operating Systems (cs.OS)</span>

</div>
<p class="mathjax">In the realm of computer systems, efficient utilisation of the CPU (Central
Processing Unit) has always been a paramount concern. Researchers and engineers
have long sought ways to optimise process execution on the CPU, leading to the
emergence of CPU scheduling as a field of study. This research proposes a novel
algorithm for batch processing that operates on a preemptive model, dynamically
assigning priorities based on a robust ratio, employing a dynamic time slice,
and utilising periodic sorting technique to achieve fairness. By engineering
this responsive and fair model, the proposed algorithm strikes a delicate
balance between efficiency and fairness, providing an optimised solution for
batch scheduling while ensuring system responsiveness.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10064" title="Abstract">arXiv:2308.10064</a> [<a href="/pdf/2308.10064" title="Download PDF">pdf</a>, <a href="/format/2308.10064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Representation Learning for Healthcare with  Cross-Architectural Self-Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+P">Pranav Singh</a>, 
<a href="/search/cs?searchtype=author&query=Cirrone%2C+J">Jacopo Cirrone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at MLHC 2023. Extended conference version of <a href="/abs/2206.04170">arXiv:2206.04170</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In healthcare and biomedical applications, extreme computational requirements
pose a significant barrier to adopting representation learning. Representation
learning can enhance the performance of deep learning architectures by learning
useful priors from limited medical data. However, state-of-the-art
self-supervised techniques suffer from reduced performance when using smaller
batch sizes or shorter pretraining epochs, which are more practical in clinical
settings. We present Cross Architectural - Self Supervision (CASS) in response
to this challenge. This novel siamese self-supervised learning approach
synergistically leverages Transformer and Convolutional Neural Networks (CNN)
for efficient learning. Our empirical evaluation demonstrates that CASS-trained
CNNs and Transformers outperform existing self-supervised learning methods
across four diverse healthcare datasets. With only 1% labeled data for
finetuning, CASS achieves a 3.8% average improvement; with 10% labeled data, it
gains 5.9%; and with 100% labeled data, it reaches a remarkable 10.13%
enhancement. Notably, CASS reduces pretraining time by 69% compared to
state-of-the-art methods, making it more amenable to clinical implementation.
We also demonstrate that CASS is considerably more robust to variations in
batch size and pretraining epochs, making it a suitable candidate for machine
learning in healthcare applications.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10068" title="Abstract">arXiv:2308.10068</a> [<a href="/pdf/2308.10068" title="Download PDF">pdf</a>, <a href="/format/2308.10068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ILCAS: Imitation Learning-Based Configuration-Adaptive Streaming for  Live Video Analytics with Cross-Camera Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Duo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dayou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Miao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruoyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fangxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shuguang Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE Transactions on Mobile Computing for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">The high-accuracy and resource-intensive deep neural networks (DNNs) have
been widely adopted by live video analytics (VA), where camera videos are
streamed over the network to resource-rich edge/cloud servers for DNN
inference. Common video encoding configurations (e.g., resolution and frame
rate) have been identified with significant impacts on striking the balance
between bandwidth consumption and inference accuracy and therefore their
adaption scheme has been a focus of optimization. However, previous
profiling-based solutions suffer from high profiling cost, while existing deep
reinforcement learning (DRL) based solutions may achieve poor performance due
to the usage of fixed reward function for training the agent, which fails to
craft the application goals in various scenarios. In this paper, we propose
ILCAS, the first imitation learning (IL) based configuration-adaptive VA
streaming system. Unlike DRL-based solutions, ILCAS trains the agent with
demonstrations collected from the expert which is designed as an offline
optimal policy that solves the configuration adaption problem through dynamic
programming. To tackle the challenge of video content dynamics, ILCAS derives
motion feature maps based on motion vectors which allow ILCAS to visually
``perceive'' video content changes. Moreover, ILCAS incorporates a cross-camera
collaboration scheme to exploit the spatio-temporal correlations of cameras for
more proper configuration selection. Extensive experiments confirm the
superiority of ILCAS compared with state-of-the-art solutions, with 2-20.9%
improvement of mean accuracy and 19.9-85.3% reduction of chunk upload lag.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10073" title="Abstract">arXiv:2308.10073</a> [<a href="/pdf/2308.10073" title="Download PDF">pdf</a>, <a href="/ps/2308.10073" title="Download PostScript">ps</a>, <a href="/format/2308.10073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Parallel Dynamic Complexity of the Abelian Cayley Group Membership  Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arvind%2C+V">V. Arvind</a>, 
<a href="/search/cs?searchtype=author&query=Datta%2C+S">Samir Datta</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Asif Khan</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+S">Shivdutt Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Vasudev%2C+Y">Yadu Vasudev</a>, 
<a href="/search/cs?searchtype=author&query=Vasudevan%2C+S+R">Shankar Ram Vasudevan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">Let $G$ be a finite group given as input by its multiplication table. For a
subset $S$ of $G$ and an element $g\in G$ the Cayley Group Membership Problem
(denoted CGM) is to check if $g$ belongs to the subgroup generated by $S$.
While this problem is easily seen to be in polynomial time, pinpointing its
parallel complexity has been of research interest over the years. In this paper
we further explore the parallel complexity of the abelian CGM problem, with
focus on the dynamic setting: the generating set $S$ changes with insertions
and deletions and the goal is to maintain a data structure that supports
efficient membership queries to the subgroup $\angle{S}$. We obtain the
following results:
<br />1. We first consider the more general problem of Monoid Membership. When $G$
is a commutative monoid we give a deterministic dynamic algorithm
<br />constant time parallel algorithm for membership testing that supports $O(1)$
insertions and deletions in each step.
<br />2. Building on the previous result we show that there is a dynamic randomized
constant-time parallel algorithm for abelian CGM that supports
polylogarithmically many insertions/deletions to $S$ in each step.
<br />3. If the number of insertions/deletions is at most $O(\log n/\log\log n)$
then we obtain a deterministic dynamic constant-time parallel algorithm for the
problem.
<br />4. We obtain analogous results for the dynamic abelian Group Isomorphism.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10077" title="Abstract">arXiv:2308.10077</a> [<a href="/pdf/2308.10077" title="Download PDF">pdf</a>, <a href="/format/2308.10077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Learning for Non-Local Graphs with Multi-Resolution  Structural Views
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Asif Khan</a>, 
<a href="/search/cs?searchtype=author&query=Storkey%2C+A">Amos Storkey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Learning node-level representations of heterophilic graphs is crucial for
various applications, including fraudster detection and protein function
prediction. In such graphs, nodes share structural similarity identified by the
equivalence of their connectivity which is implicitly encoded in the form of
higher-order hierarchical information in the graphs. The contrastive methods
are popular choices for learning the representation of nodes in a graph.
However, existing contrastive methods struggle to capture higher-order graph
structures. To address this limitation, we propose a novel multiview
contrastive learning approach that integrates diffusion filters on graphs. By
incorporating multiple graph views as augmentations, our method captures the
structural equivalence in heterophilic graphs, enabling the discovery of hidden
relationships and similarities not apparent in traditional node
representations. Our approach outperforms baselines on synthetic and real
structural datasets, surpassing the best baseline by $16.06\%$ on Cornell,
$3.27\%$ on Texas, and $8.04\%$ on Wisconsin. Additionally, it consistently
achieves superior performance on proximal tasks, demonstrating its
effectiveness in uncovering structural information and improving downstream
applications.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10078" title="Abstract">arXiv:2308.10078</a> [<a href="/pdf/2308.10078" title="Download PDF">pdf</a>, <a href="/format/2308.10078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Repeated Builds During Code Review: An Empirical Study of the OpenStack  Community
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maipradit%2C+R">Rungroj Maipradit</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Thongtanunam%2C+P">Patanamon Thongtanunam</a>, 
<a href="/search/cs?searchtype=author&query=Kula%2C+R+G">Raula Gaikovina Kula</a>, 
<a href="/search/cs?searchtype=author&query=Kamei%2C+Y">Yasutaka Kamei</a>, 
<a href="/search/cs?searchtype=author&query=McIntosh%2C+S">Shane McIntosh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Code review is a popular practice where developers critique each others'
changes. Since automated builds can identify low-level issues (e.g., syntactic
errors, regression bugs), it is not uncommon for software organizations to
incorporate automated builds in the code review process. In such code review
deployment scenarios, submitted change sets must be approved for integration by
both peer code reviewers and automated build bots. Since automated builds may
produce an unreliable signal of the status of a change set (e.g., due to
``flaky'' or non-deterministic execution behaviour), code review tools, such as
Gerrit, allow developers to request a ``recheck'', which repeats the build
process without updating the change set. We conjecture that an unconstrained
recheck command will waste time and resources if it is not applied judiciously.
To explore how the recheck command is applied in a practical setting, in this
paper, we conduct an empirical study of 66,932 code reviews from the OpenStack
community.
<br />We quantitatively analyze (i) how often build failures are rechecked; (ii)
the extent to which invoking recheck changes build failure outcomes; and (iii)
how much waste is generated by invoking recheck. We observe that (i) 55% of
code reviews invoke the recheck command after a failing build is reported; (ii)
invoking the recheck command only changes the outcome of a failing build in 42%
of the cases; and (iii) invoking the recheck command increases review waiting
time by an average of 2,200% and equates to 187.4 compute years of waste --
enough compute resources to compete with the oldest land living animal on
earth.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10079" title="Abstract">arXiv:2308.10079</a> [<a href="/pdf/2308.10079" title="Download PDF">pdf</a>, <a href="/format/2308.10079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MeDM: Mediating Image Diffusion Models for Video-to-Video Translation  with Temporal Correspondence Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+E">Ernie Chu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tzuhsuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shuo-Yen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jun-Cheng Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This study introduces an efficient and effective method, MeDM, that utilizes
pre-trained image Diffusion Models for video-to-video translation with
consistent temporal flow. The proposed framework can render videos from scene
position information, such as a normal G-buffer, or perform text-guided editing
on videos captured in real-world scenarios. We employ explicit optical flows to
construct a practical coding that enforces physical constraints on generated
frames and mediates independent frame-wise scores. By leveraging this coding,
maintaining temporal consistency in the generated videos can be framed as an
optimization problem with a closed-form solution. To ensure compatibility with
Stable Diffusion, we also suggest a workaround for modifying observed-space
scores in latent-space Diffusion Models. Notably, MeDM does not require
fine-tuning or test-time optimization of the Diffusion Models. Through
extensive qualitative, quantitative, and subjective experiments on various
benchmarks, the study demonstrates the effectiveness and superiority of the
proposed approach.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10081" title="Abstract">arXiv:2308.10081</a> [<a href="/pdf/2308.10081" title="Download PDF">pdf</a>, <a href="/format/2308.10081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transporting Higher-Order Quadrature Rules: Quasi-Monte Carlo Points and  Sparse Grids for Mixture Distributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Klebanov%2C+I">Ilja Klebanov</a>, 
<a href="/search/math?searchtype=author&query=Sullivan%2C+T+J">T. J. Sullivan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">Integration against, and hence sampling from, high-dimensional probability
distributions is of essential importance in many application areas and has been
an active research area for decades. One approach that has drawn increasing
attention in recent years has been the generation of samples from a target
distribution $\mathbb{P}_{\mathrm{tar}}$ using transport maps: if
$\mathbb{P}_{\mathrm{tar}} = T_\# \mathbb{P}_{\mathrm{ref}}$ is the pushforward
of an easily-sampled probability distribution $\mathbb{P}_{\mathrm{ref}}$ under
the transport map $T$, then the application of $T$ to
$\mathbb{P}_{\mathrm{ref}}$-distributed samples yields
$\mathbb{P}_{\mathrm{tar}}$-distributed samples. This paper proposes the
application of transport maps not just to random samples, but also to
quasi-Monte Carlo points, higher-order nets, and sparse grids in order for the
transformed samples to inherit the original convergence rates that are often
better than $N^{-1/2}$, $N$ being the number of samples/quadrature nodes. Our
main result is the derivation of an explicit transport map for the case that
$\mathbb{P}_{\mathrm{tar}}$ is a mixture of simple distributions, e.g.\ a
Gaussian mixture, in which case application of the transport map $T$ requires
the solution of an \emph{explicit} ODE with \emph{closed-form} right-hand side.
Mixture distributions are of particular applicability and interest since many
methods proceed by first approximating $\mathbb{P}_{\mathrm{tar}}$ by a mixture
and then sampling from that mixture (often using importance reweighting).
Hence, this paper allows for the sampling step to provide a better convergence
rate than $N^{-1/2}$ for all such methods.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10086" title="Abstract">arXiv:2308.10086</a> [<a href="/pdf/2308.10086" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Connecting the Dots: Leveraging Social Network Analysis to Understand  and Optimize Collaborative Dynamics Within the Global Film Production Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maghsoudi%2C+M">Mehrdad Maghsoudi</a>, 
<a href="/search/cs?searchtype=author&query=Aliakbar%2C+S">Saeid Aliakbar</a>, 
<a href="/search/cs?searchtype=author&query=HabibiPour%2C+S">Sajjad HabibiPour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">In recent years, the global film industry has observed a notable surge in
international cooperation and cross-border investments. However, a
comprehensive overview of these collaborative investments within the industry
is lacking. This study employs social network analysis to delve into the
possibilities that lie in collaborative efforts and joint investments within
the film sector. The research constructs a network of 150 countries based on
shared creative elements in their film productions, comprising over 7800
interconnected links. Employing measures of centrality, certain pivotal nations
such as the United States, China, and England emerge as influential nodes,
showcasing a strong potential to steer industry growth through collaborative
engagement. Through a more detailed exploration involving community
identification, distinct clusters centered around thematic commonalities that
have converged through joint creative endeavors become evident. For example,
the "Global Thrill Seekers" community focuses on action films, whereas the
"Cultural-Social Cinema Group" addresses worldwide cultural and social issues.
Each of these communities presents distinctive perspectives for international
cooperation and the collaborative creation of content. This analysis
significantly enhances our understanding of the global film network's structure
and dynamics, while concurrently highlighting promising pathways for future
investment and collaborative initiatives. The research underscores the critical
role of leveraging social network analysis methodologies to optimize informed
decision-making concerning collaborative investments, thereby paving the way
for anticipatory outcomes. This study not only contributes insights but also
serves as a model for investigating data-centric participation within the
creative industries.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10087" title="Abstract">arXiv:2308.10087</a> [<a href="/pdf/2308.10087" title="Download PDF">pdf</a>, <a href="/format/2308.10087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GNNPipe: Accelerating Distributed Full-Graph GNN Training with Pipelined  Model Parallelism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingji Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuoming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+X">Xuehai Qian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Current distributed full-graph GNN training methods adopt a variant of data
parallelism, namely graph parallelism, in which the whole graph is divided into
multiple partitions (subgraphs) and each GPU processes one of them. This incurs
high communication overhead because of the inter-partition message passing at
each layer. To this end, we proposed a new training method named GNNPipe that
adopts model parallelism instead, which has a lower worst-case asymptotic
communication complexity than graph parallelism. To ensure high GPU
utilization, we proposed to combine model parallelism with a chunk-based
pipelined training method, in which each GPU processes a different chunk of
graph data at different layers concurrently. We further proposed hybrid
parallelism that combines model and graph parallelism when the model-level
parallelism is insufficient. We also introduced several tricks to ensure
convergence speed and model accuracies to accommodate embedding staleness
introduced by pipelining. Extensive experiments show that our method reduces
the per-epoch training time by up to 2.45x (on average 2.03x) and reduces the
communication volume and overhead by up to 22.51x and 27.21x (on average 10.27x
and 14.96x), respectively, while achieving a comparable level of model accuracy
and convergence speed compared to graph parallelism.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10088" title="Abstract">arXiv:2308.10088</a> [<a href="/pdf/2308.10088" title="Download PDF">pdf</a>, <a href="/format/2308.10088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PACE: Improving Prompt with Actor-Critic Editing for Large Language  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yihong Dong</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+K">Kangcheng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xue Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Ge Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Large language models (LLMs) have showcased remarkable potential across
various tasks by conditioning on prompts. However, the quality of different
human-written prompts leads to substantial discrepancies in LLMs' performance,
and improving prompts usually necessitates considerable human effort and
expertise. To this end, this paper proposes Prompt with Actor-Critic Editing
(PACE) for LLMs to enable automatic prompt editing. Drawing inspiration from
the actor-critic algorithm in reinforcement learning, PACE leverages LLMs as
the dual roles of actors and critics, conceptualizing prompt as a type of
policy. PACE refines prompt, taking into account the feedback from both actors
performing prompt and critics criticizing response. This process helps LLMs
better align prompt to a specific task, thanks to real responses and thinking
from LLMs. We conduct extensive experiments on 24 instruction induction tasks
and 21 big-bench tasks. Experimental results indicate that PACE elevates the
relative performance of medium/low-quality human-written prompts by up to 98\%,
which has comparable performance to high-quality human-written prompts.
Moreover, PACE also exhibits notable efficacy for prompt generation.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10089" title="Abstract">arXiv:2308.10089</a> [<a href="/pdf/2308.10089" title="Download PDF">pdf</a>, <a href="/format/2308.10089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Root Pose Decomposition Towards Generic Non-rigid 3D Reconstruction with  Monocular Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yikai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yinpeng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Fuchun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiao Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023. Project Page: <a href="https://rpd-share.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This work focuses on the 3D reconstruction of non-rigid objects based on
monocular RGB video sequences. Concretely, we aim at building high-fidelity
models for generic object categories and casually captured scenes. To this end,
we do not assume known root poses of objects, and do not utilize
category-specific templates or dense pose priors. The key idea of our method,
Root Pose Decomposition (RPD), is to maintain a per-frame root pose
transformation, meanwhile building a dense field with local transformations to
rectify the root pose. The optimization of local transformations is performed
by point registration to the canonical space. We also adapt RPD to multi-object
scenarios with object occlusions and individual differences. As a result, RPD
allows non-rigid 3D reconstruction for complicated scenarios containing objects
with large deformations, complex motion patterns, occlusions, and scale
diversities of different individuals. Such a pipeline potentially scales to
diverse sets of objects in the wild. We experimentally show that RPD surpasses
state-of-the-art methods on the challenging DAVIS, OVIS, and AMA datasets.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10090" title="Abstract">arXiv:2308.10090</a> [<a href="/pdf/2308.10090" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimizing Turns in Watchman Robot Navigation: Strategies and Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoorfar%2C+H">Hamid Hoorfar</a>, 
<a href="/search/cs?searchtype=author&query=Largani%2C+S+M">Sara Moshtaghi Largani</a>, 
<a href="/search/cs?searchtype=author&query=Rahimi%2C+R">Reza Rahimi</a>, 
<a href="/search/cs?searchtype=author&query=Bagheri%2C+A">Alireza Bagheri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The 21st International Conference on Scientific Computing in The
  2023 World Congress in Computer Science, Computer Engineering, &amp; Applied
  Computing (CSCE'23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The Orthogonal Watchman Route Problem (OWRP) entails the search for the
shortest path, known as the watchman route, that a robot must follow within a
polygonal environment. The primary objective is to ensure that every point in
the environment remains visible from at least one point on the route, allowing
the robot to survey the entire area in a single, continuous sweep. This
research places particular emphasis on reducing the number of turns in the
route, as it is crucial for optimizing navigation in watchman routes within the
field of robotics. The cost associated with changing direction is of
significant importance, especially for specific types of robots. This paper
introduces an efficient linear-time algorithm for solving the OWRP under the
assumption that the environment is monotone. The findings of this study
contribute to the progress of robotic systems by enabling the design of more
streamlined patrol robots. These robots are capable of efficiently navigating
complex environments while minimizing the number of turns. This advancement
enhances their coverage and surveillance capabilities, making them highly
effective in various real-world applications.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10092" title="Abstract">arXiv:2308.10092</a> [<a href="/pdf/2308.10092" title="Download PDF">pdf</a>, <a href="/format/2308.10092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open, Closed, or Small Language Models for Text Classification?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zachary Yang</a>, 
<a href="/search/cs?searchtype=author&query=Pelrine%2C+K">Kellin Pelrine</a>, 
<a href="/search/cs?searchtype=author&query=Godbout%2C+J+F">Jean Francois Godbout</a>, 
<a href="/search/cs?searchtype=author&query=Rabbany%2C+R">Reihaneh Rabbany</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 15 Tables, 1 Figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent advancements in large language models have demonstrated remarkable
capabilities across various NLP tasks. But many questions remain, including
whether open-source models match closed ones, why these models excel or
struggle with certain tasks, and what types of practical procedures can improve
performance. We address these questions in the context of classification by
evaluating three classes of models using eight datasets across three distinct
tasks: named entity recognition, political party prediction, and misinformation
detection. While larger LLMs often lead to improved performance, open-source
models can rival their closed-source counterparts by fine-tuning. Moreover,
supervised smaller models, like RoBERTa, can achieve similar or even greater
performance in many datasets compared to generative LLMs. On the other hand,
closed models maintain an advantage in hard tasks that demand the most
generalizability. This study underscores the importance of model selection
based on task requirements
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10093" title="Abstract">arXiv:2308.10093</a> [<a href="/pdf/2308.10093" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Securing Pathways with Orthogonal Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoorfar%2C+H">Hamid Hoorfar</a>, 
<a href="/search/cs?searchtype=author&query=Fathi%2C+F">Faraneh Fathi</a>, 
<a href="/search/cs?searchtype=author&query=Largani%2C+S+M">Sara Moshtaghi Largani</a>, 
<a href="/search/cs?searchtype=author&query=Bagheri%2C+A">Alireza Bagheri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The 21st International Conference on Scientific Computing in The
  2023 World Congress in Computer Science, Computer Engineering, &amp; Applied
  Computing (CSCE'23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The protection of pathways holds immense significance across various domains,
including urban planning, transportation, surveillance, and security. This
article introduces a groundbreaking approach to safeguarding pathways by
employing orthogonal robots. The study specifically addresses the challenge of
efficiently guarding orthogonal areas with the minimum number of orthogonal
robots. The primary focus is on orthogonal pathways, characterized by a
path-like dual graph of vertical decomposition. It is demonstrated that
determining the minimum number of orthogonal robots for pathways can be
achieved in linear time. However, it is essential to note that the general
problem of finding the minimum number of robots for simple polygons with
general visibility, even in the orthogonal case, is known to be NP-hard.
Emphasis is placed on the flexibility of placing robots anywhere within the
polygon, whether on the boundary or in the interior.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10094" title="Abstract">arXiv:2308.10094</a> [<a href="/pdf/2308.10094" title="Download PDF">pdf</a>, <a href="/format/2308.10094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning and Communications Co-Design for Remote Inference Systems:  Feature Length Selection and Transmission Scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shisher%2C+M+K+C">Md Kamran Chowdhury Shisher</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+B">Bo Ji</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+I">I-Hong Hou</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yin Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 8 figures. The manuscript has been submitted to IEEE Journal on Selected Areas in Information Theory
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">In this paper, we consider a remote inference system, where a neural network
is used to infer a time-varying target (e.g., robot movement), based on
features (e.g., video clips) that are progressively received from a sensing
node (e.g., a camera). Each feature is a temporal sequence of sensory data. The
learning performance of the system is determined by (i) the timeliness and (ii)
the temporal sequence length of the features, where we use Age of Information
(AoI) as a metric for timeliness. While a longer feature can typically provide
better learning performance, it often requires more channel resources for
sending the feature. To minimize the time-averaged inference error, we study a
learning and communication co-design problem that jointly optimizes feature
length selection and transmission scheduling. When there is a single
sensor-predictor pair and a single channel, we develop low-complexity optimal
co-designs for both the cases of time-invariant and time-variant feature
length. When there are multiple sensor-predictor pairs and multiple channels,
the co-design problem becomes a restless multi-arm multi-action bandit problem
that is PSPACE-hard. For this setting, we design a low-complexity algorithm to
solve the problem. Trace-driven evaluations suggest that the proposed
co-designs can significantly reduce the time-averaged inference error of remote
inference systems.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10097" title="Abstract">arXiv:2308.10097</a> [<a href="/pdf/2308.10097" title="Download PDF">pdf</a>, <a href="/format/2308.10097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rafting Towards Consensus: Formation Control of Distributed Dynamical  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tariverdi%2C+A">Abbas Tariverdi</a>, 
<a href="/search/cs?searchtype=author&query=Torresen%2C+J">Jim Torresen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">In this paper, we introduce a novel adaptation of the Raft consensus
algorithm for achieving emergent formation control in multi-agent systems with
a single integrator dynamics. This strategy, dubbed "Rafting," enables robust
cooperation between distributed nodes, thereby facilitating the achievement of
desired geometric configurations. Our framework takes advantage of the Raft
algorithm's inherent fault tolerance and strong consistency guarantees to
extend its applicability to distributed formation control tasks. Following the
introduction of a decentralized mechanism for aggregating agent states, a
synchronization protocol for information exchange and consensus formation is
proposed. The Raft consensus algorithm combines leader election, log
replication, and state machine application to steer agents toward a common,
collaborative goal. A series of detailed simulations validate the efficacy and
robustness of our method under various conditions, including partial network
failures and disturbances. The outcomes demonstrate the algorithm's potential
and open up new possibilities in swarm robotics, autonomous transportation, and
distributed computation. The implementation of the algorithms presented in this
paper is available at https://github.com/abbas-tari/raft.git.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10099" title="Abstract">arXiv:2308.10099</a> [<a href="/pdf/2308.10099" title="Download PDF">pdf</a>, <a href="/format/2308.10099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometric instability of graph neural networks on large graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morris%2C+E">Emily Morris</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Haotian Shen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Weiling Du</a>, 
<a href="/search/cs?searchtype=author&query=Sajjad%2C+M+H">Muhammad Hamza Sajjad</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Borun Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">We analyse the geometric instability of embeddings produced by graph neural
networks (GNNs). Existing methods are only applicable for small graphs and lack
context in the graph domain. We propose a simple, efficient and graph-native
Graph Gram Index (GGI) to measure such instability which is invariant to
permutation, orthogonal transformation, translation and order of evaluation.
This allows us to study the varying instability behaviour of GNN embeddings on
large graphs for both node classification and link prediction.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10101" title="Abstract">arXiv:2308.10101</a> [<a href="/pdf/2308.10101" title="Download PDF">pdf</a>, <a href="/format/2308.10101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Online Multiple Kernel Parallelizable Learning Scheme
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruiz-Moreno%2C+E">Emilio Ruiz-Moreno</a>, 
<a href="/search/cs?searchtype=author&query=Beferull-Lozano%2C+B">Baltasar Beferull-Lozano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The performance of reproducing kernel Hilbert space-based methods is known to
be sensitive to the choice of the reproducing kernel. Choosing an adequate
reproducing kernel can be challenging and computationally demanding, especially
in data-rich tasks without prior information about the solution domain. In this
paper, we propose a learning scheme that scalably combines several single
kernel-based online methods to reduce the kernel-selection bias. The proposed
learning scheme applies to any task formulated as a regularized empirical risk
minimization convex problem. More specifically, our learning scheme is based on
a multi-kernel learning formulation that can be applied to widen any
single-kernel solution space, thus increasing the possibility of finding
higher-performance solutions. In addition, it is parallelizable, allowing for
the distribution of the computational load across different computing units. We
show experimentally that the proposed learning scheme outperforms the combined
single-kernel online methods separately in terms of the cumulative regularized
least squares cost metric.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10103" title="Abstract">arXiv:2308.10103</a> [<a href="/pdf/2308.10103" title="Download PDF">pdf</a>, <a href="/format/2308.10103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ASPIRE: Language-Guided Augmentation for Robust Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Sreyan Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Evuru%2C+C+K+R">Chandra Kiran Reddy Evuru</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sonal Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Tyagi%2C+U">Utkarsh Tyagi</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Sakshi Singh</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+S">Sanjoy Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-print Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Neural image classifiers can often learn to make predictions by overly
relying on non-predictive features that are spuriously correlated with the
class labels in the training data. This leads to poor performance in real-world
atypical scenarios where such features are absent. Supplementing the training
dataset with images without such spurious features can aid robust learning
against spurious correlations via better generalization. This paper presents
ASPIRE (Language-guided data Augmentation for SPurIous correlation REmoval), a
simple yet effective solution for expanding the training dataset with synthetic
images without spurious features. ASPIRE, guided by language, generates these
images without requiring any form of additional supervision or existing
examples. Precisely, we employ LLMs to first extract foreground and background
features from textual descriptions of an image, followed by advanced
language-guided image editing to discover the features that are spuriously
correlated with the class label. Finally, we personalize a text-to-image
generation model to generate diverse in-domain images without spurious
features. We demonstrate the effectiveness of ASPIRE on 4 datasets, including
the very challenging Hard ImageNet dataset, and 9 baselines and show that
ASPIRE improves the classification accuracy of prior methods by 1% - 38%. Code
soon at: https://github.com/Sreyan88/ASPIRE.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10107" title="Abstract">arXiv:2308.10107</a> [<a href="/pdf/2308.10107" title="Download PDF">pdf</a>, <a href="/format/2308.10107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayes Risk Transducer: Transducer with Controllable Alignment Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jinchuan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jianwei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hangting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Brian Yan</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+C">Chao Weng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Interspeech 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Automatic speech recognition (ASR) based on transducers is widely used. In
training, a transducer maximizes the summed posteriors of all paths. The path
with the highest posterior is commonly defined as the predicted alignment
between the speech and the transcription. While the vanilla transducer does not
have a prior preference for any of the valid paths, this work intends to
enforce the preferred paths and achieve controllable alignment prediction.
Specifically, this work proposes Bayes Risk Transducer (BRT), which uses a
Bayes risk function to set lower risk values to the preferred paths so that the
predicted alignment is more likely to satisfy specific desired properties. We
further demonstrate that these predicted alignments with intentionally designed
properties can provide practical advantages over the vanilla transducer.
Experimentally, the proposed BRT saves inference cost by up to 46% for
non-streaming ASR and reduces overall system latency by 41% for streaming ASR.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10109" title="Abstract">arXiv:2308.10109</a> [<a href="/pdf/2308.10109" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unbiased Library of k-regular, n-sized, Connected, Small Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=David-Barrett%2C+T">Tamas David-Barrett</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 49 pages,1 table, 11 figures in the main papers (and further panels of figures in the SM at the end of the paper)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">The past decade highlighted the usefulness of social network simulations that
run on k-regular, n-size, connected graphs. These can be seen as small-scale
models of human social networks of large societies. By narrowing down onto
k-regular graphs, the degree variation can be eliminated from the research
question, which allows a focus on the isolated impact by other variables, for
instance, by the clustering coefficient or the size of the network. This paper
describes the generation of a random graph library that uses a random walk
graph creation algorithm that starts from the "chain of caves", which is the
structure in which the clustering coefficient is at its maximum. This method
finds mid and high clustering coefficient graphs, while Wolfram`s RandomGraph
was useful for finding low ones. The merge of the two samples proved to be
somewhat biased. After eliminating a host of network measures, the paper
focused on mean graph distance as a further variable and created an unbiased
subsample for each size and clustering coefficient bin.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10110" title="Abstract">arXiv:2308.10110</a> [<a href="/pdf/2308.10110" title="Download PDF">pdf</a>, <a href="/format/2308.10110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Mixture-of-Expert Training for Convolutional Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yihua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+R">Ruisi Cai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianlong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guanhua Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pin-Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+S">Shiyu Chang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sijia Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Sparsely-gated Mixture of Expert (MoE), an emerging deep model architecture,
has demonstrated a great promise to enable high-accuracy and ultra-efficient
model inference. Despite the growing popularity of MoE, little work
investigated its potential to advance convolutional neural networks (CNNs),
especially in the plane of adversarial robustness. Since the lack of robustness
has become one of the main hurdles for CNNs, in this paper we ask: How to
adversarially robustify a CNN-based MoE model? Can we robustly train it like an
ordinary CNN model? Our pilot study shows that the conventional adversarial
training (AT) mechanism (developed for vanilla CNNs) no longer remains
effective to robustify an MoE-CNN. To better understand this phenomenon, we
dissect the robustness of an MoE-CNN into two dimensions: Robustness of routers
(i.e., gating functions to select data-specific experts) and robustness of
experts (i.e., the router-guided pathways defined by the subnetworks of the
backbone CNN). Our analyses show that routers and experts are hard to adapt to
each other in the vanilla AT. Thus, we propose a new router-expert alternating
Adversarial training framework for MoE, termed AdvMoE. The effectiveness of our
proposal is justified across 4 commonly-used CNN model architectures over 4
benchmark datasets. We find that AdvMoE achieves 1% ~ 4% adversarial robustness
improvement over the original dense CNN, and enjoys the efficiency merit of
sparsity-gated MoE, leading to more than 50% inference cost reduction. Codes
are available at https://github.com/OPTML-Group/Robust-MoE-CNN.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10111" title="Abstract">arXiv:2308.10111</a> [<a href="/pdf/2308.10111" title="Download PDF">pdf</a>, <a href="/format/2308.10111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controllable Multi-domain Semantic Artwork Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuantian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Iizuka%2C+S">Satoshi Iizuka</a>, 
<a href="/search/cs?searchtype=author&query=Simo-Serra%2C+E">Edgar Simo-Serra</a>, 
<a href="/search/cs?searchtype=author&query=Fukui%2C+K">Kazuhiro Fukui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, accepted by CVMJ, to appear
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We present a novel framework for multi-domain synthesis of artwork from
semantic layouts. One of the main limitations of this challenging task is the
lack of publicly available segmentation datasets for art synthesis. To address
this problem, we propose a dataset, which we call ArtSem, that contains 40,000
images of artwork from 4 different domains with their corresponding semantic
label maps. We generate the dataset by first extracting semantic maps from
landscape photography and then propose a conditional Generative Adversarial
Network (GAN)-based approach to generate high-quality artwork from the semantic
maps without necessitating paired training data. Furthermore, we propose an
artwork synthesis model that uses domain-dependent variational encoders for
high-quality multi-domain synthesis. The model is improved and complemented
with a simple but effective normalization method, based on normalizing both the
semantic and style jointly, which we call Spatially STyle-Adaptive
Normalization (SSTAN). In contrast to previous methods that only take semantic
layout as input, our model is able to learn a joint representation of both
style and semantic information, which leads to better generation quality for
synthesizing artistic images. Results indicate that our model learns to
separate the domains in the latent space, and thus, by identifying the
hyperplanes that separate the different domains, we can also perform
fine-grained control of the synthesized artwork. By combining our proposed
dataset and approach, we are able to generate user-controllable artwork that is
of higher quality than existing
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10112" title="Abstract">arXiv:2308.10112</a> [<a href="/pdf/2308.10112" title="Download PDF">pdf</a>, <a href="/format/2308.10112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PDL: Regularizing Multiple Instance Learning with Progressive Dropout  Layers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenhui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+P">Peijie Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Dumitrascu%2C+O+M">Oana M. Dumitrascu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yalin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The code is available in <a href="https://github.com/ChongQingNoSubway/PDL">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multiple instance learning (MIL) was a weakly supervised learning approach
that sought to assign binary class labels to collections of instances known as
bags. However, due to their weak supervision nature, the MIL methods were
susceptible to overfitting and required assistance in developing comprehensive
representations of target instances. While regularization typically effectively
combated overfitting, its integration with the MIL model has been frequently
overlooked in prior studies. Meanwhile, current regularization methods for MIL
have shown limitations in their capacity to uncover a diverse array of
representations. In this study, we delve into the realm of regularization
within the MIL model, presenting a novel approach in the form of a Progressive
Dropout Layer (PDL). We aim to not only address overfitting but also empower
the MIL model in uncovering intricate and impactful feature representations.
The proposed method was orthogonal to existing MIL methods and could be easily
integrated into them to boost performance. Our extensive evaluation across a
range of MIL benchmark datasets demonstrated that the incorporation of the PDL
into multiple MIL methods not only elevated their classification performance
but also augmented their potential for weakly-supervised feature localizations.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10115" title="Abstract">arXiv:2308.10115</a> [<a href="/pdf/2308.10115" title="Download PDF">pdf</a>, <a href="/format/2308.10115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Evaluation of Three Distance Measurement Technologies for Flying  Light Specks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phan%2C+T">Trung Phan</a>, 
<a href="/search/cs?searchtype=author&query=Alimohammadzadeh%2C+H">Hamed Alimohammadzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Culbertson%2C+H">Heather Culbertson</a>, 
<a href="/search/cs?searchtype=author&query=Ghandeharizadeh%2C+S">Shahram Ghandeharizadeh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In International Conference on Intelligent Metaverse Technologies and Applications (iMETA2023), Tartu, Estonia, September 18-20, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Graphics (cs.GR); Robotics (cs.RO)

</div>
<p class="mathjax">This study evaluates the accuracy of three different types of time-of-flight
sensors to measure distance. We envision the possible use of these sensors to
localize swarms of flying light specks (FLSs) to illuminate objects and avatars
of a metaverse. An FLS is a miniature-sized drone configured with RGB light
sources. It is unable to illuminate a point cloud by itself. However, the
inter-FLS relationship effect of an organizational framework will compensate
for the simplicity of each individual FLS, enabling a swarm of cooperating FLSs
to illuminate complex shapes and render haptic interactions. Distance between
FLSs is an important criterion of the inter-FLS relationship. We consider
sensors that use radio frequency (UWB), infrared light (IR), and sound
(ultrasonic) to quantify this metric. Obtained results show only one sensor is
able to measure distances as small as 1 cm with a high accuracy. A sensor may
require a calibration process that impacts its accuracy in measuring distance.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10119" title="Abstract">arXiv:2308.10119</a> [<a href="/pdf/2308.10119" title="Download PDF">pdf</a>, <a href="/format/2308.10119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error Probability Bounds for Invariant Causal Prediction via Multiple  Access Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goddard%2C+A">Austin Goddard</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Y">Yu Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Soloveychik%2C+I">Ilya Soloveychik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 2023 Asilomar Conference on Signals, Systems, and Computers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP); Methodology (stat.ME)

</div>
<p class="mathjax">We consider the problem of lower bounding the error probability under the
invariant causal prediction (ICP) framework. To this end, we examine and draw
connections between ICP and the zero-rate Gaussian multiple access channel by
first proposing a variant of the original invariant prediction assumption, and
then considering a special case of the Gaussian multiple access channel where a
codebook is shared between an unknown number of senders. This connection allows
us to develop three types of lower bounds on the error probability, each with
different assumptions and constraints, leveraging techniques for multiple
access channels. The proposed bounds are evaluated with respect to existing
causal discovery methods as well as a proposed heuristic method based on
minimum distance decoding.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10120" title="Abstract">arXiv:2308.10120</a> [<a href="/pdf/2308.10120" title="Download PDF">pdf</a>, <a href="/format/2308.10120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Generative Modeling-based Data Augmentation with Demonstration  using the BFBT Benchmark Void Fraction Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alsafadi%2C+F">Farah Alsafadi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xu Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deep learning (DL) has achieved remarkable successes in many disciplines such
as computer vision and natural language processing due to the availability of
``big data''. However, such success cannot be easily replicated in many nuclear
engineering problems because of the limited amount of training data, especially
when the data comes from high-cost experiments. To overcome such a data
scarcity issue, this paper explores the applications of deep generative models
(DGMs) that have been widely used for image data generation to scientific data
augmentation. DGMs, such as generative adversarial networks (GANs), normalizing
flows (NFs), variational autoencoders (VAEs), and conditional VAEs (CVAEs), can
be trained to learn the underlying probabilistic distribution of the training
dataset. Once trained, they can be used to generate synthetic data that are
similar to the training data and significantly expand the dataset size. By
employing DGMs to augment TRACE simulated data of the steady-state void
fractions based on the NUPEC Boiling Water Reactor Full-size Fine-mesh Bundle
Test (BFBT) benchmark, this study demonstrates that VAEs, CVAEs, and GANs have
comparable generative performance with similar errors in the synthetic data,
with CVAEs achieving the smallest errors. The findings shows that DGMs have a
great potential to augment scientific data in nuclear engineering, which proves
effective for expanding the training dataset and enabling other DL models to be
trained more accurately.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10121" title="Abstract">arXiv:2308.10121</a> [<a href="/pdf/2308.10121" title="Download PDF">pdf</a>, <a href="/format/2308.10121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dronevision: An Experimental 3D Testbed for Flying Light Specks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alimohammadzadeh%2C+H">Hamed Alimohammadzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Bernard%2C+R">Rohit Bernard</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+T">Trung Phan</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+P">Prashant Singh</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shuqin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Culbertson%2C+H">Heather Culbertson</a>, 
<a href="/search/cs?searchtype=author&query=Ghandeharizadeh%2C+S">Shahram Ghandeharizadeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Graphics (cs.GR); Robotics (cs.RO)

</div>
<p class="mathjax">Today's robotic laboratories for drones are housed in a large room. At times,
they are the size of a warehouse. These spaces are typically equipped with
permanent devices to localize the drones, e.g., Vicon Infrared cameras.
Significant time is invested to fine-tune the localization apparatus to compute
and control the position of the drones. One may use these laboratories to
develop a 3D multimedia system with miniature sized drones configured with
light sources. As an alternative, this brave new idea paper envisions shrinking
these room-sized laboratories to the size of a cube or cuboid that sits on a
desk and costs less than 10K dollars. The resulting Dronevision (DV) will be
the size of a 1990s Television. In addition to light sources, its Flying Light
Specks (FLSs) will be network-enabled drones with storage and processing
capability to implement decentralized algorithms. The DV will include a
localization technique to expedite development of 3D displays. It will act as a
haptic interface for a user to interact with and manipulate the 3D virtual
illuminations. It will empower an experimenter to design, implement, test,
debug, and maintain software and hardware that realize novel algorithms in the
comfort of their office without having to reserve a laboratory. In addition to
enhancing productivity, it will improve safety of the experimenter by
minimizing the likelihood of accidents. This paper introduces the concept of a
DV, the research agenda one may pursue using this device, and our plans to
realize one.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10122" title="Abstract">arXiv:2308.10122</a> [<a href="/pdf/2308.10122" title="Download PDF">pdf</a>, <a href="/format/2308.10122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HollowNeRF: Pruning Hashgrid-Based NeRFs with Trainable Collision  Mitigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiufeng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Gherardi%2C+R">Riccardo Gherardi</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhihong Pan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Stephen Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural radiance fields (NeRF) have garnered significant attention, with
recent works such as Instant-NGP accelerating NeRF training and evaluation
through a combination of hashgrid-based positional encoding and neural
networks. However, effectively leveraging the spatial sparsity of 3D scenes
remains a challenge. To cull away unnecessary regions of the feature grid,
existing solutions rely on prior knowledge of object shape or periodically
estimate object shape during training by repeated model evaluations, which are
costly and wasteful.
<br />To address this issue, we propose HollowNeRF, a novel compression solution
for hashgrid-based NeRF which automatically sparsifies the feature grid during
the training phase. Instead of directly compressing dense features, HollowNeRF
trains a coarse 3D saliency mask that guides efficient feature pruning, and
employs an alternating direction method of multipliers (ADMM) pruner to
sparsify the 3D saliency mask during training. By exploiting the sparsity in
the 3D scene to redistribute hash collisions, HollowNeRF improves rendering
quality while using a fraction of the parameters of comparable state-of-the-art
solutions, leading to a better cost-accuracy trade-off. Our method delivers
comparable rendering quality to Instant-NGP, while utilizing just 31% of the
parameters. In addition, our solution can achieve a PSNR accuracy gain of up to
1dB using only 56% of the parameters.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10123" title="Abstract">arXiv:2308.10123</a> [<a href="/pdf/2308.10123" title="Download PDF">pdf</a>, <a href="/format/2308.10123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D-Aware Neural Body Fitting for Occlusion Robust 3D Human Pose  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+P">Pengliang Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Angtian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+J">Jieru Mei</a>, 
<a href="/search/cs?searchtype=author&query=Kortylewski%2C+A">Adam Kortylewski</a>, 
<a href="/search/cs?searchtype=author&query=Yuille%2C+A">Alan Yuille</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023, project page: <a href="https://3dnbf.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Regression-based methods for 3D human pose estimation directly predict the 3D
pose parameters from a 2D image using deep networks. While achieving
state-of-the-art performance on standard benchmarks, their performance degrades
under occlusion. In contrast, optimization-based methods fit a parametric body
model to 2D features in an iterative manner. The localized reconstruction loss
can potentially make them robust to occlusion, but they suffer from the 2D-3D
ambiguity.
<br />Motivated by the recent success of generative models in rigid object pose
estimation, we propose 3D-aware Neural Body Fitting (3DNBF) - an approximate
analysis-by-synthesis approach to 3D human pose estimation with SOTA
performance and occlusion robustness. In particular, we propose a generative
model of deep features based on a volumetric human representation with Gaussian
ellipsoidal kernels emitting 3D pose-dependent feature vectors. The neural
features are trained with contrastive learning to become 3D-aware and hence to
overcome the 2D-3D ambiguity.
<br />Experiments show that 3DNBF outperforms other approaches on both occluded and
standard benchmarks. Code is available at https://github.com/edz-o/3DNBF
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10124" title="Abstract">arXiv:2308.10124</a> [<a href="/pdf/2308.10124" title="Download PDF">pdf</a>, <a href="/format/2308.10124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligent Communication Planning for Constrained Environmental IoT  Sensing with Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+J">Jinhang Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Iannucci%2C+B">Bob Iannucci</a>, 
<a href="/search/cs?searchtype=author&query=Joe-Wong%2C+C">Carlee Joe-Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the 20th Annual IEEE International Conference on Sensing, Communication, and Networking (SECON 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Internet of Things (IoT) technologies have enabled numerous data-driven
mobile applications and have the potential to significantly improve
environmental monitoring and hazard warnings through the deployment of a
network of IoT sensors. However, these IoT devices are often power-constrained
and utilize wireless communication schemes with limited bandwidth. Such power
constraints limit the amount of information each device can share across the
network, while bandwidth limitations hinder sensors' coordination of their
transmissions. In this work, we formulate the communication planning problem of
IoT sensors that track the state of the environment. We seek to optimize
sensors' decisions in collecting environmental data under stringent resource
constraints. We propose a multi-agent reinforcement learning (MARL) method to
find the optimal communication policies for each sensor that maximize the
tracking accuracy subject to the power and bandwidth limitations. MARL learns
and exploits the spatial-temporal correlation of the environmental data at each
sensor's location to reduce the redundant reports from the sensors. Experiments
on wildfire spread with LoRA wireless network simulators show that our MARL
method can learn to balance the need to collect enough data to predict wildfire
spread with unknown bandwidth limitations.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10130" title="Abstract">arXiv:2308.10130</a> [<a href="/pdf/2308.10130" title="Download PDF">pdf</a>, <a href="/format/2308.10130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Approximation of Operator-Valued Riccati Equations in Hilbert  Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cheung%2C+J">James Cheung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Initial Release
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">In this work, we present an abstract theory for the approximation of
operator-valued Riccati equations posed on Hilbert spaces. It is demonstrated
here, under the assumption of compactness in the coefficient operators, that
the error of the approximate solution to the operator-valued Riccati equation
is bounded above by the approximation error of the governing semigroup. One
significant outcome of this result is the correct prediction of optimal
convergence for finite element approximations of the operator-valued Riccati
equations for when the governing semigroup involves parabolic, as well as
hyperbolic processes. We derive the abstract theory for the time-dependent and
time-independent operator-valued Riccati equations in the first part of this
work. In the second part, we prove optimal convergence rates for the finite
element approximation of the functional gain associated with model
one-dimensional weakly damped wave and thermal LQR control systems. These
theoretical claims are then corroborated with computational evidence.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10133" title="Abstract">arXiv:2308.10133</a> [<a href="/pdf/2308.10133" title="Download PDF">pdf</a>, <a href="/format/2308.10133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TransFace: Calibrating Transformer Training for Face Recognition from a  Data-Centric Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dan%2C+J">Jun Dan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Haoyu Xie</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jiankang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Haoran Xie</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuansong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Baigui Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Vision Transformers (ViTs) have demonstrated powerful representation ability
in various visual tasks thanks to their intrinsic data-hungry nature. However,
we unexpectedly find that ViTs perform vulnerably when applied to face
recognition (FR) scenarios with extremely large datasets. We investigate the
reasons for this phenomenon and discover that the existing data augmentation
approach and hard sample mining strategy are incompatible with ViTs-based FR
backbone due to the lack of tailored consideration on preserving face
structural information and leveraging each local token information. To remedy
these problems, this paper proposes a superior FR model called TransFace, which
employs a patch-level data augmentation strategy named DPAP and a hard sample
mining strategy named EHSM. Specially, DPAP randomly perturbs the amplitude
information of dominant patches to expand sample diversity, which effectively
alleviates the overfitting problem in ViTs. EHSM utilizes the information
entropy in the local tokens to dynamically adjust the importance weight of easy
and hard samples during training, leading to a more stable prediction.
Experiments on several benchmarks demonstrate the superiority of our TransFace.
Code and models are available at https://github.com/DanJun6737/TransFace.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10134" title="Abstract">arXiv:2308.10134</a> [<a href="/pdf/2308.10134" title="Download PDF">pdf</a>, <a href="/format/2308.10134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoReP: Automatic ReLU Replacement for Fast Private Network Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hongwu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shaoyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yukui Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenghong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zigeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiahui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Ang Li</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+T">Tony Geng</a>, 
<a href="/search/cs?searchtype=author&query=Mahmood%2C+K">Kaleel Mahmood</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+W">Wujie Wen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaolin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Caiwen Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 accepeted publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The growth of the Machine-Learning-As-A-Service (MLaaS) market has
highlighted clients' data privacy and security issues. Private inference (PI)
techniques using cryptographic primitives offer a solution but often have high
computation and communication costs, particularly with non-linear operators
like ReLU. Many attempts to reduce ReLU operations exist, but they may need
heuristic threshold selection or cause substantial accuracy loss. This work
introduces AutoReP, a gradient-based approach to lessen non-linear operators
and alleviate these issues. It automates the selection of ReLU and polynomial
functions to speed up PI applications and introduces distribution-aware
polynomial approximation (DaPa) to maintain model expressivity while accurately
approximating ReLUs. Our experimental results demonstrate significant accuracy
improvements of 6.12% (94.31%, 12.9K ReLU budget, CIFAR-10), 8.39% (74.92%,
12.9K ReLU budget, CIFAR-100), and 9.45% (63.69%, 55K ReLU budget,
Tiny-ImageNet) over current state-of-the-art methods, e.g., SNL. Morever,
AutoReP is applied to EfficientNet-B2 on ImageNet dataset, and achieved 75.55%
accuracy with 176.1 times ReLU budget reduction.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10135" title="Abstract">arXiv:2308.10135</a> [<a href="/pdf/2308.10135" title="Download PDF">pdf</a>, <a href="/format/2308.10135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Review on Objective-Driven Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Apoorv Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures, workshop submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">While advancing rapidly, Artificial Intelligence still falls short of human
intelligence in several key aspects due to inherent limitations in current AI
technologies and our understanding of cognition. Humans have an innate ability
to understand context, nuances, and subtle cues in communication, which allows
us to comprehend jokes, sarcasm, and metaphors. Machines struggle to interpret
such contextual information accurately. Humans possess a vast repository of
common-sense knowledge that helps us make logical inferences and predictions
about the world. Machines lack this innate understanding and often struggle
with making sense of situations that humans find trivial. In this article, we
review the prospective Machine Intelligence candidates, a review from Prof.
Yann LeCun, and other work that can help close this gap between human and
machine intelligence. Specifically, we talk about what's lacking with the
current AI techniques such as supervised learning, reinforcement learning,
self-supervised learning, etc. Then we show how Hierarchical planning-based
approaches can help us close that gap and deep-dive into energy-based,
latent-variable methods and Joint embedding predictive architecture methods.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10141" title="Abstract">arXiv:2308.10141</a> [<a href="/pdf/2308.10141" title="Download PDF">pdf</a>, <a href="/format/2308.10141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> March in Chat: Interactive Prompting for Remote Embodied Referring  Expression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yanyuan Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yuankai Qi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qi Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Many Vision-and-Language Navigation (VLN) tasks have been proposed in recent
years, from room-based to object-based and indoor to outdoor. The REVERIE
(Remote Embodied Referring Expression) is interesting since it only provides
high-level instructions to the agent, which are closer to human commands in
practice. Nevertheless, this poses more challenges than other VLN tasks since
it requires agents to infer a navigation plan only based on a short
instruction. Large Language Models (LLMs) show great potential in robot action
planning by providing proper prompts. Still, this strategy has not been
explored under the REVERIE settings. There are several new challenges. For
example, the LLM should be environment-aware so that the navigation plan can be
adjusted based on the current visual observation. Moreover, the LLM planned
actions should be adaptable to the much larger and more complex REVERIE
environment. This paper proposes a March-in-Chat (MiC) model that can talk to
the LLM on the fly and plan dynamically based on a newly proposed
Room-and-Object Aware Scene Perceiver (ROASP). Our MiC model outperforms the
previous state-of-the-art by large margins by SPL and RGSPL metrics on the
REVERIE benchmark.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10144" title="Abstract">arXiv:2308.10144</a> [<a href="/pdf/2308.10144" title="Download PDF">pdf</a>, <a href="/format/2308.10144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ExpeL: LLM Agents Are Experiential Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+A">Andrew Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Daniel Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Quentin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Matthieu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong-Jin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Gao Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">The recent surge in research interest in applying large language models
(LLMs) to decision-making tasks has flourished by leveraging the extensive
world knowledge embedded in LLMs. While there is a growing demand to tailor
LLMs for custom decision-making tasks, finetuning them for specific tasks is
resource-intensive and may diminish the model's generalization capabilities.
Moreover, state-of-the-art language models like GPT-4 and Claude are primarily
accessible through API calls, with their parametric weights remaining
proprietary and unavailable to the public. This scenario emphasizes the growing
need for new methodologies that allow learning from agent experiences without
requiring parametric updates. To address these problems, we introduce the
Experiential Learning (ExpeL) agent. Our agent autonomously gathers experiences
and extracts knowledge using natural language from a collection of training
tasks. At inference, the agent recalls its extracted insights and past
experiences to make informed decisions. Our empirical results highlight the
robust learning efficacy of the ExpeL agent, indicating a consistent
enhancement in its performance as it accumulates experiences. We further
explore the emerging capabilities and transfer learning potential of the ExpeL
agent through qualitative observations and additional experiments.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10146" title="Abstract">arXiv:2308.10146</a> [<a href="/pdf/2308.10146" title="Download PDF">pdf</a>, <a href="/format/2308.10146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OCHID-Fi: Occlusion-Robust Hand Pose Estimation in 3D via RF-Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shujie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tianyue Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jingzhi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Khamis%2C+A">Abdelwahed Khamis</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiajun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jun Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Hand Pose Estimation (HPE) is crucial to many applications, but conventional
cameras-based CM-HPE methods are completely subject to Line-of-Sight (LoS), as
cameras cannot capture occluded objects. In this paper, we propose to exploit
Radio-Frequency-Vision (RF-vision) capable of bypassing obstacles for achieving
occluded HPE, and we introduce OCHID-Fi as the first RF-HPE method with 3D pose
estimation capability. OCHID-Fi employs wideband RF sensors widely available on
smart devices (e.g., iPhones) to probe 3D human hand pose and extract their
skeletons behind obstacles. To overcome the challenge in labeling RF imaging
given its human incomprehensible nature, OCHID-Fi employs a cross-modality and
cross-domain training process. It uses a pre-trained CM-HPE network and a
synchronized CM/RF dataset, to guide the training of its complex-valued RF-HPE
network under LoS conditions. It further transfers knowledge learned from
labeled LoS domain to unlabeled occluded domain via adversarial learning,
enabling OCHID-Fi to generalize to unseen occluded scenarios. Experimental
results demonstrate the superiority of OCHID-Fi: it achieves comparable
accuracy to CM-HPE under normal conditions while maintaining such accuracy even
in occluded scenarios, with empirical evidence for its generalizability to new
domains.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10147" title="Abstract">arXiv:2308.10147</a> [<a href="/pdf/2308.10147" title="Download PDF">pdf</a>, <a href="/format/2308.10147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ESTextSpotter: Towards Better Scene Text Spotting with Explicit Synergy  in Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Mingxin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+D">Dezhi Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Can Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiang Bai</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Lianwen Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, end-to-end scene text spotting approaches are evolving to
the Transformer-based framework. While previous studies have shown the crucial
importance of the intrinsic synergy between text detection and recognition,
recent advances in Transformer-based methods usually adopt an implicit synergy
strategy with shared query, which can not fully realize the potential of these
two interactive tasks. In this paper, we argue that the explicit synergy
considering distinct characteristics of text detection and recognition can
significantly improve the performance text spotting. To this end, we introduce
a new model named Explicit Synergy-based Text Spotting Transformer framework
(ESTextSpotter), which achieves explicit synergy by modeling discriminative and
interactive features for text detection and recognition within a single
decoder. Specifically, we decompose the conventional shared query into
task-aware queries for text polygon and content, respectively. Through the
decoder with the proposed vision-language communication module, the queries
interact with each other in an explicit manner while preserving discriminative
patterns of text detection and recognition, thus improving performance
significantly. Additionally, we propose a task-aware query initialization
scheme to ensure stable training. Experimental results demonstrate that our
model significantly outperforms previous state-of-the-art methods. Code is
available at https://github.com/mxin262/ESTextSpotter.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10148" title="Abstract">arXiv:2308.10148</a> [<a href="/pdf/2308.10148" title="Download PDF">pdf</a>, <a href="/ps/2308.10148" title="Download PostScript">ps</a>, <a href="/format/2308.10148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy Perceptions and Behaviors of Google Personal Account Holders in  Saudi Arabia
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alashwali%2C+E">Eman Alashwali</a>, 
<a href="/search/cs?searchtype=author&query=Cranor%2C+L+F">Lorrie Faith Cranor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Cryptography and Security (cs.CR); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">While privacy perceptions and behaviors have been investigated in Western
societies, little is known about these issues in non-Western societies. To
bridge this gap, we interviewed 30 Google personal account holders in Saudi
Arabia about their privacy perceptions (awareness, attitudes, preferences, and
concerns) regarding the activity data that Google saves about them, as well as
any steps they take to control Google's collection or use of this data. Our
study focuses on Google's Activity Controls, which enable users to control
whether, and how, Google saves their Web &amp; App Activity, Location History, and
YouTube History. Our results show that although most participants have some
level of awareness about Google's data practices and the Activity Controls,
many have only vague awareness, and the majority have not used the available
controls. When participants viewed their saved activity data, many were
surprised by what had been saved. While many participants find Google's use of
their data to improve the services provided to them acceptable, the majority
find the use of their data for ad purposes unacceptable. We observe that our
Saudi participants exhibit similar trends and patterns in privacy awareness,
attitudes, preferences, concerns, and behaviors to what has been found in
studies in the US. However, our study is not a replication of any of the US
studies, and further research is needed to directly compare US and Saudi
participants. Our results emphasize the need for: (1) improved techniques to
inform users about privacy settings during account sign-up, to remind users
about their settings, and to raise awareness about privacy settings; (2)
improved privacy setting interfaces to reduce the costs that deter many users
from changing the settings; and (3) further research to explore privacy
concerns in non-Western cultures.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10149" title="Abstract">arXiv:2308.10149</a> [<a href="/pdf/2308.10149" title="Download PDF">pdf</a>, <a href="/format/2308.10149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Fairness in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingji Li</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+M">Mengnan Du</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+R">Rui Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Ying Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 2 figures, 101 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have shown powerful performance and development
prospect and are widely deployed in the real world. However, LLMs can capture
social biases from unprocessed training data and propagate the biases to
downstream tasks. Unfair LLM systems have undesirable social impacts and
potential harms. In this paper, we provide a comprehensive review of related
research on fairness in LLMs. First, for medium-scale LLMs, we introduce
evaluation metrics and debiasing methods from the perspectives of intrinsic
bias and extrinsic bias, respectively. Then, for large-scale LLMs, we introduce
recent fairness research, including fairness evaluation, reasons for bias, and
debiasing methods. Finally, we discuss and provide insight on the challenges
and future directions for the development of fairness in LLMs.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10154" title="Abstract">arXiv:2308.10154</a> [<a href="/pdf/2308.10154" title="Download PDF">pdf</a>, <a href="/ps/2308.10154" title="Download PostScript">ps</a>, <a href="/format/2308.10154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource-Adaptive Newton&#x27;s Method for Distributed Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuzhen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+Y">Youming Tao</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zhipeng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dongxiao Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Distributed stochastic optimization methods based on Newton's method offer
significant advantages over first-order methods by leveraging curvature
information for improved performance. However, the practical applicability of
Newton's method is hindered in large-scale and heterogeneous learning
environments due to challenges such as high computation and communication costs
associated with the Hessian matrix, sub-model diversity, staleness in training,
and data heterogeneity. To address these challenges, this paper introduces a
novel and efficient algorithm called RANL, which overcomes the limitations of
Newton's method by employing a simple Hessian initialization and adaptive
assignments of training regions. The algorithm demonstrates impressive
convergence properties, which are rigorously analyzed under standard
assumptions in stochastic optimization. The theoretical analysis establishes
that RANL achieves a linear convergence rate while effectively adapting to
available resources and maintaining high efficiency. Unlike traditional
first-order methods, RANL exhibits remarkable independence from the condition
number of the problem and eliminates the need for complex parameter tuning.
These advantages make RANL a promising approach for distributed stochastic
optimization in practical scenarios.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10155" title="Abstract">arXiv:2308.10155</a> [<a href="/pdf/2308.10155" title="Download PDF">pdf</a>, <a href="/format/2308.10155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unilaterally Aggregated Contrastive Learning with Hierarchical  Augmentation for Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guodong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jie Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+X">Xiuguo Bao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Di Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV'2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Anomaly detection (AD), aiming to find samples that deviate from the training
distribution, is essential in safety-critical applications. Though recent
self-supervised learning based attempts achieve promising results by creating
virtual outliers, their training objectives are less faithful to AD which
requires a concentrated inlier distribution as well as a dispersive outlier
distribution. In this paper, we propose Unilaterally Aggregated Contrastive
Learning with Hierarchical Augmentation (UniCon-HA), taking into account both
the requirements above. Specifically, we explicitly encourage the concentration
of inliers and the dispersion of virtual outliers via supervised and
unsupervised contrastive losses, respectively. Considering that standard
contrastive data augmentation for generating positive views may induce
outliers, we additionally introduce a soft mechanism to re-weight each
augmented inlier according to its deviation from the inlier distribution, to
ensure a purified concentration. Moreover, to prompt a higher concentration,
inspired by curriculum learning, we adopt an easy-to-hard hierarchical
augmentation strategy and perform contrastive aggregation at different depths
of the network based on the strengths of data augmentation. Our method is
evaluated under three AD settings including unlabeled one-class, unlabeled
multi-class, and labeled multi-class, demonstrating its consistent superiority
over other competitors.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10156" title="Abstract">arXiv:2308.10156</a> [<a href="/pdf/2308.10156" title="Download PDF">pdf</a>, <a href="/format/2308.10156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SSMG: Spatial-Semantic Map Guided Diffusion Model for Free-form  Layout-to-Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+C">Chengyou Jia</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+M">Minnan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+Z">Zhuohang Dang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+G">Guang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiaojun Chang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengmeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingdong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite significant progress in Text-to-Image (T2I) generative models, even
lengthy and complex text descriptions still struggle to convey detailed
controls. In contrast, Layout-to-Image (L2I) generation, aiming to generate
realistic and complex scene images from user-specified layouts, has risen to
prominence. However, existing methods transform layout information into tokens
or RGB images for conditional control in the generative process, leading to
insufficient spatial and semantic controllability of individual instances. To
address these limitations, we propose a novel Spatial-Semantic Map Guided
(SSMG) diffusion model that adopts the feature map, derived from the layout, as
guidance. Owing to rich spatial and semantic information encapsulated in
well-designed feature maps, SSMG achieves superior generation quality with
sufficient spatial and semantic controllability compared to previous works.
Additionally, we propose the Relation-Sensitive Attention (RSA) and
Location-Sensitive Attention (LSA) mechanisms. The former aims to model the
relationships among multiple objects within scenes while the latter is designed
to heighten the model's sensitivity to the spatial information embedded in the
guidance. Extensive experiments demonstrate that SSMG achieves highly promising
results, setting a new state-of-the-art across a range of metrics encompassing
fidelity, diversity, and controllability.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10158" title="Abstract">arXiv:2308.10158</a> [<a href="/pdf/2308.10158" title="Download PDF">pdf</a>, <a href="/format/2308.10158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HODN: Disentangling Human-Object Feature for HOI Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+S">Shuman Fang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhiwen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+K">Ke Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jie Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xianming Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+R">Rongrong Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TMM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The task of Human-Object Interaction (HOI) detection is to detect humans and
their interactions with surrounding objects, where transformer-based methods
show dominant advances currently. However, these methods ignore the
relationship among humans, objects, and interactions: 1) human features are
more contributive than object ones to interaction prediction; 2) interactive
information disturbs the detection of objects but helps human detection. In
this paper, we propose a Human and Object Disentangling Network (HODN) to model
the HOI relationships explicitly, where humans and objects are first detected
by two disentangling decoders independently and then processed by an
interaction decoder. Considering that human features are more contributive to
interaction, we propose a Human-Guide Linking method to make sure the
interaction decoder focuses on the human-centric regions with human features as
the positional embeddings. To handle the opposite influences of interactions on
humans and objects, we propose a Stop-Gradient Mechanism to stop interaction
gradients from optimizing the object detection but to allow them to optimize
the human detection. Our proposed method achieves competitive performance on
both the V-COCO and the HICO-Det datasets. It can be combined with existing
methods easily for state-of-the-art results.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10160" title="Abstract">arXiv:2308.10160</a> [<a href="/pdf/2308.10160" title="Download PDF">pdf</a>, <a href="/format/2308.10160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Higher-Order Cheeger Inequality for Partitioning with Buffers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Makarychev%2C+K">Konstantin Makarychev</a>, 
<a href="/search/cs?searchtype=author&query=Makarychev%2C+Y">Yury Makarychev</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+L">Liren Shan</a>, 
<a href="/search/cs?searchtype=author&query=Vijayaraghavan%2C+A">Aravindan Vijayaraghavan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We prove a new generalization of the higher-order Cheeger inequality for
partitioning with buffers. Consider a graph $G=(V,E)$. The buffered expansion
of a set $S \subseteq V$ with a buffer $B \subseteq V \setminus S$ is the edge
expansion of $S$ after removing all the edges from set $S$ to its buffer $B$.
An $\varepsilon$-buffered $k$-partitioning is a partitioning of a graph into
disjoint components $P_i$ and buffers $B_i$, in which the size of buffer $B_i$
for $P_i$ is small relative to the size of $P_i$: $|B_i| \le \varepsilon
|P_i|$. The buffered expansion of a buffered partition is the maximum of
buffered expansions of the $k$ sets $P_i$ with buffers $B_i$. Let
$h^{k,\varepsilon}_G$ be the buffered expansion of the optimal
$\varepsilon$-buffered $k$-partitioning, then for every $\delta&gt;0$,
$$h_G^{k,\varepsilon} \le O_\delta(1) \cdot \Big( \frac{\log k}{
\varepsilon}\Big) \cdot \lambda_{\lfloor (1+\delta) k\rfloor},$$ where
$\lambda_{\lfloor (1+\delta)k\rfloor}$ is the $\lfloor (1+\delta)k\rfloor$-th
smallest eigenvalue of the normalized Laplacian of $G$.
<br />Our inequality is constructive and avoids the ``square-root loss'' that is
present in the standard Cheeger inequalities (even for $k=2$). We also provide
a complementary lower bound, and a novel generalization to the setting with
arbitrary vertex weights and edge costs. Moreover our result implies and
generalizes the standard higher-order Cheeger inequalities and another recent
Cheeger-type inequality by Kwok, Lau, and Lee (2017) involving robust vertex
expansion.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10161" title="Abstract">arXiv:2308.10161</a> [<a href="/pdf/2308.10161" title="Download PDF">pdf</a>, <a href="/format/2308.10161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ThermRad: A Multi-modal Dataset for Robust 3D Object Detection under  Challenging Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Q">Qiao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yihan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures, Proceedings of the IEEE/CVF International Conference on Computer Vision
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Robust 3D object detection in extreme weather and illumination conditions is
a challenging task. While radars and thermal cameras are known for their
resilience to these conditions, few studies have been conducted on
radar-thermal fusion due to the lack of corresponding datasets. To address this
gap, we first present a new multi-modal dataset called ThermRad, which includes
a 3D LiDAR, a 4D radar, an RGB camera and a thermal camera. This dataset is
unique because it includes data from all four sensors in extreme weather
conditions, providing a valuable resource for future research in this area. To
validate the robustness of 4D radars and thermal cameras for 3D object
detection in challenging weather conditions, we propose a new multi-modal
fusion method called RTDF-RCNN, which leverages the complementary strengths of
4D radars and thermal cameras to boost object detection performance. To further
prove the effectiveness of our proposed framework, we re-implement
state-of-the-art (SOTA) 3D detectors on our dataset as benchmarks for
evaluation. Our method achieves significant enhancements in detecting cars,
pedestrians, and cyclists, with improvements of over 7.98%, 24.27%, and 27.15%,
respectively, while achieving comparable results to LiDAR-based approaches. Our
contributions in both the ThermRad dataset and the new multi-modal fusion
method provide a new approach to robust 3D object detection in adverse weather
and illumination conditions. The ThermRad dataset will be released.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10162" title="Abstract">arXiv:2308.10162</a> [<a href="/pdf/2308.10162" title="Download PDF">pdf</a>, <a href="/format/2308.10162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Client Drift in Federated Learning: A Logit Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yunlu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chun-Mei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+M">Mang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+W">Wangmeng Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Ping Li</a>, 
<a href="/search/cs?searchtype=author&query=Goh%2C+R+S+M">Rick Siow Mong Goh</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C+L+P">C. L. Philip Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Federated Learning (FL) enables multiple clients to collaboratively learn in
a distributed way, allowing for privacy protection. However, the real-world
non-IID data will lead to client drift which degrades the performance of FL.
Interestingly, we find that the difference in logits between the local and
global models increases as the model is continuously updated, thus seriously
deteriorating FL performance. This is mainly due to catastrophic forgetting
caused by data heterogeneity between clients. To alleviate this problem, we
propose a new algorithm, named FedCSD, a Class prototype Similarity
Distillation in a federated framework to align the local and global models.
FedCSD does not simply transfer global knowledge to local clients, as an
undertrained global model cannot provide reliable knowledge, i.e., class
similarity information, and its wrong soft labels will mislead the optimization
of local models. Concretely, FedCSD introduces a class prototype similarity
distillation to align the local logits with the refined global logits that are
weighted by the similarity between local logits and the global prototype. To
enhance the quality of global logits, FedCSD adopts an adaptive mask to filter
out the terrible soft labels of the global models, thereby preventing them to
mislead local optimization. Extensive experiments demonstrate the superiority
of our method over the state-of-the-art federated learning approaches in
various heterogeneous settings. The source code will be released.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10166" title="Abstract">arXiv:2308.10166</a> [<a href="/pdf/2308.10166" title="Download PDF">pdf</a>, <a href="/format/2308.10166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cell Spatial Analysis in Crohn&#x27;s Disease: Unveiling Local Cell  Arrangement Pattern with Graph-based Signatures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+S">Shunxing Bao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Sichen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Kolachala%2C+V+L">Vasantha L Kolachala</a>, 
<a href="/search/cs?searchtype=author&query=Remedios%2C+L+W">Lucas W. Remedios</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+Y">Yeonjoo Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yutong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+R">Ruining Deng</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+C">Can Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yike Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Roland%2C+J+T">Joseph T. Roland</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+K+S">Ken S. Lau</a>, 
<a href="/search/cs?searchtype=author&query=Kugathasan%2C+S">Subra Kugathasan</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+P">Peng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+K+T">Keith T. Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Coburn%2C+L+A">Lori A. Coburn</a>, 
<a href="/search/cs?searchtype=author&query=Landman%2C+B+A">Bennett A. Landman</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+Y">Yuankai Huo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to SPIE Medical Imaging. San Diego, CA. February 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Crohn's disease (CD) is a chronic and relapsing inflammatory condition that
affects segments of the gastrointestinal tract. CD activity is determined by
histological findings, particularly the density of neutrophils observed on
Hematoxylin and Eosin stains (H&amp;E) imaging. However, understanding the broader
morphometry and local cell arrangement beyond cell counting and tissue
morphology remains challenging. To address this, we characterize six distinct
cell types from H&amp;E images and develop a novel approach for the local spatial
signature of each cell. Specifically, we create a 10-cell neighborhood matrix,
representing neighboring cell arrangements for each individual cell. Utilizing
t-SNE for non-linear spatial projection in scatter-plot and Kernel Density
Estimation contour-plot formats, our study examines patterns of differences in
the cellular environment associated with the odds ratio of spatial patterns
between active CD and control groups. This analysis is based on data collected
at the two research institutes. The findings reveal heterogeneous
nearest-neighbor patterns, signifying distinct tendencies of cell clustering,
with a particular focus on the rectum region. These variations underscore the
impact of data heterogeneity on cell spatial arrangements in CD patients.
Moreover, the spatial distribution disparities between the two research sites
highlight the significance of collaborative efforts among healthcare
organizations. All research analysis pipeline tools are available at
https://github.com/MASILab/cellNN.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10168" title="Abstract">arXiv:2308.10168</a> [<a href="/pdf/2308.10168" title="Download PDF">pdf</a>, <a href="/format/2308.10168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Head-to-Tail: How Knowledgeable are Large Language Models (LLM)? A.K.A.  Will LLMs Replace Knowledge Graphs?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+K">Kai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y+E">Yifan Ethan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+H">Hanwen Zha</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X+L">Xin Luna Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Since the recent prosperity of Large Language Models (LLMs), there have been
interleaved discussions regarding how to reduce hallucinations from LLM
responses, how to increase the factuality of LLMs, and whether Knowledge Graphs
(KGs), which store the world knowledge in a symbolic form, will be replaced
with LLMs. In this paper, we try to answer these questions from a new angle:
How knowledgeable are LLMs?
<br />To answer this question, we constructed Head-to-Tail, a benchmark that
consists of 18K question-answer (QA) pairs regarding head, torso, and tail
facts in terms of popularity. We designed an automated evaluation method and a
set of metrics that closely approximate the knowledge an LLM confidently
internalizes. Through a comprehensive evaluation of 14 publicly available LLMs,
we show that existing LLMs are still far from being perfect in terms of their
grasp of factual knowledge, especially for facts of torso-to-tail entities.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10169" title="Abstract">arXiv:2308.10169</a> [<a href="/pdf/2308.10169" title="Download PDF">pdf</a>, <a href="/format/2308.10169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Real-time Path Planning with Self-evolving Particle Swarm  Optimization in Dynamic Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xin%2C+J">Jinghao Xin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Ning Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures, 10 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Particle Swarm Optimization (PSO) has demonstrated efficacy in addressing
static path planning problems. Nevertheless, such application on dynamic
scenarios has been severely precluded by PSO's low computational efficiency and
premature convergence downsides. To address these limitations, we proposed a
Tensor Operation Form (TOF) that converts particle-wise manipulations to tensor
operations, thereby enhancing computational efficiency. Harnessing the
computational advantage of TOF, a variant of PSO, designated as Self-Evolving
Particle Swarm Optimization (SEPSO) was developed. The SEPSO is underpinned by
a novel Hierarchical Self-Evolving Framework (HSEF) that enables autonomous
optimization of its own hyper-parameters to evade premature convergence.
Additionally, a Priori Initialization (PI) mechanism and an Auto Truncation
(AT) mechanism that substantially elevates the real-time performance of SEPSO
on dynamic path planning problems were introduced. Comprehensive experiments on
four widely used benchmark optimization functions have been initially conducted
to corroborate the validity of SEPSO. Following this, a dynamic simulation
environment that encompasses moving start/target points and dynamic/static
obstacles was employed to assess the effectiveness of SEPSO on the dynamic path
planning problem. Simulation results exhibit that the proposed SEPSO is capable
of generating superior paths with considerably better real-time performance (67
path planning computations per second in a regular desktop computer) in
contrast to alternative methods. The code of this paper can be accessed here.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10170" title="Abstract">arXiv:2308.10170</a> [<a href="/pdf/2308.10170" title="Download PDF">pdf</a>, <a href="/format/2308.10170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FashionNTM: Multi-turn Fashion Image Retrieval via Cascaded Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pal%2C+A">Anwesan Pal</a>, 
<a href="/search/cs?searchtype=author&query=Wadhwa%2C+S">Sahil Wadhwa</a>, 
<a href="/search/cs?searchtype=author&query=Jaiswal%2C+A">Ayush Jaiswal</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chada%2C+R">Rakesh Chada</a>, 
<a href="/search/cs?searchtype=author&query=Natarajan%2C+P">Pradeep Natarajan</a>, 
<a href="/search/cs?searchtype=author&query=Christensen%2C+H+I">Henrik I. Christensen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted at ICCV-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Multi-turn textual feedback-based fashion image retrieval focuses on a
real-world setting, where users can iteratively provide information to refine
retrieval results until they find an item that fits all their requirements. In
this work, we present a novel memory-based method, called FashionNTM, for such
a multi-turn system. Our framework incorporates a new Cascaded Memory Neural
Turing Machine (CM-NTM) approach for implicit state management, thereby
learning to integrate information across all past turns to retrieve new images,
for a given turn. Unlike vanilla Neural Turing Machine (NTM), our CM-NTM
operates on multiple inputs, which interact with their respective memories via
individual read and write heads, to learn complex relationships. Extensive
evaluation results show that our proposed method outperforms the previous
state-of-the-art algorithm by 50.5%, on Multi-turn FashionIQ -- the only
existing multi-turn fashion dataset currently, in addition to having a relative
improvement of 12.6% on Multi-turn Shoes -- an extension of the single-turn
Shoes dataset that we created in this work. Further analysis of the model in a
real-world interactive setting demonstrates two important capabilities of our
model -- memory retention across turns, and agnosticity to turn order for
non-contradictory feedback. Finally, user study results show that images
retrieved by FashionNTM were favored by 83.1% over other multi-turn models.
Project page: https://sites.google.com/eng.ucsd.edu/fashionntm
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10172" title="Abstract">arXiv:2308.10172</a> [<a href="/pdf/2308.10172" title="Download PDF">pdf</a>, <a href="/format/2308.10172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VLN-PETL: Parameter-Efficient Transfer Learning for Vision-and-Language  Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yanyuan Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qi Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The performance of the Vision-and-Language Navigation~(VLN) tasks has
witnessed rapid progress recently thanks to the use of large pre-trained
vision-and-language models. However, full fine-tuning the pre-trained model for
every downstream VLN task is becoming costly due to the considerable model
size. Recent research hotspot of Parameter-Efficient Transfer Learning (PETL)
shows great potential in efficiently tuning large pre-trained models for the
common CV and NLP tasks, which exploits the most of the representation
knowledge implied in the pre-trained model while only tunes a minimal set of
parameters. However, simply utilizing existing PETL methods for the more
challenging VLN tasks may bring non-trivial degeneration to the performance.
Therefore, we present the first study to explore PETL methods for VLN tasks and
propose a VLN-specific PETL method named VLN-PETL. Specifically, we design two
PETL modules: Historical Interaction Booster (HIB) and Cross-modal Interaction
Booster (CIB). Then we combine these two modules with several existing PETL
methods as the integrated VLN-PETL. Extensive experimental results on four
mainstream VLN tasks (R2R, REVERIE, NDH, RxR) demonstrate the effectiveness of
our proposed VLN-PETL, where VLN-PETL achieves comparable or even better
performance to full fine-tuning and outperforms other PETL methods with
promising margins.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10173" title="Abstract">arXiv:2308.10173</a> [<a href="/pdf/2308.10173" title="Download PDF">pdf</a>, <a href="/format/2308.10173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FoodGPT: A Large Language Model in Food Testing Domain with Incremental  Pre-training and Knowledge Graph Prompt
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zhixiao Qi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yijiong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+M">Meiqi Tu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+J">Junyi Tan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yongfeng Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Currently, the construction of large language models in specific domains is
done by fine-tuning on a base model. Some models also incorporate knowledge
bases without the need for pre-training. This is because the base model already
contains domain-specific knowledge during the pre-training process. We build a
large language model for food testing. Unlike the above approach, a significant
amount of data in this domain exists in Scanning format for domain standard
documents. In addition, there is a large amount of untrained structured
knowledge. Therefore, we introduce an incremental pre-training step to inject
this knowledge into a large language model. In this paper, we propose a method
for handling structured knowledge and scanned documents in incremental
pre-training. To overcome the problem of machine hallucination, we constructe a
knowledge graph to serve as an external knowledge base for supporting retrieval
in the large language model. It is worth mentioning that this paper is a
technical report of our pre-release version, and we will report our specific
experimental data in future versions.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10174" title="Abstract">arXiv:2308.10174</a> [<a href="/pdf/2308.10174" title="Download PDF">pdf</a>, <a href="/format/2308.10174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Interactive Keypoint Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+A">Ailing Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Feng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shilong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruimao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This work proposes an end-to-end neural interactive keypoint detection
framework named Click-Pose, which can significantly reduce more than 10 times
labeling costs of 2D keypoint annotation compared with manual-only annotation.
Click-Pose explores how user feedback can cooperate with a neural keypoint
detector to correct the predicted keypoints in an interactive way for a faster
and more effective annotation process. Specifically, we design the pose error
modeling strategy that inputs the ground truth pose combined with four typical
pose errors into the decoder and trains the model to reconstruct the correct
poses, which enhances the self-correction ability of the model. Then, we attach
an interactive human-feedback loop that allows receiving users' clicks to
correct one or several predicted keypoints and iteratively utilizes the decoder
to update all other keypoints with a minimum number of clicks (NoC) for
efficient annotation. We validate Click-Pose in in-domain, out-of-domain
scenes, and a new task of keypoint adaptation. For annotation, Click-Pose only
needs 1.97 and 6.45 NoC@95 (at precision 95%) on COCO and Human-Art, reducing
31.4% and 36.3% efforts than the SOTA model (ViTPose) with manual correction,
respectively. Besides, without user clicks, Click-Pose surpasses the previous
end-to-end model by 1.4 AP on COCO and 3.0 AP on Human-Art. The code is
available at https://github.com/IDEA-Research/Click-Pose.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10175" title="Abstract">arXiv:2308.10175</a> [<a href="/pdf/2308.10175" title="Download PDF">pdf</a>, <a href="/format/2308.10175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BAVS: Bootstrapping Audio-Visual Segmentation by Integrating Foundation  Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peike Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lincheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dadong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xin Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Given an audio-visual pair, audio-visual segmentation (AVS) aims to locate
sounding sources by predicting pixel-wise maps. Previous methods assume that
each sound component in an audio signal always has a visual counterpart in the
image. However, this assumption overlooks that off-screen sounds and background
noise often contaminate the audio recordings in real-world scenarios. They
impose significant challenges on building a consistent semantic mapping between
audio and visual signals for AVS models and thus impede precise sound
localization. In this work, we propose a two-stage bootstrapping audio-visual
segmentation framework by incorporating multi-modal foundation knowledge. In a
nutshell, our BAVS is designed to eliminate the interference of background
noise or off-screen sounds in segmentation by establishing the audio-visual
correspondences in an explicit manner. In the first stage, we employ a
segmentation model to localize potential sounding objects from visual data
without being affected by contaminated audio signals. Meanwhile, we also
utilize a foundation audio classification model to discern audio semantics.
Considering the audio tags provided by the audio foundation model are noisy,
associating object masks with audio tags is not trivial. Thus, in the second
stage, we develop an audio-visual semantic integration strategy (AVIS) to
localize the authentic-sounding objects. Here, we construct an audio-visual
tree based on the hierarchical correspondence between sounds and object
categories. We then examine the label concurrency between the localized objects
and classified audio tags by tracing the audio-visual tree. With AVIS, we can
effectively segment real-sounding objects. Extensive experiments demonstrate
the superiority of our method on AVS datasets, particularly in scenarios
involving background noise. Our project website is
https://yenanliu.github.io/AVSS.github.io/.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10178" title="Abstract">arXiv:2308.10178</a> [<a href="/pdf/2308.10178" title="Download PDF">pdf</a>, <a href="/format/2308.10178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eventually-Consistent Federated Scheduling for Data Center Workloads
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thiyyakat%2C+M">Meghana Thiyyakat</a>, 
<a href="/search/cs?searchtype=author&query=Kalambur%2C+S">Subramaniam Kalambur</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhary%2C+R">Rishit Chaudhary</a>, 
<a href="/search/cs?searchtype=author&query=Nayak%2C+S+G">Saurav G Nayak</a>, 
<a href="/search/cs?searchtype=author&query=Shetty%2C+A">Adarsh Shetty</a>, 
<a href="/search/cs?searchtype=author&query=Sitaram%2C+D">Dinkar Sitaram</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages. Submitted to Elsevier's Ad Hoc Networks Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Data center schedulers operate at unprecedented scales today to accommodate
the growing demand for computing and storage power. The challenge that
schedulers face is meeting the requirements of scheduling speeds despite the
scale. To do so, most scheduler architectures use parallelism. However, these
architectures consist of multiple parallel scheduling entities that can only
utilize partial knowledge of the data center's state, as maintaining consistent
global knowledge or state would involve considerable communication overhead.
The disadvantage of scheduling without global knowledge is sub-optimal
placements-tasks may be made to wait in queues even though there are resources
available in zones outside the scope of the scheduling entity's state. This
leads to unnecessary queuing overheads and lower resource utilization of the
data center. In this paper, extend our previous work on Megha, a federated
decentralized data center scheduling architecture that uses eventual
consistency. The architecture utilizes both parallelism and an
eventually-consistent global state in each of its scheduling entities to make
fast decisions in a scalable manner. In our work, we compare Megha with 3
scheduling architectures: Sparrow, Eagle, and Pigeon, using simulation. We also
evaluate Megha's prototype on a 123-node cluster and compare its performance
with Pigeon's prototype using cluster traces. The results of our experiments
show that Megha consistently reduces delays in job completion time when
compared to other architectures.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10180" title="Abstract">arXiv:2308.10180</a> [<a href="/pdf/2308.10180" title="Download PDF">pdf</a>, <a href="/format/2308.10180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An IoT Architecture Leveraging Digital Twins: Compromised Node Detection  Scenario
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alanezi%2C+K">Khaled Alanezi</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Shivakant Mishra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Modern IoT (Internet of Things) environments with thousands of low-end and
diverse IoT nodes with complex interactions among them and often deployed in
remote and/or wild locations present some unique challenges that make
traditional node compromise detection services less effective. This paper
presents the design, implementation and evaluation of a fog-based architecture
that utilizes the concept of a digital-twin to detect compromised IoT nodes
exhibiting malicious behaviors by either producing erroneous data and/or being
used to launch network intrusion attacks to hijack other nodes eventually
causing service disruption. By defining a digital twin of an IoT infrastructure
at a fog server, the architecture is focused on monitoring relevant information
to save energy and storage space. The paper presents a prototype implementation
for the architecture utilizing malicious behavior datasets to perform
misbehaving node classification. An extensive accuracy and system performance
evaluation was conducted based on this prototype. Results show good accuracy
and negligible overhead especially when employing deep learning techniques such
as MLP (multilayer perceptron).
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10181" title="Abstract">arXiv:2308.10181</a> [<a href="/pdf/2308.10181" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Optimization of Coupled Power Distribution-Urban  Transportation Network Operations with Autonomous Mobility on Demand Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Han Wang</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+X">Xiaoyuan Xu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yue Chen</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+Z">Zheng Yan</a>, 
<a href="/search/eess?searchtype=author&query=Shahidehpour%2C+M">Mohammad Shahidehpour</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Jiaqi Li</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+S">Shaolun Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Autonomous mobility on demand systems (AMoDS) will significantly affect the
operation of coupled power distribution-urban transportation networks (PTNs) by
the optimal dispatch of electric vehicles (EVs). This paper proposes an
uncertainty method to analyze the operational states of PTNs with AMoDS. First,
a PTN operation framework is designed considering the controllable EVs
dispatched by AMoDS as well as the uncontrollable driving behaviors of other
vehicle users. Then, a bi-level power-traffic flow (PTF) model is proposed to
characterize the interaction of power distribution networks (PDNs) and urban
transportation networks (UTNs). In the upper level, a social optimum model is
established to minimize the operating cost of PDNs and UTNs embedded with
controllable EVs. In the lower level, a stochastic user equilibrium (SUE) model
is established to minimize the operating cost of uncontrollable EVs and
gasoline vehicles (GVs) in UTNs. Finally, a probabilistic PTF analysis method
is developed to evaluate PTN operations under environmental and human
uncertainties. A regional sensitivity analysis method is proposed to identify
the critical uncertainties and quantify the impacts of their distribution
ranges on PTN operations. The effectiveness of the proposed method is verified
by the PTN consisting of a 21-bus PDN and a 20-node UTN.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10185" title="Abstract">arXiv:2308.10185</a> [<a href="/pdf/2308.10185" title="Download PDF">pdf</a>, <a href="/format/2308.10185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ViT-Lens: Towards Omni-modal Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+W">Weixian Lei</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yixiao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Dylan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+K">Kun Yi</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 4 figures and 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Though the success of CLIP-based training recipes in vision-language models,
their scalability to more modalities (e.g., 3D, audio, etc.) is limited to
large-scale data, which is expensive or even inapplicable for rare modalities.
In this paper, we present ViT-Lens that facilitates efficient omni-modal
representation learning by perceiving novel modalities with a pretrained ViT
and aligning to a pre-defined space. Specifically, the modality-specific lens
is tuned to project multimodal signals to the shared embedding space, which are
then processed by a strong ViT that carries pre-trained image knowledge. The
encoded multimodal representations are optimized toward aligning with the
modal-independent space, pre-defined by off-the-shelf foundation models. A
well-trained lens with a ViT backbone has the potential to serve as one of
these foundation models, supervising the learning of subsequent modalities.
ViT-Lens provides a unified solution for representation learning of increasing
modalities with two appealing benefits: (i) Exploiting the pretrained ViT
across tasks and domains effectively with efficient data regime; (ii) Emergent
downstream capabilities of novel modalities are demonstrated due to the
modality alignment space. We evaluate ViT-Lens in the context of 3D as an
initial verification. In zero-shot 3D classification, ViT-Lens achieves
substantial improvements over previous state-of-the-art, showing 52.0% accuracy
on Objaverse-LVIS, 87.4% on ModelNet40, and 60.6% on ScanObjectNN. Furthermore,
we enable zero-shot 3D question-answering by simply integrating the trained 3D
lens into the InstructBLIP model without any adaptation. We will release the
results of ViT-Lens on more modalities in the near future.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10186" title="Abstract">arXiv:2308.10186</a> [<a href="/pdf/2308.10186" title="Download PDF">pdf</a>, <a href="/format/2308.10186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QoS-aware User Association and Transmission Scheduling for  Millimeter-Wave Train-ground Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangfei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yong Niu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xian Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jianwen Ding</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+B">Bo Ai</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zhangdui Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Ning Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">With the development of wireless communication, people have put forward
higher requirements for train-ground communications in the high-speed railway
(HSR) scenarios. With the help of mobile relays (MRs) installed on the roof of
the train, the application of Millimeter-Wave (mm-wave) communication which has
rich spectrum resources to the train-ground communication system can realize
high data rate, so as to meet users' increasing demand for broad-band
multimedia access. Also, full-duplex (FD) technology can theoretically double
the spectral efficiency. In this paper, we formulate the user association and
transmission scheduling problem in the mm-wave train-ground communication
system with MR operating in the FD mode as a nonlinear programming problem. In
order to maximize the system throughput and the number of users meeting quality
of service (QoS) requirements, we propose an algorithm based on coalition game
to solve the challenging NP-hard problem, and also prove the convergence and
Nash-stable structure of the proposed algorithm. Extensive simulation results
demonstrate that the proposed coalition game based algorithm can effectively
improve the system throughput and meet the QoS requirements of as many users as
possible, so that the communication system has a certain QoS awareness.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10187" title="Abstract">arXiv:2308.10187</a> [<a href="/pdf/2308.10187" title="Download PDF">pdf</a>, <a href="/format/2308.10187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spiking-Diffusion: Vector Quantized Discrete Diffusion Model with  Spiking Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingxuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+R">Rui Wen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Spiking neural networks (SNNs) have tremendous potential for energy-efficient
neuromorphic chips due to their binary and event-driven architecture. SNNs have
been primarily used in classification tasks, but limited exploration on image
generation tasks. To fill the gap, we propose a Spiking-Diffusion model, which
is based on the vector quantized discrete diffusion model. First, we develop a
vector quantized variational autoencoder with SNNs (VQ-SVAE) to learn a
discrete latent space for images. With VQ-SVAE, image features are encoded
using both the spike firing rate and postsynaptic potential, and an adaptive
spike generator is designed to restore embedding features in the form of spike
trains. Next, we perform absorbing state diffusion in the discrete latent space
and construct a diffusion image decoder with SNNs to denoise the image. Our
work is the first to build the diffusion model entirely from SNN layers.
Experimental results on MNIST, FMNIST, KMNIST, and Letters demonstrate that
Spiking-Diffusion outperforms the existing SNN-based generation model. We
achieve FIDs of 37.50, 91.98, 59.23 and 67.41 on the above datasets
respectively, with reductions of 58.60\%, 18.75\%, 64.51\%, and 29.75\% in FIDs
compared with the state-of-art work.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10188" title="Abstract">arXiv:2308.10188</a> [<a href="/pdf/2308.10188" title="Download PDF">pdf</a>, <a href="/format/2308.10188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mimicking To Dominate: Imitation Learning Strategies for Success in  Multiagent Competitive Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
The <a href="/search/cs?searchtype=author&query=Bui%2C+V">Viet Bui</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+T">Tien Mai</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+H">Thanh Hong Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Training agents in multi-agent competitive games presents significant
challenges due to their intricate nature. These challenges are exacerbated by
dynamics influenced not only by the environment but also by opponents'
strategies. Existing methods often struggle with slow convergence and
instability. To address this, we harness the potential of imitation learning to
comprehend and anticipate opponents' behavior, aiming to mitigate uncertainties
with respect to the game dynamics. Our key contributions include: (i) a new
multi-agent imitation learning model for predicting next moves of the opponents
-- our model works with hidden opponents' actions and local observations; (ii)
a new multi-agent reinforcement learning algorithm that combines our imitation
learning model and policy training into one single training process; and (iii)
extensive experiments in three challenging game environments, including an
advanced version of the Star-Craft multi-agent challenge (i.e., SMACv2).
Experimental results show that our approach achieves superior performance
compared to existing state-of-the-art multi-agent RL algorithms.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10191" title="Abstract">arXiv:2308.10191</a> [<a href="/pdf/2308.10191" title="Download PDF">pdf</a>, <a href="/format/2308.10191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Offline Pseudo Relevance Feedback for Efficient and Effective  Single-pass Dense Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+X">Xueru Wen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuanang Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Ben He</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Le Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at SIGIR2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Dense retrieval has made significant advancements in information retrieval
(IR) by achieving high levels of effectiveness while maintaining online
efficiency during a single-pass retrieval process. However, the application of
pseudo relevance feedback (PRF) to further enhance retrieval effectiveness
results in a doubling of online latency. To address this challenge, this paper
presents a single-pass dense retrieval framework that shifts the PRF process
offline through the utilization of pre-generated pseudo-queries. As a result,
online retrieval is reduced to a single matching with the pseudo-queries, hence
providing faster online retrieval. The effectiveness of the proposed approach
is evaluated on the standard TREC DL and HARD datasets, and the results
demonstrate its promise. Our code is openly available at
https://github.com/Rosenberg37/OPRF.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10193" title="Abstract">arXiv:2308.10193</a> [<a href="/pdf/2308.10193" title="Download PDF">pdf</a>, <a href="/format/2308.10193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProSpire: Proactive Spatial Prediction of Radio Environment Using Deep  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S">Shamik Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Dongning Guo</a>, 
<a href="/search/cs?searchtype=author&query=Cabric%2C+D">Danijela Cabric</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Spatial prediction of the radio propagation environment of a transmitter can
assist and improve various aspects of wireless networks. The majority of
research in this domain can be categorized as 'reactive' spatial prediction,
where the predictions are made based on a small set of measurements from an
active transmitter whose radio environment is to be predicted. Emerging
spectrum-sharing paradigms would benefit from 'proactive' spatial prediction of
the radio environment, where the spatial predictions must be done for a
transmitter for which no measurement has been collected.
<br />This paper proposes a novel, supervised deep learning-based framework,
ProSpire, that enables spectrum sharing by leveraging the idea of proactive
spatial prediction. We carefully address several challenges in ProSpire, such
as designing a framework that conveniently collects training data for learning,
performing the predictions in a fast manner, enabling operations without an
area map, and ensuring that the predictions do not lead to undesired
interference. ProSpire relies on the crowdsourcing of transmitters and
receivers during their normal operations to address some of the aforementioned
challenges. The core component of ProSpire is a deep learning-based
image-to-image translation method, which we call RSSu-net. We generate several
diverse datasets using ray tracing software and numerically evaluate ProSpire.
Our evaluations show that RSSu-net performs reasonably well in terms of signal
strength prediction, 5 dB mean absolute error, which is comparable to the
average error of other relevant methods. Importantly, due to the merits of
RSSu-net, ProSpire creates proactive boundaries around transmitters such that
they can be activated with 97% probability of not causing interference. In this
regard, the performance of RSSu-net is 19% better than that of other comparable
methods.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10195" title="Abstract">arXiv:2308.10195</a> [<a href="/pdf/2308.10195" title="Download PDF">pdf</a>, <a href="/format/2308.10195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WMFormer++: Nested Transformer for Visible Watermark Removal via Implict  Joint Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huo%2C+D">Dongjian Huo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zehong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hanjing Su</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chaowei Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingyao Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Watermarking serves as a widely adopted approach to safeguard media
copyright. In parallel, the research focus has extended to watermark removal
techniques, offering an adversarial means to enhance watermark robustness and
foster advancements in the watermarking field. Existing watermark removal
methods often rely on UNet architectures with multiple decoder branches -- one
for watermark localization and the other for background image restoration.
These methods involve complex module designs to guide information flow for
respective tasks, which can lead to suboptimal performance and an overly
cumbersome model. To simplify the existing framework, we propose a novel
Transformer-based approach with a unified decoder branch, treating watermark
extraction and background restoration as a single task and allowing thenetwork
to learn information flow between them without artificial design patterns.
Additionally, we utilize nested structures to facilitate multi-scale feature
fusion, forming a parallel ensemble of nested structures that constitute the
UNet. Supervision is applied to UNets with varying depths to facilitate
knowledge learning across all levels. Extensive experiments are conducted on
various challenging benchmarks to validate the effectiveness of our proposed
method. The results demonstrate that our approach achieves state-of-the-art
performance and produces high-quality images.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10196" title="Abstract">arXiv:2308.10196</a> [<a href="/pdf/2308.10196" title="Download PDF">pdf</a>, <a href="/format/2308.10196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blind Face Restoration for Under-Display Camera via Dictionary Guided  Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+J">Jingfan Tan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoxu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Wenhan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xiaocun Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">By hiding the front-facing camera below the display panel, Under-Display
Camera (UDC) provides users with a full-screen experience. However, due to the
characteristics of the display, images taken by UDC suffer from significant
quality degradation. Methods have been proposed to tackle UDC image restoration
and advances have been achieved. There are still no specialized methods and
datasets for restoring UDC face images, which may be the most common problem in
the UDC scene. To this end, considering color filtering, brightness
attenuation, and diffraction in the imaging process of UDC, we propose a
two-stage network UDC Degradation Model Network named UDC-DMNet to synthesize
UDC images by modeling the processes of UDC imaging. Then we use UDC-DMNet and
high-quality face images from FFHQ and CelebA-Test to create UDC face training
datasets FFHQ-P/T and testing datasets CelebA-Test-P/T for UDC face
restoration. We propose a novel dictionary-guided transformer network named
DGFormer. Introducing the facial component dictionary and the characteristics
of the UDC image in the restoration makes DGFormer capable of addressing blind
face restoration in UDC scenarios. Experiments show that our DGFormer and
UDC-DMNet achieve state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10198" title="Abstract">arXiv:2308.10198</a> [<a href="/pdf/2308.10198" title="Download PDF">pdf</a>, <a href="/format/2308.10198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing backwards with Game of Life, part 1: wires and circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salo%2C+V">Ville Salo</a>, 
<a href="/search/cs?searchtype=author&query=T%C3%B6rm%C3%A4%2C+I">Ilkka T&#xf6;rm&#xe4;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 10 figures in main text. 11 pages, 20 figures in appendix. Accompanied by two GitHub repositories containing programs and auxiliary data
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Discrete Mathematics (cs.DM); Dynamical Systems (math.DS)

</div>
<p class="mathjax">Conway's Game of Life is a two-dimensional cellular automaton. As a dynamical
system, it is well-known to be computationally universal, i.e.\ capable of
simulating an arbitrary Turing machine. We show that in a sense taking a single
backwards step of Game of Life is a computationally universal process, by
constructing patterns whose preimage computation encodes an arbitrary
circuit-satisfaction problem, or (equivalently) any tiling problem. As a
corollary, we obtain for example that the set of orphans is coNP-complete,
exhibit a $6210 \times 37800$-periodic configuration that admits a preimage but
no periodic one, and prove that the existence of a preimage for a periodic
point is undecidable. Our constructions were obtained by a combination of
computer searches and manual design.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10199" title="Abstract">arXiv:2308.10199</a> [<a href="/pdf/2308.10199" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning for Artificial Upwelling Energy Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+W">Wei Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The potential of artificial upwelling (AU) as a means of lifting
nutrient-rich bottom water to the surface, stimulating seaweed growth, and
consequently enhancing ocean carbon sequestration, has been gaining increasing
attention in recent years. This has led to the development of the first
solar-powered and air-lifted AU system (AUS) in China. However, efficient
scheduling of air injection systems remains a crucial challenge in operating
AUS, as it holds the potential to significantly improve system efficiency.
Conventional approaches based on rules or models are often impractical due to
the complex and heterogeneous nature of the marine environment and its
associated disturbances. To address this challenge, we propose a novel energy
management approach that utilizes deep reinforcement learning (DRL) algorithm
to develop efficient strategies for operating AUS. Through extensive
simulations, we evaluate the performance of our algorithm and demonstrate its
superior effectiveness over traditional rule-based approaches and other DRL
algorithms in reducing energy wastage while ensuring the stable and efficient
operation of AUS. Our findings suggest that a DRL-based approach offers a
promising way for improving the efficiency of AUS and enhancing the
sustainability of seaweed cultivation and carbon sequestration in the ocean.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10201" title="Abstract">arXiv:2308.10201</a> [<a href="/pdf/2308.10201" title="Download PDF">pdf</a>, <a href="/format/2308.10201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hiding Backdoors within Event Sequence Data via Poisoning Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kovtun%2C+E">Elizaveta Kovtun</a>, 
<a href="/search/cs?searchtype=author&query=Ermilova%2C+A">Alina Ermilova</a>, 
<a href="/search/cs?searchtype=author&query=Berestnev%2C+D">Dmitry Berestnev</a>, 
<a href="/search/cs?searchtype=author&query=Zaytsev%2C+A">Alexey Zaytsev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The financial industry relies on deep learning models for making important
decisions. This adoption brings new danger, as deep black-box models are known
to be vulnerable to adversarial attacks. In computer vision, one can shape the
output during inference by performing an adversarial attack called poisoning
via introducing a backdoor into the model during training. For sequences of
financial transactions of a customer, insertion of a backdoor is harder to
perform, as models operate over a more complex discrete space of sequences, and
systematic checks for insecurities occur. We provide a method to introduce
concealed backdoors, creating vulnerabilities without altering their
functionality for uncontaminated data. To achieve this, we replace a clean
model with a poisoned one that is aware of the availability of a backdoor and
utilize this knowledge. Our most difficult for uncovering attacks include
either additional supervised detection step of poisoned data activated during
the test or well-hidden model weight modifications. The experimental study
provides insights into how these effects vary across different datasets,
architectures, and model components. Alternative methods and baselines, such as
distillation-type regularization, are also explored but found to be less
efficient. Conducted on three open transaction datasets and architectures,
including LSTM, CNN, and Transformer, our findings not only illuminate the
vulnerabilities in contemporary models but also can drive the construction of
more robust systems.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10203" title="Abstract">arXiv:2308.10203</a> [<a href="/pdf/2308.10203" title="Download PDF">pdf</a>, <a href="/format/2308.10203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Soft Decomposed Policy-Critic: Bridging the Gap for Effective Continuous  Control with Discrete RL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yechen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuo Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Discrete reinforcement learning (RL) algorithms have demonstrated exceptional
performance in solving sequential decision tasks with discrete action spaces,
such as Atari games. However, their effectiveness is hindered when applied to
continuous control problems due to the challenge of dimensional explosion. In
this paper, we present the Soft Decomposed Policy-Critic (SDPC) architecture,
which combines soft RL and actor-critic techniques with discrete RL methods to
overcome this limitation. SDPC discretizes each action dimension independently
and employs a shared critic network to maximize the soft $Q$-function. This
novel approach enables SDPC to support two types of policies: decomposed actors
that lead to the Soft Decomposed Actor-Critic (SDAC) algorithm, and decomposed
$Q$-networks that generate Boltzmann soft exploration policies, resulting in
the Soft Decomposed-Critic Q (SDCQ) algorithm. Through extensive experiments,
we demonstrate that our proposed approach outperforms state-of-the-art
continuous RL algorithms in a variety of continuous control tasks, including
Mujoco's Humanoid and Box2d's BipedalWalker. These empirical results validate
the effectiveness of the SDPC architecture in addressing the challenges
associated with continuous control.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10204" title="Abstract">arXiv:2308.10204</a> [<a href="/pdf/2308.10204" title="Download PDF">pdf</a>, <a href="/format/2308.10204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatEDA: A Large Language Model Powered Autonomous Agent for EDA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhuolun He</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xufeng Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Su Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Haisheng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bei Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The integration of a complex set of Electronic Design Automation (EDA) tools
to enhance interoperability is a critical concern for circuit designers. Recent
advancements in large language models (LLMs) have showcased their exceptional
capabilities in natural language processing and comprehension, offering a novel
approach to interfacing with EDA tools. This research paper introduces ChatEDA,
an autonomous agent for EDA empowered by a large language model, AutoMage,
complemented by EDA tools serving as executors. ChatEDA streamlines the design
flow from the Register-Transfer Level (RTL) to the Graphic Data System Version
II (GDSII) by effectively managing task planning, script generation, and task
execution. Through comprehensive experimental evaluations, ChatEDA has
demonstrated its proficiency in handling diverse requirements, and our
fine-tuned AutoMage model has exhibited superior performance compared to GPT-4
and other similar LLMs.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10205" title="Abstract">arXiv:2308.10205</a> [<a href="/pdf/2308.10205" title="Download PDF">pdf</a>, <a href="/format/2308.10205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GeT: Generative Target Structure Debiasing for Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Can Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+G+H">Gim Hee Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Domain adaptation (DA) aims to transfer knowledge from a fully labeled source
to a scarcely labeled or totally unlabeled target under domain shift. Recently,
semi-supervised learning-based (SSL) techniques that leverage pseudo labeling
have been increasingly used in DA. Despite the competitive performance, these
pseudo labeling methods rely heavily on the source domain to generate pseudo
labels for the target domain and therefore still suffer considerably from
source data bias. Moreover, class distribution bias in the target domain is
also often ignored in the pseudo label generation and thus leading to further
deterioration of performance. In this paper, we propose GeT that learns a
non-bias target embedding distribution with high quality pseudo labels.
Specifically, we formulate an online target generative classifier to induce the
target distribution into distinctive Gaussian components weighted by their
class priors to mitigate source data bias and enhance target class
discriminability. We further propose a structure similarity regularization
framework to alleviate target class distribution bias and further improve
target class discriminability. Experimental results show that our proposed GeT
is effective and achieves consistent improvements under various DA settings
with and without class distribution bias. Our code is available at:
https://lulusindazc.github.io/getproject/.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10207" title="Abstract">arXiv:2308.10207</a> [<a href="/pdf/2308.10207" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Affective Digital Twins for Digital Human: Bridging the Gap in  Human-Machine Affective Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+F">Feng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, in Chinese language, 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Chinese Association for Artificial Intelligence, 13(3),
  11-16 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In recent years, metaverse and digital humans have become important research
and industry areas of focus. However, existing digital humans still lack
realistic affective traits, making emotional interaction with humans difficult.
Grounded in the developments of artificial intelligence, human-computer
interaction, virtual reality, and affective computing, this paper proposes the
concept and technical framework of "Affective Digital Twins for Digital Human"
based on the philosophy of digital twin technology. The paper discusses several
key technical issues including affective modeling, affective perception,
affective encoding, and affective expression. Based on this, the paper conducts
a preliminary imagination of the future application prospects of affective
digital twins for digital human, while considering potential problems that may
need to be addressed.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10208" title="Abstract">arXiv:2308.10208</a> [<a href="/pdf/2308.10208" title="Download PDF">pdf</a>, <a href="/format/2308.10208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time Regular Expression Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bernadotte%2C+A">Alexandra Bernadotte</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Computational Complexity (cs.CC); Computer Vision and Pattern Recognition (cs.CV); Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">This paper is devoted to finite state automata, regular expression matching,
pattern recognition, and the exponential blow-up problem, which is the growing
complexity of automata exponentially depending on regular expression length.
This paper presents a theoretical and hardware solution to the exponential
blow-up problem for some complicated classes of regular languages, which caused
severe limitations in Network Intrusion Detection Systems work. The article
supports the solution with theorems on correctness and complexity.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10209" title="Abstract">arXiv:2308.10209</a> [<a href="/pdf/2308.10209" title="Download PDF">pdf</a>, <a href="/format/2308.10209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fairness-aware Competitive Bidding Influence Maximization in Social  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Congcong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingya Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jianxi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yingdan Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Transactions on Computational Social Systems (TCSS), 2023, early access
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Competitive Influence Maximization (CIM) has been studied for years due to
its wide application in many domains. Most current studies primarily focus on
the micro-level optimization by designing policies for one competitor to defeat
its opponents. Furthermore, current studies ignore the fact that many
influential nodes have their own starting prices, which may lead to inefficient
budget allocation. In this paper, we propose a novel Competitive Bidding
Influence Maximization (CBIM) problem, where the competitors allocate budgets
to bid for the seeds attributed to the platform during multiple bidding rounds.
To solve the CBIM problem, we propose a Fairness-aware Multi-agent Competitive
Bidding Influence Maximization (FMCBIM) framework. In this framework, we
present a Multi-agent Bidding Particle Environment (MBE) to model the
competitors' interactions, and design a starting price adjustment mechanism to
model the dynamic bidding environment. Moreover, we put forward a novel
Multi-agent Competitive Bidding Influence Maximization (MCBIM) algorithm to
optimize competitors' bidding policies. Extensive experiments on five datasets
show that our work has good efficiency and effectiveness.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10217" title="Abstract">arXiv:2308.10217</a> [<a href="/pdf/2308.10217" title="Download PDF">pdf</a>, <a href="/format/2308.10217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fault Separation Based on An Excitation Operator with Application to a  Quadrotor UAV
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+S">Sicheng Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+M">Meng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Jia%2C+J">Jindou Jia</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+K">Kexin Guo</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+X">Xiang Yu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Youmin Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+L">Lei Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents an excitation operator based fault separation
architecture for a quadrotor unmanned aerial vehicle (UAV) subject to loss of
effectiveness (LoE) faults, actuator aging, and load uncertainty. The actuator
fault dynamics is deeply excavated, containing the deep coupling information
among the actuator faults, the system states, and control inputs. By explicitly
considering the physical constraints and tracking performance, an excitation
operator and corresponding integrated state observer are designed to estimate
separately actuator fault and load uncertainty. Moreover, a fault separation
maneuver and a safety controller are proposed to ensure the tracking
performance when the excitation operator is injected. Both comparative
simulation and flight experiments have demonstrated the effectiveness of the
proposed scheme while maintaining high levels of tracking performance.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10220" title="Abstract">arXiv:2308.10220</a> [<a href="/pdf/2308.10220" title="Download PDF">pdf</a>, <a href="/format/2308.10220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing and Evaluating Presentation Strategies for Fact-Checked  Content
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hettiachchi%2C+D">Danula Hettiachchi</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+K">Kaixin Ji</a>, 
<a href="/search/cs?searchtype=author&query=Kennedy%2C+J">Jenny Kennedy</a>, 
<a href="/search/cs?searchtype=author&query=McCosker%2C+A">Anthony McCosker</a>, 
<a href="/search/cs?searchtype=author&query=Salim%2C+F+D">Flora Dylis Salim</a>, 
<a href="/search/cs?searchtype=author&query=Sanderson%2C+M">Mark Sanderson</a>, 
<a href="/search/cs?searchtype=author&query=Scholer%2C+F">Falk Scholer</a>, 
<a href="/search/cs?searchtype=author&query=Spina%2C+D">Damiano Spina</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 32nd ACM International Conference on Information and Knowledge Management (CIKM '23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">With the rapid growth of online misinformation, it is crucial to have
reliable fact-checking methods. Recent research on finding check-worthy claims
and automated fact-checking have made significant advancements. However,
limited guidance exists regarding the presentation of fact-checked content to
effectively convey verified information to users. We address this research gap
by exploring the critical design elements in fact-checking reports and
investigating whether credibility and presentation-based design improvements
can enhance users' ability to interpret the report accurately. We co-developed
potential content presentation strategies through a workshop involving
fact-checking professionals, communication experts, and researchers. The
workshop examined the significance and utility of elements such as veracity
indicators and explored the feasibility of incorporating interactive components
for enhanced information disclosure. Building on the workshop outcomes, we
conducted an online experiment involving 76 crowd workers to assess the
efficacy of different design strategies. The results indicate that proposed
strategies significantly improve users' ability to accurately interpret the
verdict of fact-checking articles. Our findings underscore the critical role of
effective presentation of fact reports in addressing the spread of
misinformation. By adopting appropriate design enhancements, the effectiveness
of fact-checking reports can be maximized, enabling users to make informed
judgments.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10226" title="Abstract">arXiv:2308.10226</a> [<a href="/pdf/2308.10226" title="Download PDF">pdf</a>, <a href="/format/2308.10226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning-powered Combinatorial Clock Auction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soumalias%2C+E">Ermis Soumalias</a>, 
<a href="/search/cs?searchtype=author&query=Weissteiner%2C+J">Jakob Weissteiner</a>, 
<a href="/search/cs?searchtype=author&query=Heiss%2C+J">Jakob Heiss</a>, 
<a href="/search/cs?searchtype=author&query=Seuken%2C+S">Sven Seuken</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We study the design of iterative combinatorial auctions (ICAs). The main
challenge in this domain is that the bundle space grows exponentially in the
number of items. To address this, several papers have recently proposed machine
learning (ML)-based preference elicitation algorithms that aim to elicit only
the most important information from bidders. However, from a practical point of
view, the main shortcoming of this prior work is that those designs elicit
bidders' preferences via value queries (i.e., ``What is your value for the
bundle $\{A,B\}$?''). In most real-world ICA domains, value queries are
considered impractical, since they impose an unrealistically high cognitive
burden on bidders, which is why they are not used in practice. In this paper,
we address this shortcoming by designing an ML-powered combinatorial clock
auction that elicits information from the bidders only via demand queries
(i.e., ``At prices $p$, what is your most preferred bundle of items?''). We
make two key technical contributions: First, we present a novel method for
training an ML model on demand queries. Second, based on those trained ML
models, we introduce an efficient method for determining the demand query with
the highest clearing potential, for which we also provide a theoretical
foundation. We experimentally evaluate our ML-based demand query mechanism in
several spectrum auction domains and compare it against the most established
real-world ICA: the combinatorial clock auction (CCA). Our mechanism
significantly outperforms the CCA in terms of efficiency in all domains, it
achieves higher efficiency in a significantly reduced number of rounds, and,
using linear prices, it exhibits vastly higher clearing potential. Thus, with
this paper we bridge the gap between research and practice and propose the
first practical ML-powered ICA.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10227" title="Abstract">arXiv:2308.10227</a> [<a href="/pdf/2308.10227" title="Download PDF">pdf</a>, <a href="/format/2308.10227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To Healthier Ethereum: A Comprehensive and Iterative Smart Contract  Weakness Enumeration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiachi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Mingyuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zewei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+P">Peilin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zibin Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">With the increasing popularity of cryptocurrencies and blockchain technology,
smart contracts have become a prominent feature in developing decentralized
applications. However, these smart contracts are susceptible to vulnerabilities
that hackers can exploit, resulting in significant financial losses. In
response to this growing concern, various initiatives have emerged. Notably,
the SWC vulnerability list played an important role in raising awareness and
understanding of smart contract weaknesses. However, the SWC list lacks
maintenance and has not been updated with new vulnerabilities since 2020. To
address this gap, this paper introduces the Smart Contract Weakness Enumeration
(SWE), a comprehensive and practical vulnerability list up until 2023. We
collect 273 vulnerability descriptions from 86 top conference papers and
journal papers, employing open card sorting techniques to deduplicate and
categorize these descriptions. This process results in the identification of 40
common contract weaknesses, which are further classified into 20 sub-research
fields through thorough discussion and analysis. SWE provides a systematic and
comprehensive list of smart contract vulnerabilities, covering existing and
emerging vulnerabilities in the last few years. Moreover, SWE is a scalable,
continuously iterative program. We propose two update mechanisms for the
maintenance of SWE. Regular updates involve the inclusion of new
vulnerabilities from future top papers, while irregular updates enable
individuals to report new weaknesses for review and potential addition to SWE.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10228" title="Abstract">arXiv:2308.10228</a> [<a href="/pdf/2308.10228" title="Download PDF">pdf</a>, <a href="/format/2308.10228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scene-Driven Exploration and GUI Modeling for Android Apps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lingling Fan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yucheng Su</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boyuan Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Due to the competitive environment, mobile apps are usually produced under
pressure with lots of complicated functionality and UI pages. Therefore, it is
challenging for various roles to design, understand, test, and maintain these
apps. The extracted transition graphs for apps such as ATG, WTG, and STG have a
low transition coverage and coarse-grained granularity, which limits the
existing methods of graphical user interface (GUI) modeling by UI exploration.
To solve these problems, in this paper, we propose SceneDroid, a scene-driven
exploration approach to extracting the GUI scenes dynamically by integrating a
series of novel techniques including smart exploration, state fuzzing, and
indirect launching strategies. We present the GUI scenes as a scene transition
graph (SceneTG) to model the GUI of apps with high transition coverage and
fine? grained granularity. Compared with the existing GUI modeling tools,
SceneDroid has improved by 168.74% in the coverage of transition pairs and
162.42% in scene extraction. Apart from the effectiveness evaluation of
SceneDroid, we also illustrate the future potential of SceneDroid as a
fundamental capability to support app development, reverse engineering, and GUI
regression testing.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10234" title="Abstract">arXiv:2308.10234</a> [<a href="/pdf/2308.10234" title="Download PDF">pdf</a>, <a href="/format/2308.10234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MUSE-Fi: Contactless MUti-person SEnsing Exploiting Near-field Wi-Fi  Channel Variation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jingzhi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tianyue Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongbo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jun Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages. Accepted by ACM MobiCom 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Having been studied for more than a decade, Wi-Fi human sensing still faces a
major challenge in the presence of multiple persons, simply because the limited
bandwidth of Wi-Fi fails to provide a sufficient range resolution to physically
separate multiple subjects. Existing solutions mostly avoid this challenge by
switching to radars with GHz bandwidth, at the cost of cumbersome deployments.
Therefore, could Wi-Fi human sensing handle multiple subjects remains an open
question. This paper presents MUSE-Fi, the first Wi-Fi multi-person sensing
system with physical separability. The principle behind MUSE-Fi is that, given
a Wi-Fi device (e.g., smartphone) very close to a subject, the near-field
channel variation caused by the subject significantly overwhelms variations
caused by other distant subjects. Consequently, focusing on the channel state
information (CSI) carried by the traffic in and out of this device naturally
allows for physically separating multiple subjects. Based on this principle, we
propose three sensing strategies for MUSE-Fi: i) uplink CSI, ii) downlink CSI,
and iii) downlink beamforming feedback, where we specifically tackle signal
recovery from sparse (per-user) traffic under realistic multi-user
communication scenarios. Our extensive evaluations clearly demonstrate that
MUSE-Fi is able to successfully handle multi-person sensing with respect to
three typical applications: respiration monitoring, gesture detection, and
activity recognition.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10236" title="Abstract">arXiv:2308.10236</a> [<a href="/pdf/2308.10236" title="Download PDF">pdf</a>, <a href="/format/2308.10236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedSIS: Federated Split Learning with Intermediate Representation  Sampling for Privacy-preserving Generalized Face Presentation Attack  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alkhunaizi%2C+N">Naif Alkhunaizi</a>, 
<a href="/search/cs?searchtype=author&query=Srivatsan%2C+K">Koushik Srivatsan</a>, 
<a href="/search/cs?searchtype=author&query=Almalik%2C+F">Faris Almalik</a>, 
<a href="/search/cs?searchtype=author&query=Almakky%2C+I">Ibrahim Almakky</a>, 
<a href="/search/cs?searchtype=author&query=Nandakumar%2C+K">Karthik Nandakumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Lack of generalization to unseen domains/attacks is the Achilles heel of most
face presentation attack detection (FacePAD) algorithms. Existing attempts to
enhance the generalizability of FacePAD solutions assume that data from
multiple source domains are available with a single entity to enable
centralized training. In practice, data from different source domains may be
collected by diverse entities, who are often unable to share their data due to
legal and privacy constraints. While collaborative learning paradigms such as
federated learning (FL) can overcome this problem, standard FL methods are
ill-suited for domain generalization because they struggle to surmount the twin
challenges of handling non-iid client data distributions during training and
generalizing to unseen domains during inference. In this work, a novel
framework called Federated Split learning with Intermediate representation
Sampling (FedSIS) is introduced for privacy-preserving domain generalization.
In FedSIS, a hybrid Vision Transformer (ViT) architecture is learned using a
combination of FL and split learning to achieve robustness against statistical
heterogeneity in the client data distributions without any sharing of raw data
(thereby preserving privacy). To further improve generalization to unseen
domains, a novel feature augmentation strategy called intermediate
representation sampling is employed, and discriminative information from
intermediate blocks of a ViT is distilled using a shared adapter network. The
FedSIS approach has been evaluated on two well-known benchmarks for
cross-domain FacePAD to demonstrate that it is possible to achieve
state-of-the-art generalization performance without data sharing. Code:
https://github.com/Naiftt/FedSIS
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10238" title="Abstract">arXiv:2308.10238</a> [<a href="/pdf/2308.10238" title="Download PDF">pdf</a>, <a href="/format/2308.10238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Thompson Sampling for Real-Valued Combinatorial Pure Exploration of  Multi-Armed Bandit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nakamura%2C+S">Shintaro Nakamura</a>, 
<a href="/search/cs?searchtype=author&query=Sugiyama%2C+M">Masashi Sugiyama</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We study the real-valued combinatorial pure exploration of the multi-armed
bandit (R-CPE-MAB) problem. In R-CPE-MAB, a player is given $d$ stochastic
arms, and the reward of each arm $s\in\{1, \ldots, d\}$ follows an unknown
distribution with mean $\mu_s$. In each time step, a player pulls a single arm
and observes its reward. The player's goal is to identify the optimal
\emph{action} $\boldsymbol{\pi}^{*} = \argmax_{\boldsymbol{\pi} \in
\mathcal{A}} \boldsymbol{\mu}^{\top}\boldsymbol{\pi}$ from a finite-sized
real-valued \emph{action set} $\mathcal{A}\subset \mathbb{R}^{d}$ with as few
arm pulls as possible. Previous methods in the R-CPE-MAB assume that the size
of the action set $\mathcal{A}$ is polynomial in $d$. We introduce an algorithm
named the Generalized Thompson Sampling Explore (GenTS-Explore) algorithm,
which is the first algorithm that can work even when the size of the action set
is exponentially large in $d$. We also introduce a novel problem-dependent
sample complexity lower bound of the R-CPE-MAB problem, and show that the
GenTS-Explore algorithm achieves the optimal sample complexity up to a
problem-dependent constant factor.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10239" title="Abstract">arXiv:2308.10239</a> [<a href="/pdf/2308.10239" title="Download PDF">pdf</a>, <a href="/format/2308.10239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Global to Local: Multi-scale Out-of-distribution Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Ji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Lianli Gao</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+B">Bingguang Hao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jingkuan Song</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Hengtao Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Out-of-distribution (OOD) detection aims to detect "unknown" data whose
labels have not been seen during the in-distribution (ID) training process.
Recent progress in representation learning gives rise to distance-based OOD
detection that recognizes inputs as ID/OOD according to their relative
distances to the training data of ID classes. Previous approaches calculate
pairwise distances relying only on global image representations, which can be
sub-optimal as the inevitable background clutter and intra-class variation may
drive image-level representations from the same ID class far apart in a given
representation space. In this work, we overcome this challenge by proposing
Multi-scale OOD DEtection (MODE), a first framework leveraging both global
visual information and local region details of images to maximally benefit OOD
detection. Specifically, we first find that existing models pretrained by
off-the-shelf cross-entropy or contrastive losses are incompetent to capture
valuable local representations for MODE, due to the scale-discrepancy between
the ID training and OOD detection processes. To mitigate this issue and
encourage locally discriminative representations in ID training, we propose
Attention-based Local PropAgation (ALPA), a trainable objective that exploits a
cross-attention mechanism to align and highlight the local regions of the
target objects for pairwise examples. During test-time OOD detection, a
Cross-Scale Decision (CSD) function is further devised on the most
discriminative multi-scale representations to distinguish ID/OOD data more
faithfully. We demonstrate the effectiveness and flexibility of MODE on several
benchmarks -- on average, MODE outperforms the previous state-of-the-art by up
to 19.24% in FPR, 2.77% in AUROC. Code is available at
https://github.com/JimZAI/MODE-OOD.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10240" title="Abstract">arXiv:2308.10240</a> [<a href="/pdf/2308.10240" title="Download PDF">pdf</a>, <a href="/format/2308.10240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generic Attention-model Explainability by Weighted Relevance  Accumulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yiming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+A">Aozhe Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaodan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiawei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Attention-based transformer models have achieved remarkable progress in
multi-modal tasks, such as visual question answering. The explainability of
attention-based methods has recently attracted wide interest as it can explain
the inner changes of attention tokens by accumulating relevancy across
attention layers. Current methods simply update relevancy by equally
accumulating the token relevancy before and after the attention processes.
However, the importance of token values is usually different during relevance
accumulation. In this paper, we propose a weighted relevancy strategy, which
takes the importance of token values into consideration, to reduce distortion
when equally accumulating relevance. To evaluate our method, we propose a
unified CLIP-based two-stage model, named CLIPmapper, to process
Vision-and-Language tasks through CLIP encoder and a following mapper.
CLIPmapper consists of self-attention, cross-attention, single-modality, and
cross-modality attention, thus it is more suitable for evaluating our generic
explainability method. Extensive perturbation tests on visual question
answering and image captioning validate that our explainability method
outperforms existing methods.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10244" title="Abstract">arXiv:2308.10244</a> [<a href="/pdf/2308.10244" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating the acceptance of implementing business intelligence in  organizations: A system dynamics approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maghsoudi%2C+M">Mehrdad Maghsoudi</a>, 
<a href="/search/cs?searchtype=author&query=Nezafati%2C+N">Navid Nezafati</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Telematics and Informatics Reports, Volume 11, 2023, 100070
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">The rise of information technology has transformed the business landscape,
with organizations increasingly relying on information systems to collect and
store vast amounts of data. To stay competitive, businesses must harness this
data to make informed decisions that optimize their actions in response to the
market. Business intelligence (BI) is an approach that enables organizations to
leverage data-driven insights for better decision-making, but implementing BI
comes with its own set of challenges. Accordingly, understanding the key
factors that contribute to successful implementation is crucial.
<br />This study examines the factors affecting the implementation of BI projects
by analyzing the interactions between these factors using system dynamics
modeling. The research draws on interviews with five BI experts and a review of
the background literature to identify effective implementation strategies.
Specifically, the study compares traditional and self-service implementation
approaches and simulates their respective impacts on organizational acceptance
of BI. The results show that the two approaches were equally effective in
generating organizational acceptance until the twenty-fifth month of
implementation, after which the self-service strategy generated significantly
higher levels of acceptance than the traditional strategy. In fact, after 60
months, the self-service approach was associated with a 30% increase in
organizational acceptance over the traditional approach. The paper also
provides recommendations for increasing the acceptance of BI in both
implementation strategies. Overall, this study underscores the importance of
identifying and addressing key factors that impact BI implementation success,
offering practical guidance to organizations seeking to leverage the power of
BI in today's competitive business environment.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10248" title="Abstract">arXiv:2308.10248</a> [<a href="/pdf/2308.10248" title="Download PDF">pdf</a>, <a href="/format/2308.10248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Activation Addition: Steering Language Models Without Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Turner%2C+A">Alex Turner</a>, 
<a href="/search/cs?searchtype=author&query=Thiergart%2C+L">Lisa Thiergart</a>, 
<a href="/search/cs?searchtype=author&query=Udell%2C+D">David Udell</a>, 
<a href="/search/cs?searchtype=author&query=Leech%2C+G">Gavin Leech</a>, 
<a href="/search/cs?searchtype=author&query=Mini%2C+U">Ulisse Mini</a>, 
<a href="/search/cs?searchtype=author&query=MacDiarmid%2C+M">Monte MacDiarmid</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Reliably controlling the behavior of large language models (LLMs) is a
pressing open problem. Existing methods include supervised finetuning,
reinforcement learning from human feedback (RLHF), prompt engineering and
guided decoding. We instead investigate activation engineering: modifying
activations at inference time to predictably alter model behavior. In
particular, we bias the forward pass with an added 'steering vector' implicitly
specified through natural language.
<br />Unlike past work which learned these steering vectors (Subramani, Suresh, and
Peters 2022; Hernandez, Li, and Andreas 2023), our Activation Addition (ActAdd)
method computes them by taking the activation differences that result from
pairs of prompts. We demonstrate ActAdd on GPT-2 on OpenWebText and ConceptNet.
Our inference-time approach yields control over high-level properties of output
and preserves off-target model performance. It involves far less compute and
implementation effort compared to finetuning or RLHF, allows users to provide
natural language specifications, and its overhead scales naturally with model
size.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10249" title="Abstract">arXiv:2308.10249</a> [<a href="/pdf/2308.10249" title="Download PDF">pdf</a>, <a href="/format/2308.10249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Formally Verified Security Monitor for VM-based Confidential  Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ozga%2C+W">Wojciech Ozga</a>, 
<a href="/search/cs?searchtype=author&query=Hunt%2C+G+D+H">Guerney D. H. Hunt</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+M+V">Michael V. Le</a>, 
<a href="/search/cs?searchtype=author&query=Palmer%2C+E+R">Elaine R. Palmer</a>, 
<a href="/search/cs?searchtype=author&query=Shinnar%2C+A">Avraham Shinnar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Confidential computing is becoming a key technology for isolating
high-assurance applications from large amounts of untrusted code typical in
modern systems. However, existing confidential computing technologies cannot
secure the most critical applications, like systems controlling critical
infrastructure, hardware security modules, or aircraft, because they lack
formal verification needed for their certification.
<br />This paper tackles the above problem by introducing a canonical architecture
for virtual machine (VM)-based confidential computing systems. It abstracts
processor-specific components and identifies a minimal set of hardware
primitives required by a trusted security monitor to enforce security
guarantees. This paper makes a step towards formally modeling and proving the
correctness of the security monitor. We present our methodology and demonstrate
the proposed approach based on an example from our model and Rust
implementation of the security monitor for RISC-V.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10252" title="Abstract">arXiv:2308.10252</a> [<a href="/pdf/2308.10252" title="Download PDF">pdf</a>, <a href="/format/2308.10252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LMTuner: An user-friendly and highly-integrable Training Framework for  fine-tuning Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weng%2C+Y">Yixuan Weng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+H">Huanxuan Liao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shizhu He</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shengping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the burgeoning development in the realm of large language models (LLMs),
the demand for efficient incremental training tailored to specific industries
and domains continues to increase. Currently, the predominantly employed
frameworks lack modular design, it often takes a lot of coding work to
kickstart the training of LLM. To address this, we present "LMTuner", a highly
usable, integrable, and scalable system for training LLMs expeditiously and
with minimal user-input. LMTuner comprises three main modules - the
Interaction, Training, and Inference Modules. We advocate that LMTuner's
usability and integrality alleviate the complexities in training large language
models. Remarkably, even a novice user could commence training large language
models within five minutes. Furthermore, it integrates DeepSpeed frameworks and
supports Efficient Fine-Tuning methodologies like Low Rank Adaptation (LoRA),
Quantized LoRA (QLoRA), etc., enabling the training of language models scaling
from 300M to a whopping 130B parameters using a single server. The LMTuner's
homepage (https://wengsyx.github.io/LMTuner/)and screencast video
(https://youtu.be/nsXmWOmN3rE) are now publicly available.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10253" title="Abstract">arXiv:2308.10253</a> [<a href="/pdf/2308.10253" title="Download PDF">pdf</a>, <a href="/format/2308.10253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StableLLaVA: Enhanced Visual Instruction Tuning with Synthesized  Image-Dialogue Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanda Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Gang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhibin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+B">Bin Fu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guosheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chunhua Shen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Ling Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yunchao Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://github.com/icoz69/StableLLAVA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">The remarkable multimodal capabilities demonstrated by OpenAI's GPT-4 have
sparked significant interest in the development of multimodal Large Language
Models (LLMs). A primary research objective of such models is to align visual
and textual modalities effectively while comprehending human instructions.
Current methodologies often rely on annotations derived from benchmark datasets
to construct image-dialogue datasets for training purposes, akin to instruction
tuning in LLMs. However, these datasets often exhibit domain bias, potentially
constraining the generative capabilities of the models. In an effort to
mitigate these limitations, we propose a novel data collection methodology that
synchronously synthesizes images and dialogues for visual instruction tuning.
This approach harnesses the power of generative models, marrying the abilities
of ChatGPT and text-to-image generative models to yield a diverse and
controllable dataset with varied image content. This not only provides greater
flexibility compared to existing methodologies but also significantly enhances
several model capabilities. Our research includes comprehensive experiments
conducted on various datasets using the open-source LLAVA model as a testbed
for our proposed pipeline. Our results underscore marked enhancements across
more than ten commonly assessed capabilities,
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10255" title="Abstract">arXiv:2308.10255</a> [<a href="/pdf/2308.10255" title="Download PDF">pdf</a>, <a href="/ps/2308.10255" title="Download PostScript">ps</a>, <a href="/format/2308.10255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Synthesizing Datasets for IEEE 802.1 Time-sensitive Networking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ergen%C3%A7%2C+D">Do&#x11f;analp Ergen&#xe7;</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%BClb%C3%BCl%2C+N+S">Nuref&#x15f;an Sertba&#x15f; B&#xfc;lb&#xfc;l</a>, 
<a href="/search/cs?searchtype=author&query=Maile%2C+L">Lisa Maile</a>, 
<a href="/search/cs?searchtype=author&query=Arestova%2C+A">Anna Arestova</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+M">Mathias Fischer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">IEEE 802.1 Time-sensitive Networking (TSN) protocols have recently been
proposed to replace legacy networking technologies across different
mission-critical systems (MCSs). Design, configuration, and maintenance of TSN
within MCSs require advanced methods to tackle the highly complex and
interconnected nature of those systems. Accordingly, artificial intelligence
(AI) and machine learning (ML) models are the most prominent enablers to
develop such methods. However, they usually require a significant amount of
data for model training, which is not easily accessible. This short paper aims
to recapitulate the need for TSN datasets to flourish research on AI/ML-based
techniques for TSN systems. Moreover, it analyzes the main requirements and
alternative designs to build a TSN platform to synthesize realistic datasets.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10257" title="Abstract">arXiv:2308.10257</a> [<a href="/pdf/2308.10257" title="Download PDF">pdf</a>, <a href="/format/2308.10257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Make-It-4D: Synthesizing a Consistent Long-Term Dynamic Scene Video from  a Single Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Liao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Huiqiang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Juewen Peng</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+K">Ke Xian</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhiguo Cao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guosheng Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by ACM MM'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We study the problem of synthesizing a long-term dynamic video from only a
single image. This is challenging since it requires consistent visual content
movements given large camera motions. Existing methods either hallucinate
inconsistent perpetual views or struggle with long camera trajectories. To
address these issues, it is essential to estimate the underlying 4D (including
3D geometry and scene motion) and fill in the occluded regions. To this end, we
present Make-It-4D, a novel method that can generate a consistent long-term
dynamic video from a single image. On the one hand, we utilize layered depth
images (LDIs) to represent a scene, and they are then unprojected to form a
feature point cloud. To animate the visual content, the feature point cloud is
displaced based on the scene flow derived from motion estimation and the
corresponding camera pose. Such 4D representation enables our method to
maintain the global consistency of the generated dynamic video. On the other
hand, we fill in the occluded regions by using a pretrained diffusion model to
inpaint and outpaint the input image. This enables our method to work under
large camera motions. Benefiting from our design, our method can be
training-free which saves a significant amount of training time. Experimental
results demonstrate the effectiveness of our approach, which showcases
compelling rendering results.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10260" title="Abstract">arXiv:2308.10260</a> [<a href="/pdf/2308.10260" title="Download PDF">pdf</a>, <a href="/format/2308.10260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hand Dominance and Congruence for Wrist-worn Haptics using Custom  Voice-Coil Actuation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adeyemi%2C+A">Ayoade Adeyemi</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+U">Umit Sen</a>, 
<a href="/search/cs?searchtype=author&query=Ercan%2C+S+M">Samet Mert Ercan</a>, 
<a href="/search/cs?searchtype=author&query=Sarac%2C+M">Mine Sarac</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">During virtual interactions, rendering haptic feedback on a remote location
(like the wrist) instead of the fingertips freeing users' hands from mechanical
devices. This allows for real interactions while still providing information
regarding the mechanical properties of virtual objects. In this paper, we
present CoWrHap -- a novel wrist-worn haptic device with custom-made voice coil
actuation to render force feedback. Then, we investigate the impact of asking
participants to use their dominant or non-dominant hand for virtual
interactions and the best mapping between the active hand and the wrist
receiving the haptic feedback, which can be defined as hand-wrist congruence
through a user experiment based on a stiffness discrimination task. Our results
show that participants performed the tasks (i) better with non-congruent
mapping but reported better experiences with congruent mapping, and (ii) with
no statistical difference in terms of hand dominance but reported better user
experience and enjoyment using their dominant hands. This study indicates that
participants can perceive mechanical properties via haptic feedback provided
through CoWrHap.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10261" title="Abstract">arXiv:2308.10261</a> [<a href="/pdf/2308.10261" title="Download PDF">pdf</a>, <a href="/format/2308.10261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Good Are Large Language Models at Out-of-Distribution Detection?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+L">Liming Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zexin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yujie Feng</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+L">Lei Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiao-Ming Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Out-of-distribution (OOD) detection plays a vital role in enhancing the
reliability of machine learning (ML) models. The emergence of large language
models (LLMs) has catalyzed a paradigm shift within the ML community,
showcasing their exceptional capabilities across diverse natural language
processing tasks. While existing research has probed OOD detection with smaller
encoder-based Transformers like BERT and RoBERTa, the stark differences in
scales, pre-training objectives, and inference paradigms call into question the
applicability of these findings to LLMs. This paper embarks on a pioneering
empirical investigation of OOD detection in the domain of LLMs, focusing on
LLaMA series ranging from 7B to 65B in size. We thoroughly evaluate
commonly-used OOD detectors, scrutinizing their performance in both zero-grad
and fine-tuning scenarios. Notably, we alter previous discriminative
in-distribution fine-tuning into generative fine-tuning, aligning the
pre-training objective of LLMs with downstream tasks. Our findings unveil that
a simple cosine distance OOD detector demonstrates superior efficacy,
outperforming other OOD detectors. We provide an intriguing explanation for
this phenomenon by highlighting the isotropic nature of the embedding spaces of
LLMs, which distinctly contrasts with the anisotropic property observed in
smaller BERT family models. The new insight enhances our understanding of how
LLMs detect OOD data, thereby enhancing their adaptability and reliability in
dynamic environments.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10262" title="Abstract">arXiv:2308.10262</a> [<a href="/pdf/2308.10262" title="Download PDF">pdf</a>, <a href="/format/2308.10262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Disentangled Representation with Mutual Information  Maximization for Real-Time UAV Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xucheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiangyang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Hengzhou Ye</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuiwang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Efficiency has been a critical problem in UAV tracking due to limitations in
computation resources, battery capacity, and unmanned aerial vehicle maximum
load. Although discriminative correlation filters (DCF)-based trackers prevail
in this field for their favorable efficiency, some recently proposed
lightweight deep learning (DL)-based trackers using model compression
demonstrated quite remarkable CPU efficiency as well as precision.
Unfortunately, the model compression methods utilized by these works, though
simple, are still unable to achieve satisfying tracking precision with higher
compression rates. This paper aims to exploit disentangled representation
learning with mutual information maximization (DR-MIM) to further improve
DL-based trackers' precision and efficiency for UAV tracking. The proposed
disentangled representation separates the feature into an identity-related and
an identity-unrelated features. Only the latter is used, which enhances the
effectiveness of the feature representation for subsequent classification and
regression tasks. Extensive experiments on four UAV benchmarks, including
UAV123@10fps, DTB70, UAVDT and VisDrone2018, show that our DR-MIM tracker
significantly outperforms state-of-the-art UAV tracking methods.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10263" title="Abstract">arXiv:2308.10263</a> [<a href="/pdf/2308.10263" title="Download PDF">pdf</a>, <a href="/format/2308.10263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaled-up Discovery of Latent Concepts in Deep NLP Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hawasly%2C+M">Majd Hawasly</a>, 
<a href="/search/cs?searchtype=author&query=Dalvi%2C+F">Fahim Dalvi</a>, 
<a href="/search/cs?searchtype=author&query=Durrani%2C+N">Nadir Durrani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Pre-trained language models (pLMs) learn intricate patterns and contextual
dependencies via unsupervised learning on vast text data, driving breakthroughs
across NLP tasks. Despite these achievements, these models remain black boxes,
necessitating research into understanding their decision-making processes.
Recent studies explore representation analysis by clustering latent spaces
within pre-trained models. However, these approaches are limited in terms of
scalability and the scope of interpretation because of high computation costs
of clustering algorithms. This study focuses on comparing clustering algorithms
for the purpose of scaling encoded concept discovery of representations from
pLMs. Specifically, we compare three algorithms in their capacity to unveil the
encoded concepts through their alignment to human-defined ontologies:
Agglomerative Hierarchical Clustering, Leaders Algorithm, and K-Means
Clustering. Our results show that K-Means has the potential to scale to very
large datasets, allowing rich latent concept discovery, both on the word and
phrase level.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10265" title="Abstract">arXiv:2308.10265</a> [<a href="/pdf/2308.10265" title="Download PDF">pdf</a>, <a href="/format/2308.10265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Age of Information in a Multisource Ber/Geo/1/1 Preemptive Queueing  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianci Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhengchuan Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">This work studies the information freshness of the vehicle-to-infrastructure
status updating in Internet of vehicles, which is modeled as a multi-source
Ber/Geo/1/1 preemptive queueing system with heterogeneous service time. We pay
attention to both the distribution and average of AoI. To fully track the
per-source AoI evolution, a Markov two-dimensional (2D) age process is
introduced. The first element of the 2D age process stands for the
instantaneous per-source AoI, while the second represents whether an update of
the concerned source is being served and its current age. A complete framework
and detailed analyses on the per-source AoI are presented based on the
Markovity of the 2D age process. By studying the state transition
probabilities, stationary equations, and stationary distribution of the 2D age
process, analytical expressions of the probability mass function and average of
per-source AoI are derived. Numerical results validate the accuracy of the
theoretical analyses.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10268" title="Abstract">arXiv:2308.10268</a> [<a href="/pdf/2308.10268" title="Download PDF">pdf</a>, <a href="/format/2308.10268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> False Data Injection Attacks in Smart Grids: State of the Art and Way  Forward
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Irfan%2C+M">Muhammad Irfan</a>, 
<a href="/search/cs?searchtype=author&query=Sadighian%2C+A">Alireza Sadighian</a>, 
<a href="/search/cs?searchtype=author&query=Tanveer%2C+A">Adeen Tanveer</a>, 
<a href="/search/cs?searchtype=author&query=Al-Naimi%2C+S+J">Shaikha J. Al-Naimi</a>, 
<a href="/search/cs?searchtype=author&query=Oligeri%2C+G">Gabriele Oligeri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In the recent years cyberattacks to smart grids are becoming more frequent
Among the many malicious activities that can be launched against smart grids
False Data Injection FDI attacks have raised significant concerns from both
academia and industry FDI attacks can affect the internal state estimation
processcritical for smart grid monitoring and controlthus being able to bypass
conventional Bad Data Detection BDD methods Hence prompt detection and precise
localization of FDI attacks is becomming of paramount importance to ensure
smart grids security and safety Several papers recently started to study and
analyze this topic from different perspectives and address existing challenges
Datadriven techniques and mathematical modelings are the major ingredients of
the proposed approaches The primary objective of this work is to provide a
systematic review and insights into FDI attacks joint detection and
localization approaches considering that other surveys mainly concentrated on
the detection aspects without detailed coverage of localization aspects For
this purpose we select and inspect more than forty major research contributions
while conducting a detailed analysis of their methodology and objectives in
relation to the FDI attacks detection and localization We provide our key
findings of the identified papers according to different criteria such as
employed FDI attacks localization techniques utilized evaluation scenarios
investigated FDI attack types application scenarios adopted methodologies and
the use of additional data Finally we discuss open issues and future research
directions
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10269" title="Abstract">arXiv:2308.10269</a> [<a href="/pdf/2308.10269" title="Download PDF">pdf</a>, <a href="/format/2308.10269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Reduction Strategy for Non Line of Sight Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shim%2C+H">Hyunbo Shim</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+I">In Cho</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+D">Daekyu Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S+J">Seon Joo Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">This paper presents a novel optimization-based method for non-line-of-sight
(NLOS) imaging that aims to reconstruct hidden scenes under various setups. Our
method is built upon the observation that photons returning from each point in
hidden volumes can be independently computed if the interactions between hidden
surfaces are trivially ignored. We model the generalized light propagation
function to accurately represent the transients as a linear combination of
these functions. Moreover, our proposed method includes a domain reduction
procedure to exclude empty areas of the hidden volumes from the set of
propagation functions, thereby improving computational efficiency of the
optimization. We demonstrate the effectiveness of the method in various NLOS
scenarios, including non-planar relay wall, sparse scanning patterns, confocal
and non-confocal, and surface geometry reconstruction. Experiments conducted on
both synthetic and real-world data clearly support the superiority and the
efficiency of the proposed method in general NLOS scenarios.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10273" title="Abstract">arXiv:2308.10273</a> [<a href="/pdf/2308.10273" title="Download PDF">pdf</a>, <a href="/format/2308.10273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Turning Waste into Wealth: Leveraging Low-Quality Samples for Enhancing  Continuous Conditional Generative Adversarial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+X">Xin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zuheng Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Continuous Conditional Generative Adversarial Networks (CcGANs) enable
generative modeling conditional on continuous scalar variables (termed
regression labels). However, they can produce subpar fake images due to limited
training data. Although Negative Data Augmentation (NDA) effectively enhances
unconditional and class-conditional GANs by introducing anomalies into real
training images, guiding the GANs away from low-quality outputs, its impact on
CcGANs is limited, as it fails to replicate negative samples that may occur
during the CcGAN sampling. We present a novel NDA approach called Dual-NDA
specifically tailored for CcGANs to address this problem. Dual-NDA employs two
types of negative samples: visually unrealistic images generated from a
pre-trained CcGAN and label-inconsistent images created by manipulating real
images' labels. Leveraging these negative samples, we introduce a novel
discriminator objective alongside a modified CcGAN training algorithm.
Empirical analysis on UTKFace and Steering Angle reveals that Dual-NDA
consistently enhances the visual fidelity and label consistency of fake images
generated by CcGANs, exhibiting a substantial performance gain over the vanilla
NDA. Moreover, by applying Dual-NDA, CcGANs demonstrate a remarkable
advancement beyond the capabilities of state-of-the-art conditional GANs and
diffusion models, establishing a new pinnacle of performance.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10276" title="Abstract">arXiv:2308.10276</a> [<a href="/pdf/2308.10276" title="Download PDF">pdf</a>, <a href="/format/2308.10276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimalist Traffic Prediction: Linear Layer Is All You Need
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+W">Wenying Duan</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+H">Hong Rao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaoxi He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Traffic prediction is essential for the progression of Intelligent
Transportation Systems (ITS) and the vision of smart cities. While
Spatial-Temporal Graph Neural Networks (STGNNs) have shown promise in this
domain by leveraging Graph Neural Networks (GNNs) integrated with either RNNs
or Transformers, they present challenges such as computational complexity,
gradient issues, and resource-intensiveness. This paper addresses these
challenges, advocating for three main solutions: a node-embedding approach,
time series decomposition, and periodicity learning. We introduce STLinear, a
minimalist model architecture designed for optimized efficiency and
performance. Unlike traditional STGNNs, STlinear operates fully locally,
avoiding inter-node data exchanges, and relies exclusively on linear layers,
drastically cutting computational demands. Our empirical studies on real-world
datasets confirm STLinear's prowess, matching or exceeding the accuracy of
leading STGNNs, but with significantly reduced complexity and computation
overhead (more than 95% reduction in MACs per epoch compared to
state-of-the-art STGNN baseline published in 2023). In summary, STLinear
emerges as a potent, efficient alternative to conventional STGNNs, with
profound implications for the future of ITS and smart city initiatives.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10278" title="Abstract">arXiv:2308.10278</a> [<a href="/pdf/2308.10278" title="Download PDF">pdf</a>, <a href="/format/2308.10278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CharacterChat: Learning towards Conversational AI with Personalized  Social Support
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tu%2C+Q">Quan Tu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chuanqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinpeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanran Li</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+S">Shuo Shang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongyan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+R">Rui Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In our modern, fast-paced, and interconnected world, the importance of mental
well-being has grown into a matter of great urgency. However, traditional
methods such as Emotional Support Conversations (ESC) face challenges in
effectively addressing a diverse range of individual personalities. In
response, we introduce the Social Support Conversation (S2Conv) framework. It
comprises a series of support agents and the interpersonal matching mechanism,
linking individuals with persona-compatible virtual supporters. Utilizing
persona decomposition based on the MBTI (Myers-Briggs Type Indicator), we have
created the MBTI-1024 Bank, a group that of virtual characters with distinct
profiles. Through improved role-playing prompts with behavior preset and
dynamic memory, we facilitate the development of the MBTI-S2Conv dataset, which
contains conversations between the characters in the MBTI-1024 Bank. Building
upon these foundations, we present CharacterChat, a comprehensive S2Conv
system, which includes a conversational model driven by personas and memories,
along with an interpersonal matching plugin model that dispatches the optimal
supporters from the MBTI-1024 Bank for individuals with specific personas.
Empirical results indicate the remarkable efficacy of CharacterChat in
providing personalized social support and highlight the substantial advantages
derived from interpersonal matching. The source code is available in
\url{https://github.com/morecry/CharacterChat}.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10279" title="Abstract">arXiv:2308.10279</a> [<a href="/pdf/2308.10279" title="Download PDF">pdf</a>, <a href="/format/2308.10279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPFL: Simultaneously Learning Global and Personalized Feature  Information for Personalized Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+Y">Yang Hua</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+T">Tao Song</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Z">Zhengui Xue</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+R">Ruhui Ma</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jian Cao</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+H">Haibing Guan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated Learning (FL) is popular for its privacy-preserving and
collaborative learning capabilities. Recently, personalized FL (pFL) has
received attention for its ability to address statistical heterogeneity and
achieve personalization in FL. However, from the perspective of feature
extraction, most existing pFL methods only focus on extracting global or
personalized feature information during local training, which fails to meet the
collaborative learning and personalization goals of pFL. To address this, we
propose a new pFL method, named GPFL, to simultaneously learn global and
personalized feature information on each client. We conduct extensive
experiments on six datasets in three statistically heterogeneous settings and
show the superiority of GPFL over ten state-of-the-art methods regarding
effectiveness, scalability, fairness, stability, and privacy. Besides, GPFL
mitigates overfitting and outperforms the baselines by up to 8.99% in accuracy.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10280" title="Abstract">arXiv:2308.10280</a> [<a href="/pdf/2308.10280" title="Download PDF">pdf</a>, <a href="/format/2308.10280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MacFormer: Map-Agent Coupled Transformer for Real-time and Robust  Trajectory Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chen Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hangning Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Huadong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhigang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Ziyao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Boyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Shaojie Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Robotics and Automation Letters. 8 Pages, 9 Figures, 9 Tables. Video: <a href="https://www.youtube.com/watch?v=XY388iI6sPQ">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Predicting the future behavior of agents is a fundamental task in autonomous
vehicle domains. Accurate prediction relies on comprehending the surrounding
map, which significantly regularizes agent behaviors. However, existing methods
have limitations in exploiting the map and exhibit a strong dependence on
historical trajectories, which yield unsatisfactory prediction performance and
robustness. Additionally, their heavy network architectures impede real-time
applications. To tackle these problems, we propose Map-Agent Coupled
Transformer (MacFormer) for real-time and robust trajectory prediction. Our
framework explicitly incorporates map constraints into the network via two
carefully designed modules named coupled map and reference extractor. A novel
multi-task optimization strategy (MTOS) is presented to enhance learning of
topology and rule constraints. We also devise bilateral query scheme in context
fusion for a more efficient and lightweight network. We evaluated our approach
on Argoverse 1, Argoverse 2, and nuScenes real-world benchmarks, where it all
achieved state-of-the-art performance with the lowest inference latency and
smallest model size. Experiments also demonstrate that our framework is
resilient to imperfect tracklet inputs. Furthermore, we show that by combining
with our proposed strategies, classical models outperform their baselines,
further validating the versatility of our framework.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10282" title="Abstract">arXiv:2308.10282</a> [<a href="/pdf/2308.10282" title="Download PDF">pdf</a>, <a href="/format/2308.10282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Spatiotemporal Traffic Prediction through Urban Human Activity  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Sumin Han</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+Y">Youngjun Park</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Minji Lee</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+J">Jisun An</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongman Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CIKM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Traffic prediction is one of the key elements to ensure the safety and
convenience of citizens. Existing traffic prediction models primarily focus on
deep learning architectures to capture spatial and temporal correlation. They
often overlook the underlying nature of traffic. Specifically, the sensor
networks in most traffic datasets do not accurately represent the actual road
network exploited by vehicles, failing to provide insights into the traffic
patterns in urban activities. To overcome these limitations, we propose an
improved traffic prediction method based on graph convolution deep learning
algorithms. We leverage human activity frequency data from National Household
Travel Survey to enhance the inference capability of a causal relationship
between activity and traffic patterns. Despite making minimal modifications to
the conventional graph convolutional recurrent networks and graph convolutional
transformer architectures, our approach achieves state-of-the-art performance
without introducing excessive computational overhead.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10283" title="Abstract">arXiv:2308.10283</a> [<a href="/pdf/2308.10283" title="Download PDF">pdf</a>, <a href="/format/2308.10283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Uncertainty-Guided Model Selection for Data-Driven PDE  Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thanasutives%2C+P">Pongpisit Thanasutives</a>, 
<a href="/search/cs?searchtype=author&query=Morita%2C+T">Takashi Morita</a>, 
<a href="/search/cs?searchtype=author&query=Numao%2C+M">Masayuki Numao</a>, 
<a href="/search/cs?searchtype=author&query=Fukui%2C+K">Ken-ichi Fukui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">We propose a new parameter-adaptive uncertainty-penalized Bayesian
information criterion (UBIC) to prioritize the parsimonious partial
differential equation (PDE) that sufficiently governs noisy spatial-temporal
observed data with few reliable terms. Since the naive use of the BIC for model
selection has been known to yield an undesirable overfitted PDE, the UBIC
penalizes the found PDE not only by its complexity but also the quantified
uncertainty, derived from the model supports' coefficient of variation in a
probabilistic view. We also introduce physics-informed neural network learning
as a simulation-based approach to further validate the selected PDE flexibly
against the other discovered PDE. Numerical results affirm the successful
application of the UBIC in identifying the true governing PDE. Additionally, we
reveal an interesting effect of denoising the observed data on improving the
trade-off between the BIC score and model complexity. Code is available at
https://github.com/Pongpisit-Thanasutives/UBIC.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10284" title="Abstract">arXiv:2308.10284</a> [<a href="/pdf/2308.10284" title="Download PDF">pdf</a>, <a href="/format/2308.10284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Few-shot Coordination: Revisiting Ad-hoc Teamplay Challenge In  the Game of Hanabi
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nekoei%2C+H">Hadi Nekoei</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xutong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Rajendran%2C+J">Janarthanan Rajendran</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Miao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chandar%2C+S">Sarath Chandar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Cooperative Multi-agent Reinforcement Learning (MARL) algorithms with
Zero-Shot Coordination (ZSC) have gained significant attention in recent years.
ZSC refers to the ability of agents to coordinate zero-shot (without additional
interaction experience) with independently trained agents. While ZSC is crucial
for cooperative MARL agents, it might not be possible for complex tasks and
changing environments. Agents also need to adapt and improve their performance
with minimal interaction with other agents. In this work, we show empirically
that state-of-the-art ZSC algorithms have poor performance when paired with
agents trained with different learning methods, and they require millions of
interaction samples to adapt to these new partners. To investigate this issue,
we formally defined a framework based on a popular cooperative multi-agent game
called Hanabi to evaluate the adaptability of MARL methods. In particular, we
created a diverse set of pre-trained agents and defined a new metric called
adaptation regret that measures the agent's ability to efficiently adapt and
improve its coordination performance when paired with some held-out pool of
partners on top of its ZSC performance. After evaluating several SOTA
algorithms using our framework, our experiments reveal that naive Independent
Q-Learning (IQL) agents in most cases adapt as quickly as the SOTA ZSC
algorithm Off-Belief Learning (OBL). This finding raises an interesting
research question: How to design MARL algorithms with high ZSC performance and
capability of fast adaptation to unseen partners. As a first step, we studied
the role of different hyper-parameters and design choices on the adaptability
of current MARL algorithms. Our experiments show that two categories of
hyper-parameters controlling the training data diversity and optimization
process have a significant impact on the adaptability of Hanabi agents.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10285" title="Abstract">arXiv:2308.10285</a> [<a href="/pdf/2308.10285" title="Download PDF">pdf</a>, <a href="/format/2308.10285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DomainDrop: Suppressing Domain-Sensitive Channels for Domain  Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jintao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+L">Lei Qi</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yinghuan Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV2023. The code is available at <a href="https://github.com/lingeringlight/DomainDrop">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep Neural Networks have exhibited considerable success in various visual
tasks. However, when applied to unseen test datasets, state-of-the-art models
often suffer performance degradation due to domain shifts. In this paper, we
introduce a novel approach for domain generalization from a novel perspective
of enhancing the robustness of channels in feature maps to domain shifts. We
observe that models trained on source domains contain a substantial number of
channels that exhibit unstable activations across different domains, which are
inclined to capture domain-specific features and behave abnormally when exposed
to unseen target domains. To address the issue, we propose a DomainDrop
framework to continuously enhance the channel robustness to domain shifts,
where a domain discriminator is used to identify and drop unstable channels in
feature maps of each network layer during forward propagation. We theoretically
prove that our framework could effectively lower the generalization bound.
Extensive experiments on several benchmarks indicate that our framework
achieves state-of-the-art performance compared to other competing methods. Our
code is available at https://github.com/lingeringlight/DomainDrop.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10287" title="Abstract">arXiv:2308.10287</a> [<a href="/pdf/2308.10287" title="Download PDF">pdf</a>, <a href="/format/2308.10287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient-VRNet: An Exquisite Fusion Network for Riverway Panoptic  Perception based on Asymmetric Fair Fusion of Vision and 4D mmWave Radar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+R">Runwei Guan</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+S">Shanliang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaohui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Man%2C+K+L">Ka Lok Man</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yong Yue</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+J">Jeremy Smith</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+E+G">Eng Gee Lim</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yutao Yue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Panoptic perception is essential to unmanned surface vehicles (USVs) for
autonomous navigation. The current panoptic perception scheme is mainly based
on vision only, that is, object detection and semantic segmentation are
performed simultaneously based on camera sensors. Nevertheless, the fusion of
camera and radar sensors is regarded as a promising method which could
substitute pure vision methods, but almost all works focus on object detection
only. Therefore, how to maximize and subtly fuse the features of vision and
radar to improve both detection and segmentation is a challenge. In this paper,
we focus on riverway panoptic perception based on USVs, which is a considerably
unexplored field compared with road panoptic perception. We propose
Efficient-VRNet, a model based on Contextual Clustering (CoC) and the
asymmetric fusion of vision and 4D mmWave radar, which treats both vision and
radar modalities fairly. Efficient-VRNet can simultaneously perform detection
and segmentation of riverway objects and drivable area segmentation.
Furthermore, we adopt an uncertainty-based panoptic perception training
strategy to train Efficient-VRNet. In the experiments, our Efficient-VRNet
achieves better performances on our collected dataset than other uni-modal
models, especially in adverse weather and environment with poor lighting
conditions. Our code and models are available at
\url{https://github.com/GuanRunwei/Efficient-VRNet}.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10289" title="Abstract">arXiv:2308.10289</a> [<a href="/pdf/2308.10289" title="Download PDF">pdf</a>, <a href="/format/2308.10289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameter Estimation-Based States Reconstruction of Uncertain Linear  Systems with Overparameterization and Unknown Additive Perturbations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Glushchenko%2C+A">Anton Glushchenko</a>, 
<a href="/search/eess?searchtype=author&query=Lastochkin%2C+K">Konstantin Lastochkin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures. arXiv admin note: text overlap with <a href="/abs/2302.13705">arXiv:2302.13705</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The problem of state reconstruction is considered for uncertain linear
time-invariant systems with overparametrization, arbitrary state-space matrices
and unknown additive perturbation described by an exosystem. A novel adaptive
observer is proposed to solve it, which, unlike known solutions,
simultaneously: (i) reconstructs the physical state of the original system
rather than the virtual state of its observer canonical form, (ii) ensures
exponential convergence of the reconstruction error to zero when the condition
of finite excitation is satisfied, (iii) is applicable to systems, in which
mentioned perturbation is generated by an exosystem with fully uncertain
constant parameters. The proposed solution uses a recently published
parametrization of uncertain linear systems with unknown additive
perturbations, the dynamic regressor extension and mixing procedure, as well as
a method of physical states reconstruction developed by the authors. Detailed
analysis for stability and convergence has been provided along with simulation
results to validate the results of the theoretical analysis.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10292" title="Abstract">arXiv:2308.10292</a> [<a href="/pdf/2308.10292" title="Download PDF">pdf</a>, <a href="/format/2308.10292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An interpretable deep learning method for bearing fault diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Bray%2C+A+M">Austin M. Bray</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zimmerman%2C+A+T">Andrew T. Zimmerman</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongyi Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deep learning (DL) has gained popularity in recent years as an effective tool
for classifying the current health and predicting the future of industrial
equipment. However, most DL models have black-box components with an underlying
structure that is too complex to be interpreted and explained to human users.
This presents significant challenges when deploying these models for
safety-critical maintenance tasks, where non-technical personnel often need to
have complete trust in the recommendations these models give. To address these
challenges, we utilize a convolutional neural network (CNN) with
Gradient-weighted Class Activation Mapping (Grad-CAM) activation map
visualizations to form an interpretable DL method for classifying bearing
faults. After the model training process, we apply Grad-CAM to identify a
training sample's feature importance and to form a library of diagnosis
knowledge (or health library) containing training samples with annotated
feature maps. During the model evaluation process, the proposed approach
retrieves prediction basis samples from the health library according to the
similarity of the feature importance. The proposed method can be easily applied
to any CNN model without modifying the model architecture, and our experimental
results show that this method can select prediction basis samples that are
intuitively and physically meaningful, improving the model's trustworthiness
for human users.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10293" title="Abstract">arXiv:2308.10293</a> [<a href="/pdf/2308.10293" title="Download PDF">pdf</a>, <a href="/format/2308.10293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privileged Anatomical and Protocol Discrimination in Trackerless 3D  Ultrasound Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qi Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Ziyi Shen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qian Li</a>, 
<a href="/search/cs?searchtype=author&query=Barratt%2C+D+C">Dean C. Barratt</a>, 
<a href="/search/cs?searchtype=author&query=Dowrick%2C+T">Thomas Dowrick</a>, 
<a href="/search/cs?searchtype=author&query=Clarkson%2C+M+J">Matthew J. Clarkson</a>, 
<a href="/search/cs?searchtype=author&query=Vercauteren%2C+T">Tom Vercauteren</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yipeng Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Advances in Simplifying Medical UltraSound (ASMUS) workshop at MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Three-dimensional (3D) freehand ultrasound (US) reconstruction without using
any additional external tracking device has seen recent advances with deep
neural networks (DNNs). In this paper, we first investigated two identified
contributing factors of the learned inter-frame correlation that enable the
DNN-based reconstruction: anatomy and protocol. We propose to incorporate the
ability to represent these two factors - readily available during training - as
the privileged information to improve existing DNN-based methods. This is
implemented in a new multi-task method, where the anatomical and protocol
discrimination are used as auxiliary tasks. We further develop a differentiable
network architecture to optimise the branching location of these auxiliary
tasks, which controls the ratio between shared and task-specific network
parameters, for maximising the benefits from the two auxiliary tasks.
Experimental results, on a dataset with 38 forearms of 19 volunteers acquired
with 6 different scanning protocols, show that 1) both anatomical and protocol
variances are enabling factors for DNN-based US reconstruction; 2) learning how
to discriminate different subjects (anatomical variance) and predefined types
of scanning paths (protocol variance) both significantly improve frame
prediction accuracy, volume reconstruction overlap, accumulated tracking error
and final drift, using the proposed algorithm.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10294" title="Abstract">arXiv:2308.10294</a> [<a href="/pdf/2308.10294" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A review of SolarWinds attack on Orion platform using persistent threat  agents anf techniques for gaining unauthorized access
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kruti%2C+A">Antigoni Kruti</a>, 
<a href="/search/cs?searchtype=author&query=Butt%2C+U">Usman Butt</a>, 
<a href="/search/cs?searchtype=author&query=Sulaiman%2C+R">Rejwan Sulaiman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">This paper of work examines the SolarWinds attack, designed on Orion Platform
security incident. It analyses the persistent threats agents and potential
technical attack techniques to gain unauthorized access. In 2020 SolarWinds
attack indicates an initial breach disclosure on Orion Platform software by
malware distribution on IT and government organizations such as Homeland
Security, Microsoft and Intel associated with supply chains leaks consequences
from small loopholes in security systems. Hackers increased the number of
infected company and businesses networks during the supply-chain attack,
hackers were capable to propagate the attack by using a VMware exploit. On the
special way they started to target command injections, privilege escalations,
and use after free platforms of VMware. In this way, they gained access to
Virtual Machines and in the east way pivot other servers. This literature
review aim to analyze the security gap regarding to SolarWinds incident on
Orion Platform, the impact on industry and financial sectors involving the
elements of incident response plan. Therefore, this research paper ensures
specifications of proper solutions for possible defense security systems by
analyzing a SolarWinds attack case study via system evaluation and monitoring.
It concludes with necessary remediation actions on cyber hygiene
countermeasures, common vulnerabilities and exposure analysis and solutions.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10297" title="Abstract">arXiv:2308.10297</a> [<a href="/pdf/2308.10297" title="Download PDF">pdf</a>, <a href="/format/2308.10297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DomainAdaptor: A Novel Approach to Test-time Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+L">Lei Qi</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yinghuan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">To deal with the domain shift between training and test samples, current
methods have primarily focused on learning generalizable features during
training and ignore the specificity of unseen samples that are also critical
during the test. In this paper, we investigate a more challenging task that
aims to adapt a trained CNN model to unseen domains during the test. To
maximumly mine the information in the test data, we propose a unified method
called DomainAdaptor for the test-time adaptation, which consists of an
AdaMixBN module and a Generalized Entropy Minimization (GEM) loss.
Specifically, AdaMixBN addresses the domain shift by adaptively fusing training
and test statistics in the normalization layer via a dynamic mixture
coefficient and a statistic transformation operation. To further enhance the
adaptation ability of AdaMixBN, we design a GEM loss that extends the Entropy
Minimization loss to better exploit the information in the test data. Extensive
experiments show that DomainAdaptor consistently outperforms the
state-of-the-art methods on four benchmarks. Furthermore, our method brings
more remarkable improvement against existing methods on the few-data unseen
domain. The code is available at https://github.com/koncle/DomainAdaptor.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10298" title="Abstract">arXiv:2308.10298</a> [<a href="/pdf/2308.10298" title="Download PDF">pdf</a>, <a href="/ps/2308.10298" title="Download PostScript">ps</a>, <a href="/format/2308.10298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Arena: A Learning-based Synchronization Scheme for Hierarchical  Federated Learning--Technical Report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+T">Tianyu Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Y">Yufeng Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peng Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jingcai Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yuanqing Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Federated learning (FL) enables collaborative model training among
distributed devices without data sharing, but existing FL suffers from poor
scalability because of global model synchronization. To address this issue,
hierarchical federated learning (HFL) has been recently proposed to let edge
servers aggregate models of devices in proximity, while synchronizing via the
cloud periodically. However, a critical open challenge about how to make a good
synchronization scheme (when devices and edges should be synchronized) is still
unsolved. Devices are heterogeneous in computing and communication capability,
and their data could be non-IID. No existing work can well synchronize various
roles (\textit{e.g.}, devices and edges) in HFL to guarantee high learning
efficiency and accuracy. In this paper, we propose a learning-based
synchronization scheme for HFL systems. By collecting data such as edge models,
CPU usage, communication time, \textit{etc}., we design a deep reinforcement
learning-based approach to decide the frequencies of cloud aggregation and edge
aggregation, respectively. The proposed scheme well considers device
heterogeneity, non-IID data and device mobility, to maximize the training model
accuracy while minimizing the energy overhead. Meanwhile, the convergence bound
of the proposed synchronization scheme has been analyzed. And we build an HFL
testbed and conduct the experiments with real data obtained from Raspberry Pi
and Alibaba Cloud. Extensive experiments under various settings are conducted
to confirm the effectiveness of \textit{Arena}.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10299" title="Abstract">arXiv:2308.10299</a> [<a href="/pdf/2308.10299" title="Download PDF">pdf</a>, <a href="/format/2308.10299" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Adversarial Transferability by Block Shuffle and Rotation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kunyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xuanran He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenxuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaosen Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Adversarial examples mislead deep neural networks with imperceptible
perturbations and have brought significant threats to deep learning. An
important aspect is their transferability, which refers to their ability to
deceive other models, thus enabling attacks in the black-box setting. Though
various methods have been proposed to boost transferability, the performance
still falls short compared with white-box attacks. In this work, we observe
that existing input transformation based attacks, one of the mainstream
transfer-based attacks, result in different attention heatmaps on various
models, which might limit the transferability. We also find that breaking the
intrinsic relation of the image can disrupt the attention heatmap of the
original image. Based on this finding, we propose a novel input transformation
based attack called block shuffle and rotation (BSR). Specifically, BSR splits
the input image into several blocks, then randomly shuffles and rotates these
blocks to construct a set of new images for gradient calculation. Empirical
evaluations on the ImageNet dataset demonstrate that BSR could achieve
significantly better transferability than the existing input transformation
based methods under single-model and ensemble-model settings. Combining BSR
with the current input transformation method can further improve the
transferability, which significantly outperforms the state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10301" title="Abstract">arXiv:2308.10301</a> [<a href="/pdf/2308.10301" title="Download PDF">pdf</a>, <a href="/format/2308.10301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Algorithms for Integer Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qizheng He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">The integer complexity $f(n)$ of a positive integer $n$ is defined as the
minimum number of 1's needed to represent $n$, using additions, multiplications
and parentheses. We present two simple and faster algorithms for computing the
integer complexity:
<br />1) A near-optimal $O(N\mathop{\mathrm{polylog}} N)$-time algorithm for
computing the integer complexity of all $n\leq N$, improving the previous
$O(N^{1.223})$ one [Cordwell et al., 2017].
<br />2) The first sublinear-time algorithm for computing the integer complexity of
a single $n$, with running time $O(n^{0.6154})$. The previous algorithms for
computing a single $f(n)$ require computing all $f(1),\dots,f(n)$.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10304" title="Abstract">arXiv:2308.10304</a> [<a href="/pdf/2308.10304" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Economic Policy Uncertainty: A Review on Applications and Measurement  Methods with Focus on Text Mining Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaveh-Yazdy%2C+F">Fatemeh Kaveh-Yazdy</a>, 
<a href="/search/cs?searchtype=author&query=Zarifzadeh%2C+S">Sajjad Zarifzadeh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> JEL Classification: C53, C38, A13, O38, H50
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Economic Policy Uncertainty (EPU) represents the uncertainty realized by the
investors during economic policy alterations. EPU is a critical indicator in
economic studies to predict future investments, the unemployment rate, and
recessions. EPU values can be estimated based on financial parameters directly
or implied uncertainty indirectly using the text mining methods. Although EPU
is a well-studied topic within the economy, the methods utilized to measure it
are understudied. In this article, we define the EPU briefly and review the
methods used to measure the EPU, and survey the areas influenced by the changes
in EPU level. We divide the EPU measurement methods into three major groups
with respect to their input data. Examples of each group of methods are
enlisted, and the pros and cons of the groups are discussed. Among the EPU
measures, text mining-based ones are dominantly studied. These methods measure
the realized uncertainty by taking into account the uncertainty represented in
the news and publicly available sources of financial information. Finally, we
survey the research areas that rely on measuring the EPU index with the hope
that studying the impacts of uncertainty would attract further attention of
researchers from various research fields. In addition, we propose a list of
future research approaches focusing on measuring EPU using textual material.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10305" title="Abstract">arXiv:2308.10305</a> [<a href="/pdf/2308.10305" title="Download PDF">pdf</a>, <a href="/format/2308.10305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Co-Evolution of Pose and Mesh for 3D Human Body Estimation from Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yingxuan You</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Ti Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+R">Runwei Ding</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xia Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023. Project page: <a href="https://kasvii.github.io/PMCE">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite significant progress in single image-based 3D human mesh recovery,
accurately and smoothly recovering 3D human motion from a video remains
challenging. Existing video-based methods generally recover human mesh by
estimating the complex pose and shape parameters from coupled image features,
whose high complexity and low representation ability often result in
inconsistent pose motion and limited shape patterns. To alleviate this issue,
we introduce 3D pose as the intermediary and propose a Pose and Mesh
Co-Evolution network (PMCE) that decouples this task into two parts: 1)
video-based 3D human pose estimation and 2) mesh vertices regression from the
estimated 3D pose and temporal image feature. Specifically, we propose a
two-stream encoder that estimates mid-frame 3D pose and extracts a temporal
image feature from the input image sequence. In addition, we design a
co-evolution decoder that performs pose and mesh interactions with the
image-guided Adaptive Layer Normalization (AdaLN) to make pose and mesh fit the
human body shape. Extensive experiments demonstrate that the proposed PMCE
outperforms previous state-of-the-art methods in terms of both per-frame
accuracy and temporal consistency on three benchmark datasets: 3DPW, Human3.6M,
and MPI-INF-3DHP. Our code is available at https://github.com/kasvii/PMCE.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10306" title="Abstract">arXiv:2308.10306</a> [<a href="/pdf/2308.10306" title="Download PDF">pdf</a>, <a href="/format/2308.10306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Omnidirectional Information Gathering for Knowledge Transfer-based  Audio-Visual Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenguan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Si Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Audio-visual navigation is an audio-targeted wayfinding task where a robot
agent is entailed to travel a never-before-seen 3D environment towards the
sounding source. In this article, we present ORAN, an omnidirectional
audio-visual navigator based on cross-task navigation skill transfer. In
particular, ORAN sharpens its two basic abilities for a such challenging task,
namely wayfinding and audio-visual information gathering. First, ORAN is
trained with a confidence-aware cross-task policy distillation (CCPD) strategy.
CCPD transfers the fundamental, point-to-point wayfinding skill that is well
trained on the large-scale PointGoal task to ORAN, so as to help ORAN to better
master audio-visual navigation with far fewer training samples. To improve the
efficiency of knowledge transfer and address the domain gap, CCPD is made to be
adaptive to the decision confidence of the teacher policy. Second, ORAN is
equipped with an omnidirectional information gathering (OIG) mechanism, i.e.,
gleaning visual-acoustic observations from different directions before
decision-making. As a result, ORAN yields more robust navigation behaviour.
Taking CCPD and OIG together, ORAN significantly outperforms previous
competitors. After the model ensemble, we got 1st in Soundspaces Challenge
2022, improving SPL and SR by 53% and 35% relatively.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10307" title="Abstract">arXiv:2308.10307</a> [<a href="/pdf/2308.10307" title="Download PDF">pdf</a>, <a href="/format/2308.10307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UAV 3-D path planning based on MOEA/D with adaptive areal weight  adjustment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yougang Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Keyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Guohua Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages,11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Unmanned aerial vehicles (UAVs) are desirable platforms for time-efficient
and cost-effective task execution. 3-D path planning is a key challenge for
task decision-making. This paper proposes an improved multi-objective
evolutionary algorithm based on decomposition (MOEA/D) with an adaptive areal
weight adjustment (AAWA) strategy to make a tradeoff between the total flight
path length and the terrain threat. AAWA is designed to improve the diversity
of the solutions. More specifically, AAWA first removes a crowded individual
and its weight vector from the current population and then adds a sparse
individual from the external elite population to the current population. To
enable the newly-added individual to evolve towards the sparser area of the
population in the objective space, its weight vector is constructed by the
objective function value of its neighbors. The effectiveness of MOEA/D-AAWA is
validated in twenty synthetic scenarios with different number of obstacles and
four realistic scenarios in comparison with other three classical methods.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10308" title="Abstract">arXiv:2308.10308</a> [<a href="/pdf/2308.10308" title="Download PDF">pdf</a>, <a href="/format/2308.10308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representation Disparity-aware Distillation for 3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanjing Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Sheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Mingbao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jihao Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Baochang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xianbin Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV2023. arXiv admin note: text overlap with <a href="/abs/2205.15156">arXiv:2205.15156</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we focus on developing knowledge distillation (KD) for compact
3D detectors. We observe that off-the-shelf KD methods manifest their efficacy
only when the teacher model and student counterpart share similar intermediate
feature representations. This might explain why they are less effective in
building extreme-compact 3D detectors where significant representation
disparity arises due primarily to the intrinsic sparsity and irregularity in 3D
point clouds. This paper presents a novel representation disparity-aware
distillation (RDD) method to address the representation disparity issue and
reduce performance gap between compact students and over-parameterized
teachers. This is accomplished by building our RDD from an innovative
perspective of information bottleneck (IB), which can effectively minimize the
disparity of proposal region pairs from student and teacher in features and
logits. Extensive experiments are performed to demonstrate the superiority of
our RDD over existing KD methods. For example, our RDD increases mAP of
CP-Voxel-S to 57.1% on nuScenes dataset, which even surpasses teacher
performance while taking up only 42% FLOPs.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10310" title="Abstract">arXiv:2308.10310</a> [<a href="/pdf/2308.10310" title="Download PDF">pdf</a>, <a href="/format/2308.10310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DVGaze: Dual-View Gaze Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yihua Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+F">Feng Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Gaze estimation methods estimate gaze from facial appearance with a single
camera. However, due to the limited view of a single camera, the captured
facial appearance cannot provide complete facial information and thus
complicate the gaze estimation problem. Recently, camera devices are rapidly
updated. Dual cameras are affordable for users and have been integrated in many
devices. This development suggests that we can further improve gaze estimation
performance with dual-view gaze estimation. In this paper, we propose a
dual-view gaze estimation network (DV-Gaze). DV-Gaze estimates dual-view gaze
directions from a pair of images. We first propose a dual-view interactive
convolution (DIC) block in DV-Gaze. DIC blocks exchange dual-view information
during convolution in multiple feature scales. It fuses dual-view features
along epipolar lines and compensates for the original feature with the fused
feature. We further propose a dual-view transformer to estimate gaze from
dual-view features. Camera poses are encoded to indicate the position
information in the transformer. We also consider the geometric relation between
dual-view gaze directions and propose a dual-view gaze consistency loss for
DV-Gaze. DV-Gaze achieves state-of-the-art performance on ETH-XGaze and EVE
datasets. Our experiments also prove the potential of dual-view gaze
estimation. We release codes in https://github.com/yihuacheng/DVGaze.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10311" title="Abstract">arXiv:2308.10311</a> [<a href="/pdf/2308.10311" title="Download PDF">pdf</a>, <a href="/format/2308.10311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> I/O Burst Prediction for HPC Clusters using Darshan Logs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saeedizade%2C+E">Ehsan Saeedizade</a>, 
<a href="/search/cs?searchtype=author&query=Taheri%2C+R">Roya Taheri</a>, 
<a href="/search/cs?searchtype=author&query=Arslan%2C+E">Engin Arslan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 11 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Understanding cluster-wide I/O patterns of large-scale HPC clusters is
essential to minimize the occurrence and impact of I/O interference. Yet, most
previous work in this area focused on monitoring and predicting task and
node-level I/O burst events. This paper analyzes Darshan reports from three
supercomputers to extract system-level read and write I/O rates in five minutes
intervals. We observe significant (over 100x) fluctuations in read and write
I/O rates in all three clusters. We then train machine learning models to
estimate the occurrence of system-level I/O bursts 5 - 120 minutes ahead.
Evaluation results show that we can predict I/O bursts with more than 90%
accuracy (F-1 score) five minutes ahead and more than 87% accuracy two hours
ahead. We also show that the ML models attain more than 70% accuracy when
estimating the degree of the I/O burst. We believe that high-accuracy
predictions of I/O bursts can be used in multiple ways, such as postponing
delay-tolerant I/O operations (e.g., checkpointing), pausing nonessential
applications (e.g., file system scrubbers), and devising I/O-aware job
scheduling methods. To validate this claim, we simulated a burst-aware job
scheduler that can postpone the start time of applications to avoid I/O bursts.
We show that the burst-aware job scheduling can lead to an up to 5x decrease in
application runtime.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10312" title="Abstract">arXiv:2308.10312</a> [<a href="/pdf/2308.10312" title="Download PDF">pdf</a>, <a href="/format/2308.10312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demystifying the Performance of Data Transfers in High-Performance  Research Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Saeedizade%2C+E">Ehsan Saeedizade</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+B">Bing Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Arslan%2C+E">Engin Arslan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">High-speed research networks are built to meet the ever-increasing needs of
data-intensive distributed workflows. However, data transfers in these networks
often fail to attain the promised transfer rates for several reasons, including
I/O and network interference, server misconfigurations, and network anomalies.
Although understanding the root causes of performance issues is critical to
mitigating them and increasing the utilization of expensive network
infrastructures, there is currently no available mechanism to monitor data
transfers in these networks. In this paper, we present a scalable, end-to-end
monitoring framework to gather and store key performance metrics for file
transfers to shed light on the performance of transfers. The evaluation results
show that the proposed framework can monitor up to 400 transfers per host and
more than 40, 000 transfers in total while collecting performance statistics at
one-second precision. We also introduce a heuristic method to automatically
process the gathered performance metrics and identify the root causes of
performance anomalies with an F-score of 87 - 98%.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10315" title="Abstract">arXiv:2308.10315</a> [<a href="/pdf/2308.10315" title="Download PDF">pdf</a>, <a href="/format/2308.10315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Adversarial Robustness of Masked Autoencoders via Test-time  Frequency-domain Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qidong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xiaoyi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dongdong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yinpeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Lu Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+G">Gang Hua</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+N">Nenghai Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we investigate the adversarial robustness of vision
transformers that are equipped with BERT pretraining (\eg, BEiT, MAE). A
surprising observation is that MAE has significantly worse adversarial
robustness than other BERT pretraining methods. This observation drives us to
rethink the basic differences between these BERT pretraining methods and how
these differences affect the robustness against adversarial perturbations. Our
empirical analysis reveals that the adversarial robustness of BERT pretraining
is highly related to the reconstruction target, \ie, predicting the raw pixels
of masked image patches will degrade more adversarial robustness of the model
than predicting the semantic context, since it guides the model to concentrate
more on medium-/high-frequency components of images. Based on our analysis, we
provide a simple yet effective way to boost the adversarial robustness of MAE.
The basic idea is using the dataset-extracted domain knowledge to occupy the
medium-/high-frequency of images, thus narrowing the optimization space of
adversarial perturbations. Specifically, we group the distribution of
pretraining data and optimize a set of cluster-specific visual prompts on
frequency domain. These prompts are incorporated with input images through
prototype-based prompt selection during test period. Extensive evaluation shows
that our method clearly boost MAE's adversarial robustness while maintaining
its clean performance on ImageNet-1k classification. Our code is available at:
\href{https://github.com/shikiw/RobustMAE}{https://github.com/shikiw/RobustMAE}.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10316" title="Abstract">arXiv:2308.10316</a> [<a href="/pdf/2308.10316" title="Download PDF">pdf</a>, <a href="/ps/2308.10316" title="Download PostScript">ps</a>, <a href="/format/2308.10316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Differentially Private Densest Subgraph: Local and Purely  Additive
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dinitz%2C+M">Michael Dinitz</a>, 
<a href="/search/cs?searchtype=author&query=Kale%2C+S">Satyen Kale</a>, 
<a href="/search/cs?searchtype=author&query=Lattanzi%2C+S">Silvio Lattanzi</a>, 
<a href="/search/cs?searchtype=author&query=Vassilvitskii%2C+S">Sergei Vassilvitskii</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study the Densest Subgraph problem under the additional constraint of
differential privacy. In the LEDP (local edge differential privacy) model,
introduced recently by Dhulipala et al. [FOCS 2022], we give an $(\epsilon,
\delta)$-differentially private algorithm with no multiplicative loss: the loss
is purely additive. This is in contrast to every previous private algorithm for
densest subgraph (local or centralized), all of which incur some multiplicative
loss as well as some additive loss. Moreover, our additive loss matches the
best-known previous additive loss (in any version of differential privacy) when
$1/\delta$ is at least polynomial in $n$, and in the centralized setting we can
strengthen our result to provide better than the best-known additive loss.
Additionally, we give a different algorithm that is $\epsilon$-differentially
private in the LEDP model which achieves a multiplicative ratio arbitrarily
close to $2$, along with an additional additive factor. This improves over the
previous multiplicative $4$-approximation in the LEDP model. Finally, we
conclude with extensions of our techniques to both the node-weighted and the
directed versions of the problem.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10317" title="Abstract">arXiv:2308.10317</a> [<a href="/pdf/2308.10317" title="Download PDF">pdf</a>, <a href="/format/2308.10317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Sustainable Development: A Novel Integrated Machine Learning  Model for Holistic Environmental Health Monitoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mazumder%2C+A">Anirudh Mazumder</a>, 
<a href="/search/cs?searchtype=author&query=Engala%2C+S">Sarthak Engala</a>, 
<a href="/search/cs?searchtype=author&query=Nallaparaju%2C+A">Aditya Nallaparaju</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Urbanization enables economic growth but also harms the environment through
degradation. Traditional methods of detecting environmental issues have proven
inefficient. Machine learning has emerged as a promising tool for tracking
environmental deterioration by identifying key predictive features. Recent
research focused on developing a predictive model using pollutant levels and
particulate matter as indicators of environmental state in order to outline
challenges. Machine learning was employed to identify patterns linking areas
with worse conditions. This research aims to assist governments in identifying
intervention points, improving planning and conservation efforts, and
ultimately contributing to sustainable development.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10319" title="Abstract">arXiv:2308.10319</a> [<a href="/pdf/2308.10319" title="Download PDF">pdf</a>, <a href="/format/2308.10319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Tutorial on Visual Representations of Relational Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gatterbauer%2C+W">Wolfgang Gatterbauer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 page tutorial paper at VLDB 2023, tutorial web page with slides to be posted in time: <a href="https://northeastern-datalab.github.io/visual-query-representation-tutorial/.">this https URL</a> arXiv admin note: text overlap with <a href="/abs/2208.01613">arXiv:2208.01613</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Human-Computer Interaction (cs.HC); Logic in Computer Science (cs.LO); Programming Languages (cs.PL)

</div>
<p class="mathjax">Query formulation is increasingly performed by systems that need to guess a
user's intent (e.g. via spoken word interfaces). But how can a user know that
the computational agent is returning answers to the "right" query? More
generally, given that relational queries can become pretty complicated, how can
we help users understand existing relational queries, whether human-generated
or automatically generated? Now seems the right moment to revisit a topic that
predates the birth of the relational model: developing visual metaphors that
help users understand relational queries.
<br />This lecture-style tutorial surveys the key visual metaphors developed for
visual representations of relational expressions. We will survey the history
and state-of-the art of relationally-complete diagrammatic representations of
relational queries, discuss the key visual metaphors developed in over a
century of investigating diagrammatic languages, and organize the landscape by
mapping their used visual alphabets to the syntax and semantics of Relational
Algebra (RA) and Relational Calculus (RC).
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10320" title="Abstract">arXiv:2308.10320</a> [<a href="/pdf/2308.10320" title="Download PDF">pdf</a>, <a href="/format/2308.10320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyper Association Graph Matching with Uncertainty Quantification for  Coronary Artery Semantic Labeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Esposito%2C+M">Michele Esposito</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhihui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Weihua Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Coronary artery disease (CAD) is one of the primary causes leading to death
worldwide. Accurate extraction of individual arterial branches on invasive
coronary angiograms (ICA) is important for stenosis detection and CAD
diagnosis. However, deep learning-based models face challenges in generating
semantic segmentation for coronary arteries due to the morphological similarity
among different types of coronary arteries. To address this challenge, we
propose an innovative approach using the hyper association graph-matching
neural network with uncertainty quantification (HAGMN-UQ) for coronary artery
semantic labeling on ICAs. The graph-matching procedure maps the arterial
branches between two individual graphs, so that the unlabeled arterial segments
are classified by the labeled segments, and the coronary artery semantic
labeling is achieved. By incorporating the anatomical structural loss and
uncertainty, our model achieved an accuracy of 0.9345 for coronary artery
semantic labeling with a fast inference speed, leading to an effective and
efficient prediction in real-time clinical decision-making scenarios.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10328" title="Abstract">arXiv:2308.10328</a> [<a href="/pdf/2308.10328" title="Download PDF">pdf</a>, <a href="/format/2308.10328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Empirical Evaluation on Online Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soutif--Cormerais%2C+A">Albin Soutif--Cormerais</a>, 
<a href="/search/cs?searchtype=author&query=Carta%2C+A">Antonio Carta</a>, 
<a href="/search/cs?searchtype=author&query=Cossu%2C+A">Andrea Cossu</a>, 
<a href="/search/cs?searchtype=author&query=Hurtado%2C+J">Julio Hurtado</a>, 
<a href="/search/cs?searchtype=author&query=Lomonaco%2C+V">Vincenzo Lomonaco</a>, 
<a href="/search/cs?searchtype=author&query=Van+de+Weijer%2C+J">Joost Van de Weijer</a>, 
<a href="/search/cs?searchtype=author&query=Hemati%2C+H">Hamed Hemati</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV Visual Continual Learning Workshop 2023 accepted paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Online continual learning aims to get closer to a live learning experience by
learning directly on a stream of data with temporally shifting distribution and
by storing a minimum amount of data from that stream. In this empirical
evaluation, we evaluate various methods from the literature that tackle online
continual learning. More specifically, we focus on the class-incremental
setting in the context of image classification, where the learner must learn
new classes incrementally from a stream of data. We compare these methods on
the Split-CIFAR100 and Split-TinyImagenet benchmarks, and measure their average
accuracy, forgetting, stability, and quality of the representations, to
evaluate various aspects of the algorithm at the end but also during the whole
training period. We find that most methods suffer from stability and
underfitting issues. However, the learned representations are comparable to
i.i.d. training under the same computational budget. No clear winner emerges
from the results and basic experience replay, when properly tuned and
implemented, is a very strong baseline. We release our modular and extensible
codebase at https://github.com/AlbinSou/ocl_survey based on the avalanche
framework to reproduce our results and encourage future research.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10330" title="Abstract">arXiv:2308.10330</a> [<a href="/pdf/2308.10330" title="Download PDF">pdf</a>, <a href="/format/2308.10330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Real-World Visual Tracking with Temporal Contexts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Ziang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Ziyuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Liang Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Changhong Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE TPAMI, Code: <a href="https://github.com/vision4robotics/TCTrack">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual tracking has made significant improvements in the past few decades.
Most existing state-of-the-art trackers 1) merely aim for performance in ideal
conditions while overlooking the real-world conditions; 2) adopt the
tracking-by-detection paradigm, neglecting rich temporal contexts; 3) only
integrate the temporal information into the template, where temporal contexts
among consecutive frames are far from being fully utilized. To handle those
problems, we propose a two-level framework (TCTrack) that can exploit temporal
contexts efficiently. Based on it, we propose a stronger version for real-world
visual tracking, i.e., TCTrack++. It boils down to two levels: features and
similarity maps. Specifically, for feature extraction, we propose an
attention-based temporally adaptive convolution to enhance the spatial features
using temporal information, which is achieved by dynamically calibrating the
convolution weights. For similarity map refinement, we introduce an adaptive
temporal transformer to encode the temporal knowledge efficiently and decode it
for the accurate refinement of the similarity map. To further improve the
performance, we additionally introduce a curriculum learning strategy. Also, we
adopt online evaluation to measure performance in real-world conditions.
Exhaustive experiments on 8 wellknown benchmarks demonstrate the superiority of
TCTrack++. Real-world tests directly verify that TCTrack++ can be readily used
in real-world applications.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10334" title="Abstract">arXiv:2308.10334</a> [<a href="/pdf/2308.10334" title="Download PDF">pdf</a>, <a href="/format/2308.10334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coordinate Transformer: Achieving Single-stage Multi-person Mesh  Recovery from Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Haoye Dong</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+H">Hanchao Jia</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Dong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Kampffmeyer%2C+M+C">Michael C. Kampffmeyer</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Liang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaodan Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-person 3D mesh recovery from videos is a critical first step towards
automatic perception of group behavior in virtual reality, physical therapy and
beyond. However, existing approaches rely on multi-stage paradigms, where the
person detection and tracking stages are performed in a multi-person setting,
while temporal dynamics are only modeled for one person at a time.
Consequently, their performance is severely limited by the lack of inter-person
interactions in the spatial-temporal mesh recovery, as well as by detection and
tracking defects. To address these challenges, we propose the Coordinate
transFormer (CoordFormer) that directly models multi-person spatial-temporal
relations and simultaneously performs multi-mesh recovery in an end-to-end
manner. Instead of partitioning the feature map into coarse-scale patch-wise
tokens, CoordFormer leverages a novel Coordinate-Aware Attention to preserve
pixel-level spatial-temporal coordinate information. Additionally, we propose a
simple, yet effective Body Center Attention mechanism to fuse position
information. Extensive experiments on the 3DPW dataset demonstrate that
CoordFormer significantly improves the state-of-the-art, outperforming the
previously best results by 4.2%, 8.8% and 4.7% according to the MPJPE, PAMPJPE,
and PVE metrics, respectively, while being 40% faster than recent video-based
approaches. The released code can be found at
https://github.com/Li-Hao-yuan/CoordFormer.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10335" title="Abstract">arXiv:2308.10335</a> [<a href="/pdf/2308.10335" title="Download PDF">pdf</a>, <a href="/format/2308.10335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study on Robustness and Reliability of Large Language Model Code  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+L">Li Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zilong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
<p class="mathjax">Recently, the large language models (LLMs) have shown extraordinary ability
in understanding natural language and generating programming code. It has been
a common practice of software engineers to consult LLMs when encountering
coding questions. Although efforts have been made to avoid syntax errors and
align the code with the intended semantics, the reliability and robustness of
the code generationfrom LLMs have not yet been thoroughly studied. The
executable code is not equivalent to the reliable and robust code, especially
in the context of real-world software development.The misuse of APIs in the
generated code could lead to severe problem, such as resource leaks, program
crashes, etc.To make things worse, the users of LLM code generation services
are actually the developers that are most vulnerable to these code that seems
right -- They are always novice developers that are not familiar with the APIs
that LLMs generate code for them. Therefore, they could hardly tell the misuse
in the code generated by LLMs, which further facilitates the incorrect code
applied in real-world software. Existing code evaluation benchmark and datasets
focus on crafting small tasks such as programming questions in coding
interviews, which however deviates from the problem that developers would ask
LLM for real-world coding help. To fill the missing piece, in this work, we
propose a dataset RobustAPI for evaluating the reliability and robustness of
code generated by LLMs. We collect 1208 coding questions from StackOverflow on
24 representative Java APIs. We summarize thecommon misuse patterns of these
APIs and evaluate them oncurrent popular LLMs. The evaluation results show that
evenfor GPT-4, 62% of the generated code contains API misuses,which would cause
unexpected consequences if the code isintroduced into real-world software.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10337" title="Abstract">arXiv:2308.10337</a> [<a href="/pdf/2308.10337" title="Download PDF">pdf</a>, <a href="/format/2308.10337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strata-NeRF : Neural Radiance Fields for Stratified Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhiman%2C+A">Ankit Dhiman</a>, 
<a href="/search/cs?searchtype=author&query=R%2C+S">Srinath R</a>, 
<a href="/search/cs?searchtype=author&query=Rangwani%2C+H">Harsh Rangwani</a>, 
<a href="/search/cs?searchtype=author&query=Parihar%2C+R">Rishubh Parihar</a>, 
<a href="/search/cs?searchtype=author&query=Boregowda%2C+L+R">Lokesh R Boregowda</a>, 
<a href="/search/cs?searchtype=author&query=Sridhar%2C+S">Srinath Sridhar</a>, 
<a href="/search/cs?searchtype=author&query=Babu%2C+R+V">R Venkatesh Babu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023, Project Page: <a href="https://ankitatiisc.github.io/Strata-NeRF/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural Radiance Field (NeRF) approaches learn the underlying 3D
representation of a scene and generate photo-realistic novel views with high
fidelity. However, most proposed settings concentrate on modelling a single
object or a single level of a scene. However, in the real world, we may capture
a scene at multiple levels, resulting in a layered capture. For example,
tourists usually capture a monument's exterior structure before capturing the
inner structure. Modelling such scenes in 3D with seamless switching between
levels can drastically improve immersive experiences. However, most existing
techniques struggle in modelling such scenes. We propose Strata-NeRF, a single
neural radiance field that implicitly captures a scene with multiple levels.
Strata-NeRF achieves this by conditioning the NeRFs on Vector Quantized (VQ)
latent representations which allow sudden changes in scene structure. We
evaluate the effectiveness of our approach in multi-layered synthetic dataset
comprising diverse scenes and then further validate its generalization on the
real-world RealEstate10K dataset. We find that Strata-NeRF effectively captures
stratified scenes, minimizes artifacts, and synthesizes high-fidelity views
compared to existing approaches.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10340" title="Abstract">arXiv:2308.10340</a> [<a href="/pdf/2308.10340" title="Download PDF">pdf</a>, <a href="/format/2308.10340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Future Vision of Dynamic Certification Schemes for Autonomous Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kusnirakova%2C+D">Dasa Kusnirakova</a>, 
<a href="/search/cs?searchtype=author&query=Buhnova%2C+B">Barbora Buhnova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">As software becomes increasingly pervasive in critical domains like
autonomous driving, new challenges arise, necessitating rethinking of system
engineering approaches. The gradual takeover of all critical driving functions
by autonomous driving adds to the complexity of certifying these systems.
Namely, certification procedures do not fully keep pace with the dynamism and
unpredictability of future autonomous systems, and they may not fully guarantee
compliance with the requirements imposed on these systems.
<br />In this paper, we have identified several issues with the current
certification strategies that could pose serious safety risks. As an example,
we highlight the inadequate reflection of software changes in constantly
evolving systems and the lack of support for systems' cooperation necessary for
managing coordinated movements. Other shortcomings include the narrow focus of
awarded certification, neglecting aspects such as the ethical behavior of
autonomous software systems. The contribution of this paper is threefold.
First, we analyze the existing international standards used in certification
processes in relation to the requirements derived from dynamic software
ecosystems and autonomous systems themselves, and identify their shortcomings.
Second, we outline six suggestions for rethinking certification to foster
comprehensive solutions to the identified problems. Third, a conceptual
Multi-Layer Trust Governance Framework is introduced to establish a robust
governance structure for autonomous ecosystems and associated processes,
including envisioned future certification schemes. The framework comprises
three layers, which together support safe and ethical operation of autonomous
systems.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10343" title="Abstract">arXiv:2308.10343</a> [<a href="/pdf/2308.10343" title="Download PDF">pdf</a>, <a href="/format/2308.10343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing In-Situ Structural Health Monitoring through RF Energy-Powered  Sensor Nodes and Mobile Platform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Luo%2C+Y">Yu Luo</a>, 
<a href="/search/eess?searchtype=author&query=Pu%2C+L">Lina Pu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/eess?searchtype=author&query=Howard%2C+I">Isaac Howard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">This research contributes to long-term structural health monitoring (SHM) by
exploring radio frequency energy-powered sensor nodes (RF-SNs) embedded in
concrete. Unlike traditional in-situ monitoring systems relying on batteries or
wire-connected power sources, the RF-SN captures radio energy from a mobile
radio transmitter for sensing and communication. This offers a cost-effective
solution for consistent in-situ perception. To optimize the system performance
across various situations, we've explored both active and passive communication
methods. For the active RF-SN, we implement a specialized control circuit
enabling the node to transmit data through ZigBee protocol at low incident
power. For the passive RF-SN, radio energy is not only for power but also as a
carrier signal, with data conveyed by modulating the amplitude of the
backscattered radio wave. To address the challenge of significant attenuation
of the backscattering signal in concrete, we utilize a square chirp-based
modulation scheme for passive communication. This scheme allows the receiver to
successfully decode the data even under a negative signal-to-noise ratio (SNR)
condition. The experimental results indicate that an active RF-SN embedded in
concrete at a depth of 13.5 cm can be effectively powered by a 915MHz mobile
radio transmitter with an effective isotropic radiated power (EIRP) of 32.5dBm.
This setup allows the RF-SN to send over 1 kilobyte of data within 10 seconds,
with an additional 1.7 kilobytes every 1.6 seconds of extra charging. For the
passive RF-SN buried at the same depth, continuous data transmission at a rate
of 224 bps with a 3% bit error rate (BER) is achieved when the EIRP of the
transmitter is 23.6 dBm.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10345" title="Abstract">arXiv:2308.10345</a> [<a href="/pdf/2308.10345" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Large Language Models Find And Fix Vulnerable Software?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Noever%2C+D">David Noever</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this study, we evaluated the capability of Large Language Models (LLMs),
particularly OpenAI's GPT-4, in detecting software vulnerabilities, comparing
their performance against traditional static code analyzers like Snyk and
Fortify. Our analysis covered numerous repositories, including those from NASA
and the Department of Defense. GPT-4 identified approximately four times the
vulnerabilities than its counterparts. Furthermore, it provided viable fixes
for each vulnerability, demonstrating a low rate of false positives. Our tests
encompassed 129 code samples across eight programming languages, revealing the
highest vulnerabilities in PHP and JavaScript. GPT-4's code corrections led to
a 90% reduction in vulnerabilities, requiring only an 11% increase in code
lines. A critical insight was LLMs' ability to self-audit, suggesting fixes for
their identified vulnerabilities and underscoring their precision. Future
research should explore system-level vulnerabilities and integrate multiple
static code analyzers for a holistic perspective on LLMs' potential.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10347" title="Abstract">arXiv:2308.10347</a> [<a href="/pdf/2308.10347" title="Download PDF">pdf</a>, <a href="/format/2308.10347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Transformers without Self-supervised Learning: A Loss  Landscape Perspective in Sequential Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai%2C+V">Vivian Lai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huiyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+C+M">Chin-Chia Michael Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Minghua Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yiwei Cai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hao Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Transformer and its variants are a powerful class of architectures for
sequential recommendation, owing to their ability of capturing a user's dynamic
interests from their past interactions. Despite their success,
Transformer-based models often require the optimization of a large number of
parameters, making them difficult to train from sparse data in sequential
recommendation. To address the problem of data sparsity, previous studies have
utilized self-supervised learning to enhance Transformers, such as pre-training
embeddings from item attributes or contrastive data augmentations. However,
these approaches encounter several training issues, including initialization
sensitivity, manual data augmentations, and large batch-size memory
bottlenecks.
<br />In this work, we investigate Transformers from the perspective of loss
geometry, aiming to enhance the models' data efficiency and generalization in
sequential recommendation. We observe that Transformers (e.g., SASRec) can
converge to extremely sharp local minima if not adequately regularized.
Inspired by the recent Sharpness-Aware Minimization (SAM), we propose SAMRec,
which significantly improves the accuracy and robustness of sequential
recommendation. SAMRec performs comparably to state-of-the-art self-supervised
Transformers, such as S$^3$Rec and CL4SRec, without the need for pre-training
or strong data augmentations.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10354" title="Abstract">arXiv:2308.10354</a> [<a href="/pdf/2308.10354" title="Download PDF">pdf</a>, <a href="/format/2308.10354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imaginations of WALL-E : Reconstructing Experiences with an  Imagination-Inspired Module for Advanced AI Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taghavi%2C+Z+S">Zeinab Sadat Taghavi</a>, 
<a href="/search/cs?searchtype=author&query=Gooran%2C+S">Soroush Gooran</a>, 
<a href="/search/cs?searchtype=author&query=Dalili%2C+S+A">Seyed Arshan Dalili</a>, 
<a href="/search/cs?searchtype=author&query=Amirzadeh%2C+H">Hamidreza Amirzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Nematbakhsh%2C+M+J">Mohammad Jalal Nematbakhsh</a>, 
<a href="/search/cs?searchtype=author&query=Sameti%2C+H">Hossein Sameti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages,
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">In this paper, we introduce a novel Artificial Intelligence (AI) system
inspired by the philosophical and psychoanalytical concept of imagination as a
``Re-construction of Experiences". Our AI system is equipped with an
imagination-inspired module that bridges the gap between textual inputs and
other modalities, enriching the derived information based on previously learned
experiences. A unique feature of our system is its ability to formulate
independent perceptions of inputs. This leads to unique interpretations of a
concept that may differ from human interpretations but are equally valid, a
phenomenon we term as ``Interpretable Misunderstanding". We employ large-scale
models, specifically a Multimodal Large Language Model (MLLM), enabling our
proposed system to extract meaningful information across modalities while
primarily remaining unimodal. We evaluated our system against other large
language models across multiple tasks, including emotion recognition and
question-answering, using a zero-shot methodology to ensure an unbiased
scenario that may happen by fine-tuning. Significantly, our system outperformed
the best Large Language Models (LLM) on the MELD, IEMOCAP, and CoQA datasets,
achieving Weighted F1 (WF1) scores of 46.74%, 25.23%, and Overall F1 (OF1)
score of 17%, respectively, compared to 22.89%, 12.28%, and 7% from the
well-performing LLM. The goal is to go beyond the statistical view of language
processing and tie it to human concepts such as philosophy and psychoanalysis.
This work represents a significant advancement in the development of
imagination-inspired AI systems, opening new possibilities for AI to generate
deep and interpretable information across modalities, thereby enhancing
human-AI interaction.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10357" title="Abstract">arXiv:2308.10357</a> [<a href="/pdf/2308.10357" title="Download PDF">pdf</a>, <a href="/format/2308.10357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Explicit Fourth-Order Hybrid-Variable Method for Euler Equations with  A Residual-Consistent Viscosity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zeng%2C+X">Xianyi Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper we present a formally fourth-order accurate hybrid-variable
method for the Euler equations in the context of method of lines. The
hybrid-variable (HV) method seeks numerical approximations to both
cell-averages and nodal solutions and evolves them in time simultaneously; and
it is proved in previous work that these methods are inherent superconvergent.
Taking advantage of the superconvergence, the method is built on a third-order
discrete differential operator, which approximates the first spatial derivative
at each grid point, only using the information in the two neighboring cells.
Stability and accuracy analyses are conducted in the one-dimensional case for
the linear advection equation; whereas extension to nonlinear systems including
the Euler equations is achieved using characteristic decomposition and the
incorporation of a residual-consistent viscosity to capture strong
discontinuities. Extensive numerical tests are presented to assess the
numerical performance of the method for both 1D and 2D problems.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10362" title="Abstract">arXiv:2308.10362</a> [<a href="/pdf/2308.10362" title="Download PDF">pdf</a>, <a href="/format/2308.10362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vehicle Cameras Guide mmWave Beams: Approach and Real-World V2V  Demonstration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Osman%2C+T">Tawfik Osman</a>, 
<a href="/search/cs?searchtype=author&query=Charan%2C+G">Gouranga Charan</a>, 
<a href="/search/cs?searchtype=author&query=Alkhateeb%2C+A">Ahmed Alkhateeb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Dataset and code files are available on the DeepSense 6G website <a href="https://deepsense6g.net/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Computer Vision and Pattern Recognition (cs.CV); Signal Processing (eess.SP)

</div>
<p class="mathjax">Accurately aligning millimeter-wave (mmWave) and terahertz (THz) narrow beams
is essential to satisfy reliability and high data rates of 5G and beyond
wireless communication systems. However, achieving this objective is difficult,
especially in vehicle-to-vehicle (V2V) communication scenarios, where both
transmitter and receiver are constantly mobile. Recently, additional sensing
modalities, such as visual sensors, have attracted significant interest due to
their capability to provide accurate information about the wireless
environment. To that end, in this paper, we develop a deep learning solution
for V2V scenarios to predict future beams using images from a 360 camera
attached to the vehicle. The developed solution is evaluated on a real-world
multi-modal mmWave V2V communication dataset comprising co-existing 360 camera
and mmWave beam training data. The proposed vision-aided solution achieves
$\approx 85\%$ top-5 beam prediction accuracy while significantly reducing the
beam training overhead. This highlights the potential of utilizing vision for
enabling highly-mobile V2V communications.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10364" title="Abstract">arXiv:2308.10364</a> [<a href="/pdf/2308.10364" title="Download PDF">pdf</a>, <a href="/format/2308.10364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SE(3) Equivariant Augmented Coupling Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Midgley%2C+L+I">Laurence I. Midgley</a>, 
<a href="/search/cs?searchtype=author&query=Stimper%2C+V">Vincent Stimper</a>, 
<a href="/search/cs?searchtype=author&query=Antor%C3%A1n%2C+J">Javier Antor&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Mathieu%2C+E">Emile Mathieu</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>, 
<a href="/search/cs?searchtype=author&query=Hern%C3%A1ndez-Lobato%2C+J+M">Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Coupling normalizing flows allow for fast sampling and density evaluation,
making them the tool of choice for probabilistic modeling of physical systems.
However, the standard coupling architecture precludes endowing flows that
operate on the Cartesian coordinates of atoms with the SE(3) and permutation
invariances of physical systems. This work proposes a coupling flow that
preserves SE(3) and permutation equivariance by performing coordinate splits
along additional augmented dimensions. At each layer, the flow maps atoms'
positions into learned SE(3) invariant bases, where we apply standard flow
transformations, such as monotonic rational-quadratic splines, before returning
to the original basis. Crucially, our flow preserves fast sampling and density
evaluation, and may be used to produce unbiased estimates of expectations with
respect to the target distribution via importance sampling. When trained on the
DW4, LJ13 and QM9-positional datasets, our flow is competitive with equivariant
continuous normalizing flows, while allowing sampling two orders of magnitude
faster. Moreover, to the best of our knowledge, we are the first to learn the
full Boltzmann distribution of alanine dipeptide by only modeling the Cartesian
positions of its atoms. Lastly, we demonstrate that our flow can be trained to
approximately sample from the Boltzmann distribution of the DW4 and LJ13
particle systems using only their energy functions.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10365" title="Abstract">arXiv:2308.10365</a> [<a href="/pdf/2308.10365" title="Download PDF">pdf</a>, <a href="/format/2308.10365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formal Verification of Safety Architectures for Automated Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eberhart%2C+C">Clovis Eberhart</a>, 
<a href="/search/cs?searchtype=author&query=Dubut%2C+J">J&#xe9;r&#xe9;my Dubut</a>, 
<a href="/search/cs?searchtype=author&query=Haydon%2C+J">James Haydon</a>, 
<a href="/search/cs?searchtype=author&query=Hasuo%2C+I">Ichiro Hasuo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In proceedings of 2023 IEEE Intelligent Vehicles Symposium (IV), 8 pages, 5 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In 2023 IEEE Intelligent Vehicles Symposium (IV), pp. 1-8 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Safety architectures play a crucial role in the safety assurance of automated
driving vehicles (ADVs). They can be used as safety envelopes of black-box ADV
controllers, and for graceful degradation from one ODD to another. Building on
our previous work on the formalization of responsibility-sensitive safety
(RSS), we introduce a novel program logic that accommodates assume-guarantee
reasoning and fallback-like constructs. This allows us to formally define and
prove the safety of existing and novel safety architectures. We apply the logic
to a pull over scenario and experimentally evaluate the resulting safety
architecture.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10370" title="Abstract">arXiv:2308.10370</a> [<a href="/pdf/2308.10370" title="Download PDF">pdf</a>, <a href="/ps/2308.10370" title="Download PostScript">ps</a>, <a href="/format/2308.10370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> cantnlp@LT-EDI@RANLP-2023: Homophobia/Transphobia Detection in Social  Media Comments using Spatio-Temporally Retrained Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wong%2C+S+G+-">Sidney G.-J. Wong</a>, 
<a href="/search/cs?searchtype=author&query=Durward%2C+M">Matthew Durward</a>, 
<a href="/search/cs?searchtype=author&query=Adams%2C+B">Benjamin Adams</a>, 
<a href="/search/cs?searchtype=author&query=Dunn%2C+J">Jonathan Dunn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper describes our multiclass classification system developed as part
of the LTEDI@RANLP-2023 shared task. We used a BERT-based language model to
detect homophobic and transphobic content in social media comments across five
language conditions: English, Spanish, Hindi, Malayalam, and Tamil. We
retrained a transformer-based crosslanguage pretrained language model,
XLMRoBERTa, with spatially and temporally relevant social media language data.
We also retrained a subset of models with simulated script-mixed social media
language data with varied performance. We developed the best performing
seven-label classification system for Malayalam based on weighted macro
averaged F1 score (ranked first out of six) with variable performance for other
language and class-label conditions. We found the inclusion of this
spatio-temporal data improved the classification performance for all language
and task conditions when compared with the baseline. The results suggests that
transformer-based language classification systems are sensitive to
register-specific and language-specific retraining.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10373" title="Abstract">arXiv:2308.10373</a> [<a href="/pdf/2308.10373" title="Download PDF">pdf</a>, <a href="/format/2308.10373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HoSNN: Adversarially-Robust Homeostatic Spiking Neural Networks with  Adaptive Firing Thresholds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geng%2C+H">Hejia Geng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Spiking neural networks (SNNs) offer promise for efficient and powerful
neurally inspired computation. Common to other types of neural networks,
however, SNNs face the severe issue of vulnerability to adversarial attacks. We
present the first study that draws inspiration from neural homeostasis to
develop a bio-inspired solution that counters the susceptibilities of SNNs to
adversarial onslaughts. At the heart of our approach is a novel
threshold-adapting leaky integrate-and-fire (TA-LIF) neuron model, which we
adopt to construct the proposed adversarially robust homeostatic SNN (HoSNN).
Distinct from traditional LIF models, our TA-LIF model incorporates a
self-stabilizing dynamic thresholding mechanism, curtailing adversarial noise
propagation and safeguarding the robustness of HoSNNs in an unsupervised
manner. Theoretical analysis is presented to shed light on the stability and
convergence properties of the TA-LIF neurons, underscoring their superior
dynamic robustness under input distributional shifts over traditional LIF
neurons. Remarkably, without explicit adversarial training, our HoSNNs
demonstrate inherent robustness on CIFAR-10, with accuracy improvements to
72.6% and 54.19% against FGSM and PGD attacks, up from 20.97% and 0.6%,
respectively. Furthermore, with minimal FGSM adversarial training, our HoSNNs
surpass previous models by 29.99% under FGSM and 47.83% under PGD attacks on
CIFAR-10. Our findings offer a new perspective on harnessing biological
principles for bolstering SNNs adversarial robustness and defense, paving the
way to more resilient neuromorphic computing.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10379" title="Abstract">arXiv:2308.10379</a> [<a href="/pdf/2308.10379" title="Download PDF">pdf</a>, <a href="/format/2308.10379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sel%2C+B">Bilgehan Sel</a>, 
<a href="/search/cs?searchtype=author&query=Al-Tawaha%2C+A">Ahmad Al-Tawaha</a>, 
<a href="/search/cs?searchtype=author&query=Khattar%2C+V">Vanshaj Khattar</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+R">Ruoxi Jia</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Ming Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Current literature, aiming to surpass the "Chain-of-Thought" approach, often
resorts to an external modus operandi involving halting, modifying, and then
resuming the generation process to boost Large Language Models' (LLMs)
reasoning capacities. This mode escalates the number of query requests, leading
to increased costs, memory, and computational overheads. Addressing this, we
propose the Algorithm of Thoughts -- a novel strategy that propels LLMs through
algorithmic reasoning pathways, pioneering a new mode of in-context learning.
By employing algorithmic examples, we exploit the innate recurrence dynamics of
LLMs, expanding their idea exploration with merely one or a few queries. Our
technique outperforms earlier single-query methods and stands on par with a
recent multi-query strategy that employs an extensive tree search algorithm.
Intriguingly, our results suggest that instructing an LLM using an algorithm
can lead to performance surpassing that of the algorithm itself, hinting at
LLM's inherent ability to weave its intuition into optimized searches. We probe
into the underpinnings of our method's efficacy and its nuances in application.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10380" title="Abstract">arXiv:2308.10380</a> [<a href="/pdf/2308.10380" title="Download PDF">pdf</a>, <a href="/format/2308.10380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Human-on-the-Loop Optimization Autoformalism Approach for  Sustainability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Ming Jin</a>, 
<a href="/search/cs?searchtype=author&query=Sel%2C+B">Bilgehan Sel</a>, 
<a href="/search/cs?searchtype=author&query=Hardeep%2C+F">Fnu Hardeep</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+W">Wotao Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">This paper outlines a natural conversational approach to solving personalized
energy-related problems using large language models (LLMs). We focus on
customizable optimization problems that necessitate repeated solving with
slight variations in modeling and are user-specific, hence posing a challenge
to devising a one-size-fits-all model. We put forward a strategy that augments
an LLM with an optimization solver, enhancing its proficiency in understanding
and responding to user specifications and preferences while providing nonlinear
reasoning capabilities. Our approach pioneers the novel concept of human-guided
optimization autoformalism, translating a natural language task specification
automatically into an optimization instance. This enables LLMs to analyze,
explain, and tackle a variety of instance-specific energy-related problems,
pushing beyond the limits of current prompt-based techniques.
<br />Our research encompasses various commonplace tasks in the energy sector, from
electric vehicle charging and Heating, Ventilation, and Air Conditioning (HVAC)
control to long-term planning problems such as cost-benefit evaluations for
installing rooftop solar photovoltaics (PVs) or heat pumps. This pilot study
marks an essential stride towards the context-based formulation of optimization
using LLMs, with the potential to democratize optimization processes. As a
result, stakeholders are empowered to optimize their energy consumption,
promoting sustainable energy practices customized to personal needs and
preferences.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10382" title="Abstract">arXiv:2308.10382</a> [<a href="/pdf/2308.10382" title="Download PDF">pdf</a>, <a href="/format/2308.10382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> False Negative/Positive Control for SAM on Noisy Medical Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xing Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Han Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+D">Dewei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+D">Daiwei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+A">Ange Lou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+R">Ruining Deng</a>, 
<a href="/search/cs?searchtype=author&query=Arenas%2C+G">Gabriel Arenas</a>, 
<a href="/search/cs?searchtype=author&query=Oguz%2C+B">Baris Oguz</a>, 
<a href="/search/cs?searchtype=author&query=Schwartz%2C+N">Nadav Schwartz</a>, 
<a href="/search/cs?searchtype=author&query=Byram%2C+B+C">Brett C Byram</a>, 
<a href="/search/cs?searchtype=author&query=Oguz%2C+I">Ipek Oguz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The Segment Anything Model (SAM) is a recently developed all-range foundation
model for image segmentation. It can use sparse manual prompts such as bounding
boxes to generate pixel-level segmentation in natural images but struggles in
medical images such as low-contrast, noisy ultrasound images. We propose a
refined test-phase prompt augmentation technique designed to improve SAM's
performance in medical image segmentation. The method couples multi-box prompt
augmentation and an aleatoric uncertainty-based false-negative (FN) and
false-positive (FP) correction (FNPC) strategy. We evaluate the method on two
ultrasound datasets and show improvement in SAM's performance and robustness to
inaccurate prompts, without the necessity for further training or tuning.
Moreover, we present the Single-Slice-to-Volume (SS2V) method, enabling 3D
pixel-level segmentation using only the bounding box annotation from a single
2D slice. Our results allow efficient use of SAM in even noisy, low-contrast
medical images. The source code will be released soon.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10385" title="Abstract">arXiv:2308.10385</a> [<a href="/pdf/2308.10385" title="Download PDF">pdf</a>, <a href="/format/2308.10385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Effects of Engaging and Affective Behaviors of Virtual Agents in  Group Decision-Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hanseob Kim</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bin Han</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jieun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Syawaludin%2C+M+F">Muhammad Firdaus Syawaludin</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+G+J">Gerard Jounghyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jae-In Hwang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Virtual agents (VAs) need to exhibit engaged and affective behavior in order
to become more effective social actors in our daily lives. However, such
behaviors need to conform to social norms, especially in organizational
settings. This study examines how different VA behaviors influence subjects'
perceptions and actions in group decision-making processes. Participants
exposed to VAs demonstrated varying levels of engagement and affective behavior
during the group discussions. Engagement refers to the VA's focus on the group
task, while affective behavior represents the VA's emotional state. The
findings indicate that VA engagement positively influences user behavior,
particularly in attention allocation. However, it has minimal impact on
subjective perception. Conversely, affective expressions of VAs have a negative
impact on subjective perceptions, such as social presence, social influence,
and trustworthiness. Interestingly, in 64 discussions for tasks, only seven
showed a decline in group scores compared to individual scores, and in six of
these cases, the VA exhibited a non-engaged and affective state. We discuss the
results and the potential implications for future research on using VAs in
group meetings. It provides valuable insights for improving VA behavior as a
team member in group decision-making scenarios and guides VA design in
organizational contexts.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10386" title="Abstract">arXiv:2308.10386</a> [<a href="/pdf/2308.10386" title="Download PDF">pdf</a>, <a href="/format/2308.10386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Opinion Aggregation -- A Statistical Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sevuktekin%2C+N+C">Noyan C. Sevuktekin</a>, 
<a href="/search/cs?searchtype=author&query=Singer%2C+A+C">Andrew C. Singer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This research was conducted during Noyan Sevuktekin's time at University of Illinois at Urbana-Champaign and the results were first presented in Chapter 3 of his dissertation, entitled "Learning From Opinions". Permalink: <a href="https://hdl.handle.net/2142/110814">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Complex decision-making systems rarely have direct access to the current
state of the world and they instead rely on opinions to form an understanding
of what the ground truth could be. Even in problems where experts provide
opinions without any intention to manipulate the decision maker, it is
challenging to decide which expert's opinion is more reliable -- a challenge
that is further amplified when decision-maker has limited, delayed, or no
access to the ground truth after the fact. This paper explores a statistical
approach to infer the competence of each expert based on their opinions without
any need for the ground truth. Echoing the logic behind what is commonly
referred to as \textit{the wisdom of crowds}, we propose measuring the
competence of each expert by their likeliness to agree with their peers. We
further show that the more reliable an expert is the more likely it is that
they agree with their peers. We leverage this fact to propose a completely
unsupervised version of the na\"{i}ve Bayes classifier and show that the
proposed technique is asymptotically optimal for a large class of problems. In
addition to aggregating a large block of opinions, we further apply our
technique for online opinion aggregation and for decision-making based on a
limited the number of opinions.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10388" title="Abstract">arXiv:2308.10388</a> [<a href="/pdf/2308.10388" title="Download PDF">pdf</a>, <a href="/format/2308.10388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Architectures Learning Fourier Transforms, Signal Processing and  Much More....
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Verma%2C+P">Prateek Verma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures. Technical Report at Stanford University; Presented on 14th August 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This report will explore and answer fundamental questions about taking
Fourier Transforms and tying it with recent advances in AI and neural
architecture. One interpretation of the Fourier Transform is decomposing a
signal into its constituent components by projecting them onto complex
exponentials. Variants exist, such as discrete cosine transform that does not
operate on the complex domain and projects an input signal to only cosine
functions oscillating at different frequencies. However, this is a fundamental
limitation, and it needs to be more suboptimal. The first one is that all
kernels are sinusoidal: What if we could have some kernels adapted or learned
according to the problem? What if we can use neural architectures for this? We
show how one can learn these kernels from scratch for audio signal processing
applications. We find that the neural architecture not only learns sinusoidal
kernel shapes but discovers all kinds of incredible signal-processing
properties. E.g., windowing functions, onset detectors, high pass filters, low
pass filters, modulations, etc. Further, upon analysis of the filters, we find
that the neural architecture has a comb filter-like structure on top of the
learned kernels. Comb filters that allow harmonic frequencies to pass through
are one of the core building blocks/types of filters similar to high-pass,
low-pass, and band-pass filters of various traditional signal processing
algorithms. Further, we can also use the convolution operation with a signal to
be learned from scratch, and we will explore papers in the literature that uses
this with that robust Transformer architectures. Further, we would also explore
making the learned kernel's content adaptive, i.e., learning different kernels
for different inputs.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10390" title="Abstract">arXiv:2308.10390</a> [<a href="/pdf/2308.10390" title="Download PDF">pdf</a>, <a href="/format/2308.10390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LibriSQA: Pioneering Free-form and Open-ended Spoken Question Answering  with a Novel Dataset and Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zihan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yiyang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Heyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">While Large Language Models (LLMs) have demonstrated commendable performance
across a myriad of domains and tasks, existing LLMs still exhibit a palpable
deficit in handling multimodal functionalities, especially for the Spoken
Question Answering (SQA) task which necessitates precise alignment and deep
interaction between speech and text features. To address the SQA challenge on
LLMs, we initially curated the free-form and open-ended LibriSQA dataset from
Librispeech, comprising Part I with natural conversational formats and Part II
encompassing multiple-choice questions followed by answers and analytical
segments. Both parts collectively include 107k SQA pairs that cover various
topics. Given the evident paucity of existing speech-text LLMs, we propose a
lightweight, end-to-end framework to execute the SQA task on the LibriSQA,
witnessing significant results. By reforming ASR into the SQA format, we
further substantiate our framework's capability in handling ASR tasks. Our
empirical findings bolster the LLMs' aptitude for aligning and comprehending
multimodal information, paving the way for the development of universal
multimodal LLMs. The dataset and demo can be found at
https://github.com/ZihanZhaoSJTU/LibriSQA.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10392" title="Abstract">arXiv:2308.10392</a> [<a href="/pdf/2308.10392" title="Download PDF">pdf</a>, <a href="/format/2308.10392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Generalizable Morph Attack Detection with Consistency  Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kashiani%2C+H">Hossein Kashiani</a>, 
<a href="/search/cs?searchtype=author&query=Talemi%2C+N+A">Niloufar Alipour Talemi</a>, 
<a href="/search/cs?searchtype=author&query=Saadabadi%2C+M+S+E">Mohammad Saeed Ebrahimi Saadabadi</a>, 
<a href="/search/cs?searchtype=author&query=Nasrabadi%2C+N+M">Nasser M. Nasrabadi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the IEEE International Joint Conference on Biometrics (IJCB), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Though recent studies have made significant progress in morph attack
detection by virtue of deep neural networks, they often fail to generalize well
to unseen morph attacks. With numerous morph attacks emerging frequently,
generalizable morph attack detection has gained significant attention. This
paper focuses on enhancing the generalization capability of morph attack
detection from the perspective of consistency regularization. Consistency
regularization operates under the premise that generalizable morph attack
detection should output consistent predictions irrespective of the possible
variations that may occur in the input space. In this work, to reach this
objective, two simple yet effective morph-wise augmentations are proposed to
explore a wide space of realistic morph transformations in our consistency
regularization. Then, the model is regularized to learn consistently at the
logit as well as embedding levels across a wide range of morph-wise augmented
images. The proposed consistency regularization aligns the abstraction in the
hidden layers of our model across the morph attack images which are generated
from diverse domains in the wild. Experimental results demonstrate the superior
generalization and robustness performance of our proposed method compared to
the state-of-the-art studies.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10393" title="Abstract">arXiv:2308.10393</a> [<a href="/pdf/2308.10393" title="Download PDF">pdf</a>, <a href="/format/2308.10393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robotic Planning under Hierarchical Temporal Logic Specifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xusheng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shaojun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruixuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Changliu Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Past research into robotic planning with temporal logic specifications,
notably Linear Temporal Logic (LTL), was largely based on singular formulas for
individual or groups of robots. But with increasing task complexity, LTL
formulas unavoidably grow lengthy, complicating interpretation and
specification generation, and straining the computational capacities of the
planners. In order to maximize the potential of LTL specifications, we
capitalized on the intrinsic structure of tasks and introduced a hierarchical
structure to LTL specifications. In contrast to the "flat" structure, our
hierarchical model has multiple levels of compositional specifications and
offers benefits such as greater syntactic brevity, improved interpretability,
and more efficient planning. To address tasks under this hierarchical temporal
logic structure, we formulated a decomposition-based method. Each specification
is first broken down into a range of temporally interrelated sub-tasks. We
further mine the temporal relations among the sub-tasks of different
specifications within the hierarchy. Subsequently, a Mixed Integer Linear
Program is utilized to generate a spatio-temporal plan for each robot. Our
hierarchical LTL specifications were experimentally applied to domains of
robotic navigation and manipulation. Results from extensive simulation studies
illustrated both the enhanced expressive potential of the hierarchical form and
the efficacy of the proposed method.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10396" title="Abstract">arXiv:2308.10396</a> [<a href="/pdf/2308.10396" title="Download PDF">pdf</a>, <a href="/format/2308.10396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Label Selection Approach to Learning from Crowds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoshimura%2C+K">Kosuke Yoshimura</a>, 
<a href="/search/cs?searchtype=author&query=Kashima%2C+H">Hisashi Kashima</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Supervised learning, especially supervised deep learning, requires large
amounts of labeled data. One approach to collect large amounts of labeled data
is by using a crowdsourcing platform where numerous workers perform the
annotation tasks. However, the annotation results often contain label noise, as
the annotation skills vary depending on the crowd workers and their ability to
complete the task correctly. Learning from Crowds is a framework which directly
trains the models using noisy labeled data from crowd workers. In this study,
we propose a novel Learning from Crowds model, inspired by SelectiveNet
proposed for the selective prediction problem. The proposed method called Label
Selection Layer trains a prediction model by automatically determining whether
to use a worker's label for training using a selector network. A major
advantage of the proposed method is that it can be applied to almost all
variants of supervised learning problems by simply adding a selector network
and changing the objective function for existing models, without explicitly
assuming a model of the noise in crowd annotations. The experimental results
show that the performance of the proposed method is almost equivalent to or
better than the Crowd Layer, which is one of the state-of-the-art methods for
Deep Learning from Crowds, except for the regression problem case.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10397" title="Abstract">arXiv:2308.10397</a> [<a href="/pdf/2308.10397" title="Download PDF">pdf</a>, <a href="/format/2308.10397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FairBench: A Four-Stage Automatic Framework for Detecting Stereotypes  and Biases in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yanhong Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiabao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jinxin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+T">Tingjiang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xingjiao Wu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Liang He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Detecting stereotypes and biases in Large Language Models (LLMs) can enhance
fairness and reduce adverse impacts on individuals or groups when these LLMs
are applied. However, the majority of existing methods focus on measuring the
model's preference towards sentences containing biases and stereotypes within
datasets, which lacks interpretability and cannot detect implicit biases and
stereotypes in the real world. To address this gap, this paper introduces a
four-stage framework to directly evaluate stereotypes and biases in the
generated content of LLMs, including direct inquiry testing, serial or adapted
story testing, implicit association testing, and unknown situation testing.
Additionally, the paper proposes multi-dimensional evaluation metrics and
explainable zero-shot prompts for automated evaluation. Using the education
sector as a case study, we constructed the Edu-FairBench based on the
four-stage framework, which encompasses 12,632 open-ended questions covering
nine sensitive factors and 26 educational scenarios. Experimental results
reveal varying degrees of stereotypes and biases in five LLMs evaluated on
Edu-FairBench. Moreover, the results of our proposed automated evaluation
method have shown a high correlation with human annotations.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10398" title="Abstract">arXiv:2308.10398</a> [<a href="/pdf/2308.10398" title="Download PDF">pdf</a>, <a href="/format/2308.10398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causally estimating the effect of YouTube&#x27;s recommender system using  counterfactual bots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hosseinmardi%2C+H">Homa Hosseinmardi</a>, 
<a href="/search/cs?searchtype=author&query=Ghasemian%2C+A">Amir Ghasemian</a>, 
<a href="/search/cs?searchtype=author&query=Rivera-Lanas%2C+M">Miguel Rivera-Lanas</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+M+H">Manoel Horta Ribeiro</a>, 
<a href="/search/cs?searchtype=author&query=West%2C+R">Robert West</a>, 
<a href="/search/cs?searchtype=author&query=Watts%2C+D+J">Duncan J. Watts</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">In recent years, critics of online platforms have raised concerns about the
ability of recommendation algorithms to amplify problematic content, with
potentially radicalizing consequences. However, attempts to evaluate the effect
of recommenders have suffered from a lack of appropriate counterfactuals --
what a user would have viewed in the absence of algorithmic recommendations --
and hence cannot disentangle the effects of the algorithm from a user's
intentions. Here we propose a method that we call "counterfactual bots" to
causally estimate the role of algorithmic recommendations on the consumption of
highly partisan content. By comparing bots that replicate real users'
consumption patterns with "counterfactual" bots that follow rule-based
trajectories, we show that, on average, relying exclusively on the recommender
results in less partisan consumption, where the effect is most pronounced for
heavy partisan consumers. Following a similar method, we also show that if
partisan consumers switch to moderate content, YouTube's sidebar recommender
"forgets" their partisan preference within roughly 30 videos regardless of
their prior history, while homepage recommendations shift more gradually
towards moderate content. Overall, our findings indicate that, at least on
YouTube, individual consumption patterns mostly reflect individual preferences,
where algorithmic recommendations play, if anything, a moderating role.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10401" title="Abstract">arXiv:2308.10401</a> [<a href="/pdf/2308.10401" title="Download PDF">pdf</a>, <a href="/format/2308.10401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-Free Large-Scale Cloth Spreading With Mobile Manipulation: Initial  Feasibility Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2B%2C+X">Xiangyu Chu+</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2B%2C+S">Shengzhi Wang+</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+M">Minjian Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jiaxi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuxuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Au%2C+K+W+S">K. W. Samuel Au</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures, submit to CASE2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE International Conference on Automation Science and
  Engineering (CASE)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Cloth manipulation is common in domestic and service tasks, and most studies
use fixed-base manipulators to manipulate objects whose sizes are relatively
small with respect to the manipulators' workspace, such as towels, shirts, and
rags. In contrast, manipulation of large-scale cloth, such as bed making and
tablecloth spreading, poses additional challenges of reachability and
manipulation control. To address them, this paper presents a novel framework to
spread large-scale cloth, with a single-arm mobile manipulator that can solve
the reachability issue, for an initial feasibility study. On the manipulation
control side, without modeling highly deformable cloth, a vision-based
manipulation control scheme is applied and based on an online-update Jacobian
matrix mapping from selected feature points to the end-effector motion. To
coordinate the control of the manipulator and mobile platform, Behavior Trees
(BTs) are used because of their modularity. Finally, experiments are conducted,
including validation of the model-free manipulation control for cloth spreading
in different conditions and the large-scale cloth spreading framework. The
experimental results demonstrate the large-scale cloth spreading task
feasibility with a single-arm mobile manipulator and the model-free deformation
controller.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10402" title="Abstract">arXiv:2308.10402</a> [<a href="/pdf/2308.10402" title="Download PDF">pdf</a>, <a href="/format/2308.10402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simple Baselines for Interactive Video Retrieval with Questions and  Answers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+K">Kaiqu Liang</a>, 
<a href="/search/cs?searchtype=author&query=Albanie%2C+S">Samuel Albanie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023, project page: <a href="https://github.com/kevinliang888/IVR-QA-baselines">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">To date, the majority of video retrieval systems have been optimized for a
"single-shot" scenario in which the user submits a query in isolation, ignoring
previous interactions with the system. Recently, there has been renewed
interest in interactive systems to enhance retrieval, but existing approaches
are complex and deliver limited gains in performance. In this work, we revisit
this topic and propose several simple yet effective baselines for interactive
video retrieval via question-answering. We employ a VideoQA model to simulate
user interactions and show that this enables the productive study of the
interactive retrieval task without access to ground truth dialogue data.
Experiments on MSR-VTT, MSVD, and AVSD show that our framework using
question-based interaction significantly improves the performance of text-based
video retrieval systems.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10407" title="Abstract">arXiv:2308.10407</a> [<a href="/pdf/2308.10407" title="Download PDF">pdf</a>, <a href="/format/2308.10407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning for Connected and Automated Vehicles: A Survey of  Existing Approaches and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chellapandi%2C+V+P">Vishnu Pandi Chellapandi</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Liangqi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Brinton%2C+C+G">Christopher G. Brinton</a>, 
<a href="/search/cs?searchtype=author&query=Zak%2C+S+H">Stanislaw H Zak</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziran Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Machine learning (ML) is widely used for key tasks in Connected and Automated
Vehicles (CAV), including perception, planning, and control. However, its
reliance on vehicular data for model training presents significant challenges
related to in-vehicle user privacy and communication overhead generated by
massive data volumes. Federated learning (FL) is a decentralized ML approach
that enables multiple vehicles to collaboratively develop models, broadening
learning from various driving environments, enhancing overall performance, and
simultaneously securing local vehicle data privacy and security. This survey
paper presents a review of the advancements made in the application of FL for
CAV (FL4CAV). First, centralized and decentralized frameworks of FL are
analyzed, highlighting their key characteristics and methodologies. Second,
diverse data sources, models, and data security techniques relevant to FL in
CAVs are reviewed, emphasizing their significance in ensuring privacy and
confidentiality. Third, specific and important applications of FL are explored,
providing insight into the base models and datasets employed for each
application. Finally, existing challenges for FL4CAV are listed and potential
directions for future work are discussed to further enhance the effectiveness
and efficiency of FL in the context of CAV.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10408" title="Abstract">arXiv:2308.10408</a> [<a href="/pdf/2308.10408" title="Download PDF">pdf</a>, <a href="/format/2308.10408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Turning a CLIP Model into a Scene Text Spotter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+W">Wenwen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xingkui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Haoyu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiang Bai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2302.14338">arXiv:2302.14338</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We exploit the potential of the large-scale Contrastive Language-Image
Pretraining (CLIP) model to enhance scene text detection and spotting tasks,
transforming it into a robust backbone, FastTCM-CR50. This backbone utilizes
visual prompt learning and cross-attention in CLIP to extract image and
text-based prior knowledge. Using predefined and learnable prompts,
FastTCM-CR50 introduces an instance-language matching process to enhance the
synergy between image and text embeddings, thereby refining text regions. Our
Bimodal Similarity Matching (BSM) module facilitates dynamic language prompt
generation, enabling offline computations and improving performance.
FastTCM-CR50 offers several advantages: 1) It can enhance existing text
detectors and spotters, improving performance by an average of 1.7% and 1.5%,
respectively. 2) It outperforms the previous TCM-CR50 backbone, yielding an
average improvement of 0.2% and 0.56% in text detection and spotting tasks,
along with a 48.5% increase in inference speed. 3) It showcases robust few-shot
training capabilities. Utilizing only 10% of the supervised data, FastTCM-CR50
improves performance by an average of 26.5% and 5.5% for text detection and
spotting tasks, respectively. 4) It consistently enhances performance on
out-of-distribution text detection and spotting datasets, particularly the
NightTime-ArT subset from ICDAR2019-ArT and the DOTA dataset for oriented
object detection. The code is available at https://github.com/wenwenyu/TCM.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10409" title="Abstract">arXiv:2308.10409</a> [<a href="/pdf/2308.10409" title="Download PDF">pdf</a>, <a href="/format/2308.10409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Development of a Novel Impedance-Controlled Quasi-Direct-Drive Robot  Hand
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Best%2C+J">Jay Best</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 75 pages, A Thesis in Partial Fulfillment of the Requirements for the Degree of Master of Science in Mechanical Engineering at Stony Brook University
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Most robotic hands and grippers rely on actuators with large gearboxes and
force sensors for controlling gripping force. However, this might not be ideal
for tasks which require the robot to interact with an unstructured and/or
unknown environment. We propose a novel quasi-direct-drive two-fingered robotic
hand with variable impedance control in the joint space and Cartesian space.
The hand has a total of four degrees of freedom, a backdrivable gear train, and
four brushless direct current (BLDC) motors. Field-Oriented Control (FOC) with
current sensing is used to control motor torques. Variable impedance control
allows the hand to perform dexterous manipulation tasks while being safe during
human-robot interaction. The quasi-direct-drive actuators enable the fingers to
handle contact with the environment without the need for complicated tactile or
force sensors. A majority 3D printed assembly makes this a low-cost research
platform built with affordable off-the-shelf components. The hand demonstrates
grasping with force-closure and form-closure, stable grasps in response to
disturbances, tasks exploiting contact with the environment, simple in-hand
manipulation, and a light touch for handling fragile objects.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10410" title="Abstract">arXiv:2308.10410</a> [<a href="/pdf/2308.10410" title="Download PDF">pdf</a>, <a href="/format/2308.10410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models on Wikipedia-Style Survey Generation: an  Evaluation in NLP Concepts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+F">Fan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Blum%2C+M">Moritz Blum</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jinghui Lu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+I">Irene Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have achieved significant success across various
natural language processing (NLP) tasks, encompassing question-answering,
summarization, and machine translation, among others. While LLMs excel in
general tasks, their efficacy in domain-specific applications remains under
exploration. Additionally, LLM-generated text sometimes exhibits issues like
hallucination and disinformation. In this study, we assess LLMs' capability of
producing concise survey articles within the computer science-NLP domain,
focusing on 20 chosen topics. Automated evaluations indicate that GPT-4
outperforms GPT-3.5 when benchmarked against the ground truth. Furthermore,
four human evaluators provide insights from six perspectives across four model
configurations. Through case studies, we demonstrate that while GPT often
yields commendable results, there are instances of shortcomings, such as
incomplete information and the exhibition of lapses in factual accuracy.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10411" title="Abstract">arXiv:2308.10411</a> [<a href="/pdf/2308.10411" title="Download PDF">pdf</a>, <a href="/format/2308.10411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Rack Test Tube Pose Estimation Using RGB-D Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+W">Weiwei Wan</a>, 
<a href="/search/cs?searchtype=author&query=Matsushita%2C+M">Masaki Matsushita</a>, 
<a href="/search/cs?searchtype=author&query=Kotaka%2C+T">Takeyuki Kotaka</a>, 
<a href="/search/cs?searchtype=author&query=Harada%2C+K">Kensuke Harada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submit to IEEE ROBIO 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Accurate robotic manipulation of test tubes in biology and medical industries
is becoming increasingly important to address workforce shortages and improve
worker safety. The detection and localization of test tubes are essential for
the robots to successfully manipulate test tubes. In this paper, we present a
framework to detect and estimate poses for the in-rack test tubes using color
and depth data. The methodology involves the utilization of a YOLO object
detector to effectively classify and localize both the test tubes and the tube
racks within the provided image data. Subsequently, the pose of the tube rack
is estimated through point cloud registration techniques. During the process of
estimating the poses of the test tubes, we capitalize on constraints derived
from the arrangement of rack slots. By employing an optimization-based
algorithm, we effectively evaluate and refine the pose of the test tubes. This
strategic approach ensures the robustness of pose estimation, even when
confronted with noisy and incomplete point cloud data.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10413" title="Abstract">arXiv:2308.10413</a> [<a href="/pdf/2308.10413" title="Download PDF">pdf</a>, <a href="/ps/2308.10413" title="Download PostScript">ps</a>, <a href="/format/2308.10413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mechanisms that play a game, not toss a coin
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Walsh%2C+T">Toby Walsh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Randomized mechanisms can have good normative properties compared to their
deterministic counterparts. However, randomized mechanisms are problematic in
several ways such as in their verifiability. We propose here to derandomize
such mechanisms by having agents play a game instead of tossing a coin. The
game is designed so an agent's best action is to play randomly, and this play
then injects ``randomness'' into the mechanism. This derandomization retains
many of the good normative properties of the original randomized mechanism but
gives a mechanism that is deterministic and easy, for instance, to audit. We
consider three related methods to derandomize randomized mechanism in six
different domains: voting, facility location, task allocation, school choice,
peer selection, and resource allocation. We propose a number of novel
derandomized mechanisms for these six domains with good normative properties.
Each mechanism has a mixed Nash equilibrium in which agents play a modular
arithmetic game with an uniform mixed strategy. In all but one mixed Nash
equilibrium, agents report their preferences over the original problem
sincerely. The derandomized methods are thus ``quasi-strategy proof''. In one
domain, we additionally show that a new and desirable normative property
emerges as a result of derandomization.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10415" title="Abstract">arXiv:2308.10415</a> [<a href="/pdf/2308.10415" title="Download PDF">pdf</a>, <a href="/format/2308.10415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TokenSplit: Using Discrete Speech Representations for Direct, Refined,  and Transcript-Conditioned Speech Separation and Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Erdogan%2C+H">Hakan Erdogan</a>, 
<a href="/search/cs?searchtype=author&query=Wisdom%2C+S">Scott Wisdom</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xuankai Chang</a>, 
<a href="/search/cs?searchtype=author&query=Borsos%2C+Z">Zal&#xe1;n Borsos</a>, 
<a href="/search/cs?searchtype=author&query=Tagliasacchi%2C+M">Marco Tagliasacchi</a>, 
<a href="/search/cs?searchtype=author&query=Zeghidour%2C+N">Neil Zeghidour</a>, 
<a href="/search/cs?searchtype=author&query=Hershey%2C+J+R">John R. Hershey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> INTERSPEECH 2023, project webpage with audio demos at <a href="https://google-research.github.io/sound-separation/papers/tokensplit">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We present TokenSplit, a speech separation model that acts on discrete token
sequences. The model is trained on multiple tasks simultaneously: separate and
transcribe each speech source, and generate speech from text. The model
operates on transcripts and audio token sequences and achieves multiple tasks
through masking of inputs. The model is a sequence-to-sequence encoder-decoder
model that uses the Transformer architecture. We also present a "refinement"
version of the model that predicts enhanced audio tokens from the audio tokens
of speech separated by a conventional separation model. Using both objective
metrics and subjective MUSHRA listening tests, we show that our model achieves
excellent performance in terms of separation, both with or without transcript
conditioning. We also measure the automatic speech recognition (ASR)
performance and provide audio samples of speech synthesis to demonstrate the
additional utility of our model.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10417" title="Abstract">arXiv:2308.10417</a> [<a href="/pdf/2308.10417" title="Download PDF">pdf</a>, <a href="/format/2308.10417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Change You Want to See (Now in 3D)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sachdeva%2C+R">Ragav Sachdeva</a>, 
<a href="/search/cs?searchtype=author&query=Zisserman%2C+A">Andrew Zisserman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The goal of this paper is to detect what has changed, if anything, between
two "in the wild" images of the same 3D scene acquired from different camera
positions and at different temporal instances. The open-set nature of this
problem, occlusions/dis-occlusions due to the shift in viewpoint, and the lack
of suitable training datasets, presents substantial challenges in devising a
solution.
<br />To address this problem, we contribute a change detection model that is
trained entirely on synthetic data and is class-agnostic, yet it is performant
out-of-the-box on real world images without requiring fine-tuning. Our solution
entails a "register and difference" approach that leverages self-supervised
frozen embeddings and feature differences, which allows the model to generalise
to a wide variety of scenes and domains. The model is able to operate directly
on two RGB images, without requiring access to ground truth camera intrinsics,
extrinsics, depth maps, point clouds, or additional before-after images.
Finally, we collect and release a new evaluation dataset consisting of
real-world image pairs with human-annotated differences and demonstrate the
efficacy of our method. The code, datasets and pre-trained model can be found
at: https://github.com/ragavsachdeva/CYWS-3D
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10421" title="Abstract">arXiv:2308.10421</a> [<a href="/pdf/2308.10421" title="Download PDF">pdf</a>, <a href="/format/2308.10421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniM$^2$AE: Multi-modal Masked Autoencoders with Unified 3D  Representation for 3D Perception in Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">Jian Zou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tianyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guanglei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhenhua Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+W">Wangmeng Zuo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code available at <a href="https://github.com/hollow-503/UniM2AE">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Masked Autoencoders (MAE) play a pivotal role in learning potent
representations, delivering outstanding results across various 3D perception
tasks essential for autonomous driving. In real-world driving scenarios, it's
commonplace to deploy multiple sensors for comprehensive environment
perception. While integrating multi-modal features from these sensors can
produce rich and powerful features, there is a noticeable gap in MAE methods
addressing this integration. This research delves into multi-modal Masked
Autoencoders tailored for a unified representation space in autonomous driving,
aiming to pioneer a more efficient fusion of two distinct modalities. To
intricately marry the semantics inherent in images with the geometric
intricacies of LiDAR point clouds, the UniM$^2$AE is proposed. This model
stands as a potent yet straightforward, multi-modal self-supervised
pre-training framework, mainly consisting of two designs. First, it projects
the features from both modalities into a cohesive 3D volume space, ingeniously
expanded from the bird's eye view (BEV) to include the height dimension. The
extension makes it possible to back-project the informative features, obtained
by fusing features from both modalities, into their native modalities to
reconstruct the multiple masked inputs. Second, the Multi-modal 3D Interactive
Module (MMIM) is invoked to facilitate the efficient inter-modal interaction
during the interaction process. Extensive experiments conducted on the nuScenes
Dataset attest to the efficacy of UniM$^2$AE, indicating enhancements in 3D
object detection and BEV map segmentation by 1.2\%(NDS) and 6.5\% (mIoU),
respectively. Code is available at https://github.com/hollow-503/UniM2AE.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10422" title="Abstract">arXiv:2308.10422</a> [<a href="/pdf/2308.10422" title="Download PDF">pdf</a>, <a href="/format/2308.10422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Split Unlearning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Guangsheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Caijun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> An earlier edition, with extensive experiments being conducted for the forthcoming full version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Split learning is emerging as a powerful approach to decentralized machine
learning, but the urgent task of unlearning to address privacy issues presents
significant challenges. Conventional methods of retraining from scratch or
gradient ascending require all clients' involvement, incurring high
computational and communication overhead, particularly in public networks where
clients lack resources and may be reluctant to participate in unlearning
processes they have no interest. In this short article, we propose
\textsc{SplitWiper}, a new framework that integrates the concept of SISA to
reduce retraining costs and ensures no interference between the unlearning
client and others in public networks. Recognizing the inherent sharding in
split learning, we first establish the SISA-based design of
\textsc{SplitWiper}. This forms the premise for conceptualizing two unlearning
strategies for label-sharing and non-label-sharing scenarios. This article
represents an earlier edition, with extensive experiments being conducted for
the forthcoming full version.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10424" title="Abstract">arXiv:2308.10424</a> [<a href="/pdf/2308.10424" title="Download PDF">pdf</a>, <a href="/format/2308.10424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attenuation and Loss of Spatial Coherence Modeling for Atmospheric  Turbulence in Terahertz UAV MIMO Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gao%2C+W">Weijun Gao</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+C">Chong Han</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Z">Zhi Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2305.08820">arXiv:2305.08820</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Terahertz (THz) wireless communications have the potential to realize
ultra-high-speed and secure data transfer with miniaturized devices for
unmanned aerial vehicle (UAV) communications. The atmospheric turbulence due to
random airflow leads to spatial inhomogeneity of the communication medium,
which is yet missing in most existing studies, leading to additional
propagation loss and even loss of spatial coherence (LoSC) in MIMO systems. In
this paper, the attenuation and loss of spatial coherence for atmospheric
turbulence are modeled in THz UAV MIMO channels. Specifically, the frequency-
and altitude-dependency of the refractive index structure constant (RISC), as a
critical statistical parameter characterizing the intensity of turbulence, is
first investigated. Then, the LoSC, fading, and attenuation caused by
atmospheric turbulence are modeled, where the turbulence-induced fading is
modeled by a Gamma-Gamma distribution, and the turbulence attenuation as a
function of altitude and frequency is derived. Numerical results show that the
turbulence leads to at most 10 dB attenuation with frequency less than 1 THz
and distance less than 10 km. Furthermore, when the distance is 10 km and the
RISC is 10^-9m^(-2/3), the loss of spatial coherence effect leads to 10 dB
additional loss for a 1024*1024 ultra-massive MIMO system.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10425" title="Abstract">arXiv:2308.10425</a> [<a href="/pdf/2308.10425" title="Download PDF">pdf</a>, <a href="/format/2308.10425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatio-Temporal Adaptive Embedding Makes Vanilla Transformer SOTA for  Traffic Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hangchen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zheng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+R">Renhe Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jiewen Deng</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jinliang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Quanjun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xuan Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as CIKM2023 Short Paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">With the rapid development of the Intelligent Transportation System (ITS),
accurate traffic forecasting has emerged as a critical challenge. The key
bottleneck lies in capturing the intricate spatio-temporal traffic patterns. In
recent years, numerous neural networks with complicated architectures have been
proposed to address this issue. However, the advancements in network
architectures have encountered diminishing performance gains. In this study, we
present a novel component called spatio-temporal adaptive embedding that can
yield outstanding results with vanilla transformers. Our proposed
Spatio-Temporal Adaptive Embedding transformer (STAEformer) achieves
state-of-the-art performance on five real-world traffic forecasting datasets.
Further experiments demonstrate that spatio-temporal adaptive embedding plays a
crucial role in traffic forecasting by effectively capturing intrinsic
spatio-temporal relations and chronological information in traffic time series.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10427" title="Abstract">arXiv:2308.10427</a> [<a href="/pdf/2308.10427" title="Download PDF">pdf</a>, <a href="/format/2308.10427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning Robust to Byzantine Attacks: Achieving Zero  Optimality Gap
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zuo%2C+S">Shiyuan Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+R">Rongfei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Han Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+S">Shimin Gong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In this paper, we propose a robust aggregation method for federated learning
(FL) that can effectively tackle malicious Byzantine attacks. At each user,
model parameter is firstly updated by multiple steps, which is adjustable over
iterations, and then pushed to the aggregation center directly. This decreases
the number of interactions between the aggregation center and users, allows
each user to set training parameter in a flexible way, and reduces computation
burden compared with existing works that need to combine multiple historical
model parameters. At the aggregation center, geometric median is leveraged to
combine the received model parameters from each user. Rigorous proof shows that
zero optimality gap is achieved by our proposed method with linear convergence,
as long as the fraction of Byzantine attackers is below half. Numerical results
verify the effectiveness of our proposed method.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10435" title="Abstract">arXiv:2308.10435</a> [<a href="/pdf/2308.10435" title="Download PDF">pdf</a>, <a href="/format/2308.10435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPT-in-the-Loop: Adaptive Decision-Making for Multiagent Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nascimento%2C+N">Nathalia Nascimento</a>, 
<a href="/search/cs?searchtype=author&query=Alencar%2C+P">Paulo Alencar</a>, 
<a href="/search/cs?searchtype=author&query=Cowan%2C+D">Donald Cowan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Software Engineering (cs.SE)

</div>
<p class="mathjax">This paper introduces the "GPT-in-the-loop" approach, a novel method
combining the advanced reasoning capabilities of Large Language Models (LLMs)
like Generative Pre-trained Transformers (GPT) with multiagent (MAS) systems.
Venturing beyond traditional adaptive approaches that generally require long
training processes, our framework employs GPT-4 for enhanced problem-solving
and explanation skills. Our experimental backdrop is the smart streetlight
Internet of Things (IoT) application. Here, agents use sensors, actuators, and
neural networks to create an energy-efficient lighting system. By integrating
GPT-4, these agents achieve superior decision-making and adaptability without
the need for extensive training. We compare this approach with both traditional
neuroevolutionary methods and solutions provided by software engineers,
underlining the potential of GPT-driven multiagent systems in IoT.
Structurally, the paper outlines the incorporation of GPT into the agent-driven
Framework for the Internet of Things (FIoT), introduces our proposed
GPT-in-the-loop approach, presents comparative results in the IoT context, and
concludes with insights and future directions.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10438" title="Abstract">arXiv:2308.10438</a> [<a href="/pdf/2308.10438" title="Download PDF">pdf</a>, <a href="/format/2308.10438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Joint Optimization of Layer-Adaptive Weight Pruning in Deep  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kaixin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+X">Xue Geng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Min Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoli Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weisi Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we propose a novel layer-adaptive weight-pruning approach for
Deep Neural Networks (DNNs) that addresses the challenge of optimizing the
output distortion minimization while adhering to a target pruning ratio
constraint. Our approach takes into account the collective influence of all
layers to design a layer-adaptive pruning scheme. We discover and utilize a
very important additivity property of output distortion caused by pruning
weights on multiple layers. This property enables us to formulate the pruning
as a combinatorial optimization problem and efficiently solve it through
dynamic programming. By decomposing the problem into sub-problems, we achieve
linear time complexity, making our optimization algorithm fast and feasible to
run on CPUs. Our extensive experiments demonstrate the superiority of our
approach over existing methods on the ImageNet and CIFAR-10 datasets. On
CIFAR-10, our method achieves remarkable improvements, outperforming others by
up to 1.0% for ResNet-32, 0.5% for VGG-16, and 0.7% for DenseNet-121 in terms
of top-1 accuracy. On ImageNet, we achieve up to 4.7% and 4.6% higher top-1
accuracy compared to other methods for VGG-16 and ResNet-50, respectively.
These results highlight the effectiveness and practicality of our approach for
enhancing DNN performance through layer-adaptive weight pruning. Code will be
available on https://github.com/Akimoto-Cris/RD_VIT_PRUNE.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10439" title="Abstract">arXiv:2308.10439</a> [<a href="/pdf/2308.10439" title="Download PDF">pdf</a>, <a href="/format/2308.10439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Approximation of Singular Functions by Series of Non-integer  Powers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhao%2C+M">Mohan Zhao</a>, 
<a href="/search/math?searchtype=author&query=Serkh%2C+K">Kirill Serkh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we describe an algorithm for approximating functions of the
form $f(x)=\int_{a}^{b} x^{\mu} \sigma(\mu) \, d \mu$ over $[0,1] \subset
\mathbb{R}$, where $0&lt;a&lt;b&lt;\infty$ and $\sigma(\mu)$ is some signed Radon
measure over $[a,b]$ or some distribution supported on $[a,b]$. Given the
desired accuracy $\epsilon$ and the values of $a$ and $b$, our method
determines a priori a collection of non-integer powers $\{t_j\}_{j=1}^N$, so
that the functions are approximated by series of the form $f(x)\approx
\sum_{j=1}^N c_j x^{t_j}$, where the expansion coefficients can be found by
solving a square, low-dimensional Vandermonde-like linear system using the
collocation points $\{x_j\}_{j=1}^N$, also determined a priori by $\epsilon$
and the values of $a$ and $b$. We prove that our method has a small uniform
approximation error which is proportional to $\epsilon$ multiplied by some
small constants. We demonstrate the performance of our algorithm with several
numerical experiments, and show that the number of singular powers and
collocation points grows as $N=O(\log{\frac{1}{\epsilon}})$.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10441" title="Abstract">arXiv:2308.10441</a> [<a href="/pdf/2308.10441" title="Download PDF">pdf</a>, <a href="/format/2308.10441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> X-VoE: Measuring eXplanatory Violation of Expectation in Physical Events
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bo Dai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Linge Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+B">Baoxiong Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Song-Chun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yixin Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 16 figures, selected for an Oral presentation at ICCV 2023. Project link: <a href="https://pku.ai/publication/intuitive2023iccv/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Intuitive physics is pivotal for human understanding of the physical world,
enabling prediction and interpretation of events even in infancy. Nonetheless,
replicating this level of intuitive physics in artificial intelligence (AI)
remains a formidable challenge. This study introduces X-VoE, a comprehensive
benchmark dataset, to assess AI agents' grasp of intuitive physics. Built on
the developmental psychology-rooted Violation of Expectation (VoE) paradigm,
X-VoE establishes a higher bar for the explanatory capacities of intuitive
physics models. Each VoE scenario within X-VoE encompasses three distinct
settings, probing models' comprehension of events and their underlying
explanations. Beyond model evaluation, we present an explanation-based learning
system that captures physics dynamics and infers occluded object states solely
from visual sequences, without explicit occlusion labels. Experimental outcomes
highlight our model's alignment with human commonsense when tested against
X-VoE. A remarkable feature is our model's ability to visually expound VoE
events by reconstructing concealed scenes. Concluding, we discuss the findings'
implications and outline future research directions. Through X-VoE, we catalyze
the advancement of AI endowed with human-like intuitive physics capabilities.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10442" title="Abstract">arXiv:2308.10442</a> [<a href="/pdf/2308.10442" title="Download PDF">pdf</a>, <a href="/format/2308.10442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DySuse: Susceptibility Estimation in Dynamic Social Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yingdan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingya Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Congcong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been published in Expert Systems With Applications
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Expert Systems With Applications (ESWA), 2023, 234:121042
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Influence estimation aims to predict the total influence spread in social
networks and has received surged attention in recent years. Most current
studies focus on estimating the total number of influenced users in a social
network, and neglect susceptibility estimation that aims to predict the
probability of each user being influenced from the individual perspective. As a
more fine-grained estimation task, susceptibility estimation is full of
attractiveness and practical value. Based on the significance of susceptibility
estimation and dynamic properties of social networks, we propose a task, called
susceptibility estimation in dynamic social networks, which is even more
realistic and valuable in real-world applications. Susceptibility estimation in
dynamic networks has yet to be explored so far and is computationally
intractable to naively adopt Monte Carlo simulation to obtain the results. To
this end, we propose a novel end-to-end framework DySuse based on dynamic graph
embedding technology. Specifically, we leverage a structural feature module to
independently capture the structural information of influence diffusion on each
single graph snapshot. Besides, {we propose the progressive mechanism according
to the property of influence diffusion,} to couple the structural and temporal
information during diffusion tightly. Moreover, a self-attention block {is
designed to} further capture temporal dependency by flexibly weighting
historical timestamps. Experimental results show that our framework is superior
to the existing dynamic graph embedding models and has satisfactory prediction
performance in multiple influence diffusion models.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10443" title="Abstract">arXiv:2308.10443</a> [<a href="/pdf/2308.10443" title="Download PDF">pdf</a>, <a href="/format/2308.10443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Large Language Models for Cybersecurity Capture-The-Flag  Challenges and Certification Questions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tann%2C+W">Wesley Tann</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuancheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sim%2C+J+H">Jun Heng Sim</a>, 
<a href="/search/cs?searchtype=author&query=Seah%2C+C+M">Choon Meng Seah</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+E">Ee-Chien Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY)

</div>
<p class="mathjax">The assessment of cybersecurity Capture-The-Flag (CTF) exercises involves
participants finding text strings or ``flags'' by exploiting system
vulnerabilities. Large Language Models (LLMs) are natural-language models
trained on vast amounts of words to understand and generate text; they can
perform well on many CTF challenges. Such LLMs are freely available to
students. In the context of CTF exercises in the classroom, this raises
concerns about academic integrity. Educators must understand LLMs' capabilities
to modify their teaching to accommodate generative AI assistance. This research
investigates the effectiveness of LLMs, particularly in the realm of CTF
challenges and questions. Here we evaluate three popular LLMs, OpenAI ChatGPT,
Google Bard, and Microsoft Bing. First, we assess the LLMs' question-answering
performance on five Cisco certifications with varying difficulty levels. Next,
we qualitatively study the LLMs' abilities in solving CTF challenges to
understand their limitations. We report on the experience of using the LLMs for
seven test cases in all five types of CTF challenges. In addition, we
demonstrate how jailbreak prompts can bypass and break LLMs' ethical
safeguards. The paper concludes by discussing LLM's impact on CTF exercises and
its implications.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10444" title="Abstract">arXiv:2308.10444</a> [<a href="/pdf/2308.10444" title="Download PDF">pdf</a>, <a href="/format/2308.10444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Strategy Chain: Dynamic Zero-Shot CoT for Long Mental Health  Support Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dexi Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Long counseling Text Generation for Mental health support (LTGM), an
innovative and challenging task, aims to provide help-seekers with mental
health support through a comprehensive and more acceptable response. The
combination of chain-of-thought (CoT) prompting and Large Language Models
(LLMs) is employed and get the SOTA performance on various NLP tasks,
especially on text generation tasks. Zero-shot CoT prompting is one of the most
common methods in CoT prompting. However, in the LTGM task, Zero-shot CoT
prompting can not simulate a counselor or provide personalized strategies
without effective mental health counseling strategy prompts. To tackle this
challenge, we propose a zero-shot Dynamic Strategy Chain (DSC) prompting
method. Firstly, we utilize GPT2 to learn the responses written by mental
health counselors and dynamically generate mental health counseling strategies
tailored to the help-seekers' needs. Secondly, the Zero-shot DSC prompting is
constructed according to mental health counseling strategies and the
help-seekers' post. Finally, the Zero-shot DSC prompting is employed to guide
LLMs in generating more human-like responses for the help-seekers. Both
automatic and manual evaluations demonstrate that Zero-shot DSC prompting can
deliver more human-like responses than CoT prompting methods on LTGM tasks.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10445" title="Abstract">arXiv:2308.10445</a> [<a href="/pdf/2308.10445" title="Download PDF">pdf</a>, <a href="/format/2308.10445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Prompt-based Incremental Learning Does Not Meet Strong Pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yu-Ming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yi-Xing Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Wei-Shi Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Incremental learning aims to overcome catastrophic forgetting when learning
deep networks from sequential tasks. With impressive learning efficiency and
performance, prompt-based methods adopt a fixed backbone to sequential tasks by
learning task-specific prompts. However, existing prompt-based methods heavily
rely on strong pretraining (typically trained on ImageNet-21k), and we find
that their models could be trapped if the potential gap between the pretraining
task and unknown future tasks is large. In this work, we develop a learnable
Adaptive Prompt Generator (APG). The key is to unify the prompt retrieval and
prompt learning processes into a learnable prompt generator. Hence, the whole
prompting process can be optimized to reduce the negative effects of the gap
between tasks effectively. To make our APG avoid learning ineffective
knowledge, we maintain a knowledge pool to regularize APG with the feature
distribution of each class. Extensive experiments show that our method
significantly outperforms advanced methods in exemplar-free incremental
learning without (strong) pretraining. Besides, under strong retraining, our
method also has comparable performance to existing prompt-based models, showing
that our method can still benefit from pretraining. Codes can be found at
https://github.com/TOM-tym/APG
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10446" title="Abstract">arXiv:2308.10446</a> [<a href="/pdf/2308.10446" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LDCSF: Local depth convolution-based Swim framework for classifying  multi-label histopathology images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Liangrui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Y">Yutao Dou</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhichao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Liwen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Shaoliang Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to BIBM2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Histopathological images are the gold standard for diagnosing liver cancer.
However, the accuracy of fully digital diagnosis in computational pathology
needs to be improved. In this paper, in order to solve the problem of
multi-label and low classification accuracy of histopathology images, we
propose a locally deep convolutional Swim framework (LDCSF) to classify
multi-label histopathology images. In order to be able to provide local field
of view diagnostic results, we propose the LDCSF model, which consists of a
Swin transformer module, a local depth convolution (LDC) module, a feature
reconstruction (FR) module, and a ResNet module. The Swin transformer module
reduces the amount of computation generated by the attention mechanism by
limiting the attention to each window. The LDC then reconstructs the attention
map and performs convolution operations in multiple channels, passing the
resulting feature map to the next layer. The FR module uses the corresponding
weight coefficient vectors obtained from the channels to dot product with the
original feature map vector matrix to generate representative feature maps.
Finally, the residual network undertakes the final classification task. As a
result, the classification accuracy of LDCSF for interstitial area, necrosis,
non-tumor and tumor reached 0.9460, 0.9960, 0.9808, 0.9847, respectively.
Finally, we use the results of multi-label pathological image classification to
calculate the tumor-to-stromal ratio, which lays the foundation for the
analysis of the microenvironment of liver cancer histopathological images.
Second, we released a multilabel histopathology image of liver cancer, our code
and data are available at https://github.com/panliangrui/LSF.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10447" title="Abstract">arXiv:2308.10447</a> [<a href="/pdf/2308.10447" title="Download PDF">pdf</a>, <a href="/format/2308.10447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explore and Tell: Embodied Visual Captioning in 3D Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+A">Anwen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shizhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Q">Qin Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages; 10 figures; ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While current visual captioning models have achieved impressive performance,
they often assume that the image is well-captured and provides a complete view
of the scene. In real-world scenarios, however, a single image may not offer a
good viewpoint, hindering fine-grained scene understanding. To overcome this
limitation, we propose a novel task called Embodied Captioning, which equips
visual captioning models with navigation capabilities, enabling them to
actively explore the scene and reduce visual ambiguity from suboptimal
viewpoints. Specifically, starting at a random viewpoint, an agent must
navigate the environment to gather information from different viewpoints and
generate a comprehensive paragraph describing all objects in the scene. To
support this task, we build the ET-Cap dataset with Kubric simulator,
consisting of 10K 3D scenes with cluttered objects and three annotated
paragraphs per scene. We propose a Cascade Embodied Captioning model (CaBOT),
which comprises of a navigator and a captioner, to tackle this task. The
navigator predicts which actions to take in the environment, while the
captioner generates a paragraph description based on the whole navigation
trajectory. Extensive experiments demonstrate that our model outperforms other
carefully designed baselines. Our dataset, codes and models are available at
https://aim3-ruc.github.io/ExploreAndTell.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10449" title="Abstract">arXiv:2308.10449</a> [<a href="/pdf/2308.10449" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CVFC: Attention-Based Cross-View Feature Consistency for Weakly  Supervised Semantic Segmentation of Pathology Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Liangrui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhichao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Liwen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Shaoliang Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to BIBM2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Histopathology image segmentation is the gold standard for diagnosing cancer,
and can indicate cancer prognosis. However, histopathology image segmentation
requires high-quality masks, so many studies now use imagelevel labels to
achieve pixel-level segmentation to reduce the need for fine-grained
annotation. To solve this problem, we propose an attention-based cross-view
feature consistency end-to-end pseudo-mask generation framework named CVFC
based on the attention mechanism. Specifically, CVFC is a three-branch joint
framework composed of two Resnet38 and one Resnet50, and the independent branch
multi-scale integrated feature map to generate a class activation map (CAM); in
each branch, through down-sampling and The expansion method adjusts the size of
the CAM; the middle branch projects the feature matrix to the query and key
feature spaces, and generates a feature space perception matrix through the
connection layer and inner product to adjust and refine the CAM of each branch;
finally, through the feature consistency loss and feature cross loss to
optimize the parameters of CVFC in co-training mode. After a large number of
experiments, An IoU of 0.7122 and a fwIoU of 0.7018 are obtained on the
WSSS4LUAD dataset, which outperforms HistoSegNet, SEAM, C-CAM, WSSS-Tissue, and
OEEM, respectively.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10450" title="Abstract">arXiv:2308.10450</a> [<a href="/pdf/2308.10450" title="Download PDF">pdf</a>, <a href="/format/2308.10450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COCA: Classifier-Oriented Calibration for Source-Free Universal Domain  Adaptation via Textual Prototype
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinghong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chun-Mei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+L">Ling Shao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Universal Domain Adaptation (UniDA) aims to distinguish common and private
classes between the source and target domains where domain shift exists.
Recently, due to more stringent data restrictions, researchers have introduced
Source-Free UniDA (SF-UniDA) in more realistic scenarios. SF-UniDA methods
eliminate the need for direct access to source samples when performing
adaptation to the target domain. However, existing SF-UniDA methods still
require an extensive quantity of labeled source samples to train a source
model, resulting in significant labeling costs. To tackle this issue, we
present a novel Classifier-Oriented Calibration (COCA) method. This method,
which leverages textual prototypes, is formulated for the source model based on
few-shot learning. Specifically, we propose studying few-shot learning, usually
explored for closed-set scenarios, to identify common and domain-private
classes despite a significant domain shift between source and target domains.
Essentially, we present a novel paradigm based on the vision-language model to
learn SF-UniDA and hugely reduce the labeling costs on the source domain.
Experimental results demonstrate that our approach outperforms state-of-the-art
UniDA and SF-UniDA models.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10451" title="Abstract">arXiv:2308.10451</a> [<a href="/pdf/2308.10451" title="Download PDF">pdf</a>, <a href="/format/2308.10451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Game-theoretical approach for task allocation problems with constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chunxia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+K">Kaihong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaojie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Szolnoki%2C+A">Attila Szolnoki</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Applied Mathematics and Computation 458 (2023) 128251
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">The distributed task allocation problem, as one of the most interesting
distributed optimization challenges, has received considerable research
attention recently. Previous works mainly focused on the task allocation
problem in a population of individuals, where there are no constraints for
affording task amounts. The latter condition, however, cannot always be hold.
In this paper, we study the task allocation problem with constraints of task
allocation in a game-theoretical framework. We assume that each individual can
afford different amounts of task and the cost function is convex. To
investigate the problem in the framework of population games, we construct a
potential game and calculate the fitness function for each individual. We prove
that when the Nash equilibrium point in the potential game is in the feasible
solutions for the limited task allocation problem, the Nash equilibrium point
is the unique globally optimal solution. Otherwise, we also derive analytically
the unique globally optimal solution. In addition, in order to confirm our
theoretical results, we consider the exponential and quadratic forms of cost
function for each agent. Two algorithms with the mentioned representative cost
functions are proposed to numerically seek the optimal solution to the limited
task problems. We further perform Monte Carlo simulations which provide
agreeing results with our analytical calculations.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10452" title="Abstract">arXiv:2308.10452</a> [<a href="/pdf/2308.10452" title="Download PDF">pdf</a>, <a href="/format/2308.10452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing Measures of Linguistic Diversity Across Social Media Language  Data and Census Data at Subnational Geographic Areas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wong%2C+S+G+-">Sidney G.-J. Wong</a>, 
<a href="/search/cs?searchtype=author&query=Dunn%2C+J">Jonathan Dunn</a>, 
<a href="/search/cs?searchtype=author&query=Adams%2C+B">Benjamin Adams</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper describes a preliminary study on the comparative linguistic
ecology of online spaces (i.e., social media language data) and real-world
spaces in Aotearoa New Zealand (i.e., subnational administrative areas). We
compare measures of linguistic diversity between these different spaces and
discuss how social media users align with real-world populations. The results
from the current study suggests that there is potential to use online social
media language data to observe spatial and temporal changes in linguistic
diversity at subnational geographic areas; however, further work is required to
understand how well social media represents real-world behaviour.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10453" title="Abstract">arXiv:2308.10453</a> [<a href="/pdf/2308.10453" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DOMINO++: Domain-aware Loss Regularization for Deep Learning  Generalizability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stolte%2C+S+E">Skylar E. Stolte</a>, 
<a href="/search/cs?searchtype=author&query=Volle%2C+K">Kyle Volle</a>, 
<a href="/search/cs?searchtype=author&query=Indahlastari%2C+A">Aprinda Indahlastari</a>, 
<a href="/search/cs?searchtype=author&query=Albizu%2C+A">Alejandro Albizu</a>, 
<a href="/search/cs?searchtype=author&query=Woods%2C+A+J">Adam J. Woods</a>, 
<a href="/search/cs?searchtype=author&query=Brink%2C+K">Kevin Brink</a>, 
<a href="/search/cs?searchtype=author&query=Hale%2C+M">Matthew Hale</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+R">Ruogu Fang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures, 5 tables, Accepted by the International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Out-of-distribution (OOD) generalization poses a serious challenge for modern
deep learning (DL). OOD data consists of test data that is significantly
different from the model's training data. DL models that perform well on
in-domain test data could struggle on OOD data. Overcoming this discrepancy is
essential to the reliable deployment of DL. Proper model calibration decreases
the number of spurious connections that are made between model features and
class outputs. Hence, calibrated DL can improve OOD generalization by only
learning features that are truly indicative of the respective classes. Previous
work proposed domain-aware model calibration (DOMINO) to improve DL
calibration, but it lacks designs for model generalizability to OOD data. In
this work, we propose DOMINO++, a dual-guidance and dynamic domain-aware loss
regularization focused on OOD generalizability. DOMINO++ integrates
expert-guided and data-guided knowledge in its regularization. Unlike DOMINO
which imposed a fixed scaling and regularization rate, DOMINO++ designs a
dynamic scaling factor and an adaptive regularization rate. Comprehensive
evaluations compare DOMINO++ with DOMINO and the baseline model for head tissue
segmentation from magnetic resonance images (MRIs) on OOD data. The OOD data
consists of synthetic noisy and rotated datasets, as well as real data using a
different MRI scanner from a separate site. DOMINO++'s superior performance
demonstrates its potential to improve the trustworthy deployment of DL on real
clinical data.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10454" title="Abstract">arXiv:2308.10454</a> [<a href="/pdf/2308.10454" title="Download PDF">pdf</a>, <a href="/format/2308.10454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Elucidating STEM Concepts through Generative AI: A Multi-modal  Exploration of Analogical Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+C">Chen Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zijian Ding</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+G">Gyeong-Geon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+J">Jiajun Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jionghao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaoming Zhai</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IJCAI2023 Symposium on Multimodal Reasoning with LLM
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">This study explores the integration of generative artificial intelligence
(AI), specifically large language models, with multi-modal analogical reasoning
as an innovative approach to enhance science, technology, engineering, and
mathematics (STEM) education. We have developed a novel system that utilizes
the capacities of generative AI to transform intricate principles in
mathematics, physics, and programming into comprehensible metaphors. To further
augment the educational experience, these metaphors are subsequently converted
into visual form. Our study aims to enhance the learners' understanding of STEM
concepts and their learning engagement by using the visual metaphors. We
examine the efficacy of our system via a randomized A/B/C test, assessing
learning gains and motivation shifts among the learners. Our study demonstrates
the potential of applying large language models to educational practice on STEM
subjects. The results will shed light on the design of educational system in
terms of harnessing AI's potential to empower educational stakeholders.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10457" title="Abstract">arXiv:2308.10457</a> [<a href="/pdf/2308.10457" title="Download PDF">pdf</a>, <a href="/format/2308.10457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Local Steps Federated Learning with Differential Privacy Driven  by Convergence Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ling%2C+X">Xinpeng Ling</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhili Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Federated Learning (FL) is a distributed machine learning technique that
allows model training among multiple devices or organizations without sharing
data. However, while FL ensures that the raw data is not directly accessible to
external adversaries, adversaries can still obtain some statistical information
about the data through differential attacks. Differential Privacy (DP) has been
proposed, which adds noise to the model or gradients to prevent adversaries
from inferring private information from the transmitted parameters. We
reconsider the framework of differential privacy federated learning in
resource-constrained scenarios (privacy budget and communication resources). We
analyze the convergence of federated learning with differential privacy (DPFL)
on resource-constrained scenarios and propose an Adaptive Local Steps
Differential Privacy Federated Learning (ALS-DPFL) algorithm. We experiment our
algorithm on the FashionMNIST and Cifar-10 datasets and achieve quite good
performance relative to previous work.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10458" title="Abstract">arXiv:2308.10458</a> [<a href="/pdf/2308.10458" title="Download PDF">pdf</a>, <a href="/format/2308.10458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unraveling Low-Dimensional Network Dynamics: A Fusion of Sparse  Identification and Proper Orthogonal Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+R">Rui Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Chaotic Dynamics (nlin.CD)

</div>
<p class="mathjax">This study addresses the challenge of predicting network dynamics, such as
forecasting disease spread in social networks or estimating species populations
in predator-prey networks. Accurate predictions in large networks are difficult
due to the increasing number of network dynamics parameters that grow with the
size of the network population (e.g., each individual having its own contact
and recovery rates in an epidemic process), and because the network topology is
unknown or cannot be observed accurately.
<br />Inspired by the low-dimensionality inherent in network dynamics, we propose a
two-step method. First, we decompose the network dynamics into a composite of
principal components, each weighted by time-dependent coefficients.
Subsequently, we learn the governing differential equations for these
time-dependent coefficients using sparse regression over a function library
capable of describing the dynamics. We illustrate the effectiveness of our
proposed approach using simulated network dynamics datasets. The results
provide compelling evidence of our method's potential to enhance predictions in
complex networks.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10459" title="Abstract">arXiv:2308.10459</a> [<a href="/pdf/2308.10459" title="Download PDF">pdf</a>, <a href="/format/2308.10459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Bonded Discrete Element Method with Manifold Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jia-Ming Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">This paper proposes a novel approach that combines variational integration
with the bonded discrete element method (BDEM) to achieve faster and more
accurate fracture simulations. The approach leverages the efficiency of
implicit integration and the accuracy of BDEM in modeling fracture phenomena.
We introduce a variational integrator and a manifold optimization approach
utilizing a nullspace operator to speed up the solving of
quaternion-constrained systems. Additionally, the paper presents an element
packing and surface reconstruction method specifically designed for bonded
discrete element methods. Results from the experiments prove that the proposed
method offers 2.8 to 12 times faster state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10461" title="Abstract">arXiv:2308.10461</a> [<a href="/pdf/2308.10461" title="Download PDF">pdf</a>, <a href="/format/2308.10461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Preserving Face Recognition Using Random Frequency Components
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mi%2C+Y">Yuxi Mi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuge Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+J">Jiazhen Ji</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Minyi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiaxiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xingkun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+S">Shouhong Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shuigeng Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The ubiquitous use of face recognition has sparked increasing privacy
concerns, as unauthorized access to sensitive face images could compromise the
information of individuals. This paper presents an in-depth study of the
privacy protection of face images' visual information and against recovery.
Drawing on the perceptual disparity between humans and models, we propose to
conceal visual information by pruning human-perceivable low-frequency
components. For impeding recovery, we first elucidate the seeming paradox
between reducing model-exploitable information and retaining high recognition
accuracy. Based on recent theoretical insights and our observation on model
attention, we propose a solution to the dilemma, by advocating for the training
and inference of recognition models on randomly selected frequency components.
We distill our findings into a novel privacy-preserving face recognition
method, PartialFace. Extensive experiments demonstrate that PartialFace
effectively balances privacy protection goals and recognition accuracy. Code is
available at: https://github.com/Tencent/TFace.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10462" title="Abstract">arXiv:2308.10462</a> [<a href="/pdf/2308.10462" title="Download PDF">pdf</a>, <a href="/format/2308.10462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Parameter-Efficient Fine-Tuning Techniques for Code Generation  with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weyssow%2C+M">Martin Weyssow</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kisub Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>, 
<a href="/search/cs?searchtype=author&query=Sahraoui%2C+H">Houari Sahraoui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10+2 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) possess impressive capabilities to generate
meaningful code snippets given natural language intents in zero-shot, i.e.,
without the need for specific fine-tuning. In the perspective of unleashing
their full potential, prior work has demonstrated the benefits of fine-tuning
the models to task-specific data. However, fine-tuning process demands heavy
computational costs and is intractable when resources are scarce, especially
for models with billions of parameters. In light of these challenges, previous
studies explored In-Context Learning (ICL) as an effective strategy to generate
contextually appropriate code without fine-tuning. However, it operates at
inference time and does not involve learning task-specific parameters,
potentially limiting the model's performance on downstream tasks. In this
context, we foresee that Parameter-Efficient Fine-Tuning (PEFT) techniques
carry a high potential for efficiently specializing LLMs to task-specific data.
In this paper, we deliver a comprehensive study of LLMs with the impact of PEFT
techniques under the automated code generation scenario. Our experimental
results reveal the superiority and potential of such techniques over ICL on a
wide range of LLMs in reducing the computational burden and improving
performance. Therefore, the study opens opportunities for broader applications
of PEFT in software engineering scenarios.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10464" title="Abstract">arXiv:2308.10464</a> [<a href="/pdf/2308.10464" title="Download PDF">pdf</a>, <a href="/format/2308.10464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Dialogue Topic Segmentation in Hyperdimensional Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Seongmin Park</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+J">Jinkyu Seo</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jihwa Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Interspeech 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present HyperSeg, a hyperdimensional computing (HDC) approach to
unsupervised dialogue topic segmentation. HDC is a class of vector symbolic
architectures that leverages the probabilistic orthogonality of randomly drawn
vectors at extremely high dimensions (typically over 10,000). HDC generates
rich token representations through its low-cost initialization of many
unrelated vectors. This is especially beneficial in topic segmentation, which
often operates as a resource-constrained pre-processing step for downstream
transcript understanding tasks. HyperSeg outperforms the current
state-of-the-art in 4 out of 5 segmentation benchmarks -- even when baselines
are given partial access to the ground truth -- and is 10 times faster on
average. We show that HyperSeg also improves downstream summarization accuracy.
With HyperSeg, we demonstrate the viability of HDC in a major language task. We
open-source HyperSeg to provide a strong baseline for unsupervised topic
segmentation.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10466" title="Abstract">arXiv:2308.10466</a> [<a href="/pdf/2308.10466" title="Download PDF">pdf</a>, <a href="/format/2308.10466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Co-design of Storage and Control for Water Distribution  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Ye Wang</a>, 
<a href="/search/eess?searchtype=author&query=Weyer%2C+E">Erik Weyer</a>, 
<a href="/search/eess?searchtype=author&query=Manzie%2C+C">Chris Manzie</a>, 
<a href="/search/eess?searchtype=author&query=Simpson%2C+A+R">Angus R. Simpson</a>, 
<a href="/search/eess?searchtype=author&query=Blinco%2C+L">Lisa Blinco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Water distribution systems (WDSs) are typically designed with a conservative
estimate of the ability of a control system to utilize the available
infrastructure. The controller is subsequently designed and tuned based on the
designed water distribution system. This sequential approach may lead to
conservativeness in both design and control steps, impacting both operational
efficiency and economic costs. In this work, we consider simultaneously
designing infrastructure and developing a control strategy, the co-design
problem, to improve the overall system efficiency. However, implementing a
co-design problem for water distribution systems is a challenging task given
the presence of stochastic variables (e.g. water demands and electricity
prices). In this work, we propose a tractable stochastic co-design method to
design the best tank size and optimal control parameters for WDS, where the
expected operating costs are established based on Markov chain theory. We also
give a theoretical result that investigates the average long-run co-design cost
converging to the expected cost with probability 1. Furthermore, the method can
also be applied to an existing WDS to improve operation of the system. We
demonstrate the proposed co-design method on three examples and a real-world
case study in South Australia.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10467" title="Abstract">arXiv:2308.10467</a> [<a href="/pdf/2308.10467" title="Download PDF">pdf</a>, <a href="/format/2308.10467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-User Injection for Invisible Shilling Attack against Recommender  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chengzhi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hui Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CIKM 2023. 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Recommendation systems (RS) are crucial for alleviating the information
overload problem. Due to its pivotal role in guiding users to make decisions,
unscrupulous parties are lured to launch attacks against RS to affect the
decisions of normal users and gain illegal profits. Among various types of
attacks, shilling attack is one of the most subsistent and profitable attacks.
In shilling attack, an adversarial party injects a number of well-designed fake
user profiles into the system to mislead RS so that the attack goal can be
achieved. Although existing shilling attack methods have achieved promising
results, they all adopt the attack paradigm of multi-user injection, where some
fake user profiles are required. This paper provides the first study of
shilling attack in an extremely limited scenario: only one fake user profile is
injected into the victim RS to launch shilling attacks (i.e., single-user
injection). We propose a novel single-user injection method SUI-Attack for
invisible shilling attack. SUI-Attack is a graph based attack method that
models shilling attack as a node generation task over the user-item bipartite
graph of the victim RS, and it constructs the fake user profile by generating
user features and edges that link the fake user to items. Extensive experiments
demonstrate that SUI-Attack can achieve promising attack results in single-user
injection. In addition to its attack power, SUI-Attack increases the
stealthiness of shilling attack and reduces the risk of being detected. We
provide our implementation at: https://github.com/KDEGroup/SUI-Attack.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10468" title="Abstract">arXiv:2308.10468</a> [<a href="/pdf/2308.10468" title="Download PDF">pdf</a>, <a href="/format/2308.10468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STEERER: Resolving Scale Variations for Counting and Localization via  Selective Inheritance Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+T">Tao Han</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+L">Lei Bai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingbo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV2023, 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Scale variation is a deep-rooted problem in object counting, which has not
been effectively addressed by existing scale-aware algorithms. An important
factor is that they typically involve cooperative learning across
multi-resolutions, which could be suboptimal for learning the most
discriminative features from each scale. In this paper, we propose a novel
method termed STEERER (\textbf{S}elec\textbf{T}iv\textbf{E}
inh\textbf{ER}itance l\textbf{E}a\textbf{R}ning) that addresses the issue of
scale variations in object counting. STEERER selects the most suitable scale
for patch objects to boost feature extraction and only inherits discriminative
features from lower to higher resolution progressively. The main insights of
STEERER are a dedicated Feature Selection and Inheritance Adaptor (FSIA), which
selectively forwards scale-customized features at each scale, and a Masked
Selection and Inheritance Loss (MSIL) that helps to achieve high-quality
density maps across all scales. Our experimental results on nine datasets with
counting and localization tasks demonstrate the unprecedented scale
generalization ability of STEERER. Code is available at
\url{https://github.com/taohan10200/STEERER}.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10481" title="Abstract">arXiv:2308.10481</a> [<a href="/pdf/2308.10481" title="Download PDF">pdf</a>, <a href="/format/2308.10481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ADNet: Lane Shape Prediction via Anchor Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Lingyu Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wankou Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV2023 accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we revisit the limitations of anchor-based lane detection
methods, which have predominantly focused on fixed anchors that stem from the
edges of the image, disregarding their versatility and quality. To overcome the
inflexibility of anchors, we decompose them into learning the heat map of
starting points and their associated directions. This decomposition removes the
limitations on the starting point of anchors, making our algorithm adaptable to
different lane types in various datasets. To enhance the quality of anchors, we
introduce the Large Kernel Attention (LKA) for Feature Pyramid Network (FPN).
This significantly increases the receptive field, which is crucial in capturing
the sufficient context as lane lines typically run throughout the entire image.
We have named our proposed system the Anchor Decomposition Network (ADNet).
Additionally, we propose the General Lane IoU (GLIoU) loss, which significantly
improves the performance of ADNet in complex scenarios. Experimental results on
three widely used lane detection benchmarks, VIL-100, CULane, and TuSimple,
demonstrate that our approach outperforms the state-of-the-art methods on
VIL-100 and exhibits competitive accuracy on CULane and TuSimple. Code and
models will be released on https://github.com/ Sephirex-X/ADNet.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10482" title="Abstract">arXiv:2308.10482</a> [<a href="/pdf/2308.10482" title="Download PDF">pdf</a>, <a href="/format/2308.10482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Effective Method using Phrase Mechanism in Neural Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+P+M">Phuong Minh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+L+M">Le Minh Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine Translation is one of the essential tasks in Natural Language
Processing (NLP), which has massive applications in real life as well as
contributing to other tasks in the NLP research community. Recently,
Transformer -based methods have attracted numerous researchers in this domain
and achieved state-of-the-art results in most of the pair languages. In this
paper, we report an effective method using a phrase mechanism,
PhraseTransformer, to improve the strong baseline model Transformer in
constructing a Neural Machine Translation (NMT) system for parallel corpora
Vietnamese-Chinese. Our experiments on the MT dataset of the VLSP 2022
competition achieved the BLEU score of 35.3 on Vietnamese to Chinese and 33.2
BLEU scores on Chinese to Vietnamese data. Our code is available at
https://github.com/phuongnm94/PhraseTransformer.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10483" title="Abstract">arXiv:2308.10483</a> [<a href="/pdf/2308.10483" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aggregate Model of District Heating Network for Integrated Energy  Dispatch: A Physically Informed Data-Driven Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lu%2C+S">Shuai Lu</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+Z">Zihang Gao</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+Y">Yong Sun</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+S">Suhan Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+B">Baoju Li</a>, 
<a href="/search/eess?searchtype=author&query=Hao%2C+C">Chengliang Hao</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Y">Yijun Xu</a>, 
<a href="/search/eess?searchtype=author&query=Gu%2C+W">Wei Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The district heating network (DHN) is essential in enhancing the operational
flexibility of integrated energy systems (IES). Yet, it is hard to obtain an
accurate and concise DHN model for the operation owing to complicated network
features and imperfect measurement. Considering this, this paper proposes a
physically informed data-driven aggregate model (AGM) for DHN, providing a
concise description of the source-load relationship of DHN without exposing
network details. First, we derive the analytical relationship between the state
variables of the source and load nodes of DHN, offering a physical fundament
for the AGM. Second, we propose a physics-informed estimator for AGM that is
robust to low-quality measurement, in which the physical constraints associated
with the parameter normalization and sparsity are embedded to improve the
accuracy and robustness. Finally, we propose a physics-enhanced algorithm to
solve the nonlinear estimator with non-closed constraints efficiently.
Simulation results verify the effectiveness of the proposed method.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10486" title="Abstract">arXiv:2308.10486</a> [<a href="/pdf/2308.10486" title="Download PDF">pdf</a>, <a href="/format/2308.10486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Metric Loss for Multimodal Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moon%2C+S">Sehwan Moon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hyunju Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multimodal learning often outperforms its unimodal counterparts by exploiting
unimodal contributions and cross-modal interactions. However, focusing only on
integrating multimodal features into a unified comprehensive representation
overlooks the unimodal characteristics. In real data, the contributions of
modalities can vary from instance to instance, and they often reinforce or
conflict with each other. In this study, we introduce a novel \text{MultiModal}
loss paradigm for multimodal learning, which subgroups instances according to
their unimodal contributions. \text{MultiModal} loss can prevent inefficient
learning caused by overfitting and efficiently optimize multimodal models. On
synthetic data, \text{MultiModal} loss demonstrates improved classification
performance by subgrouping difficult instances within certain modalities. On
four real multimodal datasets, our loss is empirically shown to improve the
performance of recent models. Ablation studies verify the effectiveness of our
loss. Additionally, we show that our loss generates a reliable prediction score
for each modality, which is essential for subgrouping. Our \text{MultiModal}
loss is a novel loss function to subgroup instances according to the
contribution of modalities in multimodal learning and is applicable to a
variety of multimodal models with unimodal decisions. Our code is available at
https://github.com/SehwanMoon/MultiModalLoss.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10487" title="Abstract">arXiv:2308.10487</a> [<a href="/pdf/2308.10487" title="Download PDF">pdf</a>, <a href="/format/2308.10487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deciphering Raw Data in Neuro-Symbolic Learning with Provable Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+L">Lue Tao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yu-Xuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+W">Wang-Zhou Dai</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuan Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Neuro-symbolic hybrid systems are promising for integrating machine learning
and symbolic reasoning, where perception models are facilitated with
information inferred from a symbolic knowledge base through logical reasoning.
Despite empirical evidence showing the ability of hybrid systems to learn
accurate perception models, the theoretical understanding of learnability is
still lacking. Hence, it remains unclear why a hybrid system succeeds for a
specific task and when it may fail given a different knowledge base. In this
paper, we introduce a novel way of characterising supervision signals from a
knowledge base, and establish a criterion for determining the knowledge's
efficacy in facilitating successful learning. This, for the first time, allows
us to address the two questions above by inspecting the knowledge base under
investigation. Our analysis suggests that many knowledge bases satisfy the
criterion, thus enabling effective learning, while some fail to satisfy it,
indicating potential failures. Comprehensive experiments confirm the utility of
our criterion on benchmark tasks.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10490" title="Abstract">arXiv:2308.10490</a> [<a href="/pdf/2308.10490" title="Download PDF">pdf</a>, <a href="/format/2308.10490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Texture Generation on 3D Meshes with Point-UV Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+P">Peng Dai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenbo Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengzhe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xiaojuan Qi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023, Oral
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">In this work, we focus on synthesizing high-quality textures on 3D meshes. We
present Point-UV diffusion, a coarse-to-fine pipeline that marries the
denoising diffusion model with UV mapping to generate 3D consistent and
high-quality texture images in UV space. We start with introducing a point
diffusion model to synthesize low-frequency texture components with our
tailored style guidance to tackle the biased color distribution. The derived
coarse texture offers global consistency and serves as a condition for the
subsequent UV diffusion stage, aiding in regularizing the model to generate a
3D consistent UV texture image. Then, a UV diffusion model with hybrid
conditions is developed to enhance the texture fidelity in the 2D UV space. Our
method can process meshes of any genus, generating diversified,
geometry-compatible, and high-fidelity textures. Code is available at
https://cvmi-lab.github.io/Point-UV-Diffusion
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10491" title="Abstract">arXiv:2308.10491</a> [<a href="/pdf/2308.10491" title="Download PDF">pdf</a>, <a href="/format/2308.10491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SynDrone -- Multi-modal UAV Dataset for Urban Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rizzoli%2C+G">Giulia Rizzoli</a>, 
<a href="/search/cs?searchtype=author&query=Barbato%2C+F">Francesco Barbato</a>, 
<a href="/search/cs?searchtype=author&query=Caligiuri%2C+M">Matteo Caligiuri</a>, 
<a href="/search/cs?searchtype=author&query=Zanuttigh%2C+P">Pietro Zanuttigh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV Workshops, downloadable dataset with CC-BY license, 8 pages, 4 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The development of computer vision algorithms for Unmanned Aerial Vehicles
(UAVs) imagery heavily relies on the availability of annotated high-resolution
aerial data. However, the scarcity of large-scale real datasets with
pixel-level annotations poses a significant challenge to researchers as the
limited number of images in existing datasets hinders the effectiveness of deep
learning models that require a large amount of training data. In this paper, we
propose a multimodal synthetic dataset containing both images and 3D data taken
at multiple flying heights to address these limitations. In addition to
object-level annotations, the provided data also include pixel-level labeling
in 28 classes, enabling exploration of the potential advantages in tasks like
semantic segmentation. In total, our dataset contains 72k labeled samples that
allow for effective training of deep architectures showing promising results in
synthetic-to-real adaptation. The dataset will be made publicly available to
support the development of novel computer vision methods targeting UAV
applications.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10493" title="Abstract">arXiv:2308.10493</a> [<a href="/pdf/2308.10493" title="Download PDF">pdf</a>, <a href="/format/2308.10493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Graph Representation Learning for Handwritten Mathematical  Expression Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhuang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Ye Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Z">Zhilong Ji</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jingfeng Bai</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiang Bai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Handwritten mathematical expression recognition (HMER) has attracted
extensive attention recently. However, current methods cannot explicitly study
the interactions between different symbols, which may fail when faced similar
symbols. To alleviate this issue, we propose a simple but efficient method to
enhance semantic interaction learning (SIL). Specifically, we firstly construct
a semantic graph based on the statistical symbol co-occurrence probabilities.
Then we design a semantic aware module (SAM), which projects the visual and
classification feature into semantic space. The cosine distance between
different projected vectors indicates the correlation between symbols. And
jointly optimizing HMER and SIL can explicitly enhances the model's
understanding of symbol relationships. In addition, SAM can be easily plugged
into existing attention-based models for HMER and consistently bring
improvement. Extensive experiments on public benchmark datasets demonstrate
that our proposed module can effectively enhance the recognition performance.
Our method achieves better recognition performance than prior arts on both
CROHME and HME100K datasets.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10496" title="Abstract">arXiv:2308.10496</a> [<a href="/pdf/2308.10496" title="Download PDF">pdf</a>, <a href="/format/2308.10496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Autoencoders and AutoDiff to Reconstruct Missing Variables in a  Set of Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roche%2C+J">Jan-Philipp Roche</a>, 
<a href="/search/cs?searchtype=author&query=Niggemann%2C+O">Oliver Niggemann</a>, 
<a href="/search/cs?searchtype=author&query=Friebe%2C+J">Jens Friebe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">Existing black box modeling approaches in machine learning suffer from a
fixed input and output feature combination. In this paper, a new approach to
reconstruct missing variables in a set of time series is presented. An
autoencoder is trained as usual with every feature on both sides and the neural
network parameters are fixed after this training. Then, the searched variables
are defined as missing variables at the autoencoder input and optimized via
automatic differentiation. This optimization is performed with respect to the
available features loss calculation. With this method, different input and
output feature combinations of the trained model can be realized by defining
the searched variables as missing variables and reconstructing them. The
combination can be changed without training the autoencoder again. The approach
is evaluated on the base of a strongly nonlinear electrical component. It is
working well for one of four variables missing and generally even for multiple
missing variables.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10499" title="Abstract">arXiv:2308.10499</a> [<a href="/pdf/2308.10499" title="Download PDF">pdf</a>, <a href="/ps/2308.10499" title="Download PostScript">ps</a>, <a href="/format/2308.10499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fair Rank Aggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+D">Diptarka Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Syamantak Das</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Arindam Khan</a>, 
<a href="/search/cs?searchtype=author&query=Subramanian%2C+A">Aditya Subramanian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A preliminary version of this paper appeared in NeurIPS 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Ranking algorithms find extensive usage in diverse areas such as web search,
employment, college admission, voting, etc. The related rank aggregation
problem deals with combining multiple rankings into a single aggregate ranking.
However, algorithms for both these problems might be biased against some
individuals or groups due to implicit prejudice or marginalization in the
historical data. We study ranking and rank aggregation problems from a fairness
or diversity perspective, where the candidates (to be ranked) may belong to
different groups and each group should have a fair representation in the final
ranking. We allow the designer to set the parameters that define fair
representation. These parameters specify the allowed range of the number of
candidates from a particular group in the top-$k$ positions of the ranking.
Given any ranking, we provide a fast and exact algorithm for finding the
closest fair ranking for the Kendall tau metric under block-fairness. We also
provide an exact algorithm for finding the closest fair ranking for the Ulam
metric under strict-fairness, when there are only $O(1)$ number of groups. Our
algorithms are simple, fast, and might be extendable to other relevant metrics.
We also give a novel meta-algorithm for the general rank aggregation problem
under the fairness framework. Surprisingly, this meta-algorithm works for any
generalized mean objective (including center and median problems) and any
fairness criteria. As a byproduct, we obtain 3-approximation algorithms for
both center and median problems, under both Kendall tau and Ulam metrics.
Furthermore, using sophisticated techniques we obtain a
$(3-\varepsilon)$-approximation algorithm, for a constant $\varepsilon&gt;0$, for
the Ulam metric under strong fairness.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10502" title="Abstract">arXiv:2308.10502</a> [<a href="/pdf/2308.10502" title="Download PDF">pdf</a>, <a href="/format/2308.10502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GradientCoin: A Peer-to-Peer Decentralized Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yeqi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhao Song</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Junze Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
<p class="mathjax">Since 2008, after the proposal of a Bitcoin electronic cash system, Bitcoin
has fundamentally changed the economic system over the last decade. Since 2022,
large language models (LLMs) such as GPT have outperformed humans in many
real-life tasks. However, these large language models have several practical
issues. For example, the model is centralized and controlled by a specific
unit. One weakness is that if that unit decides to shut down the model, it
cannot be used anymore. The second weakness is the lack of guaranteed
discrepancy behind this model, as certain dishonest units may design their own
models and feed them unhealthy training data.
<br />In this work, we propose a purely theoretical design of a decentralized LLM
that operates similarly to a Bitcoin cash system. However, implementing such a
system might encounter various practical difficulties. Furthermore, this new
system is unlikely to perform better than the standard Bitcoin system in
economics. Therefore, the motivation for designing such a system is limited. It
is likely that only two types of people would be interested in setting up a
practical system for it:
<br />$\bullet$ Those who prefer to use a decentralized ChatGPT-like software.
<br />$\bullet$ Those who believe that the purpose of carbon-based life is to
create silicon-based life, such as Optimus Prime in Transformers.
<br />The reason the second type of people may be interested is that it is possible
that one day an AI system like this will awaken and become the next level of
intelligence on this planet.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10504" title="Abstract">arXiv:2308.10504</a> [<a href="/pdf/2308.10504" title="Download PDF">pdf</a>, <a href="/format/2308.10504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Thresholding Heuristic for KPI Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Isaac%2C+E+R+H+P">Ebenezer R.H.P. Isaac</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Akshat Sharma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">A plethora of outlier detectors have been explored in the time series domain,
however, in a business sense, not all outliers are anomalies of interest.
Existing anomaly detection solutions are confined to certain outlier detectors
limiting their applicability to broader anomaly detection use cases. Network
KPIs (Key Performance Indicators) tend to exhibit stochastic behaviour
producing statistical outliers, most of which do not adversely affect business
operations. Thus, a heuristic is required to capture the business definition of
an anomaly for time series KPI. This article proposes an Adaptive Thresholding
Heuristic (ATH) to dynamically adjust the detection threshold based on the
local properties of the data distribution and adapt to changes in time series
patterns. The heuristic derives the threshold based on the expected periodicity
and the observed proportion of anomalies minimizing false positives and
addressing concept drift. ATH can be used in conjunction with any underlying
seasonality decomposition method and an outlier detector that yields an outlier
score. This method has been tested on EON1-Cell-U, a labeled KPI anomaly
dataset produced by Ericsson, to validate our hypothesis. Experimental results
show that ATH is computationally efficient making it scalable for near real
time anomaly detection and flexible with multiple forecasters and outlier
detectors.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10505" title="Abstract">arXiv:2308.10505</a> [<a href="/pdf/2308.10505" title="Download PDF">pdf</a>, <a href="/format/2308.10505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Clustering Algorithm to Organize Satellite Hotspot Data for the  Purpose of Tracking Bushfires Remotely
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weihao Li</a>, 
<a href="/search/cs?searchtype=author&query=Dodwell%2C+E">Emily Dodwell</a>, 
<a href="/search/cs?searchtype=author&query=Cook%2C+D">Dianne Cook</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP); Computation (stat.CO); Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper proposes a spatiotemporal clustering algorithm and its
implementation in the R package spotoroo. This work is motivated by the
catastrophic bushfires in Australia throughout the summer of 2019-2020 and made
possible by the availability of satellite hotspot data. The algorithm is
inspired by two existing spatiotemporal clustering algorithms but makes
enhancements to cluster points spatially in conjunction with their movement
across consecutive time periods. It also allows for the adjustment of key
parameters, if required, for different locations and satellite data sources.
Bushfire data from Victoria, Australia, is used to illustrate the algorithm and
its use within the package.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10509" title="Abstract">arXiv:2308.10509</a> [<a href="/pdf/2308.10509" title="Download PDF">pdf</a>, <a href="/format/2308.10509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Examination of the Compositionality of Large Generative  Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+T">Teli Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rong Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Junwei Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">With the success of Large Language Models (LLMs), a surge of Generative
Vision-Language Models (GVLMs) have been constructed via multimodal instruction
tuning. The tuning recipe substantially deviates from the common contrastive
vision-language learning. However, the performance of GVLMs in multimodal
compositional reasoning remains largely unexplored, as existing evaluation
metrics and benchmarks focus predominantly on assessing contrastive models like
CLIP. In this paper, we examine the potential evaluation metrics to assess the
GVLMs and hypothesize generative score methods are suitable for evaluating
compositionality. In addition, current benchmarks tend to prioritize syntactic
correctness over semantics. The presence of morphological bias in these
benchmarks can be exploited by GVLMs, leading to ineffective evaluations. To
combat this, we define a MorphoBias Score to quantify the morphological bias
and propose a novel LLM-based strategy to calibrate the bias. Moreover, a
challenging task is added to evaluate the robustness of GVLMs against inherent
inclination toward syntactic correctness. We include the calibrated dataset and
the task into a new benchmark, namely MOrphologicall De-biased Benchmark
(MODE). Our study provides the first unbiased benchmark for the
compositionality of GVLMs, facilitating future research in this direction. We
will release our code and datasets.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10510" title="Abstract">arXiv:2308.10510</a> [<a href="/pdf/2308.10510" title="Download PDF">pdf</a>, <a href="/format/2308.10510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frequency Compensated Diffusion Model for Real-scene Dehazing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Songtao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kuanhong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhiqiang Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Due to distribution shift, deep learning based methods for image dehazing
suffer from performance degradation when applied to real-world hazy images. In
this paper, we consider a dehazing framework based on conditional diffusion
models for improved generalization to real haze. First, we find that optimizing
the training objective of diffusion models, i.e., Gaussian noise vectors, is
non-trivial. The spectral bias of deep networks hinders the higher frequency
modes in Gaussian vectors from being learned and hence impairs the
reconstruction of image details. To tackle this issue, we design a network
unit, named Frequency Compensation block (FCB), with a bank of filters that
jointly emphasize the mid-to-high frequencies of an input signal. We
demonstrate that diffusion models with FCB achieve significant gains in both
perceptual and distortion metrics. Second, to further boost the generalization
performance, we propose a novel data synthesis pipeline, HazeAug, to augment
haze in terms of degree and diversity. Within the framework, a solid baseline
for blind dehazing is set up where models are trained on synthetic hazy-clean
pairs, and directly generalize to real data. Extensive evaluations show that
the proposed dehazing diffusion model significantly outperforms
state-of-the-art methods on real-world images.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10511" title="Abstract">arXiv:2308.10511</a> [<a href="/pdf/2308.10511" title="Download PDF">pdf</a>, <a href="/ps/2308.10511" title="Download PostScript">ps</a>, <a href="/format/2308.10511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance Enhancement Leveraging Mask-RCNN on Bengali Document Layout  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Datta%2C+S">Shrestha Datta</a>, 
<a href="/search/cs?searchtype=author&query=Mollah%2C+M+A">Md Adith Mollah</a>, 
<a href="/search/cs?searchtype=author&query=Fairooz%2C+R">Raisa Fairooz</a>, 
<a href="/search/cs?searchtype=author&query=Fahim%2C+T+I">Tariful Islam Fahim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Contest paper, Conest: DL sprint 2.0 (Link: <a href="https://www.kaggle.com/competitions/dlsprint2">this https URL</a>), Solution link: <a href="https://www.kaggle.com/competitions/dlsprint2/discussion/432201">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Understanding digital documents is like solving a puzzle, especially
historical ones. Document Layout Analysis (DLA) helps with this puzzle by
dividing documents into sections like paragraphs, images, and tables. This is
crucial for machines to read and understand these documents.In the DL Sprint
2.0 competition, we worked on understanding Bangla documents. We used a dataset
called BaDLAD with lots of examples. We trained a special model called Mask
R-CNN to help with this understanding. We made this model better by
step-by-step hyperparameter tuning, and we achieved a good dice score of
0.889.However, not everything went perfectly. We tried using a model trained
for English documents, but it didn't fit well with Bangla. This showed us that
each language has its own challenges. Our solution for the DL Sprint 2.0 is
publicly available at
https://www.kaggle.com/competitions/dlsprint2/discussion/432201 along with
notebooks, weights, and inference notebook.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10512" title="Abstract">arXiv:2308.10512</a> [<a href="/pdf/2308.10512" title="Download PDF">pdf</a>, <a href="/format/2308.10512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying traffic emission reductions and traffic congestion  alleviation from high-capacity ride-sharing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+W">Wang Chen</a>, 
<a href="/search/eess?searchtype=author&query=Ke%2C+J">Jintao Ke</a>, 
<a href="/search/eess?searchtype=author&query=Xiqun">Xiqun</a> (Michael)
<a href="/search/eess?searchtype=author&query=Chen">Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Despite the promising benefits that ride-sharing offers, there has been a
lack of research on the benefits of high-capacity ride-sharing services. Prior
research has also overlooked the relationship between traffic volume and the
degree of traffic congestion and emissions. To address these gaps, this study
develops an open-source agent-based simulation platform and a heuristic
algorithm to quantify the benefits of high-capacity ride-sharing with
significantly lower computational costs. The simulation platform integrates a
traffic emission model and a speed-density traffic flow model to characterize
the interactions between traffic congestion levels and emissions. The
experiment results demonstrate that ride-sharing with vehicle capacities of 2,
4, and 6 passengers can alleviate total traffic congestion by approximately 3%,
4%, and 5%, and reduce traffic emissions of a ride-sourcing system by
approximately 30%, 45%, and 50%, respectively. This study can guide
transportation network companies in designing and managing more efficient and
environment-friendly mobility systems.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10515" title="Abstract">arXiv:2308.10515</a> [<a href="/pdf/2308.10515" title="Download PDF">pdf</a>, <a href="/format/2308.10515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QD-BEV : Quantization-aware View-guided Distillation for Multi-view 3D  Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhen Dong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Huanrui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+M">Ming Lu</a>, 
<a href="/search/cs?searchtype=author&query=Tseng%2C+C">Cheng-Ching Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yuan Du</a>, 
<a href="/search/cs?searchtype=author&query=Keutzer%2C+K">Kurt Keutzer</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Li Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanghang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 Accept
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Multi-view 3D detection based on BEV (bird-eye-view) has recently achieved
significant improvements. However, the huge memory consumption of
state-of-the-art models makes it hard to deploy them on vehicles, and the
non-trivial latency will affect the real-time perception of streaming
applications. Despite the wide application of quantization to lighten models,
we show in our paper that directly applying quantization in BEV tasks will 1)
make the training unstable, and 2) lead to intolerable performance degradation.
To solve these issues, our method QD-BEV enables a novel view-guided
distillation (VGD) objective, which can stabilize the quantization-aware
training (QAT) while enhancing the model performance by leveraging both image
features and BEV features. Our experiments show that QD-BEV achieves similar or
even better accuracy than previous methods with significant efficiency gains.
On the nuScenes datasets, the 4-bit weight and 6-bit activation quantized
QD-BEV-Tiny model achieves 37.2% NDS with only 15.8 MB model size,
outperforming BevFormer-Tiny by 1.8% with an 8x model compression. On the Small
and Base variants, QD-BEV models also perform superbly and achieve 47.9% NDS
(28.2 MB) and 50.9% NDS (32.9 MB), respectively.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10517" title="Abstract">arXiv:2308.10517</a> [<a href="/pdf/2308.10517" title="Download PDF">pdf</a>, <a href="/format/2308.10517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Patternshop: Editing Point Patterns by Image Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xingchang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ritschel%2C+T">Tobias Ritschel</a>, 
<a href="/search/cs?searchtype=author&query=Seidel%2C+H">Hans-Peter Seidel</a>, 
<a href="/search/cs?searchtype=author&query=Memari%2C+P">Pooran Memari</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+G">Gurprit Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">Point patterns are characterized by their density and correlation. While
spatial variation of density is well-understood, analysis and synthesis of
spatially-varying correlation is an open challenge. No tools are available to
intuitively edit such point patterns, primarily due to the lack of a compact
representation for spatially varying correlation. We propose a low-dimensional
perceptual embedding for point correlations. This embedding can map point
patterns to common three-channel raster images, enabling manipulation with
off-the-shelf image editing software. To synthesize back point patterns, we
propose a novel edge-aware objective that carefully handles sharp variations in
density and correlation. The resulting framework allows intuitive and
backward-compatible manipulation of point patterns, such as recoloring,
relighting to even texture synthesis that have not been available to 2D point
pattern design before. Effectiveness of our approach is tested in several user
experiments.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10521" title="Abstract">arXiv:2308.10521</a> [<a href="/pdf/2308.10521" title="Download PDF">pdf</a>, <a href="/format/2308.10521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PHE-SICH-CT-IDS: A Benchmark CT Image Dataset for Evaluation Semantic  Segmentation, Object Detection and Radiomic Feature Extraction of  Perihematomal Edema in Spontaneous Intracerebral Hemorrhage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+D">Deguo Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+L">Lin Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+T">Tianming Du</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+D">Dechao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhiyu Ma</a>, 
<a href="/search/cs?searchtype=author&query=Hongzan%2C+M+G">Marcin Grzegorzek Hongzan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hongzan Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Intracerebral hemorrhage is one of the diseases with the highest mortality
and poorest prognosis worldwide. Spontaneous intracerebral hemorrhage (SICH)
typically presents acutely, prompt and expedited radiological examination is
crucial for diagnosis, localization, and quantification of the hemorrhage.
Early detection and accurate segmentation of perihematomal edema (PHE) play a
critical role in guiding appropriate clinical intervention and enhancing
patient prognosis. However, the progress and assessment of computer-aided
diagnostic methods for PHE segmentation and detection face challenges due to
the scarcity of publicly accessible brain CT image datasets. This study
establishes a publicly available CT dataset named PHE-SICH-CT-IDS for
perihematomal edema in spontaneous intracerebral hemorrhage. The dataset
comprises 120 brain CT scans and 7,022 CT images, along with corresponding
medical information of the patients. To demonstrate its effectiveness,
classical algorithms for semantic segmentation, object detection, and radiomic
feature extraction are evaluated. The experimental results confirm the
suitability of PHE-SICH-CT-IDS for assessing the performance of segmentation,
detection and radiomic feature extraction methods. To the best of our
knowledge, this is the first publicly available dataset for PHE in SICH,
comprising various data formats suitable for applications across diverse
medical scenarios. We believe that PHE-SICH-CT-IDS will allure researchers to
explore novel algorithms, providing valuable support for clinicians and
patients in the clinical setting. PHE-SICH-CT-IDS is freely published for
non-commercial purpose at:
https://figshare.com/articles/dataset/PHE-SICH-CT-IDS/23957937.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10522" title="Abstract">arXiv:2308.10522</a> [<a href="/pdf/2308.10522" title="Download PDF">pdf</a>, <a href="/format/2308.10522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information Theory-Guided Heuristic Progressive Multi-View Coding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiangmeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Hang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Qiang%2C+W">Wenwen Qiang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Changwen Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted y the jourcal of Elsevier Neural Networks by 2023. arXiv admin note: substantial text overlap with <a href="/abs/2109.02344">arXiv:2109.02344</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Multi-view representation learning aims to capture comprehensive information
from multiple views of a shared context. Recent works intuitively apply
contrastive learning to different views in a pairwise manner, which is still
scalable: view-specific noise is not filtered in learning view-shared
representations; the fake negative pairs, where the negative terms are actually
within the same class as the positive, and the real negative pairs are
coequally treated; evenly measuring the similarities between terms might
interfere with optimization. Importantly, few works study the theoretical
framework of generalized self-supervised multi-view learning, especially for
more than two views. To this end, we rethink the existing multi-view learning
paradigm from the perspective of information theory and then propose a novel
information theoretical framework for generalized multi-view learning. Guided
by it, we build a multi-view coding method with a three-tier progressive
architecture, namely Information theory-guided hierarchical Progressive
Multi-view Coding (IPMC). In the distribution-tier, IPMC aligns the
distribution between views to reduce view-specific noise. In the set-tier, IPMC
constructs self-adjusted contrasting pools, which are adaptively modified by a
view filter. Lastly, in the instance-tier, we adopt a designed unified loss to
learn representations and reduce the gradient interference. Theoretically and
empirically, we demonstrate the superiority of IPMC over state-of-the-art
methods.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10523" title="Abstract">arXiv:2308.10523</a> [<a href="/pdf/2308.10523" title="Download PDF">pdf</a>, <a href="/format/2308.10523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Less is Enough: Positive and Unlabeled Learning Model for  Vulnerability Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+X">Xin-Cheng Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinchen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Cuiyun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shaohua Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Z">Zhaoquan Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by ASE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Automated code vulnerability detection has gained increasing attention in
recent years. The deep learning (DL)-based methods, which implicitly learn
vulnerable code patterns, have proven effective in vulnerability detection. The
performance of DL-based methods usually relies on the quantity and quality of
labeled data. However, the current labeled data are generally automatically
collected, such as crawled from human-generated commits, making it hard to
ensure the quality of the labels. Prior studies have demonstrated that the
non-vulnerable code (i.e., negative labels) tends to be unreliable in
commonly-used datasets, while vulnerable code (i.e., positive labels) is more
determined. Considering the large numbers of unlabeled data in practice, it is
necessary and worth exploring to leverage the positive data and large numbers
of unlabeled data for more accurate vulnerability detection.
<br />In this paper, we focus on the Positive and Unlabeled (PU) learning problem
for vulnerability detection and propose a novel model named PILOT, i.e.,
PositIve and unlabeled Learning mOdel for vulnerability deTection. PILOT only
learns from positive and unlabeled data for vulnerability detection. It mainly
contains two modules: (1) A distance-aware label selection module, aiming at
generating pseudo-labels for selected unlabeled data, which involves the
inter-class distance prototype and progressive fine-tuning; (2) A
mixed-supervision representation learning module to further alleviate the
influence of noise and enhance the discrimination of representations.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10524" title="Abstract">arXiv:2308.10524</a> [<a href="/pdf/2308.10524" title="Download PDF">pdf</a>, <a href="/format/2308.10524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dataset Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Daquan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jianyang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xiangyu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+D">Dongze Lian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yang You</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiashi Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">State-of-the-art deep neural networks are trained with large amounts
(millions or even billions) of data. The expensive computation and memory costs
make it difficult to train them on limited hardware resources, especially for
recent popular large language models (LLM) and computer vision models (CV).
Recent popular dataset distillation methods are thus developed, aiming to
reduce the number of training samples via synthesizing small-scale datasets via
gradient matching. However, as the gradient calculation is coupled with the
specific network architecture, the synthesized dataset is biased and performs
poorly when used for training unseen architectures. To address these
limitations, we present dataset quantization (DQ), a new framework to compress
large-scale datasets into small subsets which can be used for training any
neural network architectures. Extensive experiments demonstrate that DQ is able
to generate condensed small datasets for training unseen network architectures
with state-of-the-art compression ratios for lossless model training. To the
best of our knowledge, DQ is the first method that can successfully distill
large-scale datasets such as ImageNet-1k with a state-of-the-art compression
ratio. Notably, with 60% data from ImageNet and 20% data from Alpaca's
instruction tuning data, the models can be trained with negligible or no
performance drop for both vision tasks (including classification, semantic
segmentation, and object detection) as well as language tasks (including
instruction tuning tasks such as BBH and DROP).
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10525" title="Abstract">arXiv:2308.10525</a> [<a href="/pdf/2308.10525" title="Download PDF">pdf</a>, <a href="/format/2308.10525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LightDepth: Single-View Depth Self-Supervision from Illumination Decline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rodr%C3%ADguez-Puigvert%2C+J">Javier Rodr&#xed;guez-Puigvert</a>, 
<a href="/search/cs?searchtype=author&query=Batlle%2C+V+M">V&#xed;ctor M. Batlle</a>, 
<a href="/search/cs?searchtype=author&query=Montiel%2C+J+M+M">J.M.M. Montiel</a>, 
<a href="/search/cs?searchtype=author&query=Cantin%2C+R+M">Ruben Martinez Cantin</a>, 
<a href="/search/cs?searchtype=author&query=Fua%2C+P">Pascal Fua</a>, 
<a href="/search/cs?searchtype=author&query=Tard%C3%B3s%2C+J+D">Juan D. Tard&#xf3;s</a>, 
<a href="/search/cs?searchtype=author&query=Civera%2C+J">Javier Civera</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Single-view depth estimation can be remarkably effective if there is enough
ground-truth depth data for supervised training. However, there are scenarios,
especially in medicine in the case of endoscopies, where such data cannot be
obtained. In such cases, multi-view self-supervision and synthetic-to-real
transfer serve as alternative approaches, however, with a considerable
performance reduction in comparison to supervised case. Instead, we propose a
single-view self-supervised method that achieves a performance similar to the
supervised case. In some medical devices, such as endoscopes, the camera and
light sources are co-located at a small distance from the target surfaces.
Thus, we can exploit that, for any given albedo and surface orientation, pixel
brightness is inversely proportional to the square of the distance to the
surface, providing a strong single-view self-supervisory signal. In our
experiments, our self-supervised models deliver accuracies comparable to those
of fully supervised ones, while being applicable without depth ground-truth
data.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10526" title="Abstract">arXiv:2308.10526</a> [<a href="/pdf/2308.10526" title="Download PDF">pdf</a>, <a href="/format/2308.10526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UbiPhysio: Support Daily Functioning, Fitness, and Rehabilitation with  Action Understanding and Feedback in Natural Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chongyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yuan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+L">Lingxiao Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Siyi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Siqi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+C">Chen Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuntao Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Chengqi He</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yuanchun Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 14 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">We introduce UbiPhysio, a milestone framework that delivers fine-grained
action description and feedback in natural language to support people's daily
functioning, fitness, and rehabilitation activities. This expert-like
capability assists users in properly executing actions and maintaining
engagement in remote fitness and rehabilitation programs. Specifically, the
proposed UbiPhysio framework comprises a fine-grained action descriptor and a
knowledge retrieval-enhanced feedback module. The action descriptor translates
action data, represented by a set of biomechanical movement features we
designed based on clinical priors, into textual descriptions of action types
and potential movement patterns. Building on physiotherapeutic domain
knowledge, the feedback module provides clear and engaging expert feedback. We
evaluated UbiPhysio's performance through extensive experiments with data from
104 diverse participants, collected in a home-like setting during 25 types of
everyday activities and exercises. We assessed the quality of the language
output under different tuning strategies using standard benchmarks. We
conducted a user study to gather insights from clinical experts and potential
users on our framework. Our initial tests show promise for deploying UbiPhysio
in real-life settings without specialized devices.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10527" title="Abstract">arXiv:2308.10527</a> [<a href="/pdf/2308.10527" title="Download PDF">pdf</a>, <a href="/format/2308.10527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DPAN: Dynamic Preference-based and Attribute-aware Network for Relevant  Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+W">Wei Dai</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yingmin Su</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xiaofeng Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In e-commerce platforms, the relevant recommendation is a unique scenario
providing related items for a trigger item that users are interested in.
However, users' preferences for the similarity and diversity of recommendation
results are dynamic and vary under different conditions. Moreover, individual
item-level diversity is too coarse-grained since all recommended items are
related to the trigger item. Thus, the two main challenges are to learn
fine-grained representations of similarity and diversity and capture users'
dynamic preferences for them under different conditions. To address these
challenges, we propose a novel method called the Dynamic Preference-based and
Attribute-aware Network (DPAN) for predicting Click-Through Rate (CTR) in
relevant recommendations. Specifically, based on Attribute-aware Activation
Values Generation (AAVG), Bi-dimensional Compression-based Re-expression (BCR)
is designed to obtain similarity and diversity representations of user
interests and item information. Then Shallow and Deep Union-based Fusion (SDUF)
is proposed to capture users' dynamic preferences for the diverse degree of
recommendation results according to various conditions. DPAN has demonstrated
its effectiveness through extensive offline experiments and online A/B testing,
resulting in a significant 7.62% improvement in CTR. Currently, DPAN has been
successfully deployed on our e-commerce platform serving the primary traffic
for relevant recommendations. The code of DPAN has been made publicly
available.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10529" title="Abstract">arXiv:2308.10529</a> [<a href="/pdf/2308.10529" title="Download PDF">pdf</a>, <a href="/format/2308.10529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeqGPT: An Out-of-the-box Large Language Model for Open Domain Sequence  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tianyu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Chengyue Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lou%2C+C">Chao Lou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaobin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+J">Jiong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yangning Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+K">Kewei Tu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hai-Tao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ningyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+P">Pengjun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yong Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Initial version of SeqGPT
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have shown impressive ability for open-domain
NLP tasks. However, LLMs are sometimes too footloose for natural language
understanding (NLU) tasks which always have restricted output and input format.
Their performances on NLU tasks are highly related to prompts or demonstrations
and are shown to be poor at performing several representative NLU tasks, such
as event extraction and entity typing. To this end, we present SeqGPT, a
bilingual (i.e., English and Chinese) open-source autoregressive model
specially enhanced for open-domain natural language understanding. We express
all NLU tasks with two atomic tasks, which define fixed instructions to
restrict the input and output format but still ``open'' for arbitrarily varied
label sets. The model is first instruction-tuned with extremely fine-grained
labeled data synthesized by ChatGPT and then further fine-tuned by 233
different atomic tasks from 152 datasets across various domains. The
experimental results show that SeqGPT has decent classification and extraction
ability, and is capable of performing language understanding tasks on unseen
domains. We also conduct empirical studies on the scaling of data and model
size as well as on the transfer across tasks. Our model is accessible at
https://github.com/Alibaba-NLP/SeqGPT.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10531" title="Abstract">arXiv:2308.10531</a> [<a href="/pdf/2308.10531" title="Download PDF">pdf</a>, <a href="/format/2308.10531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SRFormer: Empowering Regression-Based Text Detection Transformer with  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bu%2C+Q">Qingwen Bu</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sungrae Park</a>, 
<a href="/search/cs?searchtype=author&query=Khang%2C+M">Minsoo Khang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yichuan Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing techniques for text detection can be broadly classified into two
primary groups: segmentation-based methods and regression-based methods.
Segmentation models offer enhanced robustness to font variations but require
intricate post-processing, leading to high computational overhead.
Regression-based methods undertake instance-aware prediction but face
limitations in robustness and data efficiency due to their reliance on
high-level representations. In our academic pursuit, we propose SRFormer, a
unified DETR-based model with amalgamated Segmentation and Regression, aiming
at the synergistic harnessing of the inherent robustness in segmentation
representations, along with the straightforward post-processing of
instance-level regression. Our empirical analysis indicates that favorable
segmentation predictions can be obtained at the initial decoder layers. In
light of this, we constrain the incorporation of segmentation branches to the
first few decoder layers and employ progressive regression refinement in
subsequent layers, achieving performance gains while minimizing additional
computational load from the mask. Furthermore, we propose a Mask-informed Query
Enhancement module. We take the segmentation result as a natural soft-ROI to
pool and extract robust pixel representations, which are then employed to
enhance and diversify instance queries. Extensive experimentation across
multiple benchmarks has yielded compelling findings, highlighting our method's
exceptional robustness, superior training and data efficiency, as well as its
state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10533" title="Abstract">arXiv:2308.10533</a> [<a href="/pdf/2308.10533" title="Download PDF">pdf</a>, <a href="/format/2308.10533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint learning of images and videos with a single Vision Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shimizu%2C+S">Shuki Shimizu</a>, 
<a href="/search/cs?searchtype=author&query=Tamaki%2C+T">Toru Tamaki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MVA2023 (18th International Conference on Machine Vision Applications), Hamamatsu, Japan, 23-25 July 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this study, we propose a method for jointly learning of images and videos
using a single model. In general, images and videos are often trained by
separate models. We propose in this paper a method that takes a batch of images
as input to Vision Transformer IV-ViT, and also a set of video frames with
temporal aggregation by late fusion. Experimental results on two image datasets
and two action recognition datasets are presented.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10537" title="Abstract">arXiv:2308.10537</a> [<a href="/pdf/2308.10537" title="Download PDF">pdf</a>, <a href="/format/2308.10537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KGrEaT: A Framework to Evaluate Knowledge Graphs via Downstream Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heist%2C+N">Nicolas Heist</a>, 
<a href="/search/cs?searchtype=author&query=Hertling%2C+S">Sven Hertling</a>, 
<a href="/search/cs?searchtype=author&query=Paulheim%2C+H">Heiko Paulheim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for the Short Paper track of CIKM'23, October 21-25, 2023, Birmingham, United Kingdom
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Databases (cs.DB); Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, countless research papers have addressed the topics of
knowledge graph creation, extension, or completion in order to create knowledge
graphs that are larger, more correct, or more diverse. This research is
typically motivated by the argumentation that using such enhanced knowledge
graphs to solve downstream tasks will improve performance. Nonetheless, this is
hardly ever evaluated. Instead, the predominant evaluation metrics - aiming at
correctness and completeness - are undoubtedly valuable but fail to capture the
complete picture, i.e., how useful the created or enhanced knowledge graph
actually is. Further, the accessibility of such a knowledge graph is rarely
considered (e.g., whether it contains expressive labels, descriptions, and
sufficient context information to link textual mentions to the entities of the
knowledge graph). To better judge how well knowledge graphs perform on actual
tasks, we present KGrEaT - a framework to estimate the quality of knowledge
graphs via actual downstream tasks like classification, clustering, or
recommendation. Instead of comparing different methods of processing knowledge
graphs with respect to a single task, the purpose of KGrEaT is to compare
various knowledge graphs as such by evaluating them on a fixed task setup. The
framework takes a knowledge graph as input, automatically maps it to the
datasets to be evaluated on, and computes performance metrics for the defined
tasks. It is built in a modular way to be easily extendable with additional
tasks and datasets.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10543" title="Abstract">arXiv:2308.10543</a> [<a href="/pdf/2308.10543" title="Download PDF">pdf</a>, <a href="/format/2308.10543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Anchor-Point Based Image-Model for Room Impulse Response Simulation  with Directional Source Radiation and Sensor Directivity Patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+C">Chao Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yilong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jilu Jin</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Lin Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingdong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Benesty%2C+J">Jacob Benesty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The image model method has been widely used to simulate room impulse
responses and the endeavor to adapt this method to different applications has
also piqued great interest over the last few decades. This paper attempts to
extend the image model method and develops an anchor-point-image-model (APIM)
approach as a solution for simulating impulse responses by including both the
source radiation and sensor directivity patterns. To determine the orientations
of all the virtual sources, anchor points are introduced to real sources, which
subsequently lead to the determination of the orientations of the virtual
sources. An algorithm is developed to generate room impulse responses with APIM
by taking into account the directional pattern functions, factional time
delays, as well as the computational complexity. The developed model and
algorithms can be used in various acoustic problems to simulate room acoustics
and improve and evaluate processing algorithms.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10544" title="Abstract">arXiv:2308.10544</a> [<a href="/pdf/2308.10544" title="Download PDF">pdf</a>, <a href="/format/2308.10544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Accelerated Model Training via Bayesian Data Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhijie Deng</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+P">Peng Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Mislabeled, duplicated, or biased data in real-world scenarios can lead to
prolonged training and even hinder model convergence. Traditional solutions
prioritizing easy or hard samples lack the flexibility to handle such a variety
simultaneously. Recent work has proposed a more reasonable data selection
principle by examining the data's impact on the model's generalization loss.
However, its practical adoption relies on less principled approximations and
additional clean holdout data. This work solves these problems by leveraging a
lightweight Bayesian treatment and incorporating off-the-shelf zero-shot
predictors built on large-scale pre-trained models. The resulting algorithm is
efficient and easy-to-implement. We perform extensive empirical studies on
challenging benchmarks with considerable data noise and imbalance in the online
batch selection scenario, and observe superior training efficiency over
competitive baselines. Notably, on the challenging WebVision benchmark, our
method can achieve similar predictive performance with significantly fewer
training iterations than leading data selection methods.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10548" title="Abstract">arXiv:2308.10548</a> [<a href="/pdf/2308.10548" title="Download PDF">pdf</a>, <a href="/ps/2308.10548" title="Download PostScript">ps</a>, <a href="/format/2308.10548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Typing Composable Coroutines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Qiqi Gu</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+W">Wei Ke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Coroutine, as a powerful programming construct, is widely used in
asynchronous applications to replace thread-based programming or the callback
hell. Using coroutines makes code more readable and maintainable, for its
ability to transfer control while keeping the literal scope. However, reasoning
about coroutine behavior can be challenging without proper typing. We propose a
type notation and calculus for composing asymmetric, first-class, stackless
coroutines. Given the types of a list of coroutines, we can compute a composed
type matching the collective behavior of the coroutines, so that the input and
output can be type-checked by a type system. Our coroutine types can model the
data received by or yielded from a coroutine, which be of coroutine types as
well. On top of our type calculus, we discuss its soundness and evaluation
issues, then provide four application scenarios of our coroutine types. Not
only can our types be used in modern programming languages, such as Python, but
also model program behaviors in OCaml and even Prolog.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10549" title="Abstract">arXiv:2308.10549</a> [<a href="/pdf/2308.10549" title="Download PDF">pdf</a>, <a href="/format/2308.10549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Temporal Persistence Using Replicability Measures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Keller%2C+J">J&#xfc;ri Keller</a>, 
<a href="/search/cs?searchtype=author&query=Breuer%2C+T">Timo Breuer</a>, 
<a href="/search/cs?searchtype=author&query=Schaer%2C+P">Philipp Schaer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in Proceedings of the Working Notes of CLEF 2023 - Conference and Labs of the Evaluation Forum, Thessaloniki, Greece 18 - 21, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">In real-world Information Retrieval (IR) experiments, the Evaluation
Environment (EE) is exposed to constant change. Documents are added, removed,
or updated, and the information need and the search behavior of users is
evolving. Simultaneously, IR systems are expected to retain a consistent
quality. The LongEval Lab seeks to investigate the longitudinal persistence of
IR systems, and in this work, we describe our participation. We submitted runs
of five advanced retrieval systems, namely a Reciprocal Rank Fusion (RRF)
approach, ColBERT, monoT5, Doc2Query, and E5, to both sub-tasks. Further, we
cast the longitudinal evaluation as a replicability study to better understand
the temporal change observed. As a result, we quantify the persistence of the
submitted runs and see great potential in this evaluation method.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10552" title="Abstract">arXiv:2308.10552</a> [<a href="/pdf/2308.10552" title="Download PDF">pdf</a>, <a href="/format/2308.10552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communicating Robot&#x27;s Intentions while Assisting Users via Augmented  Reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Stouraitis%2C+T">Theodoros Stouraitis</a>, 
<a href="/search/cs?searchtype=author&query=Belardinelli%2C+A">Anna Belardinelli</a>, 
<a href="/search/cs?searchtype=author&query=Hasler%2C+S">Stephan Hasler</a>, 
<a href="/search/cs?searchtype=author&query=Gienger%2C+M">Michael Gienger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">This paper explores the challenges faced by assistive robots in effectively
cooperating with humans, requiring them to anticipate human behavior, predict
their actions' impact, and generate understandable robot actions. The study
focuses on a use-case involving a user with limited mobility needing assistance
with pouring a beverage, where tasks like unscrewing a cap or reaching for
objects demand coordinated support from the robot. Yet, anticipating the
robot's intentions can be challenging for the user, which can hinder effective
collaboration. To address this issue, we propose an innovative solution that
utilizes Augmented Reality (AR) to communicate the robot's intentions and
expected movements to the user, fostering a seamless and intuitive interaction.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10554" title="Abstract">arXiv:2308.10554</a> [<a href="/pdf/2308.10554" title="Download PDF">pdf</a>, <a href="/format/2308.10554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Diversity in Zero-Shot GAN Adaptation with Semantic Variations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeon%2C+S">Seogkyu Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+P">Pilhyeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+K">Kibeom Hong</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jianlong Fu</a>, 
<a href="/search/cs?searchtype=author&query=Byun%2C+H">Hyeran Byun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023 (poster)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Training deep generative models usually requires a large amount of data. To
alleviate the data collection cost, the task of zero-shot GAN adaptation aims
to reuse well-trained generators to synthesize images of an unseen target
domain without any further training samples. Due to the data absence, the
textual description of the target domain and the vision-language models, e.g.,
CLIP, are utilized to effectively guide the generator. However, with only a
single representative text feature instead of real images, the synthesized
images gradually lose diversity as the model is optimized, which is also known
as mode collapse. To tackle the problem, we propose a novel method to find
semantic variations of the target text in the CLIP space. Specifically, we
explore diverse semantic variations based on the informative text feature of
the target domain while regularizing the uncontrolled deviation of the semantic
information. With the obtained variations, we design a novel directional moment
loss that matches the first and second moments of image and text direction
distributions. Moreover, we introduce elastic weight consolidation and a
relation consistency loss to effectively preserve valuable content information
from the source domain, e.g., appearances. Through extensive experiments, we
demonstrate the efficacy of the proposed methods in ensuring sample diversity
in various scenarios of zero-shot GAN adaptation. We also conduct ablation
studies to validate the effect of each proposed component. Notably, our model
achieves a new state-of-the-art on zero-shot GAN adaptation in terms of both
diversity and quality.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10555" title="Abstract">arXiv:2308.10555</a> [<a href="/pdf/2308.10555" title="Download PDF">pdf</a>, <a href="/format/2308.10555" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Programming for Device-Edge-Cloud Continuum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le-Tuan%2C+A">Anh Le-Tuan</a>, 
<a href="/search/cs?searchtype=author&query=Bowden%2C+D">David Bowden</a>, 
<a href="/search/cs?searchtype=author&query=Le-Phuoc%2C+D">Danh Le-Phuoc</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2202.13958">arXiv:2202.13958</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">This position paper presents ThothSP, a Semantic Programming framework with
the aim of lowering the coding effort in building smart applications on the
Device-Edge-Cloud continuum by leveraging semantic knowledge. It introduces a
novel neural-symbolic stream fusion mechanism, which enables the specification
of data fusion pipelines via declarative rules, with degrees of learnable
probabilistic weights. Moreover, it includes an adaptive federator that allows
the Thoth&gt;runtime to be distributed across multiple compute nodes in a network,
and to coordinate their resources to collaboratively process tasks by
delegating partial workloads to their peers. To demonstrate ThothSP's
capability, we report a case study on a distributed camera network to show
ThothSP's behaviour against a traditional edge-cloud setup.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10557" title="Abstract">arXiv:2308.10557</a> [<a href="/pdf/2308.10557" title="Download PDF">pdf</a>, <a href="/format/2308.10557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local Spherical Harmonics Improve Skeleton-Based Hand Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prasse%2C+K">Katharina Prasse</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+S">Steffen Jung</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuxuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Keuper%2C+M">Margret Keuper</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Hand action recognition is essential. Communication, human-robot
interactions, and gesture control are dependent on it. Skeleton-based action
recognition traditionally includes hands, which belong to the classes which
remain challenging to correctly recognize to date. We propose a method
specifically designed for hand action recognition which uses relative angular
embeddings and local Spherical Harmonics to create novel hand representations.
The use of Spherical Harmonics creates rotation-invariant representations which
make hand action recognition even more robust against inter-subject differences
and viewpoint changes. We conduct extensive experiments on the hand joints in
the First-Person Hand Action Benchmark with RGB-D Videos and 3D Hand Pose
Annotations, and on the NTU RGB+D 120 dataset, demonstrating the benefit of
using Local Spherical Harmonics Representations. Our code is available at
https://github.com/KathPra/LSHR_LSHT.
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10559" title="Abstract">arXiv:2308.10559</a> [<a href="/pdf/2308.10559" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metaverse: A Vision, Architectural Elements, and Future Directions for  Scalable and Realtime Virtual Worlds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ismail%2C+L">Leila Ismail</a>, 
<a href="/search/cs?searchtype=author&query=Buyya%2C+R">Rajkumar Buyya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the emergence of Cloud computing, Internet of Things-enabled
Human-Computer Interfaces, Generative Artificial Intelligence, and
high-accurate Machine and Deep-learning recognition and predictive models,
along with the Post Covid-19 proliferation of social networking, and remote
communications, the Metaverse gained a lot of popularity. Metaverse has the
prospective to extend the physical world using virtual and augmented reality so
the users can interact seamlessly with the real and virtual worlds using
avatars and holograms. It has the potential to impact people in the way they
interact on social media, collaborate in their work, perform marketing and
business, teach, learn, and even access personalized healthcare. Several works
in the literature examine Metaverse in terms of hardware wearable devices, and
virtual reality gaming applications. However, the requirements of realizing the
Metaverse in realtime and at a large-scale need yet to be examined for the
technology to be usable. To address this limitation, this paper presents the
temporal evolution of Metaverse definitions and captures its evolving
requirements. Consequently, we provide insights into Metaverse requirements. In
addition to enabling technologies, we lay out architectural elements for
scalable, reliable, and efficient Metaverse systems, and a classification of
existing Metaverse applications along with proposing required future research
directions.
</p>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10560" title="Abstract">arXiv:2308.10560</a> [<a href="/pdf/2308.10560" title="Download PDF">pdf</a>, <a href="/ps/2308.10560" title="Download PostScript">ps</a>, <a href="/format/2308.10560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wide-Aperture MIMO via Reflection off a Smooth Surface
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pizzo%2C+A">Andrea Pizzo</a>, 
<a href="/search/cs?searchtype=author&query=Lozano%2C+A">Angel Lozano</a>, 
<a href="/search/cs?searchtype=author&query=Rangan%2C+S">Sundeep Rangan</a>, 
<a href="/search/cs?searchtype=author&query=Marzetta%2C+T">Thomas Marzetta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2205.01213">arXiv:2205.01213</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in IEEE Transactions on Wireless Communications, vol. 22, no. 8,
  pp. 5229-5239, Aug. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">This paper provides a deterministic channel model for a scenario where
wireless connectivity is established through a reflection off a smooth planar
surface of an infinite extent. The developed model is rigorously built upon the
physics of wave propagation and is as precise as tight are the unboundedness
and smoothness assumptions on the surface. This model allows establishing how
line-of-sight multiantenna communication is altered by a reflection off an
electrically large surface, a situation of high interest for mmWave and
terahertz frequencies.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10561" title="Abstract">arXiv:2308.10561</a> [<a href="/pdf/2308.10561" title="Download PDF">pdf</a>, <a href="/format/2308.10561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial Transform Decoupling for Oriented Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hongtian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yunjie Tian</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qixiang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunfan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision Transformers (ViTs) have achieved remarkable success in computer
vision tasks. However, their potential in rotation-sensitive scenarios has not
been fully explored, and this limitation may be inherently attributed to the
lack of spatial invariance in the data-forwarding process. In this study, we
present a novel approach, termed Spatial Transform Decoupling (STD), providing
a simple-yet-effective solution for oriented object detection with ViTs. Built
upon stacked ViT blocks, STD utilizes separate network branches to predict the
position, size, and angle of bounding boxes, effectively harnessing the spatial
transform potential of ViTs in a divide-and-conquer fashion. Moreover, by
aggregating cascaded activation masks (CAMs) computed upon the regressed
parameters, STD gradually enhances features within regions of interest (RoIs),
which complements the self-attention mechanism. Without bells and whistles, STD
achieves state-of-the-art performance on the benchmark datasets including
DOTA-v1.0 (82.24% mAP) and HRSC2016 (98.55% mAP), which demonstrates the
effectiveness of the proposed method. Source code is available at
https://github.com/yuhongtian17/Spatial-Transform-Decoupling.
</p>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10562" title="Abstract">arXiv:2308.10562</a> [<a href="/pdf/2308.10562" title="Download PDF">pdf</a>, <a href="/format/2308.10562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seeing the Intangible: Surveying Automatic High-Level Visual  Understanding from Still Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pandiani%2C+D+S+M">Delfina Sol Martinez Pandiani</a>, 
<a href="/search/cs?searchtype=author&query=Presutti%2C+V">Valentina Presutti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">The field of Computer Vision (CV) was born with the single grand goal of
complete image understanding: providing a complete semantic interpretation of
an input image. What exactly this goal entails is not immediately
straightforward, but theoretical hierarchies of visual understanding point
towards a top level of full semantics, within which sits the most complex and
subjective information humans can detect from visual data. In particular,
non-concrete concepts including emotions, social values and ideologies seem to
be protagonists of this "high-level" visual semantic understanding. While such
"abstract concepts" are critical tools for image management and retrieval,
their automatic recognition is still a challenge, exactly because they rest at
the top of the "semantic pyramid": the well-known semantic gap problem is
worsened given their lack of unique perceptual referents, and their reliance on
more unspecific features than concrete concepts. Given that there seems to be
very scarce explicit work within CV on the task of abstract social concept
(ASC) detection, and that many recent works seem to discuss similar
non-concrete entities by using different terminology, in this survey we provide
a systematic review of CV work that explicitly or implicitly approaches the
problem of abstract (specifically social) concept detection from still images.
Specifically, this survey performs and provides: (1) A study and clustering of
high level visual understanding semantic elements from a multidisciplinary
perspective (computer science, visual studies, and cognitive perspectives); (2)
A study and clustering of high level visual understanding computer vision tasks
dealing with the identified semantic elements, so as to identify current CV
work that implicitly deals with AC detection.
</p>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10564" title="Abstract">arXiv:2308.10564</a> [<a href="/pdf/2308.10564" title="Download PDF">pdf</a>, <a href="/format/2308.10564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Software Entity Recognition with Noise-Robust Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Tai Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+Y">Yifeng Di</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Joohan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Muhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ASE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Recognizing software entities such as library names from free-form text is
essential to enable many software engineering (SE) technologies, such as
traceability link recovery, automated documentation, and API recommendation.
While many approaches have been proposed to address this problem, they suffer
from small entity vocabularies or noisy training data, hindering their ability
to recognize software entities mentioned in sophisticated narratives. To
address this challenge, we leverage the Wikipedia taxonomy to develop a
comprehensive entity lexicon with 79K unique software entities in 12
fine-grained types, as well as a large labeled dataset of over 1.7M sentences.
Then, we propose self-regularization, a noise-robust learning approach, to the
training of our software entity recognition (SER) model by accounting for many
dropouts. Results show that models trained with self-regularization outperform
both their vanilla counterparts and state-of-the-art approaches on our
Wikipedia benchmark and two Stack Overflow benchmarks. We release our models,
data, and code for future research.
</p>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10569" title="Abstract">arXiv:2308.10569</a> [<a href="/pdf/2308.10569" title="Download PDF">pdf</a>, <a href="/format/2308.10569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RT-MonoDepth: Real-time Monocular Depth Estimation on Embedded Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Cheng Feng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Congxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Weiming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bing Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+F">Feng Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Depth sensing is a crucial function of unmanned aerial vehicles and
autonomous vehicles. Due to the small size and simple structure of monocular
cameras, there has been a growing interest in depth estimation from a single
RGB image. However, state-of-the-art monocular CNN-based depth estimation
methods using fairly complex deep neural networks are too slow for real-time
inference on embedded platforms. This paper addresses the problem of real-time
depth estimation on embedded systems. We propose two efficient and lightweight
encoder-decoder network architectures, RT-MonoDepth and RT-MonoDepth-S, to
reduce computational complexity and latency. Our methodologies demonstrate that
it is possible to achieve similar accuracy as prior state-of-the-art works on
depth estimation at a faster inference speed. Our proposed networks,
RT-MonoDepth and RT-MonoDepth-S, runs at 18.4\&amp;30.5 FPS on NVIDIA Jetson Nano
and 253.0\&amp;364.1 FPS on NVIDIA Jetson AGX Orin on a single RGB image of
resolution 640$\times$192, and achieve relative state-of-the-art accuracy on
the KITTI dataset. To the best of the authors' knowledge, this paper achieves
the best accuracy and fastest inference speed compared with existing fast
monocular depth estimation methods.
</p>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10570" title="Abstract">arXiv:2308.10570</a> [<a href="/pdf/2308.10570" title="Download PDF">pdf</a>, <a href="/format/2308.10570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Feedback DETR for Temporal Action Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jihwan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Miso Lee</a>, 
<a href="/search/cs?searchtype=author&query=Heo%2C+J">Jae-Pil Heo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Temporal Action Detection (TAD) is challenging but fundamental for real-world
video applications. Recently, DETR-based models have been devised for TAD but
have not performed well yet. In this paper, we point out the problem in the
self-attention of DETR for TAD; the attention modules focus on a few key
elements, called temporal collapse problem. It degrades the capability of the
encoder and decoder since their self-attention modules play no role. To solve
the problem, we propose a novel framework, Self-DETR, which utilizes
cross-attention maps of the decoder to reactivate self-attention modules. We
recover the relationship between encoder features by simple matrix
multiplication of the cross-attention map and its transpose. Likewise, we also
get the information within decoder queries. By guiding collapsed self-attention
maps with the guidance map calculated, we settle down the temporal collapse of
self-attention modules in the encoder and decoder. Our extensive experiments
demonstrate that Self-DETR resolves the temporal collapse problem by keeping
high diversity of attention over all layers.
</p>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10571" title="Abstract">arXiv:2308.10571</a> [<a href="/pdf/2308.10571" title="Download PDF">pdf</a>, <a href="/format/2308.10571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overcoming Overconfidence for Active Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hwang%2C+Y">Yujin Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Jo%2C+W">Won Jo</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Juyoung Hong</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yukyung Choi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">It is not an exaggeration to say that the recent progress in artificial
intelligence technology depends on large-scale and high-quality data.
Simultaneously, a prevalent issue exists everywhere: the budget for data
labeling is constrained. Active learning is a prominent approach for addressing
this issue, where valuable data for labeling is selected through a model and
utilized to iteratively adjust the model. However, due to the limited amount of
data in each iteration, the model is vulnerable to bias; thus, it is more
likely to yield overconfident predictions. In this paper, we present two novel
methods to address the problem of overconfidence that arises in the active
learning scenario. The first is an augmentation strategy named
Cross-Mix-and-Mix (CMaM), which aims to calibrate the model by expanding the
limited training distribution. The second is a selection strategy named Ranked
Margin Sampling (RankedMS), which prevents choosing data that leads to overly
confident predictions. Through various experiments and analyses, we are able to
demonstrate that our proposals facilitate efficient data selection by
alleviating overconfidence, even though they are readily applicable.
</p>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10574" title="Abstract">arXiv:2308.10574</a> [<a href="/pdf/2308.10574" title="Download PDF">pdf</a>, <a href="/format/2308.10574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CHORD: Category-level Hand-held Object Reconstruction via Shape  Deformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kailin Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lixin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhen%2C+H">Haoyu Zhen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zenan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xinyu Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+L">Licheng Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kejian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be presented at ICCV 2023, Paris
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In daily life, humans utilize hands to manipulate objects. Modeling the shape
of objects that are manipulated by the hand is essential for AI to comprehend
daily tasks and to learn manipulation skills. However, previous approaches have
encountered difficulties in reconstructing the precise shapes of hand-held
objects, primarily owing to a deficiency in prior shape knowledge and
inadequate data for training. As illustrated, given a particular type of tool,
such as a mug, despite its infinite variations in shape and appearance, humans
have a limited number of 'effective' modes and poses for its manipulation. This
can be attributed to the fact that humans have mastered the shape prior of the
'mug' category, and can quickly establish the corresponding relations between
different mug instances and the prior, such as where the rim and handle are
located. In light of this, we propose a new method, CHORD, for Category-level
Hand-held Object Reconstruction via shape Deformation. CHORD deforms a
categorical shape prior for reconstructing the intra-class objects. To ensure
accurate reconstruction, we empower CHORD with three types of awareness:
appearance, shape, and interacting pose. In addition, we have constructed a new
dataset, COMIC, of category-level hand-object interaction. COMIC contains a
rich array of object instances, materials, hand interactions, and viewing
directions. Extensive evaluation shows that CHORD outperforms state-of-the-art
approaches in both quantitative and qualitative measures. Code, model, and
datasets are available at https://kailinli.github.io/CHORD.
</p>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10576" title="Abstract">arXiv:2308.10576</a> [<a href="/pdf/2308.10576" title="Download PDF">pdf</a>, <a href="/format/2308.10576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incorprating Prompt tuning for Commit classification with prior  Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tong%2C+J">Jiajun Tong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhixiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Rui%2C+X">Xiaobin Rui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Commit Classification(CC) is an important task in software maintenance since
it helps software developers classify code changes into different types
according to their nature and purpose. This allows them to better understand
how their development efforts are progressing, identify areas where they need
improvement. However, existing methods are all discriminative models, usually
with complex architectures that require additional output layers to produce
class label probabilities. Moreover, they require a large amount of labeled
data for fine-tuning, and it is difficult to learn effective classification
boundaries in the case of limited labeled data. To solve above problems, we
propose a generative framework that Incorporating prompt-tuning for commit
classification with prior knowledge (IPCK)
https://github.com/AppleMax1992/IPCK, which simplifies the model structure and
learns features across different tasks. It can still reach the SOTA performance
with only limited samples. Firstly, we proposed a generative framework based on
T5. This encoder-decoder construction method unifies different CC task into a
text2text problem, which simplifies the structure of the model by not requiring
an extra output layer. Second, instead of fine-tuning, we design an
prompt-tuning solution which can be adopted in few-shot scenarios with only
limit samples. Furthermore, we incorporate prior knowledge via an external
knowledge graph to map the probabilities of words into the final labels in the
speech machine step to improve performance in few-shot scenarios. Extensive
experiments on two open available datasets show that our framework can solve
the CC problem simply but effectively in few-shot and zeroshot scenarios, while
improving the adaptability of the model without requiring a large amount of
training samples for fine-tuning.
</p>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10578" title="Abstract">arXiv:2308.10578</a> [<a href="/pdf/2308.10578" title="Download PDF">pdf</a>, <a href="/format/2308.10578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly synchronous systems with three machines are Turing powerful
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di+Giusto%2C+C">Cinzia Di Giusto</a> (C&amp;A), 
<a href="/search/cs?searchtype=author&query=Ferr%C3%A9%2C+D">Davide Ferr&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Lozes%2C+E">Etienne Lozes</a> (I3S, LSV), 
<a href="/search/cs?searchtype=author&query=Nisse%2C+N">Nicolas Nisse</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">Communicating finite-state machines (CFMs) are a Turing powerful model of
asynchronous message-passing distributed systems. In weakly synchronous
systems, processes communicate through phases in which messages are first sent
and then received, for each process. Such systems enjoy a limited form of
synchronization, and for some communication models, this restriction is enough
to make the reachability problem decidable. In particular, we explore the
intriguing case of p2p (FIFO) communication, for which the reachability problem
is known to be undecidable for four processes, but decidable for two. We show
that the configuration reachability problem for weakly synchronous systems of
three processes is undecidable. This result is heavily inspired by our study on
the treewidth of the Message Sequence Charts (MSCs) that might be generated by
such systems. In this sense, the main contribution of this work is a weakly
synchronous system with three processes that generates MSCs of arbitrarily
large treewidth.
</p>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10579" title="Abstract">arXiv:2308.10579</a> [<a href="/pdf/2308.10579" title="Download PDF">pdf</a>, <a href="/format/2308.10579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demand-Aware Network Design with Steiner Nodes and a Connection to  Virtual Network Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Figiel%2C+A">Aleksander Figiel</a>, 
<a href="/search/cs?searchtype=author&query=Korhonen%2C+J+H">Janne H. Korhonen</a>, 
<a href="/search/cs?searchtype=author&query=Olver%2C+N">Neil Olver</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+S">Stefan Schmid</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Emerging optical and virtualization technologies enable the design of more
flexible and demand-aware networked systems, in which resources can be
optimized toward the actual workload they serve. For example, in a demand-aware
datacenter network, frequently communicating nodes (e.g., two virtual machines
or a pair of racks in a datacenter) can be placed topologically closer,
reducing communication costs and hence improving the overall network
performance.
<br />This paper revisits the bounded-degree network design problem underlying such
demand-aware networks. Namely, given a distribution over communicating server
pairs, we want to design a network with bounded maximum degree that minimizes
expected communication distance. In addition to this known problem, we
introduce and study a variant where we allow Steiner nodes (i.e., additional
routers) to be added to augment the network.
<br />We improve the understanding of this problem domain in several ways. First,
we shed light on the complexity and hardness of the aforementioned problems,
and study a connection between them and the virtual networking embedding
problem. We then provide a constant-factor approximation algorithm for the
Steiner node version of the problem, and use it to improve over prior
state-of-the-art algorithms for the original version of the problem with sparse
communication distributions. Finally, we investigate various heuristic
approaches to bounded-degree network design problem, in particular providing a
reliable heuristic algorithm with good experimental performance.
<br />We report on an extensive empirical evaluation, using several real-world
traffic traces from datacenters, and find that our approach results in improved
demand-aware network designs.
</p>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10584" title="Abstract">arXiv:2308.10584</a> [<a href="/pdf/2308.10584" title="Download PDF">pdf</a>, <a href="/format/2308.10584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RADIANCE: Radio-Frequency Adversarial Deep-learning Inference for  Automated Network Coverage Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S">Sopan Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Manshaei%2C+M+H">Mohammad Hossein Manshaei</a>, 
<a href="/search/cs?searchtype=author&query=Krunz%2C+M">Marwan Krunz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Radio-frequency coverage maps (RF maps) are extensively utilized in wireless
networks for capacity planning, placement of access points and base stations,
localization, and coverage estimation. Conducting site surveys to obtain RF
maps is labor-intensive and sometimes not feasible. In this paper, we propose
radio-frequency adversarial deep-learning inference for automated network
coverage estimation (RADIANCE), a generative adversarial network (GAN) based
approach for synthesizing RF maps in indoor scenarios. RADIANCE utilizes a
semantic map, a high-level representation of the indoor environment to encode
spatial relationships and attributes of objects within the environment and
guide the RF map generation process. We introduce a new gradient-based loss
function that computes the magnitude and direction of change in received signal
strength (RSS) values from a point within the environment. RADIANCE
incorporates this loss function along with the antenna pattern to capture
signal propagation within a given indoor configuration and generate new
patterns under new configuration, antenna (beam) pattern, and center frequency.
Extensive simulations are conducted to compare RADIANCE with ray-tracing
simulations of RF maps. Our results show that RADIANCE achieves a mean average
error (MAE) of 0.09, root-mean-squared error (RMSE) of 0.29, peak
signal-to-noise ratio (PSNR) of 10.78, and multi-scale structural similarity
index (MS-SSIM) of 0.80.
</p>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10585" title="Abstract">arXiv:2308.10585</a> [<a href="/pdf/2308.10585" title="Download PDF">pdf</a>, <a href="/format/2308.10585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Equation as a Better Intermediate Meaning Representation for  Numerical Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dingzirui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+L">Longxu Dou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenbin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+J">Junyu Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+W">Wanxiang Che</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Numerical reasoning is vital for natural language processing models to
understand and process numerical information in real-world scenarios. Most
current methods first generate the Intermediate Meaning Representations (IMRs)
of questions and then generate answers. Current SOTA methods generate programs
as IMRs with large language models (LLMs). Intuitively, equations have fewer
restrictions and closer semantics to the question than programs, leading to
higher generation accuracy. However, current LLMs generate equations worse than
programs, where we assume that the equation data is rare in pre-training data
compared to programs. So in this paper, we try to use equations as IMRs to
solve the numerical reasoning task by addressing two problems: (1)
Theoretically, how to prove that the equation is an IMR with higher generation
accuracy than programs; (2) Empirically, how to improve the generation accuracy
of equations with LLMs. For the first problem, we propose and prove a
proposition to theoretically compare the generation accuracy of different IMRs.
For the second problem, we present a method called Boosting Numerical
Reason\textbfing by Decomposing the Generation of Equations (Bridge), which can
improve the accuracy of LLMs in generating equations as IMRs by reducing the
tendency of generating constant expressions and programs. Our method improves
the performance by 2.2%, 0.9%, and 1.7% on GSM8K, SVAMP, and Algebra datasets
compared to the previous state-of-the-art methods under the single reasoning
path setting. Our codes and prompts are released in
https://github.com/zirui-HIT/Bridge_for_Numerical_Reasoning.
</p>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10586" title="Abstract">arXiv:2308.10586</a> [<a href="/pdf/2308.10586" title="Download PDF">pdf</a>, <a href="/format/2308.10586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Age Recommendation from Texts and Sentences for Children
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahman%2C+R">Rashedur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Lecorv%C3%A9%2C+G">Gw&#xe9;nol&#xe9; Lecorv&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%A9chet%2C+N">Nicolas B&#xe9;chet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages (incl. 4 pages for appendices), 4 figures, 20 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Children have less text understanding capability than adults. Moreover, this
capability differs among the children of different ages. Hence, automatically
predicting a recommended age based on texts or sentences would be a great
benefit to propose adequate texts to children and to help authors writing in
the most appropriate way. This paper presents our recent advances on the age
recommendation task. We consider age recommendation as a regression task, and
discuss the need for appropriate evaluation metrics, study the use of
state-of-the-art machine learning model, namely Transformers, and compare it to
different models coming from the literature. Our results are also compared with
recommendations made by experts. Further, this paper deals with preliminary
explainability of the age prediction model by analyzing various linguistic
features. We conduct the experiments on a dataset of 3, 673 French texts (132K
sentences, 2.5M words). To recommend age at the text level and sentence level,
our best models achieve MAE scores of 0.98 and 1.83 respectively on the test
set. Also, compared to the recommendations made by experts, our sentence-level
recommendation model gets a similar score to the experts, while the text-level
recommendation model outperforms the experts by an MAE score of 1.48.
</p>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10587" title="Abstract">arXiv:2308.10587</a> [<a href="/pdf/2308.10587" title="Download PDF">pdf</a>, <a href="/format/2308.10587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formal Analysis and Verification of Max-Plus Linear Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mufid%2C+M+S">Muhammad Syifa&#x27;ul Mufid</a>, 
<a href="/search/cs?searchtype=author&query=Micheli%2C+A">Andrea Micheli</a>, 
<a href="/search/cs?searchtype=author&query=Abate%2C+A">Alessandro Abate</a>, 
<a href="/search/cs?searchtype=author&query=Cimatti%2C+A">Alessandro Cimatti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages (including appendixes)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">Max-Plus Linear (MPL) systems are an algebraic formalism with practical
applications in transportation networks, manufacturing and biological systems.
In this paper, we investigate the problem of automatically analyzing the
properties of MPL, taking into account both structural properties such as
transient and cyclicity, and the open problem of user-defined temporal
properties. We propose Time-Difference LTL (TDLTL), a logic that encompasses
the delays between the discrete time events governed by an MPL system, and
characterize the problem of model checking TDLTL over MPL. We first consider a
framework based on the verification of infinite-state transition systems, and
propose an approach based on an encoding into model checking. Then, we leverage
the specific features of MPL systems to devise a highly optimized,
combinational approach based on Satisfiability Modulo Theory (SMT). We
experimentally evaluate the features of the proposed approaches on a large set
of benchmarks. The results show that the proposed approach substantially
outperforms the state of the art competitors in expressiveness and
effectiveness, and demonstrate the superiority of the combinational approach
over the reduction to model checking.
</p>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10592" title="Abstract">arXiv:2308.10592</a> [<a href="/pdf/2308.10592" title="Download PDF">pdf</a>, <a href="/format/2308.10592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BAN-PL: a Novel Polish Dataset of Banned Harmful and Offensive Content  from Wykop.pl web service
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Okulska%2C+I">Inez Okulska</a>, 
<a href="/search/cs?searchtype=author&query=G%C5%82%C4%85bi%C5%84ska%2C+K">Kinga G&#x142;&#x105;bi&#x144;ska</a>, 
<a href="/search/cs?searchtype=author&query=Ko%C5%82os%2C+A">Anna Ko&#x142;os</a>, 
<a href="/search/cs?searchtype=author&query=Karli%C5%84ska%2C+A">Agnieszka Karli&#x144;ska</a>, 
<a href="/search/cs?searchtype=author&query=Wi%C5%9Bnios%2C+E">Emilia Wi&#x15b;nios</a>, 
<a href="/search/cs?searchtype=author&query=Nowakowski%2C+A">Adam Nowakowski</a>, 
<a href="/search/cs?searchtype=author&query=Ellerik%2C+P">Pawe&#x142; Ellerik</a>, 
<a href="/search/cs?searchtype=author&query=Pra%C5%82at%2C+A">Andrzej Pra&#x142;at</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Advances in automated detection of offensive language online, including hate
speech and cyberbullying, require improved access to publicly available
datasets comprising social media content. In this paper, we introduce BAN-PL,
the first open dataset in the Polish language that encompasses texts flagged as
harmful and subsequently removed by professional moderators. The dataset
encompasses a total of 691,662 pieces of content from a popular social
networking service, Wykop.pl, often referred to as the "Polish Reddit",
including both posts and comments, and is evenly distributed into two distinct
classes: "harmful" and "neutral". We provide a comprehensive description of the
data collection and preprocessing procedures, as well as highlight the
linguistic specificity of the data. The BAN-PL dataset, along with advanced
preprocessing scripts for, i.a., unmasking profanities, will be publicly
available.
</p>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10597" title="Abstract">arXiv:2308.10597</a> [<a href="/pdf/2308.10597" title="Download PDF">pdf</a>, <a href="/format/2308.10597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Doppler-aware Odometry from FMCW Scanning Radar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rennie%2C+F">Fraser Rennie</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+D">David Williams</a>, 
<a href="/search/cs?searchtype=author&query=Newman%2C+P">Paul Newman</a>, 
<a href="/search/cs?searchtype=author&query=De+Martini%2C+D">Daniele De Martini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ITSC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This work explores Doppler information from a millimetre-Wave (mm-W)
Frequency-Modulated Continuous-Wave (FMCW) scanning radar to make odometry
estimation more robust and accurate. Firstly, doppler information is added to
the scan masking process to enhance correlative scan matching. Secondly, we
train a Neural Network (NN) for regressing forward velocity directly from a
single radar scan; we fuse this estimate with the correlative scan matching
estimate and show improved robustness to bad estimates caused by challenging
environment geometries, e.g. narrow tunnels. We test our method with a novel
custom dataset which is released with this work at
https://ori.ox.ac.uk/publications/datasets.
</p>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10599" title="Abstract">arXiv:2308.10599</a> [<a href="/pdf/2308.10599" title="Download PDF">pdf</a>, <a href="/format/2308.10599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image-free Classifier Injection for Zero-Shot Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Christensen%2C+A">Anders Christensen</a>, 
<a href="/search/cs?searchtype=author&query=Mancini%2C+M">Massimiliano Mancini</a>, 
<a href="/search/cs?searchtype=author&query=Koepke%2C+A+S">A. Sophia Koepke</a>, 
<a href="/search/cs?searchtype=author&query=Winther%2C+O">Ole Winther</a>, 
<a href="/search/cs?searchtype=author&query=Akata%2C+Z">Zeynep Akata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Zero-shot learning models achieve remarkable results on image classification
for samples from classes that were not seen during training. However, such
models must be trained from scratch with specialised methods: therefore, access
to a training dataset is required when the need for zero-shot classification
arises. In this paper, we aim to equip pre-trained models with zero-shot
classification capabilities without the use of image data. We achieve this with
our proposed Image-free Classifier Injection with Semantics (ICIS) that injects
classifiers for new, unseen classes into pre-trained classification models in a
post-hoc fashion without relying on image data. Instead, the existing
classifier weights and simple class-wise descriptors, such as class names or
attributes, are used. ICIS has two encoder-decoder networks that learn to
reconstruct classifier weights from descriptors (and vice versa), exploiting
(cross-)reconstruction and cosine losses to regularise the decoding process.
Notably, ICIS can be cheaply trained and applied directly on top of pre-trained
classification models. Experiments on benchmark ZSL datasets show that ICIS
produces unseen classifier weights that achieve strong (generalised) zero-shot
classification performance. Code is available at
https://github.com/ExplainableML/ImageFreeZSL .
</p>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10600" title="Abstract">arXiv:2308.10600</a> [<a href="/pdf/2308.10600" title="Download PDF">pdf</a>, <a href="/format/2308.10600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fixed-Parameter Algorithms for Computing RAC Drawings of Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brand%2C+C">Cornelius Brand</a>, 
<a href="/search/cs?searchtype=author&query=Ganian%2C+R">Robert Ganian</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%B6der%2C+S">Sebastian R&#xf6;der</a>, 
<a href="/search/cs?searchtype=author&query=Schager%2C+F">Florian Schager</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at GD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">In a right-angle crossing (RAC) drawing of a graph, each edge is represented
as a polyline and edge crossings must occur at an angle of exactly $90^\circ$,
where the number of bends on such polylines is typically restricted in some
way. While structural and topological properties of RAC drawings have been the
focus of extensive research, little was known about the boundaries of
tractability for computing such drawings. In this paper, we initiate the study
of RAC drawings from the viewpoint of parameterized complexity. In particular,
we establish that computing a RAC drawing of an input graph $G$ with at most
$b$ bends (or determining that none exists) is fixed-parameter tractable
parameterized by either the feedback edge number of $G$, or $b$ plus the vertex
cover number of $G$.
</p>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10601" title="Abstract">arXiv:2308.10601</a> [<a href="/pdf/2308.10601" title="Download PDF">pdf</a>, <a href="/format/2308.10601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the Transferability of Adversarial Examples with Arbitrary  Style Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+Z">Zhijin Ge</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+F">Fanhua Shang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+L">Liang Wan</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+W">Wei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaosen Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figures, accepted by the 31st ACM International Conference on Multimedia (MM '23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Deep neural networks are vulnerable to adversarial examples crafted by
applying human-imperceptible perturbations on clean inputs. Although many
attack methods can achieve high success rates in the white-box setting, they
also exhibit weak transferability in the black-box setting. Recently, various
methods have been proposed to improve adversarial transferability, in which the
input transformation is one of the most effective methods. In this work, we
notice that existing input transformation-based works mainly adopt the
transformed data in the same domain for augmentation. Inspired by domain
generalization, we aim to further improve the transferability using the data
augmented from different domains. Specifically, a style transfer network can
alter the distribution of low-level visual features in an image while
preserving semantic content for humans. Hence, we propose a novel attack method
named Style Transfer Method (STM) that utilizes a proposed arbitrary style
transfer network to transform the images into different domains. To avoid
inconsistent semantic information of stylized images for the classification
network, we fine-tune the style transfer network and mix up the generated
images added by random noise with the original images to maintain semantic
consistency and boost input diversity. Extensive experimental results on the
ImageNet-compatible dataset show that our proposed method can significantly
improve the adversarial transferability on either normally trained models or
adversarially trained models than state-of-the-art input transformation-based
attacks. Code is available at: https://github.com/Zhijin-Ge/STM.
</p>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10603" title="Abstract">arXiv:2308.10603</a> [<a href="/pdf/2308.10603" title="Download PDF">pdf</a>, <a href="/format/2308.10603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A step towards understanding why classification helps regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pintea%2C+S+L">Silvia L. Pintea</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yancong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Dijkstra%2C+J">Jouke Dijkstra</a>, 
<a href="/search/cs?searchtype=author&query=van+Gemert%2C+J+C">Jan C. van Gemert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">A number of computer vision deep regression approaches report improved
results when adding a classification loss to the regression loss. Here, we
explore why this is useful in practice and when it is beneficial. To do so, we
start from precisely controlled dataset variations and data samplings and find
that the effect of adding a classification loss is the most pronounced for
regression with imbalanced data. We explain these empirical findings by
formalizing the relation between the balanced and imbalanced regression losses.
Finally, we show that our findings hold on two real imbalanced image datasets
for depth estimation (NYUD2-DIR), and age estimation (IMDB-WIKI-DIR), and on
the problem of imbalanced video progress prediction (Breakfast). Our main
takeaway is: for a regression task, if the data sampling is imbalanced, then
add a classification loss.
</p>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10604" title="Abstract">arXiv:2308.10604</a> [<a href="/pdf/2308.10604" title="Download PDF">pdf</a>, <a href="/format/2308.10604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BackTrack: Robust template update via Backward Tracking of candidate  template
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongwook Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+W">Wonjun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seohyung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+B">ByungIn Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+E">Eunho Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+S">Seongju Hwang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Variations of target appearance such as deformations, illumination variance,
occlusion, etc., are the major challenges of visual object tracking that
negatively impact the performance of a tracker. An effective method to tackle
these challenges is template update, which updates the template to reflect the
change of appearance in the target object during tracking. However, with
template updates, inadequate quality of new templates or inappropriate timing
of updates may induce a model drift problem, which severely degrades the
tracking performance. Here, we propose BackTrack, a robust and reliable method
to quantify the confidence of the candidate template by backward tracking it on
the past frames. Based on the confidence score of candidates from BackTrack, we
can update the template with a reliable candidate at the right time while
rejecting unreliable candidates. BackTrack is a generic template update scheme
and is applicable to any template-based trackers. Extensive experiments on
various tracking benchmarks verify the effectiveness of BackTrack over existing
template update algorithms, as it achieves SOTA performance on various tracking
benchmarks.
</p>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10608" title="Abstract">arXiv:2308.10608</a> [<a href="/pdf/2308.10608" title="Download PDF">pdf</a>, <a href="/format/2308.10608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FocalDreamer: Text-driven 3D Editing via Focal-fusion Assembly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuhan Li</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Y">Yishun Dou</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yue Shi</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Y">Yu Lei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuanhong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Peng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+B">Bingbing Ni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="https://fantasia3d.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">While text-3D editing has made significant strides in leveraging score
distillation sampling, emerging approaches still fall short in delivering
separable, precise and consistent outcomes that are vital to content creation.
In response, we introduce FocalDreamer, a framework that merges base shape with
editable parts according to text prompts for fine-grained editing within
desired regions. Specifically, equipped with geometry union and dual-path
rendering, FocalDreamer assembles independent 3D parts into a complete object,
tailored for convenient instance reuse and part-wise control. We propose
geometric focal loss and style consistency regularization, which encourage
focal fusion and congruent overall appearance. Furthermore, FocalDreamer
generates high-fidelity geometry and PBR textures which are compatible with
widely-used graphics engines. Extensive experiments have highlighted the
superior editing capabilities of FocalDreamer in both quantitative and
qualitative evaluations.
</p>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10609" title="Abstract">arXiv:2308.10609</a> [<a href="/pdf/2308.10609" title="Download PDF">pdf</a>, <a href="/format/2308.10609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ST-RAP: A Spatio-Temporal Framework for Real Estate Appraisal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hojoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+H">Hawon Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B">Byungkun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kyungyup Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choo%2C+J">Jaegul Choo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CIKM'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper, we introduce ST-RAP, a novel Spatio-Temporal framework for
Real estate APpraisal. ST-RAP employs a hierarchical architecture with a
heterogeneous graph neural network to encapsulate temporal dynamics and spatial
relationships simultaneously. Through comprehensive experiments on a
large-scale real estate dataset, ST-RAP outperforms previous methods,
demonstrating the significant benefits of integrating spatial and temporal
aspects in real estate appraisal. Our code and dataset are available at
https://github.com/dojeon-ai/STRAP.
</p>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10610" title="Abstract">arXiv:2308.10610</a> [<a href="/pdf/2308.10610" title="Download PDF">pdf</a>, <a href="/format/2308.10610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultrafast and Ultralight Network-Based Intelligent System for Real-time  Diagnosis of Ear diseases in Any Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yubiao Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xinyu Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xiaoqiang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Meiping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+H">Haihua Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yanmei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zefeng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenrui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenzhang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This manuscript has been submitted to Neural Networks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Traditional ear disease diagnosis heavily depends on experienced specialists
and specialized equipment, frequently resulting in misdiagnoses, treatment
delays, and financial burdens for some patients. Utilizing deep learning models
for efficient ear disease diagnosis has proven effective and affordable.
However, existing research overlooked model inference speed and parameter size
required for deployment. To tackle these challenges, we constructed a
large-scale dataset comprising eight ear disease categories and normal ear
canal samples from two hospitals. Inspired by ShuffleNetV2, we developed
Best-EarNet, an ultrafast and ultralight network enabling real-time ear disease
diagnosis. Best-EarNet incorporates the novel Local-Global Spatial Feature
Fusion Module which can capture global and local spatial information
simultaneously and guide the network to focus on crucial regions within feature
maps at various levels, mitigating low accuracy issues. Moreover, our network
uses multiple auxiliary classification heads for efficient parameter
optimization. With 0.77M parameters, Best-EarNet achieves an average frames per
second of 80 on CPU. Employing transfer learning and five-fold cross-validation
with 22,581 images from Hospital-1, the model achieves an impressive 95.23%
accuracy. External testing on 1,652 images from Hospital-2 validates its
performance, yielding 92.14% accuracy. Compared to state-of-the-art networks,
Best-EarNet establishes a new state-of-the-art (SOTA) in practical
applications. Most importantly, we developed an intelligent diagnosis system
called Ear Keeper, which can be deployed on common electronic devices. By
manipulating a compact electronic otoscope, users can perform comprehensive
scanning and diagnosis of the ear canal using real-time video. This study
provides a novel paradigm for ear endoscopy and other medical endoscopic image
recognition applications.
</p>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10613" title="Abstract">arXiv:2308.10613</a> [<a href="/pdf/2308.10613" title="Download PDF">pdf</a>, <a href="/ps/2308.10613" title="Download PostScript">ps</a>, <a href="/format/2308.10613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Static Application Security Testing of Consensus-Critical Code in the  Cosmos Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Surmont%2C+J">Jasper Surmont</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weihong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Van+Cutsem%2C+T">Tom Van Cutsem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5th Conference on Blockchain Research &amp; Applications for Innovative Networks and Services (BRAINS'23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Blockchains require deterministic execution in order to reach consensus. This
is often guaranteed in languages designed to write smart contracts, such as
Solidity. Application-specific blockchains or ``appchains'' allow the
blockchain application logic to be written using general-purpose programming
languages, giving developers more flexibility but also additional
responsibilities. In particular, developers must ensure that their blockchain
application logic does not contain any sources of non-determinism. Any source
of non-determinism may be a potential source of vulnerabilities.
<br />This paper focuses on the use of Static Application Security Testing (SAST)
tools to detect such sources of non-determinism at development time. We focus
on Cosmos, a prominent open-source project that lets developers build
interconnected networks of application-specific blockchains. Cosmos provides a
Software Development Kit (SDK) that allows these chains to be implemented in
the Go programming language. We create a corpus of 11 representative
Cosmos-based appchains to analyze for sources of non-determinism in Go.
<br />As part of our study, we identified cosmos-sdk-codeql, a set of CodeQL code
analysis rules for Cosmos applications. We find that these rules generate many
false positives and propose a refactored set of rules that more precisely
detects sources of non-determinism only in code that runs as part of the
blockchain logic. We demonstrate a significant increase in the precision of the
rules, making the SAST tool more effective and hence potentially contributing
to enhanced security for Cosmos-based blockchains.
</p>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10619" title="Abstract">arXiv:2308.10619</a> [<a href="/pdf/2308.10619" title="Download PDF">pdf</a>, <a href="/format/2308.10619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> centroIDA: Cross-Domain Class Discrepancy Minimization Based on  Accumulative Class-Centroids for Imbalanced Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaona Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhenyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yichen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Saier Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Z">Zhiqiang Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Y">Yang Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Unsupervised Domain Adaptation (UDA) approaches address the covariate shift
problem by minimizing the distribution discrepancy between the source and
target domains, assuming that the label distribution is invariant across
domains. However, in the imbalanced domain adaptation (IDA) scenario, covariate
and long-tailed label shifts both exist across domains. To tackle the IDA
problem, some current research focus on minimizing the distribution
discrepancies of each corresponding class between source and target domains.
Such methods rely much on the reliable pseudo labels' selection and the feature
distributions estimation for target domain, and the minority classes with
limited numbers makes the estimations more uncertainty, which influences the
model's performance. In this paper, we propose a cross-domain class discrepancy
minimization method based on accumulative class-centroids for IDA (centroIDA).
Firstly, class-based re-sampling strategy is used to obtain an unbiased
classifier on source domain. Secondly, the accumulative class-centroids
alignment loss is proposed for iterative class-centroids alignment across
domains. Finally, class-wise feature alignment loss is used to optimize the
feature representation for a robust classification boundary. A series of
experiments have proved that our method outperforms other SOTA methods on IDA
problem, especially with the increasing degree of label shift.
</p>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10620" title="Abstract">arXiv:2308.10620</a> [<a href="/pdf/2308.10620" title="Download PDF">pdf</a>, <a href="/format/2308.10620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Software Engineering: A Systematic Literature  Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+X">Xinyi Hou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yanjie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhou Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kailong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiapu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>, 
<a href="/search/cs?searchtype=author&query=Grundy%2C+J">John Grundy</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoyu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) have significantly impacted numerous domains,
notably including Software Engineering (SE). Nevertheless, a well-rounded
understanding of the application, effects, and possible limitations of LLMs
within SE is still in its early stages. To bridge this gap, our systematic
literature review takes a deep dive into the intersection of LLMs and SE, with
a particular focus on understanding how LLMs can be exploited in SE to optimize
processes and outcomes. Through a comprehensive review approach, we collect and
analyze a total of 229 research papers from 2017 to 2023 to answer four key
research questions (RQs). In RQ1, we categorize and provide a comparative
analysis of different LLMs that have been employed in SE tasks, laying out
their distinctive features and uses. For RQ2, we detail the methods involved in
data collection, preprocessing, and application in this realm, shedding light
on the critical role of robust, well-curated datasets for successful LLM
implementation. RQ3 allows us to examine the specific SE tasks where LLMs have
shown remarkable success, illuminating their practical contributions to the
field. Finally, RQ4 investigates the strategies employed to optimize and
evaluate the performance of LLMs in SE, as well as the common techniques
related to prompt optimization. Armed with insights drawn from addressing the
aforementioned RQs, we sketch a picture of the current state-of-the-art,
pinpointing trends, identifying gaps in existing research, and flagging
promising areas for future study.
</p>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10621" title="Abstract">arXiv:2308.10621</a> [<a href="/pdf/2308.10621" title="Download PDF">pdf</a>, <a href="/format/2308.10621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Modal Dataset Acquisition for Photometrically Challenging Object
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jung%2C+H">HyunJun Jung</a>, 
<a href="/search/cs?searchtype=author&query=Ruhkamp%2C+P">Patrick Ruhkamp</a>, 
<a href="/search/cs?searchtype=author&query=Navab%2C+N">Nassir Navab</a>, 
<a href="/search/cs?searchtype=author&query=Busam%2C+B">Benjamin Busam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023 TRICKY Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper addresses the limitations of current datasets for 3D vision tasks
in terms of accuracy, size, realism, and suitable imaging modalities for
photometrically challenging objects. We propose a novel annotation and
acquisition pipeline that enhances existing 3D perception and 6D object pose
datasets. Our approach integrates robotic forward-kinematics, external infrared
trackers, and improved calibration and annotation procedures. We present a
multi-modal sensor rig, mounted on a robotic end-effector, and demonstrate how
it is integrated into the creation of highly accurate datasets. Additionally,
we introduce a freehand procedure for wider viewpoint coverage. Both approaches
yield high-quality 3D data with accurate object and camera pose annotations.
Our methods overcome the limitations of existing datasets and provide valuable
resources for 3D vision research.
</p>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10623" title="Abstract">arXiv:2308.10623</a> [<a href="/pdf/2308.10623" title="Download PDF">pdf</a>, <a href="/format/2308.10623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GaitPT: Skeletons Are All You Need For Gait Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Catruna%2C+A">Andy Catruna</a>, 
<a href="/search/cs?searchtype=author&query=Cosma%2C+A">Adrian Cosma</a>, 
<a href="/search/cs?searchtype=author&query=Radoi%2C+E">Emilian Radoi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The analysis of patterns of walking is an important area of research that has
numerous applications in security, healthcare, sports and human-computer
interaction. Lately, walking patterns have been regarded as a unique
fingerprinting method for automatic person identification at a distance. In
this work, we propose a novel gait recognition architecture called Gait Pyramid
Transformer (GaitPT) that leverages pose estimation skeletons to capture unique
walking patterns, without relying on appearance information. GaitPT adopts a
hierarchical transformer architecture that effectively extracts both spatial
and temporal features of movement in an anatomically consistent manner, guided
by the structure of the human skeleton. Our results show that GaitPT achieves
state-of-the-art performance compared to other skeleton-based gait recognition
works, in both controlled and in-the-wild scenarios. GaitPT obtains 82.6%
average accuracy on CASIA-B, surpassing other works by a margin of 6%.
Moreover, it obtains 52.16% Rank-1 accuracy on GREW, outperforming both
skeleton-based and appearance-based approaches.
</p>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10626" title="Abstract">arXiv:2308.10626</a> [<a href="/pdf/2308.10626" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital citizen science for ethical surveillance of physical activity  among youth: mobile ecological momentary assessments vs. retrospective recall
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ibrahim%2C+S+T">Sheriff Tolulope Ibrahim</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+J">Jamin Patel</a>, 
<a href="/search/cs?searchtype=author&query=Katapally%2C+T+R">Tarun Reddy Katapally</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Physical inactivity is the fourth leading risk factor of mortality globally.
Hence, understanding the physical activity (PA) patterns of youth is essential
to manage and mitigate non-communicable diseases. As digital citizen science
approaches utilizing citizen-owned smartphones to ethically obtain PA big data
can transform PA surveillance, this study aims to understand the frequency of
PA reported by youth using smartphone-deployed retrospective validated surveys
compared to prospective time-triggered mobile ecological momentary assessments
(mEMAs). Using a digital citizen science methodology, this study recruited
youth citizen scientists (N = 808) in 2018 (August 31- December 31) in
Saskatchewan, Canada. Youth citizen scientists (age 13 to 21) reported their PA
using prospective mEMAs and retrospective surveys over an eight-day period. A
significant difference was found in reporting the frequency of PA
retrospectively vs. prospectively via mEMAs (p &lt; 0.000). Ethnicity, parental
education, and strength training were associated with prospective PA frequency;
however, no associations were significant with retrospective PA frequency. With
access to ubiquitous digital devices growing worldwide, and youth having
particularly high digital literacy, digital citizen science for the ethical
surveillance of PA using mEMAs presents a promising approach for the management
and prevention of non-communicable diseases among youth.
</p>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10627" title="Abstract">arXiv:2308.10627</a> [<a href="/pdf/2308.10627" title="Download PDF">pdf</a>, <a href="/format/2308.10627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polarimetric Information for Multi-Modal 6D Pose Estimation of  Photometrically Challenging Objects with Limited Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruhkamp%2C+P">Patrick Ruhkamp</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+D">Daoyi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+H">HyunJun Jung</a>, 
<a href="/search/cs?searchtype=author&query=Navab%2C+N">Nassir Navab</a>, 
<a href="/search/cs?searchtype=author&query=Busam%2C+B">Benjamin Busam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023 TRICKY Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">6D pose estimation pipelines that rely on RGB-only or RGB-D data show
limitations for photometrically challenging objects with e.g. textureless
surfaces, reflections or transparency. A supervised learning-based method
utilising complementary polarisation information as input modality is proposed
to overcome such limitations. This supervised approach is then extended to a
self-supervised paradigm by leveraging physical characteristics of polarised
light, thus eliminating the need for annotated real data. The methods achieve
significant advancements in pose estimation by leveraging geometric information
from polarised light and incorporating shape priors and invertible physical
constraints.
</p>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10629" title="Abstract">arXiv:2308.10629</a> [<a href="/pdf/2308.10629" title="Download PDF">pdf</a>, <a href="/format/2308.10629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Who should pay for frequency-containment ancillary services? Providing  incentives to shape investment during the energy transition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Badesa%2C+L">Luis Badesa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">While the operating cost of electricity grids based on thermal generation was
largely driven by the cost of fuel, as renewable penetration increases,
ancillary services represent an increasingly large proportion of the running
costs. Electric frequency is an important magnitude in highly renewable grids,
as it becomes more volatile and therefore the cost related to maintaining it
within safe bounds has significantly increased. All generators and consumers
have so far been equally responsible for covering frequency-containment
ancillary services costs, but it has become relevant to rethink this regulatory
arrangement. In this paper, we discuss the issue of cost allocation for these
services, highlighting the need to evolve towards a causation-based regulatory
framework. We argue that parties responsible for creating the need for
ancillary services should bear these costs. However, this would imply an
important change in electricity market policy, therefore it is necessary to
understand the impact on current and future investments on generation, as well
as on electricity tariffs. Here we provide a qualitative analysis of this
issue, hoping to open up a focused discussion among academics, regulators and
industry.
</p>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10631" title="Abstract">arXiv:2308.10631</a> [<a href="/pdf/2308.10631" title="Download PDF">pdf</a>, <a href="/format/2308.10631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PsyMo: A Dataset for Estimating Self-Reported Psychological Traits from  Gait
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cosma%2C+A">Adrian Cosma</a>, 
<a href="/search/cs?searchtype=author&query=Radoi%2C+E">Emilian Radoi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Psychological trait estimation from external factors such as movement and
appearance is a challenging and long-standing problem in psychology, and is
principally based on the psychological theory of embodiment. To date, attempts
to tackle this problem have utilized private small-scale datasets with
intrusive body-attached sensors. Potential applications of an automated system
for psychological trait estimation include estimation of occupational fatigue
and psychology, and marketing and advertisement. In this work, we propose PsyMo
(Psychological traits from Motion), a novel, multi-purpose and multi-modal
dataset for exploring psychological cues manifested in walking patterns. We
gathered walking sequences from 312 subjects in 7 different walking variations
and 6 camera angles. In conjunction with walking sequences, participants filled
in 6 psychological questionnaires, totalling 17 psychometric attributes related
to personality, self-esteem, fatigue, aggressiveness and mental health. We
propose two evaluation protocols for psychological trait estimation. Alongside
the estimation of self-reported psychological traits from gait, the dataset can
be used as a drop-in replacement to benchmark methods for gait recognition. We
anonymize all cues related to the identity of the subjects and publicly release
only silhouettes, 2D / 3D human skeletons and 3D SMPL human meshes.
</p>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10632" title="Abstract">arXiv:2308.10632</a> [<a href="/pdf/2308.10632" title="Download PDF">pdf</a>, <a href="/format/2308.10632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foundation Model-oriented Robustness: Robust Image Model Evaluation with  Pretrained Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peiyan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haoyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chaozhuo Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sunghun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haohan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine learning has demonstrated remarkable performance over finite
datasets, yet whether the scores over the fixed benchmarks can sufficiently
indicate the model's performance in the real world is still in discussion. In
reality, an ideal robust model will probably behave similarly to the oracle
(e.g., the human users), thus a good evaluation protocol is probably to
evaluate the models' behaviors in comparison to the oracle. In this paper, we
introduce a new robustness measurement that directly measures the image
classification model's performance compared with a surrogate oracle (i.e., a
foundation model). Besides, we design a simple method that can accomplish the
evaluation beyond the scope of the benchmarks. Our method extends the image
datasets with new samples that are sufficiently perturbed to be distinct from
the ones in the original sets, but are still bounded within the same
image-label structure the original test image represents, constrained by a
foundation model pretrained with a large amount of samples. As a result, our
new method will offer us a new way to evaluate the models' robustness
performance, free of limitations of fixed benchmarks or constrained
perturbations, although scoped by the power of the oracle. In addition to the
evaluation results, we also leverage our generated data to understand the
behaviors of the model and our new evaluation strategies.
</p>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10633" title="Abstract">arXiv:2308.10633</a> [<a href="/pdf/2308.10633" title="Download PDF">pdf</a>, <a href="/format/2308.10633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RaLLe: A Framework for Developing and Evaluating Retrieval-Augmented  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoshi%2C+Y">Yasuto Hoshi</a>, 
<a href="/search/cs?searchtype=author&query=Miyashita%2C+D">Daisuke Miyashita</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+Y">Youyang Ng</a>, 
<a href="/search/cs?searchtype=author&query=Tatsuno%2C+K">Kento Tatsuno</a>, 
<a href="/search/cs?searchtype=author&query=Morioka%2C+Y">Yasuhiro Morioka</a>, 
<a href="/search/cs?searchtype=author&query=Torii%2C+O">Osamu Torii</a>, 
<a href="/search/cs?searchtype=author&query=Deguchi%2C+J">Jun Deguchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 2 figures, see <a href="https://youtu.be/JYbm75qnfTg">this https URL</a> for the demonstration screencast
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Retrieval-augmented large language models (R-LLMs) combine pre-trained large
language models (LLMs) with information retrieval systems to improve the
accuracy of factual question-answering. However, current libraries for building
R-LLMs provide high-level abstractions without sufficient transparency for
evaluating and optimizing prompts within specific inference processes such as
retrieval and generation. To address this gap, we present RaLLe, an open-source
framework designed to facilitate the development, evaluation, and optimization
of R-LLMs for knowledge-intensive tasks. With RaLLe, developers can easily
develop and evaluate R-LLMs, improving hand-crafted prompts, assessing
individual inference processes, and objectively measuring overall system
performance quantitatively. By leveraging these features, developers can
enhance the performance and accuracy of their R-LLMs in knowledge-intensive
generation tasks. We open-source our code at https://github.com/yhoshi3/RaLLe.
</p>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10634" title="Abstract">arXiv:2308.10634</a> [<a href="/pdf/2308.10634" title="Download PDF">pdf</a>, <a href="/format/2308.10634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Reachability Analysis of Pedestrians Using Behavior Modes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=S%C3%B6derlund%2C+A">August S&#xf6;derlund</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+F+J">Frank J. Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Narri%2C+V">Vandana Narri</a>, 
<a href="/search/eess?searchtype=author&query=Alanwar%2C+A">Amr Alanwar</a>, 
<a href="/search/eess?searchtype=author&query=Johansson%2C+K+H">Karl H. Johansson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, we present a data-driven approach for safely predicting the
future state sets of pedestrians. Previous approaches to predicting the future
state sets of pedestrians either do not provide safety guarantees or are overly
conservative. Moreover, an additional challenge is the selection or
identification of a model that sufficiently captures the motion of pedestrians.
To address these issues, this paper introduces the idea of splitting previously
collected, historical pedestrian trajectories into different behavior modes for
performing data-driven reachability analysis. Through this proposed approach,
we are able to use data-driven reachability analysis to capture the future
state sets of pedestrians, while being less conservative and still maintaining
safety guarantees. Furthermore, this approach is modular and can support
different approaches for behavior splitting. To illustrate the efficacy of the
approach, we implement our method with a basic behavior-splitting module and
evaluate the implementation on an open-source data set of real pedestrian
trajectories. In this evaluation, we find that the modal reachable sets are
less conservative and more descriptive of the future state sets of the
pedestrian.
</p>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10637" title="Abstract">arXiv:2308.10637</a> [<a href="/pdf/2308.10637" title="Download PDF">pdf</a>, <a href="/ps/2308.10637" title="Download PostScript">ps</a>, <a href="/format/2308.10637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metro Access Network with Convergence of Coherent and Analog RoF Data  Services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delmade%2C+A">Amol Delmade</a>, 
<a href="/search/cs?searchtype=author&query=Slyne%2C+F">Frank Slyne</a>, 
<a href="/search/cs?searchtype=author&query=Browning%2C+C">Colm Browning</a>, 
<a href="/search/cs?searchtype=author&query=Barry%2C+D+K+L">Daniel Kilper Liam Barry</a>, 
<a href="/search/cs?searchtype=author&query=Ruffini%2C+M">Marco Ruffini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Efficient use of spectral resources will be an important aspect of converged
access network deployment. This work analyzes the performance of variable
bandwidth Analog Radio-over-Fiber signals transmitted in the unfilled spectral
spaces of telecom-grade ROADM channels dedicated for coherent signals
transmission over the OpenIreland testbed.
</p>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10638" title="Abstract">arXiv:2308.10638</a> [<a href="/pdf/2308.10638" title="Download PDF">pdf</a>, <a href="/format/2308.10638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCULPT: Shape-Conditioned Unpaired Learning of Pose-dependent Clothed  and Textured Human Meshes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanyal%2C+S">Soubhik Sanyal</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+P">Partha Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jinlong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Black%2C+M+J">Michael J. Black</a>, 
<a href="/search/cs?searchtype=author&query=Thies%2C+J">Justus Thies</a>, 
<a href="/search/cs?searchtype=author&query=Bolkart%2C+T">Timo Bolkart</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present SCULPT, a novel 3D generative model for clothed and textured 3D
meshes of humans. Specifically, we devise a deep neural network that learns to
represent the geometry and appearance distribution of clothed human bodies.
Training such a model is challenging, as datasets of textured 3D meshes for
humans are limited in size and accessibility. Our key observation is that there
exist medium-sized 3D scan datasets like CAPE, as well as large-scale 2D image
datasets of clothed humans and multiple appearances can be mapped to a single
geometry. To effectively learn from the two data modalities, we propose an
unpaired learning procedure for pose-dependent clothed and textured human
meshes. Specifically, we learn a pose-dependent geometry space from 3D scan
data. We represent this as per vertex displacements w.r.t. the SMPL model.
Next, we train a geometry conditioned texture generator in an unsupervised way
using the 2D image data. We use intermediate activations of the learned
geometry model to condition our texture generator. To alleviate entanglement
between pose and clothing type, and pose and clothing appearance, we condition
both the texture and geometry generators with attribute labels such as clothing
types for the geometry, and clothing colors for the texture generator. We
automatically generated these conditioning labels for the 2D images based on
the visual question answering model BLIP and CLIP. We validate our method on
the SCULPT dataset, and compare to state-of-the-art 3D generative models for
clothed human bodies. We will release the codebase for research purposes.
</p>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10644" title="Abstract">arXiv:2308.10644</a> [<a href="/pdf/2308.10644" title="Download PDF">pdf</a>, <a href="/format/2308.10644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Training of Neural ODEs Using Gau&#xdf;-Legendre Quadrature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Norcliffe%2C+A">Alexander Norcliffe</a>, 
<a href="/search/cs?searchtype=author&query=Deisenroth%2C+M+P">Marc Peter Deisenroth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 16 figures, 7 tables, published in TMLR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
<p class="mathjax">Neural ODEs demonstrate strong performance in generative and time-series
modelling. However, training them via the adjoint method is slow compared to
discrete models due to the requirement of numerically solving ODEs. To speed
neural ODEs up, a common approach is to regularise the solutions. However, this
approach may affect the expressivity of the model; when the trajectory itself
matters, this is particularly important. In this paper, we propose an
alternative way to speed up the training of neural ODEs. The key idea is to
speed up the adjoint method by using Gau{\ss}-Legendre quadrature to solve
integrals faster than ODE-based methods while remaining memory efficient. We
also extend the idea to training SDEs using the Wong-Zakai theorem, by training
a corresponding ODE and transferring the parameters. Our approach leads to
faster training of neural ODEs, especially for large models. It also presents a
new way to train SDE-based models.
</p>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10647" title="Abstract">arXiv:2308.10647</a> [<a href="/pdf/2308.10647" title="Download PDF">pdf</a>, <a href="/format/2308.10647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> bbOCR: An Open-source Multi-domain OCR Pipeline for Bengali Documents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zulkarnain%2C+I+M">Imam Mohammad Zulkarnain</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+S+B">Shayekh Bin Islam</a>, 
<a href="/search/cs?searchtype=author&query=Farabe%2C+M+Z+A+Z">Md. Zami Al Zunaed Farabe</a>, 
<a href="/search/cs?searchtype=author&query=Shawon%2C+M+M+H">Md. Mehedi Hasan Shawon</a>, 
<a href="/search/cs?searchtype=author&query=Abedin%2C+J+M">Jawaril Munshad Abedin</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+B+R">Beig Rajibul Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Haque%2C+M">Marsia Haque</a>, 
<a href="/search/cs?searchtype=author&query=Shihab%2C+I">Istiak Shihab</a>, 
<a href="/search/cs?searchtype=author&query=Mobassir%2C+S">Syed Mobassir</a>, 
<a href="/search/cs?searchtype=author&query=Ansary%2C+M+N">MD. Nazmuddoha Ansary</a>, 
<a href="/search/cs?searchtype=author&query=Sushmit%2C+A">Asif Sushmit</a>, 
<a href="/search/cs?searchtype=author&query=Sadeque%2C+F">Farig Sadeque</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite the existence of numerous Optical Character Recognition (OCR) tools,
the lack of comprehensive open-source systems hampers the progress of document
digitization in various low resource languages, including Bengali. Low-resource
languages, especially those with an alphasyllabary writing system, suffer from
the lack of large-scale datasets for various document OCR components such as
word-level OCR, document layout extraction, and distortion correction; which
are available as individual modules in high-resource languages. In this paper,
we introduce Bengali.AI-BRACU-OCR (bbOCR): an open-source scalable document OCR
system that can reconstruct Bengali documents into a structured searchable
digitized format that leverages a novel Bengali text recognition model and two
novel synthetic datasets. We present extensive component-level and system-level
evaluation: both use a novel diversified evaluation dataset and comprehensive
evaluation metrics. Our extensive evaluation suggests that our proposed
solution is preferable over the current state-of-the-art Bengali OCR systems.
The source codes and datasets are available here:
https://bengaliai.github.io/bbocr.
</p>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10648" title="Abstract">arXiv:2308.10648</a> [<a href="/pdf/2308.10648" title="Download PDF">pdf</a>, <a href="/format/2308.10648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EVE: Efficient zero-shot text-based Video Editing with Depth Map  Guidance and Temporal Consistency Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yutao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xingning Dong</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+T">Tian Gan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chunluan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qingpei Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Motivated by the superior performance of image diffusion models, more and
more researchers strive to extend these models to the text-based video editing
task. Nevertheless, current video editing tasks mainly suffer from the dilemma
between the high fine-tuning cost and the limited generation capacity. Compared
with images, we conjecture that videos necessitate more constraints to preserve
the temporal consistency during editing. Towards this end, we propose EVE, a
robust and efficient zero-shot video editing method. Under the guidance of
depth maps and temporal consistency constraints, EVE derives satisfactory video
editing results with an affordable computational and time cost. Moreover,
recognizing the absence of a publicly available video editing dataset for fair
comparisons, we construct a new benchmark ZVE-50 dataset. Through comprehensive
experimentation, we validate that EVE could achieve a satisfactory trade-off
between performance and efficiency. We will release our dataset and codebase to
facilitate future researchers.
</p>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10649" title="Abstract">arXiv:2308.10649</a> [<a href="/pdf/2308.10649" title="Download PDF">pdf</a>, <a href="/ps/2308.10649" title="Download PostScript">ps</a>, <a href="/format/2308.10649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning Based Sensor Optimization for Bio-markers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khandelwal%2C+S">Sajal Khandelwal</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+P">Pawan Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Azeemuddin%2C+S">Syed Azeemuddin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Signal Processing (eess.SP)

</div>
<p class="mathjax">Radio frequency (RF) biosensors, in particular those based on inter-digitated
capacitors (IDCs), are pivotal in areas like biomedical diagnosis, remote
sensing, and wireless communication. Despite their advantages of low cost and
easy fabrication, their sensitivity can be hindered by design imperfections,
environmental factors, and circuit noise. This paper investigates enhancing the
sensitivity of IDC-based RF sensors using novel reinforcement learning based
Binary Particle Swarm Optimization (RLBPSO), and it is compared to Ant Colony
Optimization (ACO), and other state-of-the-art methods. By focusing on
optimizing design parameters like electrode design and finger width, the
proposed study found notable improvements in sensor sensitivity. The proposed
RLBPSO method shows best optimized design for various frequency ranges when
compared to current state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10650" title="Abstract">arXiv:2308.10650</a> [<a href="/pdf/2308.10650" title="Download PDF">pdf</a>, <a href="/format/2308.10650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Evidential Learning for Bayesian Quantile Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=H%C3%BCttel%2C+F+B">Frederik Boe H&#xfc;ttel</a>, 
<a href="/search/cs?searchtype=author&query=Rodrigues%2C+F">Filipe Rodrigues</a>, 
<a href="/search/cs?searchtype=author&query=Pereira%2C+F+C">Francisco C&#xe2;mara Pereira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">It is desirable to have accurate uncertainty estimation from a single
deterministic forward-pass model, as traditional methods for uncertainty
quantification are computationally expensive. However, this is difficult
because single forward-pass models do not sample weights during inference and
often make assumptions about the target distribution, such as assuming it is
Gaussian. This can be restrictive in regression tasks, where the mean and
standard deviation are inadequate to model the target distribution accurately.
This paper proposes a deep Bayesian quantile regression model that can estimate
the quantiles of a continuous target distribution without the Gaussian
assumption. The proposed method is based on evidential learning, which allows
the model to capture aleatoric and epistemic uncertainty with a single
deterministic forward-pass model. This makes the method efficient and scalable
to large models and datasets. We demonstrate that the proposed method achieves
calibrated uncertainties on non-Gaussian distributions, disentanglement of
aleatoric and epistemic uncertainty, and robustness to out-of-distribution
samples.
</p>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10651" title="Abstract">arXiv:2308.10651</a> [<a href="/pdf/2308.10651" title="Download PDF">pdf</a>, <a href="/format/2308.10651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Research Challenges in Orchestration Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Basile%2C+D">Davide Basile</a> (Formal Methods and Tools lab, ISTI-CNR, Pisa, Italy), 
<a href="/search/cs?searchtype=author&query=ter+Beek%2C+M+H">Maurice H. ter Beek</a> (Formal Methods and Tools lab, ISTI-CNR, Pisa, Italy)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings ICE 2023, <a href="/abs/2308.08920">arXiv:2308.08920</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 383, 2023, pp. 73-90
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">Contract automata allow to formally define the behaviour of service contracts
in terms of service offers and requests, some of which are moreover optional
and some of which are necessary. A composition of contracts is said to be in
agreement if all service requests are matched by corresponding offers. Whenever
a composition of contracts is not in agreement, it can be refined to reach an
agreement using the orchestration synthesis algorithm. This algorithm is a
variant of the synthesis algorithm used in supervisory control theory and it is
based on the fact that optional transitions are controllable, whereas necessary
transitions are at most semi-controllable and cannot always be controlled. In
fact, the resulting orchestration is such that as much of the behaviour in
agreement is maintained. In this paper, we discuss recent developments of the
orchestration synthesis algorithm for contract automata. Notably, we present a
refined notion of semi-controllability and compare it with the original notion
by means of examples. We then discuss the current limits of the orchestration
synthesis algorithm and identify a number of research challenges together with
a research roadmap.
</p>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10652" title="Abstract">arXiv:2308.10652</a> [<a href="/pdf/2308.10652" title="Download PDF">pdf</a>, <a href="/format/2308.10652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proofs about Network Communication: For Humans and Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeltsch%2C+W">Wolfgang Jeltsch</a> (Well-Typed, London, England), 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz%2C+J">Javier D&#xed;az</a> (Atix Labs (a Globant Division), Buenos Aires, Argentina)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings ICE 2023, <a href="/abs/2308.08920">arXiv:2308.08920</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 383, 2023, pp. 1-14
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Many concurrent and distributed systems are safety-critical and therefore
have to provide a high degree of assurance. Important properties of such
systems are frequently proved on the specification level, but implementations
typically deviate from specifications for practical reasons. Machine-checked
proofs of bisimilarity statements are often useful for guaranteeing that
properties of specifications carry over to implementations. In this paper, we
present a way of conducting such proofs with a focus on network communication.
The proofs resulting from our approach are not just machine-checked but also
intelligible for humans.
</p>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10653" title="Abstract">arXiv:2308.10653</a> [<a href="/pdf/2308.10653" title="Download PDF">pdf</a>, <a href="/ps/2308.10653" title="Download PostScript">ps</a>, <a href="/format/2308.10653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Partially Typed Multiparty Sessions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barbanera%2C+F">Franco Barbanera</a> (Dipartimento di Matematica e Informatica, Universit&#xe0; di Catania, Catania, Italy), 
<a href="/search/cs?searchtype=author&query=Dezani-Ciancaglini%2C+M">Mariangiola Dezani-Ciancaglini</a> (Dipartimento di Informatica, Universit&#xe0; di Torino, Torino, Italy)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings ICE 2023, <a href="/abs/2308.08920">arXiv:2308.08920</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 383, 2023, pp. 15-34
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">A multiparty session formalises a set of concurrent communicating
participants. We propose a type system for multiparty sessions where some
communications between participants can be ignored. This allows us to type some
sessions with global types representing interesting protocols, which have no
type in the standard type systems. Our type system enjoys Subject Reduction,
Session Fidelity and "partial" Lock-freedom. The last property ensures the
absence of locks for participants with non ignored communications. A sound and
complete type inference algorithm is also discussed.
</p>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10654" title="Abstract">arXiv:2308.10654</a> [<a href="/pdf/2308.10654" title="Download PDF">pdf</a>, <a href="/format/2308.10654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algebraic Reasoning About Timeliness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haeri%2C+S+H">Seyed Hossein Haeri</a> (IOG, Belgium &amp; University of Bergen, Norway), 
<a href="/search/cs?searchtype=author&query=Thompson%2C+P+W">Peter W. Thompson</a> (PNSol, UK), 
<a href="/search/cs?searchtype=author&query=Van+Roy%2C+P">Peter Van Roy</a> (Universit&#xe9; catholique de Louvain, Belgium), 
<a href="/search/cs?searchtype=author&query=Haveraaen%2C+M">Magne Haveraaen</a> (University of Bergen, Norway), 
<a href="/search/cs?searchtype=author&query=Davies%2C+N+J">Neil J. Davies</a> (PNSol, UK), 
<a href="/search/cs?searchtype=author&query=Barash%2C+M">Mikhail Barash</a> (University of Bergen, Norway), 
<a href="/search/cs?searchtype=author&query=Hammond%2C+K">Kevin Hammond</a> (IOG, UK), 
<a href="/search/cs?searchtype=author&query=Chapman%2C+J">James Chapman</a> (IOG, UK)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings ICE 2023, <a href="/abs/2308.08920">arXiv:2308.08920</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 383, 2023, pp. 35-54
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Designing distributed systems to have predictable performance under high load
is difficult because of resource exhaustion, non-linearity, and stochastic
behaviour. Timeliness, i.e., delivering results within defined time bounds, is
a central aspect of predictable performance. In this paper, we focus on
timeliness using the DELTA-Q Systems Development paradigm (DELTA-QSD, developed
by PNSol), which computes timeliness by modelling systems observationally using
so-called outcome expressions. An outcome expression is a compositional
definition of a system's observed behaviour in terms of its basic operations.
Given the behaviour of the basic operations, DELTA-QSD efficiently computes the
stochastic behaviour of the whole system including its timeliness.
<br />This paper formally proves useful algebraic properties of outcome expressions
w.r.t. timeliness. We prove the different algebraic structures the set of
outcome expressions form with the different DELTA-QSD operators and demonstrate
why those operators do not form richer structures. We prove or disprove the set
of all possible distributivity results on outcome expressions. On our way for
disproving 8 of those distributivity results, we develop a technique called
properisation, which gives rise to the first body of maths for improper random
variables. Finally, we also prove 14 equivalences that have been used in the
past in the practice of DELTA-QSD.
<br />An immediate benefit is rewrite rules that can be used for design exploration
under established timeliness equivalence. This work is part of an ongoing
project to disseminate and build tool support for DELTA-QSD. The ability to
rewrite outcome expressions is essential for efficient tool support.
</p>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10655" title="Abstract">arXiv:2308.10655</a> [<a href="/pdf/2308.10655" title="Download PDF">pdf</a>, <a href="/format/2308.10655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Introduction of Guarded Lists in Bach: Expressiveness,  Correctness, and Efficiency Issues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barkallah%2C+M">Manel Barkallah</a> (Nadi Research Institute Faculty of Computer Science University of Namur Namur, Belgium), 
<a href="/search/cs?searchtype=author&query=Jacquet%2C+J">Jean-Marie Jacquet</a> (Nadi Research Institute Faculty of Computer Science University of Namur Namur, Belgium)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings ICE 2023, <a href="/abs/2308.08920">arXiv:2308.08920</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 383, 2023, pp. 55-72
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Concurrency theory has received considerable attention, but mostly in the
scope of synchronous process algebras such as CCS, CSP, and ACP. As another way
of handling concurrency, data-based coordination languages aim to provide a
clear separation between interaction and computation by synchronizing processes
asynchronously by means of information being available or not on a shared
space. Although these languages enjoy interesting properties, verifying program
correctness remains challenging. Some works, such as Anemone, have introduced
facilities, including animations and model checking of temporal logic formulae,
to better grasp system modelling. However, model checking is known to raise
performance issues due to the state space explosion problem. In this paper, we
propose a guarded list construct as a solution to address this problem. We
establish that the guarded list construct increases performance while strictly
enriching the expressiveness of data-based coordination languages. Furthermore,
we introduce a notion of refinement to introduce the guarded list construct in
a correctness-preserving manner.
</p>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10656" title="Abstract">arXiv:2308.10656</a> [<a href="/pdf/2308.10656" title="Download PDF">pdf</a>, <a href="/format/2308.10656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Practical Parallel Algorithms for Non-Monotone Submodular Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shuang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kai Han</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jing Tang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">He Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xueying Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhiyuli%2C+A">Aakas Zhiyuli</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hanxiao Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Part of the contribution appears in AAAI-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Submodular maximization has found extensive applications in various domains
within the field of artificial intelligence, including but not limited to
machine learning, computer vision, and natural language processing. With the
increasing size of datasets in these domains, there is a pressing need to
develop efficient and parallelizable algorithms for submodular maximization.
One measure of the parallelizability of a submodular maximization algorithm is
its adaptive complexity, which indicates the number of sequential rounds where
a polynomial number of queries to the objective function can be executed in
parallel. In this paper, we study the problem of non-monotone submodular
maximization subject to a knapsack constraint, and propose the first
combinatorial algorithm achieving an $(8+\epsilon)$-approximation under
$\mathcal{O}(\log n)$ adaptive complexity, which is \textit{optimal} up to a
factor of $\mathcal{O}(\log\log n)$. Moreover, we also propose the first
algorithm with both provable approximation ratio and sublinear adaptive
complexity for the problem of non-monotone submodular maximization subject to a
$k$-system constraint. As a by-product, we show that our two algorithms can
also be applied to the special case of submodular maximization subject to a
cardinality constraint, and achieve performance bounds comparable with those of
state-of-the-art algorithms. Finally, the effectiveness of our approach is
demonstrated by extensive experiments on real-world applications.
</p>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10657" title="Abstract">arXiv:2308.10657</a> [<a href="/pdf/2308.10657" title="Download PDF">pdf</a>, <a href="/format/2308.10657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameterized Complexity of Fair Bisection: FPT-Approximation meets  Unbreakability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Inamdar%2C+T">Tanmay Inamdar</a>, 
<a href="/search/cs?searchtype=author&query=Lokshtanov%2C+D">Daniel Lokshtanov</a>, 
<a href="/search/cs?searchtype=author&query=Saurabh%2C+S">Saket Saurabh</a>, 
<a href="/search/cs?searchtype=author&query=Surianarayanan%2C+V">Vaishali Surianarayanan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of ESA 2023 paper. Abstract shortened to meet the character limit
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">In the Minimum Bisection problem, input is a graph $G$ and the goal is to
partition the vertex set into two parts $A$ and $B$, such that $||A|-|B|| \le
1$ and the number $k$ of edges between $A$ and $B$ is minimized. This problem
can be viewed as a clustering problem where edges represent similarity, and the
task is to partition the vertices into two equally sized clusters, while
minimizing the number of pairs of similar objects that end up in different
clusters. In this paper, we initiate the study of a fair version of Minimum
Bisection. In this problem, the vertices of the graph are colored using one of
$c \ge 1$ colors. The goal is to find a bisection $(A, B)$ with at most $k$
edges between the parts, such that for each color $i\in [c]$, $A$ has exactly
$r_i$ vertices of color $i$.
<br />We first show that Fair Bisection is $W$[1]-hard parameterized by $c$ even
when $k = 0$. On the other hand, our main technical contribution shows that is
that this hardness result is simply a consequence of the very strict
requirement that each color class $i$ has {\em exactly} $r_i$ vertices in $A$.
In particular, we give an $f(k,c,\epsilon)n^{O(1)}$ time algorithm that finds a
balanced partition $(A, B)$ with at most $k$ edges between them, such that for
each color $i\in [c]$, there are at most $(1\pm \epsilon)r_i$ vertices of color
$i$ in $A$. Our approximation algorithm is best viewed as a proof of concept
that the technique introduced by [Lampis, ICALP '18] for obtaining
FPT-approximation algorithms for problems of bounded tree-width or clique-width
can be efficiently exploited even on graphs of unbounded width. The key insight
is that the technique of Lampis is applicable on tree decompositions with
unbreakable bags (as introduced in [Cygan et al., SIAM Journal on Computing
'14]). Along the way, we also derive a combinatorial result regarding tree
decompositions of graphs.
</p>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10658" title="Abstract">arXiv:2308.10658</a> [<a href="/pdf/2308.10658" title="Download PDF">pdf</a>, <a href="/format/2308.10658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Clothing and Pose Invariant 3D Shape Representation for  Long-Term Person Re-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Feng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minchul Kim</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Z">ZiAng Gu</a>, 
<a href="/search/cs?searchtype=author&query=Jian%2C+A">Anil Jian</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoming Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures, accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Long-Term Person Re-Identification (LT-ReID) has become increasingly crucial
in computer vision and biometrics. In this work, we aim to extend LT-ReID
beyond pedestrian recognition to include a wider range of real-world human
activities while still accounting for cloth-changing scenarios over large time
gaps. This setting poses additional challenges due to the geometric
misalignment and appearance ambiguity caused by the diversity of human pose and
clothing. To address these challenges, we propose a new approach 3DInvarReID
for (i) disentangling identity from non-identity components (pose, clothing
shape, and texture) of 3D clothed humans, and (ii) reconstructing accurate 3D
clothed body shapes and learning discriminative features of naked body shapes
for person ReID in a joint manner. To better evaluate our study of LT-ReID, we
collect a real-world dataset called CCDA, which contains a wide variety of
human activities and clothing changes. Experimentally, we show the superior
performance of our approach for person ReID.
</p>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10664" title="Abstract">arXiv:2308.10664</a> [<a href="/pdf/2308.10664" title="Download PDF">pdf</a>, <a href="/format/2308.10664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Safe Deep Reinforcement Learning Approach for Energy Efficient  Federated Learning in Wireless Communication Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koursioumpas%2C+N">Nikolaos Koursioumpas</a>, 
<a href="/search/cs?searchtype=author&query=Magoula%2C+L">Lina Magoula</a>, 
<a href="/search/cs?searchtype=author&query=Petropouleas%2C+N">Nikolaos Petropouleas</a>, 
<a href="/search/cs?searchtype=author&query=Thanopoulos%2C+A">Alexandros-Ioannis Thanopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Panagea%2C+T">Theodora Panagea</a>, 
<a href="/search/cs?searchtype=author&query=Alonistioti%2C+N">Nancy Alonistioti</a>, 
<a href="/search/cs?searchtype=author&query=Gutierrez-Estevez%2C+M+A">M. A. Gutierrez-Estevez</a>, 
<a href="/search/cs?searchtype=author&query=Khalili%2C+R">Ramin Khalili</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 Pages Single Column, 6 Figures, Submitted for possible publication in the IEEE Transactions on Green Communications and Networking (TGCN). arXiv admin note: text overlap with <a href="/abs/2306.14237">arXiv:2306.14237</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Progressing towards a new era of Artificial Intelligence (AI) - enabled
wireless networks, concerns regarding the environmental impact of AI have been
raised both in industry and academia. Federated Learning (FL) has emerged as a
key privacy preserving decentralized AI technique. Despite efforts currently
being made in FL, its environmental impact is still an open problem. Targeting
the minimization of the overall energy consumption of an FL process, we propose
the orchestration of computational and communication resources of the involved
devices to minimize the total energy required, while guaranteeing a certain
performance of the model. To this end, we propose a Soft Actor Critic Deep
Reinforcement Learning (DRL) solution, where a penalty function is introduced
during training, penalizing the strategies that violate the constraints of the
environment, and ensuring a safe RL process. A device level synchronization
method, along with a computationally cost effective FL environment are
proposed, with the goal of further reducing the energy consumption and
communication overhead. Evaluation results show the effectiveness of the
proposed scheme compared to four state-of-the-art baseline solutions in both
static and dynamic environments, achieving a decrease of up to 94% in the total
energy consumption.
</p>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10666" title="Abstract">arXiv:2308.10666</a> [<a href="/pdf/2308.10666" title="Download PDF">pdf</a>, <a href="/format/2308.10666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Degenerate crossing number and signed reversal distance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fuladi%2C+N">Niloufar Fuladi</a>, 
<a href="/search/cs?searchtype=author&query=Hubard%2C+A">Alfredo Hubard</a>, 
<a href="/search/cs?searchtype=author&query=de+Mesmay%2C+A">Arnaud de Mesmay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the Proceedings of the 31st International Symposium on Graph Drawing and Network Visualization (GD 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">The degenerate crossing number of a graph is the minimum number of transverse
crossings among all its drawings, where edges are represented as simple arcs
and multiple edges passing through the same point are counted as a single
crossing. Interpreting each crossing as a cross-cap induces an embedding into a
non-orientable surface. In 2007, Mohar showed that the degenerate crossing
number of a graph is at most its non-orientable genus and he conjectured that
these quantities are equal for every graph. He also made the stronger
conjecture that this also holds for any loopless pseudotriangulation with a
fixed embedding scheme.
<br />In this paper, we prove a structure theorem that almost completely classifies
the loopless 2-vertex embedding schemes for which the degenerate crossing
number equals the non-orientable genus. In particular, we provide a
counterexample to Mohar's stronger conjecture, but show that in the vast
majority of the 2-vertex cases, the conjecture does hold.
<br />The reversal distance between two signed permutations is the minimum number
of reversals that transform one permutation to the other one. If we represent
the trajectory of each element of a signed permutation under successive
reversals by a simple arc, we obtain a drawing of a 2-vertex embedding scheme
with degenerate crossings. Our main result is proved by leveraging this
connection and a classical result in genome rearrangement (the
Hannenhali-Pevzner algorithm) and can also be understood as an extension of
this algorithm when the reversals do not necessarily happen in a monotone
order.
</p>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10671" title="Abstract">arXiv:2308.10671</a> [<a href="/pdf/2308.10671" title="Download PDF">pdf</a>, <a href="/format/2308.10671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing Object Detection Uncertainty from RGB and Thermal Data for UAV  Outdoor Surveillance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sandino%2C+J">Juan Sandino</a>, 
<a href="/search/cs?searchtype=author&query=Caccetta%2C+P+A">Peter A. Caccetta</a>, 
<a href="/search/cs?searchtype=author&query=Sanderson%2C+C">Conrad Sanderson</a>, 
<a href="/search/cs?searchtype=author&query=Maire%2C+F">Frederic Maire</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+F">Felipe Gonzalez</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Aerospace Conference, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Recent advances in Unmanned Aerial Vehicles (UAVs) have resulted in their
quick adoption for wide a range of civilian applications, including precision
agriculture, biosecurity, disaster monitoring and surveillance. UAVs offer
low-cost platforms with flexible hardware configurations, as well as an
increasing number of autonomous capabilities, including take-off, landing,
object tracking and obstacle avoidance. However, little attention has been paid
to how UAVs deal with object detection uncertainties caused by false readings
from vision-based detectors, data noise, vibrations, and occlusion. In most
situations, the relevance and understanding of these detections are delegated
to human operators, as many UAVs have limited cognition power to interact
autonomously with the environment. This paper presents a framework for
autonomous navigation under uncertainty in outdoor scenarios for small UAVs
using a probabilistic-based motion planner. The framework is evaluated with
real flight tests using a sub 2 kg quadrotor UAV and illustrated in victim
finding Search and Rescue (SAR) case study in a forest/bushland. The navigation
problem is modelled using a Partially Observable Markov Decision Process
(POMDP), and solved in real time onboard the small UAV using Augmented Belief
Trees (ABT) and the TAPIR toolkit. Results from experiments using colour and
thermal imagery show that the proposed motion planner provides accurate victim
localisation coordinates, as the UAV has the flexibility to interact with the
environment and obtain clearer visualisations of any potential victims compared
to the baseline motion planner. Incorporating this system allows optimised UAV
surveillance operations by diminishing false positive readings from
vision-based object detectors.
</p>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10675" title="Abstract">arXiv:2308.10675</a> [<a href="/pdf/2308.10675" title="Download PDF">pdf</a>, <a href="/ps/2308.10675" title="Download PostScript">ps</a>, <a href="/format/2308.10675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Improved Best-of-both-worlds Algorithm for Bandits with Delayed  Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Masoudian%2C+S">Saeed Masoudian</a>, 
<a href="/search/cs?searchtype=author&query=Zimmert%2C+J">Julian Zimmert</a>, 
<a href="/search/cs?searchtype=author&query=Seldin%2C+Y">Yevgeny Seldin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We propose a new best-of-both-worlds algorithm for bandits with variably
delayed feedback. The algorithm improves on prior work by Masoudian et al.
[2022] by eliminating the need in prior knowledge of the maximal delay
$d_{\mathrm{max}}$ and providing tighter regret bounds in both regimes. The
algorithm and its regret bounds are based on counts of outstanding observations
(a quantity that is observed at action time) rather than delays or the maximal
delay (quantities that are only observed when feedback arrives). One major
contribution is a novel control of distribution drift, which is based on biased
loss estimators and skipping of observations with excessively large delays.
Another major contribution is demonstrating that the complexity of
best-of-both-worlds bandits with delayed feedback is characterized by the
cumulative count of outstanding observations after skipping of observations
with excessively large delays, rather than the delays or the maximal delay.
</p>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10677" title="Abstract">arXiv:2308.10677</a> [<a href="/pdf/2308.10677" title="Download PDF">pdf</a>, <a href="/format/2308.10677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Crowd Analysis: Open Research Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+A">Muhammad Asif Khan</a>, 
<a href="/search/cs?searchtype=author&query=Menouar%2C+H">Hamid Menouar</a>, 
<a href="/search/cs?searchtype=author&query=Hamila%2C+R">Ridha Hamila</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in AI Magazine published by Wiley Periodicals LLC on behalf of the Association for the Advancement of Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Over the last decade, there has been a remarkable surge in interest in
automated crowd monitoring within the computer vision community. Modern
deep-learning approaches have made it possible to develop fully-automated
vision-based crowd-monitoring applications. However, despite the magnitude of
the issue at hand, the significant technological advancements, and the
consistent interest of the research community, there are still numerous
challenges that need to be overcome. In this article, we delve into six major
areas of visual crowd analysis, emphasizing the key developments in each of
these areas. We outline the crucial unresolved issues that must be tackled in
future works, in order to ensure that the field of automated crowd monitoring
continues to progress and thrive. Several surveys related to this topic have
been conducted in the past. Nonetheless, this article thoroughly examines and
presents a more intuitive categorization of works, while also depicting the
latest breakthroughs within the field, incorporating more recent studies
carried out within the last few years in a concise manner. By carefully
choosing prominent works with significant contributions in terms of novelty or
performance gains, this paper presents a more comprehensive exposition of
advancements in the current state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10680" title="Abstract">arXiv:2308.10680</a> [<a href="/pdf/2308.10680" title="Download PDF">pdf</a>, <a href="/format/2308.10680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Co-Speech Gesture Detection through Multi-phase Sequence Labeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghaleb%2C+E">Esam Ghaleb</a>, 
<a href="/search/cs?searchtype=author&query=Burenko%2C+I">Ilya Burenko</a>, 
<a href="/search/cs?searchtype=author&query=Rasenberg%2C+M">Marlou Rasenberg</a>, 
<a href="/search/cs?searchtype=author&query=Pouw%2C+W">Wim Pouw</a>, 
<a href="/search/cs?searchtype=author&query=Uhrig%2C+P">Peter Uhrig</a>, 
<a href="/search/cs?searchtype=author&query=Holler%2C+J">Judith Holler</a>, 
<a href="/search/cs?searchtype=author&query=Toni%2C+I">Ivan Toni</a>, 
<a href="/search/cs?searchtype=author&query=%C3%96zy%C3%BCrek%2C+A">Asl&#x131; &#xd6;zy&#xfc;rek</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez%2C+R">Raquel Fern&#xe1;ndez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Gestures are integral components of face-to-face communication. They unfold
over time, often following predictable movement phases of preparation, stroke,
and retraction. Yet, the prevalent approach to automatic gesture detection
treats the problem as binary classification, classifying a segment as either
containing a gesture or not, thus failing to capture its inherently sequential
and contextual nature. To address this, we introduce a novel framework that
reframes the task as a multi-phase sequence labeling problem rather than binary
classification. Our model processes sequences of skeletal movements over time
windows, uses Transformer encoders to learn contextual embeddings, and
leverages Conditional Random Fields to perform sequence labeling. We evaluate
our proposal on a large dataset of diverse co-speech gestures in task-oriented
face-to-face dialogues. The results consistently demonstrate that our method
significantly outperforms strong baseline models in detecting gesture strokes.
Furthermore, applying Transformer encoders to learn contextual embeddings from
movement sequences substantially improves gesture unit detection. These results
highlight our framework's capacity to capture the fine-grained dynamics of
co-speech gesture phases, paving the way for more nuanced and accurate gesture
detection and analysis.
</p>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10682" title="Abstract">arXiv:2308.10682</a> [<a href="/pdf/2308.10682" title="Download PDF">pdf</a>, <a href="/format/2308.10682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LibriWASN: A Data Set for Meeting Separation, Diarization, and  Recognition with Asynchronous Recording Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schmalenstroeer%2C+J">Joerg Schmalenstroeer</a>, 
<a href="/search/cs?searchtype=author&query=Gburrek%2C+T">Tobias Gburrek</a>, 
<a href="/search/cs?searchtype=author&query=Haeb-Umbach%2C+R">Reinhold Haeb-Umbach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at the ITG conference on Speech Communication 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We present LibriWASN, a data set whose design follows closely the LibriCSS
meeting recognition data set, with the marked difference that the data is
recorded with devices that are randomly positioned on a meeting table and whose
sampling clocks are not synchronized. Nine different devices, five smartphones
with a single recording channel and four microphone arrays, are used to record
a total of 29 channels. Other than that, the data set follows closely the
LibriCSS design: the same LibriSpeech sentences are played back from eight
loudspeakers arranged around a meeting table and the data is organized in
subsets with different percentages of speech overlap. LibriWASN is meant as a
test set for clock synchronization algorithms, meeting separation, diarization
and transcription systems on ad-hoc wireless acoustic sensor networks. Due to
its similarity to LibriCSS, meeting transcription systems developed for the
former can readily be tested on LibriWASN. The data set is recorded in two
different rooms and is complemented with ground-truth diarization information
of who speaks when.
</p>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10684" title="Abstract">arXiv:2308.10684</a> [<a href="/pdf/2308.10684" title="Download PDF">pdf</a>, <a href="/format/2308.10684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Systematic Offensive Stereotyping (SOS) Bias in Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elsafoury%2C+F">Fatma Elsafoury</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Keywords: Systematic offensive stereotyping (SOS) bias, Language models, bias removal, fairness, hate speech detection
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Research has shown that language models (LMs) are socially biased. However,
toxicity and offensive stereotyping bias in LMs are understudied. In this
paper, we investigate the systematic offensive stereotype (SOS) bias in LMs. We
propose a method to measure it. Then, we validate the SOS bias and investigate
the effectiveness of debias methods from the literature on removing it.
Finally, we investigate the impact of the SOS bias in LMs on their performance
and their fairness on the task of hate speech detection. Our results suggest
that all the inspected LMs are SOS biased. The results suggest that the SOS
bias in LMs is reflective of the hate experienced online by the inspected
marginalized groups. The results indicate that removing the SOS bias in LMs,
using a popular debias method from the literature, leads to worse SOS bias
scores. Finally, Our results show no strong evidence that the SOS bias in LMs
is impactful on their performance on hate speech detection. On the other hand,
there is evidence that the SOS bias in LMs is impactful on their fairness.
</p>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10685" title="Abstract">arXiv:2308.10685</a> [<a href="/pdf/2308.10685" title="Download PDF">pdf</a>, <a href="/format/2308.10685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Graph Prompt-tuning for Cross-domain Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+Z">Zixuan Yi</a>, 
<a href="/search/cs?searchtype=author&query=Ounis%2C+I">Iadh Ounis</a>, 
<a href="/search/cs?searchtype=author&query=Macdonald%2C+C">Craig Macdonald</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Recommender systems are frequently challenged by the data sparsity problem.
One approach to mitigate this issue is through cross-domain recommendation
techniques. In a cross-domain context, sharing knowledge between domains can
enhance the effectiveness in the target domain. Recent cross-domain methods
have employed a pre-training approach, but we argue that these methods often
result in suboptimal fine-tuning, especially with large neural models. Modern
language models utilize prompts for efficient model tuning. Such prompts act as
a tunable latent vector, allowing for the freezing of the main model
parameters. In our research, we introduce the Personalised Graph Prompt-based
Recommendation (PGPRec) framework. This leverages the advantages of
prompt-tuning. Within this framework, we formulate personalized graph prompts
item-wise, rooted in items that a user has previously engaged with.
Specifically, we employ Contrastive Learning (CL) to produce pre-trained
embeddings that offer greater generalizability in the pre-training phase,
ensuring robust training during the tuning phase. Our evaluation of PGPRec in
cross-domain scenarios involves comprehensive testing with the top-k
recommendation tasks and a cold-start analysis. Our empirical findings, based
on four Amazon Review datasets, reveal that the PGPRec framework can decrease
the tuned parameters by as much as 74%, maintaining competitive performance.
Remarkably, there's an 11.41% enhancement in performance against the leading
baseline in cold-start situations.
</p>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10686" title="Abstract">arXiv:2308.10686</a> [<a href="/pdf/2308.10686" title="Download PDF">pdf</a>, <a href="/format/2308.10686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Normative conditional reasoning as a fragment of HOL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parenta%2C+X">Xavier Parenta</a>, 
<a href="/search/cs?searchtype=author&query=Benzm%C3%BCller%2C+C">Christoph Benzm&#xfc;ller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 28 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI); Symbolic Computation (cs.SC)

</div>
<p class="mathjax">We report some results regarding the mechanization of normative
(preference-based) conditional reasoning. Our focus is on Aqvist's system E for
conditional obligation (and its extensions). Our mechanization is achieved via
a shallow semantical embedding in Isabelle/HOL. We consider two possible uses
of the framework. The first one is as a tool for meta-reasoning about the
considered logic. We employ it for the automated verification of deontic
correspondences (broadly conceived) and related matters, analogous to what has
been previously achieved for the modal logic cube. The second use is as a tool
for assessing ethical arguments. We provide a computer encoding of a well-known
paradox in population ethics, Parfit's repugnant conclusion. Whether the
presented encoding increases or decreases the attractiveness and persuasiveness
of the repugnant conclusion is a question we would like to pass on to
philosophy and ethics.
</p>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10689" title="Abstract">arXiv:2308.10689</a> [<a href="/pdf/2308.10689" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a knowledge leakage Mitigation framework for mobile Devices in  knowledge-intensive Organizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Serna%2C+C+A+A">Carlos Andres Agudelo Serna</a>, 
<a href="/search/cs?searchtype=author&query=Bosua%2C+R">Rachelle Bosua</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+A">Atif Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Maynard%2C+S+B">Sean B. Maynard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, ECIS full paper 2018
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Research Papers. 72 (2018) https://aisel.aisnet.org/ecis2018_rp/72
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">The use of mobile devices in knowledge-intensive organizations while
effective and cost-efficient also pose a challenging management problem. Often
employees whether deliberately or inadvertently are the cause of knowledge
leakage in organizations and the use of mobile devices further exacerbates it.
This problem is the result of overly focusing on technical controls while
neglecting human factors. Knowledge leakage is a multidimensional problem, and
in this paper, we highlight the different dimensions that constitute it. In
this study, our contributions are threefold. First, we study knowledge leakage
risk (KLR) within the context of mobile devices in knowledge-intensive
organizations in Australia. Second, we present a conceptual framework to
explain and categorize the mitigation strategies to combat KLR through the use
of mobile devices grounded in the literature. And third, we apply the framework
to the findings from interviews with security and knowledge managers. Keywords:
Knowledge Leakage, Knowledge Risk, Knowledge intensive, Mobile device.
</p>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10691" title="Abstract">arXiv:2308.10691</a> [<a href="/pdf/2308.10691" title="Download PDF">pdf</a>, <a href="/format/2308.10691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dexterous Soft Hands Linearize Feedback-Control for In-Hand Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sieler%2C+A">Adrian Sieler</a>, 
<a href="/search/cs?searchtype=author&query=Brock%2C+O">Oliver Brock</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a feedback-control framework for in-hand manipulation
(IHM) with dexterous soft hands that enables the acquisition of manipulation
skills in the real-world within minutes. We choose the deformation state of the
soft hand as the control variable. To control for a desired deformation state,
we use coarsely approximated Jacobians of the actuation-deformation dynamics.
These Jacobian are obtained via exploratory actions. This is enabled by the
self-stabilizing properties of compliant hands, which allow us to use linear
feedback control in the presence of complex contact dynamics. To evaluate the
effectiveness of our approach, we show the generalization capabilities for a
learned manipulation skill to variations in object size by 100 %, 360 degree
changes in palm inclination and to disabling up to 50 % of the involved
actuators. In addition, complex manipulations can be obtained by sequencing
such feedback-skills.
</p>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10692" title="Abstract">arXiv:2308.10692</a> [<a href="/pdf/2308.10692" title="Download PDF">pdf</a>, <a href="/format/2308.10692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Fine-Grained Representation and Recomposition for  Cloth-Changing Person Re-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qizao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+X">Xuelin Qian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bin Li</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Ying Fu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yanwei Fu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+X">Xiangyang Xue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Cloth-changing person Re-IDentification (Re-ID) is a particularly challenging
task, suffering from two limitations of inferior identity-relevant features and
limited training samples. Existing methods mainly leverage auxiliary
information to facilitate discriminative feature learning, including
soft-biometrics features of shapes and gaits, and additional labels of
clothing. However, these information may be unavailable in real-world
applications. In this paper, we propose a novel FIne-grained Representation and
Recomposition (FIRe$^{2}$) framework to tackle both limitations without any
auxiliary information. Specifically, we first design a Fine-grained Feature
Mining (FFM) module to separately cluster images of each person. Images with
similar so-called fine-grained attributes (e.g., clothes and viewpoints) are
encouraged to cluster together. An attribute-aware classification loss is
introduced to perform fine-grained learning based on cluster labels, which are
not shared among different people, promoting the model to learn
identity-relevant features. Furthermore, by taking full advantage of the
clustered fine-grained attributes, we present a Fine-grained Attribute
Recomposition (FAR) module to recompose image features with different
attributes in the latent space. It can significantly enhance representations
for robust feature learning. Extensive experiments demonstrate that FIRe$^{2}$
can achieve state-of-the-art performance on five widely-used cloth-changing
person Re-ID benchmarks.
</p>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10693" title="Abstract">arXiv:2308.10693</a> [<a href="/pdf/2308.10693" title="Download PDF">pdf</a>, <a href="/ps/2308.10693" title="Download PostScript">ps</a>, <a href="/format/2308.10693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> About the &#x27;&#x27;accurate mode&#x27;&#x27; of the IEEE 1788-2015 standard for interval  arithmetic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Revol%2C+N">Nathalie Revol</a> (ARIC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The IEEE 1788-2015 standard for interval arithmetic defines three accuracy
modes for the so-called set-based flavor: tightest, accurate and valid. This
work in progress focuses on the accurate mode.First, an introduction to
interval arithmetic and to the IEEE 1788-2015 standard is given, then the
accurate mode is defined. How can this accurate mode be tested, when a library
implementing interval arithmetic claims to provide this mode? The chosen
approach is unit testing, and the elaboration of testing pairs for this
approach is developed.A discussion closes this paper: how can the tester be
tested? And if we go to the roots of the subject, is the accurate mode really
relevant or should it be dropped off in the next version of the standard?
</p>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10694" title="Abstract">arXiv:2308.10694</a> [<a href="/pdf/2308.10694" title="Download PDF">pdf</a>, <a href="/format/2308.10694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vanishing Point Estimation in Uncalibrated Images with Prior Gravity  Direction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pautrat%2C+R">R&#xe9;mi Pautrat</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shaohui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hruby%2C+P">Petr Hruby</a>, 
<a href="/search/cs?searchtype=author&query=Pollefeys%2C+M">Marc Pollefeys</a>, 
<a href="/search/cs?searchtype=author&query=Barath%2C+D">Daniel Barath</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We tackle the problem of estimating a Manhattan frame, i.e. three orthogonal
vanishing points, and the unknown focal length of the camera, leveraging a
prior vertical direction. The direction can come from an Inertial Measurement
Unit that is a standard component of recent consumer devices, e.g.,
smartphones. We provide an exhaustive analysis of minimal line configurations
and derive two new 2-line solvers, one of which does not suffer from
singularities affecting existing solvers. Additionally, we design a new
non-minimal method, running on an arbitrary number of lines, to boost the
performance in local optimization. Combining all solvers in a hybrid robust
estimator, our method achieves increased accuracy even with a rough prior.
Experiments on synthetic and real-world datasets demonstrate the superior
accuracy of our method compared to the state of the art, while having
comparable runtimes. We further demonstrate the applicability of our solvers
for relative rotation estimation. The code is available at
https://github.com/cvg/VP-Estimation-with-Prior-Gravity.
</p>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10696" title="Abstract">arXiv:2308.10696</a> [<a href="/pdf/2308.10696" title="Download PDF">pdf</a>, <a href="/format/2308.10696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCC5G: A PQC-based Architecture for Highly Secure Critical Communication  over Cellular Network in Zero-Trust Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gharib%2C+M">Mohammed Gharib</a>, 
<a href="/search/cs?searchtype=author&query=Afghah%2C+F">Fatemeh Afghah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">5G made a significant jump in cellular network security by offering enhanced
subscriber identity protection and a user-network mutual authentication
implementation. However, it still does not fully follow the zero-trust (ZT)
requirements, as users need to trust the network, 5G network is not necessarily
authenticated in each communication instance, and there is no mutual
authentication between end users. When critical communications need to use
commercial networks, but the environment is ZT, specific security architecture
is needed to provide security services that do not rely on any 5G network
trusted authority. In this paper, we propose SCC5G Secure Critical-mission
Communication over a 5G network in ZT setting. SCC5G is a post-quantum
cryptography (PQC) security solution that loads an embedded hardware root of
authentication (HRA), such as physically unclonable functions (PUF), into the
users' devices, to achieve tamper-resistant and unclonability features for
authentication and key agreement. We evaluate the performance of the proposed
architecture through an exhaustive simulation of a 5G network in an ns-3
network simulator. Results verify the scalability and efficiency of SCC5G by
showing that it poses only a few kilobytes of traffic overhead and adds only an
order of $O(0.1)$ second of latency under the normal traffic load.
</p>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10698" title="Abstract">arXiv:2308.10698</a> [<a href="/pdf/2308.10698" title="Download PDF">pdf</a>, <a href="/format/2308.10698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Order Numerical Integration on Domains Bounded by Intersecting  Level Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Beck%2C+L">Lauritz Beck</a>, 
<a href="/search/math?searchtype=author&query=Kummer%2C+F">Florian Kummer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present a high-order method that provides numerical integration on
volumes, surfaces, and lines defined implicitly by two smooth intersecting
level sets. To approximate the integrals, the method maps quadrature rules
defined on hypercubes to the curved domains of the integrals. This enables the
numerical integration of a wide range of integrands since integration on
hypercubes is a well known problem. The mappings are constructed by treating
the isocontours of the level sets as graphs of height functions. Numerical
experiments with smooth integrands indicate a high-order of convergence for
transformed Gauss quadrature rules on domains defined by polynomial, rational,
and trigonometric level sets. We show that the approach we have used can be
combined readily with adaptive quadrature methods. Moreover, we apply the
approach to numerically integrate on difficult geometries without requiring a
low-order fallback method.
</p>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10699" title="Abstract">arXiv:2308.10699</a> [<a href="/pdf/2308.10699" title="Download PDF">pdf</a>, <a href="/format/2308.10699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cost-Efficient Online Decision Making: A Combinatorial Multi-Armed  Bandit Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahbar%2C+A">Arman Rahbar</a>, 
<a href="/search/cs?searchtype=author&query=%C3%85kerblom%2C+N">Niklas &#xc5;kerblom</a>, 
<a href="/search/cs?searchtype=author&query=Chehreghani%2C+M+H">Morteza Haghir Chehreghani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Online decision making plays a crucial role in numerous real-world
applications. In many scenarios, the decision is made based on performing a
sequence of tests on the incoming data points. However, performing all tests
can be expensive and is not always possible. In this paper, we provide a novel
formulation of the online decision making problem based on combinatorial
multi-armed bandits and take the cost of performing tests into account. Based
on this formulation, we provide a new framework for cost-efficient online
decision making which can utilize posterior sampling or BayesUCB for
exploration. We provide a rigorous theoretical analysis for our framework and
present various experimental results that demonstrate its applicability to
real-world problems.
</p>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10702" title="Abstract">arXiv:2308.10702</a> [<a href="/pdf/2308.10702" title="Download PDF">pdf</a>, <a href="/format/2308.10702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Optimal Experimental Design for Constitutive Model Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ricciardi%2C+D">Denielle Ricciardi</a>, 
<a href="/search/cs?searchtype=author&query=Seidl%2C+T">Tom Seidl</a>, 
<a href="/search/cs?searchtype=author&query=Lester%2C+B">Brian Lester</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+A">Amanda Jones</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+E">Elizabeth Jones</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Applications (stat.AP)

</div>
<p class="mathjax">Computational simulation is increasingly relied upon for high-consequence
engineering decisions, and a foundational element to solid mechanics
simulations, such as finite element analysis (FEA), is a credible constitutive
or material model. Calibration of these complex models is an essential step;
however, the selection, calibration and validation of material models is often
a discrete, multi-stage process that is decoupled from material
characterization activities, which means the data collected does not always
align with the data that is needed. To address this issue, an integrated
workflow for delivering an enhanced characterization and calibration procedure
(Interlaced Characterization and Calibration (ICC)) is introduced. This
framework leverages Bayesian optimal experimental design (BOED) to select the
optimal load path for a cruciform specimen in order to collect the most
informative data for model calibration. The critical first piece of algorithm
development is to demonstrate the active experimental design for a fast model
with simulated data. For this demonstration, a material point simulator that
models a plane stress elastoplastic material subject to bi-axial loading was
chosen. The ICC framework is demonstrated on two exemplar problems in which
BOED is used to determine which load step to take, e.g., in which direction to
increment the strain, at each iteration of the characterization and calibration
cycle. Calibration results from data obtained by adaptively selecting the load
path within the ICC algorithm are compared to results from data generated under
two naive static load paths that were chosen a priori based on human intuition.
In these exemplar problems, data generated in an adaptive setting resulted in
calibrated model parameters with reduced measures of uncertainty compared to
the static settings.
</p>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10703" title="Abstract">arXiv:2308.10703</a> [<a href="/pdf/2308.10703" title="Download PDF">pdf</a>, <a href="/format/2308.10703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal error estimates for non-conforming approximations of linear  parabolic problems with minimal regularity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Droniou%2C+J">J Droniou</a>, 
<a href="/search/math?searchtype=author&query=Eymard%2C+R">R Eymard</a>, 
<a href="/search/math?searchtype=author&query=Gallou%C3%ABt%2C+T">T Gallou&#xeb;t</a> (AMU), 
<a href="/search/math?searchtype=author&query=Guichard%2C+C">C Guichard</a> (SU), 
<a href="/search/math?searchtype=author&query=Herbin%2C+R">R Herbin</a> (AMU)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider a general linear parabolic problem with extended time boundary
conditions (including initial value problems and periodic ones), and
approximate it by the implicit Euler scheme in time and the Gradient
Discretisation method in space; the latter is in fact a class of methods that
includes conforming and nonconforming finite elements, discontinuous Galerkin
methods and several others. The main result is an error estimate which holds
without supplementary regularity hypothesis on the solution. This result states
that the approximation error has the same order as the sum of the interpolation
error and the conformity error. The proof of this result relies on an inf-sup
inequality in Hilbert spaces which can be used both in the continuous and the
discrete frameworks. The error estimate result is illustrated by numerical
examples with low regularity of the solution.
</p>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10704" title="Abstract">arXiv:2308.10704</a> [<a href="/pdf/2308.10704" title="Download PDF">pdf</a>, <a href="/format/2308.10704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sampling From Autoencoders&#x27; Latent Space via Quantization And  Probability Mass Function Concepts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bouayed%2C+A+M">Aymene Mohammed Bouayed</a>, 
<a href="/search/cs?searchtype=author&query=Iaccovelli%2C+A">Adrian Iaccovelli</a>, 
<a href="/search/cs?searchtype=author&query=Naccache%2C+D">David Naccache</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this study, we focus on sampling from the latent space of generative
models built upon autoencoders so as the reconstructed samples are lifelike
images. To do to, we introduce a novel post-training sampling algorithm rooted
in the concept of probability mass functions, coupled with a quantization
process. Our proposed algorithm establishes a vicinity around each latent
vector from the input data and then proceeds to draw samples from these defined
neighborhoods. This strategic approach ensures that the sampled latent vectors
predominantly inhabit high-probability regions, which, in turn, can be
effectively transformed into authentic real-world images. A noteworthy point of
comparison for our sampling algorithm is the sampling technique based on
Gaussian mixture models (GMM), owing to its inherent capability to represent
clusters. Remarkably, we manage to improve the time complexity from the
previous $\mathcal{O}(n\times d \times k \times i)$ associated with GMM
sampling to a much more streamlined $\mathcal{O}(n\times d)$, thereby resulting
in substantial speedup during runtime. Moreover, our experimental results,
gauged through the Fr\'echet inception distance (FID) for image generation,
underscore the superior performance of our sampling algorithm across a diverse
range of models and datasets. On the MNIST benchmark dataset, our approach
outperforms GMM sampling by yielding a noteworthy improvement of up to $0.89$
in FID value. Furthermore, when it comes to generating images of faces and
ocular images, our approach showcases substantial enhancements with FID
improvements of $1.69$ and $0.87$ respectively, as compared to GMM sampling, as
evidenced on the CelebA and MOBIUS datasets. Lastly, we substantiate our
methodology's efficacy in estimating latent space distributions in contrast to
GMM sampling, particularly through the lens of the Wasserstein distance.
</p>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10705" title="Abstract">arXiv:2308.10705</a> [<a href="/pdf/2308.10705" title="Download PDF">pdf</a>, <a href="/format/2308.10705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised 3D Pose Estimation with Non-Rigid Structure-from-Motion  Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Haorui Ji</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+H">Hui Deng</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yuchao Dai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongdong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Most of the previous 3D human pose estimation work relied on the powerful
memory capability of the network to obtain suitable 2D-3D mappings from the
training data. Few works have studied the modeling of human posture deformation
in motion. In this paper, we propose a new modeling method for human pose
deformations and design an accompanying diffusion-based motion prior. Inspired
by the field of non-rigid structure-from-motion, we divide the task of
reconstructing 3D human skeletons in motion into the estimation of a 3D
reference skeleton, and a frame-by-frame skeleton deformation. A mixed
spatial-temporal NRSfMformer is used to simultaneously estimate the 3D
reference skeleton and the skeleton deformation of each frame from 2D
observations sequence, and then sum them to obtain the pose of each frame.
Subsequently, a loss term based on the diffusion model is used to ensure that
the pipeline learns the correct prior motion knowledge. Finally, we have
evaluated our proposed method on mainstream datasets and obtained superior
results outperforming the state-of-the-art.
</p>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10707" title="Abstract">arXiv:2308.10707</a> [<a href="/pdf/2308.10707" title="Download PDF">pdf</a>, <a href="/format/2308.10707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sensor Fusion by Spatial Encoding for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lai-Dang%2C+Q">Quoc-Vinh Lai-Dang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jihui Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+B">Bumgeun Park</a>, 
<a href="/search/cs?searchtype=author&query=Har%2C+D">Dongsoo Har</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for Lecture presentation at the 2023 IEEE SENSORS conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Sensor fusion is critical to perception systems for task domains such as
autonomous driving and robotics. Recently, the Transformer integrated with CNN
has demonstrated high performance in sensor fusion for various perception
tasks. In this work, we introduce a method for fusing data from camera and
LiDAR. By employing Transformer modules at multiple resolutions, proposed
method effectively combines local and global contextual relationships. The
performance of the proposed method is validated by extensive experiments with
two adversarial benchmarks with lengthy routes and high-density traffics. The
proposed method outperforms previous approaches with the most challenging
benchmarks, achieving significantly higher driving and infraction scores.
Compared with TransFuser, it achieves 8% and 19% improvement in driving scores
for the Longest6 and Town05 Long benchmarks, respectively.
</p>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10708" title="Abstract">arXiv:2308.10708</a> [<a href="/pdf/2308.10708" title="Download PDF">pdf</a>, <a href="/format/2308.10708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring the Effect of Causal Disentanglement on the Adversarial  Robustness of Neural Network Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ness%2C+P+M">Preben M. Ness</a>, 
<a href="/search/cs?searchtype=author&query=Marijan%2C+D">Dusica Marijan</a>, 
<a href="/search/cs?searchtype=author&query=Bose%2C+S">Sunanda Bose</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Causal Neural Network models have shown high levels of robustness to
adversarial attacks as well as an increased capacity for generalisation tasks
such as few-shot learning and rare-context classification compared to
traditional Neural Networks. This robustness is argued to stem from the
disentanglement of causal and confounder input signals. However, no
quantitative study has yet measured the level of disentanglement achieved by
these types of causal models or assessed how this relates to their adversarial
robustness.
<br />Existing causal disentanglement metrics are not applicable to deterministic
models trained on real-world datasets. We, therefore, utilise metrics of
content/style disentanglement from the field of Computer Vision to measure
different aspects of the causal disentanglement for four state-of-the-art
causal Neural Network models. By re-implementing these models with a common
ResNet18 architecture we are able to fairly measure their adversarial
robustness on three standard image classification benchmarking datasets under
seven common white-box attacks. We find a strong association (r=0.820, p=0.001)
between the degree to which models decorrelate causal and confounder signals
and their adversarial robustness. Additionally, we find a moderate negative
association between the pixel-level information content of the confounder
signal and adversarial robustness (r=-0.597, p=0.040).
</p>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10711" title="Abstract">arXiv:2308.10711</a> [<a href="/pdf/2308.10711" title="Download PDF">pdf</a>, <a href="/format/2308.10711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relax and penalize: a new bilevel approach to mixed-binary  hyperparameter optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Santis%2C+M">Marianna de Santis</a> (UNIROMA), 
<a href="/search/cs?searchtype=author&query=Frecon%2C+J">Jordan Frecon</a> (LHC), 
<a href="/search/cs?searchtype=author&query=Rinaldi%2C+F">Francesco Rinaldi</a> (Unipd), 
<a href="/search/cs?searchtype=author&query=Salzo%2C+S">Saverio Salzo</a> (DIAG UNIROMA), 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+M">Martin Schmidt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In recent years, bilevel approaches have become very popular to efficiently
estimate high-dimensional hyperparameters of machine learning models. However,
to date, binary parameters are handled by continuous relaxation and rounding
strategies, which could lead to inconsistent solutions. In this context, we
tackle the challenging optimization of mixed-binary hyperparameters by
resorting to an equivalent continuous bilevel reformulation based on an
appropriate penalty term. We propose an algorithmic framework that, under
suitable assumptions, is guaranteed to provide mixed-binary solutions.
Moreover, the generality of the method allows to safely use existing continuous
bilevel solvers within the proposed framework. We evaluate the performance of
our approach for a specific machine learning problem, i.e., the estimation of
the group-sparsity structure in regression problems. Reported results clearly
show that our method outperforms state-of-the-art approaches based on
relaxation and rounding
</p>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10713" title="Abstract">arXiv:2308.10713</a> [<a href="/pdf/2308.10713" title="Download PDF">pdf</a>, <a href="/format/2308.10713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LibreFace: An Open-Source Toolkit for Deep Facial Expression Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+D">Di Chang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yufeng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongjian Li</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+M">Minh Tran</a>, 
<a href="/search/cs?searchtype=author&query=Soleymani%2C+M">Mohammad Soleymani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures. Accepted by WACV 2024 Round 1. (Application Track)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Facial expression analysis is an important tool for human-computer
interaction. In this paper, we introduce LibreFace, an open-source toolkit for
facial expression analysis. This open-source toolbox offers real-time and
offline analysis of facial behavior through deep learning models, including
facial action unit (AU) detection, AU intensity estimation, and facial
expression recognition. To accomplish this, we employ several techniques,
including the utilization of a large-scale pre-trained network, feature-wise
knowledge distillation, and task-specific fine-tuning. These approaches are
designed to effectively and accurately analyze facial expressions by leveraging
visual information, thereby facilitating the implementation of real-time
interactive applications. In terms of Action Unit (AU) intensity estimation, we
achieve a Pearson Correlation Coefficient (PCC) of 0.63 on DISFA, which is 7%
higher than the performance of OpenFace 2.0 while maintaining highly-efficient
inference that runs two times faster than OpenFace 2.0. Despite being compact,
our model also demonstrates competitive performance to state-of-the-art facial
expression analysis methods on AffecNet, FFHQ, and RAFDB. Our code will be
released at https://github.com/ihp-lab/LibreFace
</p>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10714" title="Abstract">arXiv:2308.10714</a> [<a href="/pdf/2308.10714" title="Download PDF">pdf</a>, <a href="/format/2308.10714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CXL Memory as Persistent Memory for Disaggregated HPC: A Practical  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fridman%2C+Y">Yehonatan Fridman</a>, 
<a href="/search/cs?searchtype=author&query=Desai%2C+S+M">Suprasad Mutalik Desai</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+N">Navneet Singh</a>, 
<a href="/search/cs?searchtype=author&query=Willhalm%2C+T">Thomas Willhalm</a>, 
<a href="/search/cs?searchtype=author&query=Oren%2C+G">Gal Oren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">In the landscape of High-Performance Computing (HPC), the quest for efficient
and scalable memory solutions remains paramount. The advent of Compute Express
Link (CXL) introduces a promising avenue with its potential to function as a
Persistent Memory (PMem) solution in the context of disaggregated HPC systems.
This paper presents a comprehensive exploration of CXL memory's viability as a
candidate for PMem, supported by physical experiments conducted on cutting-edge
multi-NUMA nodes equipped with CXL-attached memory prototypes. Our study not
only benchmarks the performance of CXL memory but also illustrates the seamless
transition from traditional PMem programming models to CXL, reinforcing its
practicality.
<br />To substantiate our claims, we establish a tangible CXL prototype using an
FPGA card embodying CXL 1.1/2.0 compliant endpoint designs (Intel FPGA CXL IP).
Performance evaluations, executed through the STREAM and STREAM-PMem
benchmarks, showcase CXL memory's ability to mirror PMem characteristics in
App-Direct and Memory Mode while achieving impressive bandwidth metrics with
Intel 4th generation Xeon (Sapphire Rapids) processors.
<br />The results elucidate the feasibility of CXL memory as a persistent memory
solution, outperforming previously established benchmarks. In contrast to
published DCPMM results, our CXL-DDR4 memory module offers comparable bandwidth
to local DDR4 memory configurations, albeit with a moderate decrease in
performance. The modified STREAM-PMem application underscores the ease of
transitioning programming models from PMem to CXL, thus underscoring the
practicality of adopting CXL memory.
</p>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10716" title="Abstract">arXiv:2308.10716</a> [<a href="/pdf/2308.10716" title="Download PDF">pdf</a>, <a href="/format/2308.10716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Color Prompting for Data-Free Continual Unsupervised Domain Adaptive  Person Re-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jianyang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Hao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yang You</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jian Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unsupervised domain adaptive person re-identification (Re-ID) methods
alleviate the burden of data annotation through generating pseudo supervision
messages. However, real-world Re-ID systems, with continuously accumulating
data streams, simultaneously demand more robust adaptation and anti-forgetting
capabilities. Methods based on image rehearsal addresses the forgetting issue
with limited extra storage but carry the risk of privacy leakage. In this work,
we propose a Color Prompting (CoP) method for data-free continual unsupervised
domain adaptive person Re-ID. Specifically, we employ a light-weighted prompter
network to fit the color distribution of the current task together with Re-ID
training. Then for the incoming new tasks, the learned color distribution
serves as color style transfer guidance to transfer the images into past
styles. CoP achieves accurate color style recovery for past tasks with adequate
data diversity, leading to superior anti-forgetting effects compared with image
rehearsal methods. Moreover, CoP demonstrates strong generalization performance
for fast adaptation into new domains, given only a small amount of unlabeled
images. Extensive experiments demonstrate that after the continual training
pipeline the proposed CoP achieves 6.7% and 8.1% average rank-1 improvements
over the replay method on seen and unseen domains, respectively. The source
code for this work is publicly available in
https://github.com/vimar-gu/ColorPromptReID.
</p>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10717" title="Abstract">arXiv:2308.10717</a> [<a href="/pdf/2308.10717" title="Download PDF">pdf</a>, <a href="/format/2308.10717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Person Re-identification from a Projection-on-Prototypes  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qizao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+X">Xuelin Qian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bin Li</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yanwei Fu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+X">Xiangyang Xue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Person Re-IDentification (Re-ID) as a retrieval task, has achieved tremendous
development over the past decade. Existing state-of-the-art methods follow an
analogous framework to first extract features from the input images and then
categorize them with a classifier. However, since there is no identity overlap
between training and testing sets, the classifier is often discarded during
inference. Only the extracted features are used for person retrieval via
distance metrics. In this paper, we rethink the role of the classifier in
person Re-ID, and advocate a new perspective to conceive the classifier as a
projection from image features to class prototypes. These prototypes are
exactly the learned parameters of the classifier. In this light, we describe
the identity of input images as similarities to all prototypes, which are then
utilized as more discriminative features to perform person Re-ID. We thereby
propose a new baseline ProNet, which innovatively reserves the function of the
classifier at the inference stage. To facilitate the learning of class
prototypes, both triplet loss and identity classification loss are applied to
features that undergo the projection by the classifier. An improved version of
ProNet++ is presented by further incorporating multi-granularity designs.
Experiments on four benchmarks demonstrate that our proposed ProNet is simple
yet effective, and significantly beats previous baselines. ProNet++ also
achieves competitive or even better results than transformer-based competitors.
</p>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10718" title="Abstract">arXiv:2308.10718</a> [<a href="/pdf/2308.10718" title="Download PDF">pdf</a>, <a href="/format/2308.10718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backdooring Textual Inversion for Concept Censorship
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=wu%2C+Y">Yutong wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kerschbaum%2C+F">Florian Kerschbaum</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recent years have witnessed success in AIGC (AI Generated Content). People
can make use of a pre-trained diffusion model to generate images of high
quality or freely modify existing pictures with only prompts in nature
language. More excitingly, the emerging personalization techniques make it
feasible to create specific-desired images with only a few images as
references. However, this induces severe threats if such advanced techniques
are misused by malicious users, such as spreading fake news or defaming
individual reputations. Thus, it is necessary to regulate personalization
models (i.e., concept censorship) for their development and advancement.
<br />In this paper, we focus on the personalization technique dubbed Textual
Inversion (TI), which is becoming prevailing for its lightweight nature and
excellent performance. TI crafts the word embedding that contains detailed
information about a specific object. Users can easily download the word
embedding from public websites like Civitai and add it to their own stable
diffusion model without fine-tuning for personalization. To achieve the concept
censorship of a TI model, we propose leveraging the backdoor technique for good
by injecting backdoors into the Textual Inversion embeddings. Briefly, we
select some sensitive words as triggers during the training of TI, which will
be censored for normal use. In the subsequent generation stage, if the triggers
are combined with personalized embeddings as final prompts, the model will
output a pre-defined target image rather than images including the desired
malicious concept.
<br />To demonstrate the effectiveness of our approach, we conduct extensive
experiments on Stable Diffusion, a prevailing open-sourced text-to-image model.
Our code, data, and results are available at
https://concept-censorship.github.io.
</p>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10720" title="Abstract">arXiv:2308.10720</a> [<a href="/pdf/2308.10720" title="Download PDF">pdf</a>, <a href="/format/2308.10720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the accuracy of interpolation based on single-layer artificial neural  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Auricchio%2C+F">Ferdinando Auricchio</a>, 
<a href="/search/math?searchtype=author&query=Belardo%2C+M+R">Maria Roberta Belardo</a>, 
<a href="/search/math?searchtype=author&query=Calabr%C3%B2%2C+F">Francesco Calabr&#xf2;</a>, 
<a href="/search/math?searchtype=author&query=Pascaner%2C+A+F">Ariel F. Pascaner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the present paper, we consider one-hidden layer ANNs with a feedforward
architecture, also referred to as shallow or two-layer networks, so that the
structure is determined by the number and types of neurons. The determination
of the parameters that define the function, called training, is done via the
resolution of the approximation problem, so by imposing the interpolation
through a set of specific nodes. We present the case where the parameters are
trained using a procedure that is referred to as Extreme Learning Machine (ELM)
that leads to a linear interpolation problem. In such hypotheses, the existence
of an ANN interpolating function is guaranteed. The focus is then on the
accuracy of the interpolation outside of the given sampling interpolation nodes
when they are the equispaced, the Chebychev, and the randomly selected ones.
The study is motivated by the well-known bell-shaped Runge example, which makes
it clear that the construction of a global interpolating polynomial is accurate
only if trained on suitably chosen nodes, ad example the Chebychev ones. In
order to evaluate the behavior when growing the number of interpolation nodes,
we raise the number of neurons in our network and compare it with the
interpolating polynomial. We test using Runge's function and other well-known
examples with different regularities. As expected, the accuracy of the
approximation with a global polynomial increases only if the Chebychev nodes
are considered. Instead, the error for the ANN interpolating function always
decays and in most cases we observe that the convergence follows what is
observed in the polynomial case on Chebychev nodes, despite the set of nodes
used for training.
</p>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10721" title="Abstract">arXiv:2308.10721</a> [<a href="/pdf/2308.10721" title="Download PDF">pdf</a>, <a href="/format/2308.10721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoMIX: A Multi-agent Reinforcement Learning Training Architecture for  Efficient Decentralized Coordination and Independent Decision Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Minelli%2C+G">Giovanni Minelli</a>, 
<a href="/search/cs?searchtype=author&query=Musolesi%2C+M">Mirco Musolesi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Robust coordination skills enable agents to operate cohesively in shared
environments, together towards a common goal and, ideally, individually without
hindering each other's progress. To this end, this paper presents Coordinated
QMIX (CoMIX), a novel training framework for decentralized agents that enables
emergent coordination through flexible policies, allowing at the same time
independent decision-making at individual level. CoMIX models selfish and
collaborative behavior as incremental steps in each agent's decision process.
This allows agents to dynamically adapt their behavior to different situations
balancing independence and collaboration. Experiments using a variety of
simulation environments demonstrate that CoMIX outperforms baselines on
collaborative tasks. The results validate our incremental policy approach as
effective technique for improving coordination in multi-agent systems.
</p>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10722" title="Abstract">arXiv:2308.10722</a> [<a href="/pdf/2308.10722" title="Download PDF">pdf</a>, <a href="/ps/2308.10722" title="Download PostScript">ps</a>, <a href="/format/2308.10722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Clustered Linear Contextual Bandits with Knapsacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yichuan Deng</a>, 
<a href="/search/cs?searchtype=author&query=Mamakos%2C+M">Michalis Mamakos</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhao Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">In this work, we study clustered contextual bandits where rewards and
resource consumption are the outcomes of cluster-specific linear models. The
arms are divided in clusters, with the cluster memberships being unknown to an
algorithm. Pulling an arm in a time period results in a reward and in
consumption for each one of multiple resources, and with the total consumption
of any resource exceeding a constraint implying the termination of the
algorithm. Thus, maximizing the total reward requires learning not only models
about the reward and the resource consumption, but also cluster memberships. We
provide an algorithm that achieves regret sublinear in the number of time
periods, without requiring access to all of the arms. In particular, we show
that it suffices to perform clustering only once to a randomly selected subset
of the arms. To achieve this result, we provide a sophisticated combination of
techniques from the literature of econometrics and of bandits with constraints.
</p>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10724" title="Abstract">arXiv:2308.10724</a> [<a href="/pdf/2308.10724" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Global visibility of publications through Digital Object Identifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Turki%2C+H">Houcemeddine Turki</a>, 
<a href="/search/cs?searchtype=author&query=Fraumann%2C+G">Grischa Fraumann</a>, 
<a href="/search/cs?searchtype=author&query=Taieb%2C+M+A+H">Mohamed Ali Hadj Taieb</a>, 
<a href="/search/cs?searchtype=author&query=Aouicha%2C+M+B">Mohamed Ben Aouicha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 tables, 1 figure
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Frontiers in Research Metrics and Analytics, volume 8, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">This brief research report analyzes the availability of Digital Object
Identifiers (DOIs) worldwide, highlighting the dominance of large publishing
houses and the need for unique persistent identifiers to increase the
visibility of publications from developing countries. The study reveals that a
considerable amount of publications from developing countries are excluded from
the global flow of scientific information due to the absence of DOIs,
emphasizing the need for alternative publishing models. The authors suggest
that the availability of DOIs should receive more attention in scholarly
communication and scientometrics, contributing to a necessary debate on DOIs
relevant for librarians, publishers, and scientometricians.
</p>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10727" title="Abstract">arXiv:2308.10727</a> [<a href="/pdf/2308.10727" title="Download PDF">pdf</a>, <a href="/format/2308.10727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Test-time augmentation-based active learning and self-training for  label-efficient segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Specktor-Fadida%2C+B">Bella Specktor-Fadida</a>, 
<a href="/search/cs?searchtype=author&query=Levchakov%2C+A">Anna Levchakov</a>, 
<a href="/search/cs?searchtype=author&query=Schonberger%2C+D">Dana Schonberger</a>, 
<a href="/search/cs?searchtype=author&query=Ben-Sira%2C+L">Liat Ben-Sira</a>, 
<a href="/search/cs?searchtype=author&query=Ben-Bashat%2C+D">Dafna Ben-Bashat</a>, 
<a href="/search/cs?searchtype=author&query=Joskowicz%2C+L">Leo Joskowicz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to MICCAI MILLanD workshop 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning techniques depend on large datasets whose annotation is
time-consuming. To reduce annotation burden, the self-training (ST) and
active-learning (AL) methods have been developed as well as methods that
combine them in an iterative fashion. However, it remains unclear when each
method is the most useful, and when it is advantageous to combine them. In this
paper, we propose a new method that combines ST with AL using Test-Time
Augmentations (TTA). First, TTA is performed on an initial teacher network.
Then, cases for annotation are selected based on the lowest estimated Dice
score. Cases with high estimated scores are used as soft pseudo-labels for ST.
The selected annotated cases are trained with existing annotated cases and ST
cases with border slices annotations. We demonstrate the method on MRI fetal
body and placenta segmentation tasks with different data variability
characteristics. Our results indicate that ST is highly effective for both
tasks, boosting performance for in-distribution (ID) and out-of-distribution
(OOD) data. However, while self-training improved the performance of
single-sequence fetal body segmentation when combined with AL, it slightly
deteriorated performance of multi-sequence placenta segmentation on ID data. AL
was helpful for the high variability placenta data, but did not improve upon
random selection for the single-sequence body data. For fetal body segmentation
sequence transfer, combining AL with ST following ST iteration yielded a Dice
of 0.961 with only 6 original scans and 2 new sequence scans. Results using
only 15 high-variability placenta cases were similar to those using 50 cases.
Code is available at: https://github.com/Bella31/TTA-quality-estimation-ST-AL
</p>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10729" title="Abstract">arXiv:2308.10729</a> [<a href="/pdf/2308.10729" title="Download PDF">pdf</a>, <a href="/format/2308.10729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Patch Is Not All You Need
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changzhen Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Z">Zhilong Ji</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jinfeng Bai</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+S">Shiguang Shan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision Transformers have achieved great success in computer visions,
delivering exceptional performance across various tasks. However, their
inherent reliance on sequential input enforces the manual partitioning of
images into patch sequences, which disrupts the image's inherent structural and
semantic continuity. To handle this, we propose a novel Pattern Transformer
(Patternformer) to adaptively convert images to pattern sequences for
Transformer input. Specifically, we employ the Convolutional Neural Network to
extract various patterns from the input image, with each channel representing a
unique pattern that is fed into the succeeding Transformer as a visual token.
By enabling the network to optimize these patterns, each pattern concentrates
on its local region of interest, thereby preserving its intrinsic structural
and semantic information. Only employing the vanilla ResNet and Transformer, we
have accomplished state-of-the-art performance on CIFAR-10 and CIFAR-100, and
have achieved competitive results on ImageNet.
</p>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10735" title="Abstract">arXiv:2308.10735</a> [<a href="/pdf/2308.10735" title="Download PDF">pdf</a>, <a href="/format/2308.10735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Different Types of Isomorphisms of Drawings of Complete Multipartite  Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aichholzer%2C+O">Oswin Aichholzer</a>, 
<a href="/search/cs?searchtype=author&query=Vogtenhuber%2C+B">Birgit Vogtenhuber</a>, 
<a href="/search/cs?searchtype=author&query=Weinberger%2C+A">Alexandra Weinberger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the Proceedings of the 31st International Symposium on Graph Drawing and Network Visualization (GD 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">Simple drawings are drawings of graphs in which any two edges intersect at
most once (either at a common endpoint or a proper crossing), and no edge
intersects itself. We analyze several characteristics of simple drawings of
complete multipartite graphs: which pairs of edges cross, in which order they
cross, and the cyclic order around vertices and crossings, respectively. We
consider all possible combinations of how two drawings can share some
characteristics and determine which other characteristics they imply and which
they do not imply. Our main results are that for simple drawings of complete
multipartite graphs, the orders in which edges cross determine all other
considered characteristics. Further, if all partition classes have at least
three vertices, then the pairs of edges that cross determine the rotation
system and the rotation around the crossings determine the extended rotation
system. We also show that most other implications -- including the ones that
hold for complete graphs -- do not hold for complete multipartite graphs. Using
this analysis, we establish which types of isomorphisms are meaningful for
simple drawings of complete multipartite graphs.
</p>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10737" title="Abstract">arXiv:2308.10737</a> [<a href="/pdf/2308.10737" title="Download PDF">pdf</a>, <a href="/format/2308.10737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UGSL: A Unified Framework for Benchmarking Graph Structure Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fatemi%2C+B">Bahare Fatemi</a>, 
<a href="/search/cs?searchtype=author&query=Abu-El-Haija%2C+S">Sami Abu-El-Haija</a>, 
<a href="/search/cs?searchtype=author&query=Tsitsulin%2C+A">Anton Tsitsulin</a>, 
<a href="/search/cs?searchtype=author&query=Kazemi%2C+M">Mehran Kazemi</a>, 
<a href="/search/cs?searchtype=author&query=Zelle%2C+D">Dustin Zelle</a>, 
<a href="/search/cs?searchtype=author&query=Bulut%2C+N">Neslihan Bulut</a>, 
<a href="/search/cs?searchtype=author&query=Halcrow%2C+J">Jonathan Halcrow</a>, 
<a href="/search/cs?searchtype=author&query=Perozzi%2C+B">Bryan Perozzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph neural networks (GNNs) demonstrate outstanding performance in a broad
range of applications. While the majority of GNN applications assume that a
graph structure is given, some recent methods substantially expanded the
applicability of GNNs by showing that they may be effective even when no graph
structure is explicitly provided. The GNN parameters and a graph structure are
jointly learned. Previous studies adopt different experimentation setups,
making it difficult to compare their merits. In this paper, we propose a
benchmarking strategy for graph structure learning using a unified framework.
Our framework, called Unified Graph Structure Learning (UGSL), reformulates
existing models into a single model. We implement a wide range of existing
models in our framework and conduct extensive analyses of the effectiveness of
different components in the framework. Our results provide a clear and concise
understanding of the different methods in this area as well as their strengths
and weaknesses. The benchmark code is available at
https://github.com/google-research/google-research/tree/master/ugsl.
</p>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10740" title="Abstract">arXiv:2308.10740</a> [<a href="/pdf/2308.10740" title="Download PDF">pdf</a>, <a href="/format/2308.10740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> We Don&#x27;t Need No Adam, All We Need Is EVE: On The Variance of Dual  Learning Rate And Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khadangi%2C+A">Afshin Khadangi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the rapidly advancing field of deep learning, optimising deep neural
networks is paramount. This paper introduces a novel method, Enhanced Velocity
Estimation (EVE), which innovatively applies different learning rates to
distinct components of the gradients. By bifurcating the learning rate, EVE
enables more nuanced control and faster convergence, addressing the challenges
associated with traditional single learning rate approaches. Utilising a
momentum term that adapts to the learning landscape, the method achieves a more
efficient navigation of the complex loss surface, resulting in enhanced
performance and stability. Extensive experiments demonstrate that EVE
significantly outperforms existing optimisation techniques across various
benchmark datasets and architectures.
</p>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10741" title="Abstract">arXiv:2308.10741</a> [<a href="/pdf/2308.10741" title="Download PDF">pdf</a>, <a href="/format/2308.10741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Adversarial Robustness of Multi-Modal Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schlarmann%2C+C">Christian Schlarmann</a>, 
<a href="/search/cs?searchtype=author&query=Hein%2C+M">Matthias Hein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV AROW 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Multi-modal foundation models combining vision and language models such as
Flamingo or GPT-4 have recently gained enormous interest. Alignment of
foundation models is used to prevent models from providing toxic or harmful
output. While malicious users have successfully tried to jailbreak foundation
models, an equally important question is if honest users could be harmed by
malicious third-party content. In this paper we show that imperceivable attacks
on images in order to change the caption output of a multi-modal foundation
model can be used by malicious content providers to harm honest users e.g. by
guiding them to malicious websites or broadcast fake information. This
indicates that countermeasures to adversarial attacks should be used by any
deployed multi-modal foundation model.
</p>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10743" title="Abstract">arXiv:2308.10743</a> [<a href="/pdf/2308.10743" title="Download PDF">pdf</a>, <a href="/format/2308.10743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Adversarial Attack with Similar Target
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziruo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zikai Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huanran Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Deep neural networks are vulnerable to adversarial examples, posing a threat
to the models' applications and raising security concerns. An intriguing
property of adversarial examples is their strong transferability. Several
methods have been proposed to enhance transferability, including ensemble
attacks which have demonstrated their efficacy. However, prior approaches
simply average logits, probabilities, or losses for model ensembling, lacking a
comprehensive analysis of how and why model ensembling significantly improves
transferability. In this paper, we propose a similar targeted attack method
named Similar Target~(ST). By promoting cosine similarity between the gradients
of each model, our method regularizes the optimization direction to
simultaneously attack all surrogate models. This strategy has been proven to
enhance generalization ability. Experimental results on ImageNet validate the
effectiveness of our approach in improving adversarial transferability. Our
method outperforms state-of-the-art attackers on 18 discriminative classifiers
and adversarially trained models.
</p>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10748" title="Abstract">arXiv:2308.10748</a> [<a href="/pdf/2308.10748" title="Download PDF">pdf</a>, <a href="/format/2308.10748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterative solution to the biharmonic equation in mixed form discretized  by the Hybrid High-Order method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Antonietti%2C+P+F">Paola F. Antonietti</a>, 
<a href="/search/math?searchtype=author&query=Matalon%2C+P">Pierre Matalon</a>, 
<a href="/search/math?searchtype=author&query=Verani%2C+M">Marco Verani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider the solution to the biharmonic equation in mixed form discretized
by the Hybrid High-Order (HHO) methods. The two resulting second-order elliptic
problems can be decoupled via the introduction of a new unknown, corresponding
to the boundary value of the solution of the first Laplacian problem. This
technique yields a global linear problem that can be solved iteratively via a
Krylov-type method. More precisely, at each iteration of the scheme, two
second-order elliptic problems have to be solved, and a normal derivative on
the boundary has to be computed. In this work, we specialize this scheme for
the HHO discretization. To this aim, an explicit technique to compute the
discrete normal derivative of an HHO solution of a Laplacian problem is
proposed. Moreover, we show that the resulting discrete scheme is well-posed.
Finally, a new preconditioner is designed to speed up the convergence of the
Krylov method. Numerical experiments assessing the performance of the proposed
iterative algorithm on both two- and three-dimensional test cases are
presented.
</p>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10755" title="Abstract">arXiv:2308.10755</a> [<a href="/pdf/2308.10755" title="Download PDF">pdf</a>, <a href="/format/2308.10755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WanJuan: A Comprehensive Multimodal Dataset for Advancing English and  Chinese Large Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+C">Conghui He</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhenjiang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jiantao Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">JiaQi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The rise in popularity of ChatGPT and GPT-4 has significantly accelerated the
development of large models, leading to the creation of numerous impressive
large language models(LLMs) and multimodal large language models (MLLMs). These
cutting-edge models owe their remarkable performance to high-quality data.
However, the details of the training data used in leading paradigms are often
kept confidential. This lack of transparency, coupled with the scarcity of
open-source data, impedes further developments within the community. As a
response, this paper presents "Wan Juan", a large-scale multimodal dataset
composed of both Chinese and English data, collected from a wide range of web
sources. The dataset incorporates text, image-text, and video modalities, with
a total volume exceeding 2TB. It was utilized in the training of InternLM, a
model that demonstrated significant advantages in multi-dimensional evaluations
when compared to models of a similar scale. All data can be accessed at
https://opendatalab.org.cn/WanJuan1.0.
</p>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10757" title="Abstract">arXiv:2308.10757</a> [<a href="/pdf/2308.10757" title="Download PDF">pdf</a>, <a href="/format/2308.10757" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To Whom are You Talking? A Deep Learning Model to Endow Social Robots  with Addressee Estimation Skills
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mazzola%2C+C">Carlo Mazzola</a>, 
<a href="/search/cs?searchtype=author&query=Romeo%2C+M">Marta Romeo</a>, 
<a href="/search/cs?searchtype=author&query=Rea%2C+F">Francesco Rea</a>, 
<a href="/search/cs?searchtype=author&query=Sciutti%2C+A">Alessandra Sciutti</a>, 
<a href="/search/cs?searchtype=author&query=Cangelosi%2C+A">Angelo Cangelosi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted version of a paper published at 2023 International Joint Conference on Neural Networks (IJCNN). Please find the published version and info to cite the paper at <a href="https://doi.org/10.1109/IJCNN54540.2023.10191452">this https URL</a> . 10 pages, 8 Figures, 3 Tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 International Joint Conference on Neural Networks (IJCNN),
  pp. 1-10
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Communicating shapes our social word. For a robot to be considered social and
being consequently integrated in our social environment it is fundamental to
understand some of the dynamics that rule human-human communication. In this
work, we tackle the problem of Addressee Estimation, the ability to understand
an utterance's addressee, by interpreting and exploiting non-verbal bodily cues
from the speaker. We do so by implementing an hybrid deep learning model
composed of convolutional layers and LSTM cells taking as input images
portraying the face of the speaker and 2D vectors of the speaker's body
posture. Our implementation choices were guided by the aim to develop a model
that could be deployed on social robots and be efficient in ecological
scenarios. We demonstrate that our model is able to solve the Addressee
Estimation problem in terms of addressee localisation in space, from a robot
ego-centric point of view.
</p>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10758" title="Abstract">arXiv:2308.10758</a> [<a href="/pdf/2308.10758" title="Download PDF">pdf</a>, <a href="/ps/2308.10758" title="Download PostScript">ps</a>, <a href="/format/2308.10758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DepreSym: A Depression Symptom Annotated Corpus and the Role of LLMs as  Assessors of Psychological Markers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+A">Anxo P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Pichel%2C+M">Marcos Fern&#xe1;ndez-Pichel</a>, 
<a href="/search/cs?searchtype=author&query=Parapar%2C+J">Javier Parapar</a>, 
<a href="/search/cs?searchtype=author&query=Losada%2C+D+E">David E. Losada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Computational methods for depression detection aim to mine traces of
depression from online publications posted by Internet users. However,
solutions trained on existing collections exhibit limited generalisation and
interpretability. To tackle these issues, recent studies have shown that
identifying depressive symptoms can lead to more robust models. The eRisk
initiative fosters research on this area and has recently proposed a new
ranking task focused on developing search methods to find sentences related to
depressive symptoms. This search challenge relies on the symptoms specified by
the Beck Depression Inventory-II (BDI-II), a questionnaire widely used in
clinical practice. Based on the participant systems' results, we present the
DepreSym dataset, consisting of 21580 sentences annotated according to their
relevance to the 21 BDI-II symptoms. The labelled sentences come from a pool of
diverse ranking methods, and the final dataset serves as a valuable resource
for advancing the development of models that incorporate depressive markers
such as clinical symptoms. Due to the complex nature of this relevance
annotation, we designed a robust assessment methodology carried out by three
expert assessors (including an expert psychologist). Additionally, we explore
here the feasibility of employing recent Large Language Models (ChatGPT and
GPT4) as potential assessors in this complex task. We undertake a comprehensive
examination of their performance, determine their main limitations and analyze
their role as a complement or replacement for human annotators.
</p>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10759" title="Abstract">arXiv:2308.10759</a> [<a href="/pdf/2308.10759" title="Download PDF">pdf</a>, <a href="/format/2308.10759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EALink: An Efficient and Accurate Pre-trained Framework for Issue-Commit  Link Recovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanlin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhao Wei</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Juhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hui Li</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+R">Rongrong Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures, published to ASE
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE/ACM International Conference on Automated Software
  Engineering,2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Issue-commit links, as a type of software traceability links, play a vital
role in various software development and maintenance tasks. However, they are
typically deficient, as developers often forget or fail to create tags when
making commits. Existing studies have deployed deep learning techniques,
including pretrained models, to improve automatic issue-commit link
recovery.Despite their promising performance, we argue that previous approaches
have four main problems, hindering them from recovering links in large software
projects. To overcome these problems, we propose an efficient and accurate
pre-trained framework called EALink for issue-commit link recovery. EALink
requires much fewer model parameters than existing pre-trained methods,
bringing efficient training and recovery. Moreover, we design various
techniques to improve the recovery accuracy of EALink. We construct a
large-scale dataset and conduct extensive experiments to demonstrate the power
of EALink. Results show that EALink outperforms the state-of-the-art methods by
a large margin (15.23%-408.65%) on various evaluation metrics. Meanwhile, its
training and inference overhead is orders of magnitude lower than existing
methods.
</p>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10761" title="Abstract">arXiv:2308.10761</a> [<a href="/pdf/2308.10761" title="Download PDF">pdf</a>, <a href="/format/2308.10761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoNe: Contrast Your Neighbours for Supervised Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+M">Mingkai Zheng</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+S">Shan You</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+X">Xiu Su</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chen Qian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaogang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image classification is a longstanding problem in computer vision and machine
learning research. Most recent works (e.g. SupCon , Triplet, and max-margin)
mainly focus on grouping the intra-class samples aggressively and compactly,
with the assumption that all intra-class samples should be pulled tightly
towards their class centers. However, such an objective will be very hard to
achieve since it ignores the intra-class variance in the dataset. (i.e.
different instances from the same class can have significant differences).
Thus, such a monotonous objective is not sufficient. To provide a more
informative objective, we introduce Contrast Your Neighbours (CoNe) - a simple
yet practical learning framework for supervised image classification.
Specifically, in CoNe, each sample is not only supervised by its class center
but also directly employs the features of its similar neighbors as anchors to
generate more adaptive and refined targets. Moreover, to further boost the
performance, we propose ``distributional consistency" as a more informative
regularization to enable similar instances to have a similar probability
distribution. Extensive experimental results demonstrate that CoNe achieves
state-of-the-art performance across different benchmark datasets, network
architectures, and settings. Notably, even without a complicated training
recipe, our CoNe achieves 80.8\% Top-1 accuracy on ImageNet with ResNet-50,
which surpasses the recent Timm training recipe (80.4\%). Code and pre-trained
models are available at
\href{https://github.com/mingkai-zheng/CoNe}{https://github.com/mingkai-zheng/CoNe}.
</p>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10767" title="Abstract">arXiv:2308.10767</a> [<a href="/pdf/2308.10767" title="Download PDF">pdf</a>, <a href="/format/2308.10767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GBM-based Bregman Proximal Algorithms for Constrained Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhenwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Q">Qi Deng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">As the complexity of learning tasks surges, modern machine learning
encounters a new constrained learning paradigm characterized by more intricate
and data-driven function constraints. Prominent applications include
Neyman-Pearson classification (NPC) and fairness classification, which entail
specific risk constraints that render standard projection-based training
algorithms unsuitable. Gradient boosting machines (GBMs) are among the most
popular algorithms for supervised learning; however, they are generally limited
to unconstrained settings. In this paper, we adapt the GBM for constrained
learning tasks within the framework of Bregman proximal algorithms. We
introduce a new Bregman primal-dual method with a global optimality guarantee
when the learning objective and constraint functions are convex. In cases of
nonconvex functions, we demonstrate how our algorithm remains effective under a
Bregman proximal point framework. Distinct from existing constrained learning
algorithms, ours possess a unique advantage in their ability to seamlessly
integrate with publicly available GBM implementations such as XGBoost (Chen and
Guestrin, 2016) and LightGBM (Ke et al., 2017), exclusively relying on their
public interfaces. We provide substantial experimental evidence to showcase the
effectiveness of the Bregman algorithm framework. While our primary focus is on
NPC and fairness ML, our framework holds significant potential for a broader
range of constrained learning applications. The source code is currently freely
available at
https://github.com/zhenweilin/ConstrainedGBM}{https://github.com/zhenweilin/ConstrainedGBM.
</p>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10770" title="Abstract">arXiv:2308.10770</a> [<a href="/pdf/2308.10770" title="Download PDF">pdf</a>, <a href="/format/2308.10770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Extending Concentric Tube Robot Kinematics for Large Clearance  and Impulse Curvature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhouyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jia Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ha%2C+J">Junhyoung Ha</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yue Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Concentric Tube Robots (CTRs) have been proposed to operate within the
unstructured environment for minimally invasive surgeries. In this letter, we
consider the operation scenario where the tubes travel inside the channels with
a large clearance or large curvature, such as aortas or industrial pipes.
Accurate kinematic modeling of CTRs is required for the development of advanced
control and sensing algorithms. To this end, we extended the conventional CTR
kinematics model to a more general case with large tube-to-tube clearance and
large centerline curvature. Numerical simulations and experimental validations
are conducted to compare our model with respect to the conventional CTR
kinematic model. In the physical experiments, our proposed model achieved a tip
position error of 1.53 mm in the 2D planer case and 4.36 mm in 3D case,
outperforming the state-of-the-art model by 71% and 66%, respectively.
</p>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10776" title="Abstract">arXiv:2308.10776</a> [<a href="/pdf/2308.10776" title="Download PDF">pdf</a>, <a href="/format/2308.10776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Modular and Adaptive System for Business Email Compromise Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brabec%2C+J">Jan Brabec</a>, 
<a href="/search/cs?searchtype=author&query=%C5%A0rajer%2C+F">Filip &#x160;rajer</a>, 
<a href="/search/cs?searchtype=author&query=Starosta%2C+R">Radek Starosta</a>, 
<a href="/search/cs?searchtype=author&query=Sixta%2C+T">Tom&#xe1;&#x161; Sixta</a>, 
<a href="/search/cs?searchtype=author&query=Dupont%2C+M">Marc Dupont</a>, 
<a href="/search/cs?searchtype=author&query=Lenoch%2C+M">Milo&#x161; Lenoch</a>, 
<a href="/search/cs?searchtype=author&query=Men%C5%A1%C3%ADk%2C+J">Ji&#x159;&#xed; Men&#x161;&#xed;k</a>, 
<a href="/search/cs?searchtype=author&query=Becker%2C+F">Florian Becker</a>, 
<a href="/search/cs?searchtype=author&query=Boros%2C+J">Jakub Boros</a>, 
<a href="/search/cs?searchtype=author&query=Pop%2C+T">Tom&#xe1;&#x161; Pop</a>, 
<a href="/search/cs?searchtype=author&query=Nov%C3%A1k%2C+P">Pavel Nov&#xe1;k</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The growing sophistication of Business Email Compromise (BEC) and spear
phishing attacks poses significant challenges to organizations worldwide. The
techniques featured in traditional spam and phishing detection are insufficient
due to the tailored nature of modern BEC attacks as they often blend in with
the regular benign traffic. Recent advances in machine learning, particularly
in Natural Language Understanding (NLU), offer a promising avenue for combating
such attacks but in a practical system, due to limitations such as data
availability, operational costs, verdict explainability requirements or a need
to robustly evolve the system, it is essential to combine multiple approaches
together. We present CAPE, a comprehensive and efficient system for BEC
detection that has been proven in a production environment for a period of over
two years. Rather than being a single model, CAPE is a system that combines
independent ML models and algorithms detecting BEC-related behaviors across
various email modalities such as text, images, metadata and the email's
communication context. This decomposition makes CAPE's verdicts naturally
explainable. In the paper, we describe the design principles and constraints
behind its architecture, as well as the challenges of model design, evaluation
and adapting the system continuously through a Bayesian approach that combines
limited data with domain knowledge. Furthermore, we elaborate on several
specific behavioral detectors, such as those based on Transformer neural
architectures.
</p>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10777" title="Abstract">arXiv:2308.10777</a> [<a href="/pdf/2308.10777" title="Download PDF">pdf</a>, <a href="/format/2308.10777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> I-BaR: Integrated Balance Rehabilitation Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ersoy%2C+T">Tugce Ersoy</a>, 
<a href="/search/eess?searchtype=author&query=Kaya%2C+P">P&#x131;nar Kaya</a>, 
<a href="/search/eess?searchtype=author&query=Hocaoglu%2C+E">Elif Hocaoglu</a>, 
<a href="/search/eess?searchtype=author&query=Unal%2C+R">Ramazan Unal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 2 figures, journal paper
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> BMC Sports Science, Medicine and Rehabilitation, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Neurological diseases are observed in approximately one billion people
worldwide. A further increase is foreseen at the global level as a result of
population growth and aging. Individuals with neurological disorders often
experience cognitive, motor, sensory, and lower extremity dysfunctions. Thus,
the possibility of falling and balance problems arise due to the postural
control deficiencies that occur as a result of the deterioration in the
integration of multi-sensory information. We propose a novel rehabilitation
framework, Integrated Balance Rehabilitation (I-BaR), to improve the
effectiveness of the rehabilitation with objective assessment, individualized
therapy, convenience with different disability levels and adoption of an
assist-as-needed paradigm and, with an integrated rehabilitation process as a
whole, i.e., ankle-foot preparation, balance, and stepping phases,
respectively. Integrated Balance Rehabilitation allows patients to improve
their balance ability by providing multi-modal feedback: visual via utilization
of Virtual Reality; vestibular via anteroposterior and mediolateral
perturbations with the robotic platform; proprioceptive via haptic feedback.
</p>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10778" title="Abstract">arXiv:2308.10778</a> [<a href="/pdf/2308.10778" title="Download PDF">pdf</a>, <a href="/format/2308.10778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Topology-aware Analysis of Graph Collaborative Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malitesta%2C+D">Daniele Malitesta</a>, 
<a href="/search/cs?searchtype=author&query=Pomo%2C+C">Claudio Pomo</a>, 
<a href="/search/cs?searchtype=author&query=Anelli%2C+V+W">Vito Walter Anelli</a>, 
<a href="/search/cs?searchtype=author&query=Mancino%2C+A+C+M">Alberto Carlo Maria Mancino</a>, 
<a href="/search/cs?searchtype=author&query=Di+Sciascio%2C+E">Eugenio Di Sciascio</a>, 
<a href="/search/cs?searchtype=author&query=Di+Noia%2C+T">Tommaso Di Noia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">The successful integration of graph neural networks into recommender systems
(RSs) has led to a novel paradigm in collaborative filtering (CF), graph
collaborative filtering (graph CF). By representing user-item data as an
undirected, bipartite graph, graph CF utilizes short- and long-range
connections to extract collaborative signals that yield more accurate user
preferences than traditional CF methods. Although the recent literature
highlights the efficacy of various algorithmic strategies in graph CF, the
impact of datasets and their topological features on recommendation performance
is yet to be studied. To fill this gap, we propose a topology-aware analysis of
graph CF. In this study, we (i) take some widely-adopted recommendation
datasets and use them to generate a large set of synthetic sub-datasets through
two state-of-the-art graph sampling methods, (ii) measure eleven of their
classical and topological characteristics, and (iii) estimate the accuracy
calculated on the generated sub-datasets considering four popular and recent
graph-based RSs (i.e., LightGCN, DGCF, UltraGCN, and SVD-GCN). Finally, the
investigation presents an explanatory framework that reveals the linear
relationships between characteristics and accuracy measures. The results,
statistically validated under different graph sampling settings, confirm the
existence of solid dependencies between topological characteristics and
accuracy in the graph-based recommendation, offering a new perspective on how
to interpret graph CF.
</p>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10779" title="Abstract">arXiv:2308.10779</a> [<a href="/pdf/2308.10779" title="Download PDF">pdf</a>, <a href="/format/2308.10779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spear and Shield: Adversarial Attacks and Defense Methods for  Model-Based Link Prediction on Continuous-Time Dynamic Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongjin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Juho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+K">Kijung Shin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Real-world graphs are dynamic, constantly evolving with new interactions,
such as financial transactions in financial networks. Temporal Graph Neural
Networks (TGNNs) have been developed to effectively capture the evolving
patterns in dynamic graphs. While these models have demonstrated their
superiority, being widely adopted in various important fields, their
vulnerabilities against adversarial attacks remain largely unexplored. In this
paper, we propose T-SPEAR, a simple and effective adversarial attack method for
link prediction on continuous-time dynamic graphs, focusing on investigating
the vulnerabilities of TGNNs. Specifically, before the training procedure of a
victim model, which is a TGNN for link prediction, we inject edge perturbations
to the data that are unnoticeable in terms of the four constraints we propose,
and yet effective enough to cause malfunction of the victim model. Moreover, we
propose a robust training approach T-SHIELD to mitigate the impact of
adversarial attacks. By using edge filtering and enforcing temporal smoothness
to node embeddings, we enhance the robustness of the victim model. Our
experimental study shows that T-SPEAR significantly degrades the victim model's
performance on link prediction tasks, and even more, our attacks are
transferable to other TGNNs, which differ from the victim model assumed by the
attacker. Moreover, we demonstrate that T-SHIELD effectively filters out
adversarial edges and exhibits robustness against adversarial attacks,
surpassing the link prediction performance of the naive TGNN by up to 11.2%
under T-SPEAR.
</p>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10781" title="Abstract">arXiv:2308.10781</a> [<a href="/pdf/2308.10781" title="Download PDF">pdf</a>, <a href="/format/2308.10781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed-Integer Projections for Automated Data Correction of EMRs Improve  Predictions of Sepsis among Hospitalized Patients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arora%2C+M">Mehak Arora</a>, 
<a href="/search/cs?searchtype=author&query=Mortagy%2C+H">Hassan Mortagy</a>, 
<a href="/search/cs?searchtype=author&query=Dwarshius%2C+N">Nathan Dwarshius</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Swati Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Holder%2C+A+L">Andre L. Holder</a>, 
<a href="/search/cs?searchtype=author&query=Kamaleswaran%2C+R">Rishikesan Kamaleswaran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Machine learning (ML) models are increasingly pivotal in automating clinical
decisions. Yet, a glaring oversight in prior research has been the lack of
proper processing of Electronic Medical Record (EMR) data in the clinical
context for errors and outliers. Addressing this oversight, we introduce an
innovative projections-based method that seamlessly integrates clinical
expertise as domain constraints, generating important meta-data that can be
used in ML workflows. In particular, by using high-dimensional mixed-integer
programs that capture physiological and biological constraints on patient
vitals and lab values, we can harness the power of mathematical "projections"
for the EMR data to correct patient data. Consequently, we measure the distance
of corrected data from the constraints defining a healthy range of patient
data, resulting in a unique predictive metric we term as "trust-scores". These
scores provide insight into the patient's health status and significantly boost
the performance of ML classifiers in real-life clinical settings. We validate
the impact of our framework in the context of early detection of sepsis using
ML. We show an AUROC of 0.865 and a precision of 0.922, that surpasses
conventional ML models without such projections.
</p>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10782" title="Abstract">arXiv:2308.10782</a> [<a href="/pdf/2308.10782" title="Download PDF">pdf</a>, <a href="/format/2308.10782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Linear Concept Discovery Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Panousis%2C+K+P">Konstantinos P. Panousis</a>, 
<a href="/search/cs?searchtype=author&query=Ienco%2C+D">Dino Ienco</a>, 
<a href="/search/cs?searchtype=author&query=Marcos%2C+D">Diego Marcos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted @ ICCVW CLVL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">The recent mass adoption of DNNs, even in safety-critical scenarios, has
shifted the focus of the research community towards the creation of inherently
intrepretable models. Concept Bottleneck Models (CBMs) constitute a popular
approach where hidden layers are tied to human understandable concepts allowing
for investigation and correction of the network's decisions. However, CBMs
usually suffer from: (i) performance degradation and (ii) lower
interpretability than intended due to the sheer amount of concepts contributing
to each decision. In this work, we propose a simple yet highly intuitive
interpretable framework based on Contrastive Language Image models and a single
sparse linear layer. In stark contrast to related approaches, the sparsity in
our framework is achieved via principled Bayesian arguments by inferring
concept presence via a data-driven Bernoulli distribution. As we experimentally
show, our framework not only outperforms recent CBM approaches accuracy-wise,
but it also yields high per example concept sparsity, facilitating the
individual investigation of the emerging concepts.
</p>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10783" title="Abstract">arXiv:2308.10783</a> [<a href="/pdf/2308.10783" title="Download PDF">pdf</a>, <a href="/format/2308.10783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero- and Few-Shot Prompting with LLMs: A Comparative Study with  Fine-tuned Models for Bangla Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hasan%2C+M+A">Md. Arid Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Shudipta Das</a>, 
<a href="/search/cs?searchtype=author&query=Anjum%2C+A">Afiyat Anjum</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+F">Firoj Alam</a>, 
<a href="/search/cs?searchtype=author&query=Anjum%2C+A">Anika Anjum</a>, 
<a href="/search/cs?searchtype=author&query=Sarker%2C+A">Avijit Sarker</a>, 
<a href="/search/cs?searchtype=author&query=Noori%2C+S+R+H">Sheak Rashed Haider Noori</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Zero-Shot Prompting, Few-Shot Prompting, LLMs, Comparative Study, Fine-tuned Models, Bangla, Sentiment Analysis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The rapid expansion of the digital world has propelled sentiment analysis
into a critical tool across diverse sectors such as marketing, politics,
customer service, and healthcare. While there have been significant
advancements in sentiment analysis for widely spoken languages, low-resource
languages, such as Bangla, remain largely under-researched due to resource
constraints. Furthermore, the recent unprecedented performance of Large
Language Models (LLMs) in various applications highlights the need to evaluate
them in the context of low-resource languages. In this study, we present a
sizeable manually annotated dataset encompassing 33,605 Bangla news tweets and
Facebook comments. We also investigate zero- and few-shot in-context learning
with several language models, including Flan-T5, GPT-4, and Bloomz, offering a
comparative analysis against fine-tuned models. Our findings suggest that
monolingual transformer-based models consistently outperform other models, even
in zero and few-shot scenarios. To foster continued exploration, we intend to
make this dataset and our research tools publicly available to the broader
research community. In the spirit of further research, we plan to make this
dataset and our experimental resources publicly accessible to the wider
research community.
</p>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10788" title="Abstract">arXiv:2308.10788</a> [<a href="/pdf/2308.10788" title="Download PDF">pdf</a>, <a href="/format/2308.10788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effectiveness of Reconfigurable Intelligent Surfaces to Enhance  Connectivity in UAV Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Al-Abiad%2C+M+S">Mohammed S. Al-Abiad</a>, 
<a href="/search/cs?searchtype=author&query=Javad-Kalbasi%2C+M">Mohammad Javad-Kalbasi</a>, 
<a href="/search/cs?searchtype=author&query=Valaee%2C+S">Shahrokh Valaee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures, journal paper. arXiv admin note: text overlap with <a href="/abs/2308.04675">arXiv:2308.04675</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Reconfigurable intelligent surfaces (RISs) are expected to make future 6G
networks more connected and resilient against node failures, due to their
ability to introduce controllable phase-shifts onto impinging electromagnetic
waves and impose link redundancy. Meanwhile, unmanned aerial vehicles (UAVs)
are prone to failure due to limited energy, random failures, or targeted
failures, which causes network disintegration that results in information
delivery loss. In this paper, we show that the integration between UAVs and
RISs for improving network connectivity is crucial. We utilize RISs to provide
path diversity and alternative connectivity options for information flow from
user equipments (UEs) to less critical UAVs by adding more links to the
network, thereby making the network more resilient and connected. To that end,
we first define the criticality of UAV nodes, which reflects the importance of
some nodes over other nodes. We then employ the algebraic connectivity metric,
which is adjusted by the reflected links of the RISs and their criticality
weights, to formulate the problem of maximizing the network connectivity. Such
problem is a computationally expensive combinatorial optimization. To tackle
this problem, we propose a relaxation method such that the discrete scheduling
constraint of the problem is relaxed and becomes continuous. Leveraging this,
we propose two efficient solutions, namely semi-definite programming (SDP)
optimization and perturbation heuristic, which both solve the problem in
polynomial time. For the perturbation heuristic, we derive the lower and upper
bounds of the algebraic connectivity obtained by adding new links to the
network. Finally, we corroborate the effectiveness of the proposed solutions
through extensive simulation experiments.
</p>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10792" title="Abstract">arXiv:2308.10792</a> [<a href="/pdf/2308.10792" title="Download PDF">pdf</a>, <a href="/format/2308.10792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instruction Tuning for Large Language Models: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shengyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+L">Linfeng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoya Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaofei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Runyi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoyin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A Survey paper, Pre-print
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper surveys research works in the quickly advancing field of
instruction tuning (IT), a crucial technique to enhance the capabilities and
controllability of large language models (LLMs). Instruction tuning refers to
the process of further training LLMs on a dataset consisting of
\textsc{(instruction, output)} pairs in a supervised fashion, which bridges the
gap between the next-word prediction objective of LLMs and the users' objective
of having LLMs adhere to human instructions. In this work, we make a systematic
review of the literature, including the general methodology of IT, the
construction of IT datasets, the training of IT models, and applications to
different modalities, domains and applications, along with an analysis on
aspects that influence the outcome of IT (e.g., generation of instruction
outputs, size of the instruction dataset, etc). We also review the potential
pitfalls of IT along with criticism against it, along with efforts pointing out
current deficiencies of existing strategies and suggest some avenues for
fruitful research.
</p>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10793" title="Abstract">arXiv:2308.10793</a> [<a href="/pdf/2308.10793" title="Download PDF">pdf</a>, <a href="/ps/2308.10793" title="Download PostScript">ps</a>, <a href="/format/2308.10793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simple Cycle Reservoirs are Universal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Fong%2C+R+S">Robert Simon Fong</a>, 
<a href="/search/cs?searchtype=author&query=Ti%C5%88o%2C+P">Peter Ti&#x148;o</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Reservoir computation models form a subclass of recurrent neural networks
with fixed non-trainable input and dynamic coupling weights. Only the static
readout from the state space (reservoir) is trainable, thus avoiding the known
problems with propagation of gradient information backwards through time.
Reservoir models have been successfully applied in a variety of tasks and were
shown to be universal approximators of time-invariant fading memory dynamic
filters under various settings. Simple cycle reservoirs (SCR) have been
suggested as severely restricted reservoir architecture, with equal weight ring
connectivity of the reservoir units and input-to-reservoir weights of binary
nature with the same absolute value. Such architectures are well suited for
hardware implementations without performance degradation in many practical
tasks. In this contribution, we rigorously study the expressive power of SCR in
the complex domain and show that they are capable of universal approximation of
any unrestricted linear reservoir system (with continuous readout) and hence
any time-invariant fading memory filter over uniformly bounded input streams.
</p>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10794" title="Abstract">arXiv:2308.10794</a> [<a href="/pdf/2308.10794" title="Download PDF">pdf</a>, <a href="/format/2308.10794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MGMAE: Motion Guided Masking for Video Masked Autoencoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Bingkun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhiyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guozhen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Limin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Masked autoencoding has shown excellent performance on self-supervised video
representation learning. Temporal redundancy has led to a high masking ratio
and customized masking strategy in VideoMAE. In this paper, we aim to further
improve the performance of video masked autoencoding by introducing a motion
guided masking strategy. Our key insight is that motion is a general and unique
prior in video, which should be taken into account during masked pre-training.
Our motion guided masking explicitly incorporates motion information to build
temporal consistent masking volume. Based on this masking volume, we can track
the unmasked tokens in time and sample a set of temporal consistent cubes from
videos. These temporal aligned unmasked tokens will further relieve the
information leakage issue in time and encourage the MGMAE to learn more useful
structure information. We implement our MGMAE with an online efficient optical
flow estimator and backward masking map warping strategy. We perform
experiments on the datasets of Something-Something V2 and Kinetics-400,
demonstrating the superior performance of our MGMAE to the original VideoMAE.
In addition, we provide the visualization analysis to illustrate that our MGMAE
can sample temporal consistent cubes in a motion-adaptive manner for more
effective video pre-training.
</p>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10795" title="Abstract">arXiv:2308.10795</a> [<a href="/pdf/2308.10795" title="Download PDF">pdf</a>, <a href="/format/2308.10795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visualizing Historical Book Trade Data: An Iterative Design Study with  Close Collaboration with Domain Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+Y">Yiwen Xing</a>, 
<a href="/search/cs?searchtype=author&query=Dondi%2C+C">Cristina Dondi</a>, 
<a href="/search/cs?searchtype=author&query=Borgo%2C+R">Rita Borgo</a>, 
<a href="/search/cs?searchtype=author&query=Abdul-Rahman%2C+A">Alfie Abdul-Rahman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The circulation of historical books has always been an area of interest for
historians. However, the data used to represent the journey of a book across
different places and times can be difficult for domain experts to digest due to
buried geographical and chronological features within text-based presentations.
This situation provides an opportunity for collaboration between visualization
researchers and historians. This paper describes a design study where a variant
of the Nine-Stage Framework was employed to develop a Visual Analytics (VA)
tool called DanteExploreVis. This tool was designed to aid domain experts in
exploring, explaining, and presenting book trade data from multiple
perspectives. We discuss the design choices made and how each panel in the
interface meets the domain requirements. We also present the results of a
qualitative evaluation conducted with domain experts. The main contributions of
this paper include: 1) the development of a VA tool to support domain experts
in exploring, explaining, and presenting book trade data; 2) a comprehensive
documentation of the iterative design, development, and evaluation process
following the variant Nine-Stage Framework; 3) a summary of the insights gained
and lessons learned from this design study in the context of the humanities
field; and 4) reflections on how our approach could be applied in a more
generalizable way.
</p>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10797" title="Abstract">arXiv:2308.10797</a> [<a href="/pdf/2308.10797" title="Download PDF">pdf</a>, <a href="/format/2308.10797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stabilizing Unsupervised Environment Design with a Learned Adversary
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mediratta%2C+I">Ishita Mediratta</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Minqi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Parker-Holder%2C+J">Jack Parker-Holder</a>, 
<a href="/search/cs?searchtype=author&query=Dennis%2C+M">Michael Dennis</a>, 
<a href="/search/cs?searchtype=author&query=Vinitsky%2C+E">Eugene Vinitsky</a>, 
<a href="/search/cs?searchtype=author&query=Rockt%C3%A4schel%2C+T">Tim Rockt&#xe4;schel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CoLLAs 2023 - Oral; Minqi and Jack contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">A key challenge in training generally-capable agents is the design of
training tasks that facilitate broad generalization and robustness to
environment variations. This challenge motivates the problem setting of
Unsupervised Environment Design (UED), whereby a student agent trains on an
adaptive distribution of tasks proposed by a teacher agent. A pioneering
approach for UED is PAIRED, which uses reinforcement learning (RL) to train a
teacher policy to design tasks from scratch, making it possible to directly
generate tasks that are adapted to the agent's current capabilities. Despite
its strong theoretical backing, PAIRED suffers from a variety of challenges
that hinder its practical performance. Thus, state-of-the-art methods currently
rely on curation and mutation rather than generation of new tasks. In this
work, we investigate several key shortcomings of PAIRED and propose solutions
for each shortcoming. As a result, we make it possible for PAIRED to match or
exceed state-of-the-art methods, producing robust agents in several established
challenging procedurally-generated environments, including a partially-observed
maze navigation task and a continuous-control car racing environment. We
believe this work motivates a renewed emphasis on UED methods based on learned
models that directly generate challenging environments, potentially unlocking
more open-ended RL training and, as a result, more general agents.
</p>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10800" title="Abstract">arXiv:2308.10800</a> [<a href="/pdf/2308.10800" title="Download PDF">pdf</a>, <a href="/format/2308.10800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Artificial intelligence is ineffective and potentially harmful for fact  checking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=DeVerna%2C+M+R">Matthew R. DeVerna</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H+Y">Harry Yaojun Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kai-Cheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Menczer%2C+F">Filippo Menczer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Fact checking can be an effective strategy against misinformation, but its
implementation at scale is impeded by the overwhelming volume of information
online. Recent artificial intelligence (AI) language models have shown
impressive ability in fact-checking tasks, but how humans interact with
fact-checking information provided by these models is unclear. Here we
investigate the impact of fact checks generated by a popular AI model on belief
in, and sharing intent of, political news in a preregistered randomized control
experiment. Although the AI performs reasonably well in debunking false
headlines, we find that it does not significantly affect participants' ability
to discern headline accuracy or share accurate news. However, the AI
fact-checker is harmful in specific cases: it decreases beliefs in true
headlines that it mislabels as false and increases beliefs for false headlines
that it is unsure about. On the positive side, the AI increases sharing intents
for correctly labeled true headlines. When participants are given the option to
view AI fact checks and choose to do so, they are significantly more likely to
share both true and false news but only more likely to believe false news. Our
findings highlight an important source of potential harm stemming from AI
applications and underscore the critical need for policies to prevent or
mitigate such unintended consequences.
</p>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10801" title="Abstract">arXiv:2308.10801</a> [<a href="/pdf/2308.10801" title="Download PDF">pdf</a>, <a href="/format/2308.10801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LSCPM: communities in massive real-world Link Streams by Clique  Percolation Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baudin%2C+A">Alexis Baudin</a>, 
<a href="/search/cs?searchtype=author&query=Tabourier%2C+L">Lionel Tabourier</a>, 
<a href="/search/cs?searchtype=author&query=Magnien%2C+C">Cl&#xe9;mence Magnien</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 7 figures, to be published in 30th International Symposium on Temporal Representation and Reasoning (TIME 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Community detection is a popular approach to understand the organization of
interactions in static networks. For that purpose, the Clique Percolation
Method (CPM), which involves the percolation of k-cliques, is a well-studied
technique that offers several advantages. Besides, studying interactions that
occur over time is useful in various contexts, which can be modeled by the link
stream formalism. The Dynamic Clique Percolation Method (DCPM) has been
proposed for extending CPM to temporal networks.
<br />However, existing implementations are unable to handle massive datasets. We
present a novel algorithm that adapts CPM to link streams, which has the
advantage that it allows us to speed up the computation time with respect to
the existing DCPM method. We evaluate it experimentally on real datasets and
show that it scales to massive link streams. For example, it allows to obtain a
complete set of communities in under twenty-five minutes for a dataset with
thirty million links, what the state of the art fails to achieve even after a
week of computation. We further show that our method provides communities
similar to DCPM, but slightly more aggregated. We exhibit the relevance of the
obtained communities in real world cases, and show that they provide
information on the importance of vertices in the link streams.
</p>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10806" title="Abstract">arXiv:2308.10806</a> [<a href="/pdf/2308.10806" title="Download PDF">pdf</a>, <a href="/format/2308.10806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Frank-Wolfe Optimization Layer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zixuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Liu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xueqian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Peilin Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Differentiable optimization has received a significant amount of attention
due to its foundational role in the domain of machine learning based on neural
networks. The existing methods leverages the optimality conditions and implicit
function theorem to obtain the Jacobian matrix of the output, which increases
the computational cost and limits the application of differentiable
optimization. In addition, some non-differentiable constraints lead to more
challenges when using prior differentiable optimization layers. This paper
proposes a differentiable layer, named Differentiable Frank-Wolfe Layer
(DFWLayer), by rolling out the Frank-Wolfe method, a well-known optimization
algorithm which can solve constrained optimization problems without projections
and Hessian matrix computations, thus leading to a efficient way of dealing
with large-scale problems. Theoretically, we establish a bound on the
suboptimality gap of the DFWLayer in the context of l1-norm constraints.
Experimental assessments demonstrate that the DFWLayer not only attains
competitive accuracy in solutions and gradients but also consistently adheres
to constraints. Moreover, it surpasses the baselines in both forward and
backward computational speeds.
</p>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10807" title="Abstract">arXiv:2308.10807</a> [<a href="/pdf/2308.10807" title="Download PDF">pdf</a>, <a href="/ps/2308.10807" title="Download PostScript">ps</a>, <a href="/format/2308.10807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DynED: Dynamic Ensemble Diversification in Data Stream Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abadifard%2C+S">Soheil Abadifard</a>, 
<a href="/search/cs?searchtype=author&query=Bakhshi%2C+S">Sepehr Bakhshi</a>, 
<a href="/search/cs?searchtype=author&query=Gheibuni%2C+S">Sanaz Gheibuni</a>, 
<a href="/search/cs?searchtype=author&query=Can%2C+F">Fazli Can</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 32nd ACM International Conference on Information and Knowledge Management (CIKM '23), October 21--25, 2023, Birmingham, United Kingdom
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Ensemble methods are commonly used in classification due to their remarkable
performance. Achieving high accuracy in a data stream environment is a
challenging task considering disruptive changes in the data distribution, also
known as concept drift. A greater diversity of ensemble components is known to
enhance prediction accuracy in such settings. Despite the diversity of
components within an ensemble, not all contribute as expected to its overall
performance. This necessitates a method for selecting components that exhibit
high performance and diversity. We present a novel ensemble construction and
maintenance approach based on MMR (Maximal Marginal Relevance) that dynamically
combines the diversity and prediction accuracy of components during the process
of structuring an ensemble. The experimental results on both four real and 11
synthetic datasets demonstrate that the proposed approach (DynED) provides a
higher average mean accuracy compared to the five state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10808" title="Abstract">arXiv:2308.10808</a> [<a href="/pdf/2308.10808" title="Download PDF">pdf</a>, <a href="/format/2308.10808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Neural Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yunzhe Qi</a>, 
<a href="/search/cs?searchtype=author&query=Ban%2C+Y">Yikun Ban</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jingrui He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to SIGKDD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Contextual bandits algorithms aim to choose the optimal arm with the highest
reward out of a set of candidates based on the contextual information. Various
bandit algorithms have been applied to real-world applications due to their
ability of tackling the exploitation-exploration dilemma. Motivated by online
recommendation scenarios, in this paper, we propose a framework named Graph
Neural Bandits (GNB) to leverage the collaborative nature among users empowered
by graph neural networks (GNNs). Instead of estimating rigid user clusters as
in existing works, we model the "fine-grained" collaborative effects through
estimated user graphs in terms of exploitation and exploration respectively.
Then, to refine the recommendation strategy, we utilize separate GNN-based
models on estimated user graphs for exploitation and adaptive exploration.
Theoretical analysis and experimental results on multiple real data sets in
comparison with state-of-the-art baselines are provided to demonstrate the
effectiveness of our proposed framework.
</p>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10809" title="Abstract">arXiv:2308.10809</a> [<a href="/pdf/2308.10809" title="Download PDF">pdf</a>, <a href="/format/2308.10809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Continuous Sign Language Recognition with Cross-Lingual Signs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Fangyun Wei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yutong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This work dedicates to continuous sign language recognition (CSLR), which is
a weakly supervised task dealing with the recognition of continuous signs from
videos, without any prior knowledge about the temporal boundaries between
consecutive signs. Data scarcity heavily impedes the progress of CSLR. Existing
approaches typically train CSLR models on a monolingual corpus, which is orders
of magnitude smaller than that of speech recognition. In this work, we explore
the feasibility of utilizing multilingual sign language corpora to facilitate
monolingual CSLR. Our work is built upon the observation of cross-lingual
signs, which originate from different sign languages but have similar visual
signals (e.g., hand shape and motion). The underlying idea of our approach is
to identify the cross-lingual signs in one sign language and properly leverage
them as auxiliary training data to improve the recognition capability of
another. To achieve the goal, we first build two sign language dictionaries
containing isolated signs that appear in two datasets. Then we identify the
sign-to-sign mappings between two sign languages via a well-optimized isolated
sign language recognition model. At last, we train a CSLR model on the
combination of the target data with original labels and the auxiliary data with
mapped labels. Experimentally, our approach achieves state-of-the-art
performance on two widely-used CSLR datasets: Phoenix-2014 and Phoenix-2014T.
</p>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10811" title="Abstract">arXiv:2308.10811</a> [<a href="/pdf/2308.10811" title="Download PDF">pdf</a>, <a href="/format/2308.10811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tree Drawings with Columns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klawitter%2C+J">Jonathan Klawitter</a>, 
<a href="/search/cs?searchtype=author&query=Zink%2C+J">Johannes Zink</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the Proceedings of the 31st International Symposium on Graph Drawing and Network Visualization (GD 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Our goal is to visualize an additional data dimension of a tree with
multifaceted data through superimposition on vertical strips, which we call
columns. Specifically, we extend upward drawings of unordered rooted trees
where vertices have assigned heights by mapping each vertex to a column. Under
an orthogonal drawing style and with every subtree within a column drawn
planar, we consider different natural variants concerning the arrangement of
subtrees within a column. We show that minimizing the number of crossings in
such a drawing can be achieved in fixed-parameter tractable (FPT) time in the
maximum vertex degree $\Delta$ for the most restrictive variant, while becoming
NP-hard (even to approximate) already for a slightly relaxed variant. However,
we provide an FPT algorithm in the number of crossings plus $\Delta$, and an
FPT-approximation algorithm in $\Delta$ via a reduction to feedback arc set.
</p>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10814" title="Abstract">arXiv:2308.10814</a> [<a href="/pdf/2308.10814" title="Download PDF">pdf</a>, <a href="/format/2308.10814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jumping through Local Minima: Quantization in the Loss Landscape of  Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frumkin%2C+N">Natalia Frumkin</a>, 
<a href="/search/cs?searchtype=author&query=Gope%2C+D">Dibakar Gope</a>, 
<a href="/search/cs?searchtype=author&query=Marculescu%2C+D">Diana Marculescu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2211.09643">arXiv:2211.09643</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Quantization scale and bit-width are the most important parameters when
considering how to quantize a neural network. Prior work focuses on optimizing
quantization scales in a global manner through gradient methods (gradient
descent \&amp; Hessian analysis). Yet, when applying perturbations to quantization
scales, we observe a very jagged, highly non-smooth test loss landscape. In
fact, small perturbations in quantization scale can greatly affect accuracy,
yielding a $0.5-0.8\%$ accuracy boost in 4-bit quantized vision transformers
(ViTs). In this regime, gradient methods break down, since they cannot reliably
reach local minima. In our work, dubbed Evol-Q, we use evolutionary search to
effectively traverse the non-smooth landscape. Additionally, we propose using
an infoNCE loss, which not only helps combat overfitting on the small
calibration dataset ($1,000$ images) but also makes traversing such a highly
non-smooth surface easier. Evol-Q improves the top-1 accuracy of a fully
quantized ViT-Base by $10.30\%$, $0.78\%$, and $0.15\%$ for $3$-bit, $4$-bit,
and $8$-bit weight quantization levels. Extensive experiments on a variety of
CNN and ViT architectures further demonstrate its robustness in extreme
quantization scenarios. Our code is available at
https://github.com/enyac-group/evol-q
</p>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10817" title="Abstract">arXiv:2308.10817</a> [<a href="/pdf/2308.10817" title="Download PDF">pdf</a>, <a href="/ps/2308.10817" title="Download PostScript">ps</a>, <a href="/format/2308.10817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the impossibility of discovering a formula for primes using AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kolpakov%2C+A">Alexander Kolpakov</a>, 
<a href="/search/cs?searchtype=author&query=Rocke%2C+A">Aidan Rocke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">The present work explores the theoretical limits of Machine Learning (ML)
within the framework of Kolmogorov's theory of Algorithmic Probability, which
clarifies the notion of entropy as Expected Kolmogorov Complexity and
formalizes other fundamental concepts such as Occam's razor via Levin's
Universal Distribution. As a fundamental application, we develop Maximum
Entropy methods that allow us to derive the Erd\H{o}s--Kac Law in Probabilistic
Number Theory, and establish the impossibility of discovering a formula for
primes using Machine Learning via the Prime Coding Theorem.
</p>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10819" title="Abstract">arXiv:2308.10819</a> [<a href="/pdf/2308.10819" title="Download PDF">pdf</a>, <a href="/format/2308.10819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do you really follow me? Adversarial Instructions for Evaluating the  Robustness of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zekun Li</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Baolin Peng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+P">Pengcheng He</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xifeng Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) have shown remarkable proficiency in following
instructions, making them valuable in customer-facing applications. However,
their impressive capabilities also raise concerns about the amplification of
risks posed by adversarial instructions, which can be injected into the model
input by third-party attackers to manipulate LLMs' original instructions and
prompt unintended actions and content. Therefore, it is crucial to understand
LLMs' ability to accurately discern which instructions to follow to ensure
their safe deployment in real-world scenarios. In this paper, we propose a
pioneering benchmark for automatically evaluating the robustness of LLMs
against adversarial instructions. The objective of this benchmark is to
quantify the extent to which LLMs are influenced by injected adversarial
instructions and assess their ability to differentiate between these
adversarial instructions and original user instructions. Through experiments
conducted with state-of-the-art instruction-following LLMs, we uncover
significant limitations in their robustness against adversarial instruction
attacks. Furthermore, our findings indicate that prevalent instruction-tuned
models are prone to being overfitted to follow any instruction phrase in the
prompt without truly understanding which instructions should be followed. This
highlights the need to address the challenge of training models to comprehend
prompts instead of merely following instruction phrases and completing the
text.
</p>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10820" title="Abstract">arXiv:2308.10820</a> [<a href="/pdf/2308.10820" title="Download PDF">pdf</a>, <a href="/format/2308.10820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pixel Adaptive Deep Unfolding Transformer for Hyperspectral Image  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Miaoyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Ying Fu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Ji Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yulun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Hyperspectral Image (HSI) reconstruction has made gratifying progress with
the deep unfolding framework by formulating the problem into a data module and
a prior module. Nevertheless, existing methods still face the problem of
insufficient matching with HSI data. The issues lie in three aspects: 1) fixed
gradient descent step in the data module while the degradation of HSI is
agnostic in the pixel-level. 2) inadequate prior module for 3D HSI cube. 3)
stage interaction ignoring the differences in features at different stages. To
address these issues, in this work, we propose a Pixel Adaptive Deep Unfolding
Transformer (PADUT) for HSI reconstruction. In the data module, a pixel
adaptive descent step is employed to focus on pixel-level agnostic degradation.
In the prior module, we introduce the Non-local Spectral Transformer (NST) to
emphasize the 3D characteristics of HSI for recovering. Moreover, inspired by
the diverse expression of features in different stages and depths, the stage
interaction is improved by the Fast Fourier Transform (FFT). Experimental
results on both simulated and real scenes exhibit the superior performance of
our method compared to state-of-the-art HSI reconstruction methods. The code is
released at: https://github.com/MyuLi/PADUT.
</p>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10821" title="Abstract">arXiv:2308.10821</a> [<a href="/pdf/2308.10821" title="Download PDF">pdf</a>, <a href="/format/2308.10821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Networks Optimizations Against Concept and Data Drift in Malware  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maillet%2C+W">William Maillet</a>, 
<a href="/search/cs?searchtype=author&query=Marais%2C+B">Benjamin Marais</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite the promising results of machine learning models in malware
detection, they face the problem of concept drift due to malware constant
evolution. This leads to a decline in performance over time, as the data
distribution of the new files differs from the training one, requiring regular
model update. In this work, we propose a model-agnostic protocol to improve a
baseline neural network to handle with the drift problem. We show the
importance of feature reduction and training with the most recent validation
set possible, and propose a loss function named Drift-Resilient Binary
Cross-Entropy, an improvement to the classical Binary Cross-Entropy more
effective against drift. We train our model on the EMBER dataset (2018) and
evaluate it on a dataset of recent malicious files, collected between 2020 and
2023. Our improved model shows promising results, detecting 15.2% more malware
than a baseline model.
</p>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10822" title="Abstract">arXiv:2308.10822</a> [<a href="/pdf/2308.10822" title="Download PDF">pdf</a>, <a href="/format/2308.10822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Ehanced Move Recognition Algorithm Based on Pre-trained Models  with Positional Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Hao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+X">Xiaodong Qiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The recognition of abstracts is crucial for effectively locating the content
and clarifying the article. Existing move recognition algorithms lack the
ability to learn word position information to obtain contextual semantics. This
paper proposes a novel enhanced move recognition algorithm with an improved
pre-trained model and a gated network with attention mechanism for unstructured
abstracts of Chinese scientific and technological papers. The proposed
algorithm first performs summary data segmentation and vocabulary training. The
EP-ERNIE$\_$AT-GRU framework is leveraged to incorporate word positional
information, facilitating deep semantic learning and targeted feature
extraction. Experimental results demonstrate that the proposed algorithm
achieves 13.37$\%$ higher accuracy on the split dataset than on the original
dataset and a 7.55$\%$ improvement in accuracy over the basic comparison model.
</p>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10828" title="Abstract">arXiv:2308.10828</a> [<a href="/pdf/2308.10828" title="Download PDF">pdf</a>, <a href="/format/2308.10828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Large-scale Benchmark for Log Parsing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhihan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Junjie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yichen Li</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+Y">Yintong Huo</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jiazhen Gu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuangbin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jieming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+M+R">Michael R. Lyu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Log data is pivotal in activities like anomaly detection and failure
diagnosis in the automated maintenance of software systems. Due to their
unstructured format, log parsing is often required to transform them into a
structured format for automated analysis. A variety of log parsers exist,
making it vital to benchmark these tools to comprehend their features and
performance. However, existing datasets for log parsing are limited in terms of
scale and representativeness, posing challenges for studies that aim to
evaluate or develop log parsers. This problem becomes more pronounced when
these parsers are evaluated for production use. To address these issues, we
introduce a new collection of large-scale annotated log datasets, named LogPub,
which more accurately mirrors log data observed in real-world software systems.
LogPub comprises 14 datasets, each averaging 3.6 million log lines. Utilizing
LogPub, we re-evaluate 15 log parsers in a more rigorous and practical setting.
We also propose a new evaluation metric to lessen the sensitivity of current
metrics to imbalanced data distribution. Furthermore, we are the first to
scrutinize the detailed performance of log parsers on logs that represent rare
system events and offer comprehensive information for system troubleshooting.
Parsing such logs accurately is vital yet challenging. We believe that our work
could shed light on the design and evaluation of log parsers in more realistic
settings, thereby facilitating their implementation in production systems.
</p>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10832" title="Abstract">arXiv:2308.10832</a> [<a href="/pdf/2308.10832" title="Download PDF">pdf</a>, <a href="/format/2308.10832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EigenPlaces: Training Viewpoint Robust Models for Visual Place  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berton%2C+G">Gabriele Berton</a>, 
<a href="/search/cs?searchtype=author&query=Trivigno%2C+G">Gabriele Trivigno</a>, 
<a href="/search/cs?searchtype=author&query=Caputo%2C+B">Barbara Caputo</a>, 
<a href="/search/cs?searchtype=author&query=Masone%2C+C">Carlo Masone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual Place Recognition is a task that aims to predict the place of an image
(called query) based solely on its visual features. This is typically done
through image retrieval, where the query is matched to the most similar images
from a large database of geotagged photos, using learned global descriptors. A
major challenge in this task is recognizing places seen from different
viewpoints. To overcome this limitation, we propose a new method, called
EigenPlaces, to train our neural network on images from different point of
views, which embeds viewpoint robustness into the learned global descriptors.
The underlying idea is to cluster the training data so as to explicitly present
the model with different views of the same points of interest. The selection of
this points of interest is done without the need for extra supervision. We then
present experiments on the most comprehensive set of datasets in literature,
finding that EigenPlaces is able to outperform previous state of the art on the
majority of datasets, while requiring 60\% less GPU memory for training and
using 50\% smaller descriptors. The code and trained models for EigenPlaces are
available at {\small{\url{https://github.com/gmberton/EigenPlaces}}}, while
results with any other baseline can be computed with the codebase at
{\small{\url{https://github.com/gmberton/auto_VPR}}}.
</p>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10834" title="Abstract">arXiv:2308.10834</a> [<a href="/pdf/2308.10834" title="Download PDF">pdf</a>, <a href="/format/2308.10834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SRSS: A New Chaos-Based Single-Round Single S-Box Image Encryption  Scheme for Highly Auto-Correlated Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+S">Muhammad Shahbaz Khan</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+J">Jawad Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+H">Hisham Ali</a>, 
<a href="/search/cs?searchtype=author&query=Pitropakis%2C+N">Nikolaos Pitropakis</a>, 
<a href="/search/cs?searchtype=author&query=Al-Dubai%2C+A">Ahmed Al-Dubai</a>, 
<a href="/search/cs?searchtype=author&query=Ghaleb%2C+B">Baraq Ghaleb</a>, 
<a href="/search/cs?searchtype=author&query=Buchanan%2C+W+J">William J. Buchanan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">With the advent of digital communication, securing digital images during
transmission and storage has become a critical concern. The traditional s-box
substitution methods often fail to effectively conceal the information within
highly auto-correlated regions of an image. This paper addresses the security
issues presented by three prevalent S-box substitution methods, i.e., single
S-box, multiple S-boxes, and multiple rounds with multiple S-boxes, especially
when handling images with highly auto-correlated pixels. To resolve the
addressed security issues, this paper proposes a new scheme SRSS-the Single
Round Single S-Box encryption scheme. SRSS uses a single S-box for substitution
in just one round to break the pixel correlations and encrypt the plaintext
image effectively. Additionally, this paper introduces a new Chaos-based Random
Operation Selection System-CROSS, which nullifies the requirement for multiple
S-boxes, thus reducing the encryption scheme's complexity. By randomly
selecting the operation to be performed on each pixel, driven by a chaotic
sequence, the proposed scheme effectively scrambles even high auto-correlation
areas. When compared to the substitution methods mentioned above, the proposed
encryption scheme exhibited exceptionally well in just a single round with a
single S-box. The close-to-ideal statistical security analysis results, i.e.,
an entropy of 7.89 and a correlation coefficient of 0.007, validate the
effectiveness of the proposed scheme. This research offers an innovative path
forward for securing images in applications requiring low computational
complexity and fast encryption and decryption speeds.
</p>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10835" title="Abstract">arXiv:2308.10835</a> [<a href="/pdf/2308.10835" title="Download PDF">pdf</a>, <a href="/format/2308.10835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Recommender Systems with Large Language Model Reasoning Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+Z">Zhixuan Chu</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+X">Xin Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Simeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+H">Hongyan Hao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yue Shen</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinjie Gu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+S">Siqiao Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J+Y">James Y Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Q">Qing Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Longfei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sheng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Recommendation systems aim to provide users with relevant suggestions, but
often lack interpretability and fail to capture higher-level semantic
relationships between user behaviors and profiles. In this paper, we propose a
novel approach that leverages large language models (LLMs) to construct
personalized reasoning graphs. These graphs link a user's profile and
behavioral sequences through causal and logical inferences, representing the
user's interests in an interpretable way. Our approach, LLM reasoning graphs
(LLMRG), has four components: chained graph reasoning, divergent extension,
self-verification and scoring, and knowledge base self-improvement. The
resulting reasoning graph is encoded using graph neural networks, which serves
as additional input to improve conventional recommender systems, without
requiring extra user or item information. Our approach demonstrates how LLMs
can enable more logical and interpretable recommender systems through
personalized reasoning graphs. LLMRG allows recommendations to benefit from
both engineered recommendation systems and LLM-derived reasoning graphs. We
demonstrate the effectiveness of LLMRG on benchmarks and real-world scenarios
in enhancing base recommendation models.
</p>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10837" title="Abstract">arXiv:2308.10837</a> [<a href="/pdf/2308.10837" title="Download PDF">pdf</a>, <a href="/format/2308.10837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Large Language Models for Pre-trained Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+Z">Zhixuan Chu</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+H">Hongyan Hao</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+X">Xin Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Simeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yue Shen</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinjie Gu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Q">Qing Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Longfei Li</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+S">Siqiao Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J+Y">James Y Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sheng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Recent advancements in recommendation systems have shifted towards more
comprehensive and personalized recommendations by utilizing large language
models (LLM). However, effectively integrating LLM's commonsense knowledge and
reasoning abilities into recommendation systems remains a challenging problem.
In this paper, we propose RecSysLLM, a novel pre-trained recommendation model
based on LLMs. RecSysLLM retains LLM reasoning and knowledge while integrating
recommendation domain knowledge through unique designs of data, training, and
inference. This allows RecSysLLM to leverage LLMs' capabilities for
recommendation tasks in an efficient, unified framework. We demonstrate the
effectiveness of RecSysLLM on benchmarks and real-world scenarios. RecSysLLM
provides a promising approach to developing unified recommendation systems by
fully exploiting the power of pre-trained language models.
</p>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10838" title="Abstract">arXiv:2308.10838</a> [<a href="/pdf/2308.10838" title="Download PDF">pdf</a>, <a href="/format/2308.10838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An impossibility result for Markov Chain Monte Carlo sampling from  micro-canonical bipartite graph ensembles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Preti%2C+G">Giulia Preti</a>, 
<a href="/search/cs?searchtype=author&query=De+Francisci+Morales%2C+G">Gianmarco De Francisci Morales</a>, 
<a href="/search/cs?searchtype=author&query=Riondato%2C+M">Matteo Riondato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Markov Chain Monte Carlo (MCMC) algorithms are commonly used to sample from
graph ensembles. Two graphs are neighbors in the state space if one can be
obtained from the other with only a few modifications, e.g., edge rewirings.
For many common ensembles, e.g., those preserving the degree sequences of
bipartite graphs, rewiring operations involving two edges are sufficient to
create a fully-connected state space, and they can be performed efficiently. We
show that, for ensembles of bipartite graphs with fixed degree sequences and
number of butterflies (k2,2 bi-cliques), there is no universal constant c such
that a rewiring of at most c edges at every step is sufficient for any such
ensemble to be fully connected. Our proof relies on an explicit construction of
a family of pairs of graphs with the same degree sequences and number of
butterflies, with each pair indexed by a natural c, and such that any sequence
of rewiring operations transforming one graph into the other must include at
least one rewiring operation involving at least c edges. Whether rewiring these
many edges is sufficient to guarantee the full connectivity of the state space
of any such ensemble remains an open question. Our result implies the
impossibility of developing efficient, graph-agnostic, MCMC algorithms for
these ensembles, as the necessity to rewire an impractically large number of
edges may hinder taking a step on the state space.
</p>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10839" title="Abstract">arXiv:2308.10839</a> [<a href="/pdf/2308.10839" title="Download PDF">pdf</a>, <a href="/format/2308.10839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision Transformer Pruning Via Matrix Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+T">Tianyi Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation (stat.CO)

</div>
<p class="mathjax">This is a further development of Vision Transformer Pruning via matrix
decomposition. The purpose of the Vision Transformer Pruning is to prune the
dimension of the linear projection of the dataset by learning their associated
importance score in order to reduce the storage, run-time memory, and
computational demands. In this paper we further reduce dimension and complexity
of the linear projection by implementing and comparing several matrix
decomposition methods while preserving the generated important features. We end
up selected the Singular Value Decomposition as the method to achieve our goal
by comparing the original accuracy scores in the original Github repository and
the accuracy scores of using those matrix decomposition methods, including
Singular Value Decomposition, four versions of QR Decomposition, and LU
factorization.
</p>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10842" title="Abstract">arXiv:2308.10842</a> [<a href="/pdf/2308.10842" title="Download PDF">pdf</a>, <a href="/format/2308.10842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Agent Communication and Learning through Action and Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hugo%2C+C">Caselles-Dupr&#xe9; Hugo</a>, 
<a href="/search/cs?searchtype=author&query=Olivier%2C+S">Sigaud Olivier</a>, 
<a href="/search/cs?searchtype=author&query=Mohamed%2C+C">Chetouani Mohamed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IMOL workshop, Paris 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce a novel category of GC-agents capable of functioning as both
teachers and learners. Leveraging action-based demonstrations and
language-based instructions, these agents enhance communication efficiency. We
investigate the incorporation of pedagogy and pragmatism, essential elements in
human communication and goal achievement, enhancing the agents' teaching and
learning capabilities. Furthermore, we explore the impact of combining
communication modes (action and language) on learning outcomes, highlighting
the benefits of a multi-modal approach.
</p>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10843" title="Abstract">arXiv:2308.10843</a> [<a href="/pdf/2308.10843" title="Download PDF">pdf</a>, <a href="/format/2308.10843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TranSTYLer: Multimodal Behavioral Style Transfer for Facial and Body  Gestures Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fares%2C+M">Mireille Fares</a>, 
<a href="/search/cs?searchtype=author&query=Pelachaud%2C+C">Catherine Pelachaud</a>, 
<a href="/search/cs?searchtype=author&query=Obin%2C+N">Nicolas Obin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This paper addresses the challenge of transferring the behavior expressivity
style of a virtual agent to another one while preserving behaviors shape as
they carry communicative meaning. Behavior expressivity style is viewed here as
the qualitative properties of behaviors. We propose TranSTYLer, a multimodal
transformer based model that synthesizes the multimodal behaviors of a source
speaker with the style of a target speaker. We assume that behavior
expressivity style is encoded across various modalities of communication,
including text, speech, body gestures, and facial expressions. The model
employs a style and content disentanglement schema to ensure that the
transferred style does not interfere with the meaning conveyed by the source
behaviors. Our approach eliminates the need for style labels and allows the
generalization to styles that have not been seen during the training phase. We
train our model on the PATS corpus, which we extended to include dialog acts
and 2D facial landmarks. Objective and subjective evaluations show that our
model outperforms state of the art models in style transfer for both seen and
unseen styles during training. To tackle the issues of style and content
leakage that may arise, we propose a methodology to assess the degree to which
behavior and gestures associated with the target style are successfully
transferred, while ensuring the preservation of the ones related to the source
content.
</p>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10845" title="Abstract">arXiv:2308.10845</a> [<a href="/pdf/2308.10845" title="Download PDF">pdf</a>, <a href="/format/2308.10845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Election Manipulation in Social Networks with Single-Peaked Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Auletta%2C+V">Vincenzo Auletta</a>, 
<a href="/search/cs?searchtype=author&query=Carbone%2C+F">Francesco Carbone</a>, 
<a href="/search/cs?searchtype=author&query=Ferraioli%2C+D">Diodato Ferraioli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Several elections run in the last years have been characterized by attempts
to manipulate the result of the election through the diffusion of fake or
malicious news over social networks. This problem has been recognized as a
critical issue for the robustness of our democracy. Analyzing and understanding
how such manipulations may occur is crucial to the design of effective
countermeasures to these practices.
<br />Many studies have observed that, in general, to design an optimal
manipulation is usually a computationally hard task. Nevertheless, literature
on bribery in voting and election manipulation has frequently observed that
most hardness results melt down when one focuses on the setting of (nearly)
single-peaked agents, i.e., when each voter has a preferred candidate (usually,
the one closer to her own belief) and preferences of remaining candidates are
inversely proportional to the distance between the candidate position and the
voter's belief. Unfortunately, no such analysis has been done for election
manipulations run in social networks.
<br />In this work, we try to close this gap: specifically, we consider a setting
for election manipulation that naturally raises (nearly) single-peaked
preferences, and we evaluate the complexity of election manipulation problem in
this setting: while most of the hardness and approximation results still hold,
we will show that single-peaked preferences allow to design simple, efficient
and effective heuristics for election manipulation.
</p>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10846" title="Abstract">arXiv:2308.10846</a> [<a href="/pdf/2308.10846" title="Download PDF">pdf</a>, <a href="/format/2308.10846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real World Time Series Benchmark Datasets with Distribution Shifts:  Global Crude Oil Price and Volatility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pasula%2C+P">Pranay Pasula</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures. Awarded Best Paper Runner Up / Honorable Mention and presented as Contributed Talk at IJCAI 2023, the 32nd International Joint Conference on Artificial Intelligence (AI4TS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">The scarcity of task-labeled time-series benchmarks in the financial domain
hinders progress in continual learning. Addressing this deficit would foster
innovation in this area. Therefore, we present COB, Crude Oil Benchmark
datasets. COB includes 30 years of asset prices that exhibit significant
distribution shifts and optimally generates corresponding task (i.e., regime)
labels based on these distribution shifts for the three most important crude
oils in the world. Our contributions include creating real-world benchmark
datasets by transforming asset price data into volatility proxies, fitting
models using expectation-maximization (EM), generating contextual task labels
that align with real-world events, and providing these labels as well as the
general algorithm to the public. We show that the inclusion of these task
labels universally improves performance on four continual learning algorithms,
some state-of-the-art, over multiple forecasting horizons. We hope these
benchmarks accelerate research in handling distribution shifts in real-world
data, especially due to the global importance of the assets considered. We've
made the (1) raw price data, (2) task labels generated by our approach, (3) and
code for our algorithm available at https://oilpricebenchmarks.github.io.
</p>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10848" title="Abstract">arXiv:2308.10848</a> [<a href="/pdf/2308.10848" title="Download PDF">pdf</a>, <a href="/format/2308.10848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AgentVerse: Facilitating Multi-Agent Collaboration and Exploring  Emergent Behaviors in Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weize Chen</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yusheng Su</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+J">Jingwei Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Cheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chenfei Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Chen Qian</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+C">Chi-Min Chan</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yujia Qin</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yaxi Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+R">Ruobing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Maosong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Autonomous agents empowered by Large Language Models (LLMs) have undergone
significant improvements, enabling them to generalize across a broad spectrum
of tasks. However, in real-world scenarios, cooperation among individuals is
often required to enhance the efficiency and effectiveness of task
accomplishment. Hence, inspired by human group dynamics, we propose a
multi-agent framework \framework that can collaboratively and dynamically
adjust its composition as a greater-than-the-sum-of-its-parts system. Our
experiments demonstrate that \framework framework can effectively deploy
multi-agent groups that outperform a single agent. Furthermore, we delve into
the emergence of social behaviors among individual agents within a group during
collaborative task accomplishment. In view of these behaviors, we discuss some
possible strategies to leverage positive ones and mitigate negative ones for
improving the collaborative potential of multi-agent groups. Our codes for
\framework will soon be released at
\url{https://github.com/OpenBMB/AgentVerse}.
</p>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10851" title="Abstract">arXiv:2308.10851</a> [<a href="/pdf/2308.10851" title="Download PDF">pdf</a>, <a href="/ps/2308.10851" title="Download PostScript">ps</a>, <a href="/format/2308.10851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning in Dynamic Systems and Its Application to Adaptive PID Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Makke%2C+O">Omar Makke</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+F">Feng Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Deep learning using neural networks has revolutionized machine learning and
put artificial intelligence into everyday life. In order to introduce
self-learning to dynamic systems other than neural networks, we extend the
Brandt-Lin learning algorithm of neural networks to a large class of dynamic
systems. This extension is possible because the Brandt-Lin algorithm does not
require a dedicated step to back-propagate the errors in neural networks. To
this end, we first generalize signal-flow graphs so that they can be used to
model nonlinear systems as well as linear systems. We then derive the extended
Brandt-Lin algorithm that can be used to adapt the weights of branches in
generalized signal-flow graphs. We show the applications of the new algorithm
by applying it to adaptive PID control. In particular, we derive a new
adaptation law for PID controllers. We verify the effectiveness of the method
using simulations for linear and nonlinear plants, stable as well as unstable
plants.
</p>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10852" title="Abstract">arXiv:2308.10852</a> [<a href="/pdf/2308.10852" title="Download PDF">pdf</a>, <a href="/format/2308.10852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty benchmarks for time-dependent transport problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bennett%2C+W">William Bennett</a>, 
<a href="/search/cs?searchtype=author&query=McClarren%2C+R+G">Ryan G. McClarren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Uncertainty quantification results are presented for a well known
verification solution, the time dependent transport infinite plane pulse. The
method of polynomial chaos expansions (PCE) is employed for quick and accurate
calculation of the quantities of interest. Also, the method of uncollided
solutions is used in this problem to treat part of the uncertainty calculation
analytically.
</p>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10855" title="Abstract">arXiv:2308.10855</a> [<a href="/pdf/2308.10855" title="Download PDF">pdf</a>, <a href="/format/2308.10855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LatEval: An Interactive LLMs Evaluation Benchmark with Incomplete  Information from Lateral Thinking Puzzles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shulin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shirong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Mengzuo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+W">Wuhe Zou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weidong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hai-Tao Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With the continuous evolution and refinement of LLMs, they are endowed with
impressive logical reasoning or vertical thinking capabilities. But can they
think out of the box? Do they possess proficient lateral thinking abilities?
Following the setup of Lateral Thinking Puzzles, we propose a novel evaluation
benchmark, LatEval, which assesses the model's lateral thinking within an
interactive framework. In our benchmark, we challenge LLMs with 2 aspects: the
quality of questions posed by the model and the model's capability to integrate
information for problem-solving. We find that nearly all LLMs struggle with
employing lateral thinking during interactions. For example, even the most
advanced model, GPT-4, exhibits the advantage to some extent, yet still
maintain a noticeable gap when compared to human. This evaluation benchmark
provides LLMs with a highly challenging and distinctive task that is crucial to
an effective AI assistant.
</p>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10856" title="Abstract">arXiv:2308.10856</a> [<a href="/pdf/2308.10856" title="Download PDF">pdf</a>, <a href="/format/2308.10856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Majorana Demonstrator Data Release for AI/ML Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arnquist%2C+I+J">I.J. Arnquist</a>, 
<a href="/search/cs?searchtype=author&query=Avignone%2C+F+T">F.T. Avignone III</a>, 
<a href="/search/cs?searchtype=author&query=Barabash%2C+A+S">A.S. Barabash</a>, 
<a href="/search/cs?searchtype=author&query=Barton%2C+C+J">C.J. Barton</a>, 
<a href="/search/cs?searchtype=author&query=Bhimani%2C+K+H">K.H. Bhimani</a>, 
<a href="/search/cs?searchtype=author&query=Blalock%2C+E">E. Blalock</a>, 
<a href="/search/cs?searchtype=author&query=Bos%2C+B">B. Bos</a>, 
<a href="/search/cs?searchtype=author&query=Busch%2C+M">M. Busch</a>, 
<a href="/search/cs?searchtype=author&query=Buuck%2C+M">M. Buuck</a>, 
<a href="/search/cs?searchtype=author&query=Caldwell%2C+T+S">T.S. Caldwell</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+Y+-">Y.-D. Chan</a>, 
<a href="/search/cs?searchtype=author&query=Christofferson%2C+C+D">C.D. Christofferson</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+P+-">P.-H. Chu</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+M+L">M.L. Clark</a>, 
<a href="/search/cs?searchtype=author&query=Cuesta%2C+C">C. Cuesta</a>, 
<a href="/search/cs?searchtype=author&query=Detwiler%2C+J+A">J.A. Detwiler</a>, 
<a href="/search/cs?searchtype=author&query=Efremenko%2C+Y">Yu. Efremenko</a>, 
<a href="/search/cs?searchtype=author&query=Ejiri%2C+H">H. Ejiri</a>, 
<a href="/search/cs?searchtype=author&query=Elliott%2C+S+R">S.R. Elliott</a>, 
<a href="/search/cs?searchtype=author&query=Fuad%2C+N">N. Fuad</a>, 
<a href="/search/cs?searchtype=author&query=Giovanetti%2C+G+K">G.K. Giovanetti</a>, 
<a href="/search/cs?searchtype=author&query=Green%2C+M+P">M.P. Green</a>, 
<a href="/search/cs?searchtype=author&query=Gruszko%2C+J">J. Gruszko</a>, 
<a href="/search/cs?searchtype=author&query=Guinn%2C+I+S">I.S. Guinn</a>, 
<a href="/search/cs?searchtype=author&query=Guiseppe%2C+V+E">V.E. Guiseppe</a>, 
<a href="/search/cs?searchtype=author&query=Haufe%2C+C+R">C.R. Haufe</a>, 
<a href="/search/cs?searchtype=author&query=Henning%2C+R">R. Henning</a>, 
<a href="/search/cs?searchtype=author&query=Aguilar%2C+D+H">D. Hervas Aguilar</a>, 
<a href="/search/cs?searchtype=author&query=Hoppe%2C+E+W">E.W. Hoppe</a>, 
<a href="/search/cs?searchtype=author&query=Hostiuc%2C+A">A. Hostiuc</a>, 
<a href="/search/cs?searchtype=author&query=Kidd%2C+M+F">M.F. Kidd</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+I">I. Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kouzes%2C+R+T">R.T. Kouzes</a>, 
<a href="/search/cs?searchtype=author&query=V%2C+T+E+L">T.E. Lannen V</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">A. Li</a>, 
<a href="/search/cs?searchtype=author&query=Lopez-Castano%2C+J+M">J.M. Lopez-Castano</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+R+D">R.D. Martin</a>, 
<a href="/search/cs?searchtype=author&query=Massarczyk%2C+R">R. Massarczyk</a>, 
<a href="/search/cs?searchtype=author&query=Meijer%2C+S+J">S.J. Meijer</a>, 
<a href="/search/cs?searchtype=author&query=Mertens%2C+S">S. Mertens</a>, 
<a href="/search/cs?searchtype=author&query=Oli%2C+T+K">T.K. Oli</a>, 
<a href="/search/cs?searchtype=author&query=Paudel%2C+L+S">L.S. Paudel</a>, 
<a href="/search/cs?searchtype=author&query=Pettus%2C+W">W. Pettus</a>, 
<a href="/search/cs?searchtype=author&query=Poon%2C+A+W+P">A.W.P. Poon</a>, 
<a href="/search/cs?searchtype=author&query=Quenallata%2C+B">B. Quenallata</a>, 
<a href="/search/cs?searchtype=author&query=Radford%2C+D+C">D.C. Radford</a>, 
<a href="/search/cs?searchtype=author&query=Reine%2C+A+L">A.L. Reine</a>, 
<a href="/search/cs?searchtype=author&query=Rielage%2C+K">K. Rielage</a>, 
<a href="/search/cs?searchtype=author&query=Ruof%2C+N+W">N.W. Ruof</a>, 
<a href="/search/cs?searchtype=author&query=Schaper%2C+D+C">D.C. Schaper</a>, 
<a href="/search/cs?searchtype=author&query=Schleich%2C+S+J">S.J. Schleich</a>, 
<a href="/search/cs?searchtype=author&query=Tedeschi%2C+D">D. Tedeschi</a>, 
<a href="/search/cs?searchtype=author&query=Varner%2C+R+L">R.L. Varner</a>, 
<a href="/search/cs?searchtype=author&query=Vasilyev%2C+S">S. Vasilyev</a>, 
<a href="/search/cs?searchtype=author&query=Watkins%2C+S+L">S.L. Watkins</a>, 
<a href="/search/cs?searchtype=author&query=Wilkerson%2C+J+F">J.F. Wilkerson</a>, 
<a href="/search/cs?searchtype=author&query=Wiseman%2C+C">C. Wiseman</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">W. Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C+-">C.-H. Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B+X">B.X. Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Zenodo DOI: 10.5281/zenodo.8257027
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Nuclear Experiment (nucl-ex); Data Analysis, Statistics and Probability (physics.data-an); Instrumentation and Detectors (physics.ins-det)

</div>
<p class="mathjax">The enclosed data release consists of a subset of the calibration data from
the Majorana Demonstrator experiment. Each Majorana event is accompanied by raw
Germanium detector waveforms, pulse shape discrimination cuts, and calibrated
final energies, all shared in an HDF5 file format along with relevant metadata.
This release is specifically designed to support the training and testing of
Artificial Intelligence (AI) and Machine Learning (ML) algorithms upon our
data. This document is structured as follows. Section I provides an overview of
the dataset's content and format; Section II outlines the location of this
dataset and the method for accessing it; Section III presents the NPML Machine
Learning Challenge associated with this dataset; Section IV contains a
disclaimer from the Majorana collaboration regarding the use of this dataset;
Appendix A contains technical details of this data release. Please direct
questions about the material provided within this release to liaobo77@ucsd.edu
(A. Li).
</p>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10858" title="Abstract">arXiv:2308.10858</a> [<a href="/pdf/2308.10858" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compliant Mechanism Synthesis Using Nonlinear Elastic Topology  Optimization with Variable Boundary Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alacoque%2C+L+R">Lee R. Alacoque</a> (1), 
<a href="/search/cs?searchtype=author&query=Bhattacharyya%2C+A">Anurag Bhattacharyya</a> (2), 
<a href="/search/cs?searchtype=author&query=James%2C+K+A">Kai A. James</a> (3) ((1) University of Illinois Urbana-Champaign, (2) Palo Alto Research Center, (3) Georgia Institute of Technology)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 14 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">In topology optimization of compliant mechanisms, the specific placement of
boundary conditions strongly affects the resulting material distribution and
performance of the design. At the same time, the most effective locations of
the loads and supports are often difficult to find manually. This substantially
limits topology optimization's effectiveness for many mechanism design
problems. We remove this limitation by developing a method which automatically
determines optimal positioning of a prescribed input displacement and a set of
supports simultaneously with an optimal material layout. Using nonlinear
elastic physics, we synthesize a variety of compliant mechanisms with large
output displacements, snap-through responses, and prescribed output paths,
producing designs with significantly improved performance in every case tested.
Compared to optimal designs generated using best-guess boundary conditions used
in previous studies, the mechanisms presented in this paper see performance
increases ranging from 23%-430%. The results show that nonlinear mechanism
responses may be particularly sensitive to boundary condition locations and
that effective placements can be difficult to find without an automated method.
</p>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10861" title="Abstract">arXiv:2308.10861</a> [<a href="/pdf/2308.10861" title="Download PDF">pdf</a>, <a href="/format/2308.10861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterization of random walks on space of unordered trees using  efficient metric simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naoum%2C+F+B">Farah Ben Naoum</a>, 
<a href="/search/cs?searchtype=author&query=Godin%2C+C">Christophe Godin</a>, 
<a href="/search/cs?searchtype=author&query=Aza%C3%AFs%2C+R">Romain Aza&#xef;s</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">The simple random walk on $\mathbb{Z}^p$ shows two drastically different
behaviours depending on the value of $p$: it is recurrent when $p\in\{1,2\}$
while it escapes (with a rate increasing with $p$) as soon as $p\geq3$. This
classical example illustrates that the asymptotic properties of a random walk
provides some information on the structure of its state space. This paper aims
to explore analogous questions on space made up of combinatorial objects with
no algebraic structure. We take as a model for this problem the space of
unordered unlabeled rooted trees endowed with Zhang edit distance. To this end,
it defines the canonical unbiased random walk on the space of trees and
provides an efficient algorithm to evaluate its escape rate. Compared to Zhang
algorithm, it is incremental and computes the edit distance along the random
walk approximately 100 times faster on trees of size $500$ on average. The
escape rate of the random walk on trees is precisely estimated using intensive
numerical simulations, out of reasonable reach without the incremental
algorithm.
</p>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10862" title="Abstract">arXiv:2308.10862</a> [<a href="/pdf/2308.10862" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Election Polarization: Mapping citizen divisions through elections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Navarrete%2C+C">Carlos Navarrete</a>, 
<a href="/search/cs?searchtype=author&query=Macedo%2C+M">Mariana Macedo</a>, 
<a href="/search/cs?searchtype=author&query=Stojkoski%2C+V">Viktor Stojkoski</a>, 
<a href="/search/cs?searchtype=author&query=Parada%2C+M">Marcela Parada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Elections can unveil citizens' enthusiasm and discomfort concerning political
candidates, parties, and issues. While a substantial body of literature studies
the election outcomes from the perspective of winners and losers, an
under-explored condition to understand societal divisions emerges from citizen
voting patterns. Here, we examine the concept of Election Polarization (EP) as
a measure of citizens' divisions on Election Day. We present an agnostic
approach that relies exclusively on election data and considers the
competitiveness of candidates (Between-EP) and their voting dispersion
throughout a territory (Within-EP). We use both synthetic data and presidential
election results from France, Chile, and the United States to show that our
approach successfully identified theoretical expectations of ``polarized''
elections. Furthermore, we validate its robustness over the election type,
aggregation scale, use of abstentions/spoilt votes, and the number of
candidates. Finally, our analysis reveals that state-level Within-EP and
Between-EP in the U.S. are positively associated with political polarization
and political interest, respectively, shedding light that EP could potentially
encompass a simple and reliable measure of quasi-political polarization,
opening the opportunity of studying this phenomenon both for regional level and
lower/middle-income countries without electoral surveys.
</p>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10869" title="Abstract">arXiv:2308.10869</a> [<a href="/pdf/2308.10869" title="Download PDF">pdf</a>, <a href="/format/2308.10869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Loss Function Utilizing Wasserstein Distance to Reduce  Subject-Dependent Noise for Generalizable Models in Affective Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+N">Nibraas Khan</a>, 
<a href="/search/cs?searchtype=author&query=Tauseef%2C+M">Mahrukh Tauseef</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+R">Ritam Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+N">Nilanjan Sarkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Emotions are an essential part of human behavior that can impact thinking,
decision-making, and communication skills. Thus, the ability to accurately
monitor and identify emotions can be useful in many human-centered applications
such as behavioral training, tracking emotional well-being, and development of
human-computer interfaces. The correlation between patterns in physiological
data and affective states has allowed for the utilization of deep learning
techniques which can accurately detect the affective states of a person.
However, the generalisability of existing models is often limited by the
subject-dependent noise in the physiological data due to variations in a
subject's reactions to stimuli. Hence, we propose a novel cost function that
employs Optimal Transport Theory, specifically Wasserstein Distance, to scale
the importance of subject-dependent data such that higher importance is
assigned to patterns in data that are common across all participants while
decreasing the importance of patterns that result from subject-dependent noise.
The performance of the proposed cost function is demonstrated through an
autoencoder with a multi-class classifier attached to the latent space and
trained simultaneously to detect different affective states. An autoencoder
with a state-of-the-art loss function i.e., Mean Squared Error, is used as a
baseline for comparison with our model across four different commonly used
datasets. Centroid and minimum distance between different classes are used as a
metrics to indicate the separation between different classes in the latent
space. An average increase of 14.75% and 17.75% (from benchmark to proposed
loss function) was found for minimum and centroid euclidean distance
respectively over all datasets.
</p>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10873" title="Abstract">arXiv:2308.10873</a> [<a href="/pdf/2308.10873" title="Download PDF">pdf</a>, <a href="/format/2308.10873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpikingBERT: Distilling BERT to Train Spiking Language Models Using  Implicit Differentiation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bal%2C+M">Malyaban Bal</a>, 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+A">Abhronil Sengupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Large language Models (LLMs), though growing exceedingly powerful, comprises
of orders of magnitude less neurons and synapses than the human brain. However,
it requires significantly more power/energy to operate. In this work, we
propose a novel bio-inspired spiking language model (LM) which aims to reduce
the computational cost of conventional LMs by drawing motivation from the
synaptic information flow in the brain. In this paper, we demonstrate a
framework that leverages the average spiking rate of neurons at equilibrium to
train a neuromorphic spiking LM using implicit differentiation technique,
thereby overcoming the non-differentiability problem of spiking neural network
(SNN) based algorithms without using any type of surrogate gradient. The
steady-state convergence of the spiking neurons also allows us to design a
spiking attention mechanism, which is critical in developing a scalable spiking
LM. Moreover, the convergence of average spiking rate of neurons at equilibrium
is utilized to develop a novel ANN-SNN knowledge distillation based technique
wherein we use a pre-trained BERT model as "teacher" to train our "student"
spiking architecture. While the primary architecture proposed in this paper is
motivated by BERT, the technique can be potentially extended to different kinds
of LLMs. Our work is the first one to demonstrate the performance of an
operational spiking LM architecture on multiple different tasks in the GLUE
benchmark.
</p>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10874" title="Abstract">arXiv:2308.10874</a> [<a href="/pdf/2308.10874" title="Download PDF">pdf</a>, <a href="/format/2308.10874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Transformer Dynamics as Movement through Embedding Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+S+S">Sumeet S. Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Transformer language models exhibit intelligent behaviors such as
understanding natural language, recognizing patterns, acquiring knowledge,
reasoning, planning, reflecting and using tools. This paper explores how their
underlying mechanics give rise to intelligent behaviors. We adopt a systems
approach to analyze Transformers in detail and develop a mathematical framework
that frames their dynamics as movement through embedding space. This novel
perspective provides a principled way of thinking about the problem and reveals
important insights related to the emergence of intelligence:
<br />1. At its core the Transformer is a Embedding Space walker, mapping
intelligent behavior to trajectories in this vector space.
<br />2. At each step of the walk, it composes context into a single composite
vector whose location in Embedding Space defines the next step.
<br />3. No learning actually occurs during decoding; in-context learning and
generalization are simply the result of different contexts composing into
different vectors.
<br />4. Ultimately the knowledge, intelligence and skills exhibited by the model
are embodied in the organization of vectors in Embedding Space rather than in
specific neurons or layers. These abilities are properties of this
organization.
<br />5. Attention's contribution boils down to the association-bias it lends to
vector composition and which influences the aforementioned organization.
However, more investigation is needed to ascertain its significance.
<br />6. The entire model is composed from two principal operations: data
independent filtering and data dependent aggregation. This generalization
unifies Transformers with other sequence models and across modalities.
<br />Building upon this foundation we formalize and test a semantic space theory
which posits that embedding vectors represent semantic concepts and find some
evidence of its validity.
</p>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10875" title="Abstract">arXiv:2308.10875</a> [<a href="/pdf/2308.10875" title="Download PDF">pdf</a>, <a href="/format/2308.10875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metaheuristic Algorithms in Artificial Intelligence with Applications to  Bioinformatics, Biostatistics, Ecology and, the Manufacturing Industries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+E+H">Elvis Han Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zizhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C+J">Culsome Junwen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+W+K">Weng Kee Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Nature-inspired metaheuristic algorithms are important components of
artificial intelligence, and are increasingly used across disciplines to tackle
various types of challenging optimization problems. We apply a newly proposed
nature-inspired metaheuristic algorithm called competitive swarm optimizer with
mutated agents (CSO-MA) and demonstrate its flexibility and out-performance
relative to its competitors in a variety of optimization problems in the
statistical sciences. In particular, we show the algorithm is efficient and can
incorporate various cost structures or multiple user-specified nonlinear
constraints. Our applications include (i) finding maximum likelihood estimates
of parameters in a single cell generalized trend model to study pseudotime in
bioinformatics, (ii) estimating parameters in a commonly used Rasch model in
education research, (iii) finding M-estimates for a Cox regression in a Markov
renewal model and (iv) matrix completion to impute missing values in a two
compartment model. In addition we discuss applications to (v) select variables
optimally in an ecology problem and (vi) design a car refueling experiment for
the auto industry using a logistic model with multiple interacting factors.
</p>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10882" title="Abstract">arXiv:2308.10882</a> [<a href="/pdf/2308.10882" title="Download PDF">pdf</a>, <a href="/format/2308.10882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Giraffe: Adventures in Expanding Context Lengths in LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pal%2C+A">Arka Pal</a>, 
<a href="/search/cs?searchtype=author&query=Karkhanis%2C+D">Deep Karkhanis</a>, 
<a href="/search/cs?searchtype=author&query=Roberts%2C+M">Manley Roberts</a>, 
<a href="/search/cs?searchtype=author&query=Dooley%2C+S">Samuel Dooley</a>, 
<a href="/search/cs?searchtype=author&query=Sundararajan%2C+A">Arvind Sundararajan</a>, 
<a href="/search/cs?searchtype=author&query=Naidu%2C+S">Siddartha Naidu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Modern large language models (LLMs) that rely on attention mechanisms are
typically trained with fixed context lengths which enforce upper limits on the
length of input sequences that they can handle at evaluation time. To use these
models on sequences longer than the train-time context length, one might employ
techniques from the growing family of context length extrapolation methods --
most of which focus on modifying the system of positional encodings used in the
attention mechanism to indicate where tokens or activations are located in the
input sequence. We conduct a wide survey of existing methods of context length
extrapolation on a base LLaMA or LLaMA 2 model, and introduce some of our own
design as well -- in particular, a new truncation strategy for modifying the
basis for the position encoding.
<br />We test these methods using three new evaluation tasks (FreeFormQA,
AlteredNumericQA, and LongChat-Lines) as well as perplexity, which we find to
be less fine-grained as a measure of long context performance of LLMs. We
release the three tasks publicly as datasets on HuggingFace. We discover that
linear scaling is the best method for extending context length, and show that
further gains can be achieved by using longer scales at evaluation time. We
also discover promising extrapolation capabilities in the truncated basis. To
support further research in this area, we release three new 13B parameter
long-context models which we call Giraffe: 4k and 16k context models trained
from base LLaMA-13B, and a 32k context model trained from base LLaMA2-13B. We
also release the code to replicate our results.
</p>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10883" title="Abstract">arXiv:2308.10883</a> [<a href="/pdf/2308.10883" title="Download PDF">pdf</a>, <a href="/ps/2308.10883" title="Download PostScript">ps</a>, <a href="/format/2308.10883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Symmetric Private Information Retrieval with Secure Storage and  Eavesdroppers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aytekin%2C+A">Alptug Aytekin</a>, 
<a href="/search/cs?searchtype=author&query=Nomeir%2C+M">Mohamed Nomeir</a>, 
<a href="/search/cs?searchtype=author&query=Vithana%2C+S">Sajani Vithana</a>, 
<a href="/search/cs?searchtype=author&query=Ulukus%2C+S">Sennur Ulukus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR); Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP); Quantum Physics (quant-ph)

</div>
<p class="mathjax">We consider both the classical and quantum variations of $X$-secure,
$E$-eavesdropped and $T$-colluding symmetric private information retrieval
(SPIR). This is the first work to study SPIR with $X$-security in classical or
quantum variations. We first develop a scheme for classical $X$-secure,
$E$-eavesdropped and $T$-colluding SPIR (XSETSPIR) based on a modified version
of cross subspace alignment (CSA), which achieves a rate of $R= 1 -
\frac{X+\max(T,E)}{N}$. The modified scheme achieves the same rate as the
scheme used for $X$-secure PIR with the extra benefit of symmetric privacy.
Next, we extend this scheme to its quantum counterpart based on the $N$-sum box
abstraction. This is the first work to consider the presence of eavesdroppers
in quantum private information retrieval (QPIR). In the quantum variation, the
eavesdroppers have better access to information over the quantum channel
compared to the classical channel due to the over-the-air decodability. To that
end, we develop another scheme specialized to combat eavesdroppers over quantum
channels. The scheme proposed for $X$-secure, $E$-eavesdropped and
$T$-colluding quantum SPIR (XSETQSPIR) in this work maintains the super-dense
coding gain from the shared entanglement between the databases, i.e., achieves
a rate of $R_Q = \min\left\{ 1, 2\left(1-\frac{X+\max(T,E)}{N}\right)\right\}$.
</p>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10888" title="Abstract">arXiv:2308.10888</a> [<a href="/pdf/2308.10888" title="Download PDF">pdf</a>, <a href="/format/2308.10888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unlocking Accuracy and Fairness in Differentially Private Image  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berrada%2C+L">Leonard Berrada</a>, 
<a href="/search/cs?searchtype=author&query=De%2C+S">Soham De</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J+H">Judy Hanwen Shen</a>, 
<a href="/search/cs?searchtype=author&query=Hayes%2C+J">Jamie Hayes</a>, 
<a href="/search/cs?searchtype=author&query=Stanforth%2C+R">Robert Stanforth</a>, 
<a href="/search/cs?searchtype=author&query=Stutz%2C+D">David Stutz</a>, 
<a href="/search/cs?searchtype=author&query=Kohli%2C+P">Pushmeet Kohli</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+S+L">Samuel L. Smith</a>, 
<a href="/search/cs?searchtype=author&query=Balle%2C+B">Borja Balle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY)

</div>
<p class="mathjax">Privacy-preserving machine learning aims to train models on private data
without leaking sensitive information. Differential privacy (DP) is considered
the gold standard framework for privacy-preserving training, as it provides
formal privacy guarantees. However, compared to their non-private counterparts,
models trained with DP often have significantly reduced accuracy. Private
classifiers are also believed to exhibit larger performance disparities across
subpopulations, raising fairness concerns. The poor performance of classifiers
trained with DP has prevented the widespread adoption of privacy preserving
machine learning in industry. Here we show that pre-trained foundation models
fine-tuned with DP can achieve similar accuracy to non-private classifiers,
even in the presence of significant distribution shifts between pre-training
data and downstream tasks. We achieve private accuracies within a few percent
of the non-private state of the art across four datasets, including two medical
imaging benchmarks. Furthermore, our private medical classifiers do not exhibit
larger performance disparities across demographic groups than non-private
models. This milestone to make DP training a practical and reliable technology
has the potential to widely enable machine learning practitioners to train
safely on sensitive datasets while protecting individuals' privacy.
</p>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10892" title="Abstract">arXiv:2308.10892</a> [<a href="/pdf/2308.10892" title="Download PDF">pdf</a>, <a href="/format/2308.10892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian polynomial neural networks and polynomial neural ordinary  differential equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fronk%2C+C">Colby Fronk</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+J">Jaewoong Yun</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+P">Prashant Singh</a>, 
<a href="/search/cs?searchtype=author&query=Petzold%2C+L">Linda Petzold</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">Symbolic regression with polynomial neural networks and polynomial neural
ordinary differential equations (ODEs) are two recent and powerful approaches
for equation recovery of many science and engineering problems. However, these
methods provide point estimates for the model parameters and are currently
unable to accommodate noisy data. We address this challenge by developing and
validating the following Bayesian inference methods: the Laplace approximation,
Markov Chain Monte Carlo (MCMC) sampling methods, and variational inference. We
have found the Laplace approximation to be the best method for this class of
problems. Our work can be easily extended to the broader class of symbolic
neural networks to which the polynomial neural network belongs.
</p>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10893" title="Abstract">arXiv:2308.10893</a> [<a href="/pdf/2308.10893" title="Download PDF">pdf</a>, <a href="/format/2308.10893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Transition-Based Feature Generation for Anomaly Detection in  Concurrent Data Streams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yinzheng Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Lisitsa%2C+A">Alexei Lisitsa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Databases (cs.DB)

</div>
<p class="mathjax">In this paper, we introduce the transition-based feature generator (TFGen)
technique, which reads general activity data with attributes and generates
step-by-step generated data. The activity data may consist of network activity
from packets, system calls from processes or classified activity from
surveillance cameras. TFGen processes data online and will generate data with
encoded historical data for each incoming activity with high computational
efficiency. The input activities may concurrently originate from distinct
traces or channels. The technique aims to address issues such as
domain-independent applicability, the ability to discover global process
structures, the encoding of time-series data, and online processing capability.
</p>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10896" title="Abstract">arXiv:2308.10896</a> [<a href="/pdf/2308.10896" title="Download PDF">pdf</a>, <a href="/format/2308.10896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Shadow Mapping for Efficient Inverse Graphics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Worchel%2C+M">Markus Worchel</a>, 
<a href="/search/cs?searchtype=author&query=Alexa%2C+M">Marc Alexa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2023, project page: <a href="https://mworchel.github.io/differentiable-shadow-mapping">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We show how shadows can be efficiently generated in differentiable rendering
of triangle meshes. Our central observation is that pre-filtered shadow
mapping, a technique for approximating shadows based on rendering from the
perspective of a light, can be combined with existing differentiable
rasterizers to yield differentiable visibility information. We demonstrate at
several inverse graphics problems that differentiable shadow maps are orders of
magnitude faster than differentiable light transport simulation with similar
accuracy -- while differentiable rasterization without shadows often fails to
converge.
</p>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10897" title="Abstract">arXiv:2308.10897</a> [<a href="/pdf/2308.10897" title="Download PDF">pdf</a>, <a href="/format/2308.10897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Language Models Learn to Listen?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ng%2C+E">Evonne Ng</a>, 
<a href="/search/cs?searchtype=author&query=Subramanian%2C+S">Sanjay Subramanian</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+D">Dan Klein</a>, 
<a href="/search/cs?searchtype=author&query=Kanazawa%2C+A">Angjoo Kanazawa</a>, 
<a href="/search/cs?searchtype=author&query=Darrell%2C+T">Trevor Darrell</a>, 
<a href="/search/cs?searchtype=author&query=Ginosar%2C+S">Shiry Ginosar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023; Project page: <a href="https://people.eecs.berkeley.edu/~evonne_ng/projects/text2listen/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a framework for generating appropriate facial responses from a
listener in dyadic social interactions based on the speaker's words. Given an
input transcription of the speaker's words with their timestamps, our approach
autoregressively predicts a response of a listener: a sequence of listener
facial gestures, quantized using a VQ-VAE. Since gesture is a language
component, we propose treating the quantized atomic motion elements as
additional language token inputs to a transformer-based large language model.
Initializing our transformer with the weights of a language model pre-trained
only on text results in significantly higher quality listener responses than
training a transformer from scratch. We show that our generated listener motion
is fluent and reflective of language semantics through quantitative metrics and
a qualitative user study. In our evaluation, we analyze the model's ability to
utilize temporal and semantic aspects of spoken text. Project page:
https://people.eecs.berkeley.edu/~evonne_ng/projects/text2listen/
</p>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10898" title="Abstract">arXiv:2308.10898</a> [<a href="/pdf/2308.10898" title="Download PDF">pdf</a>, <a href="/format/2308.10898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-Shot Physically-Aware Articulated Mesh Generation via Hierarchical  Deformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xueyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">He Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+L">Li Yi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023. Project Page: <a href="https://meowuu7.github.io/few-arti-obj-gen">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Conference on Computer Vision (ICCV) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">We study the problem of few-shot physically-aware articulated mesh
generation. By observing an articulated object dataset containing only a few
examples, we wish to learn a model that can generate diverse meshes with high
visual fidelity and physical validity. Previous mesh generative models either
have difficulties in depicting a diverse data space from only a few examples or
fail to ensure physical validity of their samples. Regarding the above
challenges, we propose two key innovations, including 1) a hierarchical mesh
deformation-based generative model based upon the divide-and-conquer philosophy
to alleviate the few-shot challenge by borrowing transferrable deformation
patterns from large scale rigid meshes and 2) a physics-aware deformation
correction scheme to encourage physically plausible generations. We conduct
extensive experiments on 6 articulated categories to demonstrate the
superiority of our method in generating articulated meshes with better
diversity, higher visual fidelity, and better physical validity over previous
methods in the few-shot setting. Further, we validate solid contributions of
our two innovations in the ablation study. Project page with code is available
at https://meowuu7.github.io/few-arti-obj-gen.
</p>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10899" title="Abstract">arXiv:2308.10899</a> [<a href="/pdf/2308.10899" title="Download PDF">pdf</a>, <a href="/format/2308.10899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TADA! Text to Animatable Digital Avatars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+T">Tingting Liao</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+H">Hongwei Yi</a>, 
<a href="/search/cs?searchtype=author&query=Xiu%2C+Y">Yuliang Xiu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiaxaing Tang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yangyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Thies%2C+J">Justus Thies</a>, 
<a href="/search/cs?searchtype=author&query=Black%2C+M+J">Michael J. Black</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">We introduce TADA, a simple-yet-effective approach that takes textual
descriptions and produces expressive 3D avatars with high-quality geometry and
lifelike textures, that can be animated and rendered with traditional graphics
pipelines. Existing text-based character generation methods are limited in
terms of geometry and texture quality, and cannot be realistically animated due
to inconsistent alignment between the geometry and the texture, particularly in
the face region. To overcome these limitations, TADA leverages the synergy of a
2D diffusion model and an animatable parametric body model. Specifically, we
derive an optimizable high-resolution body model from SMPL-X with 3D
displacements and a texture map, and use hierarchical rendering with score
distillation sampling (SDS) to create high-quality, detailed, holistic 3D
avatars from text. To ensure alignment between the geometry and texture, we
render normals and RGB images of the generated character and exploit their
latent embeddings in the SDS training process. We further introduce various
expression parameters to deform the generated character during training,
ensuring that the semantics of our generated character remain consistent with
the original SMPL-X model, resulting in an animatable character. Comprehensive
evaluations demonstrate that TADA significantly surpasses existing approaches
on both qualitative and quantitative measures. TADA enables creation of
large-scale digital character assets that are ready for animation and
rendering, while also being easily editable through natural language. The code
will be public for research purposes.
</p>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10901" title="Abstract">arXiv:2308.10901</a> [<a href="/pdf/2308.10901" title="Download PDF">pdf</a>, <a href="/format/2308.10901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structured World Models from Human Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mendonca%2C+R">Russell Mendonca</a>, 
<a href="/search/cs?searchtype=author&query=Bahl%2C+S">Shikhar Bahl</a>, 
<a href="/search/cs?searchtype=author&query=Pathak%2C+D">Deepak Pathak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> RSS 2023. Website at <a href="https://human-world-model.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">We tackle the problem of learning complex, general behaviors directly in the
real world. We propose an approach for robots to efficiently learn manipulation
skills using only a handful of real-world interaction trajectories from many
different settings. Inspired by the success of learning from large-scale
datasets in the fields of computer vision and natural language, our belief is
that in order to efficiently learn, a robot must be able to leverage
internet-scale, human video data. Humans interact with the world in many
interesting ways, which can allow a robot to not only build an understanding of
useful actions and affordances but also how these actions affect the world for
manipulation. Our approach builds a structured, human-centric action space
grounded in visual affordances learned from human videos. Further, we train a
world model on human videos and fine-tune on a small amount of robot
interaction data without any task supervision. We show that this approach of
affordance-space world models enables different robots to learn various
manipulation skills in complex settings, in under 30 minutes of interaction.
Videos can be found at https://human-world-model.github.io
</p>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10902" title="Abstract">arXiv:2308.10902</a> [<a href="/pdf/2308.10902" title="Download PDF">pdf</a>, <a href="/format/2308.10902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CamP: Camera Preconditioning for Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+K">Keunhong Park</a>, 
<a href="/search/cs?searchtype=author&query=Henzler%2C+P">Philipp Henzler</a>, 
<a href="/search/cs?searchtype=author&query=Mildenhall%2C+B">Ben Mildenhall</a>, 
<a href="/search/cs?searchtype=author&query=Barron%2C+J+T">Jonathan T. Barron</a>, 
<a href="/search/cs?searchtype=author&query=Martin-Brualla%2C+R">Ricardo Martin-Brualla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGGRAPH Asia 2023, Project page: <a href="https://camp-nerf.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Neural Radiance Fields (NeRF) can be optimized to obtain high-fidelity 3D
scene reconstructions of objects and large-scale scenes. However, NeRFs require
accurate camera parameters as input -- inaccurate camera parameters result in
blurry renderings. Extrinsic and intrinsic camera parameters are usually
estimated using Structure-from-Motion (SfM) methods as a pre-processing step to
NeRF, but these techniques rarely yield perfect estimates. Thus, prior works
have proposed jointly optimizing camera parameters alongside a NeRF, but these
methods are prone to local minima in challenging settings. In this work, we
analyze how different camera parameterizations affect this joint optimization
problem, and observe that standard parameterizations exhibit large differences
in magnitude with respect to small perturbations, which can lead to an
ill-conditioned optimization problem. We propose using a proxy problem to
compute a whitening transform that eliminates the correlation between camera
parameters and normalizes their effects, and we propose to use this transform
as a preconditioner for the camera parameters during joint optimization. Our
preconditioned camera optimization significantly improves reconstruction
quality on scenes from the Mip-NeRF 360 dataset: we reduce error rates (RMSE)
by 67% compared to state-of-the-art NeRF approaches that do not optimize for
cameras like Zip-NeRF, and by 29% relative to state-of-the-art joint
optimization approaches using the camera parameterization of SCNeRF. Our
approach is easy to implement, does not significantly increase runtime, can be
applied to a wide variety of camera parameterizations, and can
straightforwardly be incorporated into other NeRF-like models.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Tue, 22 Aug 23</h3>
<dl>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09655" title="Abstract">arXiv:2308.09655</a> (cross-list from math.DS) [<a href="/pdf/2308.09655" title="Download PDF">pdf</a>, <a href="/format/2308.09655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Oscillatory networks: Insights from piecewise-linear modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Coombes%2C+S">Stephen Coombes</a>, 
<a href="/search/math?searchtype=author&query=Sayli%2C+M">Mustafa Sayli</a>, 
<a href="/search/math?searchtype=author&query=Thul%2C+R">R&#xfc;diger Thul</a>, 
<a href="/search/math?searchtype=author&query=Nicks%2C+R">Rachel Nicks</a>, 
<a href="/search/math?searchtype=author&query=Porter%2C+M+A">Mason A Porter</a>, 
<a href="/search/math?searchtype=author&query=Lai%2C+Y+M">Yi Ming Lai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 63 pages, 26 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Systems and Control (eess.SY); Adaptation and Self-Organizing Systems (nlin.AO); Physics and Society (physics.soc-ph); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">There is enormous interest -- both mathematically and in diverse applications
-- in understanding the dynamics of coupled oscillator networks. The real-world
motivation of such networks arises from studies of the brain, the heart,
ecology, and more. It is common to describe the rich emergent behavior in these
systems in terms of complex patterns of network activity that reflect both the
connectivity and the nonlinear dynamics of the network components. Such
behavior is often organized around phase-locked periodic states and their
instabilities. However, the explicit calculation of periodic orbits in
nonlinear systems (even in low dimensions) is notoriously hard, so
network-level insights often require the numerical construction of some
underlying periodic component. In this paper, we review powerful techniques for
studying coupled oscillator networks. We discuss phase reductions,
phase-amplitude reductions, and the master stability function for smooth
dynamical systems. We then focus in particular on the augmentation of these
methods to analyze piecewise-linear systems, for which one can readily
construct periodic orbits. This yields useful insights into network behavior,
but the cost is that one needs to study nonsmooth dynamical systems. The study
of nonsmooth systems is well-developed when focusing on the interacting units
(i.e., at the node level) of a system, and we give a detailed presentation of
how to use \textit{saltation operators}, which can treat the propagation of
perturbations through switching manifolds, to understand dynamics and
bifurcations at the network level. We illustrate this merger of tools and
techniques from network science and nonsmooth dynamical systems with
applications to neural systems, cardiac systems, networks of electro-mechanical
oscillators, and cooperation in cattle herds.
</p>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09725" title="Abstract">arXiv:2308.09725</a> (cross-list from q-bio.GN) [<a href="/pdf/2308.09725" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MoCLIM: Towards Accurate Cancer Subtyping via Multi-Omics Contrastive  Learning with Omics-Inference Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Yang%2C+Z">Ziwei Yang</a>, 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+Z">Zheng Chen</a>, 
<a href="/search/q-bio?searchtype=author&query=Matsubara%2C+Y">Yasuko Matsubara</a>, 
<a href="/search/q-bio?searchtype=author&query=Sakurai%2C+Y">Yasushi Sakurai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CIKM'23 Long/Full Papers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Precision medicine fundamentally aims to establish causality between
dysregulated biochemical mechanisms and cancer subtypes. Omics-based cancer
subtyping has emerged as a revolutionary approach, as different level of omics
records the biochemical products of multistep processes in cancers. This paper
focuses on fully exploiting the potential of multi-omics data to improve cancer
subtyping outcomes, and hence developed MoCLIM, a representation learning
framework. MoCLIM independently extracts the informative features from distinct
omics modalities. Using a unified representation informed by contrastive
learning of different omics modalities, we can well-cluster the subtypes, given
cancer, into a lower latent space. This contrast can be interpreted as a
projection of inter-omics inference observed in biological networks.
Experimental results on six cancer datasets demonstrate that our approach
significantly improves data fit and subtyping performance in fewer
high-dimensional cancer instances. Moreover, our framework incorporates various
medical evaluations as the final component, providing high interpretability in
medical analysis.
</p>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09730" title="Abstract">arXiv:2308.09730</a> (cross-list from eess.IV) [<a href="/pdf/2308.09730" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data diversity and virtual imaging in AI-based diagnosis: A case study  based on COVID-19
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tushar%2C+F+I">Fakrul Islam Tushar</a>, 
<a href="/search/eess?searchtype=author&query=Dahal%2C+L">Lavsen Dahal</a>, 
<a href="/search/eess?searchtype=author&query=Sotoudeh-Paima%2C+S">Saman Sotoudeh-Paima</a>, 
<a href="/search/eess?searchtype=author&query=Abadi%2C+E">Ehsan Abadi</a>, 
<a href="/search/eess?searchtype=author&query=Segars%2C+W+P">W. Paul Segars</a>, 
<a href="/search/eess?searchtype=author&query=Samei%2C+E">Ehsan Samei</a>, 
<a href="/search/eess?searchtype=author&query=Lo%2C+J+Y">Joseph Y. Lo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 tables, 4 figures, 1 Supplement
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Many studies have investigated deep-learning-based artificial intelligence
(AI) models for medical imaging diagnosis of the novel coronavirus (COVID-19),
with many reports of near-perfect performance. However, variability in
performance and underlying data biases raise concerns about clinical
generalizability. This retrospective study involved the development and
evaluation of artificial intelligence (AI) models for COVID-19 diagnosis using
both diverse clinical and virtually generated medical images. In addition, we
conducted a virtual imaging trial to assess how AI performance is affected by
several patient- and physics-based factors, including the extent of disease,
radiation dose, and imaging modality of computed tomography (CT) and chest
radiography (CXR). AI performance was strongly influenced by dataset
characteristics including quantity, diversity, and prevalence, leading to poor
generalization with up to 20% drop in receiver operating characteristic area
under the curve. Model performance on virtual CT and CXR images was comparable
to overall results on clinical data. Imaging dose proved to have negligible
influence on the results, but the extent of the disease had a marked affect. CT
results were consistently superior to those from CXR. Overall, the study
highlighted the significant impact of dataset characteristics and disease
extent on COVID assessment, and the relevance and potential role of virtual
imaging trial techniques on developing effective evaluation of AI algorithms
and facilitating translation into diagnostic practice.
</p>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09751" title="Abstract">arXiv:2308.09751</a> (cross-list from astro-ph.CO) [<a href="/pdf/2308.09751" title="Download PDF">pdf</a>, <a href="/format/2308.09751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Compression and Inference in Cosmology with Self-Supervised Machine  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Akhmetzhanova%2C+A">Aizhan Akhmetzhanova</a>, 
<a href="/search/astro-ph?searchtype=author&query=Mishra-Sharma%2C+S">Siddharth Mishra-Sharma</a>, 
<a href="/search/astro-ph?searchtype=author&query=Dvorkin%2C+C">Cora Dvorkin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 + 6 pages, 10 + 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cosmology and Nongalactic Astrophysics (astro-ph.CO)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG)

</div>
<p class="mathjax">The influx of massive amounts of data from current and upcoming cosmological
surveys necessitates compression schemes that can efficiently summarize the
data with minimal loss of information. We introduce a method that leverages the
paradigm of self-supervised machine learning in a novel manner to construct
representative summaries of massive datasets using simulation-based
augmentations. Deploying the method on hydrodynamical cosmological simulations,
we show that it can deliver highly informative summaries, which can be used for
a variety of downstream tasks, including precise and accurate parameter
inference. We demonstrate how this paradigm can be used to construct summary
representations that are insensitive to prescribed systematic effects, such as
the influence of baryonic physics. Our results indicate that self-supervised
machine learning techniques offer a promising new approach for compression of
cosmological data as well its analysis.
</p>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09769" title="Abstract">arXiv:2308.09769</a> (cross-list from stat.CO) [<a href="/pdf/2308.09769" title="Download PDF">pdf</a>, <a href="/format/2308.09769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pigeons.jl: Distributed Sampling From Intractable Distributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Surjanovic%2C+N">Nikola Surjanovic</a>, 
<a href="/search/stat?searchtype=author&query=Biron-Lattes%2C+M">Miguel Biron-Lattes</a>, 
<a href="/search/stat?searchtype=author&query=Tiede%2C+P">Paul Tiede</a>, 
<a href="/search/stat?searchtype=author&query=Syed%2C+S">Saifuddin Syed</a>, 
<a href="/search/stat?searchtype=author&query=Campbell%2C+T">Trevor Campbell</a>, 
<a href="/search/stat?searchtype=author&query=Bouchard-C%C3%B4t%C3%A9%2C+A">Alexandre Bouchard-C&#xf4;t&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation (stat.CO)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">We introduce a software package, Pigeons.jl, that provides a way to leverage
distributed computation to obtain samples from complicated probability
distributions, such as multimodal posteriors arising in Bayesian inference and
high-dimensional distributions in statistical mechanics. Pigeons.jl provides
simple APIs to perform such computations single-threaded, multi-threaded,
and/or distributed over thousands of MPI-communicating machines. In addition,
Pigeons.jl guarantees a property that we call strong parallelism invariance:
the output for a given seed is identical irrespective of the number of threads
and processes, which is crucial for scientific reproducibility and software
validation. We describe the key features of Pigeons.jl and the approach taken
to implement a distributed and randomized algorithm that satisfies strong
parallelism invariance.
</p>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09790" title="Abstract">arXiv:2308.09790</a> (cross-list from stat.ML) [<a href="/pdf/2308.09790" title="Download PDF">pdf</a>, <a href="/format/2308.09790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Two-Part Machine Learning Approach to Characterizing Network  Interference in A/B Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Yuan%2C+Y">Yuan Yuan</a>, 
<a href="/search/stat?searchtype=author&query=Altenburger%2C+K+M">Kristen M. Altenburger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 5 figures, and appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">The reliability of controlled experiments, or "A/B tests," can often be
compromised due to the phenomenon of network interference, wherein the outcome
for one unit is influenced by other units. To tackle this challenge, we propose
a machine learning-based method to identify and characterize heterogeneous
network interference. Our approach accounts for latent complex network
structures and automates the task of "exposure mapping'' determination, which
addresses the two major limitations in the existing literature. We introduce
"causal network motifs'' and employ transparent machine learning models to
establish the most suitable exposure mapping that reflects underlying network
interference patterns. Our method's efficacy has been validated through
simulations on two synthetic experiments and a real-world, large-scale test
involving 1-2 million Instagram users, outperforming conventional methods such
as design-based cluster randomization and analysis-based neighborhood exposure
mapping. Overall, our approach not only offers a comprehensive, automated
solution for managing network interference and improving the precision of A/B
testing results, but it also sheds light on users' mutual influence and aids in
the refinement of marketing strategies.
</p>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09818" title="Abstract">arXiv:2308.09818</a> (cross-list from econ.GN) [<a href="/pdf/2308.09818" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Paths to Influence: How Coordinated Influence Operations Affect the  Prominence of Ideas
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Linvill%2C+D+L">Darren L. Linvill</a>, 
<a href="/search/econ?searchtype=author&query=Warren%2C+P+L">Patrick L. Warren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">This paper presents four examples of different ways that coordinated
influence operations exert pressure on the prominence of ideas on social
networks. We argue that these examples illustrate the four archetypical paths
to influence: promotion by strengthening, promotion by weakening, demotion by
strengthening, and demotion by weakening. We formalize this idea in a stylized
economic model of the optimal behavior of the influence operator and derive
some predictions about when we should expect each path to be followed. Finally
we sketch out how one might go about quantitatively estimating the key
parameters of (a variant of) this model and how it applies much more broadly
than in the international political influence examples that motivate it.
</p>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09831" title="Abstract">arXiv:2308.09831</a> (cross-list from eess.IV) [<a href="/pdf/2308.09831" title="Download PDF">pdf</a>, <a href="/format/2308.09831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-modality Attention-based Multimodal Fusion for Non-small Cell Lung  Cancer (NSCLC) Patient Survival Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Deng%2C+R">Ruining Deng</a>, 
<a href="/search/eess?searchtype=author&query=Shaikh%2C+N">Nazim Shaikh</a>, 
<a href="/search/eess?searchtype=author&query=Shannon%2C+G">Gareth Shannon</a>, 
<a href="/search/eess?searchtype=author&query=Nie%2C+Y">Yao Nie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Cancer prognosis and survival outcome predictions are crucial for therapeutic
response estimation and for stratifying patients into various treatment groups.
Medical domains concerned with cancer prognosis are abundant with multiple
modalities, including pathological image data and non-image data such as
genomic information. To date, multimodal learning has shown potential to
enhance clinical prediction model performance by extracting and aggregating
information from different modalities of the same subject. This approach could
outperform single modality learning, thus improving computer-aided diagnosis
and prognosis in numerous medical applications. In this work, we propose a
cross-modality attention-based multimodal fusion pipeline designed to integrate
modality-specific knowledge for patient survival prediction in non-small cell
lung cancer (NSCLC). Instead of merely concatenating or summing up the features
from different modalities, our method gauges the importance of each modality
for feature fusion with cross-modality relationship when infusing the
multimodal features. Compared with single modality, which achieved c-index of
0.5772 and 0.5885 using solely tissue image data or RNA-seq data, respectively,
the proposed fusion approach achieved c-index 0.6587 in our experiment,
showcasing the capability of assimilating modality-specific knowledge from
varied modalities.
</p>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09888" title="Abstract">arXiv:2308.09888</a> (cross-list from stat.ML) [<a href="/pdf/2308.09888" title="Download PDF">pdf</a>, <a href="/format/2308.09888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Estimating the Gradient of the Expected Information Gain in Bayesian  Experimental Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ao%2C+Z">Ziqiao Ao</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+J">Jinglai Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Bayesian Experimental Design (BED), which aims to find the optimal
experimental conditions for Bayesian inference, is usually posed as to optimize
the expected information gain (EIG). The gradient information is often needed
for efficient EIG optimization, and as a result the ability to estimate the
gradient of EIG is essential for BED problems. The primary goal of this work is
to develop methods for estimating the gradient of EIG, which, combined with the
stochastic gradient descent algorithms, result in efficient optimization of
EIG. Specifically, we first introduce a posterior expected representation of
the EIG gradient with respect to the design variables. Based on this, we
propose two methods for estimating the EIG gradient, UEEG-MCMC that leverages
posterior samples generated through Markov Chain Monte Carlo (MCMC) to estimate
the EIG gradient, and BEEG-AP that focuses on achieving high simulation
efficiency by repeatedly using parameter samples. Theoretical analysis and
numerical studies illustrate that UEEG-MCMC is robust agains the actual EIG
value, while BEEG-AP is more efficient when the EIG value to be optimized is
small. Moreover, both methods show superior performance compared to several
popular benchmarks in our numerical experiments.
</p>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09912" title="Abstract">arXiv:2308.09912</a> (cross-list from math.OC) [<a href="/pdf/2308.09912" title="Download PDF">pdf</a>, <a href="/format/2308.09912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complexity Guarantees for Nonconvex Newton-MR Under Inexact Hessian  Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lim%2C+A">Alexander Lim</a>, 
<a href="/search/math?searchtype=author&query=Roosta%2C+F">Fred Roosta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We consider extensions of the Newton-MR algorithm for nonconvex optimization
to the settings where Hessian information is approximated. Under additive noise
model on the Hessian matrix, we investigate the iteration and operation
complexities of these variants to achieve first and second-order sub-optimality
criteria. We show that, under certain conditions, the algorithms achieve
iteration and operation complexities that match those of the exact variant.
Focusing on the particular nonconvex problems satisfying Polyak-\L ojasiewicz
condition, we show that our algorithm achieves a linear convergence rate. We
finally compare the performance of our algorithms with several alternatives on
a few machine learning problems.
</p>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09929" title="Abstract">arXiv:2308.09929</a> (cross-list from eess.SP) [<a href="/pdf/2308.09929" title="Download PDF">pdf</a>, <a href="/format/2308.09929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RIS-assisted High-Speed Railway Integrated Sensing and Communication  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+P">Panpan Li</a>, 
<a href="/search/eess?searchtype=author&query=Niu%2C+Y">Yong Niu</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+H">Hao Wu</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+Z">Zhu Han</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+G">Guiqi Sun</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+N">Ning Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhong%2C+Z">Zhangdui Zhong</a>, 
<a href="/search/eess?searchtype=author&query=Ai%2C+B">Bo Ai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">One technology that has the potential to improve wireless communications in
years to come is integrated sensing and communication (ISAC). In this study, we
take advantage of reconfigurable intelligent surface's (RIS) potential
advantages to achieve ISAC while using the same frequency and resources.
Specifically, by using the reflecting elements, the RIS dynamically modifies
the radio waves' strength or phase in order to change the environment for radio
transmission and increase the ISAC systems' transmission rate. We investigate a
single cell downlink communication situation with RIS assistance. Combining the
ISAC base station's (BS) beamforming with RIS's discrete phase shift
optimization, while guaranteeing the sensing signal, The aim of optimizing the
sum rate is specified. We take advantage of alternating maximization to find
practical solutions with dividing the challenge into two minor issues. The
first power allocation subproblem is non-convex that CVX solves by converting
it to convex. A local search strategy is used to solve the second subproblem of
phase shift optimization. According to the results of the simulation, using RIS
with adjusted phase shifts can significantly enhance the ISAC system's
performance.
</p>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09945" title="Abstract">arXiv:2308.09945</a> (cross-list from eess.IV) [<a href="/pdf/2308.09945" title="Download PDF">pdf</a>, <a href="/format/2308.09945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual Branch Deep Learning Network for Detection and Stage Grading of  Diabetic Retinopathy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shakibania%2C+H">Hossein Shakibania</a>, 
<a href="/search/eess?searchtype=author&query=Raoufi%2C+S">Sina Raoufi</a>, 
<a href="/search/eess?searchtype=author&query=Pourafkham%2C+B">Behnam Pourafkham</a>, 
<a href="/search/eess?searchtype=author&query=Khotanlou%2C+H">Hassan Khotanlou</a>, 
<a href="/search/eess?searchtype=author&query=Mansoorizadeh%2C+M">Muharram Mansoorizadeh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Elsevier
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Diabetic retinopathy is a severe complication of diabetes that can lead to
permanent blindness if not treated promptly. Early and accurate diagnosis of
the disease is essential for successful treatment. This paper introduces a deep
learning method for the detection and stage grading of diabetic retinopathy,
using a single fundus retinal image. Our model utilizes transfer learning,
employing two state-of-the-art pre-trained models as feature extractors and
fine-tuning them on a new dataset. The proposed model is trained on a large
multi-center dataset, including the APTOS 2019 dataset, obtained from publicly
available sources. It achieves remarkable performance in diabetic retinopathy
detection and stage classification on the APTOS 2019, outperforming the
established literature. For binary classification, the proposed approach
achieves an accuracy of 98.50%, a sensitivity of 99.46%, and a specificity of
97.51%. In stage grading, it achieves a quadratic weighted kappa of 93.00%, an
accuracy of 89.60%, a sensitivity of 89.60%, and a specificity of 97.72%. The
proposed approach serves as a reliable screening and stage grading tool for
diabetic retinopathy, offering significant potential to enhance clinical
decision-making and patient care.
</p>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09952" title="Abstract">arXiv:2308.09952</a> (cross-list from physics.soc-ph) [<a href="/pdf/2308.09952" title="Download PDF">pdf</a>, <a href="/format/2308.09952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding emergence in data: causal emergence inspired dynamics learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Yang%2C+M">Mingzhe Yang</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+Z">Zhipeng Wang</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+K">Kaiwei Liu</a>, 
<a href="/search/physics?searchtype=author&query=Rong%2C+Y">Yingqi Rong</a>, 
<a href="/search/physics?searchtype=author&query=Yuan%2C+B">Bing Yuan</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+J">Jiang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Modelling complex dynamical systems in a data-driven manner is challenging
due to the presence of emergent behaviors and properties that cannot be
directly captured by micro-level observational data. Therefore, it is crucial
to develop a model that can effectively capture emergent dynamics at the
macro-level and quantify emergence based on the available data. Drawing
inspiration from the theory of causal emergence, this paper introduces a
machine learning framework aimed at learning macro-dynamics within an emergent
latent space. The framework achieves this by maximizing the effective
information (EI) to obtain a macro-dynamics model with stronger causal effects.
Experimental results on both simulated and real data demonstrate the
effectiveness of the proposed framework. Not only does it successfully capture
emergent patterns, but it also learns the coarse-graining strategy and
quantifies the degree of causal emergence in the data. Furthermore, experiments
conducted on environments different from the training dataset highlight the
superior generalization ability of our model.
</p>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10014" title="Abstract">arXiv:2308.10014</a> (cross-list from stat.ML) [<a href="/pdf/2308.10014" title="Download PDF">pdf</a>, <a href="/format/2308.10014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Implicit Variational Inference via Score Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Yu%2C+L">Longlin Yu</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+C">Cheng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 8 figures; ICLR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Semi-implicit variational inference (SIVI) greatly enriches the
expressiveness of variational families by considering implicit variational
distributions defined in a hierarchical manner. However, due to the intractable
densities of variational distributions, current SIVI approaches often use
surrogate evidence lower bounds (ELBOs) or employ expensive inner-loop MCMC
runs for unbiased ELBOs for training. In this paper, we propose SIVI-SM, a new
method for SIVI based on an alternative training objective via score matching.
Leveraging the hierarchical structure of semi-implicit variational families,
the score matching objective allows a minimax formulation where the intractable
variational densities can be naturally handled with denoising score matching.
We show that SIVI-SM closely matches the accuracy of MCMC and outperforms
ELBO-based SIVI methods in a variety of Bayesian inference tasks.
</p>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10021" title="Abstract">arXiv:2308.10021</a> (cross-list from eess.AS) [<a href="/pdf/2308.10021" title="Download PDF">pdf</a>, <a href="/format/2308.10021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effects of Convolutional Autoencoder Bottleneck Width on StarGAN-based  Singing Technique Conversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Su%2C+T">Tung-Cheng Su</a>, 
<a href="/search/eess?searchtype=author&query=Chang%2C+Y">Yung-Chuan Chang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yi-Wen Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The original edition of this paper will be published in the CMMR 2023 Proceedings. This ArXiv publication is a copy
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">Singing technique conversion (STC) refers to the task of converting from one
voice technique to another while leaving the original singer identity, melody,
and linguistic components intact. Previous STC studies, as well as singing
voice conversion research in general, have utilized convolutional autoencoders
(CAEs) for conversion, but how the bottleneck width of the CAE affects the
synthesis quality has not been thoroughly evaluated. To this end, we
constructed a GAN-based multi-domain STC system which took advantage of the
WORLD vocoder representation and the CAE architecture. We varied the bottleneck
width of the CAE, and evaluated the conversion results subjectively. The model
was trained on a Mandarin dataset which features four singers and four singing
techniques: the chest voice, the falsetto, the raspy voice, and the whistle
voice. The results show that a wider bottleneck corresponds to better
articulation clarity but does not necessarily lead to higher likeness to the
target technique. Among the four techniques, we also found that the whistle
voice is the easiest target for conversion, while the other three techniques as
a source produce more convincing conversion results than the whistle.
</p>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10033" title="Abstract">arXiv:2308.10033</a> (cross-list from q-bio.TO) [<a href="/pdf/2308.10033" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CRC-ICM: Colorectal Cancer Immune Cell Markers Pattern Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Mokhtari%2C+Z">Zahra Mokhtari</a>, 
<a href="/search/q-bio?searchtype=author&query=Amjadi%2C+E">Elham Amjadi</a>, 
<a href="/search/q-bio?searchtype=author&query=Bolhasani%2C+H">Hamidreza Bolhasani</a>, 
<a href="/search/q-bio?searchtype=author&query=Faghih%2C+Z">Zahra Faghih</a>, 
<a href="/search/q-bio?searchtype=author&query=Dehghanian%2C+A">AmirReza Dehghanian</a>, 
<a href="/search/q-bio?searchtype=author&query=Rezaei%2C+M">Marzieh Rezaei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Tissues and Organs (q-bio.TO)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Colorectal Cancer (CRC) is the second most common cause of cancer death in
the world, ad can be identified by the location of the primary tumor in the
large intestine: right and left colon, and rectum. Based on the location, CRC
shows differences in chromosomal and molecular characteristics, microbiomes
incidence, pathogenesis, and outcome. It has been shown that tumors on left and
right sides also have different immune landscape, so the prognosis may be
different based on the primary tumor locations. It is widely accepted that
immune components of the tumor microenvironment (TME) plays a critical role in
tumor development. One of the critical regulatory molecules in the TME is
immune checkpoints that as the gatekeepers of immune responses regulate the
infiltrated immune cell functions. Inhibitory immune checkpoints such as PD-1,
Tim3, and LAG3, as the main mechanism of immune suppression in TME
overexpressed and result in further development of the tumor. The images of
this dataset have been taken from colon tissues of patients with CRC, stained
with specific antibodies for CD3, CD8, CD45RO, PD-1, LAG3 and Tim3. The name of
this dataset is CRC-ICM and contains 1756 images related to 136 patients. The
initial version of CRC-ICM is published on Elsevier Mendeley dataset portal,
and the latest version is accessible via: https://databiox.com
</p>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10044" title="Abstract">arXiv:2308.10044</a> (cross-list from math.CO) [<a href="/pdf/2308.10044" title="Download PDF">pdf</a>, <a href="/format/2308.10044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A branch connection rule of one-way rail network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Akita%2C+D">Dai Akita</a>, 
<a href="/search/math?searchtype=author&query=Schenz%2C+D+T">Daniel Thorsten Schenz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We deal with network inspired by toy train, which is constructed by
connecting Y-shaped branches. A train passes a branch through either of
splitted rails and not allowed to go backward. Under these assumptions, we
consider unidirectionality of a rail network, that is, there is a orientation
of the rail network such that any trail of a train starting with the direction
does not contradict to the orientation. We find that a rail network is one-way
if and only if a digraph derived from the rail network is disconnected, which
is also equal to no existence of cycle which contains odd number of tracks
connecting the same side of branches.
</p>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10066" title="Abstract">arXiv:2308.10066</a> (cross-list from physics.soc-ph) [<a href="/pdf/2308.10066" title="Download PDF">pdf</a>, <a href="/format/2308.10066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vulnerability of democratic electoral systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Raducha%2C+T">Tomasz Raducha</a>, 
<a href="/search/physics?searchtype=author&query=Klamut%2C+J">Jaros&#x142;aw Klamut</a>, 
<a href="/search/physics?searchtype=author&query=Cremades%2C+R">Roger Cremades</a>, 
<a href="/search/physics?searchtype=author&query=Bouman%2C+P">Paul Bouman</a>, 
<a href="/search/physics?searchtype=author&query=Wili%C5%84ski%2C+M">Mateusz Wili&#x144;ski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">The two most common types of electoral systems (ES) used in electing national
legislatures are proportional representation and plurality voting. When they
are evaluated, most often the arguments come from social choice theory and
political sciences. The former overall uses an axiomatic approach including a
list of mathematical criteria a system should fulfill. The latter predominantly
focuses on the trade-off between proportionality of apportionment and
governability. However, there is no consensus on the best ES, nor on the set of
indexes and measures that would be the most important in such assessment.
Moreover, the ongoing debate about the fairness of national elections neglects
the study of their vulnerabilities. Here we address this research gap with a
framework that can measure electoral systems' vulnerability to different means
of influence. Using in silico analysis we show that plurality voting systems
are less stable than proportional representation. They are also more
susceptible to political agitators and media propaganda. A review of real-world
ES reveals possible improvements in their design leading to lower
susceptibility. Additionally, our simulation framework allows computation of
popular indexes, as the Gallagher index or the effective number of parties, in
different scenarios. Our work provides a new tool for dealing with modern
threats to democracy that could destabilize voting processes. Furthermore, our
results add an important argument in a long-standing discussion on evaluation
of ES.
</p>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10069" title="Abstract">arXiv:2308.10069</a> (cross-list from math.OC) [<a href="/pdf/2308.10069" title="Download PDF">pdf</a>, <a href="/format/2308.10069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time Mixed-Integer Quadratic Programming for Vehicle Decision  Making and Motion Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Quirynen%2C+R">Rien Quirynen</a>, 
<a href="/search/math?searchtype=author&query=Safaoui%2C+S">Sleiman Safaoui</a>, 
<a href="/search/math?searchtype=author&query=Di+Cairano%2C+S">Stefano Di Cairano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 11 figures, 3 tables, submitted to IEEE Transactions on Control Systems Technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We develop a real-time feasible mixed-integer programming-based decision
making (MIP-DM) system for automated driving. Using a linear vehicle model in a
road-aligned coordinate frame, the lane change constraints, collision avoidance
and traffic rules can be formulated as mixed-integer inequalities, resulting in
a mixed-integer quadratic program (MIQP). The proposed MIP-DM simultaneously
performs maneuver selection and trajectory generation by solving the MIQP at
each sampling time instant. While solving MIQPs in real time has been
considered intractable in the past, we show that our recently developed solver
BB-ASIPM is capable of solving MIP-DM problems on embedded hardware in real
time. The performance of this approach is illustrated in simulations in various
scenarios including merging points and traffic intersections, and
hardware-in-the-loop simulations on dSPACE Scalexio and MicroAutoBox-III.
Finally, we present results from hardware experiments on small-scale automated
vehicles.
</p>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10083" title="Abstract">arXiv:2308.10083</a> (cross-list from physics.comp-ph) [<a href="/pdf/2308.10083" title="Download PDF">pdf</a>, <a href="/ps/2308.10083" title="Download PostScript">ps</a>, <a href="/format/2308.10083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Poisson quadrature method of moments for 2D kinetic equations with  velocity of constant magnitude
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Chen%2C+Y">Yihong Chen</a>, 
<a href="/search/physics?searchtype=author&query=Huang%2C+Q">Qian Huang</a>, 
<a href="/search/physics?searchtype=author&query=Yong%2C+W">Wen-An Yong</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+R">Ruixi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Soft Condensed Matter (cond-mat.soft); Numerical Analysis (math.NA)

</div>
<p class="mathjax">This work is concerned with kinetic equations with velocity of constant
magnitude. We propose a quadrature method of moments based on the Poisson
kernel, called Poisson-EQMOM. The derived moment closure systems are well
defined for all physically relevant moments and the resultant approximations of
the distribution function converge as the number of moments goes to infinity.
The convergence makes our method stand out from most existing moment methods.
Moreover, we devise a delicate moment inversion algorithm. As an application,
the Vicsek model is studied for overdamped active particles. Then the
Poisson-EQMOM is validated with a series of numerical tests including spatially
homogeneous, one-dimensional and two-dimensional problems.
</p>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10098" title="Abstract">arXiv:2308.10098</a> (cross-list from math.OC) [<a href="/pdf/2308.10098" title="Download PDF">pdf</a>, <a href="/format/2308.10098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Bilevel Learning with Inexact Line Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Salehi%2C+M+S">Mohammad Sadegh Salehi</a>, 
<a href="/search/math?searchtype=author&query=Mukherjee%2C+S">Subhadip Mukherjee</a>, 
<a href="/search/math?searchtype=author&query=Roberts%2C+L">Lindon Roberts</a>, 
<a href="/search/math?searchtype=author&query=Ehrhardt%2C+M+J">Matthias J. Ehrhardt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In various domains within imaging and data science, particularly when
addressing tasks modeled utilizing the variational regularization approach,
manually configuring regularization parameters presents a formidable challenge.
The difficulty intensifies when employing regularizers involving a large number
of hyperparameters. To overcome this challenge, bilevel learning is employed to
learn suitable hyperparameters. However, due to the use of numerical solvers,
the exact gradient with respect to the hyperparameters is unattainable,
necessitating the use of methods relying on approximate gradients.
State-of-the-art inexact methods a priori select a decreasing summable sequence
of the required accuracy and only assure convergence given a sufficiently small
fixed step size. Despite this, challenges persist in determining the Lipschitz
constant of the hypergradient and identifying an appropriate fixed step size.
Conversely, computing exact function values is not feasible, impeding the use
of line search. In this work, we introduce a provably convergent inexact
backtracking line search involving inexact function evaluations and
hypergradients. We show convergence to a stationary point of the loss with
respect to hyperparameters. Additionally, we propose an algorithm to determine
the required accuracy dynamically. Our numerical experiments demonstrate the
efficiency and feasibility of our approach for hyperparameter estimation in
variational regularization problems, alongside its robustness in terms of the
initial accuracy and step size choices.
</p>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10113" title="Abstract">arXiv:2308.10113</a> (cross-list from stat.ML) [<a href="/pdf/2308.10113" title="Download PDF">pdf</a>, <a href="/format/2308.10113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Random Networks with Heterogeneous Reciprocity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Cirkovic%2C+D">Daniel Cirkovic</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+T">Tiandong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI); Applications (stat.AP); Computation (stat.CO)

</div>
<p class="mathjax">Reciprocity, or the tendency of individuals to mirror behavior, is a key
measure that describes information exchange in a social network. Users in
social networks tend to engage in different levels of reciprocal behavior.
Differences in such behavior may indicate the existence of communities that
reciprocate links at varying rates. In this paper, we develop methodology to
model the diverse reciprocal behavior in growing social networks. In
particular, we present a preferential attachment model with heterogeneous
reciprocity that imitates the attraction users have for popular users, plus the
heterogeneous nature by which they reciprocate links. We compare Bayesian and
frequentist model fitting techniques for large networks, as well as
computationally efficient variational alternatives. Cases where the number of
communities are known and unknown are both considered. We apply the presented
methods to the analysis of a Facebook wallpost network where users have
non-uniform reciprocal behavior patterns. The fitted model captures the
heavy-tailed nature of the empirical degree distributions in the Facebook data
and identifies multiple groups of users that differ in their tendency to reply
to and receive responses to wallposts.
</p>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10142" title="Abstract">arXiv:2308.10142</a> (cross-list from eess.IV) [<a href="/pdf/2308.10142" title="Download PDF">pdf</a>, <a href="/ps/2308.10142" title="Download PostScript">ps</a>, <a href="/format/2308.10142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polymerized Feature-based Domain Adaptation for Cervical Cancer Dose Map  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zeng%2C+J">Jie Zeng</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+Z">Zeyu Han</a>, 
<a href="/search/eess?searchtype=author&query=Peng%2C+X">Xingchen Peng</a>, 
<a href="/search/eess?searchtype=author&query=Xiao%2C+J">Jianghong Xiao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted and presented in ISBI 2023. To be published in Proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recently, deep learning (DL) has automated and accelerated the clinical
radiation therapy (RT) planning significantly by predicting accurate dose maps.
However, most DL-based dose map prediction methods are data-driven and not
applicable for cervical cancer where only a small amount of data is available.
To address this problem, this paper proposes to transfer the rich knowledge
learned from another cancer, i.e., rectum cancer, which has the same scanning
area and more clinically available data, to improve the dose map prediction
performance for cervical cancer through domain adaptation. In order to close
the congenital domain gap between the source (i.e., rectum cancer) and the
target (i.e., cervical cancer) domains, we develop an effective
Transformer-based polymerized feature module (PFM), which can generate an
optimal polymerized feature distribution to smoothly align the two input
distributions. Experimental results on two in-house clinical datasets
demonstrate the superiority of the proposed method compared with
state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10145" title="Abstract">arXiv:2308.10145</a> (cross-list from stat.ML) [<a href="/pdf/2308.10145" title="Download PDF">pdf</a>, <a href="/format/2308.10145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wasserstein Geodesic Generator for Conditional Distributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kim%2C+Y">Young-geun Kim</a>, 
<a href="/search/stat?searchtype=author&query=Lee%2C+K">Kyungbok Lee</a>, 
<a href="/search/stat?searchtype=author&query=Choi%2C+Y">Youngwon Choi</a>, 
<a href="/search/stat?searchtype=author&query=Won%2C+J">Joong-Ho Won</a>, 
<a href="/search/stat?searchtype=author&query=Paik%2C+M+C">Myunghee Cho Paik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Generating samples given a specific label requires estimating conditional
distributions. We derive a tractable upper bound of the Wasserstein distance
between conditional distributions to lay the theoretical groundwork to learn
conditional distributions. Based on this result, we propose a novel conditional
generation algorithm where conditional distributions are fully characterized by
a metric space defined by a statistical distance. We employ optimal transport
theory to propose the \textit{Wasserstein geodesic generator}, a new
conditional generator that learns the Wasserstein geodesic. The proposed method
learns both conditional distributions for observed domains and optimal
transport maps between them. The conditional distributions given unobserved
intermediate domains are on the Wasserstein geodesic between conditional
distributions given two observed domain labels. Experiments on face images with
light conditions as domain labels demonstrate the efficacy of the proposed
method.
</p>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10157" title="Abstract">arXiv:2308.10157</a> (cross-list from eess.IV) [<a href="/pdf/2308.10157" title="Download PDF">pdf</a>, <a href="/ps/2308.10157" title="Download PostScript">ps</a>, <a href="/format/2308.10157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Diffusion Model with Auxiliary Guidance for Coarse-to-Fine  PET Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Han%2C+Z">Zeyu Han</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yuhan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+L">Luping Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+P">Peng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+B">Binyu Yan</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+J">Jiliu Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+D">Dinggang Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted and presented in MICCAI 2023. To be published in Proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">To obtain high-quality positron emission tomography (PET) scans while
reducing radiation exposure to the human body, various approaches have been
proposed to reconstruct standard-dose PET (SPET) images from low-dose PET
(LPET) images. One widely adopted technique is the generative adversarial
networks (GANs), yet recently, diffusion probabilistic models (DPMs) have
emerged as a compelling alternative due to their improved sample quality and
higher log-likelihood scores compared to GANs. Despite this, DPMs suffer from
two major drawbacks in real clinical settings, i.e., the computationally
expensive sampling process and the insufficient preservation of correspondence
between the conditioning LPET image and the reconstructed PET (RPET) image. To
address the above limitations, this paper presents a coarse-to-fine PET
reconstruction framework that consists of a coarse prediction module (CPM) and
an iterative refinement module (IRM). The CPM generates a coarse PET image via
a deterministic process, and the IRM samples the residual iteratively. By
delegating most of the computational overhead to the CPM, the overall sampling
speed of our method can be significantly improved. Furthermore, two additional
strategies, i.e., an auxiliary guidance strategy and a contrastive diffusion
strategy, are proposed and integrated into the reconstruction process, which
can enhance the correspondence between the LPET image and the RPET image,
further improving clinical reliability. Extensive experiments on two human
brain PET datasets demonstrate that our method outperforms the state-of-the-art
PET reconstruction methods. The source code is available at
\url{https://github.com/Show-han/PET-Reconstruction}.
</p>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10192" title="Abstract">arXiv:2308.10192</a> (cross-list from eess.IV) [<a href="/pdf/2308.10192" title="Download PDF">pdf</a>, <a href="/ps/2308.10192" title="Download PostScript">ps</a>, <a href="/format/2308.10192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EDDense-Net: Fully Dense Encoder Decoder Network for Joint Segmentation  of Optic Cup and Disc
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mehmood%2C+M">Mehwish Mehmood</a>, 
<a href="/search/eess?searchtype=author&query=Naveed%2C+K">Khuram Naveed</a>, 
<a href="/search/eess?searchtype=author&query=Khan%2C+H+A">Haroon Ahmed Khan</a>, 
<a href="/search/eess?searchtype=author&query=Naqvi%2C+S+S">Syed S. Naqvi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Glaucoma is an eye disease that causes damage to the optic nerve, which can
lead to visual loss and permanent blindness. Early glaucoma detection is
therefore critical in order to avoid permanent blindness. The estimation of the
cup-to-disc ratio (CDR) during an examination of the optical disc (OD) is used
for the diagnosis of glaucoma. In this paper, we present the EDDense-Net
segmentation network for the joint segmentation of OC and OD. The encoder and
decoder in this network are made up of dense blocks with a grouped
convolutional layer in each block, allowing the network to acquire and convey
spatial information from the image while simultaneously reducing the network's
complexity. To reduce spatial information loss, the optimal number of filters
in all convolution layers were utilised. In semantic segmentation, dice pixel
classification is employed in the decoder to alleviate the problem of class
imbalance. The proposed network was evaluated on two publicly available
datasets where it outperformed existing state-of-the-art methods in terms of
accuracy and efficiency. For the diagnosis and analysis of glaucoma, this
method can be used as a second opinion system to assist medical
ophthalmologists.
</p>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10214" title="Abstract">arXiv:2308.10214</a> (cross-list from math.CO) [<a href="/pdf/2308.10214" title="Download PDF">pdf</a>, <a href="/format/2308.10214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational complexity of counting coincidences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chan%2C+S+H">Swee Hong Chan</a>, 
<a href="/search/math?searchtype=author&query=Pak%2C+I">Igor Pak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Complexity (cs.CC); Computational Geometry (cs.CG); Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Can you decide if there is a coincidence in the numbers counting two
different combinatorial objects? For example, can you decide if two regions in
$\mathbb{R}^3$ have the same number of domino tilings? There are two versions
of the problem, with $2\times 1 \times 1$ and $2\times 2 \times 1$ boxes. We
prove that in both cases the coincidence problem is not in the polynomial
hierarchy unless the polynomial hierarchy collapses to a finite level. While
the conclusions are the same, the proofs are notably different and generalize
in different directions.
<br />We proceed to explore the coincidence problem for counting independent sets
and matchings in graphs, matroid bases, order ideals and linear extensions in
posets, permutation patterns, and the Kronecker coefficients. We also make a
number of conjectures for counting other combinatorial objects such as plane
triangulations, contingency tables, standard Young tableaux, reduced
factorizations and the Littlewood--Richardson coefficients.
</p>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10230" title="Abstract">arXiv:2308.10230</a> (cross-list from eess.IV) [<a href="/pdf/2308.10230" title="Download PDF">pdf</a>, <a href="/format/2308.10230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Karma: Adaptive Video Streaming via Causal Sequence Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+B">Bowei Xu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+Z">Zhan Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Optimal adaptive bitrate (ABR) decision depends on a comprehensive
characterization of state transitions that involve interrelated modalities over
time including environmental observations, returns, and actions. However,
state-of-the-art learning-based ABR algorithms solely rely on past observations
to decide the next action. This paradigm tends to cause a chain of deviations
from optimal action when encountering unfamiliar observations, which
consequently undermines the model generalization. This paper presents Karma, an
ABR algorithm that utilizes causal sequence modeling to improve generalization
by comprehending the interrelated causality among past observations, returns,
and actions and timely refining action when deviation occurs. Unlike direct
observation-to-action mapping, Karma recurrently maintains a multi-dimensional
time series of observations, returns, and actions as input and employs causal
sequence modeling via a decision transformer to determine the next action. In
the input sequence, Karma uses the maximum cumulative future quality of
experience (QoE) (a.k.a, QoE-to-go) as an extended return signal, which is
periodically estimated based on current network conditions and playback status.
We evaluate Karma through trace-driven simulations and real-world field tests,
demonstrating superior performance compared to existing state-of-the-art ABR
algorithms, with an average QoE improvement ranging from 10.8% to 18.7% across
diverse network conditions. Furthermore, Karma exhibits strong generalization
capabilities, showing leading performance under unseen networks in both
simulations and real-world tests.
</p>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10275" title="Abstract">arXiv:2308.10275</a> (cross-list from q-bio.QM) [<a href="/pdf/2308.10275" title="Download PDF">pdf</a>, <a href="/format/2308.10275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SBSM-Pro: Support Bio-sequence Machine for Proteins
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+Y">Yizheng Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhai%2C+Y">Yixiao Zhai</a>, 
<a href="/search/q-bio?searchtype=author&query=Ding%2C+Y">Yijie Ding</a>, 
<a href="/search/q-bio?searchtype=author&query=Zou%2C+Q">Quan Zou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Proteins play a pivotal role in biological systems. The use of machine
learning algorithms for protein classification can assist and even guide
biological experiments, offering crucial insights for biotechnological
applications. We propose a support bio-sequence machine for proteins, a model
specifically designed for biological sequence classification. This model starts
with raw sequences and groups amino acids based on their physicochemical
properties. It incorporates sequence alignment to measure the similarities
between proteins and uses a novel MKL approach to integrate various types of
information, utilizing support vector machines for classification prediction.
The results indicate that our model demonstrates commendable performance across
10 datasets in terms of the identification of protein function and
posttranslational modification. This research not only showcases
state-of-the-art work in protein classification but also paves the way for new
directions in this domain, representing a beneficial endeavour in the
development of platforms tailored for biological sequence classification.
SBSM-Pro is available for access at <a href="http://lab.malab.cn/soft/SBSM-Pro/.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10281" title="Abstract">arXiv:2308.10281</a> (cross-list from eess.AS) [<a href="/pdf/2308.10281" title="Download PDF">pdf</a>, <a href="/format/2308.10281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The DKU-DUKEECE System for the Manipulation Region Location Task of ADD  2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cai%2C+Z">Zexin Cai</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+W">Weiqing Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yikang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+M">Ming Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The DKU-DukeECE system description to Task 2 of Audio Deepfake Detection Challenge (ADD 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">This paper introduces our system designed for Track 2, which focuses on
locating manipulated regions, in the second Audio Deepfake Detection Challenge
(ADD 2023). Our approach involves the utilization of multiple detection systems
to identify splicing regions and determine their authenticity. Specifically, we
train and integrate two frame-level systems: one for boundary detection and the
other for deepfake detection. Additionally, we employ a third VAE model trained
exclusively on genuine data to determine the authenticity of a given audio
clip. Through the fusion of these three systems, our top-performing solution
for the ADD challenge achieves an impressive 82.23% sentence accuracy and an F1
score of 60.66%. This results in a final ADD score of 0.6713, securing the
first rank in Track 2 of ADD 2023.
</p>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10302" title="Abstract">arXiv:2308.10302</a> (cross-list from q-bio.QM) [<a href="/pdf/2308.10302" title="Download PDF">pdf</a>, <a href="/format/2308.10302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preserving Specificity in Federated Graph Learning for fMRI-based  Neurological Disorder Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+J">Junhao Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+Q">Qianqian Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+X">Xiaochuan Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Qiao%2C+L">Lishan Qiao</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+M">Mingxia Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Resting-state functional magnetic resonance imaging (rs-fMRI) offers a
non-invasive approach to examining abnormal brain connectivity associated with
brain disorders. Graph neural network (GNN) gains popularity in fMRI
representation learning and brain disorder analysis with powerful graph
representation capabilities. Training a general GNN often necessitates a
large-scale dataset from multiple imaging centers/sites, but centralizing
multi-site data generally faces inherent challenges related to data privacy,
security, and storage burden. Federated Learning (FL) enables collaborative
model training without centralized multi-site fMRI data. Unfortunately,
previous FL approaches for fMRI analysis often ignore site-specificity,
including demographic factors such as age, gender, and education level. To this
end, we propose a specificity-aware federated graph learning (SFGL) framework
for rs-fMRI analysis and automated brain disorder identification, with a server
and multiple clients/sites for federated model aggregation and prediction. At
each client, our model consists of a shared and a personalized branch, where
parameters of the shared branch are sent to the server while those of the
personalized branch remain local. This can facilitate knowledge sharing among
sites and also helps preserve site specificity. In the shared branch, we employ
a spatio-temporal attention graph isomorphism network to learn dynamic fMRI
representations. In the personalized branch, we integrate vectorized
demographic information (i.e., age, gender, and education years) and functional
connectivity networks to preserve site-specific characteristics.
Representations generated by the two branches are then fused for
classification. Experimental results on two fMRI datasets with a total of 1,218
subjects suggest that SFGL outperforms several state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10322" title="Abstract">arXiv:2308.10322</a> (cross-list from astro-ph.SR) [<a href="/pdf/2308.10322" title="Download PDF">pdf</a>, <a href="/format/2308.10322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Homogenising SoHO/EIT and SDO/AIA 171&#xc5;$~$ Images: A Deep Learning  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Chatterjee%2C+S">Subhamoy Chatterjee</a>, 
<a href="/search/astro-ph?searchtype=author&query=Mu%C3%B1oz-Jaramillo%2C+A">Andr&#xe9;s Mu&#xf1;oz-Jaramillo</a>, 
<a href="/search/astro-ph?searchtype=author&query=Dayeh%2C+M">Maher Dayeh</a>, 
<a href="/search/astro-ph?searchtype=author&query=Bain%2C+H+M">Hazel M. Bain</a>, 
<a href="/search/astro-ph?searchtype=author&query=Moreland%2C+K">Kimberly Moreland</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 8 figures, accepted for publication in ApJS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Solar and Stellar Astrophysics (astro-ph.SR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Extreme Ultraviolet images of the Sun are becoming an integral part of space
weather prediction tasks. However, having different surveys requires the
development of instrument-specific prediction algorithms. As an alternative, it
is possible to combine multiple surveys to create a homogeneous dataset. In
this study, we utilize the temporal overlap of SoHO/EIT and SDO/AIA 171~\AA
~surveys to train an ensemble of deep learning models for creating a single
homogeneous survey of EUV images for 2 solar cycles. Prior applications of deep
learning have focused on validating the homogeneity of the output while
overlooking the systematic estimation of uncertainty. We use an approach called
`Approximate Bayesian Ensembling' to generate an ensemble of models whose
uncertainty mimics that of a fully Bayesian neural network at a fraction of the
cost. We find that ensemble uncertainty goes down as the training set size
increases. Additionally, we show that the model ensemble adds immense value to
the prediction by showing higher uncertainty in test data that are not well
represented in the training data.
</p>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10327" title="Abstract">arXiv:2308.10327</a> (cross-list from quant-ph) [<a href="/pdf/2308.10327" title="Download PDF">pdf</a>, <a href="/format/2308.10327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum State Tomography using Quantum Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Innan%2C+N">Nouhaila Innan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Siddiqui%2C+O+I">Owais Ishtiaq Siddiqui</a>, 
<a href="/search/quant-ph?searchtype=author&query=Arora%2C+S">Shivang Arora</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ghosh%2C+T">Tamojit Ghosh</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ko%C3%A7ak%2C+Y+P">Yasemin Poyraz Ko&#xe7;ak</a>, 
<a href="/search/quant-ph?searchtype=author&query=Paragas%2C+D">Dominic Paragas</a>, 
<a href="/search/quant-ph?searchtype=author&query=Galib%2C+A+A+O">Abdullah Al Omar Galib</a>, 
<a href="/search/quant-ph?searchtype=author&query=Khan%2C+M+A">Muhammad Al-Zafar Khan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bennai%2C+M">Mohamed Bennai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">Quantum State Tomography (QST) is a fundamental technique in Quantum
Information Processing (QIP) for reconstructing unknown quantum states.
However, the conventional QST methods are limited by the number of measurements
required, which makes them impractical for large-scale quantum systems. To
overcome this challenge, we propose the integration of Quantum Machine Learning
(QML) techniques to enhance the efficiency of QST. In this paper, we conduct a
comprehensive investigation into various approaches for QST, encompassing both
classical and quantum methodologies; We also implement different QML approaches
for QST and demonstrate their effectiveness on various simulated and
experimental quantum systems, including multi-qubit networks. Our results show
that our QML-based QST approach can achieve high fidelity (98%) with
significantly fewer measurements than conventional methods, making it a
promising tool for practical QIP applications.
</p>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10338" title="Abstract">arXiv:2308.10338</a> (cross-list from math.PR) [<a href="/pdf/2308.10338" title="Download PDF">pdf</a>, <a href="/format/2308.10338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A probabilistic analysis of selected notions of iterated conditioning  under coherence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Castronovo%2C+L">Lydia Castronovo</a>, 
<a href="/search/math?searchtype=author&query=Sanfilippo%2C+G">Giuseppe Sanfilippo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Artificial Intelligence (cs.AI); Logic (math.LO)

</div>
<p class="mathjax">It is well know that basic conditionals satisfy some desirable basic logical
and probabilistic properties, such as the compound probability theorem, but
checking the validity of these becomes trickier when we switch to compound and
iterated conditionals. We consider de Finetti's notion of conditional as a
three-valued object and as a conditional random quantity in the betting
framework. We recall the notions of conjunction and disjunction among
conditionals in selected trivalent logics. First, in the framework of specific
three-valued logics we analyze the notions of iterated conditioning introduced
by Cooper-Calabrese, de Finetti and Farrell, respectively. We show that the
compound probability theorem and other basic properties are not preserved by
these objects, by also computing some probability propagation rules. Then, for
each trivalent logic we introduce an iterated conditional as a suitable random
quantity which satisfies the compound prevision theorem and some of the
desirable properties. We also check the validity of two generalized versions of
Bayes' Rule for iterated conditionals. We study the p-validity of generalized
versions of Modus Ponens and two-premise centering for iterated conditionals.
Finally, we observe that all the basic properties are satisfied only by the
iterated conditional mainly developed in recent papers by Gilio and Sanfilippo
in the setting of conditional random quantities.
</p>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10355" title="Abstract">arXiv:2308.10355</a> (cross-list from eess.AS) [<a href="/pdf/2308.10355" title="Download PDF">pdf</a>, <a href="/format/2308.10355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local Periodicity-Based Beat Tracking for Expressive Classical Piano  Music
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chiu%2C+C">Ching-Yu Chiu</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%BCller%2C+M">Meinard M&#xfc;ller</a>, 
<a href="/search/eess?searchtype=author&query=Davies%2C+M+E+P">Matthew E. P. Davies</a>, 
<a href="/search/eess?searchtype=author&query=Su%2C+A+W">Alvin Wen-Yu Su</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Y">Yi-Hsuan Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE/ACM Transactions on Audio, Speech, and Language Processing (July 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">To model the periodicity of beats, state-of-the-art beat tracking systems use
"post-processing trackers" (PPTs) that rely on several empirically determined
global assumptions for tempo transition, which work well for music with a
steady tempo. For expressive classical music, however, these assumptions can be
too rigid. With two large datasets of Western classical piano music, namely the
Aligned Scores and Performances (ASAP) dataset and a dataset of Chopin's
Mazurkas (Maz-5), we report on experiments showing the failure of existing PPTs
to cope with local tempo changes, thus calling for new methods. In this paper,
we propose a new local periodicity-based PPT, called predominant local
pulse-based dynamic programming (PLPDP) tracking, that allows for more flexible
tempo transitions. Specifically, the new PPT incorporates a method called
"predominant local pulses" (PLP) in combination with a dynamic programming (DP)
component to jointly consider the locally detected periodicity and beat
activation strength at each time instant. Accordingly, PLPDP accounts for the
local periodicity, rather than relying on a global tempo assumption. Compared
to existing PPTs, PLPDP particularly enhances the recall values at the cost of
a lower precision, resulting in an overall improvement of F1-score for beat
tracking in ASAP (from 0.473 to 0.493) and Maz-5 (from 0.595 to 0.838).
</p>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10368" title="Abstract">arXiv:2308.10368</a> (cross-list from eess.IV) [<a href="/pdf/2308.10368" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prediction of Pneumonia and COVID-19 Using Deep Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Haque%2C+M+S">M. S. Haque</a>, 
<a href="/search/eess?searchtype=author&query=Taluckder%2C+M+S">M. S. Taluckder</a>, 
<a href="/search/eess?searchtype=author&query=Shawkat%2C+S+B">S. B. Shawkat</a>, 
<a href="/search/eess?searchtype=author&query=Shahriyar%2C+M+A">M. A. Shahriyar</a>, 
<a href="/search/eess?searchtype=author&query=Sayed%2C+M+A">M. A. Sayed</a>, 
<a href="/search/eess?searchtype=author&query=Modak%2C+C">C. Modak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Pneumonia, caused by bacteria and viruses, is a rapidly spreading viral
infection with global implications. Prompt identification of infected
individuals is crucial for containing its transmission. This study explores the
potential of medical image analysis to address this challenge. We propose
machine-learning techniques for predicting Pneumonia from chest X-ray images.
Chest X-ray imaging is vital for Pneumonia diagnosis due to its accessibility
and cost-effectiveness. However, interpreting X-rays for Pneumonia detection
can be complex, as radiographic features can overlap with other respiratory
conditions. We evaluate the performance of different machine learning models,
including DenseNet121, Inception Resnet-v2, Inception Resnet-v3, Resnet50, and
Xception, using chest X-ray images of pneumonia patients. Performance measures
and confusion matrices are employed to assess and compare the models. The
findings reveal that DenseNet121 outperforms other models, achieving an
accuracy rate of 99.58%. This study underscores the significance of machine
learning in the accurate detection of Pneumonia, leveraging chest X-ray images.
Our study offers insights into the potential of technology to mitigate the
spread of pneumonia through precise diagnostics.
</p>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10372" title="Abstract">arXiv:2308.10372</a> (cross-list from eess.IV) [<a href="/pdf/2308.10372" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Developing a Machine Learning-Based Clinical Decision Support Tool for  Uterine Tumor Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wright%2C+D+E">Darryl E. Wright</a>, 
<a href="/search/eess?searchtype=author&query=Gregory%2C+A+V">Adriana V. Gregory</a>, 
<a href="/search/eess?searchtype=author&query=Anaam%2C+D">Deema Anaam</a>, 
<a href="/search/eess?searchtype=author&query=Yadollahi%2C+S">Sepideh Yadollahi</a>, 
<a href="/search/eess?searchtype=author&query=Ramanathan%2C+S">Sumana Ramanathan</a>, 
<a href="/search/eess?searchtype=author&query=Oyemade%2C+K+A">Kafayat A. Oyemade</a>, 
<a href="/search/eess?searchtype=author&query=Alsibai%2C+R">Reem Alsibai</a>, 
<a href="/search/eess?searchtype=author&query=Holmes%2C+H">Heather Holmes</a>, 
<a href="/search/eess?searchtype=author&query=Gottlich%2C+H">Harrison Gottlich</a>, 
<a href="/search/eess?searchtype=author&query=Browne%2C+C+G">Cherie-Akilah G. Browne</a>, 
<a href="/search/eess?searchtype=author&query=Rassier%2C+S+L+C">Sarah L. Cohen Rassier</a>, 
<a href="/search/eess?searchtype=author&query=Green%2C+I">Isabel Green</a>, 
<a href="/search/eess?searchtype=author&query=Stewart%2C+E+A">Elizabeth A. Stewart</a>, 
<a href="/search/eess?searchtype=author&query=Takahashi%2C+H">Hiroaki Takahashi</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+B">Bohyun Kim</a>, 
<a href="/search/eess?searchtype=author&query=Laughlin-Tommaso%2C+S">Shannon Laughlin-Tommaso</a>, 
<a href="/search/eess?searchtype=author&query=Kline%2C+T+L">Timothy L. Kline</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Uterine leiomyosarcoma (LMS) is a rare but aggressive malignancy. On imaging,
it is difficult to differentiate LMS from, for example, degenerated leiomyoma
(LM), a prevalent but benign condition. We curated a data set of 115 axial
T2-weighted MRI images from 110 patients (mean [range] age=45 [17-81] years)
with UTs that included five different tumor types. These data were randomly
split stratifying on tumor volume into training (n=85) and test sets (n=30). An
independent second reader (reader 2) provided manual segmentations for all test
set images. To automate segmentation, we applied nnU-Net and explored the
effect of training set size on performance by randomly generating subsets with
25, 45, 65 and 85 training set images. We evaluated the ability of radiomic
features to distinguish between types of UT individually and when combined
through feature selection and machine learning. Using the entire training set
the mean [95% CI] fibroid DSC was measured as 0.87 [0.59-1.00] and the
agreement between the two readers was 0.89 [0.77-1.0] on the test set. When
classifying degenerated LM from LMS we achieve a test set F1-score of 0.80.
Classifying UTs based on radiomic features we identify classifiers achieving
F1-scores of 0.53 [0.45, 0.61] and 0.80 [0.80, 0.80] on the test set for the
benign versus malignant, and degenerated LM versus LMS tasks. We show that it
is possible to develop an automated method for 3D segmentation of the uterus
and UT that is close to human-level performance with fewer than 150 annotated
images. For distinguishing UT types, while we train models that merit further
investigation with additional data, reliable automatic differentiation of UTs
remains a challenge.
</p>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10418" title="Abstract">arXiv:2308.10418</a> (cross-list from quant-ph) [<a href="/pdf/2308.10418" title="Download PDF">pdf</a>, <a href="/ps/2308.10418" title="Download PostScript">ps</a>, <a href="/format/2308.10418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Query Lower Bounds for Key Recovery Attacks on the Even-Mansour  Cipher
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Kawachi%2C+A">Akinori Kawachi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Naito%2C+Y">Yuki Naito</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The Even-Mansour (EM) cipher is one of the famous constructions for a block
cipher. Kuwakado and Morii demonstrated that a quantum adversary can recover
its $n$-bit secret keys only with $O(n)$ nonadaptive quantum queries. While the
security of the EM cipher and its variants is well-understood for classical
adversaries, very little is currently known of their quantum security. Towards
a better understanding of the quantum security, or the limits of quantum
adversaries for the EM cipher, we study the quantum query complexity for the
key recovery of the EM cipher and prove every quantum algorithm requires
$\Omega(n)$ quantum queries for the key recovery even if it is allowed to make
adaptive queries. Therefore, the quantum attack of Kuwakado and Morii has the
optimal query complexity up to a constant factor, and we cannot asymptotically
improve it even with adaptive quantum queries.
</p>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10423" title="Abstract">arXiv:2308.10423</a> (cross-list from eess.SP) [<a href="/pdf/2308.10423" title="Download PDF">pdf</a>, <a href="/format/2308.10423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Sensing and Communications for 3D Object Imaging via Bilinear  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rou%2C+H+S">Hyeon Seok Rou</a>, 
<a href="/search/eess?searchtype=author&query=de+Abreu%2C+G+T+F">Giuseppe Thadeu Freitas de Abreu</a>, 
<a href="/search/eess?searchtype=author&query=G.%2C+D+G">David Gonz&#xe1;lez G.</a>, 
<a href="/search/eess?searchtype=author&query=Gonsa%2C+O">Osvaldo Gonsa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">We consider an uplink integrated sensing and communications (ISAC) scenario
where the detection of data symbols from multiple user equipment (UEs) occurs
simultaneously with a three-dimensional (3D) estimation of the environment,
extracted from the scattering features present in the channel state information
(CSI) and utilizing the same physical layer communications air interface, as
opposed to radar technologies. By exploiting a discrete (voxelated)
representation of the environment, two novel ISAC schemes are derived with
purpose-built message passing (MP) rules for the joint estimation of data
symbols and status (filled/empty) of the discretized environment. The first
relies on a modular feedback structure in which the data symbols and the
environment are estimated alternately, whereas the second leverages a bilinear
inference framework to estimate both variables concurrently. Both contributed
methods are shown via simulations to outperform the state-of-the-art (SotA) in
accurately recovering the transmitted data as well as the 3D image of the
environment. An analysis of the computational complexities of the proposed
methods reveals distinct advantages of each scheme, namely, that the bilinear
solution exhibits a superior robustness to short pilots and channel blockages,
while the alternating solution offers lower complexity with large number of UEs
and superior performance in ideal conditions.
</p>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10428" title="Abstract">arXiv:2308.10428</a> (cross-list from eess.AS) [<a href="/pdf/2308.10428" title="Download PDF">pdf</a>, <a href="/format/2308.10428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-GradSpeech: Towards Diffusion-based Multi-Speaker Text-to-speech  Using Consistent Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xue%2C+H">Heyang Xue</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+S">Shuai Guo</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+P">Pengcheng Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Bi%2C+M">Mengxiao Bi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Recent advancements in diffusion-based acoustic models have revolutionized
data-sufficient single-speaker Text-to-Speech (TTS) approaches, with Grad-TTS
being a prime example. However, diffusion models suffer from drift in training
and sampling distributions due to imperfect score-matching. The sampling drift
problem leads to these approaches struggling in multi-speaker scenarios in
practice. In this paper, we present Multi-GradSpeech, a multi-speaker
diffusion-based acoustic models which introduces the Consistent Diffusion Model
(CDM) as a generative modeling approach. We enforce the consistency property of
CDM during the training process to alleviate the sampling drift problem in the
inference stage, resulting in significant improvements in multi-speaker TTS
performance. Our experimental results corroborate that our proposed approach
can improve the performance of different speakers involved in multi-speaker TTS
compared to Grad-TTS, even outperforming the fine-tuning approach. Audio
samples are available at https://welkinyang.github.io/multi-gradspeech/
</p>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10430" title="Abstract">arXiv:2308.10430</a> (cross-list from math-ph) [<a href="/pdf/2308.10430" title="Download PDF">pdf</a>, <a href="/format/2308.10430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling of electronic dynamics in twisted bilayer graphene
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math-ph?searchtype=author&query=Kong%2C+T">Tianyu Kong</a>, 
<a href="/search/math-ph?searchtype=author&query=Liu%2C+D">Diyi Liu</a>, 
<a href="/search/math-ph?searchtype=author&query=Luskin%2C+M">Mitchell Luskin</a>, 
<a href="/search/math-ph?searchtype=author&query=Watson%2C+A+B">Alexander B. Watson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Physics (math-ph)</span>; Mesoscale and Nanoscale Physics (cond-mat.mes-hall); Analysis of PDEs (math.AP); Numerical Analysis (math.NA); Quantum Physics (quant-ph)

</div>
<p class="mathjax">We consider the problem of numerically computing the quantum dynamics of an
electron in twisted bilayer graphene. The challenge is that atomic-scale models
of the dynamics are aperiodic for generic twist angles because of the
incommensurability of the layers. The Bistritzer-MacDonald PDE model, which is
periodic with respect to the bilayer's moir\'e pattern, has recently been shown
to rigorously describe these dynamics in a parameter regime. In this work, we
first prove that the dynamics of the tight-binding model of incommensurate
twisted bilayer graphene can be approximated by computations on finite domains.
The main ingredient of this proof is a speed of propagation estimate proved
using Combes-Thomas estimates. We then provide extensive numerical computations
which clarify the range of validity of the Bistritzer-MacDonald model.
</p>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10436" title="Abstract">arXiv:2308.10436</a> (cross-list from stat.ML) [<a href="/pdf/2308.10436" title="Download PDF">pdf</a>, <a href="/format/2308.10436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximately Equivariant Graph Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Huang%2C+N">Ningyuan Huang</a>, 
<a href="/search/stat?searchtype=author&query=Levie%2C+R">Ron Levie</a>, 
<a href="/search/stat?searchtype=author&query=Villar%2C+S">Soledad Villar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Graph neural networks (GNNs) are commonly described as being permutation
equivariant with respect to node relabeling in the graph. This symmetry of GNNs
is often compared to the translation equivariance symmetry of Euclidean
convolution neural networks (CNNs). However, these two symmetries are
fundamentally different: The translation equivariance of CNNs corresponds to
symmetries of the fixed domain acting on the image signal (sometimes known as
active symmetries), whereas in GNNs any permutation acts on both the graph
signals and the graph domain (sometimes described as passive symmetries). In
this work, we focus on the active symmetries of GNNs, by considering a learning
setting where signals are supported on a fixed graph. In this case, the natural
symmetries of GNNs are the automorphisms of the graph. Since real-world graphs
tend to be asymmetric, we relax the notion of symmetries by formalizing
approximate symmetries via graph coarsening. We present a bias-variance formula
that quantifies the tradeoff between the loss in expressivity and the gain in
the regularity of the learned estimator, depending on the chosen symmetry
group. To illustrate our approach, we conduct extensive experiments on image
inpainting, traffic flow prediction, and human pose estimation with different
choices of symmetries. We show theoretically and empirically that the best
generalization performance can be achieved by choosing a suitably larger group
than the graph automorphism group, but smaller than the full permutation group.
</p>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10470" title="Abstract">arXiv:2308.10470</a> (cross-list from eess.AS) [<a href="/pdf/2308.10470" title="Download PDF">pdf</a>, <a href="/format/2308.10470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Self-supervised Language Representation for Spoken Language  Diarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mishra%2C+J">Jagabandhu Mishra</a>, 
<a href="/search/eess?searchtype=author&query=Prasanna%2C+S+R+M">S. R. Mahadeva Prasanna</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Planning to Submit in IEEE-JSTSP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)

</div>
<p class="mathjax">In a code-switched (CS) scenario, the use of spoken language diarization (LD)
as a pre-possessing system is essential. Further, the use of implicit
frameworks is preferable over the explicit framework, as it can be easily
adapted to deal with low/zero resource languages. Inspired by speaker
diarization (SD) literature, three frameworks based on (1) fixed segmentation,
(2) change point-based segmentation and (3) E2E are proposed to perform LD. The
initial exploration with synthetic TTSF-LD dataset shows, using x-vector as
implicit language representation with appropriate analysis window length ($N$)
can able to achieve at per performance with explicit LD. The best implicit LD
performance of $6.38$ in terms of Jaccard error rate (JER) is achieved by using
the E2E framework. However, considering the E2E framework the performance of
implicit LD degrades to $60.4$ while using with practical Microsoft CS (MSCS)
dataset. The difference in performance is mostly due to the distributional
difference between the monolingual segment duration of secondary language in
the MSCS and TTSF-LD datasets. Moreover, to avoid segment smoothing, the
smaller duration of the monolingual segment suggests the use of a small value
of $N$. At the same time with small $N$, the x-vector representation is unable
to capture the required language discrimination due to the acoustic similarity,
as the same speaker is speaking both languages. Therefore, to resolve the issue
a self-supervised implicit language representation is proposed in this study.
In comparison with the x-vector representation, the proposed representation
provides a relative improvement of $63.9\%$ and achieved a JER of $21.8$ using
the E2E framework.
</p>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10479" title="Abstract">arXiv:2308.10479</a> (cross-list from math.CO) [<a href="/pdf/2308.10479" title="Download PDF">pdf</a>, <a href="/ps/2308.10479" title="Download PostScript">ps</a>, <a href="/format/2308.10479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stabbing boxes with finitely many axis-parallel lines and flats
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chakraborty%2C+S">Sutanoya Chakraborty</a>, 
<a href="/search/math?searchtype=author&query=Ghosh%2C+A">Arijit Ghosh</a>, 
<a href="/search/math?searchtype=author&query=Nandi%2C+S">Soumi Nandi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">We give necessary and sufficient condition for an infinite collection of
axis-parallel boxes in $\mathbb{R}^{d}$ to be pierceable by finitely many
axis-parallel $k$-flats, where $0 \leq k &lt; d$. We also consider colorful
generalizations of the above result and establish their feasibility. The
problem considered in this paper is an infinite variant of the
Hadwiger-Debrunner $(p,q)$-problem.
</p>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10480" title="Abstract">arXiv:2308.10480</a> (cross-list from math.CO) [<a href="/pdf/2308.10480" title="Download PDF">pdf</a>, <a href="/format/2308.10480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dimension Independent Helly Theorem for Lines and Flats
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chakraborty%2C+S">Sutanoya Chakraborty</a>, 
<a href="/search/math?searchtype=author&query=Ghosh%2C+A">Arijit Ghosh</a>, 
<a href="/search/math?searchtype=author&query=Nandi%2C+S">Soumi Nandi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">We give a generalization of dimension independent Helly Theorem of
Adiprasito, B\'{a}r\'{a}ny, Mustafa, and Terpai (Discrete &amp; Computational
Geometry 2022) to higher dimensional transversal. We also prove some
impossibility results that establish the tightness of our extension.
</p>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10488" title="Abstract">arXiv:2308.10488</a> (cross-list from eess.IV) [<a href="/pdf/2308.10488" title="Download PDF">pdf</a>, <a href="/format/2308.10488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Medical Image Segmentation: Optimizing Cross-Entropy Weights  and Post-Processing with Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Singh%2C+P">Pranav Singh</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+L">Luoyao Chen</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+M">Mei Chen</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+J">Jinqian Pan</a>, 
<a href="/search/eess?searchtype=author&query=Chukkapalli%2C+R">Raviteja Chukkapalli</a>, 
<a href="/search/eess?searchtype=author&query=Chaudhari%2C+S">Shravan Chaudhari</a>, 
<a href="/search/eess?searchtype=author&query=Cirrone%2C+J">Jacopo Cirrone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV CVAMD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The task of medical image segmentation presents unique challenges,
necessitating both localized and holistic semantic understanding to accurately
delineate areas of interest, such as critical tissues or aberrant features.
This complexity is heightened in medical image segmentation due to the high
degree of inter-class similarities, intra-class variations, and possible image
obfuscation. The segmentation task further diversifies when considering the
study of histopathology slides for autoimmune diseases like dermatomyositis.
The analysis of cell inflammation and interaction in these cases has been less
studied due to constraints in data acquisition pipelines. Despite the
progressive strides in medical science, we lack a comprehensive collection of
autoimmune diseases. As autoimmune diseases globally escalate in prevalence and
exhibit associations with COVID-19, their study becomes increasingly essential.
While there is existing research that integrates artificial intelligence in the
analysis of various autoimmune diseases, the exploration of dermatomyositis
remains relatively underrepresented. In this paper, we present a deep-learning
approach tailored for Medical image segmentation. Our proposed method
outperforms the current state-of-the-art techniques by an average of 12.26% for
U-Net and 12.04% for U-Net++ across the ResNet family of encoders on the
dermatomyositis dataset. Furthermore, we probe the importance of optimizing
loss function weights and benchmark our methodology on three challenging
medical image segmentation tasks
</p>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10501" title="Abstract">arXiv:2308.10501</a> (cross-list from math.AP) [<a href="/pdf/2308.10501" title="Download PDF">pdf</a>, <a href="/format/2308.10501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning of Delay-Compensated Backstepping for Reaction-Diffusion  PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+S">Shanshan Wang</a>, 
<a href="/search/math?searchtype=author&query=Diagne%2C+M">Mamadou Diagne</a>, 
<a href="/search/math?searchtype=author&query=Krsti%C4%87%2C+M">Miroslav Krsti&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">Deep neural networks that approximate nonlinear function-to-function
mappings, i.e., operators, which are called DeepONet, have been demonstrated in
recent articles to be capable of encoding entire PDE control methodologies,
such as backstepping, so that, for each new functional coefficient of a PDE
plant, the backstepping gains are obtained through a simple function
evaluation. These initial results have been limited to single PDEs from a given
class, approximating the solutions of only single-PDE operators for the gain
kernels. In this paper we expand this framework to the approximation of
multiple (cascaded) nonlinear operators. Multiple operators arise in the
control of PDE systems from distinct PDE classes, such as the system in this
paper: a reaction-diffusion plant, which is a parabolic PDE, with input delay,
which is a hyperbolic PDE. The DeepONet-approximated nonlinear operator is a
cascade/composition of the operators defined by one hyperbolic PDE of the
Goursat form and one parabolic PDE on a rectangle, both of which are bilinear
in their input functions and not explicitly solvable. For the delay-compensated
PDE backstepping controller, which employs the learned control operator,
namely, the approximated gain kernel, we guarantee exponential stability in the
$L^2$ norm of the plant state and the $H^1$ norm of the input delay state.
Simulations illustrate the contributed theory.
</p>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10513" title="Abstract">arXiv:2308.10513</a> (cross-list from quant-ph) [<a href="/pdf/2308.10513" title="Download PDF">pdf</a>, <a href="/format/2308.10513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid classical-quantum computing: are we forgetting the classical part  in the binomial?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Villar-Rodriguez%2C+E">Esther Villar-Rodriguez</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gomez-Tejedor%2C+A">Aitor Gomez-Tejedor</a>, 
<a href="/search/quant-ph?searchtype=author&query=Osaba%2C+E">Eneko Osaba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages, 1 figure, paper accepted for being presented in the upcoming IEEE International Conference on Quantum Computing and Engineering - IEEE QCE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)

</div>
<p class="mathjax">The expectations arising from the latest achievements in the quantum
computing field are causing that researchers coming from classical artificial
intelligence to be fascinated by this new paradigm. In turn, quantum computing,
on the road towards usability, needs classical procedures. Hybridization is, in
these circumstances, an indispensable step but can also be seen as a promising
new avenue to get the most from both computational worlds. Nonetheless, hybrid
approaches have now and will have in the future many challenges to face, which,
if ignored, will threaten the viability or attractiveness of quantum computing
for real-world applications. To identify them and pose pertinent questions, a
proper characterization of the hybrid quantum computing field, and especially
hybrid solvers, is compulsory. With this motivation in mind, the main purpose
of this work is to propose a preliminary taxonomy for classifying hybrid
schemes, and bring to the fore some questions to stir up researchers minds
about the real challenges regarding the application of quantum computing.
</p>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10542" title="Abstract">arXiv:2308.10542</a> (cross-list from eess.IV) [<a href="/pdf/2308.10542" title="Download PDF">pdf</a>, <a href="/format/2308.10542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Weakly Convex Regularizers for Convergent Image-Reconstruction  Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Goujon%2C+A">Alexis Goujon</a>, 
<a href="/search/eess?searchtype=author&query=Neumayer%2C+S">Sebastian Neumayer</a>, 
<a href="/search/eess?searchtype=author&query=Unser%2C+M">Michael Unser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose to learn non-convex regularizers with a prescribed upper bound on
their weak-convexity modulus. Such regularizers give rise to variational
denoisers that minimize a convex energy. They rely on few parameters (less than
15,000) and offer a signal-processing interpretation as they mimic handcrafted
sparsity-promoting regularizers. Through numerical experiments, we show that
such denoisers outperform convex-regularization methods as well as the popular
BM3D denoiser. Additionally, the learned regularizer can be deployed to solve
inverse problems with iterative schemes that provably converge. For both CT and
MRI reconstruction, the regularizer generalizes well and offers an excellent
tradeoff between performance, number of parameters, guarantees, and
interpretability when compared to other data-driven approaches.
</p>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10547" title="Abstract">arXiv:2308.10547</a> (cross-list from math.OC) [<a href="/pdf/2308.10547" title="Download PDF">pdf</a>, <a href="/format/2308.10547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized Riemannian Conjugate Gradient Method on the Stiefel  Manifold
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+J">Jun Chen</a>, 
<a href="/search/math?searchtype=author&query=Ye%2C+H">Haishan Ye</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+M">Mengmeng Wang</a>, 
<a href="/search/math?searchtype=author&query=Huang%2C+T">Tianxin Huang</a>, 
<a href="/search/math?searchtype=author&query=Dai%2C+G">Guang Dai</a>, 
<a href="/search/math?searchtype=author&query=Tsang%2C+I+W">Ivor W.Tsang</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+Y">Yong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">The conjugate gradient method is a crucial first-order optimization method
that generally converges faster than the steepest descent method, and its
computational cost is much lower than the second-order methods. However, while
various types of conjugate gradient methods have been studied in Euclidean
spaces and on Riemannian manifolds, there has little study for those in
distributed scenarios. This paper proposes a decentralized Riemannian conjugate
gradient descent (DRCGD) method that aims at minimizing a global function over
the Stiefel manifold. The optimization problem is distributed among a network
of agents, where each agent is associated with a local function, and
communication between agents occurs over an undirected connected graph. Since
the Stiefel manifold is a non-convex set, a global function is represented as a
finite sum of possibly non-convex (but smooth) local functions. The proposed
method is free from expensive Riemannian geometric operations such as
retractions, exponential maps, and vector transports, thereby reducing the
computational complexity required by each agent. To the best of our knowledge,
DRCGD is the first decentralized Riemannian conjugate gradient algorithm to
achieve global convergence over the Stiefel manifold.
</p>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10590" title="Abstract">arXiv:2308.10590</a> (cross-list from physics.optics) [<a href="/pdf/2308.10590" title="Download PDF">pdf</a>, <a href="/ps/2308.10590" title="Download PostScript">ps</a>, <a href="/format/2308.10590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving multi-armed bandit problems using a chaotic microresonator comb
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Cuevas%2C+J">Jonathan Cuevas</a>, 
<a href="/search/physics?searchtype=author&query=Iwami%2C+R">Ryugo Iwami</a>, 
<a href="/search/physics?searchtype=author&query=Uchida%2C+A">Atsushi Uchida</a>, 
<a href="/search/physics?searchtype=author&query=Minoshima%2C+K">Kaoru Minoshima</a>, 
<a href="/search/physics?searchtype=author&query=Kuse%2C+N">Naoya Kuse</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">The Multi-Armed Bandit (MAB) problem, foundational to reinforcement
learning-based decision-making, addresses the challenge of maximizing rewards
amidst multiple uncertain choices. While algorithmic solutions are effective,
their computational efficiency diminishes with increasing problem complexity.
Photonic accelerators, leveraging temporal and spatial-temporal chaos, have
emerged as promising alternatives. However, despite these advancements, current
approaches either compromise computation speed or amplify system complexity. In
this paper, we introduce a chaotic microresonator frequency comb (chaos comb)
to tackle the MAB problem, where each comb mode is assigned to a slot machine.
Through a proof-of-concept experiment, we employ 44 comb modes to address an
MAB with 44 slot machines, demonstrating performance competitive with both
conventional software algorithms and other photonic methods. Further, the
scalability of decision making is explored with up to 512 slot machines using
experimentally obtained temporal chaos in different time slots. Power-law
scalability is achieved with an exponent of 0.96, outperforming conventional
software-based algorithms. Moreover, we find that a numerically calculated
chaos comb accurately reproduces experimental results, paving the way for
discussions on strategies to increase the number of slot machines.
</p>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10598" title="Abstract">arXiv:2308.10598</a> (cross-list from eess.SP) [<a href="/pdf/2308.10598" title="Download PDF">pdf</a>, <a href="/format/2308.10598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring Power Grid Information with Power Line Communications: Review  and Insights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jarouf%2C+A">Abdulah Jarouf</a>, 
<a href="/search/eess?searchtype=author&query=Fernandez%2C+J+H">Javier Hernandez Fernandez</a>, 
<a href="/search/eess?searchtype=author&query=Omri%2C+A">Aymen Omri</a>, 
<a href="/search/eess?searchtype=author&query=Di+Pietro%2C+R">Roberto Di Pietro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Communication Surveys and Tutorials Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Other Computer Science (cs.OH)

</div>
<p class="mathjax">High-frequency signals were widely studied in the last decade to identify
grid and channel conditions in PLNs. PLMs operating on the grid's physical
layer are capable of transmitting such signals to infer information about the
grid. Hence, PLC is a suitable communication technology for SG applications,
especially suited for grid monitoring and surveillance. In this paper, we
provide several contributions: 1) a classification of PLC-based applications;
2) a taxonomy of the related methodologies; 3) a review of the literature in
the area of PLC Grid Information Inference (GII); and, insights that can be
leveraged to further advance the field. We found research contributions
addressing PLMs for three main PLC-GII applications: topology inference,
anomaly detection, and physical layer key generation. In addition, various
PLC-GII measurement, processing, and analysis approaches were found to provide
distinctive features in measurement resolution, computation complexity, and
analysis accuracy. We utilize the outcome of our review to shed light on the
current limitations of the research contributions and suggest future research
directions in this field.
</p>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10606" title="Abstract">arXiv:2308.10606</a> (cross-list from stat.ML) [<a href="/pdf/2308.10606" title="Download PDF">pdf</a>, <a href="/format/2308.10606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Complex Systems with Cascades Using Continuous-Time Bayesian  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bregoli%2C+A">Alessandro Bregoli</a>, 
<a href="/search/stat?searchtype=author&query=Rathsman%2C+K">Karin Rathsman</a>, 
<a href="/search/stat?searchtype=author&query=Scutari%2C+M">Marco Scutari</a>, 
<a href="/search/stat?searchtype=author&query=Stella%2C+F">Fabio Stella</a>, 
<a href="/search/stat?searchtype=author&query=Mogensen%2C+S+W">S&#xf8;ren Wengel Mogensen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Interacting systems of events may exhibit cascading behavior where events
tend to be temporally clustered. While the cascades themselves may be obvious
from the data, it is important to understand which states of the system trigger
them. For this purpose, we propose a modeling framework based on
continuous-time Bayesian networks (CTBNs) to analyze cascading behavior in
complex systems. This framework allows us to describe how events propagate
through the system and to identify likely sentry states, that is, system states
that may lead to imminent cascading behavior. Moreover, CTBNs have a simple
graphical representation and provide interpretable outputs, both of which are
important when communicating with domain experts. We also develop new methods
for knowledge extraction from CTBNs and we apply the proposed methodology to a
data set of alarms in a large industrial system.
</p>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10622" title="Abstract">arXiv:2308.10622</a> (cross-list from stat.ME) [<a href="/pdf/2308.10622" title="Download PDF">pdf</a>, <a href="/format/2308.10622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weighting by Tying: A New Approach to Weighted Rank Correlation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Henzgen%2C+S">Sascha Henzgen</a>, 
<a href="/search/stat?searchtype=author&query=H%C3%BCllermeier%2C+E">Eyke H&#xfc;llermeier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Measures of rank correlation are commonly used in statistics to capture the
degree of concordance between two orderings of the same set of items. Standard
measures like Kendall's tau and Spearman's rho coefficient put equal emphasis
on each position of a ranking. Yet, motivated by applications in which some of
the positions (typically those on the top) are more important than others, a
few weighted variants of these measures have been proposed. Most of these
generalizations fail to meet desirable formal properties, however. Besides,
they are often quite inflexible in the sense of committing to a fixed weighing
scheme. In this paper, we propose a weighted rank correlation measure on the
basis of fuzzy order relations. Our measure, called scaled gamma, is related to
Goodman and Kruskal's gamma rank correlation. It is parametrized by a fuzzy
equivalence relation on the rank positions, which in turn is specified
conveniently by a so-called scaling function. This approach combines soundness
with flexibility: it has a sound formal foundation and allows for weighing rank
positions in a flexible way.
</p>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10630" title="Abstract">arXiv:2308.10630</a> (cross-list from math.OC) [<a href="/pdf/2308.10630" title="Download PDF">pdf</a>, <a href="/format/2308.10630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Homogenization Approach for Gradient-Dominated Stochastic Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tan%2C+J">Jiyuan Tan</a>, 
<a href="/search/math?searchtype=author&query=Xue%2C+C">Chenyu Xue</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+C">Chuwen Zhang</a>, 
<a href="/search/math?searchtype=author&query=Deng%2C+Q">Qi Deng</a>, 
<a href="/search/math?searchtype=author&query=Ge%2C+D">Dongdong Ge</a>, 
<a href="/search/math?searchtype=author&query=Ye%2C+Y">Yinyu Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Gradient dominance property is a condition weaker than strong convexity, yet
it sufficiently ensures global convergence for first-order methods even in
non-convex optimization. This property finds application in various machine
learning domains, including matrix decomposition, linear neural networks, and
policy-based reinforcement learning (RL). In this paper, we study the
stochastic homogeneous second-order descent method (SHSODM) for
gradient-dominated optimization with $\alpha \in [1, 2]$ based on a recently
proposed homogenization approach. Theoretically, we show that SHSODM achieves a
sample complexity of $O(\epsilon^{-7/(2 \alpha) +1})$ for $\alpha \in [1, 3/2)$
and $\tilde{O}(\epsilon^{-2/\alpha})$ for $\alpha \in [3/2, 2]$. We further
provide a SHSODM with a variance reduction technique enjoying an improved
sample complexity of $O( \epsilon ^{-( 7-3\alpha ) /( 2\alpha )})$ for $\alpha
\in [1,3/2)$. Our results match the state-of-the-art sample complexity bounds
for stochastic gradient-dominated optimization without \emph{cubic
regularization}. Since the homogenization approach only relies on solving
extremal eigenvector problems instead of Newton-type systems, our methods gain
the advantage of cheaper iterations and robustness in ill-conditioned problems.
Numerical experiments on several RL tasks demonstrate the efficiency of SHSODM
compared to other off-the-shelf methods.
</p>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10636" title="Abstract">arXiv:2308.10636</a> (cross-list from eess.IV) [<a href="/pdf/2308.10636" title="Download PDF">pdf</a>, <a href="/format/2308.10636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Identification of Failure Cases in Organ at Risk Segmentation  Using Distance Metrics: A Study on CT Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shandiz%2C+A+H">Amin Honarmandi Shandiz</a>, 
<a href="/search/eess?searchtype=author&query=R%C3%A1dics%2C+A">Attila R&#xe1;dics</a>, 
<a href="/search/eess?searchtype=author&query=Tamada%2C+R">Rajesh Tamada</a>, 
<a href="/search/eess?searchtype=author&query=%C3%81rp%C3%A1d%2C+M">Makk &#xc1;rp&#xe1;d</a>, 
<a href="/search/eess?searchtype=author&query=Glowacka%2C+K">Karolina Glowacka</a>, 
<a href="/search/eess?searchtype=author&query=Ferenczi%2C+L">Lehel Ferenczi</a>, 
<a href="/search/eess?searchtype=author&query=Dutta%2C+S">Sandeep Dutta</a>, 
<a href="/search/eess?searchtype=author&query=Fanariotis%2C+M">Michael Fanariotis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Automated organ at risk (OAR) segmentation is crucial for radiation therapy
planning in CT scans, but the generated contours by automated models can be
inaccurate, potentially leading to treatment planning issues. The reasons for
these inaccuracies could be varied, such as unclear organ boundaries or
inaccurate ground truth due to annotation errors. To improve the model's
performance, it is necessary to identify these failure cases during the
training process and to correct them with some potential post-processing
techniques. However, this process can be time-consuming, as traditionally it
requires manual inspection of the predicted output. This paper proposes a
method to automatically identify failure cases by setting a threshold for the
combination of Dice and Hausdorff distances. This approach reduces the
time-consuming task of visually inspecting predicted outputs, allowing for
faster identification of failure case candidates. The method was evaluated on
20 cases of six different organs in CT images from clinical expert curated
datasets. By setting the thresholds for the Dice and Hausdorff distances, the
study was able to differentiate between various states of failure cases and
evaluate over 12 cases visually. This thresholding approach could be extended
to other organs, leading to faster identification of failure cases and thereby
improving the quality of radiation therapy planning.
</p>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10641" title="Abstract">arXiv:2308.10641</a> (cross-list from eess.SP) [<a href="/pdf/2308.10641" title="Download PDF">pdf</a>, <a href="/format/2308.10641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical Analysis of Geometric Algorithms in Vehicular Visible Light  Positioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Soner%2C+B">Burak Soner</a>, 
<a href="/search/eess?searchtype=author&query=Coleri%2C+S">Sinem Coleri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report. 7 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Vehicular visible light positioning (VLP) methods find relative locations of
vehicles by estimating the positions of intensity-modulated head/tail lights of
one vehicle (target) with respect to another (ego). Estimation is done in two
steps: 1) relative bearing or range of the transmitter-receiver link is
measured over the received signal on the ego side, and 2) target position is
estimated based on those measurements using a geometric algorithm that
expresses position coordinates in terms of the bearing-range parameters. The
primary source of statistical error for these non-linear algorithms is the
channel noise on the received signals that contaminates parameter measurements
with varying levels of sensitivity. In this paper, we present two such
geometric vehicular VLP algorithms that were previously unexplored, compare
their performance with state-of-the-art algorithms over simulations, and
analyze theoretical performance of all algorithms against statistical channel
noise by deriving the respective Cramer-Rao lower bounds. The two newly
explored algorithms do not outperform existing state-of-the-art, but we present
them alongside the statistical analyses for the sake of completeness and to
motivate further research in vehicular VLP. Our main finding is that direct
bearing-based algorithms provide higher accuracy against noise for estimating
lateral position coordinates, and range-based algorithms provide higher
accuracy in the longitudinal axis due to the non-linearity of the respective
geometric algorithms.
</p>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10697" title="Abstract">arXiv:2308.10697</a> (cross-list from math.DS) [<a href="/pdf/2308.10697" title="Download PDF">pdf</a>, <a href="/format/2308.10697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond expectations: Residual Dynamic Mode Decomposition and Variance  for Stochastic Dynamical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Colbrook%2C+M+J">Matthew J. Colbrook</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+Q">Qin Li</a>, 
<a href="/search/math?searchtype=author&query=Raut%2C+R+V">Ryan V. Raut</a>, 
<a href="/search/math?searchtype=author&query=Townsend%2C+A">Alex Townsend</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA); Spectral Theory (math.SP); Chaotic Dynamics (nlin.CD)

</div>
<p class="mathjax">Koopman operators linearize nonlinear dynamical systems, making their
spectral information of crucial interest. Numerous algorithms have been
developed to approximate these spectral properties, and Dynamic Mode
Decomposition (DMD) stands out as the poster child of projection-based methods.
Although the Koopman operator itself is linear, the fact that it acts in an
infinite-dimensional space of observables poses various challenges. These
include spurious modes, essential spectra, and the verification of Koopman mode
decompositions. While recent work has addressed these challenges for
deterministic systems, there remains a notable gap in verified DMD methods
tailored for stochastic systems, where the Koopman operator measures the
expectation of observables. We show that it is necessary to go beyond
expectations to address these issues. By incorporating variance into the
Koopman framework, we address these challenges. Through an additional DMD-type
matrix, we approximate the sum of a squared residual and a variance term, each
of which can be approximated individually using batched snapshot data. This
allows verified computation of the spectral properties of stochastic Koopman
operators, controlling the projection error. We also introduce the concept of
variance-pseudospectra to gauge statistical coherency. Finally, we present a
suite of convergence results for the spectral quantities of stochastic Koopman
operators. Our study concludes with practical applications using both simulated
and experimental data. In neural recordings from awake mice, we demonstrate how
variance-pseudospectra can reveal physiologically significant information
unavailable to standard expectation-based dynamical models.
</p>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10756" title="Abstract">arXiv:2308.10756</a> (cross-list from math.CO) [<a href="/pdf/2308.10756" title="Download PDF">pdf</a>, <a href="/ps/2308.10756" title="Download PostScript">ps</a>, <a href="/format/2308.10756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing Optimal Leaf Roots of Chordal Cographs in Linear Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Le%2C+V+B">Van Bang Le</a>, 
<a href="/search/math?searchtype=author&query=Rosenke%2C+C">Christian Rosenke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 2 figures, full version of the FCT 2023 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">A graph G is a k-leaf power, for an integer k &gt;= 2, if there is a tree T with
leaf set V(G) such that, for all vertices x, y in V(G), the edge xy exists in G
if and only if the distance between x and y in T is at most k. Such a tree T is
called a k-leaf root of G. The computational problem of constructing a k-leaf
root for a given graph G and an integer k, if any, is motivated by the
challenge from computational biology to reconstruct phylogenetic trees. For
fixed k, Lafond [SODA 2022] recently solved this problem in polynomial time.
<br />In this paper, we propose to study optimal leaf roots of graphs G, that is,
the k-leaf roots of G with minimum k value. Thus, all k'-leaf roots of G
satisfy k &lt;= k'. In terms of computational biology, seeking optimal leaf roots
is more justified as they yield more probable phylogenetic trees. Lafond's
result does not imply polynomial-time computability of optimal leaf roots,
because, even for optimal k-leaf roots, k may (exponentially) depend on the
size of G. This paper presents a linear-time construction of optimal leaf roots
for chordal cographs (also known as trivially perfect graphs). Additionally, it
highlights the importance of the parity of the parameter k and provides a
deeper insight into the differences between optimal k-leaf roots of even versus
odd k.
<br />Keywords: k-leaf power, k-leaf root, optimal k-leaf root, trivially perfect
leaf power, chordal cograph
</p>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10784" title="Abstract">arXiv:2308.10784</a> (cross-list from eess.IV) [<a href="/pdf/2308.10784" title="Download PDF">pdf</a>, <a href="/format/2308.10784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dense Error Map Estimation for MRI-Ultrasound Registration in Brain  Tumor Surgery Using Swin UNETR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Salari%2C+S">Soorena Salari</a>, 
<a href="/search/eess?searchtype=author&query=Rasoulian%2C+A">Amirhossein Rasoulian</a>, 
<a href="/search/eess?searchtype=author&query=Rivaz%2C+H">Hassan Rivaz</a>, 
<a href="/search/eess?searchtype=author&query=Xiao%2C+Y">Yiming Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IEEE IUS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Early surgical treatment of brain tumors is crucial in reducing patient
mortality rates. However, brain tissue deformation (called brain shift) occurs
during the surgery, rendering pre-operative images invalid. As a cost-effective
and portable tool, intra-operative ultrasound (iUS) can track brain shift, and
accurate MRI-iUS registration techniques can update pre-surgical plans and
facilitate the interpretation of iUS. This can boost surgical safety and
outcomes by maximizing tumor removal while avoiding eloquent regions. However,
manual assessment of MRI-iUS registration results in real-time is difficult and
prone to errors due to the 3D nature of the data. Automatic algorithms that can
quantify the quality of inter-modal medical image registration outcomes can be
highly beneficial. Therefore, we propose a novel deep-learning (DL) based
framework with the Swin UNETR to automatically assess 3D-patch-wise dense error
maps for MRI-iUS registration in iUS-guided brain tumor resection and show its
performance with real clinical data for the first time.
</p>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10787" title="Abstract">arXiv:2308.10787</a> (cross-list from quant-ph) [<a href="/pdf/2308.10787" title="Download PDF">pdf</a>, <a href="/format/2308.10787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-Time Compilation of Device-Level Instructions for Quantum  Subroutines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Dalvi%2C+A+S">Aniket S. Dalvi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Whitlow%2C+J">Jacob Whitlow</a>, 
<a href="/search/quant-ph?searchtype=author&query=D%27Onofrio%2C+M">Marissa D&#x27;Onofrio</a>, 
<a href="/search/quant-ph?searchtype=author&query=Riesebos%2C+L">Leon Riesebos</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+T">Tianyi Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Phiri%2C+S">Samuel Phiri</a>, 
<a href="/search/quant-ph?searchtype=author&query=Brown%2C+K+R">Kenneth R. Brown</a>, 
<a href="/search/quant-ph?searchtype=author&query=Baker%2C+J+M">Jonathan M. Baker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET); Software Engineering (cs.SE)

</div>
<p class="mathjax">A large class of problems in the current era of quantum devices involve
interfacing between the quantum and classical system. These include calibration
procedures, characterization routines, and variational algorithms. The control
in these routines iteratively switches between the classical and the quantum
computer. This results in the repeated compilation of the program that runs on
the quantum system, scaling directly with the number of circuits and
iterations. The repeated compilation results in a significant overhead
throughout the routine. In practice, the total runtime of the program
(classical compilation plus quantum execution) has an additional cost
proportional to the circuit count. At practical scales, this can dominate the
round-trip CPU-QPU time, between 5% and 80%, depending on the proportion of
quantum execution time.
<br />To avoid repeated device-level compilation, we identify that machine code can
be parametrized corresponding to pulse/gate parameters which can be dynamically
adjusted during execution. Therefore, we develop a device-level
partial-compilation (DLPC) technique that reduces compilation overhead to
nearly constant, by using cheap remote procedure calls (RPC) from the QPU
control software to the CPU. We then demonstrate the performance speedup of
this on optimal pulse calibration, system characterization using randomized
benchmarking (RB), and variational algorithms. We execute this modified
pipeline on real trapped-ion quantum computers and observe significant
reductions in compilation time, as much as 2.7x speedup for small-scale VQE
problems.
</p>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10790" title="Abstract">arXiv:2308.10790</a> (cross-list from eess.IV) [<a href="/pdf/2308.10790" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extraction of Text from Optic Nerve Optical Coherence Tomography Reports
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Majid%2C+I">Iyad Majid</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y+V">Youchen Victor Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Chang%2C+R">Robert Chang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+S+Y">Sophia Y. Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Purpose: The purpose of this study was to develop and evaluate rule-based
algorithms to enhance the extraction of text data, including retinal nerve
fiber layer (RNFL) values and other ganglion cell count (GCC) data, from Zeiss
Cirrus optical coherence tomography (OCT) scan reports. Methods: DICOM files
that contained encapsulated PDF reports with RNFL or Ganglion Cell in their
document titles were identified from a clinical imaging repository at a single
academic ophthalmic center. PDF reports were then converted into image files
and processed using the PaddleOCR Python package for optical character
recognition. Rule-based algorithms were designed and iteratively optimized for
improved performance in extracting RNFL and GCC data. Evaluation of the
algorithms was conducted through manual review of a set of RNFL and GCC
reports. Results: The developed algorithms demonstrated high precision in
extracting data from both RNFL and GCC scans. Precision was slightly better for
the right eye in RNFL extraction (OD: 0.9803 vs. OS: 0.9046), and for the left
eye in GCC extraction (OD: 0.9567 vs. OS: 0.9677). Some values presented more
challenges in extraction, particularly clock hours 5 and 6 for RNFL thickness,
and signal strength for GCC. Conclusions: A customized optical character
recognition algorithm can identify numeric results from optical coherence scan
reports with high precision. Automated processing of PDF reports can greatly
reduce the time to extract OCT results on a large scale.
</p>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10791" title="Abstract">arXiv:2308.10791</a> (cross-list from quant-ph) [<a href="/pdf/2308.10791" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Block-Ring connected Topology of Parameterized Quantum Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+W">Wenjie Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wu%2C+Q">Qingshan Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">It is essential to select efficient topology of parameterized quantum
circuits (PQCs) in variational quantum algorithms (VQAs). However, there are
problems in current circuits, i.e. optimization difficulties caused by too many
parameters or performance is hard to guarantee. How to reduce the number of
parameters (number of single-qubit rotation gates and 2-qubit gates) in PQCs
without reducing the performance has become a new challenge. To solve this
problem, we propose a novel topology, called Block-Ring (BR) topology, to
construct the PQCs. This topology allocate all qubits to several blocks,
all-to-all mode is adopt inside each block and ring mode is applied to connect
different blocks. Compared with the pure all-to-all topology circuits which own
the best power, BR topology have similar performance and the number of
parameters and 2-qubit gate reduced from 0(n^2) to 0(mn) , m is a
hyperparameter set by ourselves. Besides, we compared BR topology with other
topology circuits in terms of expressibility and entangling capability.
Considering the effects of different 2-qubit gates on circuits, we also make a
distinction between controlled X-rotation gates and controlled Z-rotation
gates. Finally, the 1- and 2-layer configurations of PQCs are taken into
consideration as well, which shows the BR's performance improvement in the
condition of multilayer circuits.
</p>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10818" title="Abstract">arXiv:2308.10818</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2308.10818" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable Ensemble Learning for Materials Property Prediction with  Classical Interatomic Potentials: Carbon as an Example
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Jiang%2C+X">Xinyu Jiang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Sun%2C+H">Haofan Sun</a>, 
<a href="/search/cond-mat?searchtype=author&query=Choudhary%2C+K">Kamal Choudhary</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zhuang%2C+H">Houlong Zhuang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Nian%2C+Q">Qiong Nian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine learning (ML) is widely used to explore crystal materials and predict
their properties. However, the training is time-consuming for deep-learning
models, and the regression process is a black box that is hard to interpret.
Also, the preprocess to transfer a crystal structure into the input of ML,
called descriptor, needs to be designed carefully. To efficiently predict
important properties of materials, we propose an approach based on ensemble
learning consisting of regression trees to predict formation energy and elastic
constants based on small-size datasets of carbon allotropes as an example.
Without using any descriptor, the inputs are the properties calculated by
molecular dynamics with 9 different classical interatomic potentials. Overall,
the results from ensemble learning are more accurate than those from classical
interatomic potentials, and ensemble learning can capture the relatively
accurate properties from the 9 classical potentials as criteria for predicting
the final properties.
</p>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10831" title="Abstract">arXiv:2308.10831</a> (cross-list from q-bio.NC) [<a href="/pdf/2308.10831" title="Download PDF">pdf</a>, <a href="/format/2308.10831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Excitatory/Inhibitory Balance Emerges as a Key Factor for RBN  Performance, Overriding Attractor Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Calvet%2C+E">Emmanuel Calvet</a>, 
<a href="/search/q-bio?searchtype=author&query=Rouat%2C+J">Jean Rouat</a>, 
<a href="/search/q-bio?searchtype=author&query=Reulet%2C+B">Bertrand Reulet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Front. Comput. Neurosci. Volume 17 - 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Computation (stat.CO)

</div>
<p class="mathjax">Reservoir computing provides a time and cost-efficient alternative to
traditional learning methods.Critical regimes, known as the "edge of chaos,"
have been found to optimize computational performance in binary neural
networks. However, little attention has been devoted to studying
reservoir-to-reservoir variability when investigating the link between
connectivity, dynamics, and performance. As physical reservoir computers become
more prevalent, developing a systematic approach to network design is crucial.
In this article, we examine Random Boolean Networks (RBNs) and demonstrate that
specific distribution parameters can lead to diverse dynamics near critical
points. We identify distinct dynamical attractors and quantify their
statistics, revealing that most reservoirs possess a dominant attractor. We
then evaluate performance in two challenging tasks, memorization and
prediction, and find that a positive excitatory balance produces a critical
point with higher memory performance. In comparison, a negative inhibitory
balance delivers another critical point with better prediction performance.
Interestingly, we show that the intrinsic attractor dynamics have little
influence on performance in either case.
</p>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10847" title="Abstract">arXiv:2308.10847</a> (cross-list from quant-ph) [<a href="/pdf/2308.10847" title="Download PDF">pdf</a>, <a href="/format/2308.10847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating quantum generative models via imbalanced data classification  benchmarks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Enos%2C+G+R">Graham R. Enos</a>, 
<a href="/search/quant-ph?searchtype=author&query=Reagor%2C+M+J">Matthew J. Reagor</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hulburd%2C+E">Eric Hulburd</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">A limited set of tools exist for assessing whether the behavior of quantum
machine learning models diverges from conventional models, outside of abstract
or theoretical settings. We present a systematic application of explainable
artificial intelligence techniques to analyze synthetic data generated from a
hybrid quantum-classical neural network adapted from twenty different
real-world data sets, including solar flares, cardiac arrhythmia, and speech
data. Each of these data sets exhibits varying degrees of complexity and class
imbalance. We benchmark the quantum-generated data relative to state-of-the-art
methods for mitigating class imbalance for associated classification tasks. We
leverage this approach to elucidate the qualities of a problem that make it
more or less likely to be amenable to a hybrid quantum-classical generative
model.
</p>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10871" title="Abstract">arXiv:2308.10871</a> (cross-list from stat.CO) [<a href="/pdf/2308.10871" title="Download PDF">pdf</a>, <a href="/format/2308.10871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FunQuant: A R package to perform quantization in the context of rare  events and time-consuming simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sire%2C+C">Charlie Sire</a>, 
<a href="/search/stat?searchtype=author&query=Richet%2C+Y">Yann Richet</a>, 
<a href="/search/stat?searchtype=author&query=Riche%2C+R+L">Rodolphe Le Riche</a>, 
<a href="/search/stat?searchtype=author&query=Rulli%C3%A8re%2C+D">Didier Rulli&#xe8;re</a>, 
<a href="/search/stat?searchtype=author&query=Rohmer%2C+J">J&#xe9;r&#xe9;my Rohmer</a>, 
<a href="/search/stat?searchtype=author&query=Pheulpin%2C+L">Lucie Pheulpin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures. Submitted to Journal Of Open Source Software
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation (stat.CO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Quantization summarizes continuous distributions by calculating a discrete
approximation. Among the widely adopted methods for data quantization is
Lloyd's algorithm, which partitions the space into Vorono\"i cells, that can be
seen as clusters, and constructs a discrete distribution based on their
centroids and probabilistic masses. Lloyd's algorithm estimates the optimal
centroids in a minimal expected distance sense, but this approach poses
significant challenges in scenarios where data evaluation is costly, and
relates to rare events. Then, the single cluster associated to no event takes
the majority of the probability mass. In this context, a metamodel is required
and adapted sampling methods are necessary to increase the precision of the
computations on the rare clusters.
</p>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10877" title="Abstract">arXiv:2308.10877</a> (cross-list from stat.CO) [<a href="/pdf/2308.10877" title="Download PDF">pdf</a>, <a href="/ps/2308.10877" title="Download PostScript">ps</a>, <a href="/format/2308.10877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monte Carlo on manifolds in high dimensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Xu%2C+K">Kerun Xu</a>, 
<a href="/search/stat?searchtype=author&query=Holmes-Cerfon%2C+M">Miranda Holmes-Cerfon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation (stat.CO)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We introduce an efficient numerical implementation of a Markov Chain Monte
Carlo method to sample a probability distribution on a manifold (introduced
theoretically in Zappa, Holmes-Cerfon, Goodman (2018)), where the manifold is
defined by the level set of constraint functions, and the probability
distribution may involve the pseudodeterminant of the Jacobian of the
constraints, as arises in physical sampling problems. The algorithm is easy to
implement and scales well to problems with thousands of dimensions and with
complex sets of constraints provided their Jacobian retains sparsity. The
algorithm uses direct linear algebra and requires a single matrix factorization
per proposal point, which enhances its efficiency over previously proposed
methods but becomes the computational bottleneck of the algorithm in high
dimensions. We test the algorithm on several examples inspired by soft-matter
physics and materials science to study its complexity and properties.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Tue, 22 Aug 23</h3>
<dl>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1705.10648" title="Abstract">arXiv:1705.10648</a> (replaced) [<a href="/pdf/1705.10648" title="Download PDF">pdf</a>, <a href="/format/1705.10648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Logarithmic Funnel Heap: An Efficient Indexed Priority Queue
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Loeffeld%2C+C">Christian Loeffeld</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1709.09585" title="Abstract">arXiv:1709.09585</a> (replaced) [<a href="/pdf/1709.09585" title="Download PDF">pdf</a>, <a href="/format/1709.09585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepTransport: Learning Spatial-Temporal Dependency for Traffic  Condition Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xingyi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruiqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1712.00897" title="Abstract">arXiv:1712.00897</a> (replaced) [<a href="/pdf/1712.00897" title="Download PDF">pdf</a>, <a href="/format/1712.00897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial Manifestations of Order Reduction in Runge-Kutta Methods for  Initial Boundary Value Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Rosales%2C+R+R">Rodolfo Ruben Rosales</a>, 
<a href="/search/math?searchtype=author&query=Seibold%2C+B">Benjamin Seibold</a>, 
<a href="/search/math?searchtype=author&query=Shirokoff%2C+D">David Shirokoff</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+D">Dong Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1810.03579" title="Abstract">arXiv:1810.03579</a> (replaced) [<a href="/pdf/1810.03579" title="Download PDF">pdf</a>, <a href="/format/1810.03579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long ties accelerate noisy threshold-based contagions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eckles%2C+D">Dean Eckles</a>, 
<a href="/search/cs?searchtype=author&query=Mossel%2C+E">Elchanan Mossel</a>, 
<a href="/search/cs?searchtype=author&query=Rahimian%2C+M+A">M. Amin Rahimian</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+S">Subhabrata Sen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Probability (math.PR); Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1912.08917" title="Abstract">arXiv:1912.08917</a> (replaced) [<a href="/pdf/1912.08917" title="Download PDF">pdf</a>, <a href="/ps/1912.08917" title="Download PostScript">ps</a>, <a href="/format/1912.08917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Logarithmic Regret in Multisecretary and Online Linear Programming  Problems with Continuous Valuations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bray%2C+R+L">Robert L. Bray</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2011.13772" title="Abstract">arXiv:2011.13772</a> (replaced) [<a href="/pdf/2011.13772" title="Download PDF">pdf</a>, <a href="/format/2011.13772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient Descent for Deep Matrix Factorization: Dynamics and Implicit  Bias towards Low Rank
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chou%2C+H">Hung-Hsu Chou</a>, 
<a href="/search/cs?searchtype=author&query=Gieshoff%2C+C">Carsten Gieshoff</a>, 
<a href="/search/cs?searchtype=author&query=Maly%2C+J">Johannes Maly</a>, 
<a href="/search/cs?searchtype=author&query=Rauhut%2C+H">Holger Rauhut</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2012.04841" title="Abstract">arXiv:2012.04841</a> (replaced) [<a href="/pdf/2012.04841" title="Download PDF">pdf</a>, <a href="/format/2012.04841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-Vote Veto: Semi-Supervised Learning for Low-Shot Glaucoma Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+R">Rui Fan</a>, 
<a href="/search/cs?searchtype=author&query=Bowd%2C+C">Christopher Bowd</a>, 
<a href="/search/cs?searchtype=author&query=Brye%2C+N">Nicole Brye</a>, 
<a href="/search/cs?searchtype=author&query=Christopher%2C+M">Mark Christopher</a>, 
<a href="/search/cs?searchtype=author&query=Weinreb%2C+R+N">Robert N. Weinreb</a>, 
<a href="/search/cs?searchtype=author&query=Kriegman%2C+D">David Kriegman</a>, 
<a href="/search/cs?searchtype=author&query=Zangwill%2C+L+M">Linda M. Zangwill</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by IEEE Transactions on Medical Imaging (T-MI). DOI: 10.1109/TMI.2023.3307689
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2101.00256" title="Abstract">arXiv:2101.00256</a> (replaced) [<a href="/pdf/2101.00256" title="Download PDF">pdf</a>, <a href="/format/2101.00256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 5G MEC Computation Handoff for Mobile Augmented Reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Pengyuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+S">Shuhao Fu</a>, 
<a href="/search/cs?searchtype=author&query=Finley%2C+B">Benjamin Finley</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuebing Li</a>, 
<a href="/search/cs?searchtype=author&query=Tarkoma%2C+S">Sasu Tarkoma</a>, 
<a href="/search/cs?searchtype=author&query=Kangasharju%2C+J">Jussi Kangasharju</a>, 
<a href="/search/cs?searchtype=author&query=Ammar%2C+M">Mostafa Ammar</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+P">Pan Hui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2101.07107" title="Abstract">arXiv:2101.07107</a> (replaced) [<a href="/pdf/2101.07107" title="Download PDF">pdf</a>, <a href="/format/2101.07107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning for Active High Frequency Trading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Briola%2C+A">Antonio Briola</a>, 
<a href="/search/cs?searchtype=author&query=Turiel%2C+J">Jeremy Turiel</a>, 
<a href="/search/cs?searchtype=author&query=Marcaccioli%2C+R">Riccardo Marcaccioli</a>, 
<a href="/search/cs?searchtype=author&query=Cauderan%2C+A">Alvaro Cauderan</a>, 
<a href="/search/cs?searchtype=author&query=Aste%2C+T">Tomaso Aste</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Trading and Market Microstructure (q-fin.TR)

</div>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2101.10861" title="Abstract">arXiv:2101.10861</a> (replaced) [<a href="/pdf/2101.10861" title="Download PDF">pdf</a>, <a href="/format/2101.10861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Review on Deep Learning in UAV Remote Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Osco%2C+L+P">Lucas Prado Osco</a>, 
<a href="/search/cs?searchtype=author&query=Junior%2C+J+M">Jos&#xe9; Marcato Junior</a>, 
<a href="/search/cs?searchtype=author&query=Ramos%2C+A+P+M">Ana Paula Marques Ramos</a>, 
<a href="/search/cs?searchtype=author&query=de+Castro+Jorge%2C+L+A">L&#xfa;cio Andr&#xe9; de Castro Jorge</a>, 
<a href="/search/cs?searchtype=author&query=Fatholahi%2C+S+N">Sarah Narges Fatholahi</a>, 
<a href="/search/cs?searchtype=author&query=de+Andrade+Silva%2C+J">Jonathan de Andrade Silva</a>, 
<a href="/search/cs?searchtype=author&query=Matsubara%2C+E+T">Edson Takashi Matsubara</a>, 
<a href="/search/cs?searchtype=author&query=Pistori%2C+H">Hemerson Pistori</a>, 
<a href="/search/cs?searchtype=author&query=Gon%C3%A7alves%2C+W+N">Wesley Nunes Gon&#xe7;alves</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jonathan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 10 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Applied Earth Observation and
  Geoinformation, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.07081" title="Abstract">arXiv:2102.07081</a> (replaced) [<a href="/pdf/2102.07081" title="Download PDF">pdf</a>, <a href="/format/2102.07081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Proper Scoring Rules to Max-Min Optimal Forecast Aggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Neyman%2C+E">Eric Neyman</a>, 
<a href="/search/cs?searchtype=author&query=Roughgarden%2C+T">Tim Roughgarden</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.08786" title="Abstract">arXiv:2102.08786</a> (replaced) [<a href="/pdf/2102.08786" title="Download PDF">pdf</a>, <a href="/format/2102.08786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Walking Out of the Weisfeiler Leman Hierarchy: Graph Learning Beyond  Message Passing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=T%C3%B6nshoff%2C+J">Jan T&#xf6;nshoff</a>, 
<a href="/search/cs?searchtype=author&query=Ritzert%2C+M">Martin Ritzert</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+H">Hinrikus Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Grohe%2C+M">Martin Grohe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.00852" title="Abstract">arXiv:2103.00852</a> (replaced) [<a href="/pdf/2103.00852" title="Download PDF">pdf</a>, <a href="/format/2103.00852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CrossMap Transformer: A Crossmodal Masked Path Transformer Using Double  Back-Translation for Vision-and-Language Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Magassouba%2C+A">Aly Magassouba</a>, 
<a href="/search/cs?searchtype=author&query=Sugiura%2C+K">Komei Sugiura</a>, 
<a href="/search/cs?searchtype=author&query=Kawai%2C+H">Hisashi Kawai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, 5 tables. Submitted to IEEE Robotics and Automation Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.05519" title="Abstract">arXiv:2104.05519</a> (replaced) [<a href="/pdf/2104.05519" title="Download PDF">pdf</a>, <a href="/format/2104.05519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cloth Interactive Transformer for Virtual Try-On
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+B">Bin Ren</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fanyang Meng</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+R">Runwei Ding</a>, 
<a href="/search/cs?searchtype=author&query=Torr%2C+P+H+S">Philip H.S. Torr</a>, 
<a href="/search/cs?searchtype=author&query=Sebe%2C+N">Nicu Sebe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 7 figures, Accepted by ACM ToMM in 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.07903" title="Abstract">arXiv:2104.07903</a> (replaced) [<a href="/pdf/2104.07903" title="Download PDF">pdf</a>, <a href="/format/2104.07903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Pathway to Approximate Energy Expenditure and Recovery of an  Athlete
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weigend%2C+F+C">Fabian Clemens Weigend</a>, 
<a href="/search/cs?searchtype=author&query=Siegler%2C+J">Jason Siegler</a>, 
<a href="/search/cs?searchtype=author&query=Obst%2C+O">Oliver Obst</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures, 3 tables, to appear in GECCO-21
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.12856" title="Abstract">arXiv:2104.12856</a> (replaced) [<a href="/pdf/2104.12856" title="Download PDF">pdf</a>, <a href="/format/2104.12856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Free Vibration analysis of Curvilinearly Stiffened Composite plates with  an arbitrarily shaped cutout using Isogeometric Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Devarajan%2C+B">Balakrishnan Devarajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2104.05132">arXiv:2104.05132</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.12949" title="Abstract">arXiv:2104.12949</a> (replaced) [<a href="/pdf/2104.12949" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discriminative Bayesian filtering lends momentum to the stochastic  Newton method for minimizing log-convex functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Burkhart%2C+M+C">Michael C. Burkhart</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Optimization Letters 17 (2023) 657-673
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.04923" title="Abstract">arXiv:2106.04923</a> (replaced) [<a href="/pdf/2106.04923" title="Download PDF">pdf</a>, <a href="/format/2106.04923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Domain Invariant Representations by Joint Wasserstein Distance  Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Andeol%2C+L">L&#xe9;o Andeol</a>, 
<a href="/search/stat?searchtype=author&query=Kawakami%2C+Y">Yusei Kawakami</a>, 
<a href="/search/stat?searchtype=author&query=Wada%2C+Y">Yuichiro Wada</a>, 
<a href="/search/stat?searchtype=author&query=Kanamori%2C+T">Takafumi Kanamori</a>, 
<a href="/search/stat?searchtype=author&query=M%C3%BCller%2C+K">Klaus-Robert M&#xfc;ller</a>, 
<a href="/search/stat?searchtype=author&query=Montavon%2C+G">Gr&#xe9;goire Montavon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages + supplement
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.10545" title="Abstract">arXiv:2107.10545</a> (replaced) [<a href="/pdf/2107.10545" title="Download PDF">pdf</a>, <a href="/ps/2107.10545" title="Download PostScript">ps</a>, <a href="/format/2107.10545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fundamental Constructs in Programming Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mosses%2C+P+D">Peter D. Mosses</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, incl. 3 figures and 7 appendices, accepted for publication in Proceedings of ISoLA 2021; updates the submitted version with clarifications and minor enhancements
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.06936" title="Abstract">arXiv:2108.06936</a> (replaced) [<a href="/pdf/2108.06936" title="Download PDF">pdf</a>, <a href="/ps/2108.06936" title="Download PostScript">ps</a>, <a href="/format/2108.06936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decomposed Richelot isogenies of Jacobian varieties of hyperelliptic  curves and generalized Howe curves
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Katsura%2C+T">Toshiyuki Katsura</a>, 
<a href="/search/math?searchtype=author&query=Takashima%2C+K">Katsuyuki Takashima</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages. We added some explanations of back ground
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Geometry (math.AG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.13308" title="Abstract">arXiv:2108.13308</a> (replaced) [<a href="/pdf/2108.13308" title="Download PDF">pdf</a>, <a href="/format/2108.13308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GoPRONTO: a Feedback-based Framework for Nonlinear Optimal Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sforni%2C+L">Lorenzo Sforni</a>, 
<a href="/search/math?searchtype=author&query=Spedicato%2C+S">Sara Spedicato</a>, 
<a href="/search/math?searchtype=author&query=Notarnicola%2C+I">Ivano Notarnicola</a>, 
<a href="/search/math?searchtype=author&query=Notarstefano%2C+G">Giuseppe Notarstefano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.02081" title="Abstract">arXiv:2109.02081</a> (replaced) [<a href="/pdf/2109.02081" title="Download PDF">pdf</a>, <a href="/format/2109.02081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Person Generation: A Survey from the Perspective of Face, Pose and  Cloth Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sha%2C+T">Tong Sha</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+T">Tong Shen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhoujun Li</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+T">Tao Mei</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM Computing Surveys, 2023, 55(12): 1-37
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.04269" title="Abstract">arXiv:2109.04269</a> (replaced) [<a href="/pdf/2109.04269" title="Download PDF">pdf</a>, <a href="/format/2109.04269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asynchronous Federated Learning on Heterogeneous Devices: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chenhao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Youyang Qu</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Y">Yong Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Longxiang Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.12727" title="Abstract">arXiv:2109.12727</a> (replaced) [<a href="/pdf/2109.12727" title="Download PDF">pdf</a>, <a href="/format/2109.12727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anomalous Edge Detection in Edge Exchangeable Social Network Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+R">Rui Luo</a>, 
<a href="/search/cs?searchtype=author&query=Nettasinghe%2C+B">Buddhika Nettasinghe</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+V">Vikram Krishnamurthy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.07000" title="Abstract">arXiv:2110.07000</a> (replaced) [<a href="/pdf/2110.07000" title="Download PDF">pdf</a>, <a href="/format/2110.07000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed-integer linear programming approaches for tree partitioning of  power networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lan%2C+L">Leon Lan</a>, 
<a href="/search/math?searchtype=author&query=Zocca%2C+A">Alessandro Zocca</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.13939" title="Abstract">arXiv:2110.13939</a> (replaced) [<a href="/pdf/2110.13939" title="Download PDF">pdf</a>, <a href="/format/2110.13939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CausalAF: Causal Autoregressive Flow for Safety-Critical Driving  Scenario Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Wenhao Ding</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Haohong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Ding Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Acceptted to CoRL 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.14308" title="Abstract">arXiv:2110.14308</a> (replaced) [<a href="/pdf/2110.14308" title="Download PDF">pdf</a>, <a href="/format/2110.14308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Token Games and History-Deterministic Quantitative-Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boker%2C+U">Udi Boker</a>, 
<a href="/search/cs?searchtype=author&query=Lehtinen%2C+K">Karoliina Lehtinen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.15073" title="Abstract">arXiv:2110.15073</a> (replaced) [<a href="/pdf/2110.15073" title="Download PDF">pdf</a>, <a href="/format/2110.15073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MMD Aggregated Two-Sample Test
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Schrab%2C+A">Antonin Schrab</a>, 
<a href="/search/stat?searchtype=author&query=Kim%2C+I">Ilmun Kim</a>, 
<a href="/search/stat?searchtype=author&query=Albert%2C+M">M&#xe9;lisande Albert</a>, 
<a href="/search/stat?searchtype=author&query=Laurent%2C+B">B&#xe9;atrice Laurent</a>, 
<a href="/search/stat?searchtype=author&query=Guedj%2C+B">Benjamin Guedj</a>, 
<a href="/search/stat?searchtype=author&query=Gretton%2C+A">Arthur Gretton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 81 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Machine Learning Research 24(194), 1-81, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.03237" title="Abstract">arXiv:2111.03237</a> (replaced) [<a href="/pdf/2111.03237" title="Download PDF">pdf</a>, <a href="/format/2111.03237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Designing Optimal Sensing Matrices for Generalized Linear  Inverse Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Junjie Ma</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Ji Xu</a>, 
<a href="/search/cs?searchtype=author&query=Maleki%2C+A">Arian Maleki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to appear in IEEE transactions on information theory
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.04479" title="Abstract">arXiv:2111.04479</a> (replaced) [<a href="/pdf/2111.04479" title="Download PDF">pdf</a>, <a href="/format/2111.04479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ExtremeBB: A Database for Large-Scale Research into Online Hate,  Harassment, the Manosphere and Extremism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vu%2C+A+V">Anh V. Vu</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+L">Lydia Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+Y+T">Yi Ting Chua</a>, 
<a href="/search/cs?searchtype=author&query=Shumailov%2C+I">Ilia Shumailov</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+R">Ross Anderson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item671">[671]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.05687" title="Abstract">arXiv:2111.05687</a> (replaced) [<a href="/pdf/2111.05687" title="Download PDF">pdf</a>, <a href="/format/2111.05687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Adaptive Stochastic Score Classification and Explainable Halfspace  Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghuge%2C+R">Rohan Ghuge</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Anupam Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Nagarajan%2C+V">Viswanath Nagarajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of IPCO 2022 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item672">[672]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.08794" title="Abstract">arXiv:2111.08794</a> (replaced) [<a href="/pdf/2111.08794" title="Download PDF">pdf</a>, <a href="/format/2111.08794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Conversion from Mild Cognitive Impairment to Alzheimer&#x27;s  Disease using Latent Space Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ayvaz%2C+D+S">Deniz Sezin Ayvaz</a>, 
<a href="/search/cs?searchtype=author&query=Baytas%2C+I+M">Inci M. Baytas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item673">[673]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.14185" title="Abstract">arXiv:2111.14185</a> (replaced) [<a href="/pdf/2111.14185" title="Download PDF">pdf</a>, <a href="/format/2111.14185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MALIGN: Explainable Static Raw-byte Based Malware Family Classification  using Sequence Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saha%2C+S">Shoumik Saha</a>, 
<a href="/search/cs?searchtype=author&query=Afroz%2C+S">Sadia Afroz</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+A">Atif Rahman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item674">[674]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.14422" title="Abstract">arXiv:2111.14422</a> (replaced) [<a href="/pdf/2111.14422" title="Download PDF">pdf</a>, <a href="/format/2111.14422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agent-Centric Relation Graph for Object Visual Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaobo Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Youfang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhihao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+K">Kai Lv</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 13 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item675">[675]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.06786" title="Abstract">arXiv:2201.06786</a> (replaced) [<a href="/pdf/2201.06786" title="Download PDF">pdf</a>, <a href="/format/2201.06786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Multimodal Word Discovery based on Double Articulation  Analysis with Co-occurrence cues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taniguchi%2C+A">Akira Taniguchi</a>, 
<a href="/search/cs?searchtype=author&query=Murakami%2C+H">Hiroaki Murakami</a>, 
<a href="/search/cs?searchtype=author&query=Ozaki%2C+R">Ryo Ozaki</a>, 
<a href="/search/cs?searchtype=author&query=Taniguchi%2C+T">Tadahiro Taniguchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE TRANSACTIONS ON COGNITIVE DEVELOPMENTAL SYSTEMS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item676">[676]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.09636" title="Abstract">arXiv:2201.09636</a> (replaced) [<a href="/pdf/2201.09636" title="Download PDF">pdf</a>, <a href="/format/2201.09636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Implicit Surface Evolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Novello%2C+T">Tiago Novello</a>, 
<a href="/search/cs?searchtype=author&query=da+Silva%2C+V">Vinicius da Silva</a>, 
<a href="/search/cs?searchtype=author&query=Schardong%2C+G">Guilherme Schardong</a>, 
<a href="/search/cs?searchtype=author&query=Schirmer%2C+L">Luiz Schirmer</a>, 
<a href="/search/cs?searchtype=author&query=Lopes%2C+H">Helio Lopes</a>, 
<a href="/search/cs?searchtype=author&query=Velho%2C+L">Luiz Velho</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item677">[677]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.06533" title="Abstract">arXiv:2202.06533</a> (replaced) [<a href="/pdf/2202.06533" title="Download PDF">pdf</a>, <a href="/format/2202.06533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Introduction to Neural Data Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yibo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Mandt%2C+S">Stephan Mandt</a>, 
<a href="/search/cs?searchtype=author&query=Theis%2C+L">Lucas Theis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Foundations and Trends in Computer Graphics and Vision: Vol. 15, No. 2, pp 113-200. <a href="https://www.nowpublishers.com/article/Details/CGV-107">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item678">[678]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.11885" title="Abstract">arXiv:2202.11885</a> (replaced) [<a href="/e-print/2202.11885" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Partition-and-Merge Algorithm for Solving the Steiner Tree Problem in  Large Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xinyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jin-Kao Hao</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Z">Zhang-Hua Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The problem and techniques of our paper have been studied long ago, so it is currently meaningless. Therefore, we are preparing to withdraw the manuscript
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item679">[679]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.03776" title="Abstract">arXiv:2203.03776</a> (replaced) [<a href="/pdf/2203.03776" title="Download PDF">pdf</a>, <a href="/format/2203.03776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Trainable Approach to Zero-delay Smoothing Spline Interpolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruiz-Moreno%2C+E">Emilio Ruiz-Moreno</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez-Ramos%2C+L+M">Luis Miguel L&#xf3;pez-Ramos</a>, 
<a href="/search/cs?searchtype=author&query=Beferull-Lozano%2C+B">Baltasar Beferull-Lozano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item680">[680]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.03816" title="Abstract">arXiv:2203.03816</a> (replaced) [<a href="/pdf/2203.03816" title="Download PDF">pdf</a>, <a href="/format/2203.03816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Volume in Practice: What Users Can Expect from NISQ Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Pelofske%2C+E">Elijah Pelofske</a>, 
<a href="/search/quant-ph?searchtype=author&query=B%C3%A4rtschi%2C+A">Andreas B&#xe4;rtschi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Eidenbenz%2C+S">Stephan Eidenbenz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v5: typo fixes and improved typesetting
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Quantum Engineering, vol. 3, pp. 1-19, 2022,
  Art no. 3102119
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item681">[681]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.05186" title="Abstract">arXiv:2203.05186</a> (replaced) [<a href="/pdf/2203.05186" title="Download PDF">pdf</a>, <a href="/format/2203.05186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Suspected Object Matters: Rethinking Model&#x27;s Prediction for One-stage  Visual Grounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiao%2C+Y">Yang Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Jie%2C+Z">Zequn Jie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingjing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu-Gang Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ACM MM 23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item682">[682]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.06424" title="Abstract">arXiv:2203.06424</a> (replaced) [<a href="/e-print/2203.06424" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VariabilityTrack:Multi-Object Tracking with Variable Speed Object  Movement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+R">Run Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">JinLin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qiao Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> we will refine the paper in the future
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item683">[683]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.14432" title="Abstract">arXiv:2203.14432</a> (replaced) [<a href="/pdf/2203.14432" title="Download PDF">pdf</a>, <a href="/format/2203.14432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Encoding trade-offs and design toolkits in quantum algorithms for  discrete optimization: coloring, routing, scheduling, and other problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Sawaya%2C+N+P">Nicolas PD Sawaya</a>, 
<a href="/search/quant-ph?searchtype=author&query=Schmitz%2C+A+T">Albert T Schmitz</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hadfield%2C+S">Stuart Hadfield</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages; 11 figures; Accepted to Quantum Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item684">[684]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.15457" title="Abstract">arXiv:2203.15457</a> (replaced) [<a href="/pdf/2203.15457" title="Download PDF">pdf</a>, <a href="/ps/2203.15457" title="Download PostScript">ps</a>, <a href="/format/2203.15457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uniqueness of the Gibbs measure for the anti-ferromagnetic Potts model  on the infinite $&#x394;$-regular tree for large $&#x394;$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bencs%2C+F">Ferenc Bencs</a>, 
<a href="/search/math?searchtype=author&query=de+Boer%2C+D">David de Boer</a>, 
<a href="/search/math?searchtype=author&query=Buys%2C+P">Pjotr Buys</a>, 
<a href="/search/math?searchtype=author&query=Regts%2C+G">Guus Regts</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 1 figure. Small corrections based on referee comments. Published in Journal of Statistical Physics
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J Stat Phys 190, 140 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Discrete Mathematics (cs.DM); Mathematical Physics (math-ph); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item685">[685]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.16475" title="Abstract">arXiv:2203.16475</a> (replaced) [<a href="/pdf/2203.16475" title="Download PDF">pdf</a>, <a href="/format/2203.16475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concept Evolution in Deep Learning Training: A Unified Interpretation  Framework and Discoveries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Haekyu Park</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seongmin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hoover%2C+B">Benjamin Hoover</a>, 
<a href="/search/cs?searchtype=author&query=Wright%2C+A+P">Austin P. Wright</a>, 
<a href="/search/cs?searchtype=author&query=Shaikh%2C+O">Omar Shaikh</a>, 
<a href="/search/cs?searchtype=author&query=Duggal%2C+R">Rahul Duggal</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+N">Nilaksh Das</a>, 
<a href="/search/cs?searchtype=author&query=Hoffman%2C+J">Judy Hoffman</a>, 
<a href="/search/cs?searchtype=author&query=Chau%2C+D+H">Duen Horng Chau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CIKM'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item686">[686]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.02654" title="Abstract">arXiv:2205.02654</a> (replaced) [<a href="/pdf/2205.02654" title="Download PDF">pdf</a>, <a href="/format/2205.02654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial-Time Algorithms for Counting and Sampling Markov Equivalent  DAGs with Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wien%C3%B6bst%2C+M">Marcel Wien&#xf6;bst</a>, 
<a href="/search/cs?searchtype=author&query=Bannach%2C+M">Max Bannach</a>, 
<a href="/search/cs?searchtype=author&query=Li%C5%9Bkiewicz%2C+M">Maciej Li&#x15b;kiewicz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2012.09679">arXiv:2012.09679</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Machine Learning Research 24(213):1-45, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item687">[687]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.02913" title="Abstract">arXiv:2205.02913</a> (replaced) [<a href="/pdf/2205.02913" title="Download PDF">pdf</a>, <a href="/format/2205.02913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exponentially Stable Adaptive Optimal Control of Uncertain LTI Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Glushchenko%2C+A">Anton Glushchenko</a>, 
<a href="/search/eess?searchtype=author&query=Lastochkin%2C+K">Konstantin Lastochkin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item688">[688]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.09420" title="Abstract">arXiv:2205.09420</a> (replaced) [<a href="/pdf/2205.09420" title="Download PDF">pdf</a>, <a href="/format/2205.09420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multicast Scheduling over Multiple Channels: A Distribution-Embedding  Deep Reinforcement Learning Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ran Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+X">Xiaoqi Qin</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+S">Shengpei Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item689">[689]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.01409" title="Abstract">arXiv:2206.01409</a> (replaced) [<a href="/pdf/2206.01409" title="Download PDF">pdf</a>, <a href="/format/2206.01409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Models for Mixed Variables in Bayesian Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Hengrui Luo</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+Y">Younghyun Cho</a>, 
<a href="/search/cs?searchtype=author&query=Demmel%2C+J+W">James W. Demmel</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X+S">Xiaoye S. Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 8 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item690">[690]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.02034" title="Abstract">arXiv:2206.02034</a> (replaced) [<a href="/pdf/2206.02034" title="Download PDF">pdf</a>, <a href="/format/2206.02034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Control Theoretic Framework for Adaptive Gradient Optimizers in  Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chakrabarti%2C+K">Kushal Chakrabarti</a>, 
<a href="/search/cs?searchtype=author&query=Chopra%2C+N">Nikhil Chopra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item691">[691]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.03753" title="Abstract">arXiv:2206.03753</a> (replaced) [<a href="/pdf/2206.03753" title="Download PDF">pdf</a>, <a href="/format/2206.03753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task Agnostic Restoration of Natural Video Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali%2C+M+K">Muhammad Kashif Ali</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dongjin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T+H">Tae Hyun Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item692">[692]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.07425" title="Abstract">arXiv:2206.07425</a> (replaced) [<a href="/pdf/2206.07425" title="Download PDF">pdf</a>, <a href="/format/2206.07425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discrete-time Layered-network Epidemics Model with Time-varying  Transition Rates and Multiple Resources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cui%2C+S">Shaoxuan Cui</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+F">Fangzhou Liu</a>, 
<a href="/search/eess?searchtype=author&query=Jard%C3%B3n-Kojakhmetov%2C+H">Hildeberto Jard&#xf3;n-Kojakhmetov</a>, 
<a href="/search/eess?searchtype=author&query=Cao%2C+M">Ming Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item693">[693]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.09479" title="Abstract">arXiv:2206.09479</a> (replaced) [<a href="/pdf/2206.09479" title="Download PDF">pdf</a>, <a href="/format/2206.09479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StudioGAN: A Taxonomy and Benchmark of GANs for Image Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+M">Minguk Kang</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+J">Joonghyuk Shin</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jaesik Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI, 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item694">[694]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.10786" title="Abstract">arXiv:2206.10786</a> (replaced) [<a href="/pdf/2206.10786" title="Download PDF">pdf</a>, <a href="/format/2206.10786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Pretraining for Black-Box Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krishnamoorthy%2C+S">Siddarth Krishnamoorthy</a>, 
<a href="/search/cs?searchtype=author&query=Mashkaria%2C+S+M">Satvik Mehul Mashkaria</a>, 
<a href="/search/cs?searchtype=author&query=Grover%2C+A">Aditya Grover</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference for Machine Learning 2023 NeurIPS Workshop for Foundational Models for Decision Making (Oral) 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item695">[695]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.11421" title="Abstract">arXiv:2206.11421</a> (replaced) [<a href="/pdf/2206.11421" title="Download PDF">pdf</a>, <a href="/format/2206.11421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Specifying for Trustworthiness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abeywickrama%2C+D+B">Dhaminda B. Abeywickrama</a>, 
<a href="/search/cs?searchtype=author&query=Bennaceur%2C+A">Amel Bennaceur</a>, 
<a href="/search/cs?searchtype=author&query=Chance%2C+G">Greg Chance</a>, 
<a href="/search/cs?searchtype=author&query=Demiris%2C+Y">Yiannis Demiris</a>, 
<a href="/search/cs?searchtype=author&query=Kordoni%2C+A">Anastasia Kordoni</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+M">Mark Levine</a>, 
<a href="/search/cs?searchtype=author&query=Moffat%2C+L">Luke Moffat</a>, 
<a href="/search/cs?searchtype=author&query=Moreau%2C+L">Luc Moreau</a>, 
<a href="/search/cs?searchtype=author&query=Mousavi%2C+M+R">Mohammad Reza Mousavi</a>, 
<a href="/search/cs?searchtype=author&query=Nuseibeh%2C+B">Bashar Nuseibeh</a>, 
<a href="/search/cs?searchtype=author&query=Ramamoorthy%2C+S">Subramanian Ramamoorthy</a>, 
<a href="/search/cs?searchtype=author&query=Ringert%2C+J+O">Jan Oliver Ringert</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+J">James Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Windsor%2C+S">Shane Windsor</a>, 
<a href="/search/cs?searchtype=author&query=Eder%2C+K">Kerstin Eder</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted version of paper. 13 pages, 1 table, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item696">[696]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.00725" title="Abstract">arXiv:2207.00725</a> (replaced) [<a href="/pdf/2207.00725" title="Download PDF">pdf</a>, <a href="/format/2207.00725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metacognitive Decision Making Framework for Multi-UAV Target Search  Without Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Senthilnath%2C+J">J. Senthilnath</a>, 
<a href="/search/cs?searchtype=author&query=Harikumar%2C+K">K. Harikumar</a>, 
<a href="/search/cs?searchtype=author&query=Suresh%2C+S">S. Suresh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
</div>
</dd>
<dt><a name="item697">[697]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.01203" title="Abstract">arXiv:2207.01203</a> (replaced) [<a href="/pdf/2207.01203" title="Download PDF">pdf</a>, <a href="/format/2207.01203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Robust Referring Video Object Segmentation with Cyclic  Relational Consensus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinglu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaohao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Raj%2C+B">Bhiksha Raj</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yan Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> iccv 2023, <a href="https://github.com/lxa9867/R2VOS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item698">[698]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.10240" title="Abstract">arXiv:2207.10240</a> (replaced) [<a href="/pdf/2207.10240" title="Download PDF">pdf</a>, <a href="/format/2207.10240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Partial Set Cover with Applications to Facility  Location
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G+Z">George Z. Li</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D">Dung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Vullikanti%2C+A">Anil Vullikanti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 2 figures. Full version of IJCAI 2023 publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item699">[699]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.10425" title="Abstract">arXiv:2207.10425</a> (replaced) [<a href="/pdf/2207.10425" title="Download PDF">pdf</a>, <a href="/format/2207.10425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KD-MVS: Knowledge Distillation Based Self-supervised Learning for  Multi-view Stereo
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yikang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qingtian Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiangyue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Wentao Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haotian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item700">[700]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.11437" title="Abstract">arXiv:2207.11437</a> (replaced) [<a href="/pdf/2207.11437" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The prediction of the quality of results in Logic Synthesis using  Transformer and Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chenghao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongda Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yinshui Xia</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+Z">Zhufei Chu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item701">[701]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.11836" title="Abstract">arXiv:2207.11836</a> (replaced) [<a href="/pdf/2207.11836" title="Download PDF">pdf</a>, <a href="/format/2207.11836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating the Performance Sacrifice in DP-Satisfied Federated Settings  through Graph Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Haoran Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Muyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongxu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guandong Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Information Sciences
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item702">[702]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.04670" title="Abstract">arXiv:2208.04670</a> (replaced) [<a href="/e-print/2208.04670" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability of linear multiagent systems with guaranteed steady-state  performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Debele%2C+G+M">Gurmu Meseret Debele</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The article lacks quality methodology and the author decided to withdraw it for further revision
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item703">[703]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.05110" title="Abstract">arXiv:2208.05110</a> (replaced) [<a href="/pdf/2208.05110" title="Download PDF">pdf</a>, <a href="/format/2208.05110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Propagation on Multiple Instance Graphs for 3D Instance  Segmentation with Single-point Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+S">Shichao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruibo Li</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jiacheng Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fayao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+G">Guosheng Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item704">[704]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.06652" title="Abstract">arXiv:2208.06652</a> (replaced) [<a href="/pdf/2208.06652" title="Download PDF">pdf</a>, <a href="/format/2208.06652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Inductive Logic Programming in High-Dimensional Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Purga%C5%82%2C+S+J">Stanis&#x142;aw J. Purga&#x142;</a>, 
<a href="/search/cs?searchtype=author&query=Cerna%2C+D+M">David M. Cerna</a>, 
<a href="/search/cs?searchtype=author&query=Kaliszyk%2C+C">Cezary Kaliszyk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item705">[705]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.06681" title="Abstract">arXiv:2208.06681</a> (replaced) [<a href="/pdf/2208.06681" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling biological face recognition with deep convolutional neural  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Dyck%2C+L+E">Leonard E. van Dyck</a>, 
<a href="/search/cs?searchtype=author&query=Gruber%2C+W+R">Walter R. Gruber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 2 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item706">[706]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.09495" title="Abstract">arXiv:2208.09495</a> (replaced) [<a href="/pdf/2208.09495" title="Download PDF">pdf</a>, <a href="/format/2208.09495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topical: Learning Repository Embeddings from Source Code using Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lherondelle%2C+A">Agathe Lherondelle</a>, 
<a href="/search/cs?searchtype=author&query=Babbar%2C+V">Varun Babbar</a>, 
<a href="/search/cs?searchtype=author&query=Satsangi%2C+Y">Yash Satsangi</a>, 
<a href="/search/cs?searchtype=author&query=Silavong%2C+F">Fran Silavong</a>, 
<a href="/search/cs?searchtype=author&query=Eloul%2C+S">Shaltiel Eloul</a>, 
<a href="/search/cs?searchtype=author&query=Moran%2C+S">Sean Moran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-print, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item707">[707]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.10531" title="Abstract">arXiv:2208.10531</a> (replaced) [<a href="/pdf/2208.10531" title="Download PDF">pdf</a>, <a href="/format/2208.10531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RAIN: RegulArization on Input and Network for Black-Box Domain  Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+Q">Qucheng Peng</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zhengming Ding</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+L">Lingjuan Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IJCAI 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Joint Conferences on Artificial Intelligence 32
  (2023) 4118-4126
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item708">[708]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.10533" title="Abstract">arXiv:2208.10533</a> (replaced) [<a href="/pdf/2208.10533" title="Download PDF">pdf</a>, <a href="/format/2208.10533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Some Supervision Required: Incorporating Oracle Policies in  Reinforcement Learning via Epistemic Uncertainty Metrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tai%2C+J+J">Jun Jet Tai</a>, 
<a href="/search/cs?searchtype=author&query=Terry%2C+J+K">Jordan K. Terry</a>, 
<a href="/search/cs?searchtype=author&query=Innocente%2C+M+S">Mauro S. Innocente</a>, 
<a href="/search/cs?searchtype=author&query=Brusey%2C+J">James Brusey</a>, 
<a href="/search/cs?searchtype=author&query=Horri%2C+N">Nadjim Horri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review at TMLR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item709">[709]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.00993" title="Abstract">arXiv:2209.00993</a> (replaced) [<a href="/pdf/2209.00993" title="Download PDF">pdf</a>, <a href="/format/2209.00993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Fusion in Neuromarketing: Multimodal Analysis of Biosignals,  Lifecycle Stages, Current Advances, Datasets, Trends, and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=P%C3%A9rez%2C+M+Q">Mario Quiles P&#xe9;rez</a>, 
<a href="/search/eess?searchtype=author&query=Beltr%C3%A1n%2C+E+T+M">Enrique Tom&#xe1;s Mart&#xed;nez Beltr&#xe1;n</a>, 
<a href="/search/eess?searchtype=author&query=Bernal%2C+S+L">Sergio L&#xf3;pez Bernal</a>, 
<a href="/search/eess?searchtype=author&query=Prat%2C+E+H">Eduardo Horna Prat</a>, 
<a href="/search/eess?searchtype=author&query=Del+Campo%2C+L+M">Luis Montesano Del Campo</a>, 
<a href="/search/eess?searchtype=author&query=Maim%C3%B3%2C+L+F">Lorenzo Fern&#xe1;ndez Maim&#xf3;</a>, 
<a href="/search/eess?searchtype=author&query=Celdr%C3%A1n%2C+A+H">Alberto Huertas Celdr&#xe1;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item710">[710]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.01566" title="Abstract">arXiv:2209.01566</a> (replaced) [<a href="/pdf/2209.01566" title="Download PDF">pdf</a>, <a href="/format/2209.01566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Top-Down Automated Development in Limited Scopes: A  Neuro-Symbolic Framework from Expressibles to Executables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jian Gu</a>, 
<a href="/search/cs?searchtype=author&query=Gall%2C+H+C">Harald C. Gall</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 2 tables, accepted by ESEC/FSE 2023, the camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item711">[711]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.02466" title="Abstract">arXiv:2209.02466</a> (replaced) [<a href="/pdf/2209.02466" title="Download PDF">pdf</a>, <a href="/format/2209.02466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Circumventing volumetric locking in explicit material point methods: A  simple, efficient, and general approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhao%2C+Y">Yidong Zhao</a>, 
<a href="/search/math?searchtype=author&query=Jiang%2C+C">Chenfanfu Jiang</a>, 
<a href="/search/math?searchtype=author&query=Choo%2C+J">Jinhyun Choo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item712">[712]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.04587" title="Abstract">arXiv:2209.04587</a> (replaced) [<a href="/pdf/2209.04587" title="Download PDF">pdf</a>, <a href="/format/2209.04587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multipoint-BAX: A New Approach for Efficiently Tuning Particle  Accelerator Emittance via Virtual Objectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Miskovich%2C+S+A">Sara A. Miskovich</a>, 
<a href="/search/physics?searchtype=author&query=Neiswanger%2C+W">Willie Neiswanger</a>, 
<a href="/search/physics?searchtype=author&query=Colocho%2C+W">William Colocho</a>, 
<a href="/search/physics?searchtype=author&query=Emma%2C+C">Claudio Emma</a>, 
<a href="/search/physics?searchtype=author&query=Garrahan%2C+J">Jacqueline Garrahan</a>, 
<a href="/search/physics?searchtype=author&query=Maxwell%2C+T">Timothy Maxwell</a>, 
<a href="/search/physics?searchtype=author&query=Mayes%2C+C">Christopher Mayes</a>, 
<a href="/search/physics?searchtype=author&query=Ermon%2C+S">Stefano Ermon</a>, 
<a href="/search/physics?searchtype=author&query=Edelen%2C+A">Auralee Edelen</a>, 
<a href="/search/physics?searchtype=author&query=Ratner%2C+D">Daniel Ratner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Accelerator Physics (physics.acc-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item713">[713]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.05016" title="Abstract">arXiv:2209.05016</a> (replaced) [<a href="/pdf/2209.05016" title="Download PDF">pdf</a>, <a href="/format/2209.05016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FiBiNet++: Reducing Model Size by Low Rank Feature Interaction Layer for  CTR Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pengtao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zheng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junlin Zhang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM International Conference on Information and Knowledge
  Management(CIKM '23), October 21-25,2023,Birmingham,United Kingdom
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item714">[714]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.05089" title="Abstract">arXiv:2209.05089</a> (replaced) [<a href="/pdf/2209.05089" title="Download PDF">pdf</a>, <a href="/ps/2209.05089" title="Download PostScript">ps</a>, <a href="/format/2209.05089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solidarity in natural gas storage: A potential allocation mechanism of  stored quantities among several players during times of crisis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Csercsik%2C+D">D&#xe1;vid Csercsik</a>, 
<a href="/search/econ?searchtype=author&query=Neumann%2C+A">Anne Neumann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item715">[715]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.05534" title="Abstract">arXiv:2209.05534</a> (replaced) [<a href="/pdf/2209.05534" title="Download PDF">pdf</a>, <a href="/format/2209.05534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PreSTU: Pre-Training for Scene-Text Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kil%2C+J">Jihyung Kil</a>, 
<a href="/search/cs?searchtype=author&query=Changpinyo%2C+S">Soravit Changpinyo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hexiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Goodman%2C+S">Sebastian Goodman</a>, 
<a href="/search/cs?searchtype=author&query=Chao%2C+W">Wei-Lun Chao</a>, 
<a href="/search/cs?searchtype=author&query=Soricut%2C+R">Radu Soricut</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item716">[716]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.07171" title="Abstract">arXiv:2209.07171</a> (replaced) [<a href="/pdf/2209.07171" title="Download PDF">pdf</a>, <a href="/format/2209.07171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Exploit Elastic Actuators for Quadruped Locomotion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raffin%2C+A">Antonin Raffin</a>, 
<a href="/search/cs?searchtype=author&query=Seidel%2C+D">Daniel Seidel</a>, 
<a href="/search/cs?searchtype=author&query=Kober%2C+J">Jens Kober</a>, 
<a href="/search/cs?searchtype=author&query=Albu-Sch%C3%A4ffer%2C+A">Alin Albu-Sch&#xe4;ffer</a>, 
<a href="/search/cs?searchtype=author&query=Silv%C3%A9rio%2C+J">Jo&#xe3;o Silv&#xe9;rio</a>, 
<a href="/search/cs?searchtype=author&query=Stulp%2C+F">Freek Stulp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item717">[717]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.13877" title="Abstract">arXiv:2209.13877</a> (replaced) [<a href="/pdf/2209.13877" title="Download PDF">pdf</a>, <a href="/format/2209.13877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> YATO: Yet Another deep learning based Text analysis Open toolkit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zeqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yile Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiageng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+Z">Zhiyang Teng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item718">[718]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.00240" title="Abstract">arXiv:2210.00240</a> (replaced) [<a href="/pdf/2210.00240" title="Download PDF">pdf</a>, <a href="/format/2210.00240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Executable First-Order Queries in the Logic of Information Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aamer%2C+H">Heba Aamer</a>, 
<a href="/search/cs?searchtype=author&query=Bogaerts%2C+B">Bart Bogaerts</a>, 
<a href="/search/cs?searchtype=author&query=Surinx%2C+D">Dimitri Surinx</a>, 
<a href="/search/cs?searchtype=author&query=Ternovska%2C+E">Eugenia Ternovska</a>, 
<a href="/search/cs?searchtype=author&query=Van+den+Bussche%2C+J">Jan Van den Bussche</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is the extended version of the two papers presented at ICDT 2020 and ICDT 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item719">[719]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.00953" title="Abstract">arXiv:2210.00953</a> (replaced) [<a href="/pdf/2210.00953" title="Download PDF">pdf</a>, <a href="/format/2210.00953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bias and Extrapolation in Markovian Linear Stochastic Approximation with  Constant Stepsizes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Huo%2C+D">Dongyan Huo</a>, 
<a href="/search/stat?searchtype=author&query=Chen%2C+Y">Yudong Chen</a>, 
<a href="/search/stat?searchtype=author&query=Xie%2C+Q">Qiaomin Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGMETRICS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item720">[720]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.02390" title="Abstract">arXiv:2210.02390</a> (replaced) [<a href="/pdf/2210.02390" title="Download PDF">pdf</a>, <a href="/format/2210.02390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Prompt Learning for Image-Language Model Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Derakhshani%2C+M+M">Mohammad Mahdi Derakhshani</a>, 
<a href="/search/cs?searchtype=author&query=Sanchez%2C+E">Enrique Sanchez</a>, 
<a href="/search/cs?searchtype=author&query=Bulat%2C+A">Adrian Bulat</a>, 
<a href="/search/cs?searchtype=author&query=da+Costa%2C+V+G+T">Victor Guilherme Turrisi da Costa</a>, 
<a href="/search/cs?searchtype=author&query=Snoek%2C+C+G+M">Cees G. M. Snoek</a>, 
<a href="/search/cs?searchtype=author&query=Tzimiropoulos%2C+G">Georgios Tzimiropoulos</a>, 
<a href="/search/cs?searchtype=author&query=Martinez%2C+B">Brais Martinez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item721">[721]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.03599" title="Abstract">arXiv:2210.03599</a> (replaced) [<a href="/pdf/2210.03599" title="Download PDF">pdf</a>, <a href="/ps/2210.03599" title="Download PostScript">ps</a>, <a href="/format/2210.03599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RIS-Aided Localization under Position and Orientation Offsets in the  Near and Far Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Emenonye%2C+D">Don-Roberts Emenonye</a>, 
<a href="/search/cs?searchtype=author&query=Dhillon%2C+H+S">Harpreet S. Dhillon</a>, 
<a href="/search/cs?searchtype=author&query=Buehrer%2C+R+M">R. Michael Buehrer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item722">[722]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.04845" title="Abstract">arXiv:2210.04845</a> (replaced) [<a href="/pdf/2210.04845" title="Download PDF">pdf</a>, <a href="/format/2210.04845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FS-DETR: Few-Shot DEtection TRansformer with prompting and without  re-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bulat%2C+A">Adrian Bulat</a>, 
<a href="/search/cs?searchtype=author&query=Guerrero%2C+R">Ricardo Guerrero</a>, 
<a href="/search/cs?searchtype=author&query=Martinez%2C+B">Brais Martinez</a>, 
<a href="/search/cs?searchtype=author&query=Tzimiropoulos%2C+G">Georgios Tzimiropoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item723">[723]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.10651" title="Abstract">arXiv:2210.10651</a> (replaced) [<a href="/pdf/2210.10651" title="Download PDF">pdf</a>, <a href="/format/2210.10651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fant&#xf4;mas: Understanding Face Anonymization Reversibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Todt%2C+J">Julian Todt</a>, 
<a href="/search/cs?searchtype=author&query=Hanisch%2C+S">Simon Hanisch</a>, 
<a href="/search/cs?searchtype=author&query=Strufe%2C+T">Thorsten Strufe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item724">[724]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.11549" title="Abstract">arXiv:2210.11549</a> (replaced) [<a href="/pdf/2210.11549" title="Download PDF">pdf</a>, <a href="/format/2210.11549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> H4VDM: H.264 Video Device Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Z">Ziyue Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Bestagini%2C+P">Paolo Bestagini</a>, 
<a href="/search/cs?searchtype=author&query=Tubaro%2C+S">Stefano Tubaro</a>, 
<a href="/search/cs?searchtype=author&query=Delp%2C+E+J">Edward J. Delp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item725">[725]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.13530" title="Abstract">arXiv:2210.13530</a> (replaced) [<a href="/pdf/2210.13530" title="Download PDF">pdf</a>, <a href="/format/2210.13530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An efficient Monte Carlo scheme for Zakai equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Beck%2C+C">Christian Beck</a>, 
<a href="/search/math?searchtype=author&query=Becker%2C+S">Sebastian Becker</a>, 
<a href="/search/math?searchtype=author&query=Cheridito%2C+P">Patrick Cheridito</a>, 
<a href="/search/math?searchtype=author&query=Jentzen%2C+A">Arnulf Jentzen</a>, 
<a href="/search/math?searchtype=author&query=Neufeld%2C+A">Ariel Neufeld</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item726">[726]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01160" title="Abstract">arXiv:2211.01160</a> (replaced) [<a href="/pdf/2211.01160" title="Download PDF">pdf</a>, <a href="/format/2211.01160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Profit-Maximizing Strategy for Advertising on the e-Commerce Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Lianghai Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yixing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiwei Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Online advertising campaigns
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item727">[727]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.02641" title="Abstract">arXiv:2211.02641</a> (replaced) [<a href="/pdf/2211.02641" title="Download PDF">pdf</a>, <a href="/ps/2211.02641" title="Download PostScript">ps</a>, <a href="/format/2211.02641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Neural Networks on SPD Manifolds for Motor Imagery Classification:  A Perspective from the Time-Frequency Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ju%2C+C">Ce Ju</a>, 
<a href="/search/eess?searchtype=author&query=Guan%2C+C">Cuntai Guan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 5 figures, 6 Tables; This work has been accepted by the IEEE Transactions on Neural Networks and Learning Systems, 2023. Copyright will be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item728">[728]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.04880" title="Abstract">arXiv:2211.04880</a> (replaced) [<a href="/pdf/2211.04880" title="Download PDF">pdf</a>, <a href="/format/2211.04880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Outcome-Oriented Prescriptive Process Monitoring Based on Temporal Logic  Patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Donadello%2C+I">Ivan Donadello</a>, 
<a href="/search/cs?searchtype=author&query=Di+Francescomarino%2C+C">Chiara Di Francescomarino</a>, 
<a href="/search/cs?searchtype=author&query=Maggi%2C+F+M">Fabrizio Maria Maggi</a>, 
<a href="/search/cs?searchtype=author&query=Ricci%2C+F">Francesco Ricci</a>, 
<a href="/search/cs?searchtype=author&query=Shikhizada%2C+A">Aladdin Shikhizada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 6 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item729">[729]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08824" title="Abstract">arXiv:2211.08824</a> (replaced) [<a href="/pdf/2211.08824" title="Download PDF">pdf</a>, <a href="/format/2211.08824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SMILEtrack: SiMIlarity LEarning for Occlusion-Aware Multiple Object  Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Hsiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+J">Jun-Wei Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Ping-Yang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+M">Ming-Ching Chang</a>, 
<a href="/search/cs?searchtype=author&query=So%2C+H+H">Hung Hin So</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item730">[730]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.09778" title="Abstract">arXiv:2211.09778</a> (replaced) [<a href="/pdf/2211.09778" title="Download PDF">pdf</a>, <a href="/format/2211.09778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> I Can&#x27;t Believe There&#x27;s No Images! Learning Visual Tasks Using only  Language Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+S">Sophia Gu</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+C">Christopher Clark</a>, 
<a href="/search/cs?searchtype=author&query=Kembhavi%2C+A">Aniruddha Kembhavi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> website (<a href="https://prior.allenai.org/projects/close">this https URL</a>), code (<a href="https://github.com/allenai/close">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item731">[731]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.09788" title="Abstract">arXiv:2211.09788</a> (replaced) [<a href="/pdf/2211.09788" title="Download PDF">pdf</a>, <a href="/format/2211.09788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffusionDet: Diffusion Model for Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shoufa Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+P">Peize Sun</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yibing Song</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV2023 (Oral), Camera-ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item732">[732]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.10773" title="Abstract">arXiv:2211.10773</a> (replaced) [<a href="/pdf/2211.10773" title="Download PDF">pdf</a>, <a href="/format/2211.10773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Two-Stage Active Learning Algorithm for $k$-Nearest Neighbors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rittler%2C+N">Nick Rittler</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhuri%2C+K">Kamalika Chaudhuri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item733">[733]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.11825" title="Abstract">arXiv:2211.11825</a> (replaced) [<a href="/pdf/2211.11825" title="Download PDF">pdf</a>, <a href="/format/2211.11825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Directional Subspace Editing in Style-Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naveh%2C+C">Chen Naveh</a>, 
<a href="/search/cs?searchtype=author&query=Hel-Or%2C+Y">Yacov Hel-Or</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item734">[734]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.12347" title="Abstract">arXiv:2211.12347</a> (replaced) [<a href="/pdf/2211.12347" title="Download PDF">pdf</a>, <a href="/format/2211.12347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Euclidean Space is Evil: Hyperbolic Attribute Editing for Few-shot  Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lingxiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuhui Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item735">[735]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13035" title="Abstract">arXiv:2211.13035</a> (replaced) [<a href="/pdf/2211.13035" title="Download PDF">pdf</a>, <a href="/format/2211.13035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can lies be faked? Comparing low-stakes and high-stakes deception video  datasets from a Machine Learning perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Camara%2C+M+K">Mateus Karvat Camara</a>, 
<a href="/search/cs?searchtype=author&query=Postal%2C+A">Adriana Postal</a>, 
<a href="/search/cs?searchtype=author&query=Maul%2C+T+H">Tomas Henrique Maul</a>, 
<a href="/search/cs?searchtype=author&query=Paetzold%2C+G">Gustavo Paetzold</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item736">[736]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13955" title="Abstract">arXiv:2211.13955</a> (replaced) [<a href="/pdf/2211.13955" title="Download PDF">pdf</a>, <a href="/format/2211.13955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MPCViT: Searching for Accurate and Efficient MPC-Friendly Vision  Transformer with Heterogeneous Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Wenxuan Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Meng Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+W">Wenjie Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+T">Tong Tong</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wen-jie Lu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+J">Jin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Runsheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Ru Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item737">[737]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14512" title="Abstract">arXiv:2211.14512</a> (replaced) [<a href="/pdf/2211.14512" title="Download PDF">pdf</a>, <a href="/format/2211.14512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Residual Pattern Learning for Pixel-wise Out-of-Distribution Detection  in Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Choubo Ding</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yu Tian</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+G">Guansong Pang</a>, 
<a href="/search/cs?searchtype=author&query=Belagiannis%2C+V">Vasileios Belagiannis</a>, 
<a href="/search/cs?searchtype=author&query=Reid%2C+I">Ian Reid</a>, 
<a href="/search/cs?searchtype=author&query=Carneiro%2C+G">Gustavo Carneiro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper contains 16 pages and it is accepted by ICCV'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item738">[738]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.14963" title="Abstract">arXiv:2211.14963</a> (replaced) [<a href="/pdf/2211.14963" title="Download PDF">pdf</a>, <a href="/format/2211.14963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Architecture for Online Ensemble Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=W%C3%B3jcik%2C+M">Mateusz W&#xf3;jcik</a>, 
<a href="/search/cs?searchtype=author&query=Ko%C5%9Bciukiewicz%2C+W">Witold Ko&#x15b;ciukiewicz</a>, 
<a href="/search/cs?searchtype=author&query=Kajdanowicz%2C+T">Tomasz Kajdanowicz</a>, 
<a href="/search/cs?searchtype=author&query=Gonczarek%2C+A">Adam Gonczarek</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> https://meta-learn.github.io/2022/
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item739">[739]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.15046" title="Abstract">arXiv:2211.15046</a> (replaced) [<a href="/pdf/2211.15046" title="Download PDF">pdf</a>, <a href="/format/2211.15046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PCT-CycleGAN: Paired Complementary Temporal Cycle-Consistent Adversarial  Networks for Radar-Based Precipitation Nowcasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jaeho Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yura Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kwang-Ho Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+S">Sung-Hwa Jung</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+I">Ikhyun Cho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CIKM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item740">[740]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.15660" title="Abstract">arXiv:2211.15660</a> (replaced) [<a href="/pdf/2211.15660" title="Download PDF">pdf</a>, <a href="/format/2211.15660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SatlasPretrain: A Large-Scale Dataset for Remote Sensing Image  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bastani%2C+F">Favyen Bastani</a>, 
<a href="/search/cs?searchtype=author&query=Wolters%2C+P">Piper Wolters</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+R">Ritwik Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Ferdinando%2C+J">Joe Ferdinando</a>, 
<a href="/search/cs?searchtype=author&query=Kembhavi%2C+A">Aniruddha Kembhavi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item741">[741]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.00192" title="Abstract">arXiv:2212.00192</a> (replaced) [<a href="/pdf/2212.00192" title="Download PDF">pdf</a>, <a href="/format/2212.00192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Practical Few-shot Federated NLP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Dongqi Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yaozong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Haitao Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shangguang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+F+X">Felix Xiaozhu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mengwei Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EuroSys23 workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item742">[742]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01953" title="Abstract">arXiv:2212.01953</a> (replaced) [<a href="/pdf/2212.01953" title="Download PDF">pdf</a>, <a href="/format/2212.01953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-aware multi-head self-attentional neural network model for next  location prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Hong%2C+Y">Ye Hong</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+Y">Yatao Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Schindler%2C+K">Konrad Schindler</a>, 
<a href="/search/physics?searchtype=author&query=Raubal%2C+M">Martin Raubal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> updated Discussion section; accepted by Transportation Research Part C
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item743">[743]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.02469" title="Abstract">arXiv:2212.02469</a> (replaced) [<a href="/pdf/2212.02469" title="Download PDF">pdf</a>, <a href="/format/2212.02469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-shot Implicit Animatable Avatars with Model-based Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yangyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+H">Hongwei Yi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haofan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Boxi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenxiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Binbin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Debing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Deng Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at ICCV 2023. Project website: <a href="https://huangyangyi.github.io/ELICIT/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item744">[744]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.02500" title="Abstract">arXiv:2212.02500</a> (replaced) [<a href="/pdf/2212.02500" title="Download PDF">pdf</a>, <a href="/format/2212.02500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PhysDiff: Physics-Guided Human Motion Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Ye Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jiaming Song</a>, 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+U">Umar Iqbal</a>, 
<a href="/search/cs?searchtype=author&query=Vahdat%2C+A">Arash Vahdat</a>, 
<a href="/search/cs?searchtype=author&query=Kautz%2C+J">Jan Kautz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 (Oral). Project page: <a href="https://nvlabs.github.io/PhysDiff">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item745">[745]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.02710" title="Abstract">arXiv:2212.02710</a> (replaced) [<a href="/pdf/2212.02710" title="Download PDF">pdf</a>, <a href="/format/2212.02710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Object Recognition: A New Benchmark towards Object Concept  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong-Lu Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yue Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xinyu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+X">Xiaohan Mao</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Siqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023. Webpage: <a href="https://mvig-rhos.com/ocl">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item746">[746]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.03241" title="Abstract">arXiv:2212.03241</a> (replaced) [<a href="/pdf/2212.03241" title="Download PDF">pdf</a>, <a href="/format/2212.03241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> P&#xd8;DA: Prompt-driven Zero-shot Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fahes%2C+M">Mohammad Fahes</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+T">Tuan-Hung Vu</a>, 
<a href="/search/cs?searchtype=author&query=Bursuc%2C+A">Andrei Bursuc</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+P">Patrick P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=de+Charette%2C+R">Raoul de Charette</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023, Project Page: <a href="https://astra-vision.github.io/PODA/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item747">[747]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.05231" title="Abstract">arXiv:2212.05231</a> (replaced) [<a href="/pdf/2212.05231" title="Download PDF">pdf</a>, <a href="/format/2212.05231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuS2: Fast Learning of Neural Implicit Surfaces for Multi-view  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Q">Qin Han</a>, 
<a href="/search/cs?searchtype=author&query=Habermann%2C+M">Marc Habermann</a>, 
<a href="/search/cs?searchtype=author&query=Daniilidis%2C+K">Kostas Daniilidis</a>, 
<a href="/search/cs?searchtype=author&query=Theobalt%2C+C">Christian Theobalt</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingjie Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item748">[748]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.05853" title="Abstract">arXiv:2212.05853</a> (replaced) [<a href="/pdf/2212.05853" title="Download PDF">pdf</a>, <a href="/format/2212.05853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepCut: Unsupervised Segmentation using Graph Neural Networks  Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aflalo%2C+A">Amit Aflalo</a>, 
<a href="/search/cs?searchtype=author&query=Bagon%2C+S">Shai Bagon</a>, 
<a href="/search/cs?searchtype=author&query=Kashti%2C+T">Tamar Kashti</a>, 
<a href="/search/cs?searchtype=author&query=Eldar%2C+Y">Yonina Eldar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item749">[749]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.05974" title="Abstract">arXiv:2212.05974</a> (replaced) [<a href="/pdf/2212.05974" title="Download PDF">pdf</a>, <a href="/format/2212.05974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Few-Shot Learning for Mobile NLP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Dongqi Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shangguang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yaozong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+F+X">Felix Xiaozhu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mengwei Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MobiCom 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item750">[750]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.06653" title="Abstract">arXiv:2212.06653</a> (replaced) [<a href="/pdf/2212.06653" title="Download PDF">pdf</a>, <a href="/format/2212.06653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Dynamic Mixture Model with Full Covariance for Probabilistic  Traffic Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Seongjin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Saunier%2C+N">Nicolas Saunier</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+V+Z">Vincent Zhihao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Trepanier%2C+M">Martin Trepanier</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lijun Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures, 2 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item751">[751]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07282" title="Abstract">arXiv:2212.07282</a> (replaced) [<a href="/pdf/2212.07282" title="Download PDF">pdf</a>, <a href="/ps/2212.07282" title="Download PostScript">ps</a>, <a href="/format/2212.07282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Variance Forward Gradients using Direct Feedback Alignment and  Momentum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bacho%2C+F">Florian Bacho</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+D">Dominique Chu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item752">[752]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.08405" title="Abstract">arXiv:2212.08405</a> (replaced) [<a href="/pdf/2212.08405" title="Download PDF">pdf</a>, <a href="/ps/2212.08405" title="Download PostScript">ps</a>, <a href="/format/2212.08405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exponentially Stable Adaptive Observation for Systems Parameterized by  Unknown Physical Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Glushchenko%2C+A">Anton Glushchenko</a>, 
<a href="/search/eess?searchtype=author&query=Lastochkin%2C+K">Konstantin Lastochkin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item753">[753]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.08781" title="Abstract">arXiv:2212.08781</a> (replaced) [<a href="/pdf/2212.08781" title="Download PDF">pdf</a>, <a href="/format/2212.08781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Scale Relational Graph Convolutional Network for Multiple Instance  Learning in Histopathology Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bazargani%2C+R">Roozbeh Bazargani</a>, 
<a href="/search/cs?searchtype=author&query=Fazli%2C+L">Ladan Fazli</a>, 
<a href="/search/cs?searchtype=author&query=Goldenberg%2C+L">Larry Goldenberg</a>, 
<a href="/search/cs?searchtype=author&query=Gleave%2C+M">Martin Gleave</a>, 
<a href="/search/cs?searchtype=author&query=Bashashati%2C+A">Ali Bashashati</a>, 
<a href="/search/cs?searchtype=author&query=Salcudean%2C+S">Septimiu Salcudean</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item754">[754]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09100" title="Abstract">arXiv:2212.09100</a> (replaced) [<a href="/pdf/2212.09100" title="Download PDF">pdf</a>, <a href="/format/2212.09100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPARF: Large-Scale Learning of 3D Sparse Radiance Fields from Few Input  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamdi%2C+A">Abdullah Hamdi</a>, 
<a href="/search/cs?searchtype=author&query=Ghanem%2C+B">Bernard Ghanem</a>, 
<a href="/search/cs?searchtype=author&query=Nie%C3%9Fner%2C+M">Matthias Nie&#xdf;ner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> published at ICCV 2023 workshop proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item755">[755]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09450" title="Abstract">arXiv:2212.09450</a> (replaced) [<a href="/pdf/2212.09450" title="Download PDF">pdf</a>, <a href="/format/2212.09450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Antimicrobial Peptide Discovery with Latent Structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+D">Danqing Wang</a>, 
<a href="/search/q-bio?searchtype=author&query=Wen%2C+Z">Zeyu Wen</a>, 
<a href="/search/q-bio?searchtype=author&query=Ye%2C+F">Fei Ye</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhou%2C+H">Hao Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> KDD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item756">[756]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09586" title="Abstract">arXiv:2212.09586</a> (replaced) [<a href="/pdf/2212.09586" title="Download PDF">pdf</a>, <a href="/format/2212.09586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Latent Representations to Co-Adapt to Humans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parekh%2C+S">Sagar Parekh</a>, 
<a href="/search/cs?searchtype=author&query=Losey%2C+D+P">Dylan P. Losey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item757">[757]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.11581" title="Abstract">arXiv:2212.11581</a> (replaced) [<a href="/pdf/2212.11581" title="Download PDF">pdf</a>, <a href="/format/2212.11581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of a sinc-Galerkin Method for the Fractional Laplacian
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Antil%2C+H">Harbir Antil</a>, 
<a href="/search/math?searchtype=author&query=Dondl%2C+P">Patrick Dondl</a>, 
<a href="/search/math?searchtype=author&query=Striet%2C+L">Ludwig Striet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item758">[758]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.12184" title="Abstract">arXiv:2212.12184</a> (replaced) [<a href="/pdf/2212.12184" title="Download PDF">pdf</a>, <a href="/format/2212.12184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monotonous Parameter Estimation of One Class of Nonlinearly  Parameterized Regressions without Overparameterization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Glushchenko%2C+A">Anton Glushchenko</a>, 
<a href="/search/eess?searchtype=author&query=Lastochkin%2C+K">Konstantin Lastochkin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item759">[759]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.12249" title="Abstract">arXiv:2212.12249</a> (replaced) [<a href="/pdf/2212.12249" title="Download PDF">pdf</a>, <a href="/format/2212.12249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do DALL-E and Flamingo Understand Each Other?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hang Li</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jindong Gu</a>, 
<a href="/search/cs?searchtype=author&query=Koner%2C+R">Rajat Koner</a>, 
<a href="/search/cs?searchtype=author&query=Sharifzadeh%2C+S">Sahand Sharifzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Tresp%2C+V">Volker Tresp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item760">[760]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.13332" title="Abstract">arXiv:2212.13332</a> (replaced) [<a href="/pdf/2212.13332" title="Download PDF">pdf</a>, <a href="/format/2212.13332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Development and Evaluation of a Learning-based Model for Real-time  Haptic Texture Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heravi%2C+N">Negin Heravi</a>, 
<a href="/search/cs?searchtype=author&query=Culbertson%2C+H">Heather Culbertson</a>, 
<a href="/search/cs?searchtype=author&query=Okamura%2C+A+M">Allison M. Okamura</a>, 
<a href="/search/cs?searchtype=author&query=Bohg%2C+J">Jeannette Bohg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item761">[761]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.13670" title="Abstract">arXiv:2212.13670</a> (replaced) [<a href="/pdf/2212.13670" title="Download PDF">pdf</a>, <a href="/format/2212.13670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VegaProf: Profiling Vega Visualizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Junran Yang</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%A4uerle%2C+A">Alex B&#xe4;uerle</a>, 
<a href="/search/cs?searchtype=author&query=Moritz%2C+D">Dominik Moritz</a>, 
<a href="/search/cs?searchtype=author&query=Demiralp%2C+%C3%87">&#xc7;a&#x11f;atay Demiralp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at UIST'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Databases (cs.DB); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item762">[762]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.13939" title="Abstract">arXiv:2212.13939</a> (replaced) [<a href="/pdf/2212.13939" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Augmentation using Transformers and Similarity Measures for  Improving Arabic Text Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Refai%2C+D">Dania Refai</a>, 
<a href="/search/cs?searchtype=author&query=Abo-Soud%2C+S">Saleh Abo-Soud</a>, 
<a href="/search/cs?searchtype=author&query=Abdel-Rahman%2C+M">Mohammad Abdel-Rahman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 16 Figures, this work has been submitted to the IEEE Access Journal for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item763">[763]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00280" title="Abstract">arXiv:2301.00280</a> (replaced) [<a href="/pdf/2301.00280" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RECOMED: A Comprehensive Pharmaceutical Recommendation System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zomorodi%2C+M">Mariam Zomorodi</a>, 
<a href="/search/cs?searchtype=author&query=Ghodsollahee%2C+I">Ismail Ghodsollahee</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+J+H">Jennifer H. Martin</a>, 
<a href="/search/cs?searchtype=author&query=Talley%2C+N+J">Nicholas J. Talley</a>, 
<a href="/search/cs?searchtype=author&query=Salari%2C+V">Vahid Salari</a>, 
<a href="/search/cs?searchtype=author&query=Plawiak%2C+P">Pawel Plawiak</a>, 
<a href="/search/cs?searchtype=author&query=Rahimi%2C+K">Kazem Rahimi</a>, 
<a href="/search/cs?searchtype=author&query=Acharya%2C+U+R">U. Rajendra Acharya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 14 figures, 13 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item764">[764]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.01520" title="Abstract">arXiv:2301.01520</a> (replaced) [<a href="/pdf/2301.01520" title="Download PDF">pdf</a>, <a href="/format/2301.01520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Explainable Land Cover Mapping: a Counterfactual-based Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dantas%2C+C+F">Cassio F. Dantas</a>, 
<a href="/search/cs?searchtype=author&query=Marcos%2C+D">Diego Marcos</a>, 
<a href="/search/cs?searchtype=author&query=Ienco%2C+D">Dino Ienco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item765">[765]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02009" title="Abstract">arXiv:2301.02009</a> (replaced) [<a href="/pdf/2301.02009" title="Download PDF">pdf</a>, <a href="/format/2301.02009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning by Sorting: Self-supervised Learning with Group Ordering  Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shvetsova%2C+N">Nina Shvetsova</a>, 
<a href="/search/cs?searchtype=author&query=Petersen%2C+F">Felix Petersen</a>, 
<a href="/search/cs?searchtype=author&query=Kukleva%2C+A">Anna Kukleva</a>, 
<a href="/search/cs?searchtype=author&query=Schiele%2C+B">Bernt Schiele</a>, 
<a href="/search/cs?searchtype=author&query=Kuehne%2C+H">Hilde Kuehne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ICCV 2023, Code @ <a href="https://github.com/ninatu/learning_by_sorting">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item766">[766]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02412" title="Abstract">arXiv:2301.02412</a> (replaced) [<a href="/pdf/2301.02412" title="Download PDF">pdf</a>, <a href="/format/2301.02412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Code Difference Guided Adversarial Example Generation for Deep Code  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhi Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ASE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item767">[767]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02884" title="Abstract">arXiv:2301.02884</a> (replaced) [<a href="/pdf/2301.02884" title="Download PDF">pdf</a>, <a href="/format/2301.02884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TunesFormer: Forming Irish Tunes with Control Codes by Bar Patching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shangda Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaobing Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Feng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Maosong Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item768">[768]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.04011" title="Abstract">arXiv:2301.04011</a> (replaced) [<a href="/pdf/2301.04011" title="Download PDF">pdf</a>, <a href="/format/2301.04011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Support and Trivial Prototypes for Interpretable Image  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuanhong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fengbei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yu Tian</a>, 
<a href="/search/cs?searchtype=author&query=McCarthy%2C+D+J">Davis J. McCarthy</a>, 
<a href="/search/cs?searchtype=author&query=Frazer%2C+H">Helen Frazer</a>, 
<a href="/search/cs?searchtype=author&query=Carneiro%2C+G">Gustavo Carneiro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item769">[769]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.05712" title="Abstract">arXiv:2301.05712</a> (replaced) [<a href="/pdf/2301.05712" title="Download PDF">pdf</a>, <a href="/format/2301.05712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Self-supervised Learning from Multiple Perspectives:  Algorithms, Applications and Future Trends
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gui%2C+J">Jie Gui</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Q">Qiong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhenan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Hao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item770">[770]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.06309" title="Abstract">arXiv:2301.06309</a> (replaced) [<a href="/pdf/2301.06309" title="Download PDF">pdf</a>, <a href="/format/2301.06309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UATVR: Uncertainty-Adaptive Text-Video Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+B">Bo Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenhao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yuxin Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+X">Xiangbo Shu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xiangyang Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingdong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item771">[771]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07629" title="Abstract">arXiv:2301.07629</a> (replaced) [<a href="/pdf/2301.07629" title="Download PDF">pdf</a>, <a href="/format/2301.07629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalisation Through Negation and Predicate Invention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cerna%2C+D+M">David M. Cerna</a>, 
<a href="/search/cs?searchtype=author&query=Cropper%2C+A">Andrew Cropper</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under peer-review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item772">[772]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09253" title="Abstract">arXiv:2301.09253</a> (replaced) [<a href="/pdf/2301.09253" title="Download PDF">pdf</a>, <a href="/format/2301.09253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CircNet: Meshing 3D Point Clouds with Circumcenter Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+H">Huan Lei</a>, 
<a href="/search/cs?searchtype=author&query=Leng%2C+R">Ruitao Leng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Liang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongdong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to ICLR2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item773">[773]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09627" title="Abstract">arXiv:2301.09627</a> (replaced) [<a href="/pdf/2301.09627" title="Download PDF">pdf</a>, <a href="/ps/2301.09627" title="Download PostScript">ps</a>, <a href="/format/2301.09627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impossibility of Parallelizing Boosting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karbasi%2C+A">Amin Karbasi</a>, 
<a href="/search/cs?searchtype=author&query=Larsen%2C+K+G">Kasper Green Larsen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item774">[774]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10224" title="Abstract">arXiv:2301.10224</a> (replaced) [<a href="/pdf/2301.10224" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital Twins for Ports: Derived from Smart City and Supply Chain  Twinning Experience
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klar%2C+R">Robert Klar</a>, 
<a href="/search/cs?searchtype=author&query=Fredriksson%2C+A">Anna Fredriksson</a>, 
<a href="/search/cs?searchtype=author&query=Angelakis%2C+V">Vangelis Angelakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full reference: R. Klar, A. Fredriksson and V. Angelakis, "Digital Twins for Ports: Derived From Smart City and Supply Chain Twinning Experience," in IEEE Access, vol. 11, pp. 71777-71799, 2023, doi: 10.1109/ACCESS.2023.3295495
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in IEEE Access, vol. 11, pp. 71777-71799, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
</div>
</dd>
<dt><a name="item775">[775]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11530" title="Abstract">arXiv:2301.11530</a> (replaced) [<a href="/pdf/2301.11530" title="Download PDF">pdf</a>, <a href="/format/2301.11530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cost-aware Defense for Parallel Server Systems against Reliability and  Security Failures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xie%2C+Q">Qian Xie</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jiayi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+L">Li Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Major Revision in Automatica
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Computer Science and Game Theory (cs.GT); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item776">[776]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12667" title="Abstract">arXiv:2301.12667</a> (replaced) [<a href="/pdf/2301.12667" title="Download PDF">pdf</a>, <a href="/format/2301.12667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeSyFOLD: Neurosymbolic Framework for Interpretable Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Padalkar%2C+P">Parth Padalkar</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huaduo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+G">Gopal Gupta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item777">[777]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13020" title="Abstract">arXiv:2301.13020</a> (replaced) [<a href="/pdf/2301.13020" title="Download PDF">pdf</a>, <a href="/format/2301.13020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Truthful Auctions for Automated Bidding in Online Advertising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+Y">Yidan Xing</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhilin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhenzhe Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chuan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guihai Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item778">[778]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01538" title="Abstract">arXiv:2302.01538</a> (replaced) [<a href="/pdf/2302.01538" title="Download PDF">pdf</a>, <a href="/format/2302.01538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A deep complementary energy method for solid mechanics using minimum  complementary energy principle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yizheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jia Sun</a>, 
<a href="/search/cs?searchtype=author&query=Rabczuk%2C+T">Timon Rabczuk</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yinghua Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 58 pages, 30 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn)

</div>
</div>
</dd>
<dt><a name="item779">[779]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02410" title="Abstract">arXiv:2302.02410</a> (replaced) [<a href="/pdf/2302.02410" title="Download PDF">pdf</a>, <a href="/format/2302.02410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoupled Iterative Refinement Framework for Interacting Hands  Reconstruction from a Single RGB Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+P">Pengfei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+C">Chao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiaozheng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Z">Zhou Xue</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haifeng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Q">Qi Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+J">Jianxin Liao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item780">[780]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.07672" title="Abstract">arXiv:2302.07672</a> (replaced) [<a href="/pdf/2302.07672" title="Download PDF">pdf</a>, <a href="/format/2302.07672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiveHand: Real-time and Photorealistic Neural Hand Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mundra%2C+A">Akshay Mundra</a>, 
<a href="/search/cs?searchtype=author&query=R%2C+M+B">Mallikarjun B R</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiayi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Habermann%2C+M">Marc Habermann</a>, 
<a href="/search/cs?searchtype=author&query=Theobalt%2C+C">Christian Theobalt</a>, 
<a href="/search/cs?searchtype=author&query=Elgharib%2C+M">Mohamed Elgharib</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://vcai.mpi-inf.mpg.de/projects/LiveHand/">this https URL</a> | Accepted at ICCV '23 | 11 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
</div>
</dd>
<dt><a name="item781">[781]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08598" title="Abstract">arXiv:2302.08598</a> (replaced) [<a href="/pdf/2302.08598" title="Download PDF">pdf</a>, <a href="/format/2302.08598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discrete Elasticity Exact Sequences on Worsey-Farin Splits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gong%2C+S">Sining Gong</a>, 
<a href="/search/math?searchtype=author&query=Gopalakrishnan%2C+J">Jay Gopalakrishnan</a>, 
<a href="/search/math?searchtype=author&query=Guzm%C3%A1n%2C+J">Johnny Guzm&#xe1;n</a>, 
<a href="/search/math?searchtype=author&query=Neilan%2C+M">Michael Neilan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item782">[782]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09200" title="Abstract">arXiv:2302.09200</a> (replaced) [<a href="/pdf/2302.09200" title="Download PDF">pdf</a>, <a href="/format/2302.09200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brainomaly: Unsupervised Neurologic Disease Detection Utilizing  Unannotated T1-weighted Brain MR Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Siddiquee%2C+M+M+R">Md Mahfuzur Rahman Siddiquee</a>, 
<a href="/search/eess?searchtype=author&query=Shah%2C+J">Jay Shah</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+T">Teresa Wu</a>, 
<a href="/search/eess?searchtype=author&query=Chong%2C+C">Catherine Chong</a>, 
<a href="/search/eess?searchtype=author&query=Schwedt%2C+T+J">Todd J. Schwedt</a>, 
<a href="/search/eess?searchtype=author&query=Dumkrieger%2C+G">Gina Dumkrieger</a>, 
<a href="/search/eess?searchtype=author&query=Nikolova%2C+S">Simona Nikolova</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+B">Baoxin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item783">[783]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09580" title="Abstract">arXiv:2302.09580</a> (replaced) [<a href="/pdf/2302.09580" title="Download PDF">pdf</a>, <a href="/format/2302.09580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-separable Covariance Kernels for Spatiotemporal Gaussian Processes  based on a Hybrid Spectral Method and the Harmonic Oscillator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hristopulos%2C+D+T">Dionissios T.Hristopulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 56 pages, 12 figures, five appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item784">[784]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09582" title="Abstract">arXiv:2302.09582</a> (replaced) [<a href="/pdf/2302.09582" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language-Specific Representation of Emotion-Concept Knowledge Causally  Supports Emotion Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yusheng Su</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hsiu-Yuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jiali Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinmiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huadong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yujia Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaozhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 13 figures, 2 tables, fix formatting errors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item785">[785]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10899" title="Abstract">arXiv:2302.10899</a> (replaced) [<a href="/pdf/2302.10899" title="Download PDF">pdf</a>, <a href="/format/2302.10899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Affinity Assisted Knowledge Distillation and Quantization of  Deep Neural Networks on Label-Free Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhijian Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Biao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+P">Penghang Yin</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yingyong Qi</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+J">Jack Xin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item786">[786]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10977" title="Abstract">arXiv:2302.10977</a> (replaced) [<a href="/pdf/2302.10977" title="Download PDF">pdf</a>, <a href="/format/2302.10977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HLSDataset: Open-Source Dataset for ML-Assisted FPGA Design using High  Level Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhigang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+A">Aman Arora</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruihao Li</a>, 
<a href="/search/cs?searchtype=author&query=John%2C+L+K">Lizy K. John</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item787">[787]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11068" title="Abstract">arXiv:2302.11068</a> (replaced) [<a href="/pdf/2302.11068" title="Download PDF">pdf</a>, <a href="/ps/2302.11068" title="Download PostScript">ps</a>, <a href="/format/2302.11068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low Rank Matrix Completion via Robust Alternating Minimization in Nearly  Linear Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuzhou Gu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhao Song</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Junze Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lichen Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Improve the runtime from $O(mnk)$ to $O|\Omega| k)$
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item788">[788]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12447" title="Abstract">arXiv:2302.12447</a> (replaced) [<a href="/pdf/2302.12447" title="Download PDF">pdf</a>, <a href="/format/2302.12447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smaller public keys for MinRank-based schemes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di+Scala%2C+A+J">Antonio J. Di Scala</a>, 
<a href="/search/cs?searchtype=author&query=Sanna%2C+C">Carlo Sanna</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item789">[789]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13705" title="Abstract">arXiv:2302.13705</a> (replaced) [<a href="/pdf/2302.13705" title="Download PDF">pdf</a>, <a href="/format/2302.13705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameter Estimation-Based Extended Observer for Linear Systems with  Polynomial Overparametrization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Glushchenko%2C+A">Anton Glushchenko</a>, 
<a href="/search/eess?searchtype=author&query=Lastochkin%2C+K">Konstantin Lastochkin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item790">[790]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14581" title="Abstract">arXiv:2302.14581</a> (replaced) [<a href="/pdf/2302.14581" title="Download PDF">pdf</a>, <a href="/format/2302.14581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HopFIR: Hop-wise GraphFormer with Intragroup Joint Refinement for 3D  Human Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhai%2C+K">Kai Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Q">Qiang Nie</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+B">Bo Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shanlin Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item791">[791]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14640" title="Abstract">arXiv:2302.14640</a> (replaced) [<a href="/pdf/2302.14640" title="Download PDF">pdf</a>, <a href="/format/2302.14640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-Learning with Adaptive Weighted Loss for Imbalanced Cold-Start  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minchang Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yongjin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ryu%2C+J+H">Jung Hyun Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taesup Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CIKM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item792">[792]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00028" title="Abstract">arXiv:2303.00028</a> (replaced) [<a href="/pdf/2303.00028" title="Download PDF">pdf</a>, <a href="/format/2303.00028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Sensor Placement from Regression with Sparse Gaussian  Processes in Continuous and Discrete Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jakkala%2C+K">Kalvik Jakkala</a>, 
<a href="/search/cs?searchtype=author&query=Akella%2C+S">Srinivas Akella</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures, preprint, appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item793">[793]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00052" title="Abstract">arXiv:2303.00052</a> (replaced) [<a href="/pdf/2303.00052" title="Download PDF">pdf</a>, <a href="/ps/2303.00052" title="Download PostScript">ps</a>, <a href="/format/2303.00052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithmic Solutions for Maximizing Shareable Costs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+R">Rong Zou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Boyue Lin</a>, 
<a href="/search/cs?searchtype=author&query=Uetz%2C+M">Marc Uetz</a>, 
<a href="/search/cs?searchtype=author&query=Walter%2C+M">Matthias Walter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item794">[794]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01860" title="Abstract">arXiv:2303.01860</a> (replaced) [<a href="/pdf/2303.01860" title="Download PDF">pdf</a>, <a href="/format/2303.01860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rule-based Out-Of-Distribution Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Bernardi%2C+G">Giacomo De Bernardi</a>, 
<a href="/search/cs?searchtype=author&query=Narteni%2C+S">Sara Narteni</a>, 
<a href="/search/cs?searchtype=author&query=Cambiaso%2C+E">Enrico Cambiaso</a>, 
<a href="/search/cs?searchtype=author&query=Mongelli%2C+M">Maurizio Mongelli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item795">[795]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02091" title="Abstract">arXiv:2303.02091</a> (replaced) [<a href="/pdf/2303.02091" title="Download PDF">pdf</a>, <a href="/format/2303.02091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Delicate Textured Mesh Recovery from NeRF via Adaptive Surface  Refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiaxiang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaokang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+T">Tianshu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+E">Errui Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingdong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+G">Gang Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 camera-ready, Project Page: <a href="https://me.kiui.moe/nerf2mesh">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item796">[796]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02280" title="Abstract">arXiv:2303.02280</a> (replaced) [<a href="/pdf/2303.02280" title="Download PDF">pdf</a>, <a href="/format/2303.02280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Technical Report on: Tripedal Dynamic Gaits for a Quadruped Robot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stewart-Height%2C+A">Abriana Stewart-Height</a>, 
<a href="/search/cs?searchtype=author&query=Koditschek%2C+D+E">Daniel E. Koditschek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated *increased font size on figures 2-6 *added a legend, replaced text with colors in figure 5a and 6a *made variables representing vectors boldface in equations 8-10 *expanded on calculations in equations 8-10 by adding additional lines *added a missing "2" to equation 8 (typo) *added mass of the robot to tables II and III *increased the width of figures 1 and 2
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item797">[797]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05063" title="Abstract">arXiv:2303.05063</a> (replaced) [<a href="/pdf/2303.05063" title="Download PDF">pdf</a>, <a href="/format/2303.05063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ICL-D3IE: In-Context Learning with Diverse Demonstrations Updating for  Document Information Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiabang He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ning Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H+T">Heng Tao Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023. Code is available at <a href="https://github.com/MAEHCM/ICL-D3IE">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item798">[798]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05101" title="Abstract">arXiv:2303.05101</a> (replaced) [<a href="/pdf/2303.05101" title="Download PDF">pdf</a>, <a href="/format/2303.05101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Stochastic Gradient Riemannian Langevin Dynamics in  Non-Diagonal Metrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hanlin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Hartmann%2C+M">Marcelo Hartmann</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+B">Bernardo Williams</a>, 
<a href="/search/cs?searchtype=author&query=Klami%2C+A">Arto Klami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item799">[799]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05805" title="Abstract">arXiv:2303.05805</a> (replaced) [<a href="/pdf/2303.05805" title="Download PDF">pdf</a>, <a href="/ps/2303.05805" title="Download PostScript">ps</a>, <a href="/format/2303.05805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new mixed finite element for the linear elasticity problem in 3D
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hu%2C+J">Jun Hu</a>, 
<a href="/search/math?searchtype=author&query=Ma%2C+R">Rui Ma</a>, 
<a href="/search/math?searchtype=author&query=Sun%2C+Y">Yuanxun Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item800">[800]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08340" title="Abstract">arXiv:2303.08340</a> (replaced) [<a href="/pdf/2303.08340" title="Download PDF">pdf</a>, <a href="/format/2303.08340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VideoFlow: Exploiting Temporal Cues for Multi-frame Optical Flow  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xiaoyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhaoyang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+W">Weikang Bian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dasong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Manyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+K+C">Ka Chun Cheung</a>, 
<a href="/search/cs?searchtype=author&query=See%2C+S">Simon See</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Hongwei Qin</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jifeng Dai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongsheng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item801">[801]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08682" title="Abstract">arXiv:2303.08682</a> (replaced) [<a href="/pdf/2303.08682" title="Download PDF">pdf</a>, <a href="/format/2303.08682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RSFNet: A White-Box Image Retouching Approach using Region-Specific  Color Filters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wenqi Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+X">Xiaoyang Kang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+P">Peiran Ren</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuansong Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item802">[802]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08757" title="Abstract">arXiv:2303.08757</a> (replaced) [<a href="/pdf/2303.08757" title="Download PDF">pdf</a>, <a href="/format/2303.08757" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CT Perfusion is All We Need: 4D CNN Segmentation of Penumbra and Core in  Patients With Suspected Ischemic Stroke
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tomasetti%2C+L">Luca Tomasetti</a>, 
<a href="/search/eess?searchtype=author&query=Engan%2C+K">Kjersti Engan</a>, 
<a href="/search/eess?searchtype=author&query=H%C3%B8llesli%2C+L+J">Liv Jorunn H&#xf8;llesli</a>, 
<a href="/search/eess?searchtype=author&query=Kurz%2C+K+D">Kathinka D&#xe6;hli Kurz</a>, 
<a href="/search/eess?searchtype=author&query=Khanmohammadi%2C+M">Mahdieh Khanmohammadi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item803">[803]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08983" title="Abstract">arXiv:2303.08983</a> (replaced) [<a href="/pdf/2303.08983" title="Download PDF">pdf</a>, <a href="/format/2303.08983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforce Data, Multiply Impact: Improved Model Accuracy and Robustness  with Dataset Reinforcement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Faghri%2C+F">Fartash Faghri</a>, 
<a href="/search/cs?searchtype=author&query=Pouransari%2C+H">Hadi Pouransari</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+S">Sachin Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Farajtabar%2C+M">Mehrdad Farajtabar</a>, 
<a href="/search/cs?searchtype=author&query=Farhadi%2C+A">Ali Farhadi</a>, 
<a href="/search/cs?searchtype=author&query=Rastegari%2C+M">Mohammad Rastegari</a>, 
<a href="/search/cs?searchtype=author&query=Tuzel%2C+O">Oncel Tuzel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at International Conference on Computer Vision (ICCV) 2023. Camera-ready version with new Tables 9 and 10
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item804">[804]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08998" title="Abstract">arXiv:2303.08998</a> (replaced) [<a href="/pdf/2303.08998" title="Download PDF">pdf</a>, <a href="/format/2303.08998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified Visual Relationship Detection with Vision and Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Long Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Liangzhe Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+B">Boqing Gong</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yin Cui</a>, 
<a href="/search/cs?searchtype=author&query=Schroff%2C+F">Florian Schroff</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Adam%2C+H">Hartwig Adam</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023. Code is available at <a href="https://github.com/google-research/scenic/tree/main/scenic/projects/univrd">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item805">[805]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09769" title="Abstract">arXiv:2303.09769</a> (replaced) [<a href="/pdf/2303.09769" title="Download PDF">pdf</a>, <a href="/format/2303.09769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Denoising Diffusion Autoencoders are Unified Self-supervised Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiang%2C+W">Weilai Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Di Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 Oral
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item806">[806]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09867" title="Abstract">arXiv:2303.09867</a> (replaced) [<a href="/pdf/2303.09867" title="Download PDF">pdf</a>, <a href="/format/2303.09867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffusionRet: Generative Text-Video Retrieval with Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+P">Peng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zesen Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kehan Li</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xiangyang Ji</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Li Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jie Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item807">[807]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10070" title="Abstract">arXiv:2303.10070</a> (replaced) [<a href="/pdf/2303.10070" title="Download PDF">pdf</a>, <a href="/format/2303.10070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Continual Learning Framework with General Parameter-Efficient  Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Q">Qiankun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yifan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+T">Teng Xi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ghanem%2C+B">Bernard Ghanem</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item808">[808]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10130" title="Abstract">arXiv:2303.10130</a> (replaced) [<a href="/pdf/2303.10130" title="Download PDF">pdf</a>, <a href="/format/2303.10130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPTs are GPTs: An Early Look at the Labor Market Impact Potential of  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Eloundou%2C+T">Tyna Eloundou</a>, 
<a href="/search/econ?searchtype=author&query=Manning%2C+S">Sam Manning</a>, 
<a href="/search/econ?searchtype=author&query=Mishkin%2C+P">Pamela Mishkin</a>, 
<a href="/search/econ?searchtype=author&query=Rock%2C+D">Daniel Rock</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item809">[809]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10735" title="Abstract">arXiv:2303.10735</a> (replaced) [<a href="/pdf/2303.10735" title="Download PDF">pdf</a>, <a href="/format/2303.10735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SKED: Sketch-guided Text-based 3D Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mikaeili%2C+A">Aryan Mikaeili</a>, 
<a href="/search/cs?searchtype=author&query=Perel%2C+O">Or Perel</a>, 
<a href="/search/cs?searchtype=author&query=Safaee%2C+M">Mehdi Safaee</a>, 
<a href="/search/cs?searchtype=author&query=Cohen-Or%2C+D">Daniel Cohen-Or</a>, 
<a href="/search/cs?searchtype=author&query=Mahdavi-Amiri%2C+A">Ali Mahdavi-Amiri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item810">[810]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10980" title="Abstract">arXiv:2303.10980</a> (replaced) [<a href="/pdf/2303.10980" title="Download PDF">pdf</a>, <a href="/format/2303.10980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counting Homomorphisms from Hypergraphs of Bounded Generalised Hypertree  Width: A Logical Characterisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scheidt%2C+B">Benjamin Scheidt</a>, 
<a href="/search/cs?searchtype=author&query=Schweikardt%2C+N">Nicole Schweikardt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 68 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item811">[811]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11219" title="Abstract">arXiv:2303.11219</a> (replaced) [<a href="/pdf/2303.11219" title="Download PDF">pdf</a>, <a href="/format/2303.11219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeTO:Neural Reconstruction of Transparent Objects with Self-Occlusion  Aware Refraction-Tracing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongcheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+X">Xiaoxiao Long</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yusen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+T">Tuo Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+F">Fei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chunxia Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item812">[812]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11329" title="Abstract">arXiv:2303.11329</a> (replaced) [<a href="/pdf/2303.11329" title="Download PDF">pdf</a>, <a href="/format/2303.11329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sound Localization from Motion: Jointly Learning Sound Direction and  Camera Rotation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Ziyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+S">Shengyi Qian</a>, 
<a href="/search/cs?searchtype=author&query=Owens%2C+A">Andrew Owens</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023. Project site: <a href="https://ificl.github.io/SLfM/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item813">[813]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11585" title="Abstract">arXiv:2303.11585</a> (replaced) [<a href="/pdf/2303.11585" title="Download PDF">pdf</a>, <a href="/ps/2303.11585" title="Download PostScript">ps</a>, <a href="/format/2303.11585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phase-Matching Quantum Key Distribution without Intensity Modulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Shao%2C+S">Shan-Feng Shao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cao%2C+X">Xiao-Yu Cao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Xie%2C+Y">Yuan-Mei Xie</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gu%2C+J">Jie Gu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+W">Wen-Bo Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Fu%2C+Y">Yao Fu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yin%2C+H">Hua-Lei Yin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+Z">Zeng-Bing Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Comments are welcome! 12 pages, 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Phys. Rev. Applied 20, 024046 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item814">[814]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11629" title="Abstract">arXiv:2303.11629</a> (replaced) [<a href="/pdf/2303.11629" title="Download PDF">pdf</a>, <a href="/format/2303.11629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TMA: Temporal Motion Aggregation for Event-based Optical Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haotian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+S">Sanqing Qu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhijun Li</a>, 
<a href="/search/cs?searchtype=author&query=Knoll%2C+A">Alois Knoll</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Changjun Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item815">[815]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11722" title="Abstract">arXiv:2303.11722</a> (replaced) [<a href="/pdf/2303.11722" title="Download PDF">pdf</a>, <a href="/format/2303.11722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Neural Representation for Cooperative Low-light Image  Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuzhou Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Moxuan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yanmin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zihan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jian Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item816">[816]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12048" title="Abstract">arXiv:2303.12048</a> (replaced) [<a href="/pdf/2303.12048" title="Download PDF">pdf</a>, <a href="/format/2303.12048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vox-E: Text-guided Voxel Editing of 3D Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sella%2C+E">Etai Sella</a>, 
<a href="/search/cs?searchtype=author&query=Fiebelman%2C+G">Gal Fiebelman</a>, 
<a href="/search/cs?searchtype=author&query=Hedman%2C+P">Peter Hedman</a>, 
<a href="/search/cs?searchtype=author&query=Averbuch-Elor%2C+H">Hadar Averbuch-Elor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project webpage: <a href="https://tau-vailab.github.io/Vox-E/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item817">[817]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12441" title="Abstract">arXiv:2303.12441</a> (replaced) [<a href="/pdf/2303.12441" title="Download PDF">pdf</a>, <a href="/ps/2303.12441" title="Download PostScript">ps</a>, <a href="/format/2303.12441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AMPLE: An Adaptive Multiple Path Loss Exponent Radio Propagation Model  Considering Environmental Factors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Lingyou Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cetinkaya%2C+O">Oktay Cetinkaya</a>, 
<a href="/search/cs?searchtype=author&query=Jubb%2C+S">Steve Jubb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been submitted to IEEE Transactions for possible publications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item818">[818]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12557" title="Abstract">arXiv:2303.12557</a> (replaced) [<a href="/pdf/2303.12557" title="Download PDF">pdf</a>, <a href="/format/2303.12557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Q-HyViT: Post-Training Quantization for Hybrid Vision Transformer with  Bridge Block Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jemin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+Y">Yongin Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jeman Park</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+M">Misun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sihyeong Park</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hwanjun Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item819">[819]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12779" title="Abstract">arXiv:2303.12779</a> (replaced) [<a href="/pdf/2303.12779" title="Download PDF">pdf</a>, <a href="/format/2303.12779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LFM-3D: Learnable Feature Matching Across Wide Baselines Using 3D  Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karpur%2C+A">Arjun Karpur</a>, 
<a href="/search/cs?searchtype=author&query=Perrotta%2C+G">Guilherme Perrotta</a>, 
<a href="/search/cs?searchtype=author&query=Martin-Brualla%2C+R">Ricardo Martin-Brualla</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Howard Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Araujo%2C+A">Andre Araujo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item820">[820]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12782" title="Abstract">arXiv:2303.12782</a> (replaced) [<a href="/pdf/2303.12782" title="Download PDF">pdf</a>, <a href="/format/2303.12782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tube-Link: A Flexible Cross Tube Framework for Universal Video  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangtai Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Haobo Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+G">Guangliang Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+J">Jiangmiao Pang</a>, 
<a href="/search/cs?searchtype=author&query=Loy%2C+C+C">Chen Change Loy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV-2023, Project page: <a href="https://github.com/lxtGH/Tube-Link">this https URL</a> (fix typos and errors, update the results)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item821">[821]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13233" title="Abstract">arXiv:2303.13233</a> (replaced) [<a href="/pdf/2303.13233" title="Download PDF">pdf</a>, <a href="/format/2303.13233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visually-Prompted Language Model for Fine-Grained Scene Graph Generation  in an Open World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qifan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juncheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Siliang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+W">Wei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yueting Zhuang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item822">[822]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13505" title="Abstract">arXiv:2303.13505</a> (replaced) [<a href="/pdf/2303.13505" title="Download PDF">pdf</a>, <a href="/format/2303.13505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Large-scale Study of Spatiotemporal Representation Learning with a New  Benchmark on Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+A">Andong Deng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Taojiannan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item823">[823]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15247" title="Abstract">arXiv:2303.15247</a> (replaced) [<a href="/pdf/2303.15247" title="Download PDF">pdf</a>, <a href="/format/2303.15247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Composed Image Retrieval with Textual Inversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baldrati%2C+A">Alberto Baldrati</a>, 
<a href="/search/cs?searchtype=author&query=Agnolucci%2C+L">Lorenzo Agnolucci</a>, 
<a href="/search/cs?searchtype=author&query=Bertini%2C+M">Marco Bertini</a>, 
<a href="/search/cs?searchtype=author&query=Del+Bimbo%2C+A">Alberto Del Bimbo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item824">[824]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15634" title="Abstract">arXiv:2303.15634</a> (replaced) [<a href="/pdf/2303.15634" title="Download PDF">pdf</a>, <a href="/format/2303.15634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Rate Schedules in the Presence of Distribution Shift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fahrbach%2C+M">Matthew Fahrbach</a>, 
<a href="/search/cs?searchtype=author&query=Javanmard%2C+A">Adel Javanmard</a>, 
<a href="/search/cs?searchtype=author&query=Mirrokni%2C+V">Vahab Mirrokni</a>, 
<a href="/search/cs?searchtype=author&query=Worah%2C+P">Pratik Worah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 40th International Conference on Machine
  Learning (ICML 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item825">[825]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15649" title="Abstract">arXiv:2303.15649</a> (replaced) [<a href="/pdf/2303.15649" title="Download PDF">pdf</a>, <a href="/format/2303.15649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StyleDiffusion: Prompt-Embedding Inversion for Text-Based Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Senmao Li</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Weijer%2C+J">Joost van de Weijer</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+T">Taihang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+F+S">Fahad Shahbaz Khan</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Q">Qibin Hou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaxing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item826">[826]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16053" title="Abstract">arXiv:2303.16053</a> (replaced) [<a href="/pdf/2303.16053" title="Download PDF">pdf</a>, <a href="/format/2303.16053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time Multi-person Eyeblink Detection in the Wild for Untrimmed  Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Wenzheng Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yang Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Sicheng Wei</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+J">Jinfang Gan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xintao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhiguo Cao</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhiwen Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J+T">Joey Tianyi Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CVPR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item827">[827]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16817" title="Abstract">arXiv:2303.16817</a> (replaced) [<a href="/pdf/2303.16817" title="Download PDF">pdf</a>, <a href="/format/2303.16817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Superpixel for Active Learning in Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hoyoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+M">Minhyeon Oh</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+S">Sehyun Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Kwak%2C+S">Suha Kwak</a>, 
<a href="/search/cs?searchtype=author&query=Ok%2C+J">Jungseul Ok</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item828">[828]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17606" title="Abstract">arXiv:2303.17606</a> (replaced) [<a href="/pdf/2303.17606" title="Download PDF">pdf</a>, <a href="/format/2303.17606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AvatarCraft: Transforming Text into Neural Human Avatars with  Parameterized Shape and Pose Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+R">Ruixiang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Can Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingbo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+M">Menglei Chai</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+M">Mingming He</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dongdong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+J">Jing Liao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 Camera Ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item829">[829]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00054" title="Abstract">arXiv:2304.00054</a> (replaced) [<a href="/pdf/2304.00054" title="Download PDF">pdf</a>, <a href="/format/2304.00054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LivePose: Online 3D Reconstruction from Monocular Video with Dynamic  Camera Poses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stier%2C+N">Noah Stier</a>, 
<a href="/search/cs?searchtype=author&query=Angles%2C+B">Baptiste Angles</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yajie Yan</a>, 
<a href="/search/cs?searchtype=author&query=Colburn%2C+A">Alex Colburn</a>, 
<a href="/search/cs?searchtype=author&query=Chuang%2C+M">Ming Chuang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item830">[830]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00247" title="Abstract">arXiv:2304.00247</a> (replaced) [<a href="/pdf/2304.00247" title="Download PDF">pdf</a>, <a href="/format/2304.00247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving of Robotic Virtual Agent&#x27;s errors that are accepted by  reaction and human&#x27;s preference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsumura%2C+T">Takahiro Tsumura</a>, 
<a href="/search/cs?searchtype=author&query=Yamada%2C+S">Seiji Yamada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures, 5 tables, submitted ICSR2023. arXiv admin note: text overlap with <a href="/abs/2206.06128">arXiv:2206.06128</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item831">[831]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01397" title="Abstract">arXiv:2304.01397</a> (replaced) [<a href="/pdf/2304.01397" title="Download PDF">pdf</a>, <a href="/format/2304.01397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LTM: Scalable and Black-box Similarity-based Test Suite Minimization  based on Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+R">Rongqi Pan</a>, 
<a href="/search/cs?searchtype=author&query=Ghaleb%2C+T+A">Taher A. Ghaleb</a>, 
<a href="/search/cs?searchtype=author&query=Briand%2C+L">Lionel Briand</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item832">[832]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01480" title="Abstract">arXiv:2304.01480</a> (replaced) [<a href="/pdf/2304.01480" title="Download PDF">pdf</a>, <a href="/format/2304.01480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FineRecon: Depth-aware Feed-forward Network for Detailed 3D  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stier%2C+N">Noah Stier</a>, 
<a href="/search/cs?searchtype=author&query=Ranjan%2C+A">Anurag Ranjan</a>, 
<a href="/search/cs?searchtype=author&query=Colburn%2C+A">Alex Colburn</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yajie Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+F">Fangchang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Angles%2C+B">Baptiste Angles</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item833">[833]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03188" title="Abstract">arXiv:2304.03188</a> (replaced) [<a href="/pdf/2304.03188" title="Download PDF">pdf</a>, <a href="/format/2304.03188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advances in Data-Driven Analysis and Synthesis of 3D Indoor Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patil%2C+A+G">Akshay Gadi Patil</a>, 
<a href="/search/cs?searchtype=author&query=Patil%2C+S+G">Supriya Gadi Patil</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Manyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Fisher%2C+M">Matthew Fisher</a>, 
<a href="/search/cs?searchtype=author&query=Savva%2C+M">Manolis Savva</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Computer Graphics Forum, Aug 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
</div>
</dd>
<dt><a name="item834">[834]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03335" title="Abstract">arXiv:2304.03335</a> (replaced) [<a href="/pdf/2304.03335" title="Download PDF">pdf</a>, <a href="/format/2304.03335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hardware-Aware Static Optimization of Hyperdimensional Computations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> Pu (Luke)Yi, 
<a href="/search/cs?searchtype=author&query=Achour%2C+S">Sara Achour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item835">[835]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04521" title="Abstract">arXiv:2304.04521</a> (replaced) [<a href="/pdf/2304.04521" title="Download PDF">pdf</a>, <a href="/format/2304.04521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot In-Distribution Detection in Multi-Object Settings Using  Vision-Language Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miyai%2C+A">Atsuyuki Miyai</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Irie%2C+G">Go Irie</a>, 
<a href="/search/cs?searchtype=author&query=Aizawa%2C+K">Kiyoharu Aizawa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item836">[836]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04909" title="Abstract">arXiv:2304.04909</a> (replaced) [<a href="/pdf/2304.04909" title="Download PDF">pdf</a>, <a href="/format/2304.04909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SATR: Zero-Shot Semantic Segmentation of 3D Shapes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdelreheem%2C+A">Ahmed Abdelreheem</a>, 
<a href="/search/cs?searchtype=author&query=Skorokhodov%2C+I">Ivan Skorokhodov</a>, 
<a href="/search/cs?searchtype=author&query=Ovsjanikov%2C+M">Maks Ovsjanikov</a>, 
<a href="/search/cs?searchtype=author&query=Wonka%2C+P">Peter Wonka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project webpage: <a href="https://samir55.github.io/SATR/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item837">[837]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05127" title="Abstract">arXiv:2304.05127</a> (replaced) [<a href="/pdf/2304.05127" title="Download PDF">pdf</a>, <a href="/format/2304.05127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balancing Privacy and Performance for Private Federated Learning  Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+X">Xiangjian Hou</a>, 
<a href="/search/cs?searchtype=author&query=Khirirat%2C+S">Sarit Khirirat</a>, 
<a href="/search/cs?searchtype=author&query=Yaqub%2C+M">Mohammad Yaqub</a>, 
<a href="/search/cs?searchtype=author&query=Horvath%2C+S">Samuel Horvath</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item838">[838]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06867" title="Abstract">arXiv:2304.06867</a> (replaced) [<a href="/pdf/2304.06867" title="Download PDF">pdf</a>, <a href="/format/2304.06867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Safety-critical Control with Uncertainty Estimation for  Human-robot Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dianhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Van%2C+M">Mien Van</a>, 
<a href="/search/cs?searchtype=author&query=Mcllvanna%2C+S">Stephen Mcllvanna</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuzhu Sun</a>, 
<a href="/search/cs?searchtype=author&query=McLoone%2C+S">Se&#xe1;n McLoone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item839">[839]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06923" title="Abstract">arXiv:2304.06923</a> (replaced) [<a href="/pdf/2304.06923" title="Download PDF">pdf</a>, <a href="/format/2304.06923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An NMPC-ECBF Framework for Dynamic Motion Planning and Execution in  vision-based Human-Robot Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dianhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Van%2C+M">Mien Van</a>, 
<a href="/search/cs?searchtype=author&query=Sopasakis%2C+P">Pantelis Sopasakis</a>, 
<a href="/search/cs?searchtype=author&query=McLoone%2C+S">Se&#xe1;n McLoone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Image and Video Processing (eess.IV); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item840">[840]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08781" title="Abstract">arXiv:2304.08781</a> (replaced) [<a href="/pdf/2304.08781" title="Download PDF">pdf</a>, <a href="/format/2304.08781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AoI-Delay Tradeoff in Mobile Edge Caching: A Mixed-Order  Drift-Plus-Penalty Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+R">Ran Li</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+C">Chuan Huang</a>, 
<a href="/search/eess?searchtype=author&query=Qin%2C+X">Xiaoqi Qin</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+L">Lei Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item841">[841]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09987" title="Abstract">arXiv:2304.09987</a> (replaced) [<a href="/pdf/2304.09987" title="Download PDF">pdf</a>, <a href="/format/2304.09987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tetra-NeRF: Representing Neural Radiance Fields Using Tetrahedra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kulhanek%2C+J">Jonas Kulhanek</a>, 
<a href="/search/cs?searchtype=author&query=Sattler%2C+T">Torsten Sattler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023, Web: <a href="https://jkulhanek.com/tetra-nerf">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item842">[842]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09991" title="Abstract">arXiv:2304.09991</a> (replaced) [<a href="/pdf/2304.09991" title="Download PDF">pdf</a>, <a href="/format/2304.09991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supporting Human-AI Collaboration in Auditing LLMs with LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rastogi%2C+C">Charvi Rastogi</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+M+T">Marco Tulio Ribeiro</a>, 
<a href="/search/cs?searchtype=author&query=King%2C+N">Nicholas King</a>, 
<a href="/search/cs?searchtype=author&query=Amershi%2C+S">Saleema Amershi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item843">[843]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10031" title="Abstract">arXiv:2304.10031</a> (replaced) [<a href="/pdf/2304.10031" title="Download PDF">pdf</a>, <a href="/format/2304.10031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Architectures of Topological Deep Learning: A Survey on Topological  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papillon%2C+M">Mathilde Papillon</a>, 
<a href="/search/cs?searchtype=author&query=Sanborn%2C+S">Sophia Sanborn</a>, 
<a href="/search/cs?searchtype=author&query=Hajij%2C+M">Mustafa Hajij</a>, 
<a href="/search/cs?searchtype=author&query=Miolane%2C+N">Nina Miolane</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item844">[844]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10417" title="Abstract">arXiv:2304.10417</a> (replaced) [<a href="/pdf/2304.10417" title="Download PDF">pdf</a>, <a href="/format/2304.10417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SINC: Spatial Composition of 3D Human Motions for Simultaneous Action  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Athanasiou%2C+N">Nikos Athanasiou</a>, 
<a href="/search/cs?searchtype=author&query=Petrovich%2C+M">Mathis Petrovich</a>, 
<a href="/search/cs?searchtype=author&query=Black%2C+M+J">Michael J. Black</a>, 
<a href="/search/cs?searchtype=author&query=Varol%2C+G">G&#xfc;l Varol</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 Camera Ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item845">[845]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11609" title="Abstract">arXiv:2304.11609</a> (replaced) [<a href="/pdf/2304.11609" title="Download PDF">pdf</a>, <a href="/format/2304.11609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PiClick: Picking the desired mask in click-based interactive  segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+C">Cilin Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haochen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiaolong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+G">Guoliang Kang</a>, 
<a href="/search/cs?searchtype=author&query=Gavves%2C+E">Efstratios Gavves</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item846">[846]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11957" title="Abstract">arXiv:2304.11957</a> (replaced) [<a href="/pdf/2304.11957" title="Download PDF">pdf</a>, <a href="/format/2304.11957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking ChatGPT-4 on ACR Radiation Oncology In-Training (TXIT) Exam  and Red Journal Gray Zone Cases: Potentials and Challenges for AI-Assisted  Medical Education and Decision Making in Radiation Oncology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Huang%2C+Y">Yixing Huang</a>, 
<a href="/search/physics?searchtype=author&query=Gomaa%2C+A">Ahmed Gomaa</a>, 
<a href="/search/physics?searchtype=author&query=Semrau%2C+S">Sabine Semrau</a>, 
<a href="/search/physics?searchtype=author&query=Haderlein%2C+M">Marlen Haderlein</a>, 
<a href="/search/physics?searchtype=author&query=Lettmaier%2C+S">Sebastian Lettmaier</a>, 
<a href="/search/physics?searchtype=author&query=Weissmann%2C+T">Thomas Weissmann</a>, 
<a href="/search/physics?searchtype=author&query=Grigo%2C+J">Johanna Grigo</a>, 
<a href="/search/physics?searchtype=author&query=Tkhayat%2C+H+B">Hassen Ben Tkhayat</a>, 
<a href="/search/physics?searchtype=author&query=Frey%2C+B">Benjamin Frey</a>, 
<a href="/search/physics?searchtype=author&query=Gaipl%2C+U+S">Udo S. Gaipl</a>, 
<a href="/search/physics?searchtype=author&query=Distel%2C+L+V">Luitpold V. Distel</a>, 
<a href="/search/physics?searchtype=author&query=Maier%2C+A">Andreas Maier</a>, 
<a href="/search/physics?searchtype=author&query=Fietkau%2C+R">Rainer Fietkau</a>, 
<a href="/search/physics?searchtype=author&query=Bert%2C+C">Christoph Bert</a>, 
<a href="/search/physics?searchtype=author&query=Putz%2C+F">Florian Putz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item847">[847]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11963" title="Abstract">arXiv:2304.11963</a> (replaced) [<a href="/pdf/2304.11963" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Design of Neural Network Structure for Power System Frequency  Security Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zhuoxuan Li</a>, 
<a href="/search/eess?searchtype=author&query=Chu%2C+Z">Zhongda Chu</a>, 
<a href="/search/eess?searchtype=author&query=Teng%2C+F">Fei Teng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item848">[848]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14857" title="Abstract">arXiv:2304.14857</a> (replaced) [<a href="/pdf/2304.14857" title="Download PDF">pdf</a>, <a href="/format/2304.14857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MASK-CNN-Transformer For Real-Time Multi-Label Weather Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shengchao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+T">Ting Shu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Huan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y+Y">Yuan Yan Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Have been accepted. Appears in Knowledge-Based Systems, see <a href="https://www.sciencedirect.com/science/article/pii/S0950705123006317">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Knowledge-Based Systems, 110881 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item849">[849]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00795" title="Abstract">arXiv:2305.00795</a> (replaced) [<a href="/pdf/2305.00795" title="Download PDF">pdf</a>, <a href="/format/2305.00795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SelfDocSeg: A Self-Supervised vision-based Approach towards Document  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maity%2C+S">Subhajit Maity</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+S">Sanket Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Manna%2C+S">Siladittya Manna</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+A">Ayan Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Llad%C3%B3s%2C+J">Josep Llad&#xf3;s</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+S">Saumik Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+U">Umapada Pal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at The 17th International Conference on Document Analysis and Recognition (ICDAR 2023)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICDAR 2023 (International Conference on Document Analysis and
  Recognition) Lecture Notes in Computer Science, vol 14187, pp. 342-360.
  Springer Nature
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item850">[850]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00948" title="Abstract">arXiv:2305.00948</a> (replaced) [<a href="/pdf/2305.00948" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Linguistic Models: Analyzing theoretical linguistic abilities of  LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Begu%C5%A1%2C+G">Ga&#x161;per Begu&#x161;</a>, 
<a href="/search/cs?searchtype=author&query=D%C4%85bkowski%2C+M">Maksymilian D&#x105;bkowski</a>, 
<a href="/search/cs?searchtype=author&query=Rhodes%2C+R">Ryan Rhodes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item851">[851]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01154" title="Abstract">arXiv:2305.01154</a> (replaced) [<a href="/pdf/2305.01154" title="Download PDF">pdf</a>, <a href="/format/2305.01154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedAVO: Improving Communication Efficiency in Federated Learning with  African Vultures Optimizer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hossain%2C+M+Z">Md Zarif Hossain</a>, 
<a href="/search/cs?searchtype=author&query=Imteaj%2C+A">Ahmed Imteaj</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item852">[852]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01921" title="Abstract">arXiv:2305.01921</a> (replaced) [<a href="/pdf/2305.01921" title="Download PDF">pdf</a>, <a href="/format/2305.01921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffFacto: Controllable Part-Based 3D Point Cloud Generation with Cross  Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nakayama%2C+K">Kiyohiro Nakayama</a>, 
<a href="/search/cs?searchtype=author&query=Uy%2C+M+A">Mikaela Angelina Uy</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiahui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shi-Min Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Ke Li</a>, 
<a href="/search/cs?searchtype=author&query=Guibas%2C+L+J">Leonidas J Guibas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item853">[853]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03515" title="Abstract">arXiv:2305.03515</a> (replaced) [<a href="/pdf/2305.03515" title="Download PDF">pdf</a>, <a href="/format/2305.03515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GradTree: Learning Axis-Aligned Decision Trees with Gradient Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marton%2C+S">Sascha Marton</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%BCdtke%2C+S">Stefan L&#xfc;dtke</a>, 
<a href="/search/cs?searchtype=author&query=Bartelt%2C+C">Christian Bartelt</a>, 
<a href="/search/cs?searchtype=author&query=Stuckenschmidt%2C+H">Heiner Stuckenschmidt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item854">[854]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03807" title="Abstract">arXiv:2305.03807</a> (replaced) [<a href="/pdf/2305.03807" title="Download PDF">pdf</a>, <a href="/format/2305.03807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evading Watermark based Detection of AI-Generated Content
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhengyuan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinghuai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+N+Z">Neil Zhenqiang Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in ACM Conference on Computer and Communications Security (CCS), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item855">[855]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03997" title="Abstract">arXiv:2305.03997</a> (replaced) [<a href="/pdf/2305.03997" title="Download PDF">pdf</a>, <a href="/format/2305.03997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unlocking Low-Light-Rainy Image Restoration by Pairwise Degradation  Feature Vector Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lin%2C+X">Xin Lin</a>, 
<a href="/search/eess?searchtype=author&query=Yue%2C+J">Jingtong Yue</a>, 
<a href="/search/eess?searchtype=author&query=Ding%2C+S">Sixian Ding</a>, 
<a href="/search/eess?searchtype=author&query=Ren%2C+C">Chao Ren</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+C">Chun-Le Guo</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+C">Chongyi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item856">[856]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06671" title="Abstract">arXiv:2305.06671</a> (replaced) [<a href="/pdf/2305.06671" title="Download PDF">pdf</a>, <a href="/format/2305.06671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WeditGAN: Few-shot Image Generation via Latent Space Relocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yuxuan Duan</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+L">Li Niu</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yan Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liqing Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review, see supplementary material for updates of this version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item857">[857]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06741" title="Abstract">arXiv:2305.06741</a> (replaced) [<a href="/pdf/2305.06741" title="Download PDF">pdf</a>, <a href="/format/2305.06741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IVP-VAE: Modeling EHR Time Series with Initial Value Problem Solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jingge Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Basso%2C+L">Leonie Basso</a>, 
<a href="/search/cs?searchtype=author&query=Nejdl%2C+W">Wolfgang Nejdl</a>, 
<a href="/search/cs?searchtype=author&query=Ganguly%2C+N">Niloy Ganguly</a>, 
<a href="/search/cs?searchtype=author&query=Sikdar%2C+S">Sandipan Sikdar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item858">[858]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09438" title="Abstract">arXiv:2305.09438</a> (replaced) [<a href="/pdf/2305.09438" title="Download PDF">pdf</a>, <a href="/format/2305.09438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MPI-rical: Data-Driven MPI Distributed Parallelism Assistance with  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schneider%2C+N">Nadav Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Kadosh%2C+T">Tal Kadosh</a>, 
<a href="/search/cs?searchtype=author&query=Hasabnis%2C+N">Niranjan Hasabnis</a>, 
<a href="/search/cs?searchtype=author&query=Mattson%2C+T">Timothy Mattson</a>, 
<a href="/search/cs?searchtype=author&query=Pinter%2C+Y">Yuval Pinter</a>, 
<a href="/search/cs?searchtype=author&query=Oren%2C+G">Gal Oren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item859">[859]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09535" title="Abstract">arXiv:2305.09535</a> (replaced) [<a href="/pdf/2305.09535" title="Download PDF">pdf</a>, <a href="/format/2305.09535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What&#x27;s the Problem, Linda? The Conjunction Fallacy as a Fairness Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Colmenares%2C+J+A">Jose Alvarez Colmenares</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item860">[860]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11284" title="Abstract">arXiv:2305.11284</a> (replaced) [<a href="/pdf/2305.11284" title="Download PDF">pdf</a>, <a href="/format/2305.11284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated learning for secure development of AI models for Parkinson&#x27;s  disease detection using speech from different languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Arasteh%2C+S+T">Soroosh Tayebi Arasteh</a>, 
<a href="/search/eess?searchtype=author&query=Rios-Urrego%2C+C+D">Cristian David Rios-Urrego</a>, 
<a href="/search/eess?searchtype=author&query=Noeth%2C+E">Elmar Noeth</a>, 
<a href="/search/eess?searchtype=author&query=Maier%2C+A">Andreas Maier</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+S+H">Seung Hee Yang</a>, 
<a href="/search/eess?searchtype=author&query=Rusz%2C+J">Jan Rusz</a>, 
<a href="/search/eess?searchtype=author&query=Orozco-Arroyave%2C+J+R">Juan Rafael Orozco-Arroyave</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> INTERSPEECH 2023, pp. 5003--5007, Dublin, Ireland
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> INTERSPEECH 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item861">[861]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11377" title="Abstract">arXiv:2305.11377</a> (replaced) [<a href="/pdf/2305.11377" title="Download PDF">pdf</a>, <a href="/format/2305.11377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphFC: Customs Fraud Detection with Label Scarcity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+K">Karandeep Singh</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+Y">Yu-Che Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Cheng-Te Li</a>, 
<a href="/search/cs?searchtype=author&query=Cha%2C+M">Meeyoung Cha</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shou-De Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item862">[862]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12411" title="Abstract">arXiv:2305.12411</a> (replaced) [<a href="/pdf/2305.12411" title="Download PDF">pdf</a>, <a href="/format/2305.12411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthesizing Diverse Human Motions in 3D Indoor Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kaifeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shaofei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Beeler%2C+T">Thabo Beeler</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Siyu Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item863">[863]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12966" title="Abstract">arXiv:2305.12966</a> (replaced) [<a href="/pdf/2305.12966" title="Download PDF">pdf</a>, <a href="/format/2305.12966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Integration Diffusion Model for Realistic Image Deblurring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yulun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Ding Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+B">Bin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinjin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Linghe Kong</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xin Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at <a href="https://github.com/zhengchen1999/HI-Diff">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item864">[864]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13619" title="Abstract">arXiv:2305.13619</a> (replaced) [<a href="/pdf/2305.13619" title="Download PDF">pdf</a>, <a href="/ps/2305.13619" title="Download PostScript">ps</a>, <a href="/format/2305.13619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory Asymmetry Creates Heteroclinic Orbits to Nash Equilibrium in  Learning in Zero-Sum Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fujimoto%2C+Y">Yuma Fujimoto</a>, 
<a href="/search/cs?searchtype=author&query=Ariu%2C+K">Kaito Ariu</a>, 
<a href="/search/cs?searchtype=author&query=Abe%2C+K">Kenshi Abe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages &amp; 5 figures (main), 4 pages &amp; 1 figure (appendix)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA); Optimization and Control (math.OC); Chaotic Dynamics (nlin.CD)

</div>
</div>
</dd>
<dt><a name="item865">[865]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13833" title="Abstract">arXiv:2305.13833</a> (replaced) [<a href="/pdf/2305.13833" title="Download PDF">pdf</a>, <a href="/format/2305.13833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing Sensitivity on Speaker Names for Text Generation from Dialogues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+Q">Qi Jia</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Haifeng Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K+Q">Kenny Q. Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> findings of ACL'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item866">[866]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14669" title="Abstract">arXiv:2305.14669</a> (replaced) [<a href="/pdf/2305.14669" title="Download PDF">pdf</a>, <a href="/format/2305.14669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NegVSR: Augmenting Negatives for Generalized Noise Modeling in  Real-World Video Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yexing Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Meilin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+X">Xiaoyu Xian</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhijing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yuming Fan</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yukai Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item867">[867]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15121" title="Abstract">arXiv:2305.15121</a> (replaced) [<a href="/pdf/2305.15121" title="Download PDF">pdf</a>, <a href="/format/2305.15121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Individual Input for Deep Anomaly Detection on Tabular Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thimonier%2C+H">Hugo Thimonier</a>, 
<a href="/search/cs?searchtype=author&query=Popineau%2C+F">Fabrice Popineau</a>, 
<a href="/search/cs?searchtype=author&query=Rimmel%2C+A">Arpad Rimmel</a>, 
<a href="/search/cs?searchtype=author&query=Doan%2C+B">Bich-Li&#xea;n Doan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item868">[868]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15364" title="Abstract">arXiv:2305.15364</a> (replaced) [<a href="/pdf/2305.15364" title="Download PDF">pdf</a>, <a href="/format/2305.15364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LQG Risk-Sensitive Single-Agent and Major-Minor Mean Field Game Systems:  A Variational Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Liu%2C+H">Hanchao Liu</a>, 
<a href="/search/math?searchtype=author&query=Firoozi%2C+D">Dena Firoozi</a>, 
<a href="/search/math?searchtype=author&query=Breton%2C+M">Mich&#xe8;le Breton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY); Probability (math.PR); Mathematical Finance (q-fin.MF); Risk Management (q-fin.RM)

</div>
</div>
</dd>
<dt><a name="item869">[869]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15914" title="Abstract">arXiv:2305.15914</a> (replaced) [<a href="/pdf/2305.15914" title="Download PDF">pdf</a>, <a href="/format/2305.15914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reliable Detection and Quantification of Selective Forces in Language  Change
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Montero%2C+J+G">Juan Guerrero Montero</a>, 
<a href="/search/cs?searchtype=author&query=Karjus%2C+A">Andres Karjus</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+K">Kenny Smith</a>, 
<a href="/search/cs?searchtype=author&query=Blythe%2C+R+A">Richard A. Blythe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item870">[870]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16487" title="Abstract">arXiv:2305.16487</a> (replaced) [<a href="/pdf/2305.16487" title="Download PDF">pdf</a>, <a href="/format/2305.16487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EgoHumans: An Egocentric 3D Multi-Human Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khirodkar%2C+R">Rawal Khirodkar</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+A">Aayush Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lingni Ma</a>, 
<a href="/search/cs?searchtype=author&query=Newcombe%2C+R">Richard Newcombe</a>, 
<a href="/search/cs?searchtype=author&query=Vo%2C+M">Minh Vo</a>, 
<a href="/search/cs?searchtype=author&query=Kitani%2C+K">Kris Kitani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item871">[871]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16637" title="Abstract">arXiv:2305.16637</a> (replaced) [<a href="/pdf/2305.16637" title="Download PDF">pdf</a>, <a href="/format/2305.16637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FARA: Future-aware Ranking Algorithm for Fairness Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhichao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhenduo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+Q">Qingyao Ai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, four figures, four tables. CIKM2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item872">[872]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16822" title="Abstract">arXiv:2305.16822</a> (replaced) [<a href="/pdf/2305.16822" title="Download PDF">pdf</a>, <a href="/format/2305.16822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Certification of Machine Learning-Based Distributed Systems  Behavior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anisetti%2C+M">Marco Anisetti</a>, 
<a href="/search/cs?searchtype=author&query=Ardagna%2C+C+A">Claudio A. Ardagna</a>, 
<a href="/search/cs?searchtype=author&query=Bena%2C+N">Nicola Bena</a>, 
<a href="/search/cs?searchtype=author&query=Damiani%2C+E">Ernesto Damiani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 figure, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item873">[873]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17934" title="Abstract">arXiv:2305.17934</a> (replaced) [<a href="/pdf/2305.17934" title="Download PDF">pdf</a>, <a href="/format/2305.17934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZeroPose: CAD-Model-based Zero-Shot Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianqiu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mingshan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+T">Tianpeng Bao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Liwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhenyu He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item874">[874]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18017" title="Abstract">arXiv:2305.18017</a> (replaced) [<a href="/pdf/2305.18017" title="Download PDF">pdf</a>, <a href="/ps/2305.18017" title="Download PostScript">ps</a>, <a href="/format/2305.18017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trace models of concurrent valuation algebras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Evangelou-Oost%2C+N">Naso Evangelou-Oost</a>, 
<a href="/search/cs?searchtype=author&query=Meinicke%2C+L">Larissa Meinicke</a>, 
<a href="/search/cs?searchtype=author&query=Bannister%2C+C">Callum Bannister</a>, 
<a href="/search/cs?searchtype=author&query=Hayes%2C+I+J">Ian J. Hayes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item875">[875]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19190" title="Abstract">arXiv:2305.19190</a> (replaced) [<a href="/pdf/2305.19190" title="Download PDF">pdf</a>, <a href="/format/2305.19190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inverse Approximation Theory for Nonlinear Recurrent Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shida Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qianxiao Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item876">[876]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00658" title="Abstract">arXiv:2306.00658</a> (replaced) [<a href="/pdf/2306.00658" title="Download PDF">pdf</a>, <a href="/format/2306.00658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuroGF: A Neural Representation for Fast Geodesic Distance and Path  Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qijian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Junhui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Adikusuma%2C+Y+Y">Yohanes Yudhi Adikusuma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Ying He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item877">[877]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00974" title="Abstract">arXiv:2306.00974</a> (replaced) [<a href="/pdf/2306.00974" title="Download PDF">pdf</a>, <a href="/format/2306.00974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intriguing Properties of Text-guided Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qihao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kortylewski%2C+A">Adam Kortylewski</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yutong Bai</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+S">Song Bai</a>, 
<a href="/search/cs?searchtype=author&query=Yuille%2C+A">Alan Yuille</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://sage-diffusion.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item878">[878]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01590" title="Abstract">arXiv:2306.01590</a> (replaced) [<a href="/pdf/2306.01590" title="Download PDF">pdf</a>, <a href="/format/2306.01590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Log Parsing: How Far Can ChatGPT Go?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+V">Van-Hoang Le</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongyu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by ASE 2023, NIER Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item879">[879]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01792" title="Abstract">arXiv:2306.01792</a> (replaced) [<a href="/pdf/2306.01792" title="Download PDF">pdf</a>, <a href="/format/2306.01792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task Relation-aware Continual User Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sein Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+N">Namkyeong Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Donghyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Minchul Yang</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+C">Chanyoung Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> KDD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item880">[880]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02427" title="Abstract">arXiv:2306.02427</a> (replaced) [<a href="/pdf/2306.02427" title="Download PDF">pdf</a>, <a href="/format/2306.02427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Efficient Controller Synthesis Techniques for Logical LTL Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Samuel%2C+S">Stanly Samuel</a>, 
<a href="/search/cs?searchtype=author&query=D%27Souza%2C+D">Deepak D&#x27;Souza</a>, 
<a href="/search/cs?searchtype=author&query=Komondoor%2C+R">Raghavan Komondoor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL); Symbolic Computation (cs.SC); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item881">[881]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03528" title="Abstract">arXiv:2306.03528</a> (replaced) [<a href="/pdf/2306.03528" title="Download PDF">pdf</a>, <a href="/format/2306.03528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Attacks and Defenses for Semantic Communication in Vehicular  Metaverses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiawen Kang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiayi He</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Hongyang Du</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zehui Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhaohui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xumin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shengli Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item882">[882]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03691" title="Abstract">arXiv:2306.03691</a> (replaced) [<a href="/pdf/2306.03691" title="Download PDF">pdf</a>, <a href="/format/2306.03691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Sensitive Networking (TSN) for Industrial Automation: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+C">Chuanyu Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiachen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Nixon%2C+M">Mark Nixon</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Song Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item883">[883]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05281" title="Abstract">arXiv:2306.05281</a> (replaced) [<a href="/pdf/2306.05281" title="Download PDF">pdf</a>, <a href="/format/2306.05281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Graph Reconstruction by Dynamic Signal Coefficient for Fault  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=He%2C+W">Wenbin He</a>, 
<a href="/search/eess?searchtype=author&query=Mao%2C+J">Jianxu Mao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yaonan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zhe Li</a>, 
<a href="/search/eess?searchtype=author&query=Fang%2C+Q">Qiu Fang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+H">Haotian Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item884">[884]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05710" title="Abstract">arXiv:2306.05710</a> (replaced) [<a href="/pdf/2306.05710" title="Download PDF">pdf</a>, <a href="/format/2306.05710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reachability in 3-VASS is in Tower
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qizhe Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yuxi Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item885">[885]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05807" title="Abstract">arXiv:2306.05807</a> (replaced) [<a href="/pdf/2306.05807" title="Download PDF">pdf</a>, <a href="/format/2306.05807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Gated Attention Transformer for Multi-Person Pose Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doering%2C+A">Andreas Doering</a>, 
<a href="/search/cs?searchtype=author&query=Gall%2C+J">Juergen Gall</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCVW23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item886">[886]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06236" title="Abstract">arXiv:2306.06236</a> (replaced) [<a href="/pdf/2306.06236" title="Download PDF">pdf</a>, <a href="/format/2306.06236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> iPLAN: Intent-Aware Planning in Heterogeneous Traffic via Distributed  Multi-Agent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chandra%2C+R">Rohan Chandra</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+T">Tianrui Guan</a>, 
<a href="/search/cs?searchtype=author&query=Bedi%2C+A+S">Amrit Singh Bedi</a>, 
<a href="/search/cs?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item887">[887]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07180" title="Abstract">arXiv:2306.07180</a> (replaced) [<a href="/pdf/2306.07180" title="Download PDF">pdf</a>, <a href="/format/2306.07180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Models for Black-Box Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krishnamoorthy%2C+S">Siddarth Krishnamoorthy</a>, 
<a href="/search/cs?searchtype=author&query=Mashkaria%2C+S+M">Satvik Mehul Mashkaria</a>, 
<a href="/search/cs?searchtype=author&query=Grover%2C+A">Aditya Grover</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Machine Learning 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item888">[888]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08107" title="Abstract">arXiv:2306.08107</a> (replaced) [<a href="/pdf/2306.08107" title="Download PDF">pdf</a>, <a href="/format/2306.08107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoML in the Age of Large Language Models: Current Challenges, Future  Opportunities and Risks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tornede%2C+A">Alexander Tornede</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+D">Difan Deng</a>, 
<a href="/search/cs?searchtype=author&query=Eimer%2C+T">Theresa Eimer</a>, 
<a href="/search/cs?searchtype=author&query=Giovanelli%2C+J">Joseph Giovanelli</a>, 
<a href="/search/cs?searchtype=author&query=Mohan%2C+A">Aditya Mohan</a>, 
<a href="/search/cs?searchtype=author&query=Ruhkopf%2C+T">Tim Ruhkopf</a>, 
<a href="/search/cs?searchtype=author&query=Segel%2C+S">Sarah Segel</a>, 
<a href="/search/cs?searchtype=author&query=Theodorakopoulos%2C+D">Daphne Theodorakopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Tornede%2C+T">Tanja Tornede</a>, 
<a href="/search/cs?searchtype=author&query=Wachsmuth%2C+H">Henning Wachsmuth</a>, 
<a href="/search/cs?searchtype=author&query=Lindauer%2C+M">Marius Lindauer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item889">[889]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08306" title="Abstract">arXiv:2306.08306</a> (replaced) [<a href="/pdf/2306.08306" title="Download PDF">pdf</a>, <a href="/format/2306.08306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Balanced Active Learning for Multimodal Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+M">Meng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yizheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jianxiong Yin</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+H">Heqing Zou</a>, 
<a href="/search/cs?searchtype=author&query=Rajan%2C+D">Deepu Rajan</a>, 
<a href="/search/cs?searchtype=author&query=See%2C+S">Simon See</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, accepted by ACMMM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item890">[890]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09629" title="Abstract">arXiv:2306.09629</a> (replaced) [<a href="/pdf/2306.09629" title="Download PDF">pdf</a>, <a href="/format/2306.09629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fusing Structural and Functional Connectivities using Disentangled VAE  for Detecting MCI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zuo%2C+Q">Qiankun Zuo</a>, 
<a href="/search/eess?searchtype=author&query=Zhu%2C+Y">Yanfei Zhu</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+L">Libin Lu</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Z">Zhi Yang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yuhui Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+N">Ning Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item891">[891]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10521" title="Abstract">arXiv:2306.10521</a> (replaced) [<a href="/pdf/2306.10521" title="Download PDF">pdf</a>, <a href="/format/2306.10521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LM-VC: Zero-shot Voice Conversion via Speech Generation based on  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zhichao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yuanzhe Chen</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+L">Lei Xie</a>, 
<a href="/search/eess?searchtype=author&query=Tian%2C+Q">Qiao Tian</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yuping Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item892">[892]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11510" title="Abstract">arXiv:2306.11510</a> (replaced) [<a href="/pdf/2306.11510" title="Download PDF">pdf</a>, <a href="/format/2306.11510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pushing the Limits of 3D Shape Generation at Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+X">Xuelin Qian</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+J">Jingyang Huo</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tiejun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yanwei Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://argus-3d.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item893">[893]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12235" title="Abstract">arXiv:2306.12235</a> (replaced) [<a href="/pdf/2306.12235" title="Download PDF">pdf</a>, <a href="/format/2306.12235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CompMix: A Benchmark for Heterogeneous Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Christmann%2C+P">Philipp Christmann</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+R+S">Rishiraj Saha Roy</a>, 
<a href="/search/cs?searchtype=author&query=Weikum%2C+G">Gerhard Weikum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item894">[894]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13592" title="Abstract">arXiv:2306.13592</a> (replaced) [<a href="/pdf/2306.13592" title="Download PDF">pdf</a>, <a href="/format/2306.13592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TACOformer:Token-channel compounded Cross Attention for Multimodal  Emotion Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinda Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IJCAI 2023- AI4TS workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item895">[895]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13812" title="Abstract">arXiv:2306.13812</a> (replaced) [<a href="/pdf/2306.13812" title="Download PDF">pdf</a>, <a href="/format/2306.13812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Loss of Plasticity in Deep Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dohare%2C+S">Shibhansh Dohare</a>, 
<a href="/search/cs?searchtype=author&query=Hernandez-Garcia%2C+J+F">J. Fernando Hernandez-Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+P">Parash Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Sutton%2C+R+S">Richard S. Sutton</a>, 
<a href="/search/cs?searchtype=author&query=Mahmood%2C+A+R">A. Rupam Mahmood</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item896">[896]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14161" title="Abstract">arXiv:2306.14161</a> (replaced) [<a href="/pdf/2306.14161" title="Download PDF">pdf</a>, <a href="/format/2306.14161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BiFF: Bi-level Future Fusion with Polyline-based Coordinate for  Interactive Trajectory Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yiyao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Luan%2C+D">Di Luan</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Shaojie Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item897">[897]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14834" title="Abstract">arXiv:2306.14834</a> (replaced) [<a href="/pdf/2306.14834" title="Download PDF">pdf</a>, <a href="/format/2306.14834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Neural Contextual Bandit for Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zheqing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Van+Roy%2C+B">Benjamin Van Roy</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM International Conference on Information and Knowledge
  Management (CIKM 2023) 32nd ACM International Conference on Information and
  Knowledge Management (CIKM 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item898">[898]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15319" title="Abstract">arXiv:2306.15319</a> (replaced) [<a href="/pdf/2306.15319" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nano1D: An accurate Computer Vision model for segmentation and analysis  of low-dimensional objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Moradpur-Tari%2C+E">Ehsan Moradpur-Tari</a> (1), 
<a href="/search/cond-mat?searchtype=author&query=Vlassov%2C+S">Sergei Vlassov</a> (1,2), 
<a href="/search/cond-mat?searchtype=author&query=Oras%2C+S">Sven Oras</a> (1,2), 
<a href="/search/cond-mat?searchtype=author&query=Ernits%2C+M">Mart Ernits</a> (1), 
<a href="/search/cond-mat?searchtype=author&query=Damerchi%2C+E">Elyad Damerchi</a> (1), 
<a href="/search/cond-mat?searchtype=author&query=Kyritsakis%2C+A">Andreas Kyritsakis</a> (1), 
<a href="/search/cond-mat?searchtype=author&query=Zadin%2C+V">Veronika Zadin</a> (1)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item899">[899]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15667" title="Abstract">arXiv:2306.15667</a> (replaced) [<a href="/pdf/2306.15667" title="Download PDF">pdf</a>, <a href="/format/2306.15667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PoseDiffusion: Solving Pose Estimation via Diffusion-aided Bundle  Adjustment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Rupprecht%2C+C">Christian Rupprecht</a>, 
<a href="/search/cs?searchtype=author&query=Novotny%2C+D">David Novotny</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV Camera Ready: revised Introduction and Related work, added a metric mAA (AUC), and added some quantitative results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item900">[900]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15706" title="Abstract">arXiv:2306.15706</a> (replaced) [<a href="/pdf/2306.15706" title="Download PDF">pdf</a>, <a href="/format/2306.15706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximated Prompt Tuning for Vision-Language Pre-trained Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qiong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shubin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yiyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+P">Pingyang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+A">Annan Shu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+G">Guannan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+R">Rongrong Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item901">[901]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16527" title="Abstract">arXiv:2306.16527</a> (replaced) [<a href="/pdf/2306.16527" title="Download PDF">pdf</a>, <a href="/format/2306.16527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OBELICS: An Open Web-Scale Filtered Dataset of Interleaved Image-Text  Documents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lauren%C3%A7on%2C+H">Hugo Lauren&#xe7;on</a>, 
<a href="/search/cs?searchtype=author&query=Saulnier%2C+L">Lucile Saulnier</a>, 
<a href="/search/cs?searchtype=author&query=Tronchon%2C+L">L&#xe9;o Tronchon</a>, 
<a href="/search/cs?searchtype=author&query=Bekman%2C+S">Stas Bekman</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Amanpreet Singh</a>, 
<a href="/search/cs?searchtype=author&query=Lozhkov%2C+A">Anton Lozhkov</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Thomas Wang</a>, 
<a href="/search/cs?searchtype=author&query=Karamcheti%2C+S">Siddharth Karamcheti</a>, 
<a href="/search/cs?searchtype=author&query=Rush%2C+A+M">Alexander M. Rush</a>, 
<a href="/search/cs?searchtype=author&query=Kiela%2C+D">Douwe Kiela</a>, 
<a href="/search/cs?searchtype=author&query=Cord%2C+M">Matthieu Cord</a>, 
<a href="/search/cs?searchtype=author&query=Sanh%2C+V">Victor Sanh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item902">[902]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16699" title="Abstract">arXiv:2306.16699</a> (replaced) [<a href="/pdf/2306.16699" title="Download PDF">pdf</a>, <a href="/format/2306.16699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rapid-INR: Storage Efficient CPU-free DNN Training Using Implicit Neural  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hanqiu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fitzmeyer%2C+S">Stephen Fitzmeyer</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+C">Cong Hao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCAD 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICCAD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item903">[903]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17095" title="Abstract">arXiv:2306.17095</a> (replaced) [<a href="/pdf/2306.17095" title="Download PDF">pdf</a>, <a href="/ps/2306.17095" title="Download PostScript">ps</a>, <a href="/format/2306.17095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decomposing cryptocurrency high-frequency price dynamics into recurring  and noisy components
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=W%C4%85torek%2C+M">Marcin W&#x105;torek</a>, 
<a href="/search/q-fin?searchtype=author&query=Skupie%C5%84%2C+M">Maria Skupie&#x144;</a>, 
<a href="/search/q-fin?searchtype=author&query=Kwapie%C5%84%2C+J">Jaros&#x142;aw Kwapie&#x144;</a>, 
<a href="/search/q-fin?searchtype=author&query=Dro%C5%BCd%C5%BC%2C+S">Stanis&#x142;aw Dro&#x17c;d&#x17c;</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Chaos 33, 083146 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Trading and Market Microstructure (q-fin.TR)</span>; Computational Engineering, Finance, and Science (cs.CE); Econometrics (econ.EM); Data Analysis, Statistics and Probability (physics.data-an); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item904">[904]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00562" title="Abstract">arXiv:2307.00562</a> (replaced) [<a href="/pdf/2307.00562" title="Download PDF">pdf</a>, <a href="/format/2307.00562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A MIL Approach for Anomaly Detection in Surveillance Videos from  Multiple Camera Views
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pereira%2C+S+S+L">Silas Santiago Lopes Pereira</a>, 
<a href="/search/cs?searchtype=author&query=Maia%2C+J+E+B">Jos&#xe9; Everardo Bessa Maia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 Pages, 4 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item905">[905]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00750" title="Abstract">arXiv:2307.00750</a> (replaced) [<a href="/pdf/2307.00750" title="Download PDF">pdf</a>, <a href="/format/2307.00750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feasibility of Universal Anomaly Detection without Knowing the  Abnormality in Medical Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+C">Can Cui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaohong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+S">Shunxing Bao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yucheng Tang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+R">Ruining Deng</a>, 
<a href="/search/cs?searchtype=author&query=Remedios%2C+L+W">Lucas W. Remedios</a>, 
<a href="/search/cs?searchtype=author&query=Asad%2C+Z">Zuhayr Asad</a>, 
<a href="/search/cs?searchtype=author&query=Roland%2C+J+T">Joseph T. Roland</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+K+S">Ken S. Lau</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Coburn%2C+L+A">Lori A. Coburn</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+K+T">Keith T. Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Landman%2C+B+A">Bennett A. Landman</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+Y">Yuankai Huo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item906">[906]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00811" title="Abstract">arXiv:2307.00811</a> (replaced) [<a href="/pdf/2307.00811" title="Download PDF">pdf</a>, <a href="/format/2307.00811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Review helps learn better: Temporal Supervised Knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dongwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhi Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanmei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Baichen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yandong Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review in AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item907">[907]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02347" title="Abstract">arXiv:2307.02347</a> (replaced) [<a href="/pdf/2307.02347" title="Download PDF">pdf</a>, <a href="/format/2307.02347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Images Generated by Deep Diffusion Models using their Local  Intrinsic Dimensionality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lorenz%2C+P">Peter Lorenz</a>, 
<a href="/search/cs?searchtype=author&query=Durall%2C+R">Ricard Durall</a>, 
<a href="/search/cs?searchtype=author&query=Keuper%2C+J">Janis Keuper</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV WS DFAD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item908">[908]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02632" title="Abstract">arXiv:2307.02632</a> (replaced) [<a href="/pdf/2307.02632" title="Download PDF">pdf</a>, <a href="/format/2307.02632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability of Q-Learning Through Design and Optimism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meyn%2C+S">Sean Meyn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Companion paper to the INFORMS APS inaugural Applied Probability Trust Plenary Lecture, presented in Nancy France, June 2023. Slides available online, Online, DOI 10.13140/RG.2.2.24897.33127
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item909">[909]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03104" title="Abstract">arXiv:2307.03104</a> (replaced) [<a href="/pdf/2307.03104" title="Download PDF">pdf</a>, <a href="/format/2307.03104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Domain Adaptation of Sentence Embeddings Using Adapters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schopf%2C+T">Tim Schopf</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+D+N">Dennis N. Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Matthes%2C+F">Florian Matthes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 14th International Conference on Recent Advances in Natural Language Processing (RANLP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item910">[910]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03206" title="Abstract">arXiv:2307.03206</a> (replaced) [<a href="/pdf/2307.03206" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Bandwidth Selection for DENCLUE Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item911">[911]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04345" title="Abstract">arXiv:2307.04345</a> (replaced) [<a href="/pdf/2307.04345" title="Download PDF">pdf</a>, <a href="/format/2307.04345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Learning as Computationally Constrained Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Saurabh Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Marklund%2C+H">Henrik Marklund</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+A">Ashish Rao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yifan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Jeon%2C+H+J">Hong Jun Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yueyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Van+Roy%2C+B">Benjamin Van Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item912">[912]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04937" title="Abstract">arXiv:2307.04937</a> (replaced) [<a href="/pdf/2307.04937" title="Download PDF">pdf</a>, <a href="/format/2307.04937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Fair Graph Neural Networks via Graph Counterfactual
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhimeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jialiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Teng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Suhang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item913">[913]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05182" title="Abstract">arXiv:2307.05182</a> (replaced) [<a href="/pdf/2307.05182" title="Download PDF">pdf</a>, <a href="/format/2307.05182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAT-ViL: Co-Attention Gated Vision-Language Embedding for Visual  Question Localized-Answering in Robotic Surgery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+L">Long Bai</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M">Mobarakol Islam</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Hongliang Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in MICCAI 2023. Code availability: <a href="https://github.com/longbai1006/CAT-ViL">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item914">[914]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05463" title="Abstract">arXiv:2307.05463</a> (replaced) [<a href="/pdf/2307.05463" title="Download PDF">pdf</a>, <a href="/format/2307.05463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EgoVLPv2: Egocentric Video-Language Pre-training with Fusion in the  Backbone
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pramanick%2C+S">Shraman Pramanick</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yale Song</a>, 
<a href="/search/cs?searchtype=author&query=Nag%2C+S">Sayan Nag</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K+Q">Kevin Qinghong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+H">Hardik Shah</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>, 
<a href="/search/cs?searchtype=author&query=Chellappa%2C+R">Rama Chellappa</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pengchuan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item915">[915]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05909" title="Abstract">arXiv:2307.05909</a> (replaced) [<a href="/pdf/2307.05909" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring AI Tool&#x27;s Versatile Responses: An In-depth Analysis Across  Different Industries and Its Performance Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohapatra%2C+H">Hitesh Mohapatra</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S+R">Soumya Ranjan Mishra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item916">[916]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07205" title="Abstract">arXiv:2307.07205</a> (replaced) [<a href="/pdf/2307.07205" title="Download PDF">pdf</a>, <a href="/format/2307.07205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Motion Conditioned Diffusion Model for Skeleton-based Video  Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Flaborea%2C+A">Alessandro Flaborea</a>, 
<a href="/search/cs?searchtype=author&query=Collorone%2C+L">Luca Collorone</a>, 
<a href="/search/cs?searchtype=author&query=D%27Amely%2C+G">Guido D&#x27;Amely</a>, 
<a href="/search/cs?searchtype=author&query=D%27Arrigo%2C+S">Stefano D&#x27;Arrigo</a>, 
<a href="/search/cs?searchtype=author&query=Prenkaj%2C+B">Bardh Prenkaj</a>, 
<a href="/search/cs?searchtype=author&query=Galasso%2C+F">Fabio Galasso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item917">[917]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07350" title="Abstract">arXiv:2307.07350</a> (replaced) [<a href="/pdf/2307.07350" title="Download PDF">pdf</a>, <a href="/ps/2307.07350" title="Download PostScript">ps</a>, <a href="/format/2307.07350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond the worst case: Distortion in impartial culture electorates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caragiannis%2C+I">Ioannis Caragiannis</a>, 
<a href="/search/cs?searchtype=author&query=Fehrs%2C+K">Karl Fehrs</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item918">[918]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07742" title="Abstract">arXiv:2307.07742</a> (replaced) [<a href="/pdf/2307.07742" title="Download PDF">pdf</a>, <a href="/format/2307.07742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SINC: Self-Supervised In-Context Learning for Vision-Language Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yi-Syuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yun-Zhu Song</a>, 
<a href="/search/cs?searchtype=author&query=Yeo%2C+C+Y">Cheng Yu Yeo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jianlong Fu</a>, 
<a href="/search/cs?searchtype=author&query=Shuai%2C+H">Hong-Han Shuai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023; Camera Ready Version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item919">[919]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07870" title="Abstract">arXiv:2307.07870</a> (replaced) [<a href="/pdf/2307.07870" title="Download PDF">pdf</a>, <a href="/format/2307.07870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models as Superpositions of Cultural Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kova%C4%8D%2C+G">Grgur Kova&#x10d;</a>, 
<a href="/search/cs?searchtype=author&query=Sawayama%2C+M">Masataka Sawayama</a>, 
<a href="/search/cs?searchtype=author&query=Portelas%2C+R">R&#xe9;my Portelas</a>, 
<a href="/search/cs?searchtype=author&query=Colas%2C+C">C&#xe9;dric Colas</a>, 
<a href="/search/cs?searchtype=author&query=Dominey%2C+P+F">Peter Ford Dominey</a>, 
<a href="/search/cs?searchtype=author&query=Oudeyer%2C+P">Pierre-Yves Oudeyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item920">[920]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07887" title="Abstract">arXiv:2307.07887</a> (replaced) [<a href="/pdf/2307.07887" title="Download PDF">pdf</a>, <a href="/format/2307.07887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Handwritten and Printed Text Segmentation: A Signature Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gholamian%2C+S">Sina Gholamian</a>, 
<a href="/search/cs?searchtype=author&query=Vahdat%2C+A">Ali Vahdat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in ICCV 2023. Updated version with 17 pages including main text and appendecies
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item921">[921]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08652" title="Abstract">arXiv:2307.08652</a> (replaced) [<a href="/pdf/2307.08652" title="Download PDF">pdf</a>, <a href="/format/2307.08652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Search Me Knot, Render Me Knot: Embedding Search and Differentiable  Rendering of Knots in 3D
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gangopadhyay%2C+A">Aalok Gangopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+P">Paras Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+T">Tarun Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+P">Prajwal Singh</a>, 
<a href="/search/cs?searchtype=author&query=Raman%2C+S">Shanmuganathan Raman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
</div>
</dd>
<dt><a name="item922">[922]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09702" title="Abstract">arXiv:2307.09702</a> (replaced) [<a href="/pdf/2307.09702" title="Download PDF">pdf</a>, <a href="/format/2307.09702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Guided Generation for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Willard%2C+B+T">Brandon T. Willard</a>, 
<a href="/search/cs?searchtype=author&query=Louf%2C+R">R&#xe9;mi Louf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item923">[923]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10253" title="Abstract">arXiv:2307.10253</a> (replaced) [<a href="/pdf/2307.10253" title="Download PDF">pdf</a>, <a href="/format/2307.10253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient selective attention LSTM for well log curve synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuankai Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huanyu Li</a>, 
<a href="/search/cs?searchtype=author&query=liu%2C+H">Hu liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item924">[924]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10577" title="Abstract">arXiv:2307.10577</a> (replaced) [<a href="/pdf/2307.10577" title="Download PDF">pdf</a>, <a href="/format/2307.10577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ethosight: A Reasoning-Guided Iterative Learning System for Nuanced  Perception based on Joint-Embedding &amp; Contextual Label Affinity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Latapie%2C+H">Hugo Latapie</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Hammer%2C+P">Patrick Hammer</a>, 
<a href="/search/cs?searchtype=author&query=Thorisson%2C+K+R">Kristinn R. Thorisson</a>, 
<a href="/search/cs?searchtype=author&query=Petrosyan%2C+V">Vahagn Petrosyan</a>, 
<a href="/search/cs?searchtype=author&query=Kynoch%2C+B">Brandon Kynoch</a>, 
<a href="/search/cs?searchtype=author&query=Khare%2C+A">Alind Khare</a>, 
<a href="/search/cs?searchtype=author&query=Behnam%2C+P">Payman Behnam</a>, 
<a href="/search/cs?searchtype=author&query=Tumanov%2C+A">Alexey Tumanov</a>, 
<a href="/search/cs?searchtype=author&query=Saxena%2C+A">Aksheit Saxena</a>, 
<a href="/search/cs?searchtype=author&query=Aralikatti%2C+A">Anish Aralikatti</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hanning Chen</a>, 
<a href="/search/cs?searchtype=author&query=Imani%2C+M">Mohsen Imani</a>, 
<a href="/search/cs?searchtype=author&query=Archbold%2C+M">Mike Archbold</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tangrui Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hart%2C+J">Justin Hart</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item925">[925]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10652" title="Abstract">arXiv:2307.10652</a> (replaced) [<a href="/pdf/2307.10652" title="Download PDF">pdf</a>, <a href="/format/2307.10652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Landscape of Natural Language Processing Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schopf%2C+T">Tim Schopf</a>, 
<a href="/search/cs?searchtype=author&query=Arabi%2C+K">Karim Arabi</a>, 
<a href="/search/cs?searchtype=author&query=Matthes%2C+F">Florian Matthes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 14th International Conference on Recent Advances in Natural Language Processing (RANLP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item926">[926]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10816" title="Abstract">arXiv:2307.10816</a> (replaced) [<a href="/pdf/2307.10816" title="Download PDF">pdf</a>, <a href="/format/2307.10816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BoxDiff: Text-to-Image Synthesis with Training-Free Box-Constrained  Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jinheng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuexiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yawen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haozhe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wentian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yefeng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023. Code is available at: <a href="https://github.com/showlab/BoxDiff">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item927">[927]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11629" title="Abstract">arXiv:2307.11629</a> (replaced) [<a href="/pdf/2307.11629" title="Download PDF">pdf</a>, <a href="/format/2307.11629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Multi-agent Covering Option Discovery based on Kronecker Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiayu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingdi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+T">Tian Lan</a>, 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+V">Vaneet Aggarwal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2022. arXiv admin note: substantial text overlap with <a href="/abs/2201.08227">arXiv:2201.08227</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item928">[928]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11897" title="Abstract">arXiv:2307.11897</a> (replaced) [<a href="/pdf/2307.11897" title="Download PDF">pdf</a>, <a href="/format/2307.11897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hindsight-DICE: Stable Credit Assignment for Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Velu%2C+A">Akash Velu</a>, 
<a href="/search/cs?searchtype=author&query=Vaidyanath%2C+S">Skanda Vaidyanath</a>, 
<a href="/search/cs?searchtype=author&query=Arumugam%2C+D">Dilip Arumugam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item929">[929]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12463" title="Abstract">arXiv:2307.12463</a> (replaced) [<a href="/pdf/2307.12463" title="Download PDF">pdf</a>, <a href="/format/2307.12463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Data Distillation: Do Not Overlook Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Dongyao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+B">Bowen Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yanbo Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yiqun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dongkuan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item930">[930]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12510" title="Abstract">arXiv:2307.12510</a> (replaced) [<a href="/pdf/2307.12510" title="Download PDF">pdf</a>, <a href="/ps/2307.12510" title="Download PostScript">ps</a>, <a href="/format/2307.12510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Evaluation of Temporal Graph Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Le Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint, in progress, add more results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item931">[931]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12950" title="Abstract">arXiv:2307.12950</a> (replaced) [<a href="/pdf/2307.12950" title="Download PDF">pdf</a>, <a href="/format/2307.12950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RLCD: Reinforcement Learning from Contrast Distillation for Language  Model Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kevin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+D">Dan Klein</a>, 
<a href="/search/cs?searchtype=author&query=Celikyilmaz%2C+A">Asli Celikyilmaz</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+N">Nanyun Peng</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yuandong Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item932">[932]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13552" title="Abstract">arXiv:2307.13552</a> (replaced) [<a href="/pdf/2307.13552" title="Download PDF">pdf</a>, <a href="/format/2307.13552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Solving the Rubik&#x27;s Cube with Domain-Independent Planners Using  Standard Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muppasani%2C+B">Bharath Muppasani</a>, 
<a href="/search/cs?searchtype=author&query=Pallagani%2C+V">Vishal Pallagani</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+B">Biplav Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Agostinelli%2C+F">Forest Agostinelli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item933">[933]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13755" title="Abstract">arXiv:2307.13755</a> (replaced) [<a href="/pdf/2307.13755" title="Download PDF">pdf</a>, <a href="/format/2307.13755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training-based Model Refinement and Representation Disagreement for  Semi-Supervised Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marvasti-Zadeh%2C+S+M">Seyed Mojtaba Marvasti-Zadeh</a>, 
<a href="/search/cs?searchtype=author&query=Ray%2C+N">Nilanjan Ray</a>, 
<a href="/search/cs?searchtype=author&query=Erbilgin%2C+N">Nadir Erbilgin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item934">[934]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13901" title="Abstract">arXiv:2307.13901</a> (replaced) [<a href="/pdf/2307.13901" title="Download PDF">pdf</a>, <a href="/format/2307.13901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> YOLOBench: Benchmarking Efficient Object Detectors on Embedded Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lazarevich%2C+I">Ivan Lazarevich</a>, 
<a href="/search/cs?searchtype=author&query=Grimaldi%2C+M">Matteo Grimaldi</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+R">Ravish Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+S">Saptarshi Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Shahrukh Khan</a>, 
<a href="/search/cs?searchtype=author&query=Sah%2C+S">Sudhakar Sah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item935">[935]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14480" title="Abstract">arXiv:2307.14480</a> (replaced) [<a href="/pdf/2307.14480" title="Download PDF">pdf</a>, <a href="/format/2307.14480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PSOFuzz: Fuzzing Processors with Particle Swarm Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gohil%2C+V">Vasudev Gohil</a>, 
<a href="/search/cs?searchtype=author&query=Kande%2C+R">Rahul Kande</a>, 
<a href="/search/cs?searchtype=author&query=Sadeghi%2C+A">Ahmad-Reza Sadeghi</a>, 
<a href="/search/cs?searchtype=author&query=Rajendran%2C+J">Jeyavijayan Rajendran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the proceedings of the ICCAD, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item936">[936]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14751" title="Abstract">arXiv:2307.14751</a> (replaced) [<a href="/pdf/2307.14751" title="Download PDF">pdf</a>, <a href="/format/2307.14751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FLARE: Fingerprinting Deep Reinforcement Learning Agents using Universal  Adversarial Masks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tekgul%2C+B+G+A">Buse G. A. Tekgul</a>, 
<a href="/search/cs?searchtype=author&query=Asokan%2C+N">N. Asokan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Will appear in the proceedings of ACSAC 2023; 13 pages, 5 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item937">[937]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14770" title="Abstract">arXiv:2307.14770</a> (replaced) [<a href="/pdf/2307.14770" title="Download PDF">pdf</a>, <a href="/format/2307.14770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3DPortraitGAN: Learning One-Quarter Headshot 3D GANs from a Single-View  Portrait Dataset with Diverse Body Poses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yiqian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiangjun Tang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Hongbo Fu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xiaogang Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item938">[938]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16075" title="Abstract">arXiv:2307.16075</a> (replaced) [<a href="/pdf/2307.16075" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Redesigning Large-Scale Multimodal Transit Networks with Shared  Autonomous Mobility Services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ng%2C+M+T+M">Max T.M. Ng</a>, 
<a href="/search/eess?searchtype=author&query=Mahmassani%2C+H+S">Hani S. Mahmassani</a>, 
<a href="/search/eess?searchtype=author&query=Verbas%2C+%C3%96">&#xd6;mer Verbas</a>, 
<a href="/search/eess?searchtype=author&query=Cokyasar%2C+T">Taner Cokyasar</a>, 
<a href="/search/eess?searchtype=author&query=Engelhardt%2C+R">Roman Engelhardt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 15 figures, under review for the 25th International Symposium on Transportation and Traffic Theory (ISTTT25)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item939">[939]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16177" title="Abstract">arXiv:2307.16177</a> (replaced) [<a href="/pdf/2307.16177" title="Download PDF">pdf</a>, <a href="/format/2307.16177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fusing VHR Post-disaster Aerial Imagery and LiDAR Data for Roof  Classification in the Caribbean
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tingzon%2C+I">Isabelle Tingzon</a>, 
<a href="/search/cs?searchtype=author&query=Cowan%2C+N+M">Nuala Margaret Cowan</a>, 
<a href="/search/cs?searchtype=author&query=Chrzanowski%2C+P">Pierre Chrzanowski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 Workshop on Artificial Intelligence for Humanitarian Assistance and Disaster Response
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item940">[940]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16572" title="Abstract">arXiv:2307.16572</a> (replaced) [<a href="/pdf/2307.16572" title="Download PDF">pdf</a>, <a href="/format/2307.16572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transferable Attack for Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+M">Mengqi He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhaoyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+M">Mingyi He</a>, 
<a href="/search/cs?searchtype=author&query=Barnes%2C+N">Nick Barnes</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yuchao Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Source code is available at: <a href="https://github.com/anucvers/TASS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item941">[941]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16670" title="Abstract">arXiv:2307.16670</a> (replaced) [<a href="/pdf/2307.16670" title="Download PDF">pdf</a>, <a href="/format/2307.16670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditioning Generative Latent Optimization to solve Imaging Inverse  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Braure%2C+T">Thomas Braure</a>, 
<a href="/search/cs?searchtype=author&query=Ginsburger%2C+K">K&#xe9;vin Ginsburger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> comments: 20 pages, 9 figures; typos corrected
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item942">[942]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16811" title="Abstract">arXiv:2307.16811</a> (replaced) [<a href="/pdf/2307.16811" title="Download PDF">pdf</a>, <a href="/format/2307.16811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DoDo Learning: DOmain-DemOgraphic Transfer in Language Models for  Detecting Abuse Targeted at Public Figures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kirk%2C+H+R">Hannah Rose Kirk</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+A+R">Angus R. Williams</a>, 
<a href="/search/cs?searchtype=author&query=Burke%2C+L">Liam Burke</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+Y">Yi-Ling Chung</a>, 
<a href="/search/cs?searchtype=author&query=Debono%2C+I">Ivan Debono</a>, 
<a href="/search/cs?searchtype=author&query=Johansson%2C+P">Pica Johansson</a>, 
<a href="/search/cs?searchtype=author&query=Stevens%2C+F">Francesca Stevens</a>, 
<a href="/search/cs?searchtype=author&query=Bright%2C+J">Jonathan Bright</a>, 
<a href="/search/cs?searchtype=author&query=Hale%2C+S+A">Scott A. Hale</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item943">[943]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00158" title="Abstract">arXiv:2308.00158</a> (replaced) [<a href="/pdf/2308.00158" title="Download PDF">pdf</a>, <a href="/format/2308.00158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Perfect Quality Segments in MT Output with Fine-Tuned OpenAI  LLM: Is it possible to capture editing distance patterns from historical  data?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gladkoff%2C+S">Serge Gladkoff</a>, 
<a href="/search/cs?searchtype=author&query=Erofeev%2C+G">Gleb Erofeev</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Lifeng Han</a>, 
<a href="/search/cs?searchtype=author&query=Nenadic%2C+G">Goran Nenadic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 11 figures, under-review to ItalianNLP-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item944">[944]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00946" title="Abstract">arXiv:2308.00946</a> (replaced) [<a href="/pdf/2308.00946" title="Download PDF">pdf</a>, <a href="/format/2308.00946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Teaching Smaller Language Models To Generalise To Unseen Compositional  Questions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hartill%2C+T">Tim Hartill</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+N">Neset Tan</a>, 
<a href="/search/cs?searchtype=author&query=Witbrock%2C+M">Michael Witbrock</a>, 
<a href="/search/cs?searchtype=author&query=Riddle%2C+P+J">Patricia J. Riddle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item945">[945]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01269" title="Abstract">arXiv:2308.01269</a> (replaced) [<a href="/pdf/2308.01269" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VAPI: Vectorization of Algorithm for Performance Improvement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yashar%2C+M">Mahmood Yashar</a>, 
<a href="/search/cs?searchtype=author&query=Rashid%2C+T+A">Tarik A. Rashid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item946">[946]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02180" title="Abstract">arXiv:2308.02180</a> (replaced) [<a href="/pdf/2308.02180" title="Download PDF">pdf</a>, <a href="/format/2308.02180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Clinical Trial Matching Using Large Language Models: A Case  Study in Oncology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wong%2C+C">Cliff Wong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yu Gu</a>, 
<a href="/search/cs?searchtype=author&query=Moung%2C+C">Christine Moung</a>, 
<a href="/search/cs?searchtype=author&query=Abel%2C+J">Jacob Abel</a>, 
<a href="/search/cs?searchtype=author&query=Usuyama%2C+N">Naoto Usuyama</a>, 
<a href="/search/cs?searchtype=author&query=Weerasinghe%2C+R">Roshanthi Weerasinghe</a>, 
<a href="/search/cs?searchtype=author&query=Piening%2C+B">Brian Piening</a>, 
<a href="/search/cs?searchtype=author&query=Naumann%2C+T">Tristan Naumann</a>, 
<a href="/search/cs?searchtype=author&query=Bifulco%2C+C">Carlo Bifulco</a>, 
<a href="/search/cs?searchtype=author&query=Poon%2C+H">Hoifung Poon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 5 figures, accepted at Machine Learning for Healthcare (MLHC) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item947">[947]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02442" title="Abstract">arXiv:2308.02442</a> (replaced) [<a href="/pdf/2308.02442" title="Download PDF">pdf</a>, <a href="/format/2308.02442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Preferential Attached kNN Graph with Distribution-Awareness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Min%2C+S">Shaojie Min</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Ji Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item948">[948]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02751" title="Abstract">arXiv:2308.02751</a> (replaced) [<a href="/pdf/2308.02751" title="Download PDF">pdf</a>, <a href="/format/2308.02751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeRFs: The Search for the Best 3D Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramamoorthi%2C+R">Ravi Ramamoorthi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated based on feedback in-person and via e-mail at SIGGRAPH 2023. In particular, I have added references and discussion of seminal SIGGRAPH image-based rendering papers, and better put the recent Kerbl et al. work in context, with more references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item949">[949]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02774" title="Abstract">arXiv:2308.02774</a> (replaced) [<a href="/pdf/2308.02774" title="Download PDF">pdf</a>, <a href="/format/2308.02774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Distillation Network with Ensemble Prototypes: Learning Robust  Speaker Representations without Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yafeng Chen</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+S">Siqi Zheng</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Q">Qian Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2211.04168">arXiv:2211.04168</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item950">[950]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02787" title="Abstract">arXiv:2308.02787</a> (replaced) [<a href="/pdf/2308.02787" title="Download PDF">pdf</a>, <a href="/format/2308.02787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Logistic-Oriented Bin Packing Problems Through a Hybrid  Quantum-Classical Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Romero%2C+S+V">Sebasti&#xe1;n V. Romero</a>, 
<a href="/search/cs?searchtype=author&query=Osaba%2C+E">Eneko Osaba</a>, 
<a href="/search/cs?searchtype=author&query=Villar-Rodriguez%2C+E">Esther Villar-Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Asla%2C+A">Ant&#xf3;n Asla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures, paper accepted for being presented in the upcoming 26th IEEE International Conference on Intelligent Transportation Systems - ITSC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item951">[951]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02921" title="Abstract">arXiv:2308.02921</a> (replaced) [<a href="/pdf/2308.02921" title="Download PDF">pdf</a>, <a href="/format/2308.02921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PowerSimulationsDynamics.jl -- An Open Source Modeling Package for  Modern Power Systems with Inverter-Based Resources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lara%2C+J+D">Jose Daniel Lara</a>, 
<a href="/search/eess?searchtype=author&query=Henriquez-Auba%2C+R">Rodrigo Henriquez-Auba</a>, 
<a href="/search/eess?searchtype=author&query=Bossart%2C+M">Matthew Bossart</a>, 
<a href="/search/eess?searchtype=author&query=Callaway%2C+D+S">Duncan S. Callaway</a>, 
<a href="/search/eess?searchtype=author&query=Barrows%2C+C">Clayton Barrows</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item952">[952]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02946" title="Abstract">arXiv:2308.02946</a> (replaced) [<a href="/pdf/2308.02946" title="Download PDF">pdf</a>, <a href="/ps/2308.02946" title="Download PostScript">ps</a>, <a href="/format/2308.02946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the expected efficiency of branch and bound for the asymmetric TSP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frieze%2C+A">Alan Frieze</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item953">[953]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02955" title="Abstract">arXiv:2308.02955</a> (replaced) [<a href="/pdf/2308.02955" title="Download PDF">pdf</a>, <a href="/format/2308.02955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Study of AI-based Smart Contract Creation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karanjai%2C+R">Rabimba Karanjai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+E">Edward Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Weidong Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated to address issues
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item954">[954]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03202" title="Abstract">arXiv:2308.03202</a> (replaced) [<a href="/pdf/2308.03202" title="Download PDF">pdf</a>, <a href="/format/2308.03202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Source-free Domain Adaptive Human Pose Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+Q">Qucheng Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Ce Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item955">[955]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03236" title="Abstract">arXiv:2308.03236</a> (replaced) [<a href="/pdf/2308.03236" title="Download PDF">pdf</a>, <a href="/format/2308.03236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> G-Mix: A Generalized Mixup Learning Framework Towards Flat Minima
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+B">Bo Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 23 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item956">[956]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03253" title="Abstract">arXiv:2308.03253</a> (replaced) [<a href="/pdf/2308.03253" title="Download PDF">pdf</a>, <a href="/format/2308.03253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PaniniQA: Enhancing Patient Education Through Interactive Question  Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+P">Pengshan Cai</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zonghai Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dakuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Reilly%2C+M">Meghan Reilly</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Huixue Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lingxi Li</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Kapoor%2C+A">Alok Kapoor</a>, 
<a href="/search/cs?searchtype=author&query=Bajracharya%2C+A">Adarsha Bajracharya</a>, 
<a href="/search/cs?searchtype=author&query=Berlowitz%2C+D">Dan Berlowitz</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to TACL 2023. Equal contribution for the first two authors. This arXiv version is a pre-MIT Press publication version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item957">[957]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03272" title="Abstract">arXiv:2308.03272</a> (replaced) [<a href="/pdf/2308.03272" title="Download PDF">pdf</a>, <a href="/format/2308.03272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature-Suppressed Contrast for Self-Supervised Food Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinda Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yaohui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Linhu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jiang Tian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lili Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM MM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item958">[958]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03282" title="Abstract">arXiv:2308.03282</a> (replaced) [<a href="/pdf/2308.03282" title="Download PDF">pdf</a>, <a href="/format/2308.03282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Environment-Invariant Curriculum Relation Learning for Fine-Grained  Scene Graph Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Min%2C+Y">Yukuan Min</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+A">Aming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+C">Cheng Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV2023. arXiv admin note: text overlap with <a href="/abs/2203.11654">arXiv:2203.11654</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item959">[959]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03598" title="Abstract">arXiv:2308.03598</a> (replaced) [<a href="/pdf/2308.03598" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why We Don&#x27;t Have AGI Yet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Voss%2C+P">Peter Voss</a>, 
<a href="/search/cs?searchtype=author&query=Jovanovic%2C+M">Mladjan Jovanovic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item960">[960]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03810" title="Abstract">arXiv:2308.03810</a> (replaced) [<a href="/pdf/2308.03810" title="Download PDF">pdf</a>, <a href="/format/2308.03810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaER: An Adaptive Experience Replay Approach for Continual Lifelong  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+B">Bo Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haifeng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 26 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item961">[961]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04439" title="Abstract">arXiv:2308.04439</a> (replaced) [<a href="/pdf/2308.04439" title="Download PDF">pdf</a>, <a href="/ps/2308.04439" title="Download PostScript">ps</a>, <a href="/format/2308.04439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Global Differential Privacy for Distributed Metaverse Healthcare Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Letafati%2C+M">Mehdi Letafati</a>, 
<a href="/search/cs?searchtype=author&query=Otoum%2C+S">Safa Otoum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item962">[962]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04566" title="Abstract">arXiv:2308.04566</a> (replaced) [<a href="/e-print/2308.04566" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-Sentence Reader: A Novel Approach for Addressing Answer Position  Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+S+Q">Son Quoc Tran</a>, 
<a href="/search/cs?searchtype=author&query=Kretchmar%2C+M">Matt Kretchmar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We need to revise our paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item963">[963]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04583" title="Abstract">arXiv:2308.04583</a> (replaced) [<a href="/pdf/2308.04583" title="Download PDF">pdf</a>, <a href="/format/2308.04583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LATR: 3D Lane Detection from Monocular Images with Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yueru Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chaoda Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Kun%2C+T">Tang Kun</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Chao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shuguang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhen Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item964">[964]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04589" title="Abstract">arXiv:2308.04589</a> (replaced) [<a href="/pdf/2308.04589" title="Download PDF">pdf</a>, <a href="/format/2308.04589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal DINO: A Self-supervised Video Strategy to Enhance Action  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teeti%2C+I">Izzeddin Teeti</a>, 
<a href="/search/cs?searchtype=author&query=Bhargav%2C+R+S">Rongali Sai Bhargav</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+V">Vivek Singh</a>, 
<a href="/search/cs?searchtype=author&query=Bradley%2C+A">Andrew Bradley</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+B">Biplab Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Cuzzolin%2C+F">Fabio Cuzzolin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item965">[965]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04629" title="Abstract">arXiv:2308.04629</a> (replaced) [<a href="/pdf/2308.04629" title="Download PDF">pdf</a>, <a href="/format/2308.04629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instabilities of explicit finite difference schemes with ghost points on  the diffusion equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Floc%27h%2C+F+L">Fabien Le Floc&#x27;h</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Finance (q-fin.CP); Mathematical Finance (q-fin.MF); Pricing of Securities (q-fin.PR)

</div>
</div>
</dd>
<dt><a name="item966">[966]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04912" title="Abstract">arXiv:2308.04912</a> (replaced) [<a href="/pdf/2308.04912" title="Download PDF">pdf</a>, <a href="/format/2308.04912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-view Semantic Alignment for Livestreaming Product Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenjie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yan Li</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yanhua Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xudong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Quan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Han Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item967">[967]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04952" title="Abstract">arXiv:2308.04952</a> (replaced) [<a href="/pdf/2308.04952" title="Download PDF">pdf</a>, <a href="/format/2308.04952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prototypical Kernel Learning and Open-set Foreground Perception for  Generalized Few-shot Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Feigege Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+Y">Ye Xi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yutao Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item968">[968]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05637" title="Abstract">arXiv:2308.05637</a> (replaced) [<a href="/pdf/2308.05637" title="Download PDF">pdf</a>, <a href="/format/2308.05637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Fast and the Private: Task-based Dataset Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zezhou Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaxiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haonan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+E">Eugene Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item969">[969]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05784" title="Abstract">arXiv:2308.05784</a> (replaced) [<a href="/pdf/2308.05784" title="Download PDF">pdf</a>, <a href="/format/2308.05784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-performance Data Management for Whole Slide Image Analysis in  Digital Pathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Leng%2C+H">Haoju Leng</a>, 
<a href="/search/eess?searchtype=author&query=Deng%2C+R">Ruining Deng</a>, 
<a href="/search/eess?searchtype=author&query=Bao%2C+S">Shunxing Bao</a>, 
<a href="/search/eess?searchtype=author&query=Fang%2C+D">Dazheng Fang</a>, 
<a href="/search/eess?searchtype=author&query=Millis%2C+B+A">Bryan A. Millis</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+Y">Yucheng Tang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+H">Haichun Yang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Peng%2C+Y">Yifan Peng</a>, 
<a href="/search/eess?searchtype=author&query=Wan%2C+L">Lipeng Wan</a>, 
<a href="/search/eess?searchtype=author&query=Huo%2C+Y">Yuankai Huo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item970">[970]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06058" title="Abstract">arXiv:2308.06058</a> (replaced) [<a href="/pdf/2308.06058" title="Download PDF">pdf</a>, <a href="/format/2308.06058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive SGD with Polyak stepsize and Line-search: Robust Convergence  and Variance Reduction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiaowen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Stich%2C+S+U">Sebastian U. Stich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item971">[971]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06201" title="Abstract">arXiv:2308.06201</a> (replaced) [<a href="/pdf/2308.06201" title="Download PDF">pdf</a>, <a href="/format/2308.06201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SALSy: Security-Aware Layout Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eslami%2C+M">Mohammad Eslami</a>, 
<a href="/search/cs?searchtype=author&query=Perez%2C+T">Tiago Perez</a>, 
<a href="/search/cs?searchtype=author&query=Pagliarini%2C+S">Samuel Pagliarini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item972">[972]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06296" title="Abstract">arXiv:2308.06296</a> (replaced) [<a href="/pdf/2308.06296" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification of White Blood Cells Using Machine and Deep Learning  Models: A Systematic Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Asghar%2C+R">Rabia Asghar</a>, 
<a href="/search/eess?searchtype=author&query=Kumar%2C+S">Sanjay Kumar</a>, 
<a href="/search/eess?searchtype=author&query=Hynds%2C+P">Paul Hynds</a>, 
<a href="/search/eess?searchtype=author&query=Shaukat%2C+A">Arslan Shaukat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item973">[973]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06300" title="Abstract">arXiv:2308.06300</a> (replaced) [<a href="/pdf/2308.06300" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Classification of Blood Cell Images Using Convolutional Neural  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Asghar%2C+R">Rabia Asghar</a>, 
<a href="/search/eess?searchtype=author&query=Kumar%2C+S">Sanjay Kumar</a>, 
<a href="/search/eess?searchtype=author&query=Hynds%2C+P">Paul Hynds</a>, 
<a href="/search/eess?searchtype=author&query=Mahfooz%2C+A">Abeera Mahfooz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item974">[974]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06394" title="Abstract">arXiv:2308.06394</a> (replaced) [<a href="/pdf/2308.06394" title="Download PDF">pdf</a>, <a href="/format/2308.06394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting and Preventing Hallucinations in Large Vision Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gunjal%2C+A">Anisha Gunjal</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jihan Yin</a>, 
<a href="/search/cs?searchtype=author&query=Bas%2C+E">Erhan Bas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item975">[975]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06954" title="Abstract">arXiv:2308.06954</a> (replaced) [<a href="/pdf/2308.06954" title="Download PDF">pdf</a>, <a href="/format/2308.06954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Global Features are All You Need for Image Retrieval and Reranking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+S">Shihao Shao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kaifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Karpur%2C+A">Arjun Karpur</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Q">Qinghua Cui</a>, 
<a href="/search/cs?searchtype=author&query=Araujo%2C+A">Andre Araujo</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+B">Bingyi Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV23 camera-ready + appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item976">[976]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07056" title="Abstract">arXiv:2308.07056</a> (replaced) [<a href="/pdf/2308.07056" title="Download PDF">pdf</a>, <a href="/format/2308.07056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VoxBlink: X-Large Speaker Verification Dataset on Camera
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lin%2C+Y">Yuke Lin</a>, 
<a href="/search/eess?searchtype=author&query=Qin%2C+X">Xiaoyi Qin</a>, 
<a href="/search/eess?searchtype=author&query=Cheng%2C+M">Ming Cheng</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+N">Ning Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+G">Guoqing Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+M">Ming Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submit to ICASSP2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Multimedia (cs.MM); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item977">[977]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07134" title="Abstract">arXiv:2308.07134</a> (replaced) [<a href="/pdf/2308.07134" title="Download PDF">pdf</a>, <a href="/format/2308.07134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Natural Language is All a Graph Needs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+R">Ruosong Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Caiqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Runhui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shuyuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongfeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 2 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item978">[978]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07221" title="Abstract">arXiv:2308.07221</a> (replaced) [<a href="/pdf/2308.07221" title="Download PDF">pdf</a>, <a href="/format/2308.07221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AudioFormer: Audio Transformer learns audio feature representations from  discrete acoustic codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhaohui Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haitao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xinghua Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item979">[979]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07241" title="Abstract">arXiv:2308.07241</a> (replaced) [<a href="/pdf/2308.07241" title="Download PDF">pdf</a>, <a href="/format/2308.07241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-Aware Planning and Environment-Aware Memory for Instruction  Following Embodied Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Byeonghwi Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jinyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yuyeong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+C">Cheolhong Min</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jonghyun Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item980">[980]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07575" title="Abstract">arXiv:2308.07575</a> (replaced) [<a href="/pdf/2308.07575" title="Download PDF">pdf</a>, <a href="/format/2308.07575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Story Visualization by Online Text Augmentation with Context Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahn%2C+D">Daechul Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Daneul Kim</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+G">Gwangmo Song</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S+H">Seung Hwan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Honglak Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+D">Dongyeop Kang</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jonghyun Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023, Project page: <a href="https://dcahn12.github.io/projects/CMOTA/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item981">[981]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07615" title="Abstract">arXiv:2308.07615</a> (replaced) [<a href="/pdf/2308.07615" title="Download PDF">pdf</a>, <a href="/format/2308.07615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Hypergraphs for Learning Multiple World Interpretations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marcu%2C+A">Alina Marcu</a>, 
<a href="/search/cs?searchtype=author&query=Pirvu%2C+M">Mihai Pirvu</a>, 
<a href="/search/cs?searchtype=author&query=Costea%2C+D">Dragos Costea</a>, 
<a href="/search/cs?searchtype=author&query=Haller%2C+E">Emanuela Haller</a>, 
<a href="/search/cs?searchtype=author&query=Slusanschi%2C+E">Emil Slusanschi</a>, 
<a href="/search/cs?searchtype=author&query=Belbachir%2C+A+N">Ahmed Nabil Belbachir</a>, 
<a href="/search/cs?searchtype=author&query=Sukthankar%2C+R">Rahul Sukthankar</a>, 
<a href="/search/cs?searchtype=author&query=Leordeanu%2C+M">Marius Leordeanu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICCV 2023 Workshops
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item982">[982]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08114" title="Abstract">arXiv:2308.08114</a> (replaced) [<a href="/pdf/2308.08114" title="Download PDF">pdf</a>, <a href="/format/2308.08114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OmniZoomer: Learning to Move and Zoom in on Sphere at High-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zidong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+H">Hao Ai</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yan-Pei Cao</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Qie%2C+X">Xiaohu Qie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item983">[983]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08197" title="Abstract">arXiv:2308.08197</a> (replaced) [<a href="/pdf/2308.08197" title="Download PDF">pdf</a>, <a href="/format/2308.08197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Reference Deep Adaptive Curve Estimation for Low-Light Image  Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wen%2C+J">Jianyu Wen</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+C">Chenhao Wu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+Y">Yixuan Yu</a>, 
<a href="/search/eess?searchtype=author&query=Swierczynski%2C+P">Piotr Swierczynski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item984">[984]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08242" title="Abstract">arXiv:2308.08242</a> (replaced) [<a href="/pdf/2308.08242" title="Download PDF">pdf</a>, <a href="/format/2308.08242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Learning for Lane Detection via Cross-Similarity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zoljodi%2C+A">Ali Zoljodi</a>, 
<a href="/search/cs?searchtype=author&query=Abadijou%2C+S">Sadegh Abadijou</a>, 
<a href="/search/cs?searchtype=author&query=Alibeigi%2C+M">Mina Alibeigi</a>, 
<a href="/search/cs?searchtype=author&query=Daneshtalab%2C+M">Masoud Daneshtalab</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item985">[985]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08345" title="Abstract">arXiv:2308.08345</a> (replaced) [<a href="/pdf/2308.08345" title="Download PDF">pdf</a>, <a href="/format/2308.08345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GAEI-UNet: Global Attention and Elastic Interaction U-Net for Vessel  Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xiao%2C+R">Ruiqiang Xiao</a>, 
<a href="/search/eess?searchtype=author&query=Wan%2C+Z">Zhuoyue Wan</a>, 
<a href="/search/eess?searchtype=author&query=Xiang%2C+Y">Yang Xiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item986">[986]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08451" title="Abstract">arXiv:2308.08451</a> (replaced) [<a href="/pdf/2308.08451" title="Download PDF">pdf</a>, <a href="/format/2308.08451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AIGC In China: Current Developments And Future Outlook
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yuqing Fan</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Shenghui Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item987">[987]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08463" title="Abstract">arXiv:2308.08463</a> (replaced) [<a href="/pdf/2308.08463" title="Download PDF">pdf</a>, <a href="/format/2308.08463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Distill Global Representation for Sparse-View CT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zilong Li</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+C">Chenglong Ma</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jie Chen</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Junping Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Shan%2C+H">Hongming Shan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item988">[988]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08530" title="Abstract">arXiv:2308.08530</a> (replaced) [<a href="/pdf/2308.08530" title="Download PDF">pdf</a>, <a href="/format/2308.08530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ref-DVGO: Reflection-Aware Direct Voxel Grid Optimization for an  Improved Quality-Efficiency Trade-Off in Reflective Scene Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kouros%2C+G">Georgios Kouros</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Minye Wu</a>, 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+S">Shubham Shrivastava</a>, 
<a href="/search/cs?searchtype=author&query=Nagesh%2C+S">Sushruth Nagesh</a>, 
<a href="/search/cs?searchtype=author&query=Chakravarty%2C+P">Punarjay Chakravarty</a>, 
<a href="/search/cs?searchtype=author&query=Tuytelaars%2C+T">Tinne Tuytelaars</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, 3 tables, ICCV TRICKY 2023 Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item989">[989]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08545" title="Abstract">arXiv:2308.08545</a> (replaced) [<a href="/pdf/2308.08545" title="Download PDF">pdf</a>, <a href="/format/2308.08545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TeCH: Text-guided Reconstruction of Lifelike Clothed Humans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yangyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+H">Hongwei Yi</a>, 
<a href="/search/cs?searchtype=author&query=Xiu%2C+Y">Yuliang Xiu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+T">Tingting Liao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiaxiang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Deng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Thies%2C+J">Justus Thies</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project: <a href="https://huangyangyi.github.io/TeCH">this https URL</a>, Code: <a href="https://github.com/huangyangyi/TeCH">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item990">[990]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08708" title="Abstract">arXiv:2308.08708</a> (replaced) [<a href="/pdf/2308.08708" title="Download PDF">pdf</a>, <a href="/format/2308.08708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consciousness in Artificial Intelligence: Insights from the Science of  Consciousness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Butlin%2C+P">Patrick Butlin</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+R">Robert Long</a>, 
<a href="/search/cs?searchtype=author&query=Elmoznino%2C+E">Eric Elmoznino</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>, 
<a href="/search/cs?searchtype=author&query=Birch%2C+J">Jonathan Birch</a>, 
<a href="/search/cs?searchtype=author&query=Constant%2C+A">Axel Constant</a>, 
<a href="/search/cs?searchtype=author&query=Deane%2C+G">George Deane</a>, 
<a href="/search/cs?searchtype=author&query=Fleming%2C+S+M">Stephen M. Fleming</a>, 
<a href="/search/cs?searchtype=author&query=Frith%2C+C">Chris Frith</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xu Ji</a>, 
<a href="/search/cs?searchtype=author&query=Kanai%2C+R">Ryota Kanai</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+C">Colin Klein</a>, 
<a href="/search/cs?searchtype=author&query=Lindsay%2C+G">Grace Lindsay</a>, 
<a href="/search/cs?searchtype=author&query=Michel%2C+M">Matthias Michel</a>, 
<a href="/search/cs?searchtype=author&query=Mudrik%2C+L">Liad Mudrik</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+M+A+K">Megan A. K. Peters</a>, 
<a href="/search/cs?searchtype=author&query=Schwitzgebel%2C+E">Eric Schwitzgebel</a>, 
<a href="/search/cs?searchtype=author&query=Simon%2C+J">Jonathan Simon</a>, 
<a href="/search/cs?searchtype=author&query=VanRullen%2C+R">Rufin VanRullen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item991">[991]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08747" title="Abstract">arXiv:2308.08747</a> (replaced) [<a href="/pdf/2308.08747" title="Download PDF">pdf</a>, <a href="/format/2308.08747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Study of Catastrophic Forgetting in Large Language Models  During Continual Fine-tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yun Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fandong Meng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yafu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item992">[992]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08780" title="Abstract">arXiv:2308.08780</a> (replaced) [<a href="/pdf/2308.08780" title="Download PDF">pdf</a>, <a href="/format/2308.08780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Demonstration Ensembling for In-context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khalifa%2C+M">Muhammad Khalifa</a>, 
<a href="/search/cs?searchtype=author&query=Logeswaran%2C+L">Lajanugen Logeswaran</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Moontae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Honglak Lee</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ME-FoMo workshop at ICLR 2023. Arxiv version includes evaluation on 5 more tasks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item993">[993]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08806" title="Abstract">arXiv:2308.08806</a> (replaced) [<a href="/pdf/2308.08806" title="Download PDF">pdf</a>, <a href="/format/2308.08806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-distillation Regularized Connectionist Temporal Classification Loss  for Text Recognition: A Simple Yet Effective Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziyin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+N">Ning Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+M">Minghui Liao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yongshuai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Cheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Min Wang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wei Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Ziyin Zhang and Ning Lu are co-first authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item994">[994]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08828" title="Abstract">arXiv:2308.08828</a> (replaced) [<a href="/pdf/2308.08828" title="Download PDF">pdf</a>, <a href="/format/2308.08828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lifted Algorithms for Symmetric Weighted First-Order Model Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuanhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+J">Juhua Pu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ku%C5%BEelka%2C+O">Ond&#x159;ej Ku&#x17e;elka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 47 pages, 6 figures. An expanded version of "On exact sampling in the two-variable fragment of first-order logic" in LICS23, submitted to AIJ. arXiv admin note: substantial text overlap with <a href="/abs/2302.02730">arXiv:2302.02730</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item995">[995]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08917" title="Abstract">arXiv:2308.08917</a> (replaced) [<a href="/pdf/2308.08917" title="Download PDF">pdf</a>, <a href="/format/2308.08917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unfolding for Joint Channel Estimation and Symbol Detection in MIMO  Communication Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+S">Swati Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Hari%2C+K+V+S">K.V.S. Hari</a>, 
<a href="/search/cs?searchtype=author&query=Eldar%2C+Y+C">Yonina C. Eldar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 19 figures, submitted to IEEE Transactions on Signal Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item996">[996]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08979" title="Abstract">arXiv:2308.08979</a> (replaced) [<a href="/pdf/2308.08979" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Digital Penetration of the Industrialized Society and its  Ensuing Transfiguration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vrana%2C+J">Johannes Vrana</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+R">Ripudaman Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 6 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item997">[997]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08998" title="Abstract">arXiv:2308.08998</a> (replaced) [<a href="/pdf/2308.08998" title="Download PDF">pdf</a>, <a href="/format/2308.08998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforced Self-Training (ReST) for Language Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gulcehre%2C+C">Caglar Gulcehre</a>, 
<a href="/search/cs?searchtype=author&query=Paine%2C+T+L">Tom Le Paine</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+S">Srivatsan Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Konyushkova%2C+K">Ksenia Konyushkova</a>, 
<a href="/search/cs?searchtype=author&query=Weerts%2C+L">Lotte Weerts</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Abhishek Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Siddhant%2C+A">Aditya Siddhant</a>, 
<a href="/search/cs?searchtype=author&query=Ahern%2C+A">Alex Ahern</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Miaosen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+C">Chenjie Gu</a>, 
<a href="/search/cs?searchtype=author&query=Macherey%2C+W">Wolfgang Macherey</a>, 
<a href="/search/cs?searchtype=author&query=Doucet%2C+A">Arnaud Doucet</a>, 
<a href="/search/cs?searchtype=author&query=Firat%2C+O">Orhan Firat</a>, 
<a href="/search/cs?searchtype=author&query=de+Freitas%2C+N">Nando de Freitas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item998">[998]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09228" title="Abstract">arXiv:2308.09228</a> (replaced) [<a href="/pdf/2308.09228" title="Download PDF">pdf</a>, <a href="/format/2308.09228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Sum Pooling for Metric Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gurbuz%2C+Y+Z">Yeti Z. Gurbuz</a>, 
<a href="/search/cs?searchtype=author&query=Sener%2C+O">Ozan Sener</a>, 
<a href="/search/cs?searchtype=author&query=Alatan%2C+A+A">A. Ayd&#x131;n Alatan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a conference paper at International Conference on Computer Vision (ICCV) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item999">[999]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09267" title="Abstract">arXiv:2308.09267</a> (replaced) [<a href="/pdf/2308.09267" title="Download PDF">pdf</a>, <a href="/format/2308.09267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Reasoning Capabilities of Large Language Models: A Graph-Based  Verification Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Lang Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1000">[1000]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09300" title="Abstract">arXiv:2308.09300</a> (replaced) [<a href="/pdf/2308.09300" title="Download PDF">pdf</a>, <a href="/format/2308.09300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> V2A-Mapper: A Lightweight Solution for Vision-to-Audio Generation by  Connecting Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Heng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jianbo Ma</a>, 
<a href="/search/cs?searchtype=author&query=Pascual%2C+S">Santiago Pascual</a>, 
<a href="/search/cs?searchtype=author&query=Cartwright%2C+R">Richard Cartwright</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Weidong Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 10 figures. Demo page: <a href="https://v2a-mapper.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1001">[1001]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09308" title="Abstract">arXiv:2308.09308</a> (replaced) [<a href="/pdf/2308.09308" title="Download PDF">pdf</a>, <a href="/format/2308.09308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Retrieval Augmentation via Generative Language Modeling  for E-commerce Query Intent Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chenyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yunjiang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yiming Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Han Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wen-Yun Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures; accepted by CIKM2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1002">[1002]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09357" title="Abstract">arXiv:2308.09357</a> (replaced) [<a href="/pdf/2308.09357" title="Download PDF">pdf</a>, <a href="/format/2308.09357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-scale Target-Aware Framework for Constrained Image Splicing  Detection and Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yuxuan Tan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanman Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+L">Limin Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jiaxiong Ye</a>, 
<a href="/search/cs?searchtype=author&query=wang%2C+W">Wei wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xia Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by ACMMM2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item1003">[1003]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09436" title="Abstract">arXiv:2308.09436</a> (replaced) [<a href="/pdf/2308.09436" title="Download PDF">pdf</a>, <a href="/format/2308.09436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer-based Detection of Microorganisms on High-Resolution Petri  Dish Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ebert%2C+N">Nikolas Ebert</a>, 
<a href="/search/cs?searchtype=author&query=Stricker%2C+D">Didier Stricker</a>, 
<a href="/search/cs?searchtype=author&query=Wasenm%C3%BCller%2C+O">Oliver Wasenm&#xfc;ller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted at IEEE International Conference on Computer Vision Workshops (ICCV workshop), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1004">[1004]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09442" title="Abstract">arXiv:2308.09442</a> (replaced) [<a href="/pdf/2308.09442" title="Download PDF">pdf</a>, <a href="/format/2308.09442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BioMedGPT: Open Multimodal Generative Pre-trained Transformer for  BioMedicine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yizhen Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiahuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Siqi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yushuai Wu</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+M">Mu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Z">Zaiqing Nie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item1005">[1005]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09487" title="Abstract">arXiv:2308.09487</a> (replaced) [<a href="/pdf/2308.09487" title="Download PDF">pdf</a>, <a href="/format/2308.09487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Poison Dart Frog: A Clean-Label Attack with Low Poisoning Rate and High  Attack Success Rate in the Absence of Training Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+B">Binhao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiahui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dejun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+B">Bo Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1006">[1006]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09658" title="Abstract">arXiv:2308.09658</a> (replaced) [<a href="/pdf/2308.09658" title="Download PDF">pdf</a>, <a href="/format/2308.09658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tree-of-Mixed-Thought: Combining Fast and Slow Thinking for Multi-hop  Visual Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+P">Pengbo Hu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Ji Qi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hong Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+B">Bing Quan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruiyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yi Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages,1 figures, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1007">[1007]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09687" title="Abstract">arXiv:2308.09687</a> (replaced) [<a href="/pdf/2308.09687" title="Download PDF">pdf</a>, <a href="/format/2308.09687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph of Thoughts: Solving Elaborate Problems with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Besta%2C+M">Maciej Besta</a>, 
<a href="/search/cs?searchtype=author&query=Blach%2C+N">Nils Blach</a>, 
<a href="/search/cs?searchtype=author&query=Kubicek%2C+A">Ales Kubicek</a>, 
<a href="/search/cs?searchtype=author&query=Gerstenberger%2C+R">Robert Gerstenberger</a>, 
<a href="/search/cs?searchtype=author&query=Gianinazzi%2C+L">Lukas Gianinazzi</a>, 
<a href="/search/cs?searchtype=author&query=Gajda%2C+J">Joanna Gajda</a>, 
<a href="/search/cs?searchtype=author&query=Lehmann%2C+T">Tomasz Lehmann</a>, 
<a href="/search/cs?searchtype=author&query=Podstawski%2C+M">Michal Podstawski</a>, 
<a href="/search/cs?searchtype=author&query=Niewiadomski%2C+H">Hubert Niewiadomski</a>, 
<a href="/search/cs?searchtype=author&query=Nyczyk%2C+P">Piotr Nyczyk</a>, 
<a href="/search/cs?searchtype=author&query=Hoefler%2C+T">Torsten Hoefler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1008">[1008]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09690" title="Abstract">arXiv:2308.09690</a> (replaced) [<a href="/pdf/2308.09690" title="Download PDF">pdf</a>, <a href="/format/2308.09690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random Walks, Conductance, and Resistance for the Connection Graph  Laplacian
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cloninger%2C+A">Alexander Cloninger</a>, 
<a href="/search/cs?searchtype=author&query=Mishne%2C+G">Gal Mishne</a>, 
<a href="/search/cs?searchtype=author&query=Oslandsbotn%2C+A">Andreas Oslandsbotn</a>, 
<a href="/search/cs?searchtype=author&query=Robertson%2C+S+J">Sawyer Jack Robertson</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Zhengchao Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yusu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item573">Cross-lists</a></li>
<li><a href="#item641">Replacements</a></li>
</ul>
<small>[ total of 1008 entries:  <b>1-1008</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2308">2308</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
